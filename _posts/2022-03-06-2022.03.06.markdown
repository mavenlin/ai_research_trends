Prev: [2022.03.05]({{ '/2022/03/05/2022.03.05.html' | relative_url }})  Next: [2022.03.07]({{ '/2022/03/07/2022.03.07.html' | relative_url }})
{% raw %}
## Summary for 2022-03-06, created on 2022-03-16


<details><summary><b>Systematic Comparison of Path Planning Algorithms using PathBench</b>
<a href="https://arxiv.org/abs/2203.03092">arxiv:2203.03092</a>
&#x1F4C8; 180 <br>
<p>Hao-Ya Hsueh, Alexandru-Iosif Toma, Hussein Ali Jaafar, Edward Stow, Riku Murai, Paul H. J. Kelly, Sajad Saeedi</p></summary>
<p>

**Abstract:** Path planning is an essential component of mobile robotics. Classical path planning algorithms, such as wavefront and rapidly-exploring random tree (RRT) are used heavily in autonomous robots. With the recent advances in machine learning, development of learning-based path planning algorithms has been experiencing rapid growth. An unified path planning interface that facilitates the development and benchmarking of existing and new algorithms is needed. This paper presents PathBench, a platform for developing, visualizing, training, testing, and benchmarking of existing and future, classical and learning-based path planning algorithms in 2D and 3D grid world environments. Many existing path planning algorithms are supported; e.g. A*, Dijkstra, waypoint planning networks, value iteration networks, gated path planning networks; and integrating new algorithms is easy and clearly specified. The benchmarking ability of PathBench is explored in this paper by comparing algorithms across five different hardware systems and three different map types, including built-in PathBench maps, video game maps, and maps from real world databases. Metrics, such as path length, success rate, and computational time, were used to evaluate algorithms. Algorithmic analysis was also performed on a real world robot to demonstrate PathBench's support for Robot Operating System (ROS). PathBench is open source.

</p>
</details>

<details><summary><b>GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation</b>
<a href="https://arxiv.org/abs/2203.02923">arxiv:2203.02923</a>
&#x1F4C8; 31 <br>
<p>Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, Jian Tang</p></summary>
<p>

**Abstract:** Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules.

</p>
</details>

<details><summary><b>HEAR 2021: Holistic Evaluation of Audio Representations</b>
<a href="https://arxiv.org/abs/2203.03022">arxiv:2203.03022</a>
&#x1F4C8; 22 <br>
<p>Joseph Turian, Jordie Shier, Humair Raj Khan, Bhiksha Raj, Björn W. Schuller, Christian J. Steinmetz, Colin Malloy, George Tzanetakis, Gissel Velarde, Kirk McNally, Max Henry, Nicolas Pinto, Camille Noufi, Christian Clough, Dorien Herremans, Eduardo Fonseca, Jesse Engel, Justin Salamon, Philippe Esling, Pranay Manocha, Shinji Watanabe, Zeyu Jin, Yonatan Bisk</p></summary>
<p>

**Abstract:** What audio embedding approach generalizes best to a wide range of downstream tasks across a variety of everyday domains without fine-tuning? The aim of the HEAR 2021 NeurIPS challenge is to develop a general-purpose audio representation that provides a strong basis for learning in a wide variety of tasks and scenarios. HEAR 2021 evaluates audio representations using a benchmark suite across a variety of domains, including speech, environmental sound, and music. In the spirit of shared exchange, each participant submitted an audio embedding model following a common API that is general-purpose, open-source, and freely available to use. Twenty-nine models by thirteen external teams were evaluated on nineteen diverse downstream tasks derived from sixteen datasets. Open evaluation code, submitted models and datasets are key contributions, enabling comprehensive and reproducible evaluation, as well as previously impossible longitudinal studies. It still remains an open question whether one single general-purpose audio representation can perform as holistically as the human ear.

</p>
</details>

<details><summary><b>Differentially Private Federated Learning with Local Regularization and Sparsification</b>
<a href="https://arxiv.org/abs/2203.03106">arxiv:2203.03106</a>
&#x1F4C8; 7 <br>
<p>Anda Cheng, Peisong Wang, Xi Sheryl Zhang, Jian Cheng</p></summary>
<p>

**Abstract:** User-level differential privacy (DP) provides certifiable privacy guarantees to the information that is specific to any user's data in federated learning. Existing methods that ensure user-level DP come at the cost of severe accuracy decrease. In this paper, we study the cause of model performance degradation in federated learning under user-level DP guarantee. We find the key to solving this issue is to naturally restrict the norm of local updates before executing operations that guarantee DP. To this end, we propose two techniques, Bounded Local Update Regularization and Local Update Sparsification, to increase model quality without sacrificing privacy. We provide theoretical analysis on the convergence of our framework and give rigorous privacy guarantees. Extensive experiments show that our framework significantly improves the privacy-utility trade-off over the state-of-the-arts for federated learning with user-level DP guarantee.

</p>
</details>

<details><summary><b>GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction</b>
<a href="https://arxiv.org/abs/2203.03079">arxiv:2203.03079</a>
&#x1F4C8; 6 <br>
<p>Kareem Metwaly, Aerin Kim, Elliot Branson, Vishal Monga</p></summary>
<p>

**Abstract:** Attaching attributes (such as color, shape, state, action) to object categories is an important computer vision problem. Attribute prediction has seen exciting recent progress and is often formulated as a multi-label classification problem. Yet significant challenges remain in: 1) predicting diverse attributes over multiple categories, 2) modeling attributes-category dependency, 3) capturing both global and local scene context, and 4) predicting attributes of objects with low pixel-count. To address these issues, we propose a novel multi-category attribute prediction deep architecture named GlideNet, which contains three distinct feature extractors. A global feature extractor recognizes what objects are present in a scene, whereas a local one focuses on the area surrounding the object of interest. Meanwhile, an intrinsic feature extractor uses an extension of standard convolution dubbed Informed Convolution to retrieve features of objects with low pixel-count. GlideNet uses gating mechanisms with binary masks and its self-learned category embedding to combine the dense embeddings. Collectively, the Global-Local-Intrinsic blocks comprehend the scene's global context while attending to the characteristics of the local object of interest. Finally, using the combined features, an interpreter predicts the attributes, and the length of the output is determined by the category, thereby removing unnecessary attributes. GlideNet can achieve compelling results on two recent and challenging datasets -- VAW and CAR -- for large-scale attribute prediction. For instance, it obtains more than 5\% gain over state of the art in the mean recall (mR) metric. GlideNet's advantages are especially apparent when predicting attributes of objects with low pixel counts as well as attributes that demand global context understanding. Finally, we show that GlideNet excels in training starved real-world scenarios.

</p>
</details>

<details><summary><b>HAR-GCNN: Deep Graph CNNs for Human Activity Recognition From Highly Unlabeled Mobile Sensor Data</b>
<a href="https://arxiv.org/abs/2203.03087">arxiv:2203.03087</a>
&#x1F4C8; 5 <br>
<p>Abduallah Mohamed, Fernando Lejarza, Stephanie Cahail, Christian Claudel, Edison Thomaz</p></summary>
<p>

**Abstract:** The problem of human activity recognition from mobile sensor data applies to multiple domains, such as health monitoring, personal fitness, daily life logging, and senior care. A critical challenge for training human activity recognition models is data quality. Acquiring balanced datasets containing accurate activity labels requires humans to correctly annotate and potentially interfere with the subjects' normal activities in real-time. Despite the likelihood of incorrect annotation or lack thereof, there is often an inherent chronology to human behavior. For example, we take a shower after we exercise. This implicit chronology can be used to learn unknown labels and classify future activities. In this work, we propose HAR-GCCN, a deep graph CNN model that leverages the correlation between chronologically adjacent sensor measurements to predict the correct labels for unclassified activities that have at least one activity label. We propose a new training strategy enforcing that the model predicts the missing activity labels by leveraging the known ones. HAR-GCCN shows superior performance relative to previously used baseline methods, improving classification accuracy by about 25% and up to 68% on different datasets. Code is available at \url{https://github.com/abduallahmohamed/HAR-GCNN}.

</p>
</details>

<details><summary><b>On the importance of stationarity, strong baselines and benchmarks in transport prediction problems</b>
<a href="https://arxiv.org/abs/2203.02954">arxiv:2203.02954</a>
&#x1F4C8; 5 <br>
<p>Filipe Rodrigues</p></summary>
<p>

**Abstract:** Over the last years, the transportation community has witnessed a tremendous amount of research contributions on new deep learning approaches for spatio-temporal forecasting. These contributions tend to emphasize the modeling of spatial correlations, while neglecting the fairly stable and recurrent nature of human mobility patterns. In this short paper, we show that a naive baseline method based on the average weekly pattern and linear regression can achieve comparable results to many state-of-the-art deep learning approaches for spatio-temporal forecasting in transportation, or even outperform them on several datasets, thus contrasting the importance of stationarity and recurrent patterns in the data with the importance of spatial correlations. Furthermore, we establish 9 different reference benchmarks that can be used to compare new approaches for spatio-temporal forecasting, and provide a discussion on best practices and the direction that the field is taking.

</p>
</details>

<details><summary><b>Fluid registration between lung CT and stationary chest tomosynthesis images</b>
<a href="https://arxiv.org/abs/2203.04958">arxiv:2203.04958</a>
&#x1F4C8; 4 <br>
<p>Lin Tian, Connor Puett, Peirong Liu, Zhengyang Shen, Stephen R. Aylward, Yueh Z. Lee, Marc Niethammer</p></summary>
<p>

**Abstract:** Registration is widely used in image-guided therapy and image-guided surgery to estimate spatial correspondences between organs of interest between planning and treatment images. However, while high-quality computed tomography (CT) images are often available at planning time, limited angle acquisitions are frequently used during treatment because of radiation concerns or imaging time constraints. This requires algorithms to register CT images based on limited angle acquisitions. We, therefore, formulate a 3D/2D registration approach which infers a 3D deformation based on measured projections and digitally reconstructed radiographs of the CT. Most 3D/2D registration approaches use simple transformation models or require complex mathematical derivations to formulate the underlying optimization problem. Instead, our approach entirely relies on differentiable operations which can be combined with modern computational toolboxes supporting automatic differentiation. This then allows for rapid prototyping, integration with deep neural networks, and to support a variety of transformation models including fluid flow models. We demonstrate our approach for the registration between CT and stationary chest tomosynthesis (sDCT) images and show how it naturally leads to an iterative image reconstruction approach.

</p>
</details>

<details><summary><b>P2M: A Processing-in-Pixel-in-Memory Paradigm for Resource-Constrained TinyML Applications</b>
<a href="https://arxiv.org/abs/2203.04737">arxiv:2203.04737</a>
&#x1F4C8; 4 <br>
<p>Gourav Datta, Souvik Kundu, Zihan Yin, Ravi Teja Lakkireddy, Peter A. Beerel, Ajey Jacob, Akhilesh R. Jaiswal</p></summary>
<p>

**Abstract:** The demand to process vast amounts of data generated from state-of-the-art high resolution cameras has motivated novel energy-efficient on-device AI solutions. Visual data in such cameras are usually captured in the form of analog voltages by a sensor pixel array, and then converted to the digital domain for subsequent AI processing using analog-to-digital converters (ADC). Recent research has tried to take advantage of massively parallel low-power analog/digital computing in the form of near- and in-sensor processing, in which the AI computation is performed partly in the periphery of the pixel array and partly in a separate on-board CPU/accelerator. Unfortunately, high-resolution input images still need to be streamed between the camera and the AI processing unit, frame by frame, causing energy, bandwidth, and security bottlenecks. To mitigate this problem, we propose a novel Processing-in-Pixel-in-memory (P2M) paradigm, that customizes the pixel array by adding support for analog multi-channel, multi-bit convolution and ReLU (Rectified Linear Units). Our solution includes a holistic algorithm-circuit co-design approach and the resulting P2M paradigm can be used as a drop-in replacement for embedding memory-intensive first few layers of convolutional neural network (CNN) models within foundry-manufacturable CMOS image sensor platforms. Our experimental results indicate that P2M reduces data transfer bandwidth from sensors and analog to digital conversions by ~21x, and the energy-delay product (EDP) incurred in processing a MobileNetV2 model on a TinyML use case for visual wake words dataset (VWW) by up to ~11x compared to standard near-processing or in-sensor implementations, without any significant drop in test accuracy.

</p>
</details>

<details><summary><b>Is Bayesian Model-Agnostic Meta Learning Better than Model-Agnostic Meta Learning, Provably?</b>
<a href="https://arxiv.org/abs/2203.03059">arxiv:2203.03059</a>
&#x1F4C8; 3 <br>
<p>Lisha Chen, Tianyi Chen</p></summary>
<p>

**Abstract:** Meta learning aims at learning a model that can quickly adapt to unseen tasks. Widely used meta learning methods include model agnostic meta learning (MAML), implicit MAML, Bayesian MAML. Thanks to its ability of modeling uncertainty, Bayesian MAML often has advantageous empirical performance. However, the theoretical understanding of Bayesian MAML is still limited, especially on questions such as if and when Bayesian MAML has provably better performance than MAML. In this paper, we aim to provide theoretical justifications for Bayesian MAML's advantageous performance by comparing the meta test risks of MAML and Bayesian MAML. In the meta linear regression, under both the distribution agnostic and linear centroid cases, we have established that Bayesian MAML indeed has provably lower meta test risks than MAML. We verify our theoretical results through experiments.

</p>
</details>

<details><summary><b>Offline Deep Reinforcement Learning for Dynamic Pricing of Consumer Credit</b>
<a href="https://arxiv.org/abs/2203.03003">arxiv:2203.03003</a>
&#x1F4C8; 3 <br>
<p>Raad Khraishi, Ramin Okhrati</p></summary>
<p>

**Abstract:** We introduce a method for pricing consumer credit using recent advances in offline deep reinforcement learning. This approach relies on a static dataset and requires no assumptions on the functional form of demand. Using both real and synthetic data on consumer credit applications, we demonstrate that our approach using the conservative Q-Learning algorithm is capable of learning an effective personalized pricing policy without any online interaction or price experimentation.

</p>
</details>

<details><summary><b>Dynamic Key-value Memory Enhanced Multi-step Graph Reasoning for Knowledge-based Visual Question Answering</b>
<a href="https://arxiv.org/abs/2203.02985">arxiv:2203.02985</a>
&#x1F4C8; 3 <br>
<p>Mingxiao Li, Marie-Francine Moens</p></summary>
<p>

**Abstract:** Knowledge-based visual question answering (VQA) is a vision-language task that requires an agent to correctly answer image-related questions using knowledge that is not presented in the given image. It is not only a more challenging task than regular VQA but also a vital step towards building a general VQA system. Most existing knowledge-based VQA systems process knowledge and image information similarly and ignore the fact that the knowledge base (KB) contains complete information about a triplet, while the extracted image information might be incomplete as the relations between two objects are missing or wrongly detected. In this paper, we propose a novel model named dynamic knowledge memory enhanced multi-step graph reasoning (DMMGR), which performs explicit and implicit reasoning over a key-value knowledge memory module and a spatial-aware image graph, respectively. Specifically, the memory module learns a dynamic knowledge representation and generates a knowledge-aware question representation at each reasoning step. Then, this representation is used to guide a graph attention operator over the spatial-aware image graph. Our model achieves new state-of-the-art accuracy on the KRVQR and FVQA datasets. We also conduct ablation experiments to prove the effectiveness of each component of the proposed model.

</p>
</details>

<details><summary><b>Deep Learning the Shape of the Brain Connectome</b>
<a href="https://arxiv.org/abs/2203.06122">arxiv:2203.06122</a>
&#x1F4C8; 2 <br>
<p>Haocheng Dai, Martin Bauer, P. Thomas Fletcher, Sarang C. Joshi</p></summary>
<p>

**Abstract:** To statistically study the variability and differences between normal and abnormal brain connectomes, a mathematical model of the neural connections is required. In this paper, we represent the brain connectome as a Riemannian manifold, which allows us to model neural connections as geodesics. We show for the first time how one can leverage deep neural networks to estimate a Riemannian metric of the brain that can accommodate fiber crossings and is a natural modeling tool to infer the shape of the brain from DWMRI. Our method achieves excellent performance in geodesic-white-matter-pathway alignment and tackles the long-standing issue in previous methods: the inability to recover the crossing fibers with high fidelity.

</p>
</details>

<details><summary><b>Mismatch between Multi-turn Dialogue and its Evaluation Metric in Dialogue State Tracking</b>
<a href="https://arxiv.org/abs/2203.03123">arxiv:2203.03123</a>
&#x1F4C8; 2 <br>
<p>Takyoung Kim, Hoonsang Yoon, Yukyung Lee, Pilsung Kang, Misuk Kim</p></summary>
<p>

**Abstract:** Dialogue state tracking (DST) aims to extract essential information from multi-turn dialogue situations and take appropriate actions. A belief state, one of the core pieces of information, refers to the subject and its specific content, and appears in the form of \texttt{domain-slot-value}. The trained model predicts "accumulated" belief states in every turn, and joint goal accuracy and slot accuracy are mainly used to evaluate the prediction; however, we specify that the current evaluation metrics have a critical limitation when evaluating belief states accumulated as the dialogue proceeds, especially in the most used MultiWOZ dataset. Additionally, we propose \textbf{relative slot accuracy} to complement existing metrics. Relative slot accuracy does not depend on the number of predefined slots, and allows intuitive evaluation by assigning relative scores according to the turn of each dialogue. This study also encourages not solely the reporting of joint goal accuracy, but also various complementary metrics in DST tasks for the sake of a realistic evaluation.

</p>
</details>

<details><summary><b>Prediction of transport property via machine learning molecular movements</b>
<a href="https://arxiv.org/abs/2203.03103">arxiv:2203.03103</a>
&#x1F4C8; 2 <br>
<p>Ikki Yasuda, Yusei Kobayashi, Katsuhiro Endo, Yoshihiro Hayakawa, Kazuhiko Fujiwara, Kuniaki Yajima, Noriyoshi Arai, Kenji Yasuoka</p></summary>
<p>

**Abstract:** Molecular dynamics (MD) simulations are increasingly being combined with machine learning (ML) to predict material properties. The molecular configurations obtained from MD are represented by multiple features, such as thermodynamic properties, and are used as the ML input. However, to accurately find the input--output patterns, ML requires a sufficiently sized dataset that depends on the complexity of the ML model. Generating such a large dataset from MD simulations is not ideal because of their high computation cost. In this study, we present a simple supervised ML method to predict the transport properties of materials. To simplify the model, an unsupervised ML method obtains an efficient representation of molecular movements. This method was applied to predict the viscosity of lubricant molecules in confinement with shear flow. Furthermore, simplicity facilitates the interpretation of the model to understand the molecular mechanics of viscosity. We revealed two types of molecular mechanisms that contribute to low viscosity.

</p>
</details>

<details><summary><b>ILDAE: Instance-Level Difficulty Analysis of Evaluation Data</b>
<a href="https://arxiv.org/abs/2203.03073">arxiv:2203.03073</a>
&#x1F4C8; 2 <br>
<p>Neeraj Varshney, Swaroop Mishra, Chitta Baral</p></summary>
<p>

**Abstract:** Knowledge of questions' difficulty level helps a teacher in several ways, such as estimating students' potential quickly by asking carefully selected questions and improving quality of examination by modifying trivial and hard questions. Can we extract such benefits of instance difficulty in NLP? To this end, we conduct Instance-Level Difficulty Analysis of Evaluation data (ILDAE) in a large-scale setup of 23 datasets and demonstrate its five novel applications: 1) conducting efficient-yet-accurate evaluations with fewer instances saving computational cost and time, 2) improving quality of existing evaluation datasets by repairing erroneous and trivial instances, 3) selecting the best model based on application requirements, 4) analyzing dataset characteristics for guiding future data creation, 5) estimating Out-of-Domain performance reliably. Comprehensive experiments for these applications result in several interesting findings, such as evaluation using just 5% instances (selected via ILDAE) achieves as high as 0.93 Kendall correlation with evaluation using complete dataset and computing weighted accuracy using difficulty scores leads to 5.2% higher correlation with Out-of-Domain performance. We release the difficulty scores and hope our analyses and findings will bring more attention to this important yet understudied field of leveraging instance difficulty in evaluations.

</p>
</details>

<details><summary><b>Story Point Effort Estimation by Text Level Graph Neural Network</b>
<a href="https://arxiv.org/abs/2203.03062">arxiv:2203.03062</a>
&#x1F4C8; 2 <br>
<p>Hung Phan, Ali Jannesari</p></summary>
<p>

**Abstract:** Estimating the software projects' efforts developed by agile methods is important for project managers or technical leads. It provides a summary as a first view of how many hours and developers are required to complete the tasks. There are research works on automatic predicting the software efforts, including Term Frequency Inverse Document Frequency (TFIDF) as the traditional approach for this problem. Graph Neural Network is a new approach that has been applied in Natural Language Processing for text classification. The advantages of Graph Neural Network are based on the ability to learn information via graph data structure, which has more representations such as the relationships between words compared to approaches of vectorizing sequence of words. In this paper, we show the potential and possible challenges of Graph Neural Network text classification in story point level estimation. By the experiments, we show that the GNN Text Level Classification can achieve as high accuracy as about 80 percent for story points level classification, which is comparable to the traditional approach. We also analyze the GNN approach and point out several current disadvantages that the GNN approach can improve for this problem or other problems in software engineering.

</p>
</details>

<details><summary><b>Recent Advances in Neural Text Generation: A Task-Agnostic Survey</b>
<a href="https://arxiv.org/abs/2203.03047">arxiv:2203.03047</a>
&#x1F4C8; 2 <br>
<p>Chen Tang, Frank Guerin, Yucheng Li, Chenghua Lin</p></summary>
<p>

**Abstract:** In recent years much effort has been devoted to applying neural models to the task of natural language generation. The challenge is to generate natural human-like text, and to control the generation process. This paper presents a task-agnostic survey of recent advances in neural text generation. These advances have been achieved by numerous developments, which we group under the following four headings: data construction, neural frameworks, training and inference strategies, and evaluation metrics. Finally we discuss the future directions for the development of neural text generation including neural pipelines and exploiting back-ground knowledge.

</p>
</details>

<details><summary><b>Modeling Coreference Relations in Visual Dialog</b>
<a href="https://arxiv.org/abs/2203.02986">arxiv:2203.02986</a>
&#x1F4C8; 2 <br>
<p>Mingxiao Li, Marie-Francine Moens</p></summary>
<p>

**Abstract:** Visual dialog is a vision-language task where an agent needs to answer a series of questions grounded in an image based on the understanding of the dialog history and the image. The occurrences of coreference relations in the dialog makes it a more challenging task than visual question-answering. Most previous works have focused on learning better multi-modal representations or on exploring different ways of fusing visual and language features, while the coreferences in the dialog are mainly ignored. In this paper, based on linguistic knowledge and discourse features of human dialog we propose two soft constraints that can improve the model's ability of resolving coreferences in dialog in an unsupervised way. Experimental results on the VisDial v1.0 dataset shows that our model, which integrates two novel and linguistically inspired soft constraints in a deep transformer neural architecture, obtains new state-of-the-art performance in terms of recall at 1 and other evaluation metrics compared to current existing models and this without pretraining on other vision-language datasets. Our qualitative results also demonstrate the effectiveness of the method that we propose.

</p>
</details>

<details><summary><b>A Perspective on Robotic Telepresence and Teleoperation using Cognition: Are we there yet?</b>
<a href="https://arxiv.org/abs/2203.02959">arxiv:2203.02959</a>
&#x1F4C8; 2 <br>
<p>Hrishav Bakul Barua, Ashis Sau, Ruddra dev Roychoudhury</p></summary>
<p>

**Abstract:** Telepresence and teleoperation robotics have attracted a great amount of attention in the last 10 years. With the Artificial Intelligence (AI) revolution already being started, we can see a wide range of robotic applications being realized. Intelligent robotic systems are being deployed both in industrial and domestic environments. Telepresence is the idea of being present in a remote location virtually or via robotic avatars. Similarly, the idea of operating a robot from a remote location for various tasks is called teleoperation. These technologies find significant application in health care, education, surveillance, disaster recovery, and corporate/government sectors. But question still remains about their maturity, security and safety levels. We also need to think about enhancing the user experience and trust in such technologies going into the next generation of computing.

</p>
</details>

<details><summary><b>On Steering Multi-Annotations per Sample for Multi-Task Learning</b>
<a href="https://arxiv.org/abs/2203.02946">arxiv:2203.02946</a>
&#x1F4C8; 2 <br>
<p>Yuanze Li, Yiwen Guo, Qizhang Li, Hongzhi Zhang, Wangmeng Zuo</p></summary>
<p>

**Abstract:** The study of multi-task learning has drawn great attention from the community. Despite the remarkable progress, the challenge of optimally learning different tasks simultaneously remains to be explored. Previous works attempt to modify the gradients from different tasks. Yet these methods give a subjective assumption of the relationship between tasks, and the modified gradient may be less accurate. In this paper, we introduce Stochastic Task Allocation~(STA), a mechanism that addresses this issue by a task allocation approach, in which each sample is randomly allocated a subset of tasks. For further progress, we propose Interleaved Stochastic Task Allocation~(ISTA) to iteratively allocate all tasks to each example during several consecutive iterations. We evaluate STA and ISTA on various datasets and applications: NYUv2, Cityscapes, and COCO for scene understanding and instance segmentation. Our experiments show both STA and ISTA outperform current state-of-the-art methods. The code will be available.

</p>
</details>

<details><summary><b>A Robust Framework of Chromosome Straightening with ViT-Patch GAN</b>
<a href="https://arxiv.org/abs/2203.02901">arxiv:2203.02901</a>
&#x1F4C8; 2 <br>
<p>Sifan Song, Jinfeng Wang, Fengrui Cheng, Qirui Cao, Yihan Zuo, Yongteng Lei, Ruomai Yang, Chunxiao Yang, Frans Coenen, Jia Meng, Kang Dang, Jionglong Su</p></summary>
<p>

**Abstract:** Chromosomes exhibit non-rigid and non-articulated nature with varying degrees of curvature. Chromosome straightening is an essential step for subsequent karyotype construction, pathological diagnosis and cytogenetic map development. However, robust chromosome straightening remains challenging, due to the unavailability of training images, distorted chromosome details and shapes after straightening, as well as poor generalization capability. We propose a novel architecture, ViT-Patch GAN, consisting of a motion transformation generator and a Vision Transformer-based patch (ViT-Patch) discriminator. The generator learns the motion representation of chromosomes for straightening. With the help of the ViT-Patch discriminator, the straightened chromosomes retain more shape and banding pattern details. The proposed framework is trained on a small dataset and is able to straighten chromosome images with state-of-the-art performance for two large datasets.

</p>
</details>

<details><summary><b>Focus on the Target's Vocabulary: Masked Label Smoothing for Machine Translation</b>
<a href="https://arxiv.org/abs/2203.02889">arxiv:2203.02889</a>
&#x1F4C8; 2 <br>
<p>Liang Chen, Runxin Xu, Baobao Chang</p></summary>
<p>

**Abstract:** Label smoothing and vocabulary sharing are two widely used techniques in neural machine translation models. However, we argue that simply applying both techniques can be conflicting and even leads to sub-optimal performance. When allocating smoothed probability, original label smoothing treats the source-side words that would never appear in the target language equally to the real target-side words, which could bias the translation model. To address this issue, we propose Masked Label Smoothing (MLS), a new mechanism that masks the soft label probability of source-side words to zero. Simple yet effective, MLS manages to better integrate label smoothing with vocabulary sharing. Our extensive experiments show that MLS consistently yields improvement over original label smoothing on different datasets, including bilingual and multilingual translation from both translation quality and model's calibration. Our code is released at https://github.com/PKUnlp-icler/MLS

</p>
</details>

<details><summary><b>Student Become Decathlon Master in Retinal Vessel Segmentation via Dual-teacher Multi-target Domain Adaptation</b>
<a href="https://arxiv.org/abs/2203.03631">arxiv:2203.03631</a>
&#x1F4C8; 1 <br>
<p>Linkai Peng, Li Lin, Pujin Cheng, Huaqing He, Xiaoying Tang</p></summary>
<p>

**Abstract:** Unsupervised domain adaptation has been proposed recently to tackle the so-called domain shift between training data and test data with different distributions. However, most of them only focus on single-target domain adaptation and cannot be applied to the scenario with multiple target domains. In this paper, we propose RVms, a novel unsupervised multi-target domain adaptation approach to segment retinal vessels (RVs) from multimodal and multicenter retinal images. RVms mainly consists of a style augmentation and transfer (SAT) module and a dual-teacher knowledge distillation (DTKD) module. SAT augments and clusters images into source-similar domains and source-dissimilar domains via Bézier and Fourier transformations. DTKD utilizes the augmented and transformed data to train two teachers, one for source-similar domains and the other for source-dissimilar domains. Afterwards, knowledge distillation is performed to iteratively distill different domain knowledge from teachers to a generic student. The local relative intensity transformation is employed to characterize RVs in a domain invariant manner and promote the generalizability of teachers and student models. Moreover, we construct a new multimodal and multicenter vascular segmentation dataset from existing publicly-available datasets, which can be used to benchmark various domain adaptation and domain generalization methods. Through extensive experiments, RVms is found to be very close to the target-trained Oracle in terms of segmenting the RVs, largely outperforming other state-of-the-art methods.

</p>
</details>

<details><summary><b>Searching for Robust Neural Architectures via Comprehensive and Reliable Evaluation</b>
<a href="https://arxiv.org/abs/2203.03128">arxiv:2203.03128</a>
&#x1F4C8; 1 <br>
<p>Jialiang Sun, Tingsong Jiang, Chao Li, Weien Zhou, Xiaoya Zhang, Wen Yao, Xiaoqian Chen</p></summary>
<p>

**Abstract:** Neural architecture search (NAS) could help search for robust network architectures, where defining robustness evaluation metrics is the important procedure. However, current robustness evaluations in NAS are not sufficiently comprehensive and reliable. In particular, the common practice only considers adversarial noise and quantified metrics such as the Jacobian matrix, whereas, some studies indicated that the models are also vulnerable to other types of noises such as natural noise. In addition, existing methods taking adversarial noise as the evaluation just use the robust accuracy of the FGSM or PGD, but these adversarial attacks could not provide the adequately reliable evaluation, leading to the vulnerability of the models under stronger attacks. To alleviate the above problems, we propose a novel framework, called Auto Adversarial Attack and Defense (AAAD), where we employ neural architecture search methods, and four types of robustness evaluations are considered, including adversarial noise, natural noise, system noise and quantified metrics, thereby assisting in finding more robust architectures. Also, among the adversarial noise, we use the composite adversarial attack obtained by random search as the new metric to evaluate the robustness of the model architectures. The empirical results on the CIFAR10 dataset show that the searched efficient attack could help find more robust architectures.

</p>
</details>

<details><summary><b>Fast and Data Efficient Reinforcement Learning from Pixels via Non-Parametric Value Approximation</b>
<a href="https://arxiv.org/abs/2203.03078">arxiv:2203.03078</a>
&#x1F4C8; 1 <br>
<p>Alexander Long, Alan Blair, Herke van Hoof</p></summary>
<p>

**Abstract:** We present Nonparametric Approximation of Inter-Trace returns (NAIT), a Reinforcement Learning algorithm for discrete action, pixel-based environments that is both highly sample and computation efficient. NAIT is a lazy-learning approach with an update that is equivalent to episodic Monte-Carlo on episode completion, but that allows the stable incorporation of rewards while an episode is ongoing. We make use of a fixed domain-agnostic representation, simple distance based exploration and a proximity graph-based lookup to facilitate extremely fast execution. We empirically evaluate NAIT on both the 26 and 57 game variants of ATARI100k where, despite its simplicity, it achieves competitive performance in the online setting with greater than 100x speedup in wall-time.

</p>
</details>

<details><summary><b>Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography</b>
<a href="https://arxiv.org/abs/2203.03074">arxiv:2203.03074</a>
&#x1F4C8; 1 <br>
<p>Fakrul Islam Tushar, Ehsan Abadi, Saman Sotoudeh-Paima, Rafael B. Fricks, Maciej A. Mazurowski, W. Paul Segars, Ehsan Samei, Joseph Y. Lo</p></summary>
<p>

**Abstract:** Research studies of artificial intelligence models in medical imaging have been hampered by poor generalization. This problem has been especially concerning over the last year with numerous applications of deep learning for COVID-19 diagnosis. Virtual imaging trials (VITs) could provide a solution for objective evaluation of these models. In this work utilizing the VITs, we created the CVIT-COVID dataset including 180 virtually imaged computed tomography (CT) images from simulated COVID-19 and normal phantom models under different COVID-19 morphology and imaging properties. We evaluated the performance of an open-source, deep-learning model from the University of Waterloo trained with multi-institutional data and an in-house model trained with the open clinical dataset called MosMed. We further validated the model's performance against open clinical data of 305 CT images to understand virtual vs. real clinical data performance. The open-source model was published with nearly perfect performance on the original Waterloo dataset but showed a consistent performance drop in external testing on another clinical dataset (AUC=0.77) and our simulated CVIT-COVID dataset (AUC=0.55). The in-house model achieved an AUC of 0.87 while testing on the internal test set (MosMed test set). However, performance dropped to an AUC of 0.65 and 0.69 when evaluated on clinical and our simulated CVIT-COVID dataset. The VIT framework offered control over imaging conditions, allowing us to show there was no change in performance as CT exposure was changed from 28.5 to 57 mAs. The VIT framework also provided voxel-level ground truth, revealing that performance of in-house model was much higher at AUC=0.87 for diffuse COVID-19 infection size >2.65% lung volume versus AUC=0.52 for focal disease with <2.65% volume. The virtual imaging framework enabled these uniquely rigorous analyses of model performance.

</p>
</details>

<details><summary><b>Leashing the Inner Demons: Self-Detoxification for Language Models</b>
<a href="https://arxiv.org/abs/2203.03072">arxiv:2203.03072</a>
&#x1F4C8; 1 <br>
<p>Canwen Xu, Zexue He, Zhankui He, Julian McAuley</p></summary>
<p>

**Abstract:** Language models (LMs) can reproduce (or amplify) toxic language seen during training, which poses a risk to their practical application. In this paper, we conduct extensive experiments to study this phenomenon. We analyze the impact of prompts, decoding strategies and training corpora on the output toxicity. Based on our findings, we propose a simple yet effective method for language models to "detoxify" themselves without an additional large corpus or external discriminator. Compared to a supervised baseline, our proposed method shows better toxicity reduction with good generation quality in the generated content under multiple settings. Warning: some examples shown in the paper may contain uncensored offensive content.

</p>
</details>

<details><summary><b>Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation</b>
<a href="https://arxiv.org/abs/2203.03057">arxiv:2203.03057</a>
&#x1F4C8; 1 <br>
<p>Abduallah Mohamed, Deyao Zhu, Warren Vu, Mohamed Elhoseiny, Christian Claudel</p></summary>
<p>

**Abstract:** Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in real time of about 580Hz and achieves competitive results. Interactive demo of the problem can be seen here \url{https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo}. Code is available at \url{https://github.com/abduallahmohamed/Social-Implicit}.

</p>
</details>

<details><summary><b>A Unified View of SDP-based Neural Network Verification through Completely Positive Programming</b>
<a href="https://arxiv.org/abs/2203.03034">arxiv:2203.03034</a>
&#x1F4C8; 1 <br>
<p>Robin Brown, Edward Schmerling, Navid Azizan, Marco Pavone</p></summary>
<p>

**Abstract:** Verifying that input-output relationships of a neural network conform to prescribed operational specifications is a key enabler towards deploying these networks in safety-critical applications. Semidefinite programming (SDP)-based approaches to Rectified Linear Unit (ReLU) network verification transcribe this problem into an optimization problem, where the accuracy of any such formulation reflects the level of fidelity in how the neural network computation is represented, as well as the relaxations of intractable constraints. While the literature contains much progress on improving the tightness of SDP formulations while maintaining tractability, comparatively little work has been devoted to the other extreme, i.e., how to most accurately capture the original verification problem before SDP relaxation. In this work, we develop an exact, convex formulation of verification as a completely positive program (CPP), and provide analysis showing that our formulation is minimal -- the removal of any constraint fundamentally misrepresents the neural network computation. We leverage our formulation to provide a unifying view of existing approaches, and give insight into the source of large relaxation gaps observed in some cases.

</p>
</details>

<details><summary><b>Single microphone speaker extraction using unified time-frequency Siamese-Unet</b>
<a href="https://arxiv.org/abs/2203.02941">arxiv:2203.02941</a>
&#x1F4C8; 1 <br>
<p>Aviad Eisenberg, Sharon Gannot, Shlomo E. Chazan</p></summary>
<p>

**Abstract:** In this paper we present a unified time-frequency method for speaker extraction in clean and noisy conditions. Given a mixed signal, along with a reference signal, the common approaches for extracting the desired speaker are either applied in the time-domain or in the frequency-domain. In our approach, we propose a Siamese-Unet architecture that uses both representations. The Siamese encoders are applied in the frequency-domain to infer the embedding of the noisy and reference spectra, respectively. The concatenated representations are then fed into the decoder to estimate the real and imaginary components of the desired speaker, which are then inverse-transformed to the time-domain. The model is trained with the Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) loss to exploit the time-domain information. The time-domain loss is also regularized with frequency-domain loss to preserve the speech patterns. Experimental results demonstrate that the unified approach is not only very easy to train, but also provides superior results as compared with state-of-the-art (SOTA) Blind Source Separation (BSS) methods, as well as commonly used speaker extraction approach.

</p>
</details>

<details><summary><b>Detection of Parasitic Eggs from Microscopy Images and the emergence of a new dataset</b>
<a href="https://arxiv.org/abs/2203.02940">arxiv:2203.02940</a>
&#x1F4C8; 1 <br>
<p>Perla Mayo, Nantheera Anantrasirichai, Thanarat H. Chalidabhongse, Duangdao Palasuwan, Alin Achim</p></summary>
<p>

**Abstract:** Automatic detection of parasitic eggs in microscopy images has the potential to increase the efficiency of human experts whilst also providing an objective assessment. The time saved by such a process would both help ensure a prompt treatment to patients, and off-load excessive work from experts' shoulders. Advances in deep learning inspired us to exploit successful architectures for detection, adapting them to tackle a different domain. We propose a framework that exploits two such state-of-the-art models. Specifically, we demonstrate results produced by both a Generative Adversarial Network (GAN) and Faster-RCNN, for image enhancement and object detection respectively, on microscopy images of varying quality. The use of these techniques yields encouraging results, though further improvements are still needed for certain egg types whose detection still proves challenging. As a result, a new dataset has been created and made publicly available, providing an even wider range of classes and variability.

</p>
</details>

<details><summary><b>Evaluation of Interpretability Methods and Perturbation Artifacts in Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2203.02928">arxiv:2203.02928</a>
&#x1F4C8; 1 <br>
<p>Lennart Brocki, Neo Christopher Chung</p></summary>
<p>

**Abstract:** The challenge of interpreting predictions from deep neural networks has prompted the development of numerous interpretability methods. Many of interpretability methods attempt to quantify the importance of input features with respect to the class probabilities, and are called importance estimators or saliency maps. A popular approach to evaluate such interpretability methods is to perturb input features deemed important for predictions and observe the decrease in accuracy. However, perturbation-based evaluation methods may confound the sources of accuracy degradation. We conduct computational experiments that allow to empirically estimate the $\textit{fidelity}$ of interpretability methods and the contribution of perturbation artifacts. All considered importance estimators clearly outperform a random baseline, which contradicts the findings of ROAR [arXiv:1806.10758]. We further compare our results to the crop-and-resize evaluation framework [arXiv:1705.07857], which are largely in agreement. Our study suggests that we can estimate the impact of artifacts and thus empirically evaluate interpretability methods without retraining.

</p>
</details>

<details><summary><b>Enabling Automated Machine Learning for Model-Driven AI Engineering</b>
<a href="https://arxiv.org/abs/2203.02927">arxiv:2203.02927</a>
&#x1F4C8; 1 <br>
<p>Armin Moin, Ukrit Wattanavaekin, Alexandra Lungu, Moharram Challenger, Atta Badii, Stephan Günnemann</p></summary>
<p>

**Abstract:** Developing smart software services requires both Software Engineering and Artificial Intelligence (AI) skills. AI practitioners, such as data scientists often focus on the AI side, for example, creating and training Machine Learning (ML) models given a specific use case and data. They are typically not concerned with the entire software development life-cycle, architectural decisions for the system and performance issues beyond the predictive ML models (e.g., regarding the security, privacy, throughput, scalability, availability, as well as ethical, legal and regulatory compliance). In this manuscript, we propose a novel approach to enable Model-Driven Software Engineering and Model-Driven AI Engineering. In particular, we support Automated ML, thus assisting software engineers without deep AI knowledge in developing AI-intensive systems by choosing the most appropriate ML model, algorithm and techniques with suitable hyper-parameters for the task at hand. To validate our work, we carry out a case study in the smart energy domain.

</p>
</details>

<details><summary><b>Depthwise Convolution for Multi-Agent Communication with Enhanced Mean-Field Approximation</b>
<a href="https://arxiv.org/abs/2203.02896">arxiv:2203.02896</a>
&#x1F4C8; 1 <br>
<p>Donghan Xie, Zhi Wang, Chunlin Chen, Daoyi Dong</p></summary>
<p>

**Abstract:** Multi-agent settings remain a fundamental challenge in the reinforcement learning (RL) domain due to the partial observability and the lack of accurate real-time interactions across agents. In this paper, we propose a new method based on local communication learning to tackle the multi-agent RL (MARL) challenge within a large number of agents coexisting. First, we design a new communication protocol that exploits the ability of depthwise convolution to efficiently extract local relations and learn local communication between neighboring agents. To facilitate multi-agent coordination, we explicitly learn the effect of joint actions by taking the policies of neighboring agents as inputs. Second, we introduce the mean-field approximation into our method to reduce the scale of agent interactions. To more effectively coordinate behaviors of neighboring agents, we enhance the mean-field approximation by a supervised policy rectification network (PRN) for rectifying real-time agent interactions and by a learnable compensation term for correcting the approximation bias. The proposed method enables efficient coordination as well as outperforms several baseline approaches on the adaptive traffic signal control (ATSC) task and the StarCraft II multi-agent challenge (SMAC).

</p>
</details>

<details><summary><b>Watch from sky: machine-learning-based multi-UAV network for predictive police surveillance</b>
<a href="https://arxiv.org/abs/2203.02892">arxiv:2203.02892</a>
&#x1F4C8; 1 <br>
<p>Ryusei Sugano, Ryoichi Shinkuma, Takayuki Nishio, Sohei Itahara, Narayan B. Mandayam</p></summary>
<p>

**Abstract:** This paper presents the watch-from-sky framework, where multiple unmanned aerial vehicles (UAVs) play four roles, i.e., sensing, data forwarding, computing, and patrolling, for predictive police surveillance. Our framework is promising for crime deterrence because UAVs are useful for collecting and distributing data and have high mobility. Our framework relies on machine learning (ML) technology for controlling and dispatching UAVs and predicting crimes. This paper compares the conceptual model of our framework against the literature. It also reports a simulation of UAV dispatching using reinforcement learning and distributed ML inference over a lossy UAV network.

</p>
</details>

<details><summary><b>MIRROR: Differentiable Deep Social Projection for Assistive Human-Robot Communication</b>
<a href="https://arxiv.org/abs/2203.02877">arxiv:2203.02877</a>
&#x1F4C8; 1 <br>
<p>Kaiqi Chen, Jeffrey Fong, Harold Soh</p></summary>
<p>

**Abstract:** Communication is a hallmark of intelligence. In this work, we present MIRROR, an approach to (i) quickly learn human models from human demonstrations, and (ii) use the models for subsequent communication planning in assistive shared-control settings. MIRROR is inspired by social projection theory, which hypothesizes that humans use self-models to understand others. Likewise, MIRROR leverages self-models learned using reinforcement learning to bootstrap human modeling. Experiments with simulated humans show that this approach leads to rapid learning and more robust models compared to existing behavioral cloning and state-of-the-art imitation learning methods. We also present a human-subject study using the CARLA simulator which shows that (i) MIRROR is able to scale to complex domains with high-dimensional observations and complicated world physics and (ii) provides effective assistive communication that enabled participants to drive more safely in adverse weather conditions.

</p>
</details>

<details><summary><b>Kernel Packet: An Exact and Scalable Algorithm for Gaussian Process Regression with Matérn Correlations</b>
<a href="https://arxiv.org/abs/2203.03116">arxiv:2203.03116</a>
&#x1F4C8; 0 <br>
<p>Haoyuan Chen, Liang Ding, Rui Tuo</p></summary>
<p>

**Abstract:** We develop an exact and scalable algorithm for one-dimensional Gaussian process regression with Matérn correlations whose smoothness parameter $ν$ is a half-integer. The proposed algorithm only requires $\mathcal{O}(ν^3 n)$ operations and $\mathcal{O}(νn)$ storage. This leads to a linear-cost solver since $ν$ is chosen to be fixed and usually very small in most applications. The proposed method can be applied to multi-dimensional problems if a full grid or a sparse grid design is used. The proposed method is based on a novel theory for Matérn correlation functions. We find that a suitable rearrangement of these correlation functions can produce a compactly supported function, called a "kernel packet". Using a set of kernel packets as basis functions leads to a sparse representation of the covariance matrix that results in the proposed algorithm. Simulation studies show that the proposed algorithm, when applicable, is significantly superior to the existing alternatives in both the computational time and predictive accuracy.

</p>
</details>

<details><summary><b>Matrix Decomposition Perspective for Accuracy Assessment of Item Response Theory</b>
<a href="https://arxiv.org/abs/2203.03112">arxiv:2203.03112</a>
&#x1F4C8; 0 <br>
<p>Hideo Hirose</p></summary>
<p>

**Abstract:** The item response theory obtains the estimates and their confidence intervals for parameters of abilities of examinees and difficulties of problems by using the observed item response matrix consisting of 0/1 value elements. Many papers discuss the performance of the estimates. However, this paper does not. Using the maximum likelihood estimates, we can reconstruct the estimated item response matrix. Then we can assess the accuracy of this reconstructed matrix to the observed response matrix from the matrix decomposition perspective. That is, this paper focuses on the performance of the reconstructed response matrix. To compare the performance of the item response theory with others, we provided the two kinds of low rank response matrix by approximating the observed response matrix; one is the matrix via the singular value decomposition method when the response matrix is a complete matrix, and the other is the matrix via the matrix decomposition method when the response matrix is an incomplete matrix. We have, firstly, found that the performance of the singular value decomposition method and the matrix decomposition method is almost the same when the response matrix is a complete matrix. Here, the performance is measured by the closeness between the two matrices using the root mean squared errors and the accuracy. Secondary, we have seen that the closeness of the reconstructed matrix obtained from the item response theory to the observed matrix is located between the two approximated low rank response matrices obtained from the matrix decomposition method of k= and k=2 to the observed matrix, where k indicates the first k columns use in the decomposed matrices.

</p>
</details>

<details><summary><b>Cascaded Gaps: Towards Gap-Dependent Regret for Risk-Sensitive Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2203.03110">arxiv:2203.03110</a>
&#x1F4C8; 0 <br>
<p>Yingjie Fei, Ruitu Xu</p></summary>
<p>

**Abstract:** In this paper, we study gap-dependent regret guarantees for risk-sensitive reinforcement learning based on the entropic risk measure. We propose a novel definition of sub-optimality gaps, which we call cascaded gaps, and we discuss their key components that adapt to the underlying structures of the problem. Based on the cascaded gaps, we derive non-asymptotic and logarithmic regret bounds for two model-free algorithms under episodic Markov decision processes. We show that, in appropriate settings, these bounds feature exponential improvement over existing ones that are independent of gaps. We also prove gap-dependent lower bounds, which certify the near optimality of the upper bounds.

</p>
</details>

<details><summary><b>SurvSet: An open-source time-to-event dataset repository</b>
<a href="https://arxiv.org/abs/2203.03094">arxiv:2203.03094</a>
&#x1F4C8; 0 <br>
<p>Erik Drysdale</p></summary>
<p>

**Abstract:** Time-to-event (T2E) analysis is a branch of statistics that models the duration of time it takes for an event to occur. Such events can include outcomes like death, unemployment, or product failure. Most modern machine learning (ML) algorithms, like decision trees and kernel methods, are supported for T2E modelling with data science software (python and R). To complement these developments, SurvSet is the first open-source T2E dataset repository designed for a rapid benchmarking of ML algorithms and statistical methods. The data in SurvSet have been consistently formatted so that a single preprocessing method will work for all datasets. SurvSet currently has 76 datasets which vary in dimensionality, time dependency, and background (the majority of which come from biomedicine). SurvSet is available on PyPI and can be installed with pip install SurvSet. R users can download the data directly from the corresponding git repository.

</p>
</details>

<details><summary><b>Scalable Uncertainty Quantification for Deep Operator Networks using Randomized Priors</b>
<a href="https://arxiv.org/abs/2203.03048">arxiv:2203.03048</a>
&#x1F4C8; 0 <br>
<p>Yibo Yang, Georgios Kissas, Paris Perdikaris</p></summary>
<p>

**Abstract:** We present a simple and effective approach for posterior uncertainty quantification in deep operator networks (DeepONets); an emerging paradigm for supervised learning in function spaces. We adopt a frequentist approach based on randomized prior ensembles, and put forth an efficient vectorized implementation for fast parallel inference on accelerated hardware. Through a collection of representative examples in computational mechanics and climate modeling, we show that the merits of the proposed approach are fourfold. (1) It can provide more robust and accurate predictions when compared against deterministic DeepONets. (2) It shows great capability in providing reliable uncertainty estimates on scarce data-sets with multi-scale function pairs. (3) It can effectively detect out-of-distribution and adversarial examples. (4) It can seamlessly quantify uncertainty due to model bias, as well as noise corruption in the data. Finally, we provide an optimized JAX library called {\em UQDeepONet} that can accommodate large model architectures, large ensemble sizes, as well as large data-sets with excellent parallel performance on accelerated hardware, thereby enabling uncertainty quantification for DeepONets in realistic large-scale applications.

</p>
</details>

<details><summary><b>Frames for Graph Signals on the Symmetric Group: A Representation Theoretic Approach</b>
<a href="https://arxiv.org/abs/2203.03036">arxiv:2203.03036</a>
&#x1F4C8; 0 <br>
<p>Kathryn Beck, Mahya Ghandehari</p></summary>
<p>

**Abstract:** An important problem in the field of graph signal processing is developing appropriate overcomplete dictionaries for signals defined on different families of graphs. The Cayley graph of the symmetric group has natural applications in ranked data analysis, as its vertices represent permutations, while the generating set formalizes a notion of distance between rankings. Taking advantage of the rich theory of representations of the symmetric group, we study a particular class of frames, called Frobenius-Schur frames, where every atom belongs to the coefficient space of only one irreducible representation of the symmetric group. We provide a characterization for all Frobenius-Schur frames on the group algebra of the symmetric group which are "compatible" with respect to the generating set. Such frames have been previously studied for the permutahedron, the Cayley graph of the symmetric group with the generating set of adjacent transpositions, and have proved to be capable of producing meaningful interpretation of the ranked data set via the analysis coefficients. Our results generalize frame constructions for the permutahedron to any inverse-closed generating set.

</p>
</details>

<details><summary><b>Hierarchically Structured Scheduling and Execution of Tasks in a Multi-Agent Environment</b>
<a href="https://arxiv.org/abs/2203.03021">arxiv:2203.03021</a>
&#x1F4C8; 0 <br>
<p>Diogo S. Carvalho, Biswa Sengupta</p></summary>
<p>

**Abstract:** In a warehouse environment, tasks appear dynamically. Consequently, a task management system that matches them with the workforce too early (e.g., weeks in advance) is necessarily sub-optimal. Also, the rapidly increasing size of the action space of such a system consists of a significant problem for traditional schedulers. Reinforcement learning, however, is suited to deal with issues requiring making sequential decisions towards a long-term, often remote, goal. In this work, we set ourselves on a problem that presents itself with a hierarchical structure: the task-scheduling, by a centralised agent, in a dynamic warehouse multi-agent environment and the execution of one such schedule, by decentralised agents with only partial observability thereof. We propose to use deep reinforcement learning to solve both the high-level scheduling problem and the low-level multi-agent problem of schedule execution. Finally, we also conceive the case where centralisation is impossible at test time and workers must learn how to cooperate in executing the tasks in an environment with no schedule and only partial observability.

</p>
</details>

<details><summary><b>Smoothing with the Best Rectangle Window is Optimal for All Tapered Rectangle Windows</b>
<a href="https://arxiv.org/abs/2203.02997">arxiv:2203.02997</a>
&#x1F4C8; 0 <br>
<p>Kaan Gokcesu, Hakan Gokcesu</p></summary>
<p>

**Abstract:** We investigate the optimal selection of weight windows for the problem of weighted least squares. We show that weight windows should be symmetric around its center, which is also its peak. We consider the class of tapered rectangle window weights, which are nonincreasing away from the center. We show that the best rectangle window is optimal for such window definitions. We also extend our results to the least absolutes and more general case of arbitrary loss functions to find similar results.

</p>
</details>

<details><summary><b>Towards a Responsible AI Development Lifecycle: Lessons From Information Security</b>
<a href="https://arxiv.org/abs/2203.02958">arxiv:2203.02958</a>
&#x1F4C8; 0 <br>
<p>Erick Galinkin</p></summary>
<p>

**Abstract:** Legislation and public sentiment throughout the world have promoted fairness metrics, explainability, and interpretability as prescriptions for the responsible development of ethical artificial intelligence systems. Despite the importance of these three pillars in the foundation of the field, they can be challenging to operationalize and attempts to solve the problems in production environments often feel Sisyphean. This difficulty stems from a number of factors: fairness metrics are computationally difficult to incorporate into training and rarely alleviate all of the harms perpetrated by these systems. Interpretability and explainability can be gamed to appear fair, may inadvertently reduce the privacy of personal information contained in training data, and increase user confidence in predictions -- even when the explanations are wrong. In this work, we propose a framework for responsibly developing artificial intelligence systems by incorporating lessons from the field of information security and the secure development lifecycle to overcome challenges associated with protecting users in adversarial settings. In particular, we propose leveraging the concepts of threat modeling, design review, penetration testing, and incident response in the context of developing AI systems as ways to resolve shortcomings in the aforementioned methods.

</p>
</details>


{% endraw %}
Prev: [2022.03.05]({{ '/2022/03/05/2022.03.05.html' | relative_url }})  Next: [2022.03.07]({{ '/2022/03/07/2022.03.07.html' | relative_url }})