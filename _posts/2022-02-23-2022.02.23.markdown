Prev: [2022.02.22]({{ '/2022/02/22/2022.02.22.html' | relative_url }})  Next: [2022.02.24]({{ '/2022/02/24/2022.02.24.html' | relative_url }})
{% raw %}
## Summary for 2022-02-23, created on 2022-03-05


<details><summary><b>Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut</b>
<a href="https://arxiv.org/abs/2202.11539">arxiv:2202.11539</a>
&#x1F4C8; 13000 <br>
<p>Yangtao Wang, Xi Shen, Shell Hu, Yuan Yuan, James Crowley, Dominique Vaufreydaz</p></summary>
<p>

**Abstract:** Transformers trained with self-supervised learning using self-distillation loss (DINO) have been shown to produce attention maps that highlight salient foreground objects. In this paper, we demonstrate a graph-based approach that uses the self-supervised transformer features to discover an object from an image. Visual tokens are viewed as nodes in a weighted graph with edges representing a connectivity score based on the similarity of tokens. Foreground objects can then be segmented using a normalized graph-cut to group self-similar regions. We solve the graph-cut problem using spectral clustering with generalized eigen-decomposition and show that the second smallest eigenvector provides a cutting solution since its absolute value indicates the likelihood that a token belongs to a foreground object. Despite its simplicity, this approach significantly boosts the performance of unsupervised object discovery: we improve over the recent state of the art LOST by a margin of 6.9%, 8.1%, and 8.1% respectively on the VOC07, VOC12, and COCO20K. The performance can be further improved by adding a second stage class-agnostic detector (CAD). Our proposed method can be easily extended to unsupervised saliency detection and weakly supervised object detection. For unsupervised saliency detection, we improve IoU for 4.9%, 5.2%, 12.9% on ECSSD, DUTS, DUT-OMRON respectively compared to previous state of the art. For weakly supervised object detection, we achieve competitive performance on CUB and ImageNet.

</p>
</details>

<details><summary><b>Explanatory Paradigms in Neural Networks</b>
<a href="https://arxiv.org/abs/2202.11838">arxiv:2202.11838</a>
&#x1F4C8; 166 <br>
<p>Ghassan AlRegib, Mohit Prabhushankar</p></summary>
<p>

**Abstract:** In this article, we present a leap-forward expansion to the study of explainability in neural networks by considering explanations as answers to abstract reasoning-based questions. With $P$ as the prediction from a neural network, these questions are `Why P?', `What if not P?', and `Why P, rather than Q?' for a given contrast prediction $Q$. The answers to these questions are observed correlations, observed counterfactuals, and observed contrastive explanations respectively. Together, these explanations constitute the abductive reasoning scheme. We term the three explanatory schemes as observed explanatory paradigms. The term observed refers to the specific case of post-hoc explainability, when an explanatory technique explains the decision $P$ after a trained neural network has made the decision $P$. The primary advantage of viewing explanations through the lens of abductive reasoning-based questions is that explanations can be used as reasons while making decisions. The post-hoc field of explainability, that previously only justified decisions, becomes active by being involved in the decision making process and providing limited, but relevant and contextual interventions. The contributions of this article are: ($i$) realizing explanations as reasoning paradigms, ($ii$) providing a probabilistic definition of observed explanations and their completeness, ($iii$) creating a taxonomy for evaluation of explanations, and ($iv$) positioning gradient-based complete explanainability's replicability and reproducibility across multiple applications and data modalities, ($v$) code repositories, publicly available at https://github.com/olivesgatech/Explanatory-Paradigms.

</p>
</details>

<details><summary><b>Biometric security technology</b>
<a href="https://arxiv.org/abs/2202.11459">arxiv:2202.11459</a>
&#x1F4C8; 154 <br>
<p>Marcos Faundez-Zanuy</p></summary>
<p>

**Abstract:** This paper presents an overview of the main topics related to biometric security technology, with the main purpose to provide a primer on this subject. Biometrics can offer greater security and convenience than traditional methods for people recognition. Even if we do not want to replace a classic method (password or handheld token) by a biometric one, for sure, we are potential users of these systems, which will even be mandatory for new passport models. For this reason, to be familiarized with the possibilities of biometric security technology is useful.

</p>
</details>

<details><summary><b>On PAC-Bayesian reconstruction guarantees for VAEs</b>
<a href="https://arxiv.org/abs/2202.11455">arxiv:2202.11455</a>
&#x1F4C8; 152 <br>
<p>Badr-Eddine Chérief-Abdellatif, Yuyang Shi, Arnaud Doucet, Benjamin Guedj</p></summary>
<p>

**Abstract:** Despite its wide use and empirical successes, the theoretical understanding and study of the behaviour and performance of the variational autoencoder (VAE) have only emerged in the past few years. We contribute to this recent line of work by analysing the VAE's reconstruction ability for unseen test data, leveraging arguments from the PAC-Bayes theory. We provide generalisation bounds on the theoretical reconstruction error, and provide insights on the regularisation effect of VAE objectives. We illustrate our theoretical results with supporting experiments on classical benchmark datasets.

</p>
</details>

<details><summary><b>Deep Learning Reproducibility and Explainable AI (XAI)</b>
<a href="https://arxiv.org/abs/2202.11452">arxiv:2202.11452</a>
&#x1F4C8; 143 <br>
<p>A. -M. Leventi-Peetz, T. Östreich</p></summary>
<p>

**Abstract:** The nondeterminism of Deep Learning (DL) training algorithms and its influence on the explainability of neural network (NN) models are investigated in this work with the help of image classification examples. To discuss the issue, two convolutional neural networks (CNN) have been trained and their results compared. The comparison serves the exploration of the feasibility of creating deterministic, robust DL models and deterministic explainable artificial intelligence (XAI) in practice. Successes and limitation of all here carried out efforts are described in detail. The source code of the attained deterministic models has been listed in this work. Reproducibility is indexed as a development-phase-component of the Model Governance Framework, proposed by the EU within their excellence in AI approach. Furthermore, reproducibility is a requirement for establishing causality for the interpretation of model results and building of trust towards the overwhelming expansion of AI systems applications. Problems that have to be solved on the way to reproducibility and ways to deal with some of them, are examined in this work.

</p>
</details>

<details><summary><b>Flow-based sampling in the lattice Schwinger model at criticality</b>
<a href="https://arxiv.org/abs/2202.11712">arxiv:2202.11712</a>
&#x1F4C8; 45 <br>
<p>Michael S. Albergo, Denis Boyda, Kyle Cranmer, Daniel C. Hackett, Gurtej Kanwar, Sébastien Racanière, Danilo J. Rezende, Fernando Romero-López, Phiala E. Shanahan, Julian M. Urban</p></summary>
<p>

**Abstract:** Recent results suggest that flow-based algorithms may provide efficient sampling of field distributions for lattice field theory applications, such as studies of quantum chromodynamics and the Schwinger model. In this work, we provide a numerical demonstration of robust flow-based sampling in the Schwinger model at the critical value of the fermion mass. In contrast, at the same parameters, conventional methods fail to sample all parts of configuration space, leading to severely underestimated uncertainties.

</p>
</details>

<details><summary><b>Near Perfect GAN Inversion</b>
<a href="https://arxiv.org/abs/2202.11833">arxiv:2202.11833</a>
&#x1F4C8; 25 <br>
<p>Qianli Feng, Viraj Shah, Raghudeep Gadde, Pietro Perona, Aleix Martinez</p></summary>
<p>

**Abstract:** To edit a real photo using Generative Adversarial Networks (GANs), we need a GAN inversion algorithm to identify the latent vector that perfectly reproduces it. Unfortunately, whereas existing inversion algorithms can synthesize images similar to real photos, they cannot generate the identical clones needed in most applications. Here, we derive an algorithm that achieves near perfect reconstructions of photos. Rather than relying on encoder- or optimization-based methods to find an inverse mapping on a fixed generator $G(\cdot)$, we derive an approach to locally adjust $G(\cdot)$ to more optimally represent the photos we wish to synthesize. This is done by locally tweaking the learned mapping $G(\cdot)$ s.t. $\| {\bf x} - G({\bf z}) \|<ε$, with ${\bf x}$ the photo we wish to reproduce, ${\bf z}$ the latent vector, $\|\cdot\|$ an appropriate metric, and $ε> 0$ a small scalar. We show that this approach can not only produce synthetic images that are indistinguishable from the real photos we wish to replicate, but that these images are readily editable. We demonstrate the effectiveness of the derived algorithm on a variety of datasets including human faces, animals, and cars, and discuss its importance for diversity and inclusion.

</p>
</details>

<details><summary><b>How Many Data Are Needed for Robust Learning?</b>
<a href="https://arxiv.org/abs/2202.11592">arxiv:2202.11592</a>
&#x1F4C8; 21 <br>
<p>Hongyang Zhang, Yihan Wu, Heng Huang</p></summary>
<p>

**Abstract:** We show that the sample complexity of robust interpolation problem could be exponential in the input dimensionality and discover a phase transition phenomenon when the data are in a unit ball. Robust interpolation refers to the problem of interpolating $n$ noisy training data in $\R^d$ by a Lipschitz function. Although this problem has been well understood when the covariates are drawn from an isoperimetry distribution, much remains unknown concerning its performance under generic or even the worst-case distributions. Our results are two-fold: 1) too many data hurt robustness; we provide a tight and universal Lipschitzness lower bound $Ω(n^{1/d})$ of the interpolating function for arbitrary data distributions. Our result disproves potential existence of an $\mathcal{O}(1)$-Lipschitz function in the overparametrization scenario when $n=\exp(ω(d))$. 2) Small data hurt robustness: $n=\exp(Ω(d))$ is necessary for obtaining a good population error under certain distributions by any $\mathcal{O}(1)$-Lipschitz learning algorithm. Perhaps surprisingly, our results shed light on the curse of big data and the blessing of dimensionality for robustness, and discover an intriguing phenomenon of phase transition at $n=\exp(Θ(d))$.

</p>
</details>

<details><summary><b>Exploring Classic Quantitative Strategies</b>
<a href="https://arxiv.org/abs/2202.11309">arxiv:2202.11309</a>
&#x1F4C8; 21 <br>
<p>Jun Lu</p></summary>
<p>

**Abstract:** The goal of this paper is to debunk and dispel the magic behind the black-box quantitative strategies. It aims to build a solid foundation on how and why the techniques work. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind the strategies. This tutorial doesn't shy away from addressing both the formal and informal aspects of quantitative strategies. By doing so, it hopes to provide readers with a deeper understanding of these techniques as well as the when, the how and the why of applying these techniques. The strategies are presented in terms of both S\&P500 and SH510300 data sets. However, the results from the tests are just examples of how the methods work; no claim is made on the suggestion of real market positions.

</p>
</details>

<details><summary><b>Sky Computing: Accelerating Geo-distributed Computing in Federated Learning</b>
<a href="https://arxiv.org/abs/2202.11836">arxiv:2202.11836</a>
&#x1F4C8; 18 <br>
<p>Jie Zhu, Shenggui Li, Yang You</p></summary>
<p>

**Abstract:** Federated learning is proposed by Google to safeguard data privacy through training models locally on users' devices. However, with deep learning models growing in size to achieve better results, it becomes increasingly difficult to accommodate the whole model on one single device. Thus, model parallelism is then used to divide the model weights among several devices. With this logic, the approach currently used evenly allocates weights among devices. However, in reality, a computation bottleneck may occur resulting from variant computing power of different users' devices. To address this problem, load balancing is needed to allocate the model weights based on the computational capability of the device. In this paper, we proposed Sky Computing, a load-balanced model parallelism framework to adaptively allocate the weights to devices. Sky Computing outperforms the baseline method by 55% in training time when training 160-layer BERT with 64 nodes. The source code can be found at https://github.com/hpcaitech/SkyComputing.

</p>
</details>

<details><summary><b>CAISE: Conversational Agent for Image Search and Editing</b>
<a href="https://arxiv.org/abs/2202.11847">arxiv:2202.11847</a>
&#x1F4C8; 11 <br>
<p>Hyounghun Kim, Doo Soon Kim, Seunghyun Yoon, Franck Dernoncourt, Trung Bui, Mohit Bansal</p></summary>
<p>

**Abstract:** Demand for image editing has been increasing as users' desire for expression is also increasing. However, for most users, image editing tools are not easy to use since the tools require certain expertise in photo effects and have complex interfaces. Hence, users might need someone to help edit their images, but having a personal dedicated human assistant for every user is impossible to scale. For that reason, an automated assistant system for image editing is desirable. Additionally, users want more image sources for diverse image editing works, and integrating an image search functionality into the editing tool is a potential remedy for this demand. Thus, we propose a dataset of an automated Conversational Agent for Image Search and Editing (CAISE). To our knowledge, this is the first dataset that provides conversational image search and editing annotations, where the agent holds a grounded conversation with users and helps them to search and edit images according to their requests. To build such a system, we first collect image search and editing conversations between pairs of annotators. The assistant-annotators are equipped with a customized image search and editing tool to address the requests from the user-annotators. The functions that the assistant-annotators conduct with the tool are recorded as executable commands, allowing the trained system to be useful for real-world application execution. We also introduce a generator-extractor baseline model for this task, which can adaptively select the source of the next token (i.e., from the vocabulary or from textual/visual contexts) for the executable command. This serves as a strong starting point while still leaving a large human-machine performance gap for useful future work. Our code and dataset are publicly available at: https://github.com/hyounghk/CAISE

</p>
</details>

<details><summary><b>Fine-Grained Prediction of Political Leaning on Social Media with Unsupervised Deep Learning</b>
<a href="https://arxiv.org/abs/2202.12382">arxiv:2202.12382</a>
&#x1F4C8; 8 <br>
<p>Tiziano Fagni, Stefano Cresci</p></summary>
<p>

**Abstract:** Predicting the political leaning of social media users is an increasingly popular task, given its usefulness for electoral forecasts, opinion dynamics models and for studying the political dimension of polarization and disinformation. Here, we propose a novel unsupervised technique for learning fine-grained political leaning from the textual content of social media posts. Our technique leverages a deep neural network for learning latent political ideologies in a representation learning task. Then, users are projected in a low-dimensional ideology space where they are subsequently clustered. The political leaning of a user is automatically derived from the cluster to which the user is assigned. We evaluated our technique in two challenging classification tasks and we compared it to baselines and other state-of-the-art approaches. Our technique obtains the best results among all unsupervised techniques, with micro F1 = 0.426 in the 8-class task and micro F1 = 0.772 in the 3-class task. Other than being interesting on their own, our results also pave the way for the development of new and better unsupervised approaches for the detection of fine-grained political leaning.

</p>
</details>

<details><summary><b>Wide Mean-Field Bayesian Neural Networks Ignore the Data</b>
<a href="https://arxiv.org/abs/2202.11670">arxiv:2202.11670</a>
&#x1F4C8; 8 <br>
<p>Beau Coker, Wessel P. Bruinsma, David R. Burt, Weiwei Pan, Finale Doshi-Velez</p></summary>
<p>

**Abstract:** Bayesian neural networks (BNNs) combine the expressive power of deep learning with the advantages of Bayesian formalism. In recent years, the analysis of wide, deep BNNs has provided theoretical insight into their priors and posteriors. However, we have no analogous insight into their posteriors under approximate inference. In this work, we show that mean-field variational inference entirely fails to model the data when the network width is large and the activation function is odd. Specifically, for fully-connected BNNs with odd activation functions and a homoscedastic Gaussian likelihood, we show that the optimal mean-field variational posterior predictive (i.e., function space) distribution converges to the prior predictive distribution as the width tends to infinity. We generalize aspects of this result to other likelihoods. Our theoretical results are suggestive of underfitting behavior previously observered in BNNs. While our convergence bounds are non-asymptotic and constants in our analysis can be computed, they are currently too loose to be applicable in standard training regimes. Finally, we show that the optimal approximate posterior need not tend to the prior if the activation function is not odd, showing that our statements cannot be generalized arbitrarily.

</p>
</details>

<details><summary><b>State-of-the-art in speaker recognition</b>
<a href="https://arxiv.org/abs/2202.12705">arxiv:2202.12705</a>
&#x1F4C8; 7 <br>
<p>Marcos Faundez-Zanuy, Enric Monte-Moreno</p></summary>
<p>

**Abstract:** Recent advances in speech technologies have produced new tools that can be used to improve the performance and flexibility of speaker recognition While there are few degrees of freedom or alternative methods when using fingerprint or iris identification techniques, speech offers much more flexibility and different levels for performing recognition: the system can force the user to speak in a particular manner, different for each attempt to enter. Also with voice input the system has other degrees of freedom, such as the use of knowledge/codes that only the user knows, or dialectical/semantical traits that are difficult to forge. This paper offers and overview of the state of the art in speaker recognition, with special emphasis on the pros and contras, and the current research lines. The current research lines include improved classification systems, and the use of high level information by means of probabilistic grammars. In conclusion, speaker recognition is far away from being a technology where all the possibilities have already been explored.

</p>
</details>

<details><summary><b>Improving Robustness of Convolutional Neural Networks Using Element-Wise Activation Scaling</b>
<a href="https://arxiv.org/abs/2202.11898">arxiv:2202.11898</a>
&#x1F4C8; 7 <br>
<p>Zhi-Yuan Zhang, Di Liu</p></summary>
<p>

**Abstract:** Recent works reveal that re-calibrating the intermediate activation of adversarial examples can improve the adversarial robustness of a CNN model. The state of the arts [Baiet al., 2021] and [Yanet al., 2021] explores this feature at the channel level, i.e. the activation of a channel is uniformly scaled by a factor. In this paper, we investigate the intermediate activation manipulation at a more fine-grained level. Instead of uniformly scaling the activation, we individually adjust each element within an activation and thus propose Element-Wise Activation Scaling, dubbed EWAS, to improve CNNs' adversarial robustness. Experimental results on ResNet-18 and WideResNet with CIFAR10 and SVHN show that EWAS significantly improves the robustness accuracy. Especially for ResNet18 on CIFAR10, EWAS increases the adversarial accuracy by 37.65% to 82.35% against C&W attack. EWAS is simple yet very effective in terms of improving robustness. The codes are anonymously available at https://anonymous.4open.science/r/EWAS-DD64.

</p>
</details>

<details><summary><b>Differentially Private Speaker Anonymization</b>
<a href="https://arxiv.org/abs/2202.11823">arxiv:2202.11823</a>
&#x1F4C8; 7 <br>
<p>Ali Shahin Shamsabadi, Brij Mohan Lal Srivastava, Aurélien Bellet, Nathalie Vauquier, Emmanuel Vincent, Mohamed Maouche, Marc Tommasi, Nicolas Papernot</p></summary>
<p>

**Abstract:** Sharing real-world speech utterances is key to the training and deployment of voice-based services. However, it also raises privacy risks as speech contains a wealth of personal data. Speaker anonymization aims to remove speaker information from a speech utterance while leaving its linguistic and prosodic attributes intact. State-of-the-art techniques operate by disentangling the speaker information (represented via a speaker embedding) from these attributes and re-synthesizing speech based on the speaker embedding of another speaker. Prior research in the privacy community has shown that anonymization often provides brittle privacy protection, even less so any provable guarantee. In this work, we show that disentanglement is indeed not perfect: linguistic and prosodic attributes still contain speaker information. We remove speaker information from these attributes by introducing differentially private feature extractors based on an autoencoder and an automatic speech recognizer, respectively, trained using noise layers. We plug these extractors in the state-of-the-art anonymization pipeline and generate, for the first time, differentially private utterances with a provable upper bound on the speaker information they contain. We evaluate empirically the privacy and utility resulting from our differentially private speaker anonymization approach on the LibriSpeech data set. Experimental results show that the generated utterances retain very high utility for automatic speech recognition training and inference, while being much better protected against strong adversaries who leverage the full knowledge of the anonymization process to try to infer the speaker identity.

</p>
</details>

<details><summary><b>Benefit of Interpolation in Nearest Neighbor Algorithms</b>
<a href="https://arxiv.org/abs/2202.11817">arxiv:2202.11817</a>
&#x1F4C8; 7 <br>
<p>Yue Xing, Qifan Song, Guang Cheng</p></summary>
<p>

**Abstract:** In some studies \citep[e.g.,][]{zhang2016understanding} of deep learning, it is observed that over-parametrized deep neural networks achieve a small testing error even when the training error is almost zero. Despite numerous works towards understanding this so-called "double descent" phenomenon \citep[e.g.,][]{belkin2018reconciling,belkin2019two}, in this paper, we turn into another way to enforce zero training error (without over-parametrization) through a data interpolation mechanism. Specifically, we consider a class of interpolated weighting schemes in the nearest neighbors (NN) algorithms. By carefully characterizing the multiplicative constant in the statistical risk, we reveal a U-shaped performance curve for the level of data interpolation in both classification and regression setups. This sharpens the existing result \citep{belkin2018does} that zero training error does not necessarily jeopardize predictive performances and claims a counter-intuitive result that a mild degree of data interpolation actually {\em strictly} improve the prediction performance and statistical stability over those of the (un-interpolated) $k$-NN algorithm. In the end, the universality of our results, such as change of distance measure and corrupted testing data, will also be discussed.

</p>
</details>

<details><summary><b>Using Bayesian Deep Learning to infer Planet Mass from Gaps in Protoplanetary Disks</b>
<a href="https://arxiv.org/abs/2202.11730">arxiv:2202.11730</a>
&#x1F4C8; 7 <br>
<p>Sayantan Auddy, Ramit Dey, Min-Kai Lin, Daniel Carrera, Jacob B. Simon</p></summary>
<p>

**Abstract:** Planet induced sub-structures, like annular gaps, observed in dust emission from protoplanetary disks provide a unique probe to characterize unseen young planets. While deep learning based model has an edge in characterizing the planet's properties over traditional methods, like customized simulations and empirical relations, it lacks in its ability to quantify the uncertainty associated with its predictions. In this paper, we introduce a Bayesian deep learning network "DPNNet-Bayesian" that can predict planet mass from disk gaps and provides uncertainties associated with the prediction. A unique feature of our approach is that it can distinguish between the uncertainty associated with the deep learning architecture and uncertainty inherent in the input data due to measurement noise. The model is trained on a data set generated from disk-planet simulations using the \textsc{fargo3d} hydrodynamics code with a newly implemented fixed grain size module and improved initial conditions. The Bayesian framework enables estimating a gauge/confidence interval over the validity of the prediction when applied to unknown observations. As a proof-of-concept, we apply DPNNet-Bayesian to dust gaps observed in HL Tau. The network predicts masses of $ 86.0 \pm 5.5 M_{\Earth} $, $ 43.8 \pm 3.3 M_{\Earth} $, and $ 92.2 \pm 5.1 M_{\Earth} $ respectively, which are comparable to other studies based on specialized simulations.

</p>
</details>

<details><summary><b>COLD Decoding: Energy-based Constrained Text Generation with Langevin Dynamics</b>
<a href="https://arxiv.org/abs/2202.11705">arxiv:2202.11705</a>
&#x1F4C8; 7 <br>
<p>Lianhui Qin, Sean Welleck, Daniel Khashabi, Yejin Choi</p></summary>
<p>

**Abstract:** Many applications of text generation require incorporating different constraints to control the semantics or style of generated text. These constraints can be hard (e.g., ensuring certain keywords are included in the output) and soft (e.g., contextualizing the output with the left- or right-hand context). In this paper, we present Energy-based Constrained Decoding with Langevin Dynamics (COLD), a decoding framework which unifies constrained generation as specifying constraints through an energy function, then performing efficient differentiable reasoning over the constraints through gradient-based sampling. COLD decoding is a flexible framework that can be applied directly to off-the-shelf left-to-right language models without the need for any task-specific fine-tuning, as demonstrated through three challenging text generation applications: lexically-constrained generation, abductive reasoning, and counterfactual reasoning. Our experiments on these constrained generation tasks point to the effectiveness of our approach, both in terms of automatic and human evaluation.

</p>
</details>

<details><summary><b>ReverseORC: Reverse Engineering of Resizable User Interface Layouts with OR-Constraints</b>
<a href="https://arxiv.org/abs/2202.11523">arxiv:2202.11523</a>
&#x1F4C8; 7 <br>
<p>Yue Jiang, Wolfgang Stuerzlinger, Christof Lutteroth</p></summary>
<p>

**Abstract:** Reverse engineering (RE) of user interfaces (UIs) plays an important role in software evolution. However, the large diversity of UI technologies and the need for UIs to be resizable make this challenging. We propose ReverseORC, a novel RE approach able to discover diverse layout types and their dynamic resizing behaviours independently of their implementation, and to specify them by using OR constraints. Unlike previous RE approaches, ReverseORC infers flexible layout constraint specifications by sampling UIs at different sizes and analyzing the differences between them. It can create specifications that replicate even some non-standard layout managers with complex dynamic layout behaviours. We demonstrate that ReverseORC works across different platforms with very different layout approaches, e.g., for GUIs as well as for the Web. Furthermore, it can be used to detect and fix problems in legacy UIs, extend UIs with enhanced layout behaviours, and support the creation of flexible UI layouts.

</p>
</details>

<details><summary><b>Multi-view Intent Disentangle Graph Networks for Bundle Recommendation</b>
<a href="https://arxiv.org/abs/2202.11425">arxiv:2202.11425</a>
&#x1F4C8; 7 <br>
<p>Sen Zhao, Wei Wei, Ding Zou, Xianling Mao</p></summary>
<p>

**Abstract:** Bundle recommendation aims to recommend the user a bundle of items as a whole. Nevertheless, they usually neglect the diversity of the user's intents on adopting items and fail to disentangle the user's intents in representations. In the real scenario of bundle recommendation, a user's intent may be naturally distributed in the different bundles of that user (Global view), while a bundle may contain multiple intents of a user (Local view). Each view has its advantages for intent disentangling: 1) From the global view, more items are involved to present each intent, which can demonstrate the user's preference under each intent more clearly. 2) From the local view, it can reveal the association among items under each intent since items within the same bundle are highly correlated to each other. To this end, we propose a novel model named Multi-view Intent Disentangle Graph Networks (MIDGN), which is capable of precisely and comprehensively capturing the diversity of the user's intent and items' associations at the finer granularity. Specifically, MIDGN disentangles the user's intents from two different perspectives, respectively: 1) In the global level, MIDGN disentangles the user's intent coupled with inter-bundle items; 2) In the Local level, MIDGN disentangles the user's intent coupled with items within each bundle.
  Meanwhile, we compare the user's intents disentangled from different views under the contrast learning framework to improve the learned intents. Extensive experiments conducted on two benchmark datasets demonstrate that MIDGN outperforms the state-of-the-art methods by over 10.7% and 26.8%, respectively.

</p>
</details>

<details><summary><b>M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction</b>
<a href="https://arxiv.org/abs/2202.11884">arxiv:2202.11884</a>
&#x1F4C8; 6 <br>
<p>Qiao Sun, Xin Huang, Junru Gu, Brian C. Williams, Hang Zhao</p></summary>
<p>

**Abstract:** Predicting future motions of road participants is an important task for driving autonomously in urban scenes. Existing models excel at predicting marginal trajectories for single agents, yet it remains an open question to jointly predict scene compliant trajectories over multiple agents. The challenge is due to exponentially increasing prediction space as a function of the number of agents. In this work, we exploit the underlying relations between interacting agents and decouple the joint prediction problem into marginal prediction problems. Our proposed approach M2I first classifies interacting agents as pairs of influencers and reactors, and then leverages a marginal prediction model and a conditional prediction model to predict trajectories for the influencers and reactors, respectively. The predictions from interacting agents are combined and selected according to their joint likelihoods. Experiments show that our simple but effective approach achieves state-of-the-art performance on the Waymo Open Motion Dataset interactive prediction benchmark.

</p>
</details>

<details><summary><b>Completely Quantum Neural Networks</b>
<a href="https://arxiv.org/abs/2202.11727">arxiv:2202.11727</a>
&#x1F4C8; 6 <br>
<p>Steve Abel, Juan C. Criado, Michael Spannowsky</p></summary>
<p>

**Abstract:** Artificial neural networks are at the heart of modern deep learning algorithms. We describe how to embed and train a general neural network in a quantum annealer without introducing any classical element in training. To implement the network on a state-of-the-art quantum annealer, we develop three crucial ingredients: binary encoding the free parameters of the network, polynomial approximation of the activation function, and reduction of binary higher-order polynomials into quadratic ones. Together, these ideas allow encoding the loss function as an Ising model Hamiltonian. The quantum annealer then trains the network by finding the ground state. We implement this for an elementary network and illustrate the advantages of quantum training: its consistency in finding the global minimum of the loss function and the fact that the network training converges in a single annealing step, which leads to short training times while maintaining a high classification performance. Our approach opens a novel avenue for the quantum training of general machine learning models.

</p>
</details>

<details><summary><b>Bayesian Model Selection, the Marginal Likelihood, and Generalization</b>
<a href="https://arxiv.org/abs/2202.11678">arxiv:2202.11678</a>
&#x1F4C8; 6 <br>
<p>Sanae Lotfi, Pavel Izmailov, Gregory Benton, Micah Goldblum, Andrew Gordon Wilson</p></summary>
<p>

**Abstract:** How do we compare between hypotheses that are entirely consistent with observations? The marginal likelihood (aka Bayesian evidence), which represents the probability of generating our observations from a prior, provides a distinctive approach to this foundational question, automatically encoding Occam's razor. Although it has been observed that the marginal likelihood can overfit and is sensitive to prior assumptions, its limitations for hyperparameter learning and discrete model comparison have not been thoroughly investigated. We first revisit the appealing properties of the marginal likelihood for learning constraints and hypothesis testing. We then highlight the conceptual and practical issues in using the marginal likelihood as a proxy for generalization. Namely, we show how marginal likelihood can be negatively correlated with generalization, with implications for neural architecture search, and can lead to both underfitting and overfitting in hyperparameter learning. We provide a partial remedy through a conditional marginal likelihood, which we show is more aligned with generalization, and practically valuable for large-scale hyperparameter learning, such as in deep kernel learning.

</p>
</details>

<details><summary><b>Enabling arbitrary translation objectives with Adaptive Tree Search</b>
<a href="https://arxiv.org/abs/2202.11444">arxiv:2202.11444</a>
&#x1F4C8; 6 <br>
<p>Wang Ling, Wojciech Stokowiec, Domenic Donato, Laurent Sartran, Lei Yu, Austin Matthews, Chris Dyer</p></summary>
<p>

**Abstract:** We introduce an adaptive tree search algorithm, that can find high-scoring outputs under translation models that make no assumptions about the form or structure of the search objective. This algorithm -- a deterministic variant of Monte Carlo tree search -- enables the exploration of new kinds of models that are unencumbered by constraints imposed to make decoding tractable, such as autoregressivity or conditional independence assumptions. When applied to autoregressive models, our algorithm has different biases than beam search has, which enables a new analysis of the role of decoding bias in autoregressive models. Empirically, we show that our adaptive tree search algorithm finds outputs with substantially better model scores compared to beam search in autoregressive models, and compared to reranking techniques in models whose scores do not decompose additively with respect to the words in the output. We also characterise the correlation of several translation model objectives with respect to BLEU. We find that while some standard models are poorly calibrated and benefit from the beam search bias, other often more robust models (autoregressive models tuned to maximize expected automatic metric scores, the noisy channel model and a newly proposed objective) benefit from increasing amounts of search using our proposed decoder, whereas the beam search bias limits the improvements obtained from such objectives. Thus, we argue that as models improve, the improvements may be masked by over-reliance on beam search or reranking based methods.

</p>
</details>

<details><summary><b>Absolute Zero-Shot Learning</b>
<a href="https://arxiv.org/abs/2202.11319">arxiv:2202.11319</a>
&#x1F4C8; 6 <br>
<p>Rui Gao, Fan Wan, Daniel Organisciak, Jiyao Pu, Junyan Wang, Haoran Duan, Peng Zhang, Xingsong Hou, Yang Long</p></summary>
<p>

**Abstract:** Considering the increasing concerns about data copyright and privacy issues, we present a novel Absolute Zero-Shot Learning (AZSL) paradigm, i.e., training a classifier with zero real data. The key innovation is to involve a teacher model as the data safeguard to guide the AZSL model training without data leaking. The AZSL model consists of a generator and student network, which can achieve date-free knowledge transfer while maintaining the performance of the teacher network. We investigate `black-box' and `white-box' scenarios in AZSL task as different levels of model security. Besides, we also provide discussion of teacher model in both inductive and transductive settings. Despite embarrassingly simple implementations and data-missing disadvantages, our AZSL framework can retain state-of-the-art ZSL and GZSL performance under the `white-box' scenario. Extensive qualitative and quantitative analysis also demonstrates promising results when deploying the model under `black-box' scenario.

</p>
</details>

<details><summary><b>Are We Ready for Robust and Resilient SLAM? A Framework For Quantitative Characterization of SLAM Datasets</b>
<a href="https://arxiv.org/abs/2202.11312">arxiv:2202.11312</a>
&#x1F4C8; 6 <br>
<p>Islam Ali, Hong Zhang</p></summary>
<p>

**Abstract:** Reliability of SLAM systems is considered one of the critical requirements in many modern autonomous systems. This directed the efforts to developing many state-of-the-art systems, creating challenging datasets, and introducing rigorous metrics to measure SLAM system performance. However, the link between datasets and performance in the robustness/resilience context has rarely been explored. In order to fill this void, characterization the operating conditions of SLAM systems is essential in order to provide an environment for quantitative measurement of robustness and resilience. In this paper, we argue that for proper evaluation of SLAM performance, the characterization of SLAM datasets serves as a critical first step. The study starts by reviewing previous efforts for quantitative characterization of SLAM datasets. Then, the problem of perturbations characterization is discussed and the linkage to SLAM robustness/resilience is established. After that, we propose a novel, generic and extendable framework for quantitative analysis and comparison of SLAM datasets. Additionally, a description of different characterization parameters is provided. Finally, we demonstrate the application of our framework by presenting the characterization results of three SLAM datasets: KITTI, EuroC-MAV, and TUM-VI highlighting the level of insights achieved by the proposed framework.

</p>
</details>

<details><summary><b>EMOTHAW: A novel database for emotional state recognition from handwriting</b>
<a href="https://arxiv.org/abs/2202.12245">arxiv:2202.12245</a>
&#x1F4C8; 5 <br>
<p>Laurence Likforman-Sulem, Anna Esposito, Marcos Faundez-Zanuy, Stephan Clemençon, Gennaro Cordasco</p></summary>
<p>

**Abstract:** The detection of negative emotions through daily activities such as handwriting is useful for promoting well-being. The spread of human-machine interfaces such as tablets makes the collection of handwriting samples easier. In this context, we present a first publicly available handwriting database which relates emotional states to handwriting, that we call EMOTHAW. This database includes samples of 129 participants whose emotional states, namely anxiety, depression and stress, are assessed by the Depression Anxiety Stress Scales (DASS) questionnaire. Seven tasks are recorded through a digitizing tablet: pentagons and house drawing, words copied in handprint, circles and clock drawing, and one sentence copied in cursive writing. Records consist in pen positions, on-paper and in-air, time stamp, pressure, pen azimuth and altitude. We report our analysis on this database. From collected data, we first compute measurements related to timing and ductus. We compute separate measurements according to the position of the writing device: on paper or in-air. We analyse and classify this set of measurements (referred to as features) using a random forest approach. This latter is a machine learning method [2], based on an ensemble of decision trees, which includes a feature ranking process. We use this ranking process to identify the features which best reveal a targeted emotional state.
  We then build random forest classifiers associated to each emotional state. Our results, obtained from cross-validation experiments, show that the targeted emotional states can be identified with accuracies ranging from 60% to 71%.

</p>
</details>

<details><summary><b>A Note on Machine Learning Approach for Computational Imaging</b>
<a href="https://arxiv.org/abs/2202.11883">arxiv:2202.11883</a>
&#x1F4C8; 5 <br>
<p>Bin Dong</p></summary>
<p>

**Abstract:** Computational imaging has been playing a vital role in the development of natural sciences. Advances in sensory, information, and computer technologies have further extended the scope of influence of imaging, making digital images an essential component of our daily lives. For the past three decades, we have witnessed phenomenal developments of mathematical and machine learning methods in computational imaging. In this note, we will review some of the recent developments of the machine learning approach for computational imaging and discuss its differences and relations to the mathematical approach. We will demonstrate how we may combine the wisdom from both approaches, discuss the merits and potentials of such a combination and present some of the new computational and theoretical challenges it brings about.

</p>
</details>

<details><summary><b>Adversarially-regularized mixed effects deep learning (ARMED) models for improved interpretability, performance, and generalization on clustered data</b>
<a href="https://arxiv.org/abs/2202.11783">arxiv:2202.11783</a>
&#x1F4C8; 5 <br>
<p>Kevin P. Nguyen, Albert Montillo</p></summary>
<p>

**Abstract:** Data in the natural sciences frequently violate assumptions of independence. Such datasets have samples with inherent clustering (e.g. by study site, subject, experimental batch), which may lead to spurious associations, poor model fitting, and confounded analyses. While largely unaddressed in deep learning, mixed effects models have been used in traditional statistics for clustered data. Mixed effects models separate cluster-invariant, population-level fixed effects from cluster-specific random effects. We propose a general-purpose framework for building Adversarially-Regularized Mixed Effects Deep learning (ARMED) models through 3 non-intrusive additions to existing networks: 1) a domain adversarial classifier constraining the original model to learn only cluster-invariant features, 2) a random effects subnetwork capturing cluster-specific features, and 3) a cluster-inferencing approach to predict on clusters unseen during training. We apply this framework to dense feedforward neural networks (DFNNs), convolutional neural networks, and autoencoders on 4 applications including simulations, dementia prognosis and diagnosis, and cell microscopy. We compare to conventional models, domain adversarial-only models, and the naive inclusion of cluster membership as a covariate. Our models better distinguish confounded from true associations in simulations and emphasize more biologically plausible features in clinical applications. ARMED DFNNs quantify inter-cluster variance in clinical data while ARMED autoencoders visualize batch effects in cell images. Finally, ARMED improves accuracy on data from clusters seen during training (up to 28% vs. conventional models) and generalizes better to unseen clusters (up to 9% vs. conventional models). By incorporating powerful mixed effects modeling into deep learning, ARMED increases performance, interpretability, and generalization on clustered data.

</p>
</details>

<details><summary><b>Art Creation with Multi-Conditional StyleGANs</b>
<a href="https://arxiv.org/abs/2202.11777">arxiv:2202.11777</a>
&#x1F4C8; 5 <br>
<p>Konstantin Dobler, Florian Hübscher, Jan Westphal, Alejandro Sierra-Múnera, Gerard de Melo, Ralf Krestel</p></summary>
<p>

**Abstract:** Creating meaningful art is often viewed as a uniquely human endeavor. A human artist needs a combination of unique skills, understanding, and genuine intention to create artworks that evoke deep feelings and emotions. In this paper, we introduce a multi-conditional Generative Adversarial Network (GAN) approach trained on large amounts of human paintings to synthesize realistic-looking paintings that emulate human art. Our approach is based on the StyleGAN neural network architecture, but incorporates a custom multi-conditional control mechanism that provides fine-granular control over characteristics of the generated paintings, e.g., with regard to the perceived emotion evoked in a spectator. For better control, we introduce the conditional truncation trick, which adapts the standard truncation trick for the conditional setting and diverse datasets. Finally, we develop a diverse set of evaluation techniques tailored to multi-conditional generation.

</p>
</details>

<details><summary><b>Discovering Multiple and Diverse Directions for Cognitive Image Properties</b>
<a href="https://arxiv.org/abs/2202.11772">arxiv:2202.11772</a>
&#x1F4C8; 5 <br>
<p>Umut Kocasari, Alperen Bag, Oguz Kaan Yuksel, Pinar Yanardag</p></summary>
<p>

**Abstract:** Recent research has shown that it is possible to find interpretable directions in the latent spaces of pre-trained GANs. These directions enable controllable generation and support a variety of semantic editing operations. While previous work has focused on discovering a single direction that performs a desired editing operation such as zoom-in, limited work has been done on the discovery of multiple and diverse directions that can achieve the desired edit. In this work, we propose a novel framework that discovers multiple and diverse directions for a given property of interest. In particular, we focus on the manipulation of cognitive properties such as Memorability, Emotional Valence and Aesthetics. We show with extensive experiments that our method successfully manipulates these properties while producing diverse outputs. Our project page and source code can be found at http://catlab-team.github.io/latentcognitive.

</p>
</details>

<details><summary><b>ML-based Anomaly Detection in Optical Fiber Monitoring</b>
<a href="https://arxiv.org/abs/2202.11756">arxiv:2202.11756</a>
&#x1F4C8; 5 <br>
<p>Khouloud Abdelli, Joo Yeon Cho, Carsten Tropschug</p></summary>
<p>

**Abstract:** Secure and reliable data communication in optical networks is critical for high-speed internet. We propose a data driven approach for the anomaly detection and faults identification in optical networks to diagnose physical attacks such as fiber breaks and optical tapping. The proposed methods include an autoencoder-based anomaly detection and an attention-based bidirectional gated recurrent unit algorithm for the fiber fault identification and localization. We verify the efficiency of our methods by experiments under various attack scenarios using real operational data.

</p>
</details>

<details><summary><b>Truncated LinUCB for Stochastic Linear Bandits</b>
<a href="https://arxiv.org/abs/2202.11735">arxiv:2202.11735</a>
&#x1F4C8; 5 <br>
<p>Yanglei Song, Meng zhou</p></summary>
<p>

**Abstract:** This paper considers contextual bandits with a finite number of arms, where the contexts are independent and identically distributed $d$-dimensional random vectors, and the expected rewards are linear in both the arm parameters and contexts. The LinUCB algorithm, which is near minimax optimal for related linear bandits, is shown to have a cumulative regret that is suboptimal in both the dimension $d$ and time horizon $T$, due to its over-exploration. A truncated version of LinUCB is proposed and termed "Tr-LinUCB", which follows LinUCB up to a truncation time $S$ and performs pure exploitation afterwards. The Tr-LinUCB algorithm is shown to achieve $O(d\log(T))$ regret if $S = Cd\log(T)$ for a sufficiently large constant $C$, and a matching lower bound is established, which shows the rate optimality of Tr-LinUCB in both $d$ and $T$ under a low dimensional regime. Further, if $S = d\log^κ(T)$ for some $κ>1$, the loss compared to the optimal is a multiplicative $\log\log(T)$ factor, which does not depend on $d$. This insensitivity to overshooting in choosing the truncation time of Tr-LinUCB is of practical importance.

</p>
</details>

<details><summary><b>Mirror Descent Strikes Again: Optimal Stochastic Convex Optimization under Infinite Noise Variance</b>
<a href="https://arxiv.org/abs/2202.11632">arxiv:2202.11632</a>
&#x1F4C8; 5 <br>
<p>Nuri Mert Vural, Lu Yu, Krishnakumar Balasubramanian, Stanislav Volgushev, Murat A. Erdogdu</p></summary>
<p>

**Abstract:** We study stochastic convex optimization under infinite noise variance. Specifically, when the stochastic gradient is unbiased and has uniformly bounded $(1+κ)$-th moment, for some $κ\in (0,1]$, we quantify the convergence rate of the Stochastic Mirror Descent algorithm with a particular class of uniformly convex mirror maps, in terms of the number of iterations, dimensionality and related geometric parameters of the optimization problem. Interestingly this algorithm does not require any explicit gradient clipping or normalization, which have been extensively used in several recent empirical and theoretical works. We complement our convergence results with information-theoretic lower bounds showing that no other algorithm using only stochastic first-order oracles can achieve improved rates. Our results have several interesting consequences for devising online/streaming stochastic approximation algorithms for problems arising in robust statistics and machine learning.

</p>
</details>

<details><summary><b>Short-answer scoring with ensembles of pretrained language models</b>
<a href="https://arxiv.org/abs/2202.11558">arxiv:2202.11558</a>
&#x1F4C8; 5 <br>
<p>Christopher Ormerod</p></summary>
<p>

**Abstract:** We investigate the effectiveness of ensembles of pretrained transformer-based language models on short answer questions using the Kaggle Automated Short Answer Scoring dataset. We fine-tune a collection of popular small, base, and large pretrained transformer-based language models, and train one feature-base model on the dataset with the aim of testing ensembles of these models. We used an early stopping mechanism and hyperparameter optimization in training. We observe that generally that the larger models perform slightly better, however, they still fall short of state-of-the-art results one their own. Once we consider ensembles of models, there are ensembles of a number of large networks that do produce state-of-the-art results, however, these ensembles are too large to realistically be put in a production environment.

</p>
</details>

<details><summary><b>Commonsense Reasoning for Identifying and Understanding the Implicit Need of Help and Synthesizing Assistive Actions</b>
<a href="https://arxiv.org/abs/2202.11337">arxiv:2202.11337</a>
&#x1F4C8; 5 <br>
<p>Maëlic Neau, Paulo Santos, Anne-Gwenn Bosser, Nathan Beu, Cédric Buche</p></summary>
<p>

**Abstract:** Human-Robot Interaction (HRI) is an emerging subfield of service robotics. While most existing approaches rely on explicit signals (i.e. voice, gesture) to engage, current literature is lacking solutions to address implicit user needs. In this paper, we present an architecture to (a) detect user implicit need of help and (b) generate a set of assistive actions without prior learning. Task (a) will be performed using state-of-the-art solutions for Scene Graph Generation coupled to the use of commonsense knowledge; whereas, task (b) will be performed using additional commonsense knowledge as well as a sentiment analysis on graph structure. Finally, we propose an evaluation of our solution using established benchmarks (e.g. ActionGenome dataset) along with human experiments. The main motivation of our approach is the embedding of the perception-decision-action loop in a single architecture.

</p>
</details>

<details><summary><b>Web of Scholars: A Scholar Knowledge Graph</b>
<a href="https://arxiv.org/abs/2202.11311">arxiv:2202.11311</a>
&#x1F4C8; 5 <br>
<p>Jiaying Liu, Jing Ren, Wenqing Zheng, Lianhua Chi, Ivan Lee, Feng Xia</p></summary>
<p>

**Abstract:** In this work, we demonstrate a novel system, namely Web of Scholars, which integrates state-of-the-art mining techniques to search, mine, and visualize complex networks behind scholars in the field of Computer Science. Relying on the knowledge graph, it provides services for fast, accurate, and intelligent semantic querying as well as powerful recommendations. In addition, in order to realize information sharing, it provides an open API to be served as the underlying architecture for advanced functions. Web of Scholars takes advantage of knowledge graph, which means that it will be able to access more knowledge if more search exist. It can be served as a useful and interoperable tool for scholars to conduct in-depth analysis within Science of Science.

</p>
</details>

<details><summary><b>Learning Relative Return Policies With Upside-Down Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2202.12742">arxiv:2202.12742</a>
&#x1F4C8; 4 <br>
<p>Dylan R. Ashley, Kai Arulkumaran, Jürgen Schmidhuber, Rupesh Kumar Srivastava</p></summary>
<p>

**Abstract:** Lately, there has been a resurgence of interest in using supervised learning to solve reinforcement learning problems. Recent work in this area has largely focused on learning command-conditioned policies. We investigate the potential of one such method -- upside-down reinforcement learning -- to work with commands that specify a desired relationship between some scalar value and the observed return. We show that upside-down reinforcement learning can learn to carry out such commands online in a tabular bandit setting and in CartPole with non-linear function approximation. By doing so, we demonstrate the power of this family of methods and open the way for their practical use under more complicated command structures.

</p>
</details>

<details><summary><b>Flat latent manifolds for music improvisation between human and machine</b>
<a href="https://arxiv.org/abs/2202.12243">arxiv:2202.12243</a>
&#x1F4C8; 4 <br>
<p>Nutan Chen, Djalel Benbouzid, Francesco Ferroni, Mathis Nitschke, Luciano Pinna, Patrick van der Smagt</p></summary>
<p>

**Abstract:** The use of machine learning in artistic music generation leads to controversial discussions of the quality of art, for which objective quantification is nonsensical. We therefore consider a music-generating algorithm as a counterpart to a human musician, in a setting where reciprocal improvisation is to lead to new experiences, both for the musician and the audience. To obtain this behaviour, we resort to the framework of recurrent Variational Auto-Encoders (VAE) and learn to generate music, seeded by a human musician. In the learned model, we generate novel musical sequences by interpolation in latent space. Standard VAEs however do not guarantee any form of smoothness in their latent representation. This translates into abrupt changes in the generated music sequences. To overcome these limitations, we regularise the decoder and endow the latent space with a flat Riemannian manifold, i.e., a manifold that is isometric to the Euclidean space. As a result, linearly interpolating in the latent space yields realistic and smooth musical changes that fit the type of machine--musician interactions we aim for. We provide empirical evidence for our method via a set of experiments on music datasets and we deploy our model for an interactive jam session with a professional drummer. The live performance provides qualitative evidence that the latent representation can be intuitively interpreted and exploited by the drummer to drive the interplay. Beyond the musical application, our approach showcases an instance of human-centred design of machine-learning models, driven by interpretability and the interaction with the end user.

</p>
</details>

<details><summary><b>On-line signature verification system with failure to enroll managing</b>
<a href="https://arxiv.org/abs/2202.12242">arxiv:2202.12242</a>
&#x1F4C8; 4 <br>
<p>Joan Fabregas, Marcos Faundez-Zanuy</p></summary>
<p>

**Abstract:** In this paper we simulate a real biometric verification system based on on-line signatures. For this purpose we have split the MCYT signature database in three subsets: one for classifier training, another for system adjustment and a third one for system testing simulating enrollment and verification. This context corresponds to a real operation, where a new user tries to enroll an existing system and must be automatically guided by the system in order to detect the failure to enroll situations. The main contribution of this work is the management of failure to enroll situations by means of a new proposal, called intelligent enrollment, which consists of consistency checking in order to automatically reject low quality samples. This strategy lets to enhance the verification errors up to 22% when leaving out 8% of the users. In this situation 8% of the people cannot be enrolled in the system and must be verified by other biometrics or by human abilities. These people are identified with intelligent enrollment and the situation can be thus managed. In addition we also propose a DCT-based feature extractor with threshold coding and discriminability criteria.

</p>
</details>

<details><summary><b>Controlling Memorability of Face Images</b>
<a href="https://arxiv.org/abs/2202.11896">arxiv:2202.11896</a>
&#x1F4C8; 4 <br>
<p>Mohammad Younesi, Yalda Mohsenzadeh</p></summary>
<p>

**Abstract:** Everyday, we are bombarded with many photographs of faces, whether on social media, television, or smartphones. From an evolutionary perspective, faces are intended to be remembered, mainly due to survival and personal relevance. However, all these faces do not have the equal opportunity to stick in our minds. It has been shown that memorability is an intrinsic feature of an image but yet, it is largely unknown what attributes make an image more memorable. In this work, we aimed to address this question by proposing a fast approach to modify and control the memorability of face images. In our proposed method, we first found a hyperplane in the latent space of StyleGAN to separate high and low memorable images. We then modified the image memorability (while maintaining the identity and other facial features such as age, emotion, etc.) by moving in the positive or negative direction of this hyperplane normal vector. We further analyzed how different layers of the StyleGAN augmented latent space contribute to face memorability. These analyses showed how each individual face attribute makes an image more or less memorable. Most importantly, we evaluated our proposed method for both real and synthesized face images. The proposed method successfully modifies and controls the memorability of real human faces as well as unreal synthesized faces. Our proposed method can be employed in photograph editing applications for social media, learning aids, or advertisement purposes.

</p>
</details>

<details><summary><b>A spectral-spatial fusion anomaly detection method for hyperspectral imagery</b>
<a href="https://arxiv.org/abs/2202.11889">arxiv:2202.11889</a>
&#x1F4C8; 4 <br>
<p>Zengfu Hou, Siyuan Cheng, Ting Hu</p></summary>
<p>

**Abstract:** In hyperspectral, high-quality spectral signals convey subtle spectral differences to distinguish similar materials, thereby providing unique advantage for anomaly detection. Hence fine spectra of anomalous pixels can be effectively screened out from heterogeneous background pixels. Since the same materials have similar characteristics in spatial and spectral dimension, detection performance can be significantly enhanced by jointing spatial and spectral information. In this paper, a spectralspatial fusion anomaly detection (SSFAD) method is proposed for hyperspectral imagery. First, original spectral signals are mapped to a local linear background space composed of median and mean with high confidence, where saliency weight and feature enhancement strategies are implemented to obtain an initial detection map in spectral domain. Futhermore, to make full use of similarity information of local background around testing pixel, a new detector is designed to extract the local similarity spatial features of patch images in spatial domain. Finally, anomalies are detected by adaptively combining the spectral and spatial detection maps. The experimental results demonstrate that our proposed method has superior detection performance than traditional methods.

</p>
</details>

<details><summary><b>Loss as the Inconsistency of a Probabilistic Dependency Graph: Choose Your Model, Not Your Loss Function</b>
<a href="https://arxiv.org/abs/2202.11862">arxiv:2202.11862</a>
&#x1F4C8; 4 <br>
<p>Oliver E Richardson</p></summary>
<p>

**Abstract:** In a world blessed with a great diversity of loss functions, we argue that that choice between them is not a matter of taste or pragmatics, but of model. Probabilistic depencency graphs (PDGs) are probabilistic models that come equipped with a measure of "inconsistency". We prove that many standard loss functions arise as the inconsistency of a natural PDG describing the appropriate scenario, and use the same approach to justify a well-known connection between regularizers and priors. We also show that the PDG inconsistency captures a large class of statistical divergences, and detail benefits of thinking of them in this way, including an intuitive visual language for deriving inequalities between them. In variational inference, we find that the ELBO, a somewhat opaque objective for latent variable models, and variants of it arise for free out of uncontroversial modeling assumptions -- as do simple graphical proofs of their corresponding bounds. Finally, we observe that inconsistency becomes the log partition function (free energy) in the setting where PDGs are factor graphs.

</p>
</details>

<details><summary><b>Learning Multi-Object Dynamics with Compositional Neural Radiance Fields</b>
<a href="https://arxiv.org/abs/2202.11855">arxiv:2202.11855</a>
&#x1F4C8; 4 <br>
<p>Danny Driess, Zhiao Huang, Yunzhu Li, Russ Tedrake, Marc Toussaint</p></summary>
<p>

**Abstract:** We present a method to learn compositional predictive models from image observations based on implicit object encoders, Neural Radiance Fields (NeRFs), and graph neural networks. A central question in learning dynamic models from sensor observations is on which representations predictions should be performed. NeRFs have become a popular choice for representing scenes due to their strong 3D prior. However, most NeRF approaches are trained on a single scene, representing the whole scene with a global model, making generalization to novel scenes, containing different numbers of objects, challenging. Instead, we present a compositional, object-centric auto-encoder framework that maps multiple views of the scene to a \emph{set} of latent vectors representing each object separately. The latent vectors parameterize individual NeRF models from which the scene can be reconstructed and rendered from novel viewpoints. We train a graph neural network dynamics model in the latent space to achieve compositionality for dynamics prediction. A key feature of our approach is that the learned 3D information of the scene through the NeRF model enables us to incorporate structural priors in learning the dynamics models, making long-term predictions more stable. The model can further be used to synthesize new scenes from individual object observations. For planning, we utilize RRTs in the learned latent space, where we can exploit our model and the implicit object encoder to make sampling the latent space informative and more efficient. In the experiments, we show that the model outperforms several baselines on a pushing task containing many objects. Video: https://dannydriess.github.io/compnerfdyn/

</p>
</details>

<details><summary><b>A modification of the conjugate direction method for motion estimation</b>
<a href="https://arxiv.org/abs/2202.11831">arxiv:2202.11831</a>
&#x1F4C8; 4 <br>
<p>Marcos Faundez-Zanuy, Francesc Tarres-Ruiz</p></summary>
<p>

**Abstract:** A comparative study of different block matching alternatives for motion estimation is presented. The study is focused on computational burden and objective measures on the accuracy of prediction. Together with existing algorithms several new variations have been tested. An interesting modification of the conjugate direction method previously related in literature is reported. This new algorithm shows a good trade-off between computational complexity and accuracy of motion vector estimation. Computational complexity is evaluated using a sequence of artificial images designed to incorporate a great variety of motion vectors. The performance of block matching methods has been measured in terms of the entropy in the error signal between the motion compensated and the original frames.

</p>
</details>

<details><summary><b>Physics-informed neural networks for inverse problems in supersonic flows</b>
<a href="https://arxiv.org/abs/2202.11821">arxiv:2202.11821</a>
&#x1F4C8; 4 <br>
<p>Ameya D. Jagtap, Zhiping Mao, Nikolaus Adams, George Em Karniadakis</p></summary>
<p>

**Abstract:** Accurate solutions to inverse supersonic compressible flow problems are often required for designing specialized aerospace vehicles. In particular, we consider the problem where we have data available for density gradients from Schlieren photography as well as data at the inflow and part of wall boundaries. These inverse problems are notoriously difficult and traditional methods may not be adequate to solve such ill-posed inverse problems. To this end, we employ the physics-informed neural networks (PINNs) and its extended version, extended PINNs (XPINNs), where domain decomposition allows deploying locally powerful neural networks in each subdomain, which can provide additional expressivity in subdomains, where a complex solution is expected. Apart from the governing compressible Euler equations, we also enforce the entropy conditions in order to obtain viscosity solutions. Moreover, we enforce positivity conditions on density and pressure. We consider inverse problems involving two-dimensional expansion waves, two-dimensional oblique and bow shock waves. We compare solutions obtained by PINNs and XPINNs and invoke some theoretical results that can be used to decide on the generalization errors of the two methods.

</p>
</details>

<details><summary><b>Consistent Dropout for Policy Gradient Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2202.11818">arxiv:2202.11818</a>
&#x1F4C8; 4 <br>
<p>Matthew Hausknecht, Nolan Wagener</p></summary>
<p>

**Abstract:** Dropout has long been a staple of supervised learning, but is rarely used in reinforcement learning. We analyze why naive application of dropout is problematic for policy-gradient learning algorithms and introduce consistent dropout, a simple technique to address this instability. We demonstrate consistent dropout enables stable training with A2C and PPO in both continuous and discrete action environments across a wide range of dropout probabilities. Finally, we show that consistent dropout enables the online training of complex architectures such as GPT without needing to disable the model's native dropout.

</p>
</details>

<details><summary><b>Generative modeling via tensor train sketching</b>
<a href="https://arxiv.org/abs/2202.11788">arxiv:2202.11788</a>
&#x1F4C8; 4 <br>
<p>Y. Hur, J. G. Hoskins, M. Lindsey, E. M. Stoudenmire, Y. Khoo</p></summary>
<p>

**Abstract:** In this paper we introduce a sketching algorithm for constructing a tensor train representation of a probability density from its samples. Our method deviates from the standard recursive SVD-based procedure for constructing a tensor train. Instead we formulate and solve a sequence of small linear systems for the individual tensor train cores. This approach can avoid the curse of dimensionality that threatens both the algorithmic and sample complexities of the recovery problem. Specifically, for Markov models, we prove that the tensor cores can be recovered with a sample complexity that is constant with respect to the dimension. Finally, we illustrate the performance of the method with several numerical experiments.

</p>
</details>

<details><summary><b>When do GANs replicate? On the choice of dataset size</b>
<a href="https://arxiv.org/abs/2202.11765">arxiv:2202.11765</a>
&#x1F4C8; 4 <br>
<p>Qianli Feng, Chenqi Guo, Fabian Benitez-Quiroz, Aleix Martinez</p></summary>
<p>

**Abstract:** Do GANs replicate training images? Previous studies have shown that GANs do not seem to replicate training data without significant change in the training procedure. This leads to a series of research on the exact condition needed for GANs to overfit to the training data. Although a number of factors has been theoretically or empirically identified, the effect of dataset size and complexity on GANs replication is still unknown. With empirical evidence from BigGAN and StyleGAN2, on datasets CelebA, Flower and LSUN-bedroom, we show that dataset size and its complexity play an important role in GANs replication and perceptual quality of the generated images. We further quantify this relationship, discovering that replication percentage decays exponentially with respect to dataset size and complexity, with a shared decaying factor across GAN-dataset combinations. Meanwhile, the perceptual image quality follows a U-shape trend w.r.t dataset size. This finding leads to a practical tool for one-shot estimation on minimal dataset size to prevent GAN replication which can be used to guide datasets construction and selection.

</p>
</details>

<details><summary><b>Super-resolution GANs of randomly-seeded fields</b>
<a href="https://arxiv.org/abs/2202.11701">arxiv:2202.11701</a>
&#x1F4C8; 4 <br>
<p>Alejandro Güemes, Carlos Sanmiguel Vila, Stefano Discetti</p></summary>
<p>

**Abstract:** Reconstruction of field quantities from sparse measurements is a problem arising in a broad spectrum of applications. This task is particularly challenging when mapping between point sparse measurements and field quantities shall be performed in an unsupervised manner. Further complexity is added for moving sensors and/or random on-off status. Under such conditions, the most straightforward solution is to interpolate the scattered data onto a regular grid. However, the spatial resolution achieved with this approach is ultimately limited by the mean spacing between the sparse measurements. In this work, we propose a novel super-resolution generative adversarial network (GAN) framework to estimate field quantities from random sparse sensors without needing any full-resolution field for training. The algorithm exploits random sampling to provide incomplete views of the high-resolution underlying distributions. It is hereby referred to as RAndomly-SEEDed super-resolution GAN (RaSeedGAN). The proposed technique is tested on synthetic databases of fluid flow simulations, ocean surface temperature distributions measurements, and particle image velocimetry data of a zero-pressure-gradient turbulent boundary layer. The results show an excellent performance of the proposed methodology even in cases with a high level of gappyness (>50\%) or noise conditions. To our knowledge, this is the first super-resolution GANs algorithm for full-field estimation from randomly-seeded fields with no need of a full-field high-resolution representation during training nor of a library of training examples.

</p>
</details>

<details><summary><b>TEE-based decentralized recommender systems: The raw data sharing redemption</b>
<a href="https://arxiv.org/abs/2202.11655">arxiv:2202.11655</a>
&#x1F4C8; 4 <br>
<p>Akash Dhasade, Nevena Dresevic, Anne-Marie Kermarrec, Rafael Pires</p></summary>
<p>

**Abstract:** Recommenders are central in many applications today. The most effective recommendation schemes, such as those based on collaborative filtering (CF), exploit similarities between user profiles to make recommendations, but potentially expose private data. Federated learning and decentralized learning systems address this by letting the data stay on user's machines to preserve privacy: each user performs the training on local data and only the model parameters are shared. However, sharing the model parameters across the network may still yield privacy breaches. In this paper, we present REX, the first enclave-based decentralized CF recommender. REX exploits Trusted execution environments (TEE), such as Intel software guard extensions (SGX), that provide shielded environments within the processor to improve convergence while preserving privacy. Firstly, REX enables raw data sharing, which ultimately speeds up convergence and reduces the network load. Secondly, REX fully preserves privacy. We analyze the impact of raw data sharing in both deep neural network (DNN) and matrix factorization (MF) recommenders and showcase the benefits of trusted environments in a full-fledged implementation of REX. Our experimental results demonstrate that through raw data sharing, REX significantly decreases the training time by 18.3x and the network load by 2 orders of magnitude over standard decentralized approaches that share only parameters, while fully protecting privacy by leveraging trustworthy hardware enclaves with very little overhead.

</p>
</details>

<details><summary><b>Amortised Likelihood-free Inference for Expensive Time-series Simulators with Signatured Ratio Estimation</b>
<a href="https://arxiv.org/abs/2202.11585">arxiv:2202.11585</a>
&#x1F4C8; 4 <br>
<p>Joel Dyer, Patrick Cannon, Sebastian M Schmon</p></summary>
<p>

**Abstract:** Simulation models of complex dynamics in the natural and social sciences commonly lack a tractable likelihood function, rendering traditional likelihood-based statistical inference impossible. Recent advances in machine learning have introduced novel algorithms for estimating otherwise intractable likelihood functions using a likelihood ratio trick based on binary classifiers. Consequently, efficient likelihood approximations can be obtained whenever good probabilistic classifiers can be constructed. We propose a kernel classifier for sequential data using path signatures based on the recently introduced signature kernel. We demonstrate that the representative power of signatures yields a highly performant classifier, even in the crucially important case where sample numbers are low. In such scenarios, our approach can outperform sophisticated neural networks for common posterior inference tasks.

</p>
</details>

<details><summary><b>Thermal hand image segmentation for biometric recognition</b>
<a href="https://arxiv.org/abs/2202.11462">arxiv:2202.11462</a>
&#x1F4C8; 4 <br>
<p>Xavier Font-Aragones, Marcos Faundez-Zanuy, Jiri Mekyska</p></summary>
<p>

**Abstract:** In this paper we present a method to identify people by means of thermal (TH) and visible (VIS) hand images acquired simultaneously with a TESTO 882-3 camera. In addition, we also present a new database specially acquired for this work. The real challenge when dealing with TH images is the cold finger areas, which can be confused with the acquisition surface. This problem is solved by taking advantage of the VIS information. We have performed different tests to show how TH and VIS images work in identification problems. Experimental results reveal that TH hand image is as suitable for biometric recognition systems as VIS hand images, and better results are obtained when combining this information. A Biometric Dispersion Matcher has been used as a feature vector dimensionality reduction technique as well as a classification task. Its selection criteria helps to reduce the length of the vectors used to perform identification up to a hundred measurements. Identification rates reach a maximum value of 98.3% under these conditions, when using a database of 104 people.

</p>
</details>

<details><summary><b>Towards Speaker Age Estimation with Label Distribution Learning</b>
<a href="https://arxiv.org/abs/2202.11424">arxiv:2202.11424</a>
&#x1F4C8; 4 <br>
<p>Shijing Si, Jianzong Wang, Junqing Peng, Jing Xiao</p></summary>
<p>

**Abstract:** Existing methods for speaker age estimation usually treat it as a multi-class classification or a regression problem. However, precise age identification remains a challenge due to label ambiguity, \emph{i.e.}, utterances from adjacent age of the same person are often indistinguishable. To address this, we utilize the ambiguous information among the age labels, convert each age label into a discrete label distribution and leverage the label distribution learning (LDL) method to fit the data. For each audio data sample, our method produces a age distribution of its speaker, and on top of the distribution we also perform two other tasks: age prediction and age uncertainty minimization. Therefore, our method naturally combines the age classification and regression approaches, which enhances the robustness of our method. We conduct experiments on the public NIST SRE08-10 dataset and a real-world dataset, which exhibit that our method outperforms baseline methods by a relatively large margin, yielding a 10\% reduction in terms of mean absolute error (MAE) on a real-world dataset.

</p>
</details>

<details><summary><b>Deep Metric Learning-Based Semi-Supervised Regression With Alternate Learning</b>
<a href="https://arxiv.org/abs/2202.11388">arxiv:2202.11388</a>
&#x1F4C8; 4 <br>
<p>Adina Zell, Gencer Sumbul, Begüm Demir</p></summary>
<p>

**Abstract:** This paper introduces a novel deep metric learning-based semi-supervised regression (DML-S2R) method for parameter estimation problems. The proposed DML-S2R method aims to mitigate the problems of insufficient amount of labeled samples without collecting any additional samples with target values. To this end, the proposed DML-S2R method is made up of two main steps: i) pairwise similarity modeling with scarce labeled data; and ii) triplet-based metric learning with abundant unlabeled data. The first step aims to model pairwise sample similarities by using a small number of labeled samples. This is achieved by estimating the target value differences of labeled samples with a Siamese neural network (SNN). The second step aims to learn a triplet-based metric space (in which similar samples are close to each other and dissimilar samples are far apart from each other) when the number of labeled samples is insufficient. This is achieved by employing the SNN of the first step for triplet-based deep metric learning that exploits not only labeled samples but also unlabeled samples. For the end-to-end training of DML-S2R, we investigate an alternate learning strategy for the two steps. Due to this strategy, the encoded information in each step becomes a guidance for learning the other step. The experimental results confirm the success of DML-S2R compared to the state-of-the-art semi-supervised regression methods. The code of the proposed method is publicly available at https://git.tu-berlin.de/rsim/DML-S2R.

</p>
</details>

<details><summary><b>A comparative study of several parameterizations for speaker recognition</b>
<a href="https://arxiv.org/abs/2203.00513">arxiv:2203.00513</a>
&#x1F4C8; 3 <br>
<p>Marcos Faundez-Zanuy</p></summary>
<p>

**Abstract:** This paper presents an exhaustive study about the robustness of several parameterizations, in speaker verification and identification tasks. We have studied several mismatch conditions: different recording sessions, microphones, and different languages (it has been obtained from a bilingual set of speakers). This study reveals that the combination of several parameterizations can improve the robustness in all the scenarios for both tasks, identification and verification. In addition, two different methods have been evaluated: vector quantization, and covariance matrices with an arithmetic-harmonic sphericity measure.

</p>
</details>

<details><summary><b>Technological evaluation of two AFIS systems</b>
<a href="https://arxiv.org/abs/2203.00447">arxiv:2203.00447</a>
&#x1F4C8; 3 <br>
<p>Marcos Faundez-Zanuy</p></summary>
<p>

**Abstract:** This paper provides a technological evaluation of two Automatic Fingerprint Identification Systems (AFIS) used in forensic applications. Both of them are installed and working in Spanish police premises. The first one is a Printrak AFIS 2000 system with a database of more than 450,000 fingerprints, while the second one is a NEC AFIS 21 SAID NT-LEXS Release 2.4.4 with a database of more than 15 million fingerprints. Our experiments reveal that although both systems can manage inkless fingerprints, the latest one offers better experimental results

</p>
</details>

<details><summary><b>Path-Aware Graph Attention for HD Maps in Motion Prediction</b>
<a href="https://arxiv.org/abs/2202.13772">arxiv:2202.13772</a>
&#x1F4C8; 3 <br>
<p>Fang Da, Yu Zhang</p></summary>
<p>

**Abstract:** The success of motion prediction for autonomous driving relies on integration of information from the HD maps. As maps are naturally graph-structured, investigation on graph neural networks (GNNs) for encoding HD maps is burgeoning in recent years. However, unlike many other applications where GNNs have been straightforwardly deployed, HD maps are heterogeneous graphs where vertices (lanes) are connected by edges (lane-lane interaction relationships) of various nature, and most graph-based models are not designed to understand the variety of edge types which provide crucial cues for predicting how the agents would travel the lanes. To overcome this challenge, we propose Path-Aware Graph Attention, a novel attention architecture that infers the attention between two vertices by parsing the sequence of edges forming the paths that connect them. Our analysis illustrates how the proposed attention mechanism can facilitate learning in a didactic problem where existing graph networks like GCN struggle. By improving map encoding, the proposed model surpasses previous state of the art on the Argoverse Motion Forecasting dataset, and won the first place in the 2021 Argoverse Motion Forecasting Competition.

</p>
</details>

<details><summary><b>Modulation and signal class labelling using active learning and classification using machine learning</b>
<a href="https://arxiv.org/abs/2202.12930">arxiv:2202.12930</a>
&#x1F4C8; 3 <br>
<p>Bhargava B C, Ankush Deshmukh, A V Narasimhadhan</p></summary>
<p>

**Abstract:** Supervised learning in machine learning (ML) requires labelled data set. Further real-time data classification requires an easily available methodology for labelling. Wireless modulation and signal classification find their application in plenty of areas such as military, commercial and electronic reconaissance and cognitive radio. This paper mainly aims to solve the problem of real-time wireless modulation and signal class labelling with an active learning framework. Further modulation and signal classification is performed with machine learning algorithms such as KNN, SVM, Naive bayes. Active learning helps in labelling the data points belonging to different classes with the least amount of data samples trained. An accuracy of 86 percent is obtained by the active learning algorithm for the signal with SNR 18 dB. Further, KNN based model for modulation and signal classification performs well over range of SNR, and an accuracy of 99.8 percent is obtained for 18 dB signal. The novelty of this work exists in applying active learning for wireless modulation and signal class labelling. Both modulation and signal classes are labelled at a given time with help of couplet formation from the data samples.

</p>
</details>

<details><summary><b>UnifiedQA-v2: Stronger Generalization via Broader Cross-Format Training</b>
<a href="https://arxiv.org/abs/2202.12359">arxiv:2202.12359</a>
&#x1F4C8; 3 <br>
<p>Daniel Khashabi, Yeganeh Kordi, Hannaneh Hajishirzi</p></summary>
<p>

**Abstract:** We present UnifiedQA-v2, a QA model built with the same process as UnifiedQA, except that it utilizes more supervision -- roughly 3x the number of datasets used for UnifiedQA. This generally leads to better in-domain and cross-domain results.

</p>
</details>

<details><summary><b>A comparative study of in-air trajectories at short and long distances in online handwriting</b>
<a href="https://arxiv.org/abs/2202.12237">arxiv:2202.12237</a>
&#x1F4C8; 3 <br>
<p>Carlos Alonso-Martinez, Marcos Faundez-Zanuy, Jiri Mekyska</p></summary>
<p>

**Abstract:** Introduction Existing literature about online handwriting analysis to support pathology diagnosis has taken advantage of in-air trajectories. A similar situation occurred in biometric security applications where the goal is to identify or verify an individual using his signature or handwriting. These studies do not consider the distance of the pen tip to the writing surface. This is due to the fact that current acquisition devices do not provide height formation. However, it is quite straightforward to differentiate movements at two different heights: a) short distance: height lower or equal to 1 cm above a surface of digitizer, the digitizer provides x and y coordinates. b) long distance: height exceeding 1 cm, the only information available is a time stamp that indicates the time that a specific stroke has spent at long distance. Although short distance has been used in several papers, long distances have been ignored and will be investigated in this paper. Methods In this paper, we will analyze a large set of databases (BIOSECURID, EMOTHAW, PaHaW, Oxygen-Therapy and SALT), which contain a total amount of 663 users and 17951 files. We have specifically studied: a) the percentage of time spent on-surface, in-air at short distance, and in-air at long distance for different user profiles (pathological and healthy users) and different tasks; b) The potential use of these signals to improve classification rates. Results and conclusions Our experimental results reveal that long-distance movements represent a very small portion of the total execution time (0.5 % in the case of signatures and 10.4% for uppercase words of BIOSECUR-ID, which is the largest database). In addition, significant differences have been found in the comparison of pathological versus control group for letter l in PaHaW database (p=0.0157) and crossed pentagons in SALT database (p=0.0122)

</p>
</details>

<details><summary><b>No-Regret Learning in Games is Turing Complete</b>
<a href="https://arxiv.org/abs/2202.11871">arxiv:2202.11871</a>
&#x1F4C8; 3 <br>
<p>Gabriel P. Andrade, Rafael Frongillo, Georgios Piliouras</p></summary>
<p>

**Abstract:** Games are natural models for multi-agent machine learning settings, such as generative adversarial networks (GANs). The desirable outcomes from algorithmic interactions in these games are encoded as game theoretic equilibrium concepts, e.g. Nash and coarse correlated equilibria. As directly computing an equilibrium is typically impractical, one often aims to design learning algorithms that iteratively converge to equilibria. A growing body of negative results casts doubt on this goal, from non-convergence to chaotic and even arbitrary behaviour. In this paper we add a strong negative result to this list: learning in games is Turing complete. Specifically, we prove Turing completeness of the replicator dynamic on matrix games, one of the simplest possible settings. Our results imply the undecicability of reachability problems for learning algorithms in games, a special case of which is determining equilibrium convergence.

</p>
</details>

<details><summary><b>Robust Federated Learning with Connectivity Failures: A Semi-Decentralized Framework with Collaborative Relaying</b>
<a href="https://arxiv.org/abs/2202.11850">arxiv:2202.11850</a>
&#x1F4C8; 3 <br>
<p>Michal Yemini, Rajarshi Saha, Emre Ozfatura, Deniz Gündüz, Andrea J. Goldsmith</p></summary>
<p>

**Abstract:** Intermittent client connectivity is one of the major challenges in centralized federated edge learning frameworks. Intermittently failing uplinks to the central parameter server (PS) can induce a large generalization gap in performance especially when the data distribution among the clients exhibits heterogeneity. In this work, to mitigate communication blockages between clients and the central PS, we introduce the concept of knowledge relaying wherein the successfully participating clients collaborate in relaying their neighbors' local updates to a central parameter server (PS) in order to boost the participation of clients with intermittently failing connectivity. We propose a collaborative relaying based semi-decentralized federated edge learning framework where at every communication round each client first computes a local consensus of the updates from its neighboring clients and eventually transmits a weighted average of its own update and those of its neighbors to the PS. We appropriately optimize these averaging weights to reduce the variance of the global update at the PS while ensuring that the global update is unbiased, consequently improving the convergence rate. Finally, by conducting experiments on CIFAR-10 dataset we validate our theoretical results and demonstrate that our proposed scheme is superior to Federated averaging benchmark especially when data distribution among clients is non-iid.

</p>
</details>

<details><summary><b>Nuclei panoptic segmentation and composition regression with multi-task deep neural networks</b>
<a href="https://arxiv.org/abs/2202.11804">arxiv:2202.11804</a>
&#x1F4C8; 3 <br>
<p>Satoshi Kondo, Satoshi Kasai</p></summary>
<p>

**Abstract:** Nuclear segmentation, classification and quantification within Haematoxylin & Eosin stained histology images enables the extraction of interpretable cell-based features that can be used in downstream explainable models in computational pathology. The Colon Nuclei Identification and Counting (CoNIC) Challenge is held to help drive forward research and innovation for automatic nuclei recognition in computational pathology. This report describes our proposed method submitted to the CoNIC challenge. Our method employs a multi-task learning framework, which performs a panoptic segmentation task and a regression task. For the panoptic segmentation task, we use encoder-decoder type deep neural networks predicting a direction map in addition to a segmentation map in order to separate neighboring nuclei into different instances

</p>
</details>

<details><summary><b>Drawing Inductor Layout with a Reinforcement Learning Agent: Method and Application for VCO Inductors</b>
<a href="https://arxiv.org/abs/2202.11798">arxiv:2202.11798</a>
&#x1F4C8; 3 <br>
<p>Cameron Haigh, Zichen Zhang, Negar Hassanpour, Khurram Javed, Yingying Fu, Shayan Shahramian, Shawn Zhang, Jun Luo</p></summary>
<p>

**Abstract:** Design of Voltage-Controlled Oscillator (VCO) inductors is a laborious and time-consuming task that is conventionally done manually by human experts. In this paper, we propose a framework for automating the design of VCO inductors, using Reinforcement Learning (RL). We formulate the problem as a sequential procedure, where wire segments are drawn one after another, until a complete inductor is created. We then employ an RL agent to learn to draw inductors that meet certain target specifications. In light of the need to tweak the target specifications throughout the circuit design cycle, we also develop a variant in which the agent can learn to quickly adapt to draw new inductors for moderately different target specifications. Our empirical results show that the proposed framework is successful at automatically generating VCO inductors that meet or exceed the target specification.

</p>
</details>

<details><summary><b>Learning Fast and Slow for Online Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2202.11672">arxiv:2202.11672</a>
&#x1F4C8; 3 <br>
<p>Quang Pham, Chenghao Liu, Doyen Sahoo, Steven C. H. Hoi</p></summary>
<p>

**Abstract:** The fast adaptation capability of deep neural networks in non-stationary environments is critical for online time series forecasting. Successful solutions require handling changes to new and recurring patterns. However, training deep neural forecaster on the fly is notoriously challenging because of their limited ability to adapt to non-stationary environments and the catastrophic forgetting of old knowledge. In this work, inspired by the Complementary Learning Systems (CLS) theory, we propose Fast and Slow learning Networks (FSNet), a holistic framework for online time-series forecasting to simultaneously deal with abrupt changing and repeating patterns. Particularly, FSNet improves the slowly-learned backbone by dynamically balancing fast adaptation to recent changes and retrieving similar old knowledge. FSNet achieves this mechanism via an interaction between two complementary components of an adapter to monitor each layer's contribution to the lost, and an associative memory to support remembering, updating, and recalling repeating events. Extensive experiments on real and synthetic datasets validate FSNet's efficacy and robustness to both new and recurring patterns. Our code will be made publicly available.

</p>
</details>

<details><summary><b>Globally Convergent Policy Search over Dynamic Filters for Output Estimation</b>
<a href="https://arxiv.org/abs/2202.11659">arxiv:2202.11659</a>
&#x1F4C8; 3 <br>
<p>Jack Umenberger, Max Simchowitz, Juan C. Perdomo, Kaiqing Zhang, Russ Tedrake</p></summary>
<p>

**Abstract:** We introduce the first direct policy search algorithm which provably converges to the globally optimal $\textit{dynamic}$ filter for the classical problem of predicting the outputs of a linear dynamical system, given noisy, partial observations. Despite the ubiquity of partial observability in practice, theoretical guarantees for direct policy search algorithms, one of the backbones of modern reinforcement learning, have proven difficult to achieve. This is primarily due to the degeneracies which arise when optimizing over filters that maintain internal state.
  In this paper, we provide a new perspective on this challenging problem based on the notion of $\textit{informativity}$, which intuitively requires that all components of a filter's internal state are representative of the true state of the underlying dynamical system. We show that informativity overcomes the aforementioned degeneracy. Specifically, we propose a $\textit{regularizer}$ which explicitly enforces informativity, and establish that gradient descent on this regularized objective - combined with a ``reconditioning step'' - converges to the globally optimal cost a $\mathcal{O}(1/T)$ rate. Our analysis relies on several new results which may be of independent interest, including a new framework for analyzing non-convex gradient descent via convex reformulation, and novel bounds on the solution to linear Lyapunov equations in terms of (our quantitative measure of) informativity.

</p>
</details>

<details><summary><b>Deep Bayesian ICP Covariance Estimation</b>
<a href="https://arxiv.org/abs/2202.11607">arxiv:2202.11607</a>
&#x1F4C8; 3 <br>
<p>Andrea De Maio, Simon Lacroix</p></summary>
<p>

**Abstract:** Covariance estimation for the Iterative Closest Point (ICP) point cloud registration algorithm is essential for state estimation and sensor fusion purposes. We argue that a major source of error for ICP is in the input data itself, from the sensor noise to the scene geometry. Benefiting from recent developments in deep learning for point clouds, we propose a data-driven approach to learn an error model for ICP. We estimate covariances modeling data-dependent heteroscedastic aleatoric uncertainty, and epistemic uncertainty using a variational Bayesian approach. The system evaluation is performed on LiDAR odometry on different datasets, highlighting good results in comparison to the state of the art.

</p>
</details>

<details><summary><b>Finding Safe Zones of policies Markov Decision Processes</b>
<a href="https://arxiv.org/abs/2202.11593">arxiv:2202.11593</a>
&#x1F4C8; 3 <br>
<p>Lee Cohen, Yishay Mansour, Michal Moshkovitz</p></summary>
<p>

**Abstract:** Given a policy, we define a SafeZone as a subset of states, such that most of the policy's trajectories are confined to this subset. The quality of the SafeZone is parameterized by the number of states and the escape probability, i.e., the probability that a random trajectory will leave the subset. SafeZones are especially interesting when they have a small number of states and low escape probability. We study the complexity of finding optimal SafeZones, and show that in general the problem is computationally hard. For this reason we concentrate on computing approximate SafeZones. Our main result is a bi-criteria approximation algorithm which gives a factor of almost $2$ approximation for both the escape probability and SafeZone size, using a polynomial size sample complexity. We conclude the paper with an empirical evaluation of our algorithm.

</p>
</details>

<details><summary><b>Diffractive optical system design by cascaded propagation</b>
<a href="https://arxiv.org/abs/2202.11535">arxiv:2202.11535</a>
&#x1F4C8; 3 <br>
<p>Boris Ferdman, Alon Saguy, Onit Alalouf, Yoav Shechtman</p></summary>
<p>

**Abstract:** Modern design of complex optical systems relies heavily on computational tools. These typically utilize geometrical optics as well as Fourier optics, which enables the use of diffractive elements to manipulate light with features on the scale of a wavelength. Fourier optics is typically used for designing thin elements, placed in the system's aperture, generating a shift-invariant Point Spread Function (PSF). A major bottleneck in applying Fourier Optics in many cases of interest, e.g. when dealing with multiple, or out-of-aperture elements, comes from numerical complexity. In this work, we propose and implement an efficient and differentiable propagation model based on the Collins integral, which enables the optimization of diffraction optical systems with unprecedented design freedom using backpropagation. We demonstrate the applicability of our method, numerically and experimentally, by engineering shift-variant PSFs via thin plate elements placed in arbitrary planes inside complex imaging systems, performing cascaded optimization of multiple planes, and designing optimal machine-vision systems by deep learning.

</p>
</details>

<details><summary><b>Weakly-supervised learning for image-based classification of primary melanomas into genomic immune subgroups</b>
<a href="https://arxiv.org/abs/2202.11524">arxiv:2202.11524</a>
&#x1F4C8; 3 <br>
<p>Lucy Godson, Navid Alemi, Jeremie Nsengimana, Graham P. Cook, Emily L. Clarke, Darren Treanor, D. Timothy Bishop, Julia Newton-Bishop, Ali Gooya</p></summary>
<p>

**Abstract:** Determining early-stage prognostic markers and stratifying patients for effective treatment are two key challenges for improving outcomes for melanoma patients. Previous studies have used tumour transcriptome data to stratify patients into immune subgroups, which were associated with differential melanoma specific survival and potential treatment strategies. However, acquiring transcriptome data is a time-consuming and costly process. Moreover, it is not routinely used in the current clinical workflow. Here we attempt to overcome this by developing deep learning models to classify gigapixel H&E stained pathology slides, which are well established in clinical workflows, into these immune subgroups. Previous subtyping approaches have employed supervised learning which requires fully annotated data, or have only examined single genetic mutations in melanoma patients. We leverage a multiple-instance learning approach, which only requires slide-level labels and uses an attention mechanism to highlight regions of high importance to the classification. Moreover, we show that pathology-specific self-supervised models generate better representations compared to pathology-agnostic models for improving our model performance, achieving a mean AUC of 0.76 for classifying histopathology images as high or low immune subgroups. We anticipate that this method may allow us to find new biomarkers of high importance and could act as a tool for clinicians to infer the immune landscape of tumours and stratify patients, without needing to carry out additional expensive genetic tests.

</p>
</details>

<details><summary><b>Augmentation based unsupervised domain adaptation</b>
<a href="https://arxiv.org/abs/2202.11486">arxiv:2202.11486</a>
&#x1F4C8; 3 <br>
<p>Mauricio Orbes-Arteaga, Thomas Varsavsky, Lauge Sorensen, Mads Nielsen, Akshay Pai, Sebastien Ourselin, Marc Modat, M Jorge Cardoso</p></summary>
<p>

**Abstract:** The insertion of deep learning in medical image analysis had lead to the development of state-of-the art strategies in several applications such a disease classification, as well as abnormality detection and segmentation. However, even the most advanced methods require a huge and diverse amount of data to generalize. Because in realistic clinical scenarios, data acquisition and annotation is expensive, deep learning models trained on small and unrepresentative data tend to outperform when deployed in data that differs from the one used for training (e.g data from different scanners). In this work, we proposed a domain adaptation methodology to alleviate this problem in segmentation models. Our approach takes advantage of the properties of adversarial domain adaptation and consistency training to achieve more robust adaptation. Using two datasets with white matter hyperintensities (WMH) annotations, we demonstrated that the proposed method improves model generalization even in corner cases where individual strategies tend to fail.

</p>
</details>

<details><summary><b>Listen to Interpret: Post-hoc Interpretability for Audio Networks with NMF</b>
<a href="https://arxiv.org/abs/2202.11479">arxiv:2202.11479</a>
&#x1F4C8; 3 <br>
<p>Jayneel Parekh, Sanjeel Parekh, Pavlo Mozharovskyi, Florence d'Alché-Buc, Gaël Richard</p></summary>
<p>

**Abstract:** This paper tackles post-hoc interpretability for audio processing networks. Our goal is to interpret decisions of a network in terms of high-level audio objects that are also listenable for the end-user. To this end, we propose a novel interpreter design that incorporates non-negative matrix factorization (NMF). In particular, a carefully regularized interpreter module is trained to take hidden layer representations of the targeted network as input and produce time activations of pre-learnt NMF components as intermediate outputs. Our methodology allows us to generate intuitive audio-based interpretations that explicitly enhance parts of the input signal most relevant for a network's decision. We demonstrate our method's applicability on popular benchmarks, including a real-world multi-label classification task.

</p>
</details>

<details><summary><b>Deepfake Detection for Facial Images with Facemasks</b>
<a href="https://arxiv.org/abs/2202.11359">arxiv:2202.11359</a>
&#x1F4C8; 3 <br>
<p>Donggeun Ko, Sangjun Lee, Jinyong Park, Saebyeol Shin, Donghee Hong, Simon S. Woo</p></summary>
<p>

**Abstract:** Hyper-realistic face image generation and manipulation have givenrise to numerous unethical social issues, e.g., invasion of privacy,threat of security, and malicious political maneuvering, which re-sulted in the development of recent deepfake detection methodswith the rising demands of deepfake forensics. Proposed deepfakedetection methods to date have shown remarkable detection perfor-mance and robustness. However, none of the suggested deepfakedetection methods assessed the performance of deepfakes withthe facemask during the pandemic crisis after the outbreak of theCovid-19. In this paper, we thoroughly evaluate the performance ofstate-of-the-art deepfake detection models on the deepfakes withthe facemask. Also, we propose two approaches to enhance themasked deepfakes detection:face-patchandface-crop. The experi-mental evaluations on both methods are assessed through the base-line deepfake detection models on the various deepfake datasets.Our extensive experiments show that, among the two methods,face-cropperforms better than theface-patch, and could be a trainmethod for deepfake detection models to detect fake faces withfacemask in real world.

</p>
</details>

<details><summary><b>Speech segmentation using multilevel hybrid filters</b>
<a href="https://arxiv.org/abs/2203.01819">arxiv:2203.01819</a>
&#x1F4C8; 2 <br>
<p>Marcos Faundez-Zanuy, Francesc Vallverdu-Bayes</p></summary>
<p>

**Abstract:** A novel approach for speech segmentation is proposed, based on Multilevel Hybrid (mean/min) Filters (MHF) with the following features: An accurate transition location. Good performance in noisy environments (gaussian and impulsive noise). The proposed method is based on spectral changes, with the goal of segmenting the voice into homogeneous acoustic segments. This algorithm is being used for phoneticallysegmented speech coder, with successful results.

</p>
</details>

<details><summary><b>ADPCM with nonlinear prediction</b>
<a href="https://arxiv.org/abs/2203.01818">arxiv:2203.01818</a>
&#x1F4C8; 2 <br>
<p>Marcos Faundez-Zanuy, Oscar Oliva-Suarez</p></summary>
<p>

**Abstract:** Many speech coders are based on linear prediction coding (LPC), nevertheless with LPC is not possible to model the nonlinearities present in the speech signal. Because of this there is a growing interest for nonlinear techniques. In this paper we discuss ADPCM schemes with a nonlinear predictor based on neural nets, which yields an increase of 1-2.5dB in the SEGSNR over classical methods. This paper will discuss the block-adaptive and sample-adaptive predictions.

</p>
</details>

<details><summary><b>Applying multi-angled parallelism to Spanish topographical maps</b>
<a href="https://arxiv.org/abs/2203.01169">arxiv:2203.01169</a>
&#x1F4C8; 2 <br>
<p>Josep-Maria Cusco, Marcos Faundez-Zanuy</p></summary>
<p>

**Abstract:** Multi-Angled Parallelism (MAP) is a method to recognize lines in binary images. It is suitable to be implemented in parallel processing and image processing hardware. The binary image is transformed into directional planes, upon which, directional operators of erosion-dilation are iteratively applyed. From a set of basic operators, more complex ones are created, which let to extract the several types of lines. Each type is extracted with a different set of operations and so the lines are identified when extracted. In this paper, an overview of MAP is made, and it is adapted to line recognition in Spanish topographical maps, with the double purpose of testing the method in a real case and studying the process of adapting it to a custom application.

</p>
</details>

<details><summary><b>Speaker recognition improvement using blind inversion of distortions</b>
<a href="https://arxiv.org/abs/2203.01164">arxiv:2203.01164</a>
&#x1F4C8; 2 <br>
<p>Marcos Faundez-Zanuy, Jordi Sole-Casals</p></summary>
<p>

**Abstract:** In this paper we propose the inversion of nonlinear distortions in order to improve the recognition rates of a speaker recognizer system. We study the effect of saturations on the test signals, trying to take into account real situations where the training material has been recorded in a controlled situation but the testing signals present some mismatch with the input signal level (saturations). The experimental results shows that a combination of data fusion with and without nonlinear distortion compensation can improve the recognition rates with saturated test sentences from 80% to 88.57%, while the results with clean speech (without saturation) is 87.76% for one microphone.

</p>
</details>

<details><summary><b>Semi-Structured Query Grounding for Document-Oriented Databases with Deep Retrieval and Its Application to Receipt and POI Matching</b>
<a href="https://arxiv.org/abs/2202.13959">arxiv:2202.13959</a>
&#x1F4C8; 2 <br>
<p>Geewook Kim, Wonseok Hwang, Minjoon Seo, Seunghyun Park</p></summary>
<p>

**Abstract:** Semi-structured query systems for document-oriented databases have many real applications. One particular application that we are interested in is matching each financial receipt image with its corresponding place of interest (POI, e.g., restaurant) in the nationwide database. The problem is especially challenging in the real production environment where many similar or incomplete entries exist in the database and queries are noisy (e.g., errors in optical character recognition). In this work, we aim to address practical challenges when using embedding-based retrieval for the query grounding problem in semi-structured data. Leveraging recent advancements in deep language encoding for retrieval, we conduct extensive experiments to find the most effective combination of modules for the embedding and retrieval of both query and database entries without any manually engineered component. The proposed model significantly outperforms the conventional manual pattern-based model while requiring much less development and maintenance cost. We also discuss some core observations in our experiments, which could be helpful for practitioners working on a similar problem in other domains.

</p>
</details>

<details><summary><b>Learning the nonlinear dynamics of soft mechanical metamaterials with graph networks</b>
<a href="https://arxiv.org/abs/2202.13775">arxiv:2202.13775</a>
&#x1F4C8; 2 <br>
<p>Tianju Xue, Sigrid Adriaenssens, Sheng Mao</p></summary>
<p>

**Abstract:** The dynamics of soft mechanical metamaterials provides opportunities for many exciting engineering applications. Previous studies often use discrete systems, composed of rigid elements and nonlinear springs, to model the nonlinear dynamic responses of the continuum metamaterials. Yet it remains a challenge to accurately construct such systems based on the geometry of the building blocks of the metamaterial. In this work, we propose a machine learning approach to address this challenge. A metamaterial graph network (MGN) is used to represent the discrete system, where the nodal features contain the positions and orientations the rigid elements, and the edge update functions describe the mechanics of the nonlinear springs. We use Gaussian process regression as the surrogate model to characterize the elastic energy of the nonlinear springs as a function of the relative positions and orientations of the connected rigid elements. The optimal model can be obtained by "learning" from the data generated via finite element calculation over the corresponding building block of the continuum metamaterial. Then, we deploy the optimal model to the network so that the dynamics of the metamaterial at the structural scale can be studied. We verify the accuracy of our machine learning approach against several representative numerical examples. In these examples, the proposed approach can significantly reduce the computational cost when compared to direct numerical simulation while reaching comparable accuracy. Moreover, defects and spatial inhomogeneities can be easily incorporated into our approach, which can be useful for the rational design of soft mechanical metamaterials.

</p>
</details>

<details><summary><b>Clustering Edges in Directed Graphs</b>
<a href="https://arxiv.org/abs/2202.12265">arxiv:2202.12265</a>
&#x1F4C8; 2 <br>
<p>Manohar Murthi, Kamal Premaratne</p></summary>
<p>

**Abstract:** How do vertices exert influence in graph data? We develop a framework for edge clustering, a new method for exploratory data analysis that reveals how both vertices and edges collaboratively accomplish directed influence in graphs, especially for directed graphs. In contrast to the ubiquitous vertex clustering which groups vertices, edge clustering groups edges. Edges sharing a functional affinity are assigned to the same group and form an influence subgraph cluster. With a complexity comparable to that of vertex clustering, this framework presents three different methods for edge spectral clustering that reveal important influence subgraphs in graph data, with each method providing different insight into directed influence processes. We present several diverse examples demonstrating the potential for widespread application of edge clustering in scientific research.

</p>
</details>

<details><summary><b>Using Deep Learning to Detect Digitally Encoded DNA Trigger for Trojan Malware in Bio-Cyber Attacks</b>
<a href="https://arxiv.org/abs/2202.11824">arxiv:2202.11824</a>
&#x1F4C8; 2 <br>
<p>Mohd Siblee Islam, Stepan Ivanov, Hamdan Awan, Jennifer Drohan, Sasitharan Balasubramaniam, Lee Coffey, Srivatsan Kidambi, Witty Sri-saan</p></summary>
<p>

**Abstract:** This article uses Deep Learning technologies to safeguard DNA sequencing against Bio-Cyber attacks. We consider a hybrid attack scenario where the payload is encoded into a DNA sequence to activate a Trojan malware implanted in a software tool used in the sequencing pipeline in order to allow the perpetrators to gain control over the resources used in that pipeline during sequence analysis. The scenario considered in the paper is based on perpetrators submitting synthetically engineered DNA samples that contain digitally encoded IP address and port number of the perpetrators machine in the DNA. Genetic analysis of the samples DNA will decode the address that is used by the software trojan malware to activate and trigger a remote connection. This approach can open up to multiple perpetrators to create connections to hijack the DNA sequencing pipeline. As a way of hiding the data, the perpetrators can avoid detection by encoding the address to maximise similarity with genuine DNAs, which we showed previously. However, in this paper we show how Deep Learning can be used to successfully detect and identify the trigger encoded data, in order to protect a DNA sequencing pipeline from trojan attacks. The result shows nearly up to 100% accuracy in detection in such a novel Trojan attack scenario even after applying fragmentation encryption and steganography on the encoded trigger data. In addition, feasibility of designing and synthesizing encoded DNA for such Trojan payloads is validated by a wet lab experiment.

</p>
</details>

<details><summary><b>Exploiting Correlation to Achieve Faster Learning Rates in Low-Rank Preference Bandits</b>
<a href="https://arxiv.org/abs/2202.11795">arxiv:2202.11795</a>
&#x1F4C8; 2 <br>
<p>Suprovat Ghoshal, Aadirupa Saha</p></summary>
<p>

**Abstract:** We introduce the \emph{Correlated Preference Bandits} problem with random utility-based choice models (RUMs), where the goal is to identify the best item from a given pool of $n$ items through online subsetwise preference feedback. We investigate whether models with a simple correlation structure, e.g. low rank, can result in faster learning rates. While we show that the problem can be impossible to solve for the general `low rank' choice models, faster learning rates can be attained assuming more structured item correlations. In particular, we introduce a new class of \emph{Block-Rank} based RUM model, where the best item is shown to be $(ε,δ)$-PAC learnable with only $O(r ε^{-2} \log(n/δ))$ samples. This improves on the standard sample complexity bound of $\tilde{O}(nε^{-2} \log(1/δ))$ known for the usual learning algorithms which might not exploit the item-correlations ($r \ll n$). We complement the above sample complexity with a matching lower bound (up to logarithmic factors), justifying the tightness of our analysis. Surprisingly, we also show a lower bound of $Ω(nε^{-2}\log(1/δ))$ when the learner is forced to play just duels instead of larger subsetwise queries. Further, we extend the results to a more general `\emph{noisy Block-Rank}' model, which ensures robustness of our techniques. Overall, our results justify the advantage of playing subsetwise queries over pairwise preferences $(k=2)$, we show the latter provably fails to exploit correlation.

</p>
</details>

<details><summary><b>A Class of Geometric Structures in Transfer Learning: Minimax Bounds and Optimality</b>
<a href="https://arxiv.org/abs/2202.11685">arxiv:2202.11685</a>
&#x1F4C8; 2 <br>
<p>Xuhui Zhang, Jose Blanchet, Soumyadip Ghosh, Mark S. Squillante</p></summary>
<p>

**Abstract:** We study the problem of transfer learning, observing that previous efforts to understand its information-theoretic limits do not fully exploit the geometric structure of the source and target domains. In contrast, our study first illustrates the benefits of incorporating a natural geometric structure within a linear regression model, which corresponds to the generalized eigenvalue problem formed by the Gram matrices of both domains. We next establish a finite-sample minimax lower bound, propose a refined model interpolation estimator that enjoys a matching upper bound, and then extend our framework to multiple source domains and generalized linear models. Surprisingly, as long as information is available on the distance between the source and target parameters, negative-transfer does not occur. Simulation studies show that our proposed interpolation estimator outperforms state-of-the-art transfer learning methods in both moderate- and high-dimensional settings.

</p>
</details>

<details><summary><b>Amodal Panoptic Segmentation</b>
<a href="https://arxiv.org/abs/2202.11542">arxiv:2202.11542</a>
&#x1F4C8; 2 <br>
<p>Rohit Mohan, Abhinav Valada</p></summary>
<p>

**Abstract:** Humans have the remarkable ability to perceive objects as a whole, even when parts of them are occluded. This ability of amodal perception forms the basis of our perceptual and cognitive understanding of our world. To enable robots to reason with this capability, we formulate and propose a novel task that we name amodal panoptic segmentation. The goal of this task is to simultaneously predict the pixel-wise semantic segmentation labels of the visible regions of stuff classes and the instance segmentation labels of both the visible and occluded regions of thing classes. To facilitate research on this new task, we extend two established benchmark datasets with pixel-level amodal panoptic segmentation labels that we make publicly available as KITTI-360-APS and BDD100K-APS. We present several strong baselines, along with the amodal panoptic quality (APQ) and amodal parsing coverage (APC) metrics to quantify the performance in an interpretable manner. Furthermore, we propose the novel amodal panoptic segmentation network (APSNet), as a first step towards addressing this task by explicitly modeling the complex relationships between the occluders and occludes. Extensive experimental evaluations demonstrate that APSNet achieves state-of-the-art performance on both benchmarks and more importantly exemplifies the utility of amodal recognition. The benchmarks are available at http://amodal-panoptic.cs.uni-freiburg.de.

</p>
</details>

<details><summary><b>Visual-tactile sensing for Real-time liquid Volume Estimation in Grasping</b>
<a href="https://arxiv.org/abs/2202.11503">arxiv:2202.11503</a>
&#x1F4C8; 2 <br>
<p>Fan Zhu, Ruixing Jia, Lei Yang, Youcan Yan, Zheng Wang, Jia Pan, Wenping Wang</p></summary>
<p>

**Abstract:** We propose a deep visuo-tactile model for realtime estimation of the liquid inside a deformable container in a proprioceptive way.We fuse two sensory modalities, i.e., the raw visual inputs from the RGB camera and the tactile cues from our specific tactile sensor without any extra sensor calibrations.The robotic system is well controlled and adjusted based on the estimation model in real time. The main contributions and novelties of our work are listed as follows: 1) Explore a proprioceptive way for liquid volume estimation by developing an end-to-end predictive model with multi-modal convolutional networks, which achieve a high precision with an error of around 2 ml in the experimental validation. 2) Propose a multi-task learning architecture which comprehensively considers the losses from both classification and regression tasks, and comparatively evaluate the performance of each variant on the collected data and actual robotic platform. 3) Utilize the proprioceptive robotic system to accurately serve and control the requested volume of liquid, which is continuously flowing into a deformable container in real time. 4) Adaptively adjust the grasping plan to achieve more stable grasping and manipulation according to the real-time liquid volume prediction.

</p>
</details>

<details><summary><b>MITI: SLAM Benchmark for Laparoscopic Surgery</b>
<a href="https://arxiv.org/abs/2202.11496">arxiv:2202.11496</a>
&#x1F4C8; 2 <br>
<p>Regine Hartwig, Daniel Ostler, Jean-Claude Rosenthal, Hubertus Feußner, Dirk Wilhelm, Dirk Wollherr</p></summary>
<p>

**Abstract:** We propose a new benchmark for evaluating stereoscopic visual-inertial computer vision algorithms (SLAM/ SfM/ 3D Reconstruction/ Visual-Inertial Odometry) for minimally invasive surgical (MIS) interventions in the abdomen. Our MITI Dataset available at [https://mediatum.ub.tum.de/1621941] provides all the necessary data by a complete recording of a handheld surgical intervention at Research Hospital Rechts der Isar of TUM. It contains multimodal sensor information from IMU, stereoscopic video, and infrared (IR) tracking as ground truth for evaluation. Furthermore, calibration for the stereoscope, accelerometer, magnetometer, the rigid transformations in the sensor setup, and time-offsets are available. We wisely chose a suitable intervention that contains very few cutting and tissue deformation and shows a full scan of the abdomen with a handheld camera such that it is ideal for testing SLAM algorithms. Intending to promote the progress of visual-inertial algorithms designed for MIS application, we hope that our clinical training dataset helps and enables researchers to enhance algorithms.

</p>
</details>

<details><summary><b>Privacy issues on biometric systems</b>
<a href="https://arxiv.org/abs/2202.11415">arxiv:2202.11415</a>
&#x1F4C8; 2 <br>
<p>Marcos Faundez-Zanuy</p></summary>
<p>

**Abstract:** In the XXIth century there is a strong interest on privacy issues. Technology permits obtaining personal information without individuals consent, computers make it feasible to share and process this information, and this can bring about damaging implications. In some sense, biometric information is personal information, so it is important to be conscious about what is true and what is false when some people claim that biometrics is an attempt to individuals privacy. In this paper, key points related to this matter are dealt with.

</p>
</details>

<details><summary><b>Mixed-Block Neural Architecture Search for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2202.11401">arxiv:2202.11401</a>
&#x1F4C8; 2 <br>
<p>Martijn M. A. Bosma, Arkadiy Dushatskiy, Monika Grewal, Tanja Alderliesten, Peter A. N. Bosman</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) have the potential for making various clinical procedures more time-efficient by automating medical image segmentation. Due to their strong, in some cases human-level, performance, they have become the standard approach in this field. The design of the best possible medical image segmentation DNNs, however, is task-specific. Neural Architecture Search (NAS), i.e., the automation of neural network design, has been shown to have the capability to outperform manually designed networks for various tasks. However, the existing NAS methods for medical image segmentation have explored a quite limited range of types of DNN architectures that can be discovered. In this work, we propose a novel NAS search space for medical image segmentation networks. This search space combines the strength of a generalised encoder-decoder structure, well known from U-Net, with network blocks that have proven to have a strong performance in image classification tasks. The search is performed by looking for the best topology of multiple cells simultaneously with the configuration of each cell within, allowing for interactions between topology and cell-level attributes. From experiments on two publicly available datasets, we find that the networks discovered by our proposed NAS method have better performance than well-known handcrafted segmentation networks, and outperform networks found with other NAS approaches that perform only topology search, and topology-level search followed by cell-level search.

</p>
</details>

<details><summary><b>Fast Sparse Classification for Generalized Linear and Additive Models</b>
<a href="https://arxiv.org/abs/2202.11389">arxiv:2202.11389</a>
&#x1F4C8; 2 <br>
<p>Jiachang Liu, Chudi Zhong, Margo Seltzer, Cynthia Rudin</p></summary>
<p>

**Abstract:** We present fast classification techniques for sparse generalized linear and additive models. These techniques can handle thousands of features and thousands of observations in minutes, even in the presence of many highly correlated features. For fast sparse logistic regression, our computational speed-up over other best-subset search techniques owes to linear and quadratic surrogate cuts for the logistic loss that allow us to efficiently screen features for elimination, as well as use of a priority queue that favors a more uniform exploration of features. As an alternative to the logistic loss, we propose the exponential loss, which permits an analytical solution to the line search at each iteration. Our algorithms are generally 2 to 5 times faster than previous approaches. They produce interpretable models that have accuracy comparable to black box models on challenging datasets.

</p>
</details>

<details><summary><b>Preformer: Predictive Transformer with Multi-Scale Segment-wise Correlations for Long-Term Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2202.11356">arxiv:2202.11356</a>
&#x1F4C8; 2 <br>
<p>Dazhao Du, Bing Su, Zhewei Wei</p></summary>
<p>

**Abstract:** Transformer-based methods have shown great potential in long-term time series forecasting. However, most of these methods adopt the standard point-wise self-attention mechanism, which not only becomes intractable for long-term forecasting since its complexity increases quadratically with the length of time series, but also cannot explicitly capture the predictive dependencies from contexts since the corresponding key and value are transformed from the same point. This paper proposes a predictive Transformer-based model called {\em Preformer}. Preformer introduces a novel efficient {\em Multi-Scale Segment-Correlation} mechanism that divides time series into segments and utilizes segment-wise correlation-based attention for encoding time series. A multi-scale structure is developed to aggregate dependencies at different temporal scales and facilitate the selection of segment length. Preformer further designs a predictive paradigm for decoding, where the key and value come from two successive segments rather than the same segment. In this way, if a key segment has a high correlation score with the query segment, its successive segment contributes more to the prediction of the query segment. Extensive experiments demonstrate that our Preformer outperforms other Transformer-based methods.

</p>
</details>

<details><summary><b>Prompt-Learning for Short Text Classification</b>
<a href="https://arxiv.org/abs/2202.11345">arxiv:2202.11345</a>
&#x1F4C8; 2 <br>
<p>Yi Zhu, Xinke Zhou, Jipeng Qiang, Yun Li, Yunhao Yuan, Xindong Wu</p></summary>
<p>

**Abstract:** In the short text, the extreme short length, feature sparsity and high ambiguity pose huge challenge to classification tasks. Recently, as an effective method for tuning Pre-trained Language Models for specific downstream tasks, prompt-learning has attracted vast amount of attention and research. The main intuition behind the prompt-learning is to insert template into the input and convert the text classification tasks into equivalent cloze-style tasks. However, most prompt-learning methods expand label words manually or only consider the class name for knowledge incorporating in cloze-style prediction, which will inevitably incurred omissions and bias in classification tasks. In this paper, we propose a simple short text classification approach that makes use of prompt-learning based on knowledgeable expansion, which can consider both the short text itself and class name during expanding label words space. Specifically, the top $N$ concepts related to the entity in short text are retrieved from the open Knowledge Graph like Probase, and we further refine the expanded label words by the distance calculation between selected concepts and class label. Experimental results show that our approach obtains obvious improvement compared with other fine-tuning, prompt-learning and knowledgeable prompt-tuning methods, outperforming the state-of-the-art by up to 6 Accuracy points on three well-known datasets.

</p>
</details>

<details><summary><b>Constant matters: Fine-grained Complexity of Differentially Private Continual Observation Using Completely Bounded Norms</b>
<a href="https://arxiv.org/abs/2202.11205">arxiv:2202.11205</a>
&#x1F4C8; 2 <br>
<p>Monika Henzinger, Jalaj Upadhyay</p></summary>
<p>

**Abstract:** We study fine-grained error bounds for differentially private algorithms for averaging and counting in the continual observation model. For this, we use the completely bounded spectral norm (cb norm) from operator algebra. For a matrix $W$, its cb norm is defined as
  \[
  \|{W}\|_{\mathsf{cb}} = \max_{Q} \left\{ \frac{\|{Q \bullet W}\|}{\|{Q}\|} \right\},
  \]
  where $Q \bullet W$ denotes the Schur product and $\|{\cdot}\|$ denotes the spectral norm. We bound the cb norm of two fundamental matrices studied in differential privacy under the continual observation model: the counting matrix $M_{\mathsf{counting}}$ and the averaging matrix $M_{\mathsf{average}}$. For $M_{\mathsf{counting}}$, we give lower and upper bound whose additive gap is $1 + \frac{1}π$. Our factorization also has two desirable properties sufficient for streaming setting: the factorization contains of lower-triangular matrices and the number of distinct entries in the factorization is exactly $T$. This allows us to compute the factorization on the fly while requiring the curator to store a $T$-dimensional vector. For $M_{\mathsf{average}}$, we show an additive gap between the lower and upper bound of $\approx 0.64$.

</p>
</details>

<details><summary><b>Simulating Network Paths with Recurrent Buffering Units</b>
<a href="https://arxiv.org/abs/2202.13870">arxiv:2202.13870</a>
&#x1F4C8; 1 <br>
<p>Divyam Anshumaan, Sriram Balasubramanian, Shubham Tiwari, Nagarajan Natarajan, Sundararajan Sellamanickam, Venkata N. Padmanabhan</p></summary>
<p>

**Abstract:** Simulating physical network paths (e.g., Internet) is a cornerstone research problem in the emerging sub-field of AI-for-networking. We seek a model that generates end-to-end packet delay values in response to the time-varying load offered by a sender, which is typically a function of the previously output delays. We formulate an ML problem at the intersection of dynamical systems, sequential decision making, and time-series generative modeling. We propose a novel grey-box approach to network simulation that embeds the semantics of physical network path in a new RNN-style architecture called Recurrent Buffering Unit, providing the interpretability of standard network simulator tools, the power of neural models, the efficiency of SGD-based techniques for learning, and yielding promising results on synthetic and real-world network traces.

</p>
</details>

<details><summary><b>Attainability and Optimality: The Equalized Odds Fairness Revisited</b>
<a href="https://arxiv.org/abs/2202.11853">arxiv:2202.11853</a>
&#x1F4C8; 1 <br>
<p>Zeyu Tang, Kun Zhang</p></summary>
<p>

**Abstract:** Fairness of machine learning algorithms has been of increasing interest. In order to suppress or eliminate discrimination in prediction, various notions as well as approaches have been proposed to impose fairness. Given a notion of fairness, an essential problem is then whether or not it can always be attained, even if with an unlimited amount of data. This issue is, however, not well addressed yet. In this paper, focusing on the Equalized Odds notion of fairness, we consider the attainability of this criterion and, furthermore, if it is attainable, the optimality of the prediction performance under various settings. In particular, for prediction performed by a deterministic function of input features, we give conditions under which Equalized Odds can hold true; if the stochastic prediction is acceptable, we show that under mild assumptions, fair predictors can always be derived. For classification, we further prove that compared to enforcing fairness by post-processing, one can always benefit from exploiting all available features during training and get potentially better prediction performance while remaining fair. Moreover, while stochastic prediction can attain Equalized Odds with theoretical guarantees, we also discuss its limitation and potential negative social impacts.

</p>
</details>

<details><summary><b>Comparative analysis of machine learning methods for active flow control</b>
<a href="https://arxiv.org/abs/2202.11664">arxiv:2202.11664</a>
&#x1F4C8; 1 <br>
<p>Fabio Pino, Lorenzo Schena, Jean Rabault, Alexander Kuhnle, Miguel A. Mendez</p></summary>
<p>

**Abstract:** Machine learning frameworks such as Genetic Programming (GP) and Reinforcement Learning (RL) are gaining popularity in flow control. This work presents a comparative analysis of the two, bench-marking some of their most representative algorithms against global optimization techniques such as Bayesian Optimization (BO) and Lipschitz global optimization (LIPO). First, we review the general framework of the flow control problem, linking optimal control theory with model-free machine learning methods. Then, we test the control algorithms on three test cases. These are (1) the stabilization of a nonlinear dynamical system featuring frequency cross-talk, (2) the wave cancellation from a Burgers' flow and (3) the drag reduction in a cylinder wake flow. Although the control of these problems has been tackled in the recent literature with one method or the other, we present a comprehensive comparison to illustrate their differences in exploration versus exploitation and their balance between `model capacity' in the control law definition versus `required complexity'. We believe that such a comparison opens the path towards hybridization of the various methods, and we offer some perspective on their future development in the literature of flow control problems.

</p>
</details>

<details><summary><b>Cyclical Variational Bayes Monte Carlo for Efficient Multi-Modal Posterior Distributions Evaluation</b>
<a href="https://arxiv.org/abs/2202.11645">arxiv:2202.11645</a>
&#x1F4C8; 1 <br>
<p>Felipe Igea, Alice Cicirello</p></summary>
<p>

**Abstract:** Statistical model updating is frequently used in engineering to calculate the uncertainty of some unknown latent parameters when a set of measurements on observable quantities is given. Variational inference is an alternative approach to sampling methods that has been developed by the machine learning community to estimate posterior approximations through an optimization approach. In this paper, the Variational Bayesian Monte Carlo (VBMC) method is investigated with the purpose of dealing with statistical model updating problems in engineering involving expensive-to-run models. This method combines the active-sampling Bayesian quadrature with a Gaussian-process based variational inference to yield a non-parametric estimation of the posterior distribution of the identified parameters involving few runs of the expensive-to-run model. VBMC can also be used for model selection as it produces an estimation of the model's evidence lower bound. In this paper, a variant of the VBMC algorithm is developed through the introduction of a cyclical annealing schedule into the algorithm. The proposed cyclical VBMC algorithm allows to deal effectively with multi-modal posteriors by having multiple cycles of exploration and exploitation phases. Four numerical examples are used to compare the standard VBMC algorithm, the monotonic VBMC, the cyclical VBMC and the Transitional Ensemble Markov Chain Monte Carlo (TEMCMC). Overall, it is found that the proposed cyclical VBMC approach yields accurate results with a very reduced number of model runs compared to the state of the art sampling technique TEMCMC. In the presence of potential multi-modal problems, the proposed cyclical VBMC algorithm outperforms all the other approaches in terms of accuracy of the resulting posterior.

</p>
</details>

<details><summary><b>A Dimensionality Reduction Method for Finding Least Favorable Priors with a Focus on Bregman Divergence</b>
<a href="https://arxiv.org/abs/2202.11598">arxiv:2202.11598</a>
&#x1F4C8; 1 <br>
<p>Alex Dytso, Mario Goldenbaum, H. Vincent Poor, Shlomo Shamai</p></summary>
<p>

**Abstract:** A common way of characterizing minimax estimators in point estimation is by moving the problem into the Bayesian estimation domain and finding a least favorable prior distribution. The Bayesian estimator induced by a least favorable prior, under mild conditions, is then known to be minimax. However, finding least favorable distributions can be challenging due to inherent optimization over the space of probability distributions, which is infinite-dimensional. This paper develops a dimensionality reduction method that allows us to move the optimization to a finite-dimensional setting with an explicit bound on the dimension. The benefit of this dimensionality reduction is that it permits the use of popular algorithms such as projected gradient ascent to find least favorable priors. Throughout the paper, in order to make progress on the problem, we restrict ourselves to Bayesian risks induced by a relatively large class of loss functions, namely Bregman divergences.

</p>
</details>

<details><summary><b>Shisha: Online scheduling of CNN pipelines on heterogeneous architectures</b>
<a href="https://arxiv.org/abs/2202.11575">arxiv:2202.11575</a>
&#x1F4C8; 1 <br>
<p>Pirah Noor Soomro, Mustafa Abduljabbar, Jeronimo Castrillon, Miquel Pericàs</p></summary>
<p>

**Abstract:** Chiplets have become a common methodology in modern chip design. Chiplets improve yield and enable heterogeneity at the level of cores, memory subsystem and the interconnect. Convolutional Neural Networks (CNNs) have high computational, bandwidth and memory capacity requirements owing to the increasingly large amount of weights. Thus to exploit chiplet-based architectures, CNNs must be optimized in terms of scheduling and workload distribution among computing resources. We propose Shisha, an online approach to generate and schedule parallel CNN pipelines on chiplet architectures. Shisha targets heterogeneity in compute performance and memory bandwidth and tunes the pipeline schedule through a fast online exploration technique. We compare Shisha with Simulated Annealing, Hill Climbing and Pipe-Search. On average, the convergence time is improved by ~35x in Shisha compared to other exploration algorithms. Despite the quick exploration, Shisha's solution is often better than that of other heuristic exploration algorithms.

</p>
</details>

<details><summary><b>Robust Geometric Metric Learning</b>
<a href="https://arxiv.org/abs/2202.11550">arxiv:2202.11550</a>
&#x1F4C8; 1 <br>
<p>Antoine Collas, Arnaud Breloy, Guillaume Ginolhac, Chengfang Ren, Jean-Philippe Ovarlez</p></summary>
<p>

**Abstract:** This paper proposes new algorithms for the metric learning problem. We start by noticing that several classical metric learning formulations from the literature can be viewed as modified covariance matrix estimation problems. Leveraging this point of view, a general approach, called Robust Geometric Metric Learning (RGML), is then studied. This method aims at simultaneously estimating the covariance matrix of each class while shrinking them towards their (unknown) barycenter. We focus on two specific costs functions: one associated with the Gaussian likelihood (RGML Gaussian), and one with Tyler's M -estimator (RGML Tyler). In both, the barycenter is defined with the Riemannian distance, which enjoys nice properties of geodesic convexity and affine invariance. The optimization is performed using the Riemannian geometry of symmetric positive definite matrices and its submanifold of unit determinant. Finally, the performance of RGML is asserted on real datasets. Strong performance is exhibited while being robust to mislabeled data.

</p>
</details>

<details><summary><b>Using Deep Reinforcement Learning with Automatic Curriculum earning for Mapless Navigation in Intralogistics</b>
<a href="https://arxiv.org/abs/2202.11512">arxiv:2202.11512</a>
&#x1F4C8; 1 <br>
<p>Honghu Xue, Benedikt Hein, Mohamed Bakr, Georg Schildbach, Bengt Abel, Elmar Rueckert</p></summary>
<p>

**Abstract:** We propose a deep reinforcement learning approach for solving a mapless navigation problem in warehouse scenarios. The automatic guided vehicle is equipped with LiDAR and frontal RGB sensors and learns to reach underneath the target dolly. The challenges reside in the sparseness of positive samples for learning, multi-modal sensor perception with partial observability, the demand for accurate steering maneuvers together with long training cycles. To address these points, we proposed NavACL-Q as an automatic curriculum learning together with distributed soft actor-critic. The performance of the learning algorithm is evaluated exhaustively in a different warehouse environment to check both robustness and generalizability of the learned policy. Results in NVIDIA Isaac Sim demonstrates that our trained agent significantly outperforms the map-based navigation pipeline provided by NVIDIA Isaac Sim in terms of higher agent-goal distances and relative orientations. The ablation studies also confirmed that NavACL-Q greatly facilitates the whole learning process and a pre-trained feature extractor manifestly boosts the training speed.

</p>
</details>

<details><summary><b>Fairness-Aware Naive Bayes Classifier for Data with Multiple Sensitive Features</b>
<a href="https://arxiv.org/abs/2202.11499">arxiv:2202.11499</a>
&#x1F4C8; 1 <br>
<p>Stelios Boulitsakis-Logothetis</p></summary>
<p>

**Abstract:** Fairness-aware machine learning seeks to maximise utility in generating predictions while avoiding unfair discrimination based on sensitive attributes such as race, sex, religion, etc. An important line of work in this field is enforcing fairness during the training step of a classifier. A simple yet effective binary classification algorithm that follows this strategy is two-naive-Bayes (2NB), which enforces statistical parity - requiring that the groups comprising the dataset receive positive labels with the same likelihood. In this paper, we generalise this algorithm into N-naive-Bayes (NNB) to eliminate the simplification of assuming only two sensitive groups in the data and instead apply it to an arbitrary number of groups.
  We propose an extension of the original algorithm's statistical parity constraint and the post-processing routine that enforces statistical independence of the label and the single sensitive attribute. Then, we investigate its application on data with multiple sensitive features and propose a new constraint and post-processing routine to enforce differential fairness, an extension of established group-fairness constraints focused on intersectionalities. We empirically demonstrate the effectiveness of the NNB algorithm on US Census datasets and compare its accuracy and debiasing performance, as measured by disparate impact and DF-$ε$ score, with similar group-fairness algorithms. Finally, we lay out important considerations users should be aware of before incorporating this algorithm into their application, and direct them to further reading on the pros, cons, and ethical implications of using statistical parity as a fairness criterion.

</p>
</details>

<details><summary><b>Networked Online Learning for Control of Safety-Critical Resource-Constrained Systems based on Gaussian Processes</b>
<a href="https://arxiv.org/abs/2202.11491">arxiv:2202.11491</a>
&#x1F4C8; 1 <br>
<p>Armin Lederer, Mingmin Zhang, Samuel Tesfazgi, Sandra Hirche</p></summary>
<p>

**Abstract:** Safety-critical technical systems operating in unknown environments require the ability to quickly adapt their behavior, which can be achieved in control by inferring a model online from the data stream generated during operation. Gaussian process-based learning is particularly well suited for safety-critical applications as it ensures bounded prediction errors. While there exist computationally efficient approximations for online inference, these approaches lack guarantees for the prediction error and have high memory requirements, and are therefore not applicable to safety-critical systems with tight memory constraints. In this work, we propose a novel networked online learning approach based on Gaussian process regression, which addresses the issue of limited local resources by employing remote data management in the cloud. Our approach formally guarantees a bounded tracking error with high probability, which is exploited to identify the most relevant data to achieve a certain control performance. We further propose an effective data transmission scheme between the local system and the cloud taking bandwidth limitations and time delay of the transmission channel into account. The effectiveness of the proposed method is successfully demonstrated in a simulation.

</p>
</details>

<details><summary><b>Residual Bootstrap Exploration for Stochastic Linear Bandit</b>
<a href="https://arxiv.org/abs/2202.11474">arxiv:2202.11474</a>
&#x1F4C8; 1 <br>
<p>Shuang Wu, Chi-Hua Wang, Yuantong Li, Guang Cheng</p></summary>
<p>

**Abstract:** We propose a new bootstrap-based online algorithm for stochastic linear bandit problems. The key idea is to adopt residual bootstrap exploration, in which the agent estimates the next step reward by re-sampling the residuals of mean reward estimate. Our algorithm, residual bootstrap exploration for stochastic linear bandit (\texttt{LinReBoot}), estimates the linear reward from its re-sampling distribution and pulls the arm with the highest reward estimate. In particular, we contribute a theoretical framework to demystify residual bootstrap-based exploration mechanisms in stochastic linear bandit problems. The key insight is that the strength of bootstrap exploration is based on collaborated optimism between the online-learned model and the re-sampling distribution of residuals. Such observation enables us to show that the proposed \texttt{LinReBoot} secure a high-probability $\tilde{O}(d \sqrt{n})$ sub-linear regret under mild conditions. Our experiments support the easy generalizability of the \texttt{ReBoot} principle in the various formulations of linear bandit problems and show the significant computational efficiency of \texttt{LinReBoot}.

</p>
</details>

<details><summary><b>Exponential Tail Local Rademacher Complexity Risk Bounds Without the Bernstein Condition</b>
<a href="https://arxiv.org/abs/2202.11461">arxiv:2202.11461</a>
&#x1F4C8; 1 <br>
<p>Varun Kanade, Patrick Rebeschini, Tomas Vaskevicius</p></summary>
<p>

**Abstract:** The local Rademacher complexity framework is one of the most successful general-purpose toolboxes for establishing sharp excess risk bounds for statistical estimators based on the framework of empirical risk minimization. Applying this toolbox typically requires using the Bernstein condition, which often restricts applicability to convex and proper settings. Recent years have witnessed several examples of problems where optimal statistical performance is only achievable via non-convex and improper estimators originating from aggregation theory, including the fundamental problem of model selection. These examples are currently outside of the reach of the classical localization theory.
  In this work, we build upon the recent approach to localization via offset Rademacher complexities, for which a general high-probability theory has yet to be established. Our main result is an exponential-tail excess risk bound expressed in terms of the offset Rademacher complexity that yields results at least as sharp as those obtainable via the classical theory. However, our bound applies under an estimator-dependent geometric condition (the "offset condition") instead of the estimator-independent (but, in general, distribution-dependent) Bernstein condition on which the classical theory relies. Our results apply to improper prediction regimes not directly covered by the classical theory.

</p>
</details>

<details><summary><b>Reconstruction of observed mechanical motions with Artificial Intelligence tools</b>
<a href="https://arxiv.org/abs/2202.11447">arxiv:2202.11447</a>
&#x1F4C8; 1 <br>
<p>Antal Jakovac, Marcell T. Kurbucz, Peter Posfay</p></summary>
<p>

**Abstract:** The goal of this paper is to determine the laws of observed trajectories assuming that there is a mechanical system in the background and using these laws to continue the observed motion in a plausible way. The laws are represented by neural networks with a limited number of parameters. The training of the networks follows the Extreme Learning Machine idea. We determine laws for different levels of embedding, thus we can represent not only the equation of motion but also the symmetries of different kinds. In the recursive numerical evolution of the system, we require the fulfillment of all the observed laws, within the determined numerical precision. In this way, we can successfully reconstruct both integrable and chaotic motions, as we demonstrate in the example of the gravity pendulum and the double pendulum.

</p>
</details>

<details><summary><b>Extension of Dynamic Mode Decomposition for dynamic systems with incomplete information based on t-model of optimal prediction</b>
<a href="https://arxiv.org/abs/2202.11432">arxiv:2202.11432</a>
&#x1F4C8; 1 <br>
<p>Aleksandr Katrutsa, Sergey Utyuzhnikov, Ivan Oseledets</p></summary>
<p>

**Abstract:** The Dynamic Mode Decomposition has proved to be a very efficient technique to study dynamic data. This is entirely a data-driven approach that extracts all necessary information from data snapshots which are commonly supposed to be sampled from measurement. The application of this approach becomes problematic if the available data is incomplete because some dimensions of smaller scale either missing or unmeasured. Such setting occurs very often in modeling complex dynamical systems such as power grids, in particular with reduced-order modeling. To take into account the effect of unresolved variables the optimal prediction approach based on the Mori-Zwanzig formalism can be applied to obtain the most expected prediction under existing uncertainties. This effectively leads to the development of a time-predictive model accounting for the impact of missing data. In the present paper we provide a detailed derivation of the considered method from the Liouville equation and finalize it with the optimization problem that defines the optimal transition operator corresponding to the observed data. In contrast to the existing approach, we consider a first-order approximation of the Mori-Zwanzig decomposition, state the corresponding optimization problem and solve it with the gradient-based optimization method. The gradient of the obtained objective function is computed precisely through the automatic differentiation technique. The numerical experiments illustrate that the considered approach gives practically the same dynamics as the exact Mori-Zwanzig decomposition, but is less computationally intensive.

</p>
</details>

<details><summary><b>Differential privacy for symmetric log-concave mechanisms</b>
<a href="https://arxiv.org/abs/2202.11393">arxiv:2202.11393</a>
&#x1F4C8; 1 <br>
<p>Staal A. Vinterbo</p></summary>
<p>

**Abstract:** Adding random noise to database query results is an important tool for achieving privacy. A challenge is to minimize this noise while still meeting privacy requirements. Recently, a sufficient and necessary condition for $(ε, δ)$-differential privacy for Gaussian noise was published. This condition allows the computation of the minimum privacy-preserving scale for this distribution. We extend this work and provide a sufficient and necessary condition for $(ε, δ)$-differential privacy for all symmetric and log-concave noise densities. Our results allow fine-grained tailoring of the noise distribution to the dimensionality of the query result. We demonstrate that this can yield significantly lower mean squared errors than those incurred by the currently used Laplace and Gaussian mechanisms for the same $ε$ and $δ$.

</p>
</details>

<details><summary><b>Cooperative Behavioral Planning for Automated Driving using Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2202.11376">arxiv:2202.11376</a>
&#x1F4C8; 1 <br>
<p>Marvin Klimke, Benjamin Völz, Michael Buchholz</p></summary>
<p>

**Abstract:** Urban intersections are prone to delays and inefficiencies due to static precedence rules and occlusions limiting the view on prioritized traffic. Existing approaches to improve traffic flow, widely known as automatic intersection management systems, are mostly based on non-learning reservation schemes or optimization algorithms. Machine learning-based techniques show promising results in planning for a single ego vehicle. This work proposes to leverage machine learning algorithms to optimize traffic flow at urban intersections by jointly planning for multiple vehicles. Learning-based behavior planning poses several challenges, demanding for a suited input and output representation as well as large amounts of ground-truth data. We address the former issue by using a flexible graph-based input representation accompanied by a graph neural network. This allows to efficiently encode the scene and inherently provide individual outputs for all involved vehicles. To learn a sensible policy, without relying on the imitation of expert demonstrations, the cooperative planning task is phrased as a reinforcement learning problem. We train and evaluate the proposed method in an open-source simulation environment for decision making in automated driving. Compared to a first-in-first-out scheme and traffic governed by static priority rules, the learned planner shows a significant gain in flow rate, while reducing the number of induced stops. In addition to synthetic simulations, the approach is also evaluated based on real-world traffic data taken from the publicly available inD dataset.

</p>
</details>

<details><summary><b>Energy-efficient Training of Distributed DNNs in the Mobile-edge-cloud Continuum</b>
<a href="https://arxiv.org/abs/2202.11349">arxiv:2202.11349</a>
&#x1F4C8; 1 <br>
<p>Francesco Malandrino, Carla Fabiana Chiasserini, Giuseppe Di Giacomo</p></summary>
<p>

**Abstract:** We address distributed machine learning in multi-tier (e.g., mobile-edge-cloud) networks where a heterogeneous set of nodes cooperate to perform a learning task. Due to the presence of multiple data sources and computation-capable nodes, a learning controller (e.g., located in the edge) has to make decisions about (i) which distributed ML model structure to select, (ii) which data should be used for the ML model training, and (iii) which resources should be allocated to it. Since these decisions deeply influence one another, they should be made jointly. In this paper, we envision a new approach to distributed learning in multi-tier networks, which aims at maximizing ML efficiency. To this end, we propose a solution concept, called RightTrain, that achieves energy-efficient ML model training, while fulfilling learning time and quality requirements. RightTrain makes high-quality decisions in polynomial time. Further, our performance evaluation shows that RightTrain closely matches the optimum and outperforms the state of the art by over 50%.

</p>
</details>

<details><summary><b>Reinforcement Learning from Demonstrations by Novel Interactive Expert and Application to Automatic Berthing Control Systems for Unmanned Surface Vessel</b>
<a href="https://arxiv.org/abs/2202.11325">arxiv:2202.11325</a>
&#x1F4C8; 1 <br>
<p>Haoran Zhang, Chenkun Yin, Yanxin Zhang, Shangtai Jin, Zhenxuan Li</p></summary>
<p>

**Abstract:** In this paper, two novel practical methods of Reinforcement Learning from Demonstration (RLfD) are developed and applied to automatic berthing control systems for Unmanned Surface Vessel. A new expert data generation method, called Model Predictive Based Expert (MPBE) which combines Model Predictive Control and Deep Deterministic Policy Gradient, is developed to provide high quality supervision data for RLfD algorithms. A straightforward RLfD method, model predictive Deep Deterministic Policy Gradient (MP-DDPG), is firstly introduced by replacing the RL agent with MPBE to directly interact with the environment. Then distribution mismatch problem is analyzed for MP-DDPG, and two techniques that alleviate distribution mismatch are proposed. Furthermore, another novel RLfD algorithm based on the MP-DDPG, called Self-Guided Actor-Critic (SGAC) is present, which can effectively leverage MPBE by continuously querying it to generate high quality expert data online. The distribution mismatch problem leading to unstable learning process is addressed by SGAC in a DAgger manner. In addition, theoretical analysis is given to prove that SGAC algorithm can converge with guaranteed monotonic improvement. Simulation results verify the effectiveness of MP-DDPG and SGAC to accomplish the ship berthing control task, and show advantages of SGAC comparing with other typical reinforcement learning algorithms and MP-DDPG.

</p>
</details>

<details><summary><b>Efficient CDF Approximations for Normalizing Flows</b>
<a href="https://arxiv.org/abs/2202.11322">arxiv:2202.11322</a>
&#x1F4C8; 1 <br>
<p>Chandramouli Shama Sastry, Andreas Lehrmann, Marcus Brubaker, Alexander Radovic</p></summary>
<p>

**Abstract:** Normalizing flows model a complex target distribution in terms of a bijective transform operating on a simple base distribution. As such, they enable tractable computation of a number of important statistical quantities, particularly likelihoods and samples. Despite these appealing properties, the computation of more complex inference tasks, such as the cumulative distribution function (CDF) over a complex region (e.g., a polytope) remains challenging. Traditional CDF approximations using Monte-Carlo techniques are unbiased but have unbounded variance and low sample efficiency. Instead, we build upon the diffeomorphic properties of normalizing flows and leverage the divergence theorem to estimate the CDF over a closed region in target space in terms of the flux across its \emph{boundary}, as induced by the normalizing flow. We describe both deterministic and stochastic instances of this estimator: while the deterministic variant iteratively improves the estimate by strategically subdividing the boundary, the stochastic variant provides unbiased estimates. Our experiments on popular flow architectures and UCI benchmark datasets show a marked improvement in sample efficiency as compared to traditional estimators.

</p>
</details>

<details><summary><b>Multivariate Quantile Function Forecaster</b>
<a href="https://arxiv.org/abs/2202.11316">arxiv:2202.11316</a>
&#x1F4C8; 1 <br>
<p>Kelvin Kan, François-Xavier Aubet, Tim Januschowski, Youngsuk Park, Konstantinos Benidis, Lars Ruthotto, Jan Gasthaus</p></summary>
<p>

**Abstract:** We propose Multivariate Quantile Function Forecaster (MQF$^2$), a global probabilistic forecasting method constructed using a multivariate quantile function and investigate its application to multi-horizon forecasting. Prior approaches are either autoregressive, implicitly capturing the dependency structure across time but exhibiting error accumulation with increasing forecast horizons, or multi-horizon sequence-to-sequence models, which do not exhibit error accumulation, but also do typically not model the dependency structure across time steps. MQF$^2$ combines the benefits of both approaches, by directly making predictions in the form of a multivariate quantile function, defined as the gradient of a convex function which we parametrize using input-convex neural networks. By design, the quantile function is monotone with respect to the input quantile levels and hence avoids quantile crossing. We provide two options to train MQF$^2$: with energy score or with maximum likelihood. Experimental results on real-world and synthetic datasets show that our model has comparable performance with state-of-the-art methods in terms of single time step metrics while capturing the time dependency structure.

</p>
</details>

<details><summary><b>A Complete Criterion for Value of Information in Soluble Influence Diagrams</b>
<a href="https://arxiv.org/abs/2202.11629">arxiv:2202.11629</a>
&#x1F4C8; 0 <br>
<p>Chris van Merwijk, Ryan Carey, Tom Everitt</p></summary>
<p>

**Abstract:** Influence diagrams have recently been used to analyse the safety and fairness properties of AI systems. A key building block for this analysis is a graphical criterion for value of information (VoI). This paper establishes the first complete graphical criterion for VoI in influence diagrams with multiple decisions. Along the way, we establish two important techniques for proving properties of multi-decision influence diagrams: ID homomorphisms are structure-preserving transformations of influence diagrams, while a Tree of Systems is collection of paths that captures how information and control can flow in an influence diagram.

</p>
</details>

<details><summary><b>DL-SLOT: Dynamic Lidar SLAM and Object Tracking Based On Graph Optimization</b>
<a href="https://arxiv.org/abs/2202.11431">arxiv:2202.11431</a>
&#x1F4C8; 0 <br>
<p>Xuebo Tian, Junqiao Zhao, Chen Ye</p></summary>
<p>

**Abstract:** Ego-pose estimation and dynamic object tracking are two key issues in an autonomous driving system. Two assumptions are often made for them, i.e. the static world assumption of simultaneous localization and mapping (SLAM) and the exact ego-pose assumption of object tracking, respectively. However, these assumptions are difficult to hold in highly dynamic road scenarios where SLAM and object tracking become correlated and mutually beneficial. In this paper, DL-SLOT, a dynamic Lidar SLAM and object tracking method is proposed. This method integrates the state estimations of both the ego vehicle and the static and dynamic objects in the environment into a unified optimization framework, to realize SLAM and object tracking (SLOT) simultaneously. Firstly, we implement object detection to remove all the points that belong to potential dynamic objects. Then, LiDAR odometry is conducted using the filtered point cloud. At the same time, detected objects are associated with the history object trajectories based on the time-series information in a sliding window. The states of the static and dynamic objects and ego vehicle in the sliding window are integrated into a unified local optimization framework. We perform SLAM and object tracking simultaneously in this framework, which significantly improves the robustness and accuracy of SLAM in highly dynamic road scenarios and the accuracy of objects' states estimation. Experiments on public datasets have shown that our method achieves better accuracy than A-LOAM.

</p>
</details>


{% endraw %}
Prev: [2022.02.22]({{ '/2022/02/22/2022.02.22.html' | relative_url }})  Next: [2022.02.24]({{ '/2022/02/24/2022.02.24.html' | relative_url }})