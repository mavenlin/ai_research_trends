Prev: [2022.01.14]({{ '/2022/01/14/2022.01.14.html' | relative_url }})  Next: [2022.01.16]({{ '/2022/01/16/2022.01.16.html' | relative_url }})
{% raw %}
## Summary for 2022-01-15, created on 2022-01-25


<details><summary><b>Deciding Not To Decide</b>
<a href="https://arxiv.org/abs/2201.05818">arxiv:2201.05818</a>
&#x1F4C8; 2300 <br>
<p>Florian Ellsaesser, Guido Fioretti</p></summary>
<p>

**Abstract:** Sometimes unexpected, novel, unconceivable events enter our lives. The cause-effect mappings that usually guide our behaviour are destroyed. Surprised and shocked by possibilities that we had never imagined, we are unable to make any decision beyond mere routine. Among them there are decisions, such as making investments, that are essential for the long-term survival of businesses as well as the economy at large. We submit that the standard machinery of utility maximization does not apply, but we propose measures inspired by scenario planning and graph analysis, pointing to solutions being explored in machine learning.

</p>
</details>

<details><summary><b>GradTail: Learning Long-Tailed Data Using Gradient-based Sample Weighting</b>
<a href="https://arxiv.org/abs/2201.05938">arxiv:2201.05938</a>
&#x1F4C8; 5 <br>
<p>Zhao Chen, Vincent Casser, Henrik Kretzschmar, Dragomir Anguelov</p></summary>
<p>

**Abstract:** We propose GradTail, an algorithm that uses gradients to improve model performance on the fly in the face of long-tailed training data distributions. Unlike conventional long-tail classifiers which operate on converged - and possibly overfit - models, we demonstrate that an approach based on gradient dot product agreement can isolate long-tailed data early on during model training and improve performance by dynamically picking higher sample weights for that data. We show that such upweighting leads to model improvements for both classification and regression models, the latter of which are relatively unexplored in the long-tail literature, and that the long-tail examples found by gradient alignment are consistent with our semantic expectations.

</p>
</details>

<details><summary><b>Profitable Strategy Design by Using Deep Reinforcement Learning for Trades on Cryptocurrency Markets</b>
<a href="https://arxiv.org/abs/2201.05906">arxiv:2201.05906</a>
&#x1F4C8; 5 <br>
<p>Mohsen Asgari, Seyed Hossein Khasteh</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning solutions have been applied to different control problems with outperforming and promising results. In this research work we have applied Proximal Policy Optimization, Soft Actor-Critic and Generative Adversarial Imitation Learning to strategy design problem of three cryptocurrency markets. Our input data includes price data and technical indicators. We have implemented a Gym environment based on cryptocurrency markets to be used with the algorithms. Our test results on unseen data shows a great potential for this approach in helping investors with an expert system to exploit the market and gain profit. Our highest gain for an unseen 66 day span is 4850 US dollars per 10000 US dollars investment. We also discuss on how a specific hyperparameter in the environment design can be used to adjust risk in the generated strategies.

</p>
</details>

<details><summary><b>Recent Progress in the CUHK Dysarthric Speech Recognition System</b>
<a href="https://arxiv.org/abs/2201.05845">arxiv:2201.05845</a>
&#x1F4C8; 5 <br>
<p>Shansong Liu, Mengzhe Geng, Shoukang Hu, Xurong Xie, Mingyu Cui, Jianwei Yu, Xunying Liu, Helen Meng</p></summary>
<p>

**Abstract:** Despite the rapid progress of automatic speech recognition (ASR) technologies in the past few decades, recognition of disordered speech remains a highly challenging task to date. Disordered speech presents a wide spectrum of challenges to current data intensive deep neural networks (DNNs) based ASR technologies that predominantly target normal speech. This paper presents recent research efforts at the Chinese University of Hong Kong (CUHK) to improve the performance of disordered speech recognition systems on the largest publicly available UASpeech dysarthric speech corpus. A set of novel modelling techniques including neural architectural search, data augmentation using spectra-temporal perturbation, model based speaker adaptation and cross-domain generation of visual features within an audio-visual speech recognition (AVSR) system framework were employed to address the above challenges. The combination of these techniques produced the lowest published word error rate (WER) of 25.21% on the UASpeech test set 16 dysarthric speakers, and an overall WER reduction of 5.4% absolute (17.6% relative) over the CUHK 2018 dysarthric speech recognition system featuring a 6-way DNN system combination and cross adaptation of out-of-domain normal speech data trained systems. Bayesian model adaptation further allows rapid adaptation to individual dysarthric speakers to be performed using as little as 3.06 seconds of speech. The efficacy of these techniques were further demonstrated on a CUDYS Cantonese dysarthric speech recognition task.

</p>
</details>

<details><summary><b>A Benchmark for Generalizable and Interpretable Temporal Question Answering over Knowledge Bases</b>
<a href="https://arxiv.org/abs/2201.05793">arxiv:2201.05793</a>
&#x1F4C8; 5 <br>
<p>Sumit Neelam, Udit Sharma, Hima Karanam, Shajith Ikbal, Pavan Kapanipathi, Ibrahim Abdelaziz, Nandana Mihindukulasooriya, Young-Suk Lee, Santosh Srivastava, Cezar Pendus, Saswati Dana, Dinesh Garg, Achille Fokoue, G P Shrivatsa Bhargav, Dinesh Khandelwal, Srinivas Ravishankar, Sairam Gurajada, Maria Chang, Rosario Uceda-Sosa, Salim Roukos, Alexander Gray, Guilherme Lima, Ryan Riegel, Francois Luus, L Venkata Subramaniam</p></summary>
<p>

**Abstract:** Knowledge Base Question Answering (KBQA) tasks that involve complex reasoning are emerging as an important research direction. However, most existing KBQA datasets focus primarily on generic multi-hop reasoning over explicit facts, largely ignoring other reasoning types such as temporal, spatial, and taxonomic reasoning. In this paper, we present a benchmark dataset for temporal reasoning, TempQA-WD, to encourage research in extending the present approaches to target a more challenging set of complex reasoning tasks. Specifically, our benchmark is a temporal question answering dataset with the following advantages: (a) it is based on Wikidata, which is the most frequently curated, openly available knowledge base, (b) it includes intermediate sparql queries to facilitate the evaluation of semantic parsing based approaches for KBQA, and (c) it generalizes to multiple knowledge bases: Freebase and Wikidata. The TempQA-WD dataset is available at https://github.com/IBM/tempqa-wd.

</p>
</details>

<details><summary><b>A Novel Multi-Task Learning Method for Symbolic Music Emotion Recognition</b>
<a href="https://arxiv.org/abs/2201.05782">arxiv:2201.05782</a>
&#x1F4C8; 5 <br>
<p>Jibao Qiu, C. L. Philip Chen, Tong Zhang</p></summary>
<p>

**Abstract:** Symbolic Music Emotion Recognition(SMER) is to predict music emotion from symbolic data, such as MIDI and MusicXML. Previous work mainly focused on learning better representation via (mask) language model pre-training but ignored the intrinsic structure of the music, which is extremely important to the emotional expression of music. In this paper, we present a simple multi-task framework for SMER, which incorporates the emotion recognition task with other emotion-related auxiliary tasks derived from the intrinsic structure of the music. The results show that our multi-task framework can be adapted to different models. Moreover, the labels of auxiliary tasks are easy to be obtained, which means our multi-task methods do not require manually annotated labels other than emotion. Conducting on two publicly available datasets (EMOPIA and VGMIDI), the experiments show that our methods perform better in SMER task. Specifically, accuracy has been increased by 4.17 absolute point to 67.58 in EMOPIA dataset, and 1.97 absolute point to 55.85 in VGMIDI dataset. Ablation studies also show the effectiveness of multi-task methods designed in this paper.

</p>
</details>

<details><summary><b>ViTBIS: Vision Transformer for Biomedical Image Segmentation</b>
<a href="https://arxiv.org/abs/2201.05920">arxiv:2201.05920</a>
&#x1F4C8; 4 <br>
<p>Abhinav Sagar</p></summary>
<p>

**Abstract:** In this paper, we propose a novel network named Vision Transformer for Biomedical Image Segmentation (ViTBIS). Our network splits the input feature maps into three parts with $1\times 1$, $3\times 3$ and $5\times 5$ convolutions in both encoder and decoder. Concat operator is used to merge the features before being fed to three consecutive transformer blocks with attention mechanism embedded inside it. Skip connections are used to connect encoder and decoder transformer blocks. Similarly, transformer blocks and multi scale architecture is used in decoder before being linearly projected to produce the output segmentation map. We test the performance of our network using Synapse multi-organ segmentation dataset, Automated cardiac diagnosis challenge dataset, Brain tumour MRI segmentation dataset and Spleen CT segmentation dataset. Without bells and whistles, our network outperforms most of the previous state of the art CNN and transformer based models using Dice score and the Hausdorff distance as the evaluation metrics.

</p>
</details>

<details><summary><b>Common Phone: A Multilingual Dataset for Robust Acoustic Modelling</b>
<a href="https://arxiv.org/abs/2201.05912">arxiv:2201.05912</a>
&#x1F4C8; 4 <br>
<p>Philipp Klumpp, Tomás Arias-Vergara, Paula Andrea Pérez-Toro, Elmar Nöth, Juan Rafael Orozco-Arroyave</p></summary>
<p>

**Abstract:** Current state of the art acoustic models can easily comprise more than 100 million parameters. This growing complexity demands larger training datasets to maintain a decent generalization of the final decision function. An ideal dataset is not necessarily large in size, but large with respect to the amount of unique speakers, utilized hardware and varying recording conditions. This enables a machine learning model to explore as much of the domain-specific input space as possible during parameter estimation. This work introduces Common Phone, a gender-balanced, multilingual corpus recorded from more than 76.000 contributors via Mozilla's Common Voice project. It comprises around 116 hours of speech enriched with automatically generated phonetic segmentation. A Wav2Vec 2.0 acoustic model was trained with the Common Phone to perform phonetic symbol recognition and validate the quality of the generated phonetic annotation. The architecture achieved a PER of 18.1 % on the entire test set, computed with all 101 unique phonetic symbols, showing slight differences between the individual languages. We conclude that Common Phone provides sufficient variability and reliable phonetic annotation to help bridging the gap between research and application of acoustic models.

</p>
</details>

<details><summary><b>A Framework for Pedestrian Sub-classification and Arrival Time Prediction at Signalized Intersection Using Preprocessed Lidar Data</b>
<a href="https://arxiv.org/abs/2201.05877">arxiv:2201.05877</a>
&#x1F4C8; 4 <br>
<p>Tengfeng Lin, Zhixiong Jin, Seongjin Choi, Hwasoo Yeo</p></summary>
<p>

**Abstract:** The mortality rate for pedestrians using wheelchairs was 36% higher than the overall population pedestrian mortality rate. However, there is no data to clarify the pedestrians' categories in both fatal and nonfatal accidents, since police reports often do not keep a record of whether a victim was using a wheelchair or has a disability. Currently, real-time detection of vulnerable road users using advanced traffic sensors installed at the infrastructure side has a great potential to significantly improve traffic safety at the intersection. In this research, we develop a systematic framework with a combination of machine learning and deep learning models to distinguish disabled people from normal walk pedestrians and predict the time needed to reach the next side of the intersection. The proposed framework shows high performance both at vulnerable user classification and arrival time prediction accuracy.

</p>
</details>

<details><summary><b>Explainability Tools Enabling Deep Learning in Future In-Situ Real-Time Planetary Explorations</b>
<a href="https://arxiv.org/abs/2201.05775">arxiv:2201.05775</a>
&#x1F4C8; 4 <br>
<p>Daniel Lundstrom, Alexander Huyen, Arya Mevada, Kyongsik Yun, Thomas Lu</p></summary>
<p>

**Abstract:** Deep learning (DL) has proven to be an effective machine learning and computer vision technique. DL-based image segmentation, object recognition and classification will aid many in-situ Mars rover tasks such as path planning and artifact recognition/extraction. However, most of the Deep Neural Network (DNN) architectures are so complex that they are considered a 'black box'. In this paper, we used integrated gradients to describe the attributions of each neuron to the output classes. It provides a set of explainability tools (ET) that opens the black box of a DNN so that the individual contribution of neurons to category classification can be ranked and visualized. The neurons in each dense layer are mapped and ranked by measuring expected contribution of a neuron to a class vote given a true image label. The importance of neurons is prioritized according to their correct or incorrect contribution to the output classes and suppression or bolstering of incorrect classes, weighted by the size of each class. ET provides an interface to prune the network to enhance high-rank neurons and remove low-performing neurons. ET technology will make DNNs smaller and more efficient for implementation in small embedded systems. It also leads to more explainable and testable DNNs that can make systems easier for Validation \& Verification. The goal of ET technology is to enable the adoption of DL in future in-situ planetary exploration missions.

</p>
</details>

<details><summary><b>StolenEncoder: Stealing Pre-trained Encoders</b>
<a href="https://arxiv.org/abs/2201.05889">arxiv:2201.05889</a>
&#x1F4C8; 3 <br>
<p>Yupei Liu, Jinyuan Jia, Hongbin Liu, Neil Zhenqiang Gong</p></summary>
<p>

**Abstract:** Pre-trained encoders are general-purpose feature extractors that can be used for many downstream tasks. Recent progress in self-supervised learning can pre-train highly effective encoders using a large volume of unlabeled data, leading to the emerging encoder as a service (EaaS). A pre-trained encoder may be deemed confidential because its training often requires lots of data and computation resources as well as its public release may facilitate misuse of AI, e.g., for deepfakes generation. In this paper, we propose the first attack called StolenEncoder to steal pre-trained image encoders. We evaluate StolenEncoder on multiple target encoders pre-trained by ourselves and three real-world target encoders including the ImageNet encoder pre-trained by Google, CLIP encoder pre-trained by OpenAI, and Clarifai's General Embedding encoder deployed as a paid EaaS. Our results show that the encoders stolen by StolenEncoder have similar functionality with the target encoders. In particular, the downstream classifiers built upon a target encoder and a stolen encoder have similar accuracy. Moreover, stealing a target encoder using StolenEncoder requires much less data and computation resources than pre-training it from scratch. We also explore three defenses that perturb feature vectors produced by a target encoder. Our evaluation shows that these defenses are not enough to mitigate StolenEncoder.

</p>
</details>

<details><summary><b>Deep Unified Representation for Heterogeneous Recommendation</b>
<a href="https://arxiv.org/abs/2201.05861">arxiv:2201.05861</a>
&#x1F4C8; 3 <br>
<p>Chengqiang Lu, Mingyang Yin, Shuheng Shen, Luo Ji, Qi Liu, Hongxia Yang</p></summary>
<p>

**Abstract:** Recommendation system has been a widely studied task both in academia and industry. Previous works mainly focus on homogeneous recommendation and little progress has been made for heterogeneous recommender systems. However, heterogeneous recommendations, e.g., recommending different types of items including products, videos, celebrity shopping notes, among many others, are dominant nowadays. State-of-the-art methods are incapable of leveraging attributes from different types of items and thus suffer from data sparsity problems. And it is indeed quite challenging to represent items with different feature spaces jointly. To tackle this problem, we propose a kernel-based neural network, namely deep unified representation (or DURation) for heterogeneous recommendation, to jointly model unified representations of heterogeneous items while preserving their original feature space topology structures. Theoretically, we prove the representation ability of the proposed model. Besides, we conduct extensive experiments on real-world datasets. Experimental results demonstrate that with the unified representation, our model achieves remarkable improvement (e.g., 4.1% ~ 34.9% lift by AUC score and 3.7% lift by online CTR) over existing state-of-the-art models.

</p>
</details>

<details><summary><b>Weighting and Pruning based Ensemble Deep Random Vector Functional Link Network for Tabular Data Classification</b>
<a href="https://arxiv.org/abs/2201.05809">arxiv:2201.05809</a>
&#x1F4C8; 3 <br>
<p>Qiushi Shi, Ponnuthurai Nagaratnam Suganthan, Rakesh Katuwal</p></summary>
<p>

**Abstract:** In this paper, we first introduce batch normalization to the edRVFL network. This re-normalization method can help the network avoid divergence of the hidden features. Then we propose novel variants of Ensemble Deep Random Vector Functional Link (edRVFL). Weighted edRVFL (WedRVFL) uses weighting methods to give training samples different weights in different layers according to how the samples were classified confidently in the previous layer thereby increasing the ensemble's diversity and accuracy. Furthermore, a pruning-based edRVFL (PedRVFL) has also been proposed. We prune some inferior neurons based on their importance for classification before generating the next hidden layer. Through this method, we ensure that the randomly generated inferior features will not propagate to deeper layers. Subsequently, the combination of weighting and pruning, called Weighting and Pruning based Ensemble Deep Random Vector Functional Link Network (WPedRVFL), is proposed. We compare their performances with other state-of-the-art deep feedforward neural networks (FNNs) on 24 tabular UCI classification datasets. The experimental results illustrate the superior performance of our proposed methods.

</p>
</details>

<details><summary><b>Hyperplane bounds for neural feature mappings</b>
<a href="https://arxiv.org/abs/2201.05799">arxiv:2201.05799</a>
&#x1F4C8; 3 <br>
<p>Antonio Jimeno Yepes</p></summary>
<p>

**Abstract:** Deep learning methods minimise the empirical risk using loss functions such as the cross entropy loss. When minimising the empirical risk, the generalisation of the learnt function still depends on the performance on the training data, the Vapnik-Chervonenkis(VC)-dimension of the function and the number of training examples. Neural networks have a large number of parameters, which correlates with their VC-dimension that is typically large but not infinite, and typically a large number of training instances are needed to effectively train them.
  In this work, we explore how to optimize feature mappings using neural network with the intention to reduce the effective VC-dimension of the hyperplane found in the space generated by the mapping. An interpretation of the results of this study is that it is possible to define a loss that controls the VC-dimension of the separating hyperplane. We evaluate this approach and observe that the performance when using this method improves when the size of the training set is small.

</p>
</details>

<details><summary><b>Mixed Diagnostics for Longitudinal Properties of Electron Bunches in a Free-Electron Laser</b>
<a href="https://arxiv.org/abs/2201.05769">arxiv:2201.05769</a>
&#x1F4C8; 3 <br>
<p>J. Zhu, N. M. Lockmann, M. K. Czwalinna, H. Schlarb</p></summary>
<p>

**Abstract:** Longitudinal properties of electron bunches are critical for the performance of a wide range of scientific facilities. In a free-electron laser, for example, the existing diagnostics only provide very limited longitudinal information of the electron bunch during online tuning and optimization. We leverage the power of artificial intelligence to build a neural network model using experimental data, in order to bring the destructive longitudinal phase space (LPS) diagnostics online virtually and improve the existing current profile online diagnostics which uses a coherent transition radiation (CTR) spectrometer. The model can also serve as a digital twin of the real machine on which algorithms can be tested efficiently and effectively. We demonstrate at the FLASH facility that the encoder-decoder model with more than one decoder can make highly accurate predictions of megapixel LPS images and coherent transition radiation spectra concurrently for electron bunches in a bunch train with broad ranges of LPS shapes and peak currents, which are obtained by scanning all the major control knobs for LPS manipulation. Furthermore, we propose a way to significantly improve the CTR spectrometer online measurement by combining the predicted and measured spectra. Our work showcases how to combine virtual and real diagnostics in order to provide heterogeneous and reliable mixed diagnostics for scientific facilities.

</p>
</details>

<details><summary><b>Big Data Application for Network Level Travel Time Prediction</b>
<a href="https://arxiv.org/abs/2201.05760">arxiv:2201.05760</a>
&#x1F4C8; 3 <br>
<p>Tianya T. Zhang, Ying Ye, Yu Kathy Zhang</p></summary>
<p>

**Abstract:** Travel time is essential in advanced traveler information systems (ATIS). This paper used the big data analytics engines Apache Spark and Apache MXNet for data processing and modeling. The efficiency gain was evaluated by comparing it with popular data science and deep learning frameworks. The hierarchical feature pooling is explored for both between layer and the output layer LSTM (Long-Short-Term-Memory). The designed hierarchical LSTM (hiLSTM) model can consider the dependencies at a different time scale to capture the spatial-temporal correlations from network-level corridor travel time. A self-attention module is then used to connect temporal and spatial features to the fully connected layers, predicting travel time for all corridors instead of a single link/route. Seasonality and autocorrelation were performed to explore the trend of time-varying data. The case study shows that the Hierarchical LSTM with Attention (hiLSTMat) model gives the best result and outperforms baseline models. The California Bay Area corridor travel time dataset covering four-year periods was published from Caltrans Performance Measurement System (PeMS) system.

</p>
</details>

<details><summary><b>Enhancement of Healthcare Data Performance Metrics using Neural Network Machine Learning Algorithms</b>
<a href="https://arxiv.org/abs/2201.05962">arxiv:2201.05962</a>
&#x1F4C8; 2 <br>
<p>Qi An, Patryk Szewczyk, Michael N Johnstone, James Jin Kang</p></summary>
<p>

**Abstract:** Patients are often encouraged to make use of wearable devices for remote collection and monitoring of health data. This adoption of wearables results in a significant increase in the volume of data collected and transmitted. The battery life of the devices is then quickly diminished due to the high processing requirements of the devices. Given the importance attached to medical data, it is imperative that all transmitted data adhere to strict integrity and availability requirements. Reducing the volume of healthcare data for network transmission may improve sensor battery life without compromising accuracy. There is a trade-off between efficiency and accuracy which can be controlled by adjusting the sampling and transmission rates. This paper demonstrates that machine learning can be used to analyse complex health data metrics such as the accuracy and efficiency of data transmission to overcome the trade-off problem. The study uses time series nonlinear autoregressive neural network algorithms to enhance both data metrics by taking fewer samples to transmit. The algorithms were tested with a standard heart rate dataset to compare their accuracy and efficiency. The result showed that the Levenbery-Marquardt algorithm was the best performer with an efficiency of 3.33 and accuracy of 79.17%, which is similar to other algorithms accuracy but demonstrates improved efficiency. This proves that machine learning can improve without sacrificing a metric over the other compared to the existing methods with high efficiency.

</p>
</details>

<details><summary><b>Global Regular Network for Writer Identification</b>
<a href="https://arxiv.org/abs/2201.05951">arxiv:2201.05951</a>
&#x1F4C8; 2 <br>
<p>Shiyu Wang</p></summary>
<p>

**Abstract:** Writer identification has practical applications for forgery detection and forensic science. Most models based on deep neural networks extract features from character image or sub-regions in character image, which ignoring features contained in page-region image. Our proposed global regular network (GRN) pays attention to these features. GRN network consists of two branches: one branch takes page handwriting as input to extract global features, and the other takes word handwriting as input to extract local features. Global features and local features merge in a global residual way to form overall features of the handwriting. The proposed GRN has two attributions: one is adding a branch to extract features contained in page; the other is using residual attention network to extract local feature. Experiments demonstrate the effectiveness of both strategies. On CVL dataset, our models achieve impressive 99.98% top-1 accuracy and 100% top-5 accuracy with shorter training time and fewer network parameters, which exceeded the state-of-the-art structure. The experiment shows the powerful ability of the network in the field of writer identification. The source code is available at https://github.com/wangshiyu001/GRN.

</p>
</details>

<details><summary><b>Characterizing Big Data Management</b>
<a href="https://arxiv.org/abs/2201.05929">arxiv:2201.05929</a>
&#x1F4C8; 2 <br>
<p>Rogerio Rossi, Kechi Hirama</p></summary>
<p>

**Abstract:** Big data management is a reality for an increasing number of organizations in many areas and represents a set of challenges involving big data modeling, storage and retrieval, analysis and visualization. However, technological resources, people and processes are crucial to facilitate the management of big data in any kind of organization, allowing information and knowledge from a large volume of data to support decision-making. Big data management can be supported by these three dimensions: technology, people and processes. Hence, this article discusses these dimensions: the technological dimension that is related to storage, analytics and visualization of big data; the human aspects of big data; and, in addition, the process management dimension that involves in a technological and business approach the aspects of big data management.

</p>
</details>

<details><summary><b>Theoretical analysis and computation of the sample Frechet mean for sets of large graphs based on spectral information</b>
<a href="https://arxiv.org/abs/2201.05923">arxiv:2201.05923</a>
&#x1F4C8; 2 <br>
<p>Daniel Ferguson, Francois G. Meyer</p></summary>
<p>

**Abstract:** To characterize the location (mean, median) of a set of graphs, one needs a notion of centrality that is adapted to metric spaces, since graph sets are not Euclidean spaces. A standard approach is to consider the Frechet mean. In this work, we equip a set of graphs with the pseudometric defined by the norm between the eigenvalues of their respective adjacency matrix. Unlike the edit distance, this pseudometric reveals structural changes at multiple scales, and is well adapted to studying various statistical problems for graph-valued data. We describe an algorithm to compute an approximation to the sample Frechet mean of a set of undirected unweighted graphs with a fixed size using this pseudometric.

</p>
</details>

<details><summary><b>Noncommutative Geometry of Computational Models and Uniformization for Framed Quiver Varieties</b>
<a href="https://arxiv.org/abs/2201.05900">arxiv:2201.05900</a>
&#x1F4C8; 2 <br>
<p>George Jeffreys, Siu-Cheong Lau</p></summary>
<p>

**Abstract:** We formulate a mathematical setup for computational neural networks using noncommutative algebras and near-rings, in motivation of quantum automata. We study the moduli space of the corresponding framed quiver representations, and find moduli of Euclidean and non-compact types in light of uniformization.

</p>
</details>

<details><summary><b>Domain Adaptation via Bidirectional Cross-Attention Transformer</b>
<a href="https://arxiv.org/abs/2201.05887">arxiv:2201.05887</a>
&#x1F4C8; 2 <br>
<p>Xiyu Wang, Pengxin Guo, Yu Zhang</p></summary>
<p>

**Abstract:** Domain Adaptation (DA) aims to leverage the knowledge learned from a source domain with ample labeled data to a target domain with unlabeled data only. Most existing studies on DA contribute to learning domain-invariant feature representations for both domains by minimizing the domain gap based on convolution-based neural networks. Recently, vision transformers significantly improved performance in multiple vision tasks. Built on vision transformers, in this paper we propose a Bidirectional Cross-Attention Transformer (BCAT) for DA with the aim to improve the performance. In the proposed BCAT, the attention mechanism can extract implicit source and target mix-up feature representations to narrow the domain discrepancy. Specifically, in BCAT, we design a weight-sharing quadruple-branch transformer with a bidirectional cross-attention mechanism to learn domain-invariant feature representations. Extensive experiments demonstrate that the proposed BCAT model achieves superior performance on four benchmark datasets over existing state-of-the-art DA methods that are based on convolutions or transformers.

</p>
</details>

<details><summary><b>Smart Parking Space Detection under Hazy conditions using Convolutional Neural Networks: A Novel Approach</b>
<a href="https://arxiv.org/abs/2201.05858">arxiv:2201.05858</a>
&#x1F4C8; 2 <br>
<p>Gaurav Satyanath, Jajati Keshari Sahoo, Rajendra Kumar Roul</p></summary>
<p>

**Abstract:** Limited urban parking space combined with urbanization has necessitated the development of smart parking systems that can communicate the availability of parking slots to the end users. Towards this, various deep learning based solutions using convolutional neural networks have been proposed for parking space occupation detection. Though these approaches are robust to partial obstructions and lighting conditions, their performance is found to degrade in the presence of haze conditions. Looking in this direction, this paper investigates the use of dehazing networks that improves the performance of parking space occupancy classifier under hazy conditions. Additionally, training procedures are proposed for dehazing networks to maximize the performance of the system on both hazy and non-hazy conditions. The proposed system is deployable as part of existing smart parking systems where limited number of cameras are used to monitor hundreds of parking spaces. To validate our approach, we have developed a custom hazy parking system dataset from real-world task-driven test set of RESIDE-\b{eta} dataset. The proposed approach is tested against existing state-of-the-art parking space detectors on CNRPark-EXT and hazy parking system datasets. Experimental results indicate that there is a significant accuracy improvement of the proposed approach on the hazy parking system dataset.

</p>
</details>

<details><summary><b>Cooperative Multi-Agent Deep Reinforcement Learning for Reliable Surveillance via Autonomous Multi-UAV Control</b>
<a href="https://arxiv.org/abs/2201.05843">arxiv:2201.05843</a>
&#x1F4C8; 2 <br>
<p>Won Joon Yun, Soohyun Park, Joongheon Kim, MyungJae Shin, Soyi Jung, David A. Mohaisen, Jae-Hyun Kim</p></summary>
<p>

**Abstract:** CCTV-based surveillance using unmanned aerial vehicles (UAVs) is considered a key technology for security in smart city environments. This paper creates a case where the UAVs with CCTV-cameras fly over the city area for flexible and reliable surveillance services. UAVs should be deployed to cover a large area while minimize overlapping and shadow areas for a reliable surveillance system. However, the operation of UAVs is subject to high uncertainty, necessitating autonomous recovery systems. This work develops a multi-agent deep reinforcement learning-based management scheme for reliable industry surveillance in smart city applications. The core idea this paper employs is autonomously replenishing the UAV's deficient network requirements with communications. Via intensive simulations, our proposed algorithm outperforms the state-of-the-art algorithms in terms of surveillance coverage, user support capability, and computational costs.

</p>
</details>

<details><summary><b>Multi-View representation learning in Multi-Task Scene</b>
<a href="https://arxiv.org/abs/2201.05829">arxiv:2201.05829</a>
&#x1F4C8; 2 <br>
<p>Run-kun Lu, Jian-wei Liu, Si-ming Lian, Xin Zuo</p></summary>
<p>

**Abstract:** Over recent decades have witnessed considerable progress in whether multi-task learning or multi-view learning, but the situation that consider both learning scenes simultaneously has received not too much attention. How to utilize multiple views latent representation of each single task to improve each learning task performance is a challenge problem. Based on this, we proposed a novel semi-supervised algorithm, termed as Multi-Task Multi-View learning based on Common and Special Features (MTMVCSF). In general, multi-views are the different aspects of an object and every view includes the underlying common or special information of this object. As a consequence, we will mine multiple views jointly latent factor of each learning task which consists of each view special feature and the common feature of all views. By this way, the original multi-task multi-view data has degenerated into multi-task data, and exploring the correlations among multiple tasks enables to make an improvement on the performance of learning algorithm. Another obvious advantage of this approach is that we get latent representation of the set of unlabeled instances by the constraint of regression task with labeled instances. The performance of classification and semi-supervised clustering task in these latent representations perform obviously better than it in raw data. Furthermore, an anti-noise multi-task multi-view algorithm called AN-MTMVCSF is proposed, which has a strong adaptability to noise labels. The effectiveness of these algorithms is proved by a series of well-designed experiments on both real world and synthetic data.

</p>
</details>

<details><summary><b>Automated causal inference in application to randomized controlled clinical trials</b>
<a href="https://arxiv.org/abs/2201.05773">arxiv:2201.05773</a>
&#x1F4C8; 2 <br>
<p>Jiqing Wu, Nanda Horeweg, Marco de Bruyn, Remi A. Nout, Ina M. Jürgenliemk-Schulz, Ludy C. H. W. Lutgens, Jan J. Jobsen, Elzbieta M. van der Steen-Banasik, Hans W. Nijman, Vincent T. H. B. M. Smit, Tjalling Bosse, Carien L. Creutzberg, Viktor H. Koelzer</p></summary>
<p>

**Abstract:** Randomized controlled trials (RCTs) are considered as the gold standard for testing causal hypotheses in the clinical domain. However, the investigation of prognostic variables of patient outcome in a hypothesized cause-effect route is not feasible using standard statistical methods. Here, we propose a new automated causal inference method (AutoCI) built upon the invariant causal prediction (ICP) framework for the causal re-interpretation of clinical trial data. Compared to existing methods, we show that the proposed AutoCI allows to efficiently determine the causal variables with a clear differentiation on two real-world RCTs of endometrial cancer patients with mature outcome and extensive clinicopathological and molecular data. This is achieved via suppressing the causal probability of non-causal variables by a wide margin. In ablation studies, we further demonstrate that the assignment of causal probabilities by AutoCI remain consistent in the presence of confounders. In conclusion, these results confirm the robustness and feasibility of AutoCI for future applications in real-world clinical analysis.

</p>
</details>

<details><summary><b>Chatbot Based Solution for Supporting Software Incident Management Process</b>
<a href="https://arxiv.org/abs/2201.08167">arxiv:2201.08167</a>
&#x1F4C8; 1 <br>
<p>Nagib Sabbag Filho, Rogerio Rossi</p></summary>
<p>

**Abstract:** A set of steps for implementing a chatbot, to support decision-making activities in the software incident management process is proposed and discussed in this article. Each step is presented independently of the platform used for the construction of chatbots and are detailed with their respective activities. The proposed steps can be carried out in a continuous and adaptable way, favoring the constant training of a chatbot and allowing the increasingly cohesive interpretatin of the intentions of the specialists who work in the Software Incident Management Process. The software incident resolution process accordingly to the ITIL framework, is considered for the experiment. The results of the work present the steps for the chatbot construction, the solution based on DialogFlow platform and some conclusions based on the experiment.

</p>
</details>

<details><summary><b>Universal Online Learning: an Optimistically Universal Learning Rule</b>
<a href="https://arxiv.org/abs/2201.05947">arxiv:2201.05947</a>
&#x1F4C8; 1 <br>
<p>Moïse Blanchard</p></summary>
<p>

**Abstract:** We study the subject of universal online learning with non-i.i.d. processes for bounded losses. The notion of an universally consistent learning was defined by Hanneke in an effort to study learning theory under minimal assumptions, where the objective is to obtain low long-run average loss for any target function. We are interested in characterizing processes for which learning is possible and whether there exist learning rules guaranteed to be universally consistent given the only assumption that such learning is possible. The case of unbounded losses is very restrictive, since the learnable processes almost surely visit a finite number of points and as a result, simple memorization is optimistically universal. We focus on the bounded setting and give a complete characterization of the processes admitting strong and weak universal learning. We further show that k-nearest neighbor algorithm (kNN) is not optimistically universal and present a novel variant of 1NN which is optimistically universal for general input and value spaces in both strong and weak setting. This closes all COLT 2021 open problems posed by Hanneke on universal online learning.

</p>
</details>

<details><summary><b>SS-3DCapsNet: Self-supervised 3D Capsule Networks for Medical Segmentation on Less Labeled Data</b>
<a href="https://arxiv.org/abs/2201.05905">arxiv:2201.05905</a>
&#x1F4C8; 1 <br>
<p>Minh Tran, Loi Ly, Binh-Son Hua, Ngan Le</p></summary>
<p>

**Abstract:** Capsule network is a recent new deep network architecture that has been applied successfully for medical image segmentation tasks. This work extends capsule networks for volumetric medical image segmentation with self-supervised learning. To improve on the problem of weight initialization compared to previous capsule networks, we leverage self-supervised learning for capsule networks pre-training, where our pretext-task is optimized by self-reconstruction. Our capsule network, SS-3DCapsNet, has a UNet-based architecture with a 3D Capsule encoder and 3D CNNs decoder. Our experiments on multiple datasets including iSeg-2017, Hippocampus, and Cardiac demonstrate that our 3D capsule network with self-supervised pre-training considerably outperforms previous capsule networks and 3D-UNets.

</p>
</details>

<details><summary><b>Robust uncertainty estimates with out-of-distribution pseudo-inputs training</b>
<a href="https://arxiv.org/abs/2201.05890">arxiv:2201.05890</a>
&#x1F4C8; 1 <br>
<p>Pierre Segonne, Yevgen Zainchkovskyy, Søren Hauberg</p></summary>
<p>

**Abstract:** Probabilistic models often use neural networks to control their predictive uncertainty. However, when making out-of-distribution (OOD)} predictions, the often-uncontrollable extrapolation properties of neural networks yield poor uncertainty predictions. Such models then don't know what they don't know, which directly limits their robustness w.r.t unexpected inputs. To counter this, we propose to explicitly train the uncertainty predictor where we are not given data to make it reliable. As one cannot train without data, we provide mechanisms for generating pseudo-inputs in informative low-density regions of the input space, and show how to leverage these in a practical Bayesian framework that casts a prior distribution over the model uncertainty. With a holistic evaluation, we demonstrate that this yields robust and interpretable predictions of uncertainty while retaining state-of-the-art performance on diverse tasks such as regression and generative modelling

</p>
</details>

<details><summary><b>Large-Scale Inventory Optimization: A Recurrent-Neural-Networks-Inspired Simulation Approach</b>
<a href="https://arxiv.org/abs/2201.05868">arxiv:2201.05868</a>
&#x1F4C8; 1 <br>
<p>Tan Wan, L. Jeff Hong</p></summary>
<p>

**Abstract:** Many large-scale production networks include thousands types of final products and tens to hundreds thousands types of raw materials and intermediate products. These networks face complicated inventory management decisions, which are often too complicated for inventory models and too large for simulation models. In this paper, by combing efficient computational tools of recurrent neural networks (RNN) and the structural information of production networks, we propose a RNN inspired simulation approach that may be thousands times faster than existing simulation approach and is capable of solving large-scale inventory optimization problems in a reasonable amount of time.

</p>
</details>

<details><summary><b>SDT-DCSCN for Simultaneous Super-Resolution and Deblurring of Text Images</b>
<a href="https://arxiv.org/abs/2201.05865">arxiv:2201.05865</a>
&#x1F4C8; 1 <br>
<p>Hala Neji, Mohamed Ben Halima, Javier Nogueras-Iso, Tarek. M. Hamdani, Abdulrahman M. Qahtani, Omar Almutiry, Habib Dhahri, Adel M. Alimi</p></summary>
<p>

**Abstract:** Deep convolutional neural networks (Deep CNN) have achieved hopeful performance for single image super-resolution. In particular, the Deep CNN skip Connection and Network in Network (DCSCN) architecture has been successfully applied to natural images super-resolution. In this work we propose an approach called SDT-DCSCN that jointly performs super-resolution and deblurring of low-resolution blurry text images based on DCSCN. Our approach uses subsampled blurry images in the input and original sharp images as ground truth. The used architecture is consists of a higher number of filters in the input CNN layer to a better analysis of the text details. The quantitative and qualitative evaluation on different datasets prove the high performance of our model to reconstruct high-resolution and sharp text images. In addition, in terms of computational time, our proposed method gives competitive performance compared to state of the art methods.

</p>
</details>

<details><summary><b>Two-Stage is Enough: A Concise Deep Unfolding Reconstruction Network for Flexible Video Compressive Sensing</b>
<a href="https://arxiv.org/abs/2201.05810">arxiv:2201.05810</a>
&#x1F4C8; 1 <br>
<p>Siming Zheng, Xiaoyu Yang, Xin Yuan</p></summary>
<p>

**Abstract:** We consider the reconstruction problem of video compressive sensing (VCS) under the deep unfolding/rolling structure. Yet, we aim to build a flexible and concise model using minimum stages. Different from existing deep unfolding networks used for inverse problems, where more stages are used for higher performance but without flexibility to different masks and scales, hereby we show that a 2-stage deep unfolding network can lead to the state-of-the-art (SOTA) results (with a 1.7dB gain in PSNR over the single stage model, RevSCI) in VCS. The proposed method possesses the properties of adaptation to new masks and ready to scale to large data without any additional training thanks to the advantages of deep unfolding. Furthermore, we extend the proposed model for color VCS to perform joint reconstruction and demosaicing. Experimental results demonstrate that our 2-stage model has also achieved SOTA on color VCS reconstruction, leading to a >2.3dB gain in PSNR over the previous SOTA algorithm based on plug-and-play framework, meanwhile speeds up the reconstruction by >17 times. In addition, we have found that our network is also flexible to the mask modulation and scale size for color VCS reconstruction so that a single trained network can be applied to different hardware systems. The code and models will be released to the public.

</p>
</details>

<details><summary><b>Edge-based Tensor prediction via graph neural networks</b>
<a href="https://arxiv.org/abs/2201.05770">arxiv:2201.05770</a>
&#x1F4C8; 1 <br>
<p>Yang Zhong, Hongyu Yu, Xingao Gong, Hongjun Xiang</p></summary>
<p>

**Abstract:** Message-passing neural networks (MPNN) have shown extremely high efficiency and accuracy in predicting the physical properties of molecules and crystals, and are expected to become the next-generation material simulation tool after the density functional theory (DFT). However, there is currently a lack of a general MPNN framework for directly predicting the tensor properties of the crystals. In this work, a general framework for the prediction of tensor properties was proposed: the tensor property of a crystal can be decomposed into the average of the tensor contributions of all the atoms in the crystal, and the tensor contribution of each atom can be expanded as the sum of the tensor projections in the directions of the edges connecting the atoms. On this basis, the edge-based expansions of force vectors, Born effective charges (BECs), dielectric (DL) and piezoelectric (PZ) tensors were proposed. These expansions are rotationally equivariant, while the coefficients in these tensor expansions are rotationally invariant scalars which are similar to physical quantities such as formation energy and band gap. The advantage of this tensor prediction framework is that it does not require the network itself to be equivariant. Therefore, in this work, we directly designed the edge-based tensor prediction graph neural network (ETGNN) model on the basis of the invariant graph neural network to predict tensors. The validity and high precision of this tensor prediction framework were shown by the tests of ETGNN on the extended systems, random perturbed structures and JARVIS-DFT datasets. This tensor prediction framework is general for nearly all the GNNs and can achieve higher accuracy with more advanced GNNs in the future.

</p>
</details>

<details><summary><b>Spectral Compressive Imaging Reconstruction Using Convolution and Spectral Contextual Transformer</b>
<a href="https://arxiv.org/abs/2201.05768">arxiv:2201.05768</a>
&#x1F4C8; 1 <br>
<p>Lishun Wang, Zongliang Wu, Yong Zhong, Xin Yuan</p></summary>
<p>

**Abstract:** Spectral compressive imaging (SCI) is able to encode the high-dimensional hyperspectral image to a 2D measurement, and then uses algorithms to reconstruct the spatio-spectral data-cube. At present, the main bottleneck of SCI is the reconstruction algorithm, and the state-of-the-art (SOTA) reconstruction methods generally face the problem of long reconstruction time and/or poor detail recovery. In this paper, we propose a novel hybrid network module, namely CSCoT (Convolution and Spectral Contextual Transformer) block, which can acquire the local perception of convolution and the global perception of transformer simultaneously, and is conducive to improving the quality of reconstruction to restore fine details. We integrate the proposed CSCoT block into deep unfolding framework based on the generalized alternating projection algorithm, and further propose the GAP-CSCoT network. Finally, we apply the GAP-CSCoT algorithm to SCI reconstruction. Through the experiments of extensive synthetic and real data, our proposed model achieves higher reconstruction quality ($>$2dB in PSNR on simulated benchmark datasets) and shorter running time than existing SOTA algorithms by a large margin. The code and models will be released to the public.

</p>
</details>

<details><summary><b>Training Fair Deep Neural Networks by Balancing Influence</b>
<a href="https://arxiv.org/abs/2201.05759">arxiv:2201.05759</a>
&#x1F4C8; 1 <br>
<p>Haonan Wang, Ziwei Wu, Jingrui He</p></summary>
<p>

**Abstract:** Most fair machine learning methods either highly rely on the sensitive information of the training samples or require a large modification on the target models, which hinders their practical application. To address this issue, we propose a two-stage training algorithm named FAIRIF. It minimizes the loss over the reweighted data set (second stage) where the sample weights are computed to balance the model performance across different demographic groups (first stage). FAIRIF can be applied on a wide range of models trained by stochastic gradient descent without changing the model, while only requiring group annotations on a small validation set to compute sample weights. Theoretically, we show that, in the classification setting, three notions of disparity among different groups can be mitigated by training with the weights. Experiments on synthetic data sets demonstrate that FAIRIF yields models with better fairness-utility trade-offs against various types of bias; and on real-world data sets, we show the effectiveness and scalability of FAIRIF. Moreover, as evidenced by the experiments with pretrained models, FAIRIF is able to alleviate the unfairness issue of pretrained models without hurting their performance.

</p>
</details>

<details><summary><b>A Residual Encoder-Decoder Network for Segmentation of Retinal Image-Based Exudates in Diabetic Retinopathy Screening</b>
<a href="https://arxiv.org/abs/2201.05963">arxiv:2201.05963</a>
&#x1F4C8; 0 <br>
<p>Malik A. Manan, Tariq M. Khan, Ahsan Saadat, Muhammad Arsalan, Syed S. Naqvi</p></summary>
<p>

**Abstract:** Diabetic retinopathy refers to the pathology of the retina induced by diabetes and is one of the leading causes of preventable blindness in the world. Early detection of diabetic retinopathy is critical to avoid vision problem through continuous screening and treatment. In traditional clinical practice, the involved lesions are manually detected using photographs of the fundus. However, this task is cumbersome and time-consuming and requires intense effort due to the small size of lesion and low contrast of the images. Thus, computer-assisted diagnosis of diabetic retinopathy based on the detection of red lesions is actively being explored recently. In this paper, we present a convolutional neural network with residual skip connection for the segmentation of exudates in retinal images. To improve the performance of network architecture, a suitable image augmentation technique is used. The proposed network can robustly segment exudates with high accuracy, which makes it suitable for diabetic retinopathy screening. Comparative performance analysis of three benchmark databases: HEI-MED, E-ophtha, and DiaretDB1 is presented. It is shown that the proposed method achieves accuracy (0.98, 0.99, 0.98) and sensitivity (0.97, 0.92, and 0.95) on E-ophtha, HEI-MED, and DiaReTDB1, respectively.

</p>
</details>

<details><summary><b>Physical Derivatives: Computing policy gradients by physical forward-propagation</b>
<a href="https://arxiv.org/abs/2201.05830">arxiv:2201.05830</a>
&#x1F4C8; 0 <br>
<p>Arash Mehrjou, Ashkan Soleymani, Stefan Bauer, Bernhard Schölkopf</p></summary>
<p>

**Abstract:** Model-free and model-based reinforcement learning are two ends of a spectrum. Learning a good policy without a dynamic model can be prohibitively expensive. Learning the dynamic model of a system can reduce the cost of learning the policy, but it can also introduce bias if it is not accurate. We propose a middle ground where instead of the transition model, the sensitivity of the trajectories with respect to the perturbation of the parameters is learned. This allows us to predict the local behavior of the physical system around a set of nominal policies without knowing the actual model. We assay our method on a custom-built physical robot in extensive experiments and show the feasibility of the approach in practice. We investigate potential challenges when applying our method to physical systems and propose solutions to each of them.

</p>
</details>


{% endraw %}
Prev: [2022.01.14]({{ '/2022/01/14/2022.01.14.html' | relative_url }})  Next: [2022.01.16]({{ '/2022/01/16/2022.01.16.html' | relative_url }})