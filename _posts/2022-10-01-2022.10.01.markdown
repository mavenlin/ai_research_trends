Prev: [2022.09.30]({{ '/2022/09/30/2022.09.30.html' | relative_url }})  Next: [2022.10.02]({{ '/2022/10/02/2022.10.02.html' | relative_url }})
{% raw %}
## Summary for 2022-10-01, created on 2022-10-11


<details><summary><b>Detecting Irregular Network Activity with Adversarial Learning and Expert Feedback</b>
<a href="https://arxiv.org/abs/2210.02841">arxiv:2210.02841</a>
&#x1F4C8; 37 <br>
<p>Gopikrishna Rathinavel, Nikhil Muralidhar, Timothy O'Shea, Naren Ramakrishnan</p></summary>
<p>

**Abstract:** Anomaly detection is a ubiquitous and challenging task relevant across many disciplines. With the vital role communication networks play in our daily lives, the security of these networks is imperative for smooth functioning of society. To this end, we propose a novel self-supervised deep learning framework CAAD for anomaly detection in wireless communication systems. Specifically, CAAD employs contrastive learning in an adversarial setup to learn effective representations of normal and anomalous behavior in wireless networks. We conduct rigorous performance comparisons of CAAD with several state-of-the-art anomaly detection techniques and verify that CAAD yields a mean performance improvement of 92.84%. Additionally, we also augment CAAD enabling it to systematically incorporate expert feedback through a novel contrastive learning feedback loop to improve the learned representations and thereby reduce prediction uncertainty (CAAD-EF). We view CAAD-EF as a novel, holistic and widely applicable solution to anomaly detection.

</p>
</details>

<details><summary><b>Stochastic optimization on matrices and a graphon McKean-Vlasov limit</b>
<a href="https://arxiv.org/abs/2210.00422">arxiv:2210.00422</a>
&#x1F4C8; 6 <br>
<p>Zaid Harchaoui, Sewoong Oh, Soumik Pal, Raghav Somani, Raghavendra Tripathi</p></summary>
<p>

**Abstract:** We consider stochastic gradient descents on the space of large symmetric matrices of suitable functions that are invariant under permuting the rows and columns using the same permutation. We establish deterministic limits of these random curves as the dimensions of the matrices go to infinity while the entries remain bounded. Under a ``small noise'' assumption the limit is shown to be the gradient flow of functions on graphons whose existence was established in arXiv:2111.09459. We also consider limits of stochastic gradient descents with added properly scaled reflected Brownian noise. The limiting curve of graphons is characterized by a family of stochastic differential equations with reflections and can be thought of as an extension of the classical McKean-Vlasov limit for interacting diffusions. The proofs introduce a family of infinite-dimensional exchangeable arrays of reflected diffusions and a novel notion of propagation of chaos for large matrices of interacting diffusions.

</p>
</details>

<details><summary><b>Physical computation and compositionality</b>
<a href="https://arxiv.org/abs/2210.00392">arxiv:2210.00392</a>
&#x1F4C8; 6 <br>
<p>Nima Dehghani, Gianluca Caterina</p></summary>
<p>

**Abstract:** Developments in quantum computing and, more in general, non-standard computing systems, represent a clear indication that the very notion of what a physical computing device is and does should be recast in a rigorous and sound framework. Physical computing has opened a whole stream of new research aimed to understand and control how information is processed by several types of physical devices. Therefore, classical definitions and entire frameworks need to be adapted in order to fit a broader notion of what physical computing systems really are. Recent studies have proposed a formalism that can be used to carve out a more proper notion of physical computing. In this paper we present a framework which capture such results in a very natural way via some basic constructions in Category Theory. Furthermore, we show that, within our framework, the compositional nature of physical computing systems is naturally formalized, and that it can be organized in coherent structures by the means of their relational nature.

</p>
</details>

<details><summary><b>DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability</b>
<a href="https://arxiv.org/abs/2210.00364">arxiv:2210.00364</a>
&#x1F4C8; 6 <br>
<p>Cian Eastwood, Andrei Liviu Nicolicioiu, Julius von Kügelgen, Armin Kekić, Frederik Träuble, Andrea Dittadi, Bernhard Schölkopf</p></summary>
<p>

**Abstract:** In representation learning, a common approach is to seek representations which disentangle the underlying factors of variation. Eastwood & Williams (2018) proposed three metrics for quantifying the quality of such disentangled representations: disentanglement (D), completeness (C) and informativeness (I). In this work, we first connect this DCI framework to two common notions of linear and nonlinear identifiability, thus establishing a formal link between disentanglement and the closely-related field of independent component analysis. We then propose an extended DCI-ES framework with two new measures of representation quality - explicitness (E) and size (S) - and point out how D and C can be computed for black-box predictors. Our main idea is that the functional capacity required to use a representation is an important but thus-far neglected aspect of representation quality, which we quantify using explicitness or ease-of-use (E). We illustrate the relevance of our extensions on the MPI3D and Cars3D datasets.

</p>
</details>

<details><summary><b>Social and environmental impact of recent developments in machine learning on biology and chemistry research</b>
<a href="https://arxiv.org/abs/2210.00356">arxiv:2210.00356</a>
&#x1F4C8; 5 <br>
<p>Daniel Probst</p></summary>
<p>

**Abstract:** Potential societal and environmental effects such as the rapidly increasing resource use and the associated environmental impact, reproducibility issues, and exclusivity, the privatization of ML research leading to a public research brain-drain, a narrowing of the research effort caused by a focus on deep learning, and the introduction of biases through a lack of sociodemographic diversity in data and personnel caused by recent developments in machine learning are a current topic of discussion and scientific publications. However, these discussions and publications focus mainly on computer science-adjacent fields, including computer vision and natural language processing or basic ML research. Using bibliometric analysis of the complete and full-text analysis of the open-access literature, we show that the same observations can be made for applied machine learning in chemistry and biology. These developments can potentially affect basic and applied research, such as drug discovery and development, beyond the known issue of biased data sets.

</p>
</details>

<details><summary><b>Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening Problem</b>
<a href="https://arxiv.org/abs/2210.00411">arxiv:2210.00411</a>
&#x1F4C8; 4 <br>
<p>Xingyu Chen, Ruonan Zhang, Ji Jiang, Yan Wang, Ge Li, Thomas H. Li</p></summary>
<p>

**Abstract:** Self-supervised monocular depth estimation (MDE) models universally suffer from the notorious edge-fattening issue. Triplet loss, popular for metric learning, has made a great success in many computer vision tasks. In this paper, we redesign the patch-based triplet loss in MDE to alleviate the ubiquitous edge-fattening issue. We show two drawbacks of the raw triplet loss in MDE and demonstrate our problem-driven redesigns. First, we present a min. operator based strategy applied to all negative samples, to prevent well-performing negatives sheltering the error of edge-fattening negatives. Second, we split the anchor-positive distance and anchor-negative distance from within the original triplet, which directly optimizes the positives without any mutual effect with the negatives. Extensive experiments show the combination of these two small redesigns can achieve unprecedented results: Our powerful and versatile triplet loss not only makes our model outperform all previous SoTA by a large margin, but also provides substantial performance boosts to a large number of existing models, while introducing no extra inference computation at all.

</p>
</details>

<details><summary><b>Longitudinal Sentiment Analyses for Radicalization Research: Intertemporal Dynamics on Social Media Platforms and their Implications</b>
<a href="https://arxiv.org/abs/2210.00339">arxiv:2210.00339</a>
&#x1F4C8; 4 <br>
<p>Dennis Klinkhammer</p></summary>
<p>

**Abstract:** This discussion paper demonstrates how longitudinal sentiment analyses can depict intertemporal dynamics on social media platforms, what challenges are inherent and how further research could benefit from a longitudinal perspective. Furthermore and since tools for sentiment analyses shall simplify and accelerate the analytical process regarding qualitative data at acceptable inter-rater reliability, their applicability in the context of radicalization research will be examined regarding the Tweets collected on January 6th 2021, the day of the storming of the U.S. Capitol in Washington. Therefore, a total of 49,350 Tweets will be analyzed evenly distributed within three different sequences: before, during and after the U.S. Capitol in Washington was stormed. These sequences highlight the intertemporal dynamics within comments on social media platforms as well as the possible benefits of a longitudinal perspective when using conditional means and conditional variances. Limitations regarding the identification of supporters of such events and associated hate speech as well as common application errors will be demonstrated as well. As a result, only under certain conditions a longitudinal sentiment analysis can increase the accuracy of evidence based predictions in the context of radicalization research.

</p>
</details>

<details><summary><b>Clustering for directed graphs using parametrized random walk diffusion kernels</b>
<a href="https://arxiv.org/abs/2210.00310">arxiv:2210.00310</a>
&#x1F4C8; 4 <br>
<p>Harry Sevi, Matthieu Jonckheere, Argyris Kalogeratos</p></summary>
<p>

**Abstract:** Clustering based on the random walk operator has been proven effective for undirected graphs, but its generalization to directed graphs (digraphs) is much more challenging. Although the random walk operator is well-defined for digraphs, in most cases such graphs are not strongly connected, and hence the associated random walks are not irreducible, which is a crucial property for clustering that exists naturally in the undirected setting. To remedy this, the usual workaround is to either naively symmetrize the adjacency matrix or to replace the natural random walk operator by the teleporting random walk operator, but this can lead to the loss of valuable information carried by edge directionality. In this paper, we introduce a new clustering framework, the Parametrized Random Walk Diffusion Kernel Clustering (P-RWDKC), which is suitable for handling both directed and undirected graphs. Our framework is based on the diffusion geometry and the generalized spectral clustering framework. Accordingly, we propose an algorithm that automatically reveals the cluster structure at a given scale, by considering the random walk dynamics associated with a parametrized kernel operator, and by estimating its critical diffusion time. Experiments on $K$-NN graphs constructed from real-world datasets and real-world graphs show that our clustering approach performs well in all tested cases, and outperforms existing approaches in most of them.

</p>
</details>

<details><summary><b>An Ensemble of Convolutional Neural Networks to Detect Foliar Diseases in Apple Plants</b>
<a href="https://arxiv.org/abs/2210.00298">arxiv:2210.00298</a>
&#x1F4C8; 4 <br>
<p>Kush Vora, Dishant Padalia</p></summary>
<p>

**Abstract:** Apple diseases, if not diagnosed early, can lead to massive resource loss and pose a serious threat to humans and animals who consume the infected apples. Hence, it is critical to diagnose these diseases early in order to manage plant health and minimize the risks associated with them. However, the conventional approach of monitoring plant diseases entails manual scouting and analyzing the features, texture, color, and shape of the plant leaves, resulting in delayed diagnosis and misjudgments. Our work proposes an ensembled system of Xception, InceptionResNet, and MobileNet architectures to detect 5 different types of apple plant diseases. The model has been trained on the publicly available Plant Pathology 2021 dataset and can classify multiple diseases in a given plant leaf. The system has achieved outstanding results in multi-class and multi-label classification and can be used in a real-time setting to monitor large apple plantations to aid the farmers manage their yields effectively.

</p>
</details>

<details><summary><b>Differentiable Parsing and Visual Grounding of Verbal Instructions for Object Placement</b>
<a href="https://arxiv.org/abs/2210.00215">arxiv:2210.00215</a>
&#x1F4C8; 4 <br>
<p>Zirui Zhao, Wee Sun Lee, David Hsu</p></summary>
<p>

**Abstract:** Grounding spatial relations in natural language for object placing could have ambiguity and compositionality issues. To address the issues, we introduce ParaGon, a PARsing And visual GrOuNding framework for language-conditioned object placement. It parses language instructions into relations between objects and grounds those objects in visual scenes. A particle-based GNN then conducts relational reasoning between grounded objects for placement generation. ParaGon encodes all of those procedures into neural networks for end-to-end training, which avoids annotating parsing and object reference grounding labels. Our approach inherently integrates parsing-based methods into a probabilistic, data-driven framework. It is data-efficient and generalizable for learning compositional instructions, robust to noisy language inputs, and adapts to the uncertainty of ambiguous instructions.

</p>
</details>

<details><summary><b>Disentangling Mixtures of Unknown Causal Interventions</b>
<a href="https://arxiv.org/abs/2210.03242">arxiv:2210.03242</a>
&#x1F4C8; 3 <br>
<p>Abhinav Kumar, Gaurav Sinha</p></summary>
<p>

**Abstract:** In many real-world scenarios, such as gene knockout experiments, targeted interventions are often accompanied by unknown interventions at off-target sites. Moreover, different units can get randomly exposed to different unknown interventions, thereby creating a mixture of interventions. Identifying different components of this mixture can be very valuable in some applications. Motivated by such situations, in this work, we study the problem of identifying all components present in a mixture of interventions on a given causal Bayesian Network. We construct an example to show that, in general, the components are not identifiable from the mixture distribution. Next, assuming that the given network satisfies a positivity condition, we show that, if the set of mixture components satisfy a mild exclusion assumption, then they can be uniquely identified. Our proof gives an efficient algorithm to recover these targets from the exponentially large search space of possible targets. In the more realistic scenario, where distributions are given via finitely many samples, we conduct a simulation study to analyze the performance of an algorithm derived from our identifiability proof.

</p>
</details>

<details><summary><b>Bayesian Q-learning With Imperfect Expert Demonstrations</b>
<a href="https://arxiv.org/abs/2210.01800">arxiv:2210.01800</a>
&#x1F4C8; 3 <br>
<p>Fengdi Che, Xiru Zhu, Doina Precup, David Meger, Gregory Dudek</p></summary>
<p>

**Abstract:** Guided exploration with expert demonstrations improves data efficiency for reinforcement learning, but current algorithms often overuse expert information. We propose a novel algorithm to speed up Q-learning with the help of a limited amount of imperfect expert demonstrations. The algorithm avoids excessive reliance on expert data by relaxing the optimal expert assumption and gradually reducing the usage of uninformative expert data. Experimentally, we evaluate our approach on a sparse-reward chain environment and six more complicated Atari games with delayed rewards. With the proposed methods, we can achieve better results than Deep Q-learning from Demonstrations (Hester et al., 2017) in most environments.

</p>
</details>

<details><summary><b>Metric Distribution to Vector: Constructing Data Representation via Broad-Scale Discrepancies</b>
<a href="https://arxiv.org/abs/2210.00415">arxiv:2210.00415</a>
&#x1F4C8; 3 <br>
<p>Xue Liu, Dan Sun, Xiaobo Cao, Hao Ye, Wei Wei</p></summary>
<p>

**Abstract:** Graph embedding provides a feasible methodology to conduct pattern classification for graph-structured data by mapping each data into the vectorial space. Various pioneering works are essentially coding method that concentrates on a vectorial representation about the inner properties of a graph in terms of the topological constitution, node attributions, link relations, etc. However, the classification for each targeted data is a qualitative issue based on understanding the overall discrepancies within the dataset scale. From the statistical point of view, these discrepancies manifest a metric distribution over the dataset scale if the distance metric is adopted to measure the pairwise similarity or dissimilarity. Therefore, we present a novel embedding strategy named $\mathbf{MetricDistribution2vec}$ to extract such distribution characteristics into the vectorial representation for each data. We demonstrate the application and effectiveness of our representation method in the supervised prediction tasks on extensive real-world structural graph datasets. The results have gained some unexpected increases compared with a surge of baselines on all the datasets, even if we take the lightweight models as classifiers. Moreover, the proposed methods also conducted experiments in Few-Shot classification scenarios, and the results still show attractive discrimination in rare training samples based inference.

</p>
</details>

<details><summary><b>PCONet: A Convolutional Neural Network Architecture to Detect Polycystic Ovary Syndrome (PCOS) from Ovarian Ultrasound Images</b>
<a href="https://arxiv.org/abs/2210.00407">arxiv:2210.00407</a>
&#x1F4C8; 3 <br>
<p>A. K. M. Salman Hosain, Md Humaion Kabir Mehedi, Irteza Enan Kabir</p></summary>
<p>

**Abstract:** Polycystic Ovary Syndrome (PCOS) is an endrocrinological dysfunction prevalent among women of reproductive age. PCOS is a combination of syndromes caused by an excess of androgens - a group of sex hormones - in women. Syndromes including acne, alopecia, hirsutism, hyperandrogenaemia, oligo-ovulation, etc. are caused by PCOS. It is also a major cause of female infertility. An estimated 15% of reproductive-aged women are affected by PCOS globally. The necessity of detecting PCOS early due to the severity of its deleterious effects cannot be overstated. In this paper, we have developed PCONet - a Convolutional Neural Network (CNN) - to detect polycistic ovary from ovarian ultrasound images. We have also fine tuned InceptionV3 - a pretrained convolutional neural network of 45 layers - by utilizing the transfer learning method to classify polcystic ovarian ultrasound images. We have compared these two models on various quantitative performance evaluation parameters and demonstrated that PCONet is the superior one among these two with an accuracy of 98.12%, whereas the fine tuned InceptionV3 showcased an accuracy of 96.56% on test images.

</p>
</details>

<details><summary><b>Convolutional Neural Networks on Manifolds: From Graphs and Back</b>
<a href="https://arxiv.org/abs/2210.00376">arxiv:2210.00376</a>
&#x1F4C8; 3 <br>
<p>Zhiyang Wang, Luana Ruiz, Alejandro Ribeiro</p></summary>
<p>

**Abstract:** Geometric deep learning has gained much attention in recent years due to more available data acquired from non-Euclidean domains. Some examples include point clouds for 3D models and wireless sensor networks in communications. Graphs are common models to connect these discrete data points and capture the underlying geometric structure. With the large amount of these geometric data, graphs with arbitrarily large size tend to converge to a limit model -- the manifold. Deep neural network architectures have been proved as a powerful technique to solve problems based on these data residing on the manifold. In this paper, we propose a manifold neural network (MNN) composed of a bank of manifold convolutional filters and point-wise nonlinearities. We define a manifold convolution operation which is consistent with the discrete graph convolution by discretizing in both space and time domains. To sum up, we focus on the manifold model as the limit of large graphs and construct MNNs, while we can still bring back graph neural networks by the discretization of MNNs. We carry out experiments based on point-cloud dataset to showcase the performance of our proposed MNNs.

</p>
</details>

<details><summary><b>Gait-based Age Group Classification with Adaptive Graph Neural Network</b>
<a href="https://arxiv.org/abs/2210.00294">arxiv:2210.00294</a>
&#x1F4C8; 3 <br>
<p>Timilehin B. Aderinola, Tee Connie, Thian Song Ong, Andrew Beng Jin Teoh, Michael Kah Ong Goh</p></summary>
<p>

**Abstract:** Deep learning techniques have recently been utilized for model-free age-associated gait feature extraction. However, acquiring model-free gait demands accurate pre-processing such as background subtraction, which is non-trivial in unconstrained environments. On the other hand, model-based gait can be obtained without background subtraction and is less affected by covariates. For model-based gait-based age group classification problems, present works rely solely on handcrafted features, where feature extraction is tedious and requires domain expertise. This paper proposes a deep learning approach to extract age-associated features from model-based gait for age group classification. Specifically, we first develop an unconstrained gait dataset called Multimedia University Gait Age and Gender dataset (MMU GAG). Next, the body joint coordinates are determined via pose estimation algorithms and represented as compact gait graphs via a novel part aggregation scheme. Then, a Part-AdaptIve Residual Graph Convolutional Neural Network (PairGCN) is designed for age-associated feature learning. Experiments suggest that PairGCN features are far more informative than handcrafted features, yielding up to 99% accuracy for classifying subjects as a child, adult, or senior in the MMU GAG dataset.

</p>
</details>

<details><summary><b>Deep Intrinsically Motivated Exploration in Continuous Control</b>
<a href="https://arxiv.org/abs/2210.00293">arxiv:2210.00293</a>
&#x1F4C8; 3 <br>
<p>Baturay Saglam, Suleyman S. Kozat</p></summary>
<p>

**Abstract:** In continuous control, exploration is often performed through undirected strategies in which parameters of the networks or selected actions are perturbed by random noise. Although the deep setting of undirected exploration has been shown to improve the performance of on-policy methods, they introduce an excessive computational complexity and are known to fail in the off-policy setting. The intrinsically motivated exploration is an effective alternative to the undirected strategies, but they are usually studied for discrete action domains. In this paper, we investigate how intrinsic motivation can effectively be combined with deep reinforcement learning in the control of continuous systems to obtain a directed exploratory behavior. We adapt the existing theories on animal motivational systems into the reinforcement learning paradigm and introduce a novel and scalable directed exploration strategy. The introduced approach, motivated by the maximization of the value function's error, can benefit from a collected set of experiences by extracting useful information and unify the intrinsic exploration motivations in the literature under a single exploration objective. An extensive set of empirical studies demonstrate that our framework extends to larger and more diverse state spaces, dramatically improves the baselines, and outperforms the undirected strategies significantly.

</p>
</details>

<details><summary><b>Det-SLAM: A semantic visual SLAM for highly dynamic scenes using Detectron2</b>
<a href="https://arxiv.org/abs/2210.00278">arxiv:2210.00278</a>
&#x1F4C8; 3 <br>
<p>Ali Eslamian, Mohammad R. Ahmadzadeh</p></summary>
<p>

**Abstract:** According to experts, Simultaneous Localization and Mapping (SLAM) is an intrinsic part of autonomous robotic systems. Several SLAM systems with impressive performance have been invented and used during the last several decades. However, there are still unresolved issues, such as how to deal with moving objects in dynamic situations. Classic SLAM systems depend on the assumption of a static environment, which becomes unworkable in highly dynamic situations. Several methods have been presented to tackle this issue in recent years, but each has its limitations. This research combines the visual SLAM systems ORB-SLAM3 and Detectron2 to present the Det-SLAM system, which employs depth information and semantic segmentation to identify and eradicate dynamic spots to accomplish semantic SLAM for dynamic situations. Evaluation of public TUM datasets indicates that Det-SLAM is more resilient than previous dynamic SLAM systems and can lower the estimated error of camera posture in dynamic indoor scenarios.

</p>
</details>

<details><summary><b>Attention Augmented ConvNeXt UNet For Rectal Tumour Segmentation</b>
<a href="https://arxiv.org/abs/2210.00227">arxiv:2210.00227</a>
&#x1F4C8; 3 <br>
<p>Hongwei Wu, Junlin Wang, Xin Wang, Hui Nan, Yaxin Wang, Haonan Jing, Kaixuan Shi</p></summary>
<p>

**Abstract:** It is a challenge to segment the location and size of rectal cancer tumours through deep learning. In this paper, in order to improve the ability of extracting suffi-cient feature information in rectal tumour segmentation, attention enlarged ConvNeXt UNet (AACN-UNet), is proposed. The network mainly includes two improvements: 1) the encoder stage of UNet is changed to ConvNeXt structure for encoding operation, which can not only integrate multi-scale semantic information on a large scale, but al-so reduce information loss and extract more feature information from CT images; 2) CBAM attention mechanism is added to improve the connection of each feature in channel and space, which is conducive to extracting the effective feature of the target and improving the segmentation accuracy.The experiment with UNet and its variant network shows that AACN-UNet is 0.9% ,1.1% and 1.4% higher than the current best results in P, F1 and Miou.Compared with the training time, the number of parameters in UNet network is less. This shows that our proposed AACN-UNet has achieved ex-cellent results in CT image segmentation of rectal cancer.

</p>
</details>

<details><summary><b>STGIN: A Spatial Temporal Graph-Informer Network for Long Sequence Traffic Speed Forecasting</b>
<a href="https://arxiv.org/abs/2210.01799">arxiv:2210.01799</a>
&#x1F4C8; 2 <br>
<p>Ruikang Luo, Yaofeng Song, Liping Huang, Yicheng Zhang, Rong Su</p></summary>
<p>

**Abstract:** Accurate long series forecasting of traffic information is critical for the development of intelligent traffic systems. We may benefit from the rapid growth of neural network analysis technology to better understand the underlying functioning patterns of traffic networks as a result of this progress. Due to the fact that traffic data and facility utilization circumstances are sequentially dependent on past and present situations, several related neural network techniques based on temporal dependency extraction models have been developed to solve the problem. The complicated topological road structure, on the other hand, amplifies the effect of spatial interdependence, which cannot be captured by pure temporal extraction approaches. Additionally, the typical Deep Recurrent Neural Network (RNN) topology has a constraint on global information extraction, which is required for comprehensive long-term prediction. This study proposes a new spatial-temporal neural network architecture, called Spatial-Temporal Graph-Informer (STGIN), to handle the long-term traffic parameters forecasting issue by merging the Informer and Graph Attention Network (GAT) layers for spatial and temporal relationships extraction. The attention mechanism potentially guarantees long-term prediction performance without significant information loss from distant inputs. On two real-world traffic datasets with varying horizons, experimental findings validate the long sequence prediction abilities, and further interpretation is provided.

</p>
</details>

<details><summary><b>Tensor-reduced atomic density representations</b>
<a href="https://arxiv.org/abs/2210.01705">arxiv:2210.01705</a>
&#x1F4C8; 2 <br>
<p>James P. Darby, Dávid P. Kovács, Ilyes Batatia, Miguel A. Caro, Gus L. W. Hart, Christoph Ortner, Gábor Csányi</p></summary>
<p>

**Abstract:** Density based representations of atomic environments that are invariant under Euclidean symmetries have become a widely used tool in the machine learning of interatomic potentials, broader data-driven atomistic modelling and the visualisation and analysis of materials datasets.The standard mechanism used to incorporate chemical element information is to create separate densities for each element and form tensor products between them. This leads to a steep scaling in the size of the representation as the number of elements increases. Graph neural networks, which do not explicitly use density representations, escape this scaling by mapping the chemical element information into a fixed dimensional space in a learnable way. We recast this approach as tensor factorisation by exploiting the tensor structure of standard neighbour density based descriptors. In doing so, we form compact tensor-reduced representations whose size does not depend on the number of chemical elements, but remain systematically convergeable and are therefore applicable to a wide range of data analysis and regression tasks.

</p>
</details>

<details><summary><b>Systematic Generalization and Emergent Structures in Transformers Trained on Structured Tasks</b>
<a href="https://arxiv.org/abs/2210.00400">arxiv:2210.00400</a>
&#x1F4C8; 2 <br>
<p>Yuxuan Li, James L. McClelland</p></summary>
<p>

**Abstract:** Transformer networks have seen great success in natural language processing and machine vision, where task objectives such as next word prediction and image classification benefit from nuanced context sensitivity across high-dimensional inputs. However, there is an ongoing debate about how and when transformers can acquire highly structured behavior and achieve systematic generalization. Here, we explore how well a causal transformer can perform a set of algorithmic tasks, including copying, sorting, and hierarchical compositions of these operations. We demonstrate strong generalization to sequences longer than those used in training by replacing the standard positional encoding typically used in transformers with labels arbitrarily paired with items in the sequence. By finding the layer and head configuration sufficient to solve the task, then performing ablation experiments and representation analysis, we show that two-layer transformers learn generalizable solutions to multi-level problems and develop signs of systematic task decomposition. They also exploit shared computation across related tasks. These results provide key insights into how transformer models may be capable of decomposing complex decisions into reusable, multi-level policies in tasks requiring structured behavior.

</p>
</details>

<details><summary><b>Causal Knowledge Transfer from Task Affinity</b>
<a href="https://arxiv.org/abs/2210.00380">arxiv:2210.00380</a>
&#x1F4C8; 2 <br>
<p>Ahmed Aloui, Juncheng Dong, Cat P. Le, Vahid Tarokh</p></summary>
<p>

**Abstract:** Recent developments in deep representation models through counterfactual balancing have led to a promising framework for estimating Individual Treatment Effects (ITEs) that are essential to causal inference in the Neyman-Rubin potential outcomes framework. While Randomized Control Trials are vital to understanding causal effects, they are sometimes infeasible, costly, or unethical to conduct. Motivated by these potential obstacles to data acquisition, we focus on transferring the causal knowledge acquired in prior experiments to new scenarios for which only limited data is available. To this end, we first observe that the absolute values of ITEs are invariant under the action of the symmetric group on the labels of treatments. Given this invariance, we propose a symmetrized task distance for calculating the similarity of a target scenario with those encountered before. The aforementioned task distance is then used to transfer causal knowledge from the closest of all the available previously learned tasks to the target scenario. We provide upper bounds on the counterfactual loss and ITE error of the target task indicating the transferability of causal knowledge. Empirical studies are provided for various real-world, semi-synthetic, and synthetic datasets demonstrating that the proposed symmetrized task distance is strongly related to the estimation of the counterfactual loss. Numerical results indicate that transferring causal knowledge reduces the amount of required data by up to 95% when compared to training from scratch. These results reveal the promise of our method when applied to important albeit challenging real-world scenarios such as transferring the knowledge of treatment effects (e.g., medicine, social policy, personal training, etc.) studied on a population to other groups absent in the study.

</p>
</details>

<details><summary><b>Zero-Shot Policy Transfer with Disentangled Task Representation of Meta-Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.00350">arxiv:2210.00350</a>
&#x1F4C8; 2 <br>
<p>Zheng Wu, Yichen Xie, Wenzhao Lian, Changhao Wang, Yanjiang Guo, Jianyu Chen, Stefan Schaal, Masayoshi Tomizuka</p></summary>
<p>

**Abstract:** Humans are capable of abstracting various tasks as different combinations of multiple attributes. This perspective of compositionality is vital for human rapid learning and adaption since previous experiences from related tasks can be combined to generalize across novel compositional settings. In this work, we aim to achieve zero-shot policy generalization of Reinforcement Learning (RL) agents by leveraging the task compositionality. Our proposed method is a meta- RL algorithm with disentangled task representation, explicitly encoding different aspects of the tasks. Policy generalization is then performed by inferring unseen compositional task representations via the obtained disentanglement without extra exploration. The evaluation is conducted on three simulated tasks and a challenging real-world robotic insertion task. Experimental results demonstrate that our proposed method achieves policy generalization to unseen compositional tasks in a zero-shot manner.

</p>
</details>

<details><summary><b>Speed Up the Cold-Start Learning in Two-Sided Bandits with Many Arms</b>
<a href="https://arxiv.org/abs/2210.00340">arxiv:2210.00340</a>
&#x1F4C8; 2 <br>
<p>Mohsen Bayati, Junyu Cao, Wanning Chen</p></summary>
<p>

**Abstract:** Multi-armed bandit (MAB) algorithms are efficient approaches to reduce the opportunity cost of online experimentation and are used by companies to find the best product from periodically refreshed product catalogs. However, these algorithms face the so-called cold-start at the onset of the experiment due to a lack of knowledge of customer preferences for new products, requiring an initial data collection phase known as the burning period. During this period, MAB algorithms operate like randomized experiments, incurring large burning costs which scale with the large number of products. We attempt to reduce the burning by identifying that many products can be cast into two-sided products, and then naturally model the rewards of the products with a matrix, whose rows and columns represent the two sides respectively. Next, we design two-phase bandit algorithms that first use subsampling and low-rank matrix estimation to obtain a substantially smaller targeted set of products and then apply a UCB procedure on the target products to find the best one. We theoretically show that the proposed algorithms lower costs and expedite the experiment in cases when there is limited experimentation time along with a large product set. Our analysis also reveals three regimes of long, short, and ultra-short horizon experiments, depending on dimensions of the matrix. Empirical evidence from both synthetic data and a real-world dataset on music streaming services validates this superior performance.

</p>
</details>

<details><summary><b>Deep Recurrent Q-learning for Energy-constrained Coverage with a Mobile Robot</b>
<a href="https://arxiv.org/abs/2210.00327">arxiv:2210.00327</a>
&#x1F4C8; 2 <br>
<p>Aaron Zellner, Ayan Dutta, Iliya Kulbaka, Gokarna Sharma</p></summary>
<p>

**Abstract:** In this paper, we study the problem of coverage of an environment with an energy-constrained robot in the presence of multiple charging stations. As the robot's on-board power supply is limited, it might not have enough energy to cover all the points in the environment with a single charge. Instead, it will need to stop at one or more charging stations to recharge its battery intermittently. The robot cannot violate the energy constraint, i.e., visit a location with negative available energy. To solve this problem, we propose a deep Q-learning framework that produces a policy to maximize the coverage and minimize the budget violations. Our proposed framework also leverages the memory of a recurrent neural network (RNN) to better suit this multi-objective optimization problem. We have tested the presented framework within a 16 x 16 grid environment having charging stations and various obstacle configurations. Results show that our proposed method finds feasible solutions and outperforms a comparable existing technique.

</p>
</details>

<details><summary><b>MALM: Mixing Augmented Language Modeling for Zero-Shot Machine Translation</b>
<a href="https://arxiv.org/abs/2210.00320">arxiv:2210.00320</a>
&#x1F4C8; 2 <br>
<p>Kshitij Gupta</p></summary>
<p>

**Abstract:** Large pre-trained language models have brought remarkable progress in NLP. Pre-training and Fine-tuning have given state-of-art performance across tasks in text processing. Data Augmentation techniques have also helped build state-of-art models on low or zero resource tasks. Many works in the past have attempted at learning a single massively-multilingual machine translation model for zero-shot translation. Although those translation models are producing correct translations, the main challenge is those models are producing the wrong languages for zero-shot translation. This work and its results indicate that prompt conditioned large models do not suffer from off-target language errors i.e. errors arising due to translation to wrong languages. We empirically demonstrate the effectiveness of self-supervised pre-training and data augmentation for zero-shot multi-lingual machine translation.

</p>
</details>

<details><summary><b>CAST: Concurrent Recognition and Segmentation with Adaptive Segment Tokens</b>
<a href="https://arxiv.org/abs/2210.00314">arxiv:2210.00314</a>
&#x1F4C8; 2 <br>
<p>Tsung-Wei Ke, Jyh-Jing Hwang, Stella X. Yu</p></summary>
<p>

**Abstract:** Recognizing an image and segmenting it into coherent regions are often treated as separate tasks. Human vision, however, has a general sense of segmentation hierarchy before recognition occurs. We are thus inspired to learn image recognition with hierarchical image segmentation based entirely on unlabeled images. Our insight is to learn fine-to-coarse features concurrently at superpixels, segments, and full image levels, enforcing consistency and goodness of feature induced segmentations while maximizing discrimination among image instances.
  Our model innovates vision transformers on three aspects. 1) We use adaptive segment tokens instead of fixed-shape patch tokens. 2) We create a token hierarchy by inserting graph pooling between transformer blocks, naturally producing consistent multi-scale segmentations while increasing the segment size and reducing the number of tokens. 3) We produce hierarchical image segmentation for free while training for recognition by maximizing image-wise discrimination.
  Our work delivers the first concurrent recognition and hierarchical segmentation model without any supervision. Validated on ImageNet and PASCAL VOC, it achieves better recognition and segmentation with higher computational efficiency.

</p>
</details>

<details><summary><b>CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family</b>
<a href="https://arxiv.org/abs/2210.00313">arxiv:2210.00313</a>
&#x1F4C8; 2 <br>
<p>S Ashwin Hebbar, Viraj Nadkarni, Ashok Vardhan Makkuva, Suma Bhat, Sewoong Oh, Pramod Viswanath</p></summary>
<p>

**Abstract:** Polar codes are widely used state-of-the-art codes for reliable communication that have recently been included in the 5th generation wireless standards (5G). However, there remains room for the design of polar decoders that are both efficient and reliable in the short blocklength regime. Motivated by recent successes of data-driven channel decoders, we introduce a novel $\textbf{C}$ur$\textbf{RI}$culum based $\textbf{S}$equential neural decoder for $\textbf{P}$olar codes (CRISP). We design a principled curriculum, guided by information-theoretic insights, to train CRISP and show that it outperforms the successive-cancellation (SC) decoder and attains near-optimal reliability performance on the Polar(16,32) and Polar(22, 64) codes. The choice of the proposed curriculum is critical in achieving the accuracy gains of CRISP, as we show by comparing against other curricula. More notably, CRISP can be readily extended to Polarization-Adjusted-Convolutional (PAC) codes, where existing SC decoders are significantly less reliable. To the best of our knowledge, CRISP constructs the first data-driven decoder for PAC codes and attains near-optimal performance on the PAC(16, 32) code.

</p>
</details>

<details><summary><b>DeltaBound Attack: Efficient decision-based attack in low queries regime</b>
<a href="https://arxiv.org/abs/2210.00292">arxiv:2210.00292</a>
&#x1F4C8; 2 <br>
<p>Lorenzo Rossi</p></summary>
<p>

**Abstract:** Deep neural networks and other machine learning systems, despite being extremely powerful and able to make predictions with high accuracy, are vulnerable to adversarial attacks. We proposed the DeltaBound attack: a novel, powerful attack in the hard-label setting with $\ell_2$ norm bounded perturbations. In this scenario, the attacker has only access to the top-1 predicted label of the model and can be therefore applied to real-world settings such as remote API. This is a complex problem since the attacker has very little information about the model. Consequently, most of the other techniques present in the literature require a massive amount of queries for attacking a single example. Oppositely, this work mainly focuses on the evaluation of attack's power in the low queries regime $\leq 1000$ queries) with $\ell_2$ norm in the hard-label settings. We find that the DeltaBound attack performs as well and sometimes better than current state-of-the-art attacks while remaining competitive across different kinds of models. Moreover, we evaluate our method against not only deep neural networks, but also non-deep learning models, such as Gradient Boosting Decision Trees and Multinomial Naive Bayes.

</p>
</details>

<details><summary><b>Fine-tuning Wav2vec for Vocal-burst Emotion Recognition</b>
<a href="https://arxiv.org/abs/2210.00263">arxiv:2210.00263</a>
&#x1F4C8; 2 <br>
<p>Dang-Khanh Nguyen, Sudarshan Pant, Ngoc-Huynh Ho, Guee-Sang Lee, Soo-Huyng Kim, Hyung-Jeong Yang</p></summary>
<p>

**Abstract:** The ACII Affective Vocal Bursts (A-VB) competition introduces a new topic in affective computing, which is understanding emotional expression using the non-verbal sound of humans. We are familiar with emotion recognition via verbal vocal or facial expression. However, the vocal bursts such as laughs, cries, and signs, are not exploited even though they are very informative for behavior analysis. The A-VB competition comprises four tasks that explore non-verbal information in different spaces. This technical report describes the method and the result of SclabCNU Team for the tasks of the challenge. We achieved promising results compared to the baseline model provided by the organizers.

</p>
</details>

<details><summary><b>Cascaded Multi-Modal Mixing Transformers for Alzheimer's Disease Classification with Incomplete Data</b>
<a href="https://arxiv.org/abs/2210.00255">arxiv:2210.00255</a>
&#x1F4C8; 2 <br>
<p>Linfeng Liu, Siyu Liu, Lu Zhang, Xuan Vinh To, Fatima Nasrallah, Shekhar S. Chandra</p></summary>
<p>

**Abstract:** Accurate medical classification requires a large number of multi-modal data, and in many cases, in different formats. Previous studies have shown promising results when using multi-modal data, outperforming single-modality models on when classifying disease such as AD. However, those models are usually not flexible enough to handle missing modalities. Currently, the most common workaround is excluding samples with missing modalities which leads to considerable data under-utilisation. Adding to the fact that labelled medical images are already scarce, the performance of data-driven methods like deep learning is severely hampered. Therefore, a multi-modal method that can gracefully handle missing data in various clinical settings is highly desirable. In this paper, we present the Multi-Modal Mixing Transformer (3MT), a novel Transformer for disease classification based on multi-modal data. In this work, we test it for \ac{AD} or \ac{CN} classification using neuroimaging data, gender, age and MMSE scores. The model uses a novel Cascaded Modality Transformers architecture with cross-attention to incorporate multi-modal information for more informed predictions. Auxiliary outputs and a novel modality dropout mechanism were incorporated to ensure an unprecedented level of modality independence and robustness. The result is a versatile network that enables the mixing of an unlimited number of modalities with different formats and full data utilization. 3MT was first tested on the ADNI dataset and achieved state-of-the-art test accuracy of $0.987\pm0.0006$. To test its generalisability, 3MT was directly applied to the AIBL after training on the ADNI dataset, and achieved a test accuracy of $0.925\pm0.0004$ without fine-tuning. Finally, we show that Grad-CAM visualizations are also possible with our model for explainable results.

</p>
</details>

<details><summary><b>Efficient Quantum Agnostic Improper Learning of Decision Trees</b>
<a href="https://arxiv.org/abs/2210.00212">arxiv:2210.00212</a>
&#x1F4C8; 2 <br>
<p>Debajyoti Bera, Sagnik Chatterjee</p></summary>
<p>

**Abstract:** The agnostic setting is the hardest generalization of the PAC model since it is akin to learning with adversarial noise. We study an open question on the existence of efficient quantum boosting algorithms in this setting. We answer this question in the affirmative by providing a quantum version of the Kalai-Kanade potential boosting algorithm. This algorithm shows the standard quadratic speedup in the VC dimension of the weak learner compared to the classical case.
  Using our boosting algorithm as a subroutine, we give a quantum algorithm for agnostically learning decision trees in polynomial running time without using membership queries. To the best of our knowledge, this is the first algorithm (quantum or classical) to do so. Learning decision trees without membership queries is hard (and an open problem) in the standard classical realizable setting. In general, even coming up with weak learners in the agnostic setting is a challenging task. We show how to construct a quantum agnostic weak learner using standard quantum algorithms, which is of independent interest for designing ensemble learning setups.

</p>
</details>

<details><summary><b>Adversarial Attacks on Transformers-Based Malware Detectors</b>
<a href="https://arxiv.org/abs/2210.00008">arxiv:2210.00008</a>
&#x1F4C8; 2 <br>
<p>Yash Jakhotiya, Heramb Patil, Jugal Rawlani</p></summary>
<p>

**Abstract:** Signature-based malware detectors have proven to be insufficient as even a small change in malignant executable code can bypass these signature-based detectors. Many machine learning-based models have been proposed to efficiently detect a wide variety of malware. Many of these models are found to be susceptible to adversarial attacks - attacks that work by generating intentionally designed inputs that can force these models to misclassify. Our work aims to explore vulnerabilities in the current state of the art malware detectors to adversarial attacks. We train a Transformers-based malware detector, carry out adversarial attacks resulting in a misclassification rate of 23.9% and propose defenses that reduce this misclassification rate to half. An implementation of our work can be found at https://github.com/yashjakhotiya/Adversarial-Attacks-On-Transformers.

</p>
</details>

<details><summary><b>Supervised Parameter Estimation of Neuron Populations from Multiple Firing Events</b>
<a href="https://arxiv.org/abs/2210.01767">arxiv:2210.01767</a>
&#x1F4C8; 1 <br>
<p>Long Le, Yao Li</p></summary>
<p>

**Abstract:** The firing dynamics of biological neurons in mathematical models is often determined by the model's parameters, representing the neurons' underlying properties. The parameter estimation problem seeks to recover those parameters of a single neuron or a neuron population from their responses to external stimuli and interactions between themselves. Most common methods for tackling this problem in the literature use some mechanistic models in conjunction with either a simulation-based or solution-based optimization scheme. In this paper, we study an automatic approach of learning the parameters of neuron populations from a training set consisting of pairs of spiking series and parameter labels via supervised learning. Unlike previous work, this automatic learning does not require additional simulations at inference time nor expert knowledge in deriving an analytical solution or in constructing some approximate models. We simulate many neuronal populations with different parameter settings using a stochastic neuron model. Using that data, we train a variety of supervised machine learning models, including convolutional and deep neural networks, random forest, and support vector regression. We then compare their performance against classical approaches including a genetic search, Bayesian sequential estimation, and a random walk approximate model. The supervised models almost always outperform the classical methods in parameter estimation and spike reconstruction errors, and computation expense. Convolutional neural network, in particular, is the best among all models across all metrics. The supervised models can also generalize to out-of-distribution data to a certain extent.

</p>
</details>

<details><summary><b>Subspace Learning for Feature Selection via Rank Revealing QR Factorization: Unsupervised and Hybrid Approaches with Non-negative Matrix Factorization and Evolutionary Algorithm</b>
<a href="https://arxiv.org/abs/2210.00418">arxiv:2210.00418</a>
&#x1F4C8; 1 <br>
<p>Amir Moslemi, Arash Ahmadian</p></summary>
<p>

**Abstract:** The selection of most informative and discriminative features from high-dimensional data has been noticed as an important topic in machine learning and data engineering. Using matrix factorization-based techniques such as nonnegative matrix factorization for feature selection has emerged as a hot topic in feature selection. The main goal of feature selection using matrix factorization is to extract a subspace which approximates the original space but in a lower dimension. In this study, rank revealing QR (RRQR) factorization, which is computationally cheaper than singular value decomposition (SVD), is leveraged in obtaining the most informative features as a novel unsupervised feature selection technique. This technique uses the permutation matrix of QR for feature selection which is a unique property to this factorization method. Moreover, QR factorization is embedded into non-negative matrix factorization (NMF) objective function as a new unsupervised feature selection method. Lastly, a hybrid feature selection algorithm is proposed by coupling RRQR, as a filter-based technique, and a Genetic algorithm as a wrapper-based technique. In this method, redundant features are removed using RRQR factorization and the most discriminative subset of features are selected using the Genetic algorithm. The proposed algorithm shows to be dependable and robust when compared against state-of-the-art feature selection algorithms in supervised, unsupervised, and semi-supervised settings. All methods are tested on seven available microarray datasets using KNN, SVM and C4.5 classifiers. In terms of evaluation metrics, the experimental results shows that the proposed method is comparable with the state-of-the-art feature selection.

</p>
</details>

<details><summary><b>Identifying Selections Operating on HIV-1 Reverse Transcriptase via Uniform Manifold Approximation and Projection</b>
<a href="https://arxiv.org/abs/2210.00345">arxiv:2210.00345</a>
&#x1F4C8; 1 <br>
<p>Shefali Qamar, Manel Camps, Jay Kim</p></summary>
<p>

**Abstract:** We analyze 14,651 HIV1 reverse transcriptase (HIV RT) sequences from the Stanford HIV Drug Resistance Database labeled with treatment regimen in order to study the evolution this enzyme under drug selection in the clinic. Our goal is to identify distinct sectors of HIV RT's sequence space that are undergoing evolution as a way to identify individual selections and/or evolutionary solutions. We utilize Uniform Manifold Approximation and Projection (UMAP), a graph-based dimensionality reduction technique uniquely suited for the detection of non-linear dependencies and visualize the results using an unsupervised clustering algorithm based on density analysis. Our analysis produced 21 distinct clusters of sequences. Supporting the biological significance of these clusters, they tend to represent phylogenetically related sequences with strong correspondence to distinct treatment regimens. Thus, this method for visualization of areas of HIV RT undergoing evolution can help infer information about selective pressures, although it is correlative. The mutation signatures associated with each cluster may represent the higher-order epistatic context facilitating these evolutionary pathways, information that is generally not accessible by other types of mutational co-dependence analyses.

</p>
</details>

<details><summary><b>Privacy-preserving Decentralized Federated Learning over Time-varying Communication Graph</b>
<a href="https://arxiv.org/abs/2210.00325">arxiv:2210.00325</a>
&#x1F4C8; 1 <br>
<p>Yang Lu, Zhengxin Yu, Neeraj Suri</p></summary>
<p>

**Abstract:** Establishing how a set of learners can provide privacy-preserving federated learning in a fully decentralized (peer-to-peer, no coordinator) manner is an open problem. We propose the first privacy-preserving consensus-based algorithm for the distributed learners to achieve decentralized global model aggregation in an environment of high mobility, where the communication graph between the learners may vary between successive rounds of model aggregation. In particular, in each round of global model aggregation, the Metropolis-Hastings method is applied to update the weighted adjacency matrix based on the current communication topology. In addition, the Shamir's secret sharing scheme is integrated to facilitate privacy in reaching consensus of the global model. The paper establishes the correctness and privacy properties of the proposed algorithm. The computational efficiency is evaluated by a simulation built on a federated learning framework with a real-word dataset.

</p>
</details>

<details><summary><b>NeuroEvo: A Cloud-based Platform for Automated Design and Training of Neural Networks using Evolutionary and Particle Swarm Algorithms</b>
<a href="https://arxiv.org/abs/2210.00286">arxiv:2210.00286</a>
&#x1F4C8; 1 <br>
<p>Philip Schroeder</p></summary>
<p>

**Abstract:** Evolutionary algorithms (EAs) provide unique advantages for optimizing neural networks in complex search spaces. This paper introduces a new web platform, NeuroEvo (neuroevo.io), that allows users to interactively design and train neural network classifiers using evolutionary and particle swarm algorithms. The classification problem and training data are provided by the user and, upon completion of the training process, the best classifier is made available to download and implement in Python, Java, and JavaScript. NeuroEvo is a cloud-based application that leverages GPU parallelization to improve the speed with which the independent evolutionary steps, such as mutation, crossover, and fitness evaluation, are executed across the population. This paper outlines the training algorithms and opportunities for users to specify design decisions and hyperparameter settings. The algorithms described in this paper are also made available as a Python package, neuroevo (PyPI: https://pypi.org/project/neuroevo/).

</p>
</details>

<details><summary><b>Construction and Evaluation of a Self-Attention Model for Semantic Understanding of Sentence-Final Particles</b>
<a href="https://arxiv.org/abs/2210.00282">arxiv:2210.00282</a>
&#x1F4C8; 1 <br>
<p>Shuhei Mandokoro, Natsuki Oka, Akane Matsushima, Chie Fukada, Yuko Yoshimura, Koji Kawahara, Kazuaki Tanaka</p></summary>
<p>

**Abstract:** Sentence-final particles serve an essential role in spoken Japanese because they express the speaker's mental attitudes toward a proposition and/or an interlocutor. They are acquired at early ages and occur very frequently in everyday conversation. However, there has been little proposal for a computational model of acquiring sentence-final particles. This paper proposes Subjective BERT, a self-attention model that takes various subjective senses in addition to language and images as input and learns the relationship between words and subjective senses. An evaluation experiment revealed that the model understands the usage of "yo", which expresses the speaker's intention to communicate new information, and that of "ne", which denotes the speaker's desire to confirm that some information is shared.

</p>
</details>


{% endraw %}
Prev: [2022.09.30]({{ '/2022/09/30/2022.09.30.html' | relative_url }})  Next: [2022.10.02]({{ '/2022/10/02/2022.10.02.html' | relative_url }})