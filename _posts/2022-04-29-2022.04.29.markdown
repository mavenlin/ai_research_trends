Prev: [2022.04.28]({{ '/2022/04/28/2022.04.28.html' | relative_url }})  Next: [2022.04.30]({{ '/2022/04/30/2022.04.30.html' | relative_url }})
{% raw %}
## Summary for 2022-04-29, created on 2022-05-03


<details><summary><b>Flamingo: a Visual Language Model for Few-Shot Learning</b>
<a href="https://arxiv.org/abs/2204.14198">arxiv:2204.14198</a>
&#x1F4C8; 7810 <br>
<p>Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol Vinyals</p></summary>
<p>

**Abstract:** Building models that can be rapidly adapted to numerous tasks using only a handful of annotated examples is an open challenge for multimodal machine learning research. We introduce Flamingo, a family of Visual Language Models (VLM) with this ability. Flamingo models include key architectural innovations to: (i) bridge powerful pretrained vision-only and language-only models, (ii) handle sequences of arbitrarily interleaved visual and textual data, and (iii) seamlessly ingest images or videos as inputs. Thanks to their flexibility, Flamingo models can be trained on large-scale multimodal web corpora containing arbitrarily interleaved text and images, which is key to endow them with in-context few-shot learning capabilities. We perform a thorough evaluation of the proposed Flamingo models, exploring and measuring their ability to rapidly adapt to a variety of image and video understanding benchmarks. These include open-ended tasks such as visual question-answering, where the model is prompted with a question which it has to answer, captioning tasks, which evaluate the ability to describe a scene or an event, and close-ended tasks such as multiple choice visual question-answering. For tasks lying anywhere on this spectrum, we demonstrate that a single Flamingo model can achieve a new state of the art for few-shot learning, simply by prompting the model with task-specific examples. On many of these benchmarks, Flamingo actually surpasses the performance of models that are fine-tuned on thousands of times more task-specific data.

</p>
</details>

<details><summary><b>Unsupervised Reinforcement Learning for Transferable Manipulation Skill Discovery</b>
<a href="https://arxiv.org/abs/2204.13906">arxiv:2204.13906</a>
&#x1F4C8; 22 <br>
<p>Daesol Cho, Jigang Kim, H. Jin Kim</p></summary>
<p>

**Abstract:** Current reinforcement learning (RL) in robotics often experiences difficulty in generalizing to new downstream tasks due to the innate task-specific training paradigm. To alleviate it, unsupervised RL, a framework that pre-trains the agent in a task-agnostic manner without access to the task-specific reward, leverages active exploration for distilling diverse experience into essential skills or reusable knowledge. For exploiting such benefits also in robotic manipulation, we propose an unsupervised method for transferable manipulation skill discovery that ties structured exploration toward interacting behavior and transferable skill learning. It not only enables the agent to learn interaction behavior, the key aspect of the robotic manipulation learning, without access to the environment reward, but also to generalize to arbitrary downstream manipulation tasks with the learned task-agnostic skills. Through comparative experiments, we show that our approach achieves the most diverse interacting behavior and significantly improves sample efficiency in downstream tasks including the extension to multi-object, multitask problems.

</p>
</details>

<details><summary><b>How Robust is Neural Machine Translation to Language Imbalance in Multilingual Tokenizer Training?</b>
<a href="https://arxiv.org/abs/2204.14268">arxiv:2204.14268</a>
&#x1F4C8; 4 <br>
<p>Shiyue Zhang, Vishrav Chaudhary, Naman Goyal, James Cross, Guillaume Wenzek, Mohit Bansal, Francisco Guzman</p></summary>
<p>

**Abstract:** A multilingual tokenizer is a fundamental component of multilingual neural machine translation. It is trained from a multilingual corpus. Since a skewed data distribution is considered to be harmful, a sampling strategy is usually used to balance languages in the corpus. However, few works have systematically answered how language imbalance in tokenizer training affects downstream performance. In this work, we analyze how translation performance changes as the data ratios among languages vary in the tokenizer training corpus. We find that while relatively better performance is often observed when languages are more equally sampled, the downstream performance is more robust to language imbalance than we usually expected. Two features, UNK rate and closeness to the character level, can warn of poor downstream performance before performing the task. We also distinguish language sampling for tokenizer training from sampling for model training and show that the model is more sensitive to the latter.

</p>
</details>

<details><summary><b>PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining</b>
<a href="https://arxiv.org/abs/2204.14095">arxiv:2204.14095</a>
&#x1F4C8; 4 <br>
<p>Yuting Gao, Jinfeng Liu, Zihan Xu, Jun Zhang, Ke Li, Chunhua Shen</p></summary>
<p>

**Abstract:** Large-scale vision-language pre-training has achieved promising results on downstream tasks. Existing methods highly rely on the assumption that the image-text pairs crawled from the Internet are in perfect one-to-one correspondence. However, in real scenarios, this assumption can be difficult to hold: the text description, obtained by crawling the affiliated metadata of the image, often suffer from semantic mismatch and mutual compatibility. To address these issues, here we introduce PyramidCLIP, which constructs an input pyramid with different semantic levels, and aligns visual elements and linguistic elements in the form of hierarchy via intra-level semantics alignment and cross-level relation alignment. Furthermore, we adjust the objective function by softening the loss of negative samples (unpaired samples) so as to weaken the strict constraint during the pre-training stage, thus mitigating the risk of the model being over-confident. Experiments on three downstream tasks, including zero-shot image classification, zero-shot image-text retrieval and image object detection, verify the effectiveness of the proposed PyramidCLIP. In particular, with the same amount of pre-training data of 15 millions image-text pairs, PyramidCLIP exceeds CLIP by 19.2%/18.5%/19.6% respectively, with the image encoder being ResNet-50/ViT-B32/ViT-B16 on ImageNet zero-shot classification top-1 accuracy. When scaling to larger datasets, the results of PyramidCLIP only trained for 8 epochs using 128M image-text pairs are very close to that of CLIP trained for 32 epochs using 400M training data.

</p>
</details>

<details><summary><b>Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN</b>
<a href="https://arxiv.org/abs/2204.14079">arxiv:2204.14079</a>
&#x1F4C8; 4 <br>
<p>Dongyeun Lee, Jae Young Lee, Doyeon Kim, Jaehyun Choi, Junmo Kim</p></summary>
<p>

**Abstract:** Transfer learning of StyleGAN has recently shown great potential to solve diverse tasks, especially in domain translation. Previous methods utilized a source model by swapping or freezing weights during transfer learning, however, they have limitations on visual quality and controlling source features. In other words, they require additional models that are computationally demanding and have restricted control steps that prevent a smooth transition. In this paper, we propose a new approach to overcome these limitations. Instead of swapping or freezing, we introduce a simple feature matching loss to improve generation quality. In addition, to control the degree of source features, we train a target model with the proposed strategy, FixNoise, to preserve the source features only in a disentangled subspace of a target feature space. Owing to the disentangled feature space, our method can smoothly control the degree of the source features in a single model. Extensive experiments demonstrate that the proposed method can generate more consistent and realistic images than previous works.

</p>
</details>

<details><summary><b>Industry-academia research collaboration and knowledge co-creation: Patterns and anti-patterns</b>
<a href="https://arxiv.org/abs/2204.14180">arxiv:2204.14180</a>
&#x1F4C8; 2 <br>
<p>Dusica Marijan, Sagar Sen</p></summary>
<p>

**Abstract:** Increasing the impact of software engineering research in the software industry and the society at large has long been a concern of high priority for the software engineering community. The problem of two cultures, research conducted in a vacuum (disconnected from the real world), or misaligned time horizons are just some of the many complex challenges standing in the way of successful industry-academia collaborations. This paper reports on the experience of research collaboration and knowledge co-creation between industry and academia in software engineering as a way to bridge the research-practice collaboration gap. Our experience spans 14 years of collaboration between researchers in software engineering and the European and Norwegian software and IT industry. Using the participant observation and interview methods we have collected and afterwards analyzed an extensive record of qualitative data. Drawing upon the findings made and the experience gained, we provide a set of 14 patterns and 14 anti-patterns for industry-academia collaborations, aimed to support other researchers and practitioners in establishing and running research collaboration projects in software engineering.

</p>
</details>

<details><summary><b>Learning from Natural Language Feedback</b>
<a href="https://arxiv.org/abs/2204.14146">arxiv:2204.14146</a>
&#x1F4C8; 2 <br>
<p>Jérémy Scheurer, Jon Ander Campos, Jun Shern Chan, Angelica Chen, Kyunghyun Cho, Ethan Perez</p></summary>
<p>

**Abstract:** Pretrained language models often do not perform tasks in ways that are in line with our preferences, e.g., generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human evaluation: comparisons between pairs of model-generated task outputs. Comparison feedback conveys limited information about human preferences per human evaluation. Here, we propose to learn from natural language feedback, which conveys more information per human evaluation. We learn from language feedback on model outputs using a three-step learning algorithm. First, we condition the language model on the initial output and feedback to generate many refinements. Second, we choose the refinement with the highest similarity to the feedback. Third, we finetune a language model to maximize the likelihood of the chosen refinement given the input. In synthetic experiments, we first evaluate whether language models accurately incorporate feedback to produce refinements, finding that only large language models (175B parameters) do so. Using only 100 samples of human-written feedback, our learning algorithm finetunes a GPT-3 model to roughly human-level summarization.

</p>
</details>

<details><summary><b>KERMIT -- A Transformer-Based Approach for Knowledge Graph Matching</b>
<a href="https://arxiv.org/abs/2204.13931">arxiv:2204.13931</a>
&#x1F4C8; 2 <br>
<p>Sven Hertling, Jan Portisch, Heiko Paulheim</p></summary>
<p>

**Abstract:** One of the strongest signals for automated matching of knowledge graphs and ontologies are textual concept descriptions. With the rise of transformer-based language models, text comparison based on meaning (rather than lexical features) is available to researchers. However, performing pairwise comparisons of all textual descriptions of concepts in two knowledge graphs is expensive and scales quadratically (or even worse if concepts have more than one description). To overcome this problem, we follow a two-step approach: we first generate matching candidates using a pre-trained sentence transformer (so called bi-encoder). In a second step, we use fine-tuned transformer cross-encoders to generate the best candidates. We evaluate our approach on multiple datasets and show that it is feasible and produces competitive results.

</p>
</details>

<details><summary><b>Maxmin Participatory Budgeting</b>
<a href="https://arxiv.org/abs/2204.13923">arxiv:2204.13923</a>
&#x1F4C8; 2 <br>
<p>Gogulapati Sreedurga, Mayank Ratan Bhardwaj, Y. Narahari</p></summary>
<p>

**Abstract:** Participatory Budgeting (PB) is a popular voting method by which a limited budget is divided among a set of projects, based on the preferences of voters over the projects. PB is broadly categorised as divisible PB (if the projects are fractionally implementable) and indivisible PB (if the projects are atomic). Egalitarianism, an important objective in PB, has not received much attention in the context of indivisible PB. This paper addresses this gap through a detailed study of a natural egalitarian rule, Maxmin Participatory Budgeting (MPB), in the context of indivisible PB. Our study is in two parts: (1) computational (2) axiomatic. In the first part, we prove that MPB is computationally hard and give pseudo-polynomial time and polynomial-time algorithms when parameterized by certain well-motivated parameters. We propose an algorithm that achieves for MPB, additive approximation guarantees for restricted spaces of instances and empirically show that our algorithm in fact gives exact optimal solutions on real-world PB datasets. We also establish an upper bound on the approximation ratio achievable for MPB by the family of exhaustive strategy-proof PB algorithms. In the second part, we undertake an axiomatic study of the MPB rule by generalizing known axioms in the literature. Our study leads to the proposal of a new axiom, maximal coverage, which captures fairness aspects. We prove that MPB satisfies maximal coverage.

</p>
</details>

<details><summary><b>Preoperative brain tumor imaging: models and software for segmentation and standardized reporting</b>
<a href="https://arxiv.org/abs/2204.14199">arxiv:2204.14199</a>
&#x1F4C8; 1 <br>
<p>D. Bouget, A. Pedersen, A. S. Jakola, V. Kavouridis, K. E. Emblem, R. S. Eijgelaar, I. Kommers, H. Ardon, F. Barkhof, L. Bello, M. S. Berger, M. C. Nibali, J. Furtner, S. Hervey-Jumper, A. J. S. Idema, B. Kiesel, A. Kloet, E. Mandonnet, D. M. J. Müller, P. A. Robe, M. Rossi, T. Sciortino, W. Van den Brink, M. Wagemakers, G. Widhalm</p></summary>
<p>

**Abstract:** For patients suffering from brain tumor, prognosis estimation and treatment decisions are made by a multidisciplinary team based on a set of preoperative MR scans. Currently, the lack of standardized and automatic methods for tumor detection and generation of clinical reports represents a major hurdle. In this study, we investigate glioblastomas, lower grade gliomas, meningiomas, and metastases, through four cohorts of up to 4000 patients. Tumor segmentation models were trained using the AGU-Net architecture with different preprocessing steps and protocols. Segmentation performances were assessed in-depth using a wide-range of voxel and patient-wise metrics covering volume, distance, and probabilistic aspects. Finally, two software solutions have been developed, enabling an easy use of the trained models and standardized generation of clinical reports: Raidionics and Raidionics-Slicer. Segmentation performances were quite homogeneous across the four different brain tumor types, with an average true positive Dice ranging between 80% and 90%, patient-wise recall between 88% and 98%, and patient-wise precision around 95%. With our Raidionics software, running on a desktop computer with CPU support, tumor segmentation can be performed in 16 to 54 seconds depending on the dimensions of the MRI volume. For the generation of a standardized clinical report, including the tumor segmentation and features computation, 5 to 15 minutes are necessary. All trained models have been made open-access together with the source code for both software solutions and validation metrics computation. In the future, an automatic classification of the brain tumor type would be necessary to replace manual user input. Finally, the inclusion of post-operative segmentation in both software solutions will be key for generating complete post-operative standardized clinical reports.

</p>
</details>

<details><summary><b>Segmentation of kidney stones in endoscopic video feeds</b>
<a href="https://arxiv.org/abs/2204.14175">arxiv:2204.14175</a>
&#x1F4C8; 1 <br>
<p>Zachary A Stoebner, Daiwei Lu, Seok Hee Hong, Nicholas L Kavoussi, Ipek Oguz</p></summary>
<p>

**Abstract:** Image segmentation has been increasingly applied in medical settings as recent developments have skyrocketed the potential applications of deep learning. Urology, specifically, is one field of medicine that is primed for the adoption of a real-time image segmentation system with the long-term aim of automating endoscopic stone treatment. In this project, we explored supervised deep learning models to annotate kidney stones in surgical endoscopic video feeds. In this paper, we describe how we built a dataset from the raw videos and how we developed a pipeline to automate as much of the process as possible. For the segmentation task, we adapted and analyzed three baseline deep learning models -- U-Net, U-Net++, and DenseNet -- to predict annotations on the frames of the endoscopic videos with the highest accuracy above 90\%. To show clinical potential for real-time use, we also confirmed that our best trained model can accurately annotate new videos at 30 frames per second. Our results demonstrate that the proposed method justifies continued development and study of image segmentation to annotate ureteroscopic video feeds.

</p>
</details>

<details><summary><b>Evolutionary Approach to Security Games with Signaling</b>
<a href="https://arxiv.org/abs/2204.14173">arxiv:2204.14173</a>
&#x1F4C8; 1 <br>
<p>Adam Żychowski, Jacek Mańdziuk, Elizabeth Bondi, Aravind Venugopal, Milind Tambe, Balaraman Ravindran</p></summary>
<p>

**Abstract:** Green Security Games have become a popular way to model scenarios involving the protection of natural resources, such as wildlife. Sensors (e.g. drones equipped with cameras) have also begun to play a role in these scenarios by providing real-time information. Incorporating both human and sensor defender resources strategically is the subject of recent work on Security Games with Signaling (SGS). However, current methods to solve SGS do not scale well in terms of time or memory. We therefore propose a novel approach to SGS, which, for the first time in this domain, employs an Evolutionary Computation paradigm: EASGS. EASGS effectively searches the huge SGS solution space via suitable solution encoding in a chromosome and a specially-designed set of operators. The operators include three types of mutations, each focusing on a particular aspect of the SGS solution, optimized crossover and a local coverage improvement scheme (a memetic aspect of EASGS). We also introduce a new set of benchmark games, based on dense or locally-dense graphs that reflect real-world SGS settings. In the majority of 342 test game instances, EASGS outperforms state-of-the-art methods, including a reinforcement learning method, in terms of time scalability, nearly constant memory utilization, and quality of the returned defender's strategies (expected payoffs).

</p>
</details>

<details><summary><b>Tractable Uncertainty for Structure Learning</b>
<a href="https://arxiv.org/abs/2204.14170">arxiv:2204.14170</a>
&#x1F4C8; 1 <br>
<p>Benjie Wang, Matthew Wicker, Marta Kwiatkowska</p></summary>
<p>

**Abstract:** Bayesian structure learning allows one to capture uncertainty over the causal directed acyclic graph (DAG) responsible for generating given data. In this work, we present Tractable Uncertainty for STructure learning (TRUST), a framework for approximate posterior inference that relies on probabilistic circuits as the representation of our posterior belief. In contrast to sample-based posterior approximations, our representation can capture a much richer space of DAGs, while being able to tractably answer a range of useful inference queries. We empirically show how probabilistic circuits can be used as an augmented representation for structure learning methods, leading to improvement in both the quality of inferred structures and posterior uncertainty. Experimental results also demonstrate the improved representational capacity of TRUST, outperforming competing methods on conditional query answering.

</p>
</details>

<details><summary><b>Learning Anisotropic Interaction Rules from Individual Trajectories in a Heterogeneous Cellular Population</b>
<a href="https://arxiv.org/abs/2204.14141">arxiv:2204.14141</a>
&#x1F4C8; 1 <br>
<p>Daniel A. Messenger, Graycen E. Wheeler, Xuedong Liu, David M. Bortz</p></summary>
<p>

**Abstract:** Interacting particle system (IPS) models have proven to be highly successful for describing the spatial movement of organisms. However, it has proven challenging to infer the interaction rules directly from data. In the field of equation discovery, the Weak form Sparse Identification of Nonlinear Dynamics (WSINDy) methodology has been shown to be very computationally efficient for identifying the governing equations of complex systems, even in the presence of substantial noise. Motivated by the success of IPS models to describe the spatial movement of organisms, we develop WSINDy for second order IPSs to model the movement of communities of cells. Specifically, our approach learns the directional interaction rules that govern the dynamics of a heterogeneous population of migrating cells. Rather than aggregating cellular trajectory data into a single best-fit model, we learn the models for each individual cell. These models can then be efficiently classified according to the active classes of interactions present in the model. From these classifications, aggregated models are constructed hierarchically to simultaneously identify different species of cells present in the population and determine best-fit models for each species. We demonstrate the efficiency and proficiency of the method on several test scenarios, motivated by common cell migration experiments.

</p>
</details>

<details><summary><b>Adversarial Distortion Learning for Medical Image Denoising</b>
<a href="https://arxiv.org/abs/2204.14100">arxiv:2204.14100</a>
&#x1F4C8; 1 <br>
<p>Morteza Ghahremani, Mohammad Khateri, Alejandra Sierra, Jussi Tohka</p></summary>
<p>

**Abstract:** We present a novel adversarial distortion learning (ADL) for denoising two- and three-dimensional (2D/3D) biomedical image data. The proposed ADL consists of two auto-encoders: a denoiser and a discriminator. The denoiser removes noise from input data and the discriminator compares the denoised result to its noise-free counterpart. This process is repeated until the discriminator cannot differentiate the denoised data from the reference. Both the denoiser and the discriminator are built upon a proposed auto-encoder called Efficient-Unet. Efficient-Unet has a light architecture that uses the residual blocks and a novel pyramidal approach in the backbone to efficiently extract and re-use feature maps. During training, the textural information and contrast are controlled by two novel loss functions. The architecture of Efficient-Unet allows generalizing the proposed method to any sort of biomedical data. The 2D version of our network was trained on ImageNet and tested on biomedical datasets whose distribution is completely different from ImageNet; so, there is no need for re-training. Experimental results carried out on magnetic resonance imaging (MRI), dermatoscopy, electron microscopy and X-ray datasets show that the proposed method achieved the best on each benchmark. Our implementation and pre-trained models are available at https://github.com/mogvision/ADL.

</p>
</details>

<details><summary><b>Bayesian Information Criterion for Event-based Multi-trial Ensemble data</b>
<a href="https://arxiv.org/abs/2204.14096">arxiv:2204.14096</a>
&#x1F4C8; 1 <br>
<p>Kaidi Shao, Nikos K. Logothetis, Michel Besserve</p></summary>
<p>

**Abstract:** Transient recurring phenomena are ubiquitous in many scientific fields like neuroscience and meteorology. Time inhomogenous Vector Autoregressive Models (VAR) may be used to characterize peri-event system dynamics associated with such phenomena, and can be learned by exploiting multi-dimensional data gathering samples of the evolution of the system in multiple time windows comprising, each associated with one occurrence of the transient phenomenon, that we will call "trial". However, optimal VAR model order selection methods, commonly relying on the Akaike or Bayesian Information Criteria (AIC/BIC), are typically not designed for multi-trial data. Here we derive the BIC methods for multi-trial ensemble data which are gathered after the detection of the events. We show using simulated bivariate AR models that the multi-trial BIC is able to recover the real model order. We also demonstrate with simulated transient events and real data that the multi-trial BIC is able to estimate a sufficiently small model order for dynamic system modeling.

</p>
</details>

<details><summary><b>Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling</b>
<a href="https://arxiv.org/abs/2204.14017">arxiv:2204.14017</a>
&#x1F4C8; 1 <br>
<p>KiYoon Yoo, Nojun Kwak</p></summary>
<p>

**Abstract:** Recent advances in federated learning have demonstrated its promising capability to learn on decentralized datasets. However, a considerable amount of work has raised concerns due to the potential risks of adversaries participating in the framework to poison the global model for an adversarial purpose. This paper investigates the feasibility of model poisoning for backdoor attacks through \textit{rare word embeddings of NLP models} in text classification and sequence-to-sequence tasks. In text classification, less than 1\% of adversary clients suffices to manipulate the model output without any drop in the performance of clean sentences. For a less complex dataset, a mere 0.1\% of adversary clients is enough to poison the global model effectively. We also propose a technique specialized in the federated learning scheme called gradient ensemble, which enhances the backdoor performance in all experimental settings.

</p>
</details>

<details><summary><b>Robust Solutions for Multi-Defender Stackelberg Security Games</b>
<a href="https://arxiv.org/abs/2204.14000">arxiv:2204.14000</a>
&#x1F4C8; 1 <br>
<p>Dolev Mutzari, Yonatan Aumann, Sarit Kraus</p></summary>
<p>

**Abstract:** Multi-defender Stackelberg Security Games (MSSG) have recently gained increasing attention in the literature. However, the solutions offered to date are highly sensitive, wherein even small perturbations in the attacker's utility or slight uncertainties thereof can dramatically change the defenders' resulting payoffs and alter the equilibrium. In this paper, we introduce a robust model for MSSGs, which admits solutions that are resistant to small perturbations or uncertainties in the game's parameters. First, we formally define the notion of robustness, as well as the robust MSSG model. Then, for the non-cooperative setting, we prove the existence of a robust approximate equilibrium in any such game, and provide an efficient construction thereof. For the cooperative setting, we show that any such game admits a robust approximate alpha-core, provide an efficient construction thereof, and prove that stronger types of the core may be empty. Interestingly, the robust solutions can substantially increase the defenders' utilities over those of the non-robust ones.

</p>
</details>

<details><summary><b>Statistical applications of contrastive learning</b>
<a href="https://arxiv.org/abs/2204.13999">arxiv:2204.13999</a>
&#x1F4C8; 1 <br>
<p>Michael U. Gutmann, Steven Kleinegesse, Benjamin Rhodes</p></summary>
<p>

**Abstract:** The likelihood function plays a crucial role in statistical inference and experimental design. However, it is computationally intractable for several important classes of statistical models, including energy-based models and simulator-based models. Contrastive learning is an intuitive and computationally feasible alternative to likelihood-based learning. We here first provide an introduction to contrastive learning and then show how we can use it to derive methods for diverse statistical problems, namely parameter estimation for energy-based models, Bayesian inference for simulator-based models, as well as experimental design.

</p>
</details>

<details><summary><b>PIE: a Parameter and Inference Efficient Solution for Large Scale Knowledge Graph Embedding Reasoning</b>
<a href="https://arxiv.org/abs/2204.13957">arxiv:2204.13957</a>
&#x1F4C8; 1 <br>
<p>Linlin Chao, Taifeng Wang, Wei Chu</p></summary>
<p>

**Abstract:** Knowledge graph (KG) embedding methods which map entities and relations to unique embeddings in the KG have shown promising results on many reasoning tasks. However, the same embedding dimension for both dense entities and sparse entities will cause either over parameterization (sparse entities) or under fitting (dense entities). Normally, a large dimension is set to get better performance. Meanwhile, the inference time grows log-linearly with the number of entities for all entities are traversed and compared. Both the parameter and inference become challenges when working with huge amounts of entities. Thus, we propose PIE, a \textbf{p}arameter and \textbf{i}nference \textbf{e}fficient solution. Inspired from tensor decomposition methods, we find that decompose entity embedding matrix into low rank matrices can reduce more than half of the parameters while maintaining comparable performance. To accelerate model inference, we propose a self-supervised auxiliary task, which can be seen as fine-grained entity typing. By randomly masking and recovering entities' connected relations, the task learns the co-occurrence of entity and relations. Utilizing the fine grained typing, we can filter unrelated entities during inference and get targets with possibly sub-linear time requirement. Experiments on link prediction benchmarks demonstrate the proposed key capabilities. Moreover, we prove effectiveness of the proposed solution on the Open Graph Benchmark large scale challenge dataset WikiKG90Mv2 and achieve the state of the art performance.

</p>
</details>

<details><summary><b>User Experience Design for Automatic Credibility Assessment of News Content About COVID-19</b>
<a href="https://arxiv.org/abs/2204.13943">arxiv:2204.13943</a>
&#x1F4C8; 1 <br>
<p>Konstantin Schulz, Jens Rauenbusch, Jan Fillies, Lisa Rutenburg, Dimitrios Karvelas, Georg Rehm</p></summary>
<p>

**Abstract:** The increasingly rapid spread of information about COVID-19 on the web calls for automatic measures of quality assurance. In that context, we check the credibility of news content using selected linguistic features. We present two empirical studies to evaluate the usability of graphical interfaces that offer such credibility assessment. In a moderated qualitative interview with six participants, we identify rating scale, sub-criteria and algorithm authorship as important predictors of the usability. A subsequent quantitative online survey with 50 participants reveals a conflict between transparency and conciseness in the interface design, as well as a perceived hierarchy of metadata: the authorship of a news text is more important than the authorship of the credibility algorithm used to assess the content quality. Finally, we make suggestions for future research, such as proactively documenting credibility-related metadata for Natural Language Processing and Language Technology services and establishing an explicit hierarchical taxonomy of usability predictors for automatic credibility assessment.

</p>
</details>

<details><summary><b>Short-Term Density Forecasting of Low-Voltage Load using Bernstein-Polynomial Normalizing Flows</b>
<a href="https://arxiv.org/abs/2204.13939">arxiv:2204.13939</a>
&#x1F4C8; 1 <br>
<p>Marcel Arpogaus, Marcus Voss, Beate Sick, Mark Nigge-Uricher, Oliver Dürr</p></summary>
<p>

**Abstract:** The transition to a fully renewable energy grid requires better forecasting of demand at the low-voltage level to increase efficiency and ensure reliable control. However, high fluctuations and increasing electrification cause huge forecast variability, not reflected in traditional point estimates. Probabilistic load forecasts take future uncertainties into account and thus allow more informed decision-making for the planning and operation of low-carbon energy systems. We propose an approach for flexible conditional density forecasting of short-term load based on Bernstein polynomial normalizing flows, where a neural network controls the parameters of the flow. In an empirical study with 363 smart meter customers, our density predictions compare favorably against Gaussian and Gaussian mixture densities. Also, they outperform a non-parametric approach based on the pinball loss for 24h-ahead load forecasting for two different neural network architectures.

</p>
</details>

<details><summary><b>A study of tree-based methods and their combination</b>
<a href="https://arxiv.org/abs/2204.13916">arxiv:2204.13916</a>
&#x1F4C8; 1 <br>
<p>Yinuo Zeng</p></summary>
<p>

**Abstract:** Tree-based methods are popular machine learning techniques used in various fields. In this work, we review their foundations and a general framework the importance sampled learning ensemble (ISLE) that accelerates their fitting process. Furthermore, we describe a model combination strategy called the adaptive regression by mixing (ARM), which is feasible for tree-based methods via ISLE. Moreover, three modified ISLEs are proposed, and their performance are evaluated on the real data sets.

</p>
</details>

<details><summary><b>End-to-end Spoken Conversational Question Answering: Task, Dataset and Model</b>
<a href="https://arxiv.org/abs/2204.14272">arxiv:2204.14272</a>
&#x1F4C8; 0 <br>
<p>Chenyu You, Nuo Chen, Fenglin Liu, Shen Ge, Xian Wu, Yuexian Zou</p></summary>
<p>

**Abstract:** In spoken question answering, the systems are designed to answer questions from contiguous text spans within the related speech transcripts. However, the most natural way that human seek or test their knowledge is via human conversations. Therefore, we propose a new Spoken Conversational Question Answering task (SCQA), aiming at enabling the systems to model complex dialogue flows given the speech documents. In this task, our main objective is to build the system to deal with conversational questions based on the audio recordings, and to explore the plausibility of providing more cues from different modalities with systems in information gathering. To this end, instead of directly adopting automatically generated speech transcripts with highly noisy data, we propose a novel unified data distillation approach, DDNet, which effectively ingests cross-modal information to achieve fine-grained representations of the speech and language modalities. Moreover, we propose a simple and novel mechanism, termed Dual Attention, by encouraging better alignments between audio and text to ease the process of knowledge transfer. To evaluate the capacity of SCQA systems in a dialogue-style interaction, we assemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with more than 40k question-answer pairs from 4k conversations. The performance of the existing state-of-the-art methods significantly degrade on our dataset, hence demonstrating the necessity of cross-modal information integration. Our experimental results demonstrate that our proposed method achieves superior performance in spoken conversational question answering tasks.

</p>
</details>

<details><summary><b>Finite Entailment of UCRPQs over ALC Ontologies</b>
<a href="https://arxiv.org/abs/2204.14261">arxiv:2204.14261</a>
&#x1F4C8; 0 <br>
<p>Vıctor Gutiérrez-Basulto, Albert Gutowski, Yazmın Ibáñez-Garcıa, Filip Murlak</p></summary>
<p>

**Abstract:** We investigate the problem of finite entailment of ontology-mediated queries. We consider the expressive query language, unions of conjunctive regular path queries (UCRPQs), extending the well-known class of union of conjunctive queries, with regular expressions over roles. We look at ontologies formulated using the description logic ALC, and show a tight 2EXPTIME upper bound for entailment of UCRPQs. At the core of our decision procedure, there is a novel automata-based technique introducing a stratification of interpretations induced by the deterministic finite automaton underlying the input UCRPQ

</p>
</details>

<details><summary><b>Lipschitz-based Surrogate Model for High-dimensional Computationally Expensive Problems</b>
<a href="https://arxiv.org/abs/2204.14236">arxiv:2204.14236</a>
&#x1F4C8; 0 <br>
<p>Jakub Kudela, Radomil Matousek</p></summary>
<p>

**Abstract:** Standard evolutionary optimization algorithms assume that the evaluation of the objective and constraint functions is straightforward and computationally cheap. However, in many real-world optimization problems, the computations of the objective function or constraints involve computationally expensive numerical simulations or physical experiments. Surrogate-assisted evolutionary algorithms (SAEAs) have recently gained increased attention because of their search capabilities for solving these computationally expensive optimization problems. The main idea of SAEAs is the integration of an evolutionary algorithm with a selected surrogate model. In this paper, we propose a novel surrogate model based on a Lipschitz underestimation of the expensive-to-compute objective function. We also develop a differential evolution-based algorithm, that utilizes the Lipschitz-based surrogate model, along with a standard radial basis function surrogate model and a local search procedure. This algorithm, called Lipschitz Surrogate-assisted Differential Evolution (LSADE), is designed for high-dimensional computationally expensive problems. The experimental results on seven benchmark functions of dimensions 30, 50, 100, and 200 show that the proposed method utilizing the Lipschitz-based surrogate model is competitive compared with the state-of-the-art algorithms under a limited computational budget, being especially effective for the very complicated benchmark functions in high dimensions.

</p>
</details>

<details><summary><b>Explainable AI via Learning to Optimize</b>
<a href="https://arxiv.org/abs/2204.14174">arxiv:2204.14174</a>
&#x1F4C8; 0 <br>
<p>Howard Heaton, Samy Wu Fung</p></summary>
<p>

**Abstract:** Indecipherable black boxes are common in machine learning (ML), but applications increasingly require explainable artificial intelligence (XAI). The core of XAI is to establish transparent and interpretable data-driven algorithms. This work provides concrete tools for XAI in situations where prior knowledge must be encoded and untrustworthy inferences flagged. We use the "learn to optimize" (L2O) methodology wherein each inference solves a data-driven optimization problem. Our L2O models are straightforward to implement, directly encode prior knowledge, and yield theoretical guarantees (e.g. satisfaction of constraints). We also propose use of interpretable certificates to verify whether model inferences are trustworthy. Numerical examples are provided in the applications of dictionary-based signal recovery, CT imaging, and arbitrage trading of cryptoassets.

</p>
</details>

<details><summary><b>Exploration and Exploitation in Federated Learning to Exclude Clients with Poisoned Data</b>
<a href="https://arxiv.org/abs/2204.14020">arxiv:2204.14020</a>
&#x1F4C8; 0 <br>
<p>Shadha Tabatabai, Ihab Mohammed, Basheer Qolomany, Abdullatif Albasser, Kashif Ahmad, Mohamed Abdallah, Ala Al-Fuqaha</p></summary>
<p>

**Abstract:** Federated Learning (FL) is one of the hot research topics, and it utilizes Machine Learning (ML) in a distributed manner without directly accessing private data on clients. However, FL faces many challenges, including the difficulty to obtain high accuracy, high communication cost between clients and the server, and security attacks related to adversarial ML. To tackle these three challenges, we propose an FL algorithm inspired by evolutionary techniques. The proposed algorithm groups clients randomly in many clusters, each with a model selected randomly to explore the performance of different models. The clusters are then trained in a repetitive process where the worst performing cluster is removed in each iteration until one cluster remains. In each iteration, some clients are expelled from clusters either due to using poisoned data or low performance. The surviving clients are exploited in the next iteration. The remaining cluster with surviving clients is then used for training the best FL model (i.e., remaining FL model). Communication cost is reduced since fewer clients are used in the final training of the FL model. To evaluate the performance of the proposed algorithm, we conduct a number of experiments using FEMNIST dataset and compare the result against the random FL algorithm. The experimental results show that the proposed algorithm outperforms the baseline algorithm in terms of accuracy, communication cost, and security.

</p>
</details>

<details><summary><b>Local Explanation of Dimensionality Reduction</b>
<a href="https://arxiv.org/abs/2204.14012">arxiv:2204.14012</a>
&#x1F4C8; 0 <br>
<p>Avraam Bardos, Ioannis Mollas, Nick Bassiliades, Grigorios Tsoumakas</p></summary>
<p>

**Abstract:** Dimensionality reduction (DR) is a popular method for preparing and analyzing high-dimensional data. Reduced data representations are less computationally intensive and easier to manage and visualize, while retaining a significant percentage of their original information. Aside from these advantages, these reduced representations can be difficult or impossible to interpret in most circumstances, especially when the DR approach does not provide further information about which features of the original space led to their construction. This problem is addressed by Interpretable Machine Learning, a subfield of Explainable Artificial Intelligence that addresses the opacity of machine learning models. However, current research on Interpretable Machine Learning has been focused on supervised tasks, leaving unsupervised tasks like Dimensionality Reduction unexplored. In this paper, we introduce LXDR, a technique capable of providing local interpretations of the output of DR techniques. Experiment results and two LXDR use case examples are presented to evaluate its usefulness.

</p>
</details>

<details><summary><b>Learned Gradient of a Regularizer for Plug-and-Play Gradient Descent</b>
<a href="https://arxiv.org/abs/2204.13940">arxiv:2204.13940</a>
&#x1F4C8; 0 <br>
<p>Rita Fermanian, Mikael Le Pendu, Christine Guillemot</p></summary>
<p>

**Abstract:** The Plug-and-Play (PnP) framework allows integrating advanced image denoising priors into optimization algorithms, to efficiently solve a variety of image restoration tasks. The Plug-and-Play alternating direction method of multipliers (ADMM) and the Regularization by Denoising (RED) algorithms are two examples of such methods that made a breakthrough in image restoration. However, while the former method only applies to proximal algorithms, it has recently been shown that there exists no regularization that explains the RED algorithm when the denoisers lack Jacobian symmetry, which happen to be the case of most practical denoisers. To the best of our knowledge, there exists no method for training a network that directly represents the gradient of a regularizer, which can be directly used in Plug-and-Play gradient-based algorithms. We show that it is possible to train a denoiser along with a network that corresponds to the gradient of its regularizer. We use this gradient of the regularizer in gradient-based optimization methods and obtain better results comparing to other generic Plug-and-Play approaches. We also show that the regularizer can be used as a pre-trained network for unrolled gradient descent. Lastly, we show that the resulting denoiser allows for a quick convergence of the Plug-and-Play ADMM.

</p>
</details>

<details><summary><b>Framework for Behavioral Disorder Detection Using Machine Learning and Application of Virtual Cognitive Behavioral Therapy in COVID-19 Pandemic</b>
<a href="https://arxiv.org/abs/2204.13900">arxiv:2204.13900</a>
&#x1F4C8; 0 <br>
<p>Tasnim Niger, Hasanur Rayhan, Rashidul Islam, Kazi Asif Abdullah Noor, Kamrul Hasan</p></summary>
<p>

**Abstract:** In this modern world, people are becoming more self-centered and unsocial. On the other hand, people are stressed, becoming more anxious during COVID-19 pandemic situation and exhibits symptoms of behavioral disorder. To measure the symptoms of behavioral disorder, usually psychiatrist use long hour sessions and inputs from specific questionnaire. This process is time consuming and sometime is ineffective to detect the right behavioral disorder. Also, reserved people sometime hesitate to follow this process. We have created a digital framework which can detect behavioral disorder and prescribe virtual Cognitive Behavioral Therapy (vCBT) for recovery. By using this framework people can input required data that are highly responsible for the three behavioral disorders namely depression, anxiety and internet addiction. We have applied machine learning technique to detect specific behavioral disorder from samples. This system guides the user with basic understanding and treatment through vCBT from anywhere any time which would potentially be the steppingstone for the user to be conscious and pursue right treatment.

</p>
</details>

<details><summary><b>Autonomous In-Situ Soundscape Augmentation via Joint Selection of Masker and Gain</b>
<a href="https://arxiv.org/abs/2204.13883">arxiv:2204.13883</a>
&#x1F4C8; 0 <br>
<p>Karn N. Watcharasupat, Kenneth Ooi, Bhan Lam, Trevor Wong, Zhen-Ting Ong, Woon-Seng Gan</p></summary>
<p>

**Abstract:** The selection of maskers and playback gain levels in a soundscape augmentation system is crucial to its effectiveness in improving the overall acoustic comfort of a given environment. Traditionally, the selection of appropriate maskers and gain levels has been informed by expert opinion, which may not representative of the target population, or by listening tests, which can be time-consuming and labour-intensive. Furthermore, the resulting static choices of masker and gain are often inflexible to the dynamic nature of real-world soundscapes. In this work, we utilized a deep learning model to perform joint selection of the optimal masker and its gain level for a given soundscape. The proposed model was designed with highly modular building blocks, allowing for an optimized inference process that can quickly search through a large number of masker and gain combinations. In addition, we introduced the use of feature-domain soundscape augmentation conditioned on the digital gain level, eliminating the computationally expensive waveform-domain mixing process during inference time, as well as the tedious pre-calibration process required for new maskers. The proposed system was validated on a large-scale dataset of subjective responses to augmented soundscapes with more than 440 participants, ensuring the ability of the model to predict combined effect of the masker and its gain level on the perceptual pleasantness level.

</p>
</details>


{% endraw %}
Prev: [2022.04.28]({{ '/2022/04/28/2022.04.28.html' | relative_url }})  Next: [2022.04.30]({{ '/2022/04/30/2022.04.30.html' | relative_url }})