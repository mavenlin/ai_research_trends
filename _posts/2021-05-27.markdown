## Summary for 2021-05-27, created on 2021-12-21


<details><summary><b>Deep Ensembles from a Bayesian Perspective</b>
<a href="https://arxiv.org/abs/2105.13283">arxiv:2105.13283</a>
&#x1F4C8; 30 <br>
<p>Lara Hoffmann, Clemens Elster</p></summary>
<p>

**Abstract:** Deep ensembles can be considered as the current state-of-the-art for uncertainty quantification in deep learning. While the approach was originally proposed as a non-Bayesian technique, arguments supporting its Bayesian footing have been put forward as well. We show that deep ensembles can be viewed as an approximate Bayesian method by specifying the corresponding assumptions. Our findings lead to an improved approximation which results in an enlarged epistemic part of the uncertainty. Numerical examples suggest that the improved approximation can lead to more reliable uncertainties. Analytical derivations ensure easy calculation of results.

</p>
</details>

<details><summary><b>Tracking Without Re-recognition in Humans and Machines</b>
<a href="https://arxiv.org/abs/2105.13351">arxiv:2105.13351</a>
&#x1F4C8; 29 <br>
<p>Drew Linsley, Girik Malik, Junkyung Kim, Lakshmi N Govindarajan, Ennio Mingolla, Thomas Serre</p></summary>
<p>

**Abstract:** Imagine trying to track one particular fruitfly in a swarm of hundreds. Higher biological visual systems have evolved to track moving objects by relying on both appearance and motion features. We investigate if state-of-the-art deep neural networks for visual tracking are capable of the same. For this, we introduce PathTracker, a synthetic visual challenge that asks human observers and machines to track a target object in the midst of identical-looking "distractor" objects. While humans effortlessly learn PathTracker and generalize to systematic variations in task design, state-of-the-art deep networks struggle. To address this limitation, we identify and model circuit mechanisms in biological brains that are implicated in tracking objects based on motion cues. When instantiated as a recurrent network, our circuit model learns to solve PathTracker with a robust visual strategy that rivals human performance and explains a significant proportion of their decision-making on the challenge. We also show that the success of this circuit model extends to object tracking in natural videos. Adding it to a transformer-based architecture for object tracking builds tolerance to visual nuisances that affect object appearance, resulting in a new state-of-the-art performance on the large-scale TrackingNet object tracking challenge. Our work highlights the importance of building artificial vision models that can help us better understand human vision and improve computer vision.

</p>
</details>

<details><summary><b>Drawing Multiple Augmentation Samples Per Image During Training Efficiently Decreases Test Error</b>
<a href="https://arxiv.org/abs/2105.13343">arxiv:2105.13343</a>
&#x1F4C8; 24 <br>
<p>Stanislav Fort, Andrew Brock, Razvan Pascanu, Soham De, Samuel L. Smith</p></summary>
<p>

**Abstract:** In computer vision, it is standard practice to draw a single sample from the data augmentation procedure for each unique image in the mini-batch, however it is not clear whether this choice is optimal for generalization. In this work, we provide a detailed empirical evaluation of how the number of augmentation samples per unique image influences performance on held out data. Remarkably, we find that drawing multiple samples per image consistently enhances the test accuracy achieved for both small and large batch training, despite reducing the number of unique training examples in each mini-batch. This benefit arises even when different augmentation multiplicities perform the same number of parameter updates and gradient evaluations. Our results suggest that, although the variance in the gradient estimate arising from subsampling the dataset has an implicit regularization benefit, the variance which arises from the data augmentation process harms test accuracy. By applying augmentation multiplicity to the recently proposed NFNet model family, we achieve a new ImageNet state of the art of 86.8$\%$ top-1 w/o extra data.

</p>
</details>

<details><summary><b>Graph-Based Deep Learning for Medical Diagnosis and Analysis: Past, Present and Future</b>
<a href="https://arxiv.org/abs/2105.13137">arxiv:2105.13137</a>
&#x1F4C8; 23 <br>
<p>David Ahmedt-Aristizabal, Mohammad Ali Armin, Simon Denman, Clinton Fookes, Lars Petersson</p></summary>
<p>

**Abstract:** With the advances of data-driven machine learning research, a wide variety of prediction problems have been tackled. It has become critical to explore how machine learning and specifically deep learning methods can be exploited to analyse healthcare data. A major limitation of existing methods has been the focus on grid-like data; however, the structure of physiological recordings are often irregular and unordered which makes it difficult to conceptualise them as a matrix. As such, graph neural networks have attracted significant attention by exploiting implicit information that resides in a biological system, with interactive nodes connected by edges whose weights can be either temporal associations or anatomical junctions. In this survey, we thoroughly review the different types of graph architectures and their applications in healthcare. We provide an overview of these methods in a systematic manner, organized by their domain of application including functional connectivity, anatomical structure and electrical-based analysis. We also outline the limitations of existing techniques and discuss potential directions for future research.

</p>
</details>

<details><summary><b>Efficient and Accurate Gradients for Neural SDEs</b>
<a href="https://arxiv.org/abs/2105.13493">arxiv:2105.13493</a>
&#x1F4C8; 21 <br>
<p>Patrick Kidger, James Foster, Xuechen Li, Terry Lyons</p></summary>
<p>

**Abstract:** Neural SDEs combine many of the best qualities of both RNNs and SDEs: memory efficient training, high-capacity function approximation, and strong priors on model space. This makes them a natural choice for modelling many types of temporal dynamics. Training a Neural SDE (either as a VAE or as a GAN) requires backpropagating through an SDE solve. This may be done by solving a backwards-in-time SDE whose solution is the desired parameter gradients. However, this has previously suffered from severe speed and accuracy issues, due to high computational cost and numerical truncation errors. Here, we overcome these issues through several technical innovations. First, we introduce the \textit{reversible Heun method}. This is a new SDE solver that is \textit{algebraically reversible}: eliminating numerical gradient errors, and the first such solver of which we are aware. Moreover it requires half as many function evaluations as comparable solvers, giving up to a $1.98\times$ speedup. Second, we introduce the \textit{Brownian Interval}: a new, fast, memory efficient, and exact way of sampling \textit{and reconstructing} Brownian motion. With this we obtain up to a $10.6\times$ speed improvement over previous techniques, which in contrast are both approximate and relatively slow. Third, when specifically training Neural SDEs as GANs (Kidger et al. 2021), we demonstrate how SDE-GANs may be trained through careful weight clipping and choice of activation function. This reduces computational cost (giving up to a $1.87\times$ speedup) and removes the numerical truncation errors associated with gradient penalty. Altogether, we outperform the state-of-the-art by substantial margins, with respect to training speed, and with respect to classification, prediction, and MMD test metrics. We have contributed implementations of all of our techniques to the torchsde library to help facilitate their adoption.

</p>
</details>

<details><summary><b>Passing Multi-Channel Material Textures to a 3-Channel Loss</b>
<a href="https://arxiv.org/abs/2105.13012">arxiv:2105.13012</a>
&#x1F4C8; 20 <br>
<p>Thomas Chambon, Eric Heitz, Laurent Belcour</p></summary>
<p>

**Abstract:** Our objective is to compute a textural loss that can be used to train texture generators with multiple material channels typically used for physically based rendering such as albedo, normal, roughness, metalness, ambient occlusion, etc. Neural textural losses often build on top of the feature spaces of pretrained convolutional neural networks. Unfortunately, these pretrained models are only available for 3-channel RGB data and hence limit neural textural losses to this format. To overcome this limitation, we show that passing random triplets to a 3-channel loss provides a multi-channel loss that can be used to generate high-quality material textures.

</p>
</details>

<details><summary><b>Model Selection for Production System via Automated Online Experiments</b>
<a href="https://arxiv.org/abs/2105.13420">arxiv:2105.13420</a>
&#x1F4C8; 19 <br>
<p>Zhenwen Dai, Praveen Chandar, Ghazal Fazelnia, Ben Carterette, Mounia Lalmas-Roelleke</p></summary>
<p>

**Abstract:** A challenge that machine learning practitioners in the industry face is the task of selecting the best model to deploy in production. As a model is often an intermediate component of a production system, online controlled experiments such as A/B tests yield the most reliable estimation of the effectiveness of the whole system, but can only compare two or a few models due to budget constraints. We propose an automated online experimentation mechanism that can efficiently perform model selection from a large pool of models with a small number of online experiments. We derive the probability distribution of the metric of interest that contains the model uncertainty from our Bayesian surrogate model trained using historical logs. Our method efficiently identifies the best model by sequentially selecting and deploying a list of models from the candidate set that balance exploration-exploitation. Using simulations based on real data, we demonstrate the effectiveness of our method on two different tasks.

</p>
</details>

<details><summary><b>AndroidEnv: A Reinforcement Learning Platform for Android</b>
<a href="https://arxiv.org/abs/2105.13231">arxiv:2105.13231</a>
&#x1F4C8; 17 <br>
<p>Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici, Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad, Doina Precup</p></summary>
<p>

**Abstract:** We introduce AndroidEnv, an open-source platform for Reinforcement Learning (RL) research built on top of the Android ecosystem. AndroidEnv allows RL agents to interact with a wide variety of apps and services commonly used by humans through a universal touchscreen interface. Since agents train on a realistic simulation of an Android device, they have the potential to be deployed on real devices. In this report, we give an overview of the environment, highlighting the significant features it provides for research, and we present an empirical evaluation of some popular reinforcement learning agents on a set of tasks built on this platform.

</p>
</details>

<details><summary><b>An Impossibility Theorem for Node Embedding</b>
<a href="https://arxiv.org/abs/2105.13251">arxiv:2105.13251</a>
&#x1F4C8; 16 <br>
<p>T. Mitchell Roddenberry, Yu Zhu, Santiago Segarra</p></summary>
<p>

**Abstract:** With the increasing popularity of graph-based methods for dimensionality reduction and representation learning, node embedding functions have become important objects of study in the literature. In this paper, we take an axiomatic approach to understanding node embedding methods, first stating three properties for embedding dissimilarity networks, then proving that all three cannot be satisfied simultaneously by any node embedding method. Similar to existing results on the impossibility of clustering under certain axiomatic assumptions, this points to fundamental difficulties inherent to node embedding tasks. Once these difficulties are identified, we then relax these axioms to allow for certain node embedding methods to be admissible in our framework.

</p>
</details>

<details><summary><b>Towards Understanding Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2105.13093">arxiv:2105.13093</a>
&#x1F4C8; 14 <br>
<p>Mary Phuong, Christoph H. Lampert</p></summary>
<p>

**Abstract:** Knowledge distillation, i.e., one classifier being trained on the outputs of another classifier, is an empirically very successful technique for knowledge transfer between classifiers. It has even been observed that classifiers learn much faster and more reliably if trained with the outputs of another classifier as soft labels, instead of from ground truth data. So far, however, there is no satisfactory theoretical explanation of this phenomenon. In this work, we provide the first insights into the working mechanisms of distillation by studying the special case of linear and deep linear classifiers. Specifically, we prove a generalization bound that establishes fast convergence of the expected risk of a distillation-trained linear classifier. From the bound and its proof we extract three key factors that determine the success of distillation: * data geometry -- geometric properties of the data distribution, in particular class separation, has a direct influence on the convergence speed of the risk; * optimization bias -- gradient descent optimization finds a very favorable minimum of the distillation objective; and * strong monotonicity -- the expected risk of the student classifier always decreases when the size of the training set grows.

</p>
</details>

<details><summary><b>Self-Supervised Multimodal Opinion Summarization</b>
<a href="https://arxiv.org/abs/2105.13135">arxiv:2105.13135</a>
&#x1F4C8; 13 <br>
<p>Jinbae Im, Moonki Kim, Hoyeop Lee, Hyunsouk Cho, Sehee Chung</p></summary>
<p>

**Abstract:** Recently, opinion summarization, which is the generation of a summary from multiple reviews, has been conducted in a self-supervised manner by considering a sampled review as a pseudo summary. However, non-text data such as image and metadata related to reviews have been considered less often. To use the abundant information contained in non-text data, we propose a self-supervised multimodal opinion summarization framework called MultimodalSum. Our framework obtains a representation of each modality using a separate encoder for each modality, and the text decoder generates a summary. To resolve the inherent heterogeneity of multimodal data, we propose a multimodal training pipeline. We first pretrain the text encoder--decoder based solely on text modality data. Subsequently, we pretrain the non-text modality encoders by considering the pretrained text decoder as a pivot for the homogeneous representation of multimodal data. Finally, to fuse multimodal representations, we train the entire framework in an end-to-end manner. We demonstrate the superiority of MultimodalSum by conducting experiments on Yelp and Amazon datasets.

</p>
</details>

<details><summary><b>ILDC for CJPE: Indian Legal Documents Corpus for Court Judgment Prediction and Explanation</b>
<a href="https://arxiv.org/abs/2105.13562">arxiv:2105.13562</a>
&#x1F4C8; 10 <br>
<p>Vijit Malik, Rishabh Sanjay, Shubham Kumar Nigam, Kripa Ghosh, Shouvik Kumar Guha, Arnab Bhattacharya, Ashutosh Modi</p></summary>
<p>

**Abstract:** An automated system that could assist a judge in predicting the outcome of a case would help expedite the judicial process. For such a system to be practically useful, predictions by the system should be explainable. To promote research in developing such a system, we introduce ILDC (Indian Legal Documents Corpus). ILDC is a large corpus of 35k Indian Supreme Court cases annotated with original court decisions. A portion of the corpus (a separate test set) is annotated with gold standard explanations by legal experts. Based on ILDC, we propose the task of Court Judgment Prediction and Explanation (CJPE). The task requires an automated system to predict an explainable outcome of a case. We experiment with a battery of baseline models for case predictions and propose a hierarchical occlusion based model for explainability. Our best prediction model has an accuracy of 78% versus 94% for human legal experts, pointing towards the complexity of the prediction task. The analysis of explanations by the proposed algorithm reveals a significant difference in the point of view of the algorithm and legal experts for explaining the judgments, pointing towards scope for future research.

</p>
</details>

<details><summary><b>Neural Options Pricing</b>
<a href="https://arxiv.org/abs/2105.13320">arxiv:2105.13320</a>
&#x1F4C8; 10 <br>
<p>Timothy DeLise</p></summary>
<p>

**Abstract:** This research investigates pricing financial options based on the traditional martingale theory of arbitrage pricing applied to neural SDEs. We treat neural SDEs as universal Itô process approximators. In this way we can lift all assumptions on the form of the underlying price process, and compute theoretical option prices numerically. We propose a variation of the SDE-GAN approach by implementing the Wasserstein distance metric as a loss function for training. Furthermore, it is conjectured that the error of the option price implied by the learnt model can be bounded by the very Wasserstein distance metric that was used to fit the empirical data.

</p>
</details>

<details><summary><b>Measuring Fine-Grained Domain Relevance of Terms: A Hierarchical Core-Fringe Approach</b>
<a href="https://arxiv.org/abs/2105.13255">arxiv:2105.13255</a>
&#x1F4C8; 10 <br>
<p>Jie Huang, Kevin Chen-Chuan Chang, Jinjun Xiong, Wen-mei Hwu</p></summary>
<p>

**Abstract:** We propose to measure fine-grained domain relevance - the degree that a term is relevant to a broad (e.g., computer science) or narrow (e.g., deep learning) domain. Such measurement is crucial for many downstream tasks in natural language processing. To handle long-tail terms, we build a core-anchored semantic graph, which uses core terms with rich description information to bridge the vast remaining fringe terms semantically. To support a fine-grained domain without relying on a matching corpus for supervision, we develop hierarchical core-fringe learning, which learns core and fringe terms jointly in a semi-supervised manner contextualized in the hierarchy of the domain. To reduce expensive human efforts, we employ automatic annotation and hierarchical positive-unlabeled learning. Our approach applies to big or small domains, covers head or tail terms, and requires little human effort. Extensive experiments demonstrate that our methods outperform strong baselines and even surpass professional human performance.

</p>
</details>

<details><summary><b>On the Universality of Graph Neural Networks on Large Random Graphs</b>
<a href="https://arxiv.org/abs/2105.13099">arxiv:2105.13099</a>
&#x1F4C8; 10 <br>
<p>Nicolas Keriven, Alberto Bietti, Samuel Vaiter</p></summary>
<p>

**Abstract:** We study the approximation power of Graph Neural Networks (GNNs) on latent position random graphs. In the large graph limit, GNNs are known to converge to certain "continuous" models known as c-GNNs, which directly enables a study of their approximation power on random graph models. In the absence of input node features however, just as GNNs are limited by the Weisfeiler-Lehman isomorphism test, c-GNNs will be severely limited on simple random graph models. For instance, they will fail to distinguish the communities of a well-separated Stochastic Block Model (SBM) with constant degree function. Thus, we consider recently proposed architectures that augment GNNs with unique node identifiers, referred to as Structural GNNs here (SGNNs). We study the convergence of SGNNs to their continuous counterpart (c-SGNNs) in the large random graph limit, under new conditions on the node identifiers. We then show that c-SGNNs are strictly more powerful than c-GNNs in the continuous limit, and prove their universality on several random graph models of interest, including most SBMs and a large class of random geometric graphs. Our results cover both permutation-invariant and permutation-equivariant architectures.

</p>
</details>

<details><summary><b>FuSeConv: Fully Separable Convolutions for Fast Inference on Systolic Arrays</b>
<a href="https://arxiv.org/abs/2105.13434">arxiv:2105.13434</a>
&#x1F4C8; 9 <br>
<p>Surya Selvam, Vinod Ganesan, Pratyush Kumar</p></summary>
<p>

**Abstract:** Both efficient neural networks and hardware accelerators are being explored to speed up DNN inference on edge devices. For example, MobileNet uses depthwise separable convolution to achieve much lower latency, while systolic arrays provide much higher performance per watt. Interestingly however, the combination of these two ideas is inefficient: The computational patterns of depth-wise separable convolution are not systolic and lack data reuse to saturate the systolic array's constrained dataflow. In this paper, we propose FuSeConv (Fully-Separable Convolution) as a drop-in replacement for depth-wise separable convolution. FuSeConv generalizes the decomposition of convolutions fully to separable 1D convolutions along spatial and depth dimensions. The resultant computation is systolic and efficiently utilizes the systolic array with a slightly modified dataflow. With FuSeConv, we achieve a significant speed-up of 3x-7x with the MobileNet family of networks on a systolic array of size 64x64, with comparable accuracy on the ImageNet dataset. The high speed-up motivates exploration of hardware-aware Neural Operator Search (NOS) in complement to ongoing efforts on Neural Architecture Search (NAS).

</p>
</details>

<details><summary><b>Characterizing the SLOPE Trade-off: A Variational Perspective and the Donoho-Tanner Limit</b>
<a href="https://arxiv.org/abs/2105.13302">arxiv:2105.13302</a>
&#x1F4C8; 9 <br>
<p>Zhiqi Bu, Jason Klusowski, Cynthia Rush, Weijie J. Su</p></summary>
<p>

**Abstract:** Sorted l1 regularization has been incorporated into many methods for solving high-dimensional statistical estimation problems, including the SLOPE estimator in linear regression. In this paper, we study how this relatively new regularization technique improves variable selection by characterizing the optimal SLOPE trade-off between the false discovery proportion (FDP) and true positive proportion (TPP) or, equivalently, between measures of type I error and power. Assuming a regime of linear sparsity and working under Gaussian random designs, we obtain an upper bound on the optimal trade-off for SLOPE, showing its capability of breaking the Donoho-Tanner power limit. To put it into perspective, this limit is the highest possible power that the Lasso, which is perhaps the most popular l1-based method, can achieve even with arbitrarily strong effect sizes. Next, we derive a tight lower bound that delineates the fundamental limit of sorted l1 regularization in optimally trading the FDP off for the TPP. Finally, we show that on any problem instance, SLOPE with a certain regularization sequence outperforms the Lasso, in the sense of having a smaller FDP, larger TPP and smaller l2 estimation risk simultaneously. Our proofs are based on a novel technique that reduces a variational calculus problem to a class of infinite-dimensional convex optimization problems and a very recent result from approximate message passing theory.

</p>
</details>

<details><summary><b>Evaluation of concept drift adaptation for acoustic scene classifier based on Kernel Density Drift Detection and Combine Merge Gaussian Mixture Model</b>
<a href="https://arxiv.org/abs/2105.13220">arxiv:2105.13220</a>
&#x1F4C8; 9 <br>
<p>Ibnu Daqiqil Id, Masanobu Abe, Sunao Hara</p></summary>
<p>

**Abstract:** Based on the experimental results, all concepts drift types have their respective hyperparameter configurations. Simple and gradual concept drift have similar pattern which requires a smaller α value than recurring concept drift because, in this type of drift, a new concept appear continuously, so it needs a high-frequency model adaptation. However, in recurring concepts, the new concept may repeat in the future, so the lower frequency adaptation is better. Furthermore, high-frequency model adaptation could lead to an overfitting problem. Implementing CMGMM component pruning mechanism help to control the number of the active component and improve model performance.

</p>
</details>

<details><summary><b>Joint-DetNAS: Upgrade Your Detector with NAS, Pruning and Dynamic Distillation</b>
<a href="https://arxiv.org/abs/2105.12971">arxiv:2105.12971</a>
&#x1F4C8; 9 <br>
<p>Lewei Yao, Renjie Pi, Hang Xu, Wei Zhang, Zhenguo Li, Tong Zhang</p></summary>
<p>

**Abstract:** We propose Joint-DetNAS, a unified NAS framework for object detection, which integrates 3 key components: Neural Architecture Search, pruning, and Knowledge Distillation. Instead of naively pipelining these techniques, our Joint-DetNAS optimizes them jointly. The algorithm consists of two core processes: student morphism optimizes the student's architecture and removes the redundant parameters, while dynamic distillation aims to find the optimal matching teacher. For student morphism, weight inheritance strategy is adopted, allowing the student to flexibly update its architecture while fully utilize the predecessor's weights, which considerably accelerates the search; To facilitate dynamic distillation, an elastic teacher pool is trained via integrated progressive shrinking strategy, from which teacher detectors can be sampled without additional cost in subsequent searches. Given a base detector as the input, our algorithm directly outputs the derived student detector with high performance without additional training. Experiments demonstrate that our Joint-DetNAS outperforms the naive pipelining approach by a great margin. Given a classic R101-FPN as the base detector, Joint-DetNAS is able to boost its mAP from 41.4 to 43.9 on MS COCO and reduce the latency by 47%, which is on par with the SOTA EfficientDet while requiring less search cost. We hope our proposed method can provide the community with a new way of jointly optimizing NAS, KD and pruning.

</p>
</details>

<details><summary><b>Selective Knowledge Distillation for Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2105.12967">arxiv:2105.12967</a>
&#x1F4C8; 9 <br>
<p>Fusheng Wang, Jianhao Yan, Fandong Meng, Jie Zhou</p></summary>
<p>

**Abstract:** Neural Machine Translation (NMT) models achieve state-of-the-art performance on many translation benchmarks. As an active research field in NMT, knowledge distillation is widely applied to enhance the model's performance by transferring teacher model's knowledge on each training sample. However, previous work rarely discusses the different impacts and connections among these samples, which serve as the medium for transferring teacher knowledge. In this paper, we design a novel protocol that can effectively analyze the different impacts of samples by comparing various samples' partitions. Based on above protocol, we conduct extensive experiments and find that the teacher's knowledge is not the more, the better. Knowledge over specific samples may even hurt the whole performance of knowledge distillation. Finally, to address these issues, we propose two simple yet effective strategies, i.e., batch-level and global-level selections, to pick suitable samples for distillation. We evaluate our approaches on two large-scale machine translation tasks, WMT'14 English->German and WMT'19 Chinese->English. Experimental results show that our approaches yield up to +1.28 and +0.89 BLEU points improvements over the Transformer baseline, respectively.

</p>
</details>

<details><summary><b>TensorFlow RiemOpt: a library for optimization on Riemannian manifolds</b>
<a href="https://arxiv.org/abs/2105.13921">arxiv:2105.13921</a>
&#x1F4C8; 8 <br>
<p>Oleg Smirnov</p></summary>
<p>

**Abstract:** The adoption of neural networks and deep learning in non-Euclidean domains has been hindered until recently by the lack of scalable and efficient learning frameworks. Existing toolboxes in this space were mainly motivated by research and education use cases, whereas practical aspects, such as deploying and maintaining machine learning models, were often overlooked.
  We attempt to bridge this gap by proposing TensorFlow RiemOpt, a Python library for optimization on Riemannian manifolds in TensorFlow. The library is designed with the aim for a seamless integration with the TensorFlow ecosystem, targeting not only research, but also streamlining production machine learning pipelines.

</p>
</details>

<details><summary><b>A Modular and Transferable Reinforcement Learning Framework for the Fleet Rebalancing Problem</b>
<a href="https://arxiv.org/abs/2105.13284">arxiv:2105.13284</a>
&#x1F4C8; 8 <br>
<p>Erotokritos Skordilis, Yi Hou, Charles Tripp, Matthew Moniot, Peter Graf, David Biagioni</p></summary>
<p>

**Abstract:** Mobility on demand (MoD) systems show great promise in realizing flexible and efficient urban transportation. However, significant technical challenges arise from operational decision making associated with MoD vehicle dispatch and fleet rebalancing. For this reason, operators tend to employ simplified algorithms that have been demonstrated to work well in a particular setting. To help bridge the gap between novel and existing methods, we propose a modular framework for fleet rebalancing based on model-free reinforcement learning (RL) that can leverage an existing dispatch method to minimize system cost. In particular, by treating dispatch as part of the environment dynamics, a centralized agent can learn to intermittently direct the dispatcher to reposition free vehicles and mitigate against fleet imbalance. We formulate RL state and action spaces as distributions over a grid partitioning of the operating area, making the framework scalable and avoiding the complexities associated with multiagent RL. Numerical experiments, using real-world trip and network data, demonstrate that this approach has several distinct advantages over baseline methods including: improved system cost; high degree of adaptability to the selected dispatch method; and the ability to perform scale-invariant transfer learning between problem instances with similar vehicle and request distributions.

</p>
</details>

<details><summary><b>GoSafe: Globally Optimal Safe Robot Learning</b>
<a href="https://arxiv.org/abs/2105.13281">arxiv:2105.13281</a>
&#x1F4C8; 8 <br>
<p>Dominik Baumann, Alonso Marco, Matteo Turchetta, Sebastian Trimpe</p></summary>
<p>

**Abstract:** When learning policies for robotic systems from data, safety is a major concern, as violation of safety constraints may cause hardware damage. SafeOpt is an efficient Bayesian optimization (BO) algorithm that can learn policies while guaranteeing safety with high probability. However, its search space is limited to an initially given safe region. We extend this method by exploring outside the initial safe area while still guaranteeing safety with high probability. This is achieved by learning a set of initial conditions from which we can recover safely using a learned backup controller in case of a potential failure. We derive conditions for guaranteed convergence to the global optimum and validate GoSafe in hardware experiments.

</p>
</details>

<details><summary><b>A Microarchitecture Implementation Framework for Online Learning with Temporal Neural Networks</b>
<a href="https://arxiv.org/abs/2105.13262">arxiv:2105.13262</a>
&#x1F4C8; 8 <br>
<p>Harideep Nair, John Paul Shen, James E. Smith</p></summary>
<p>

**Abstract:** Temporal Neural Networks (TNNs) are spiking neural networks that use time as a resource to represent and process information, similar to the mammalian neocortex. In contrast to compute-intensive deep neural networks that employ separate training and inference phases, TNNs are capable of extremely efficient online incremental/continual learning and are excellent candidates for building edge-native sensory processing units. This work proposes a microarchitecture framework for implementing TNNs using standard CMOS. Gate-level implementations of three key building blocks are presented: 1) multi-synapse neurons, 2) multi-neuron columns, and 3) unsupervised and supervised online learning algorithms based on Spike Timing Dependent Plasticity (STDP). The proposed microarchitecture is embodied in a set of characteristic scaling equations for assessing the gate count, area, delay and power for any TNN design. Post-synthesis results (in 45nm CMOS) for the proposed designs are presented, and their online incremental learning capability is demonstrated.

</p>
</details>

<details><summary><b>Bayesian Optimisation for Constrained Problems</b>
<a href="https://arxiv.org/abs/2105.13245">arxiv:2105.13245</a>
&#x1F4C8; 8 <br>
<p>Juan Ungredda, Juergen Branke</p></summary>
<p>

**Abstract:** Many real-world optimisation problems such as hyperparameter tuning in machine learning or simulation-based optimisation can be formulated as expensive-to-evaluate black-box functions. A popular approach to tackle such problems is Bayesian optimisation (BO), which builds a response surface model based on the data collected so far, and uses the mean and uncertainty predicted by the model to decide what information to collect next. In this paper, we propose a novel variant of the well-known Knowledge Gradient acquisition function that allows it to handle constraints. We empirically compare the new algorithm with four other state-of-the-art constrained Bayesian optimisation algorithms and demonstrate its superior performance. We also prove theoretical convergence in the infinite budget limit.

</p>
</details>

<details><summary><b>Optimization Induced Equilibrium Networks</b>
<a href="https://arxiv.org/abs/2105.13228">arxiv:2105.13228</a>
&#x1F4C8; 8 <br>
<p>Xingyu Xie, Qiuhao Wang, Zenan Ling, Xia Li, Yisen Wang, Guangcan Liu, Zhouchen Lin</p></summary>
<p>

**Abstract:** Implicit equilibrium models, i.e., deep neural networks (DNNs) defined by implicit equations, have been becoming more and more attractive recently. In this paper, we investigate an emerging question: can an implicit equilibrium model's equilibrium point be regarded as the solution of an optimization problem? To this end, we first decompose DNNs into a new class of unit layer that is the proximal operator of an implicit convex function while keeping its output unchanged. Then, the equilibrium model of the unit layer can be derived, named Optimization Induced Equilibrium Networks (OptEq), which can be easily extended to deep layers. The equilibrium point of OptEq can be theoretically connected to the solution of its corresponding convex optimization problem with explicit objectives. Based on this, we can flexibly introduce prior properties to the equilibrium points: 1) modifying the underlying convex problems explicitly so as to change the architectures of OptEq; and 2) merging the information into the fixed point iteration, which guarantees to choose the desired equilibrium point when the fixed point set is non-singleton. We show that deep OptEq outperforms previous implicit models even with fewer parameters. This work establishes the first step towards the optimization-guided design of deep models.

</p>
</details>

<details><summary><b>ProtAugment: Unsupervised diverse short-texts paraphrasing for intent detection meta-learning</b>
<a href="https://arxiv.org/abs/2105.12995">arxiv:2105.12995</a>
&#x1F4C8; 8 <br>
<p>Thomas Dopierre, Christophe Gravier, Wilfried Logerais</p></summary>
<p>

**Abstract:** Recent research considers few-shot intent detection as a meta-learning problem: the model is learning to learn from a consecutive set of small tasks named episodes. In this work, we propose ProtAugment, a meta-learning algorithm for short texts classification (the intent detection task). ProtAugment is a novel extension of Prototypical Networks, that limits overfitting on the bias introduced by the few-shots classification objective at each episode. It relies on diverse paraphrasing: a conditional language model is first fine-tuned for paraphrasing, and diversity is later introduced at the decoding stage at each meta-learning episode. The diverse paraphrasing is unsupervised as it is applied to unlabelled data, and then fueled to the Prototypical Network training objective as a consistency loss. ProtAugment is the state-of-the-art method for intent detection meta-learning, at no extra labeling efforts and without the need to fine-tune a conditional language model on a given application domain.

</p>
</details>

<details><summary><b>Non-negative matrix factorization algorithms greatly improve topic model fits</b>
<a href="https://arxiv.org/abs/2105.13440">arxiv:2105.13440</a>
&#x1F4C8; 7 <br>
<p>Peter Carbonetto, Abhishek Sarkar, Zihao Wang, Matthew Stephens</p></summary>
<p>

**Abstract:** We report on the potential for using algorithms for non-negative matrix factorization (NMF) to improve parameter estimation in topic models. While several papers have studied connections between NMF and topic models, none have suggested leveraging these connections to develop new algorithms for fitting topic models. Importantly, NMF avoids the "sum-to-one" constraints on the topic model parameters, resulting in an optimization problem with simpler structure and more efficient computations. Building on recent advances in optimization algorithms for NMF, we show that first solving the NMF problem then recovering the topic model fit can produce remarkably better fits, and in less time, than standard algorithms for topic models. While we focus primarily on maximum likelihood estimation, we show that this approach also has the potential to improve variational inference for topic models. Our methods are implemented in the R package fastTopics.

</p>
</details>

<details><summary><b>Optimization in Open Networks via Dual Averaging</b>
<a href="https://arxiv.org/abs/2105.13348">arxiv:2105.13348</a>
&#x1F4C8; 7 <br>
<p>Yu-Guan Hsieh, Franck Iutzeler, Jérôme Malick, Panayotis Mertikopoulos</p></summary>
<p>

**Abstract:** In networks of autonomous agents (e.g., fleets of vehicles, scattered sensors), the problem of minimizing the sum of the agents' local functions has received a lot of interest. We tackle here this distributed optimization problem in the case of open networks when agents can join and leave the network at any time. Leveraging recent online optimization techniques, we propose and analyze the convergence of a decentralized asynchronous optimization method for open networks.

</p>
</details>

<details><summary><b>MeshCNN Fundamentals: Geometric Learning through a Reconstructable Representation</b>
<a href="https://arxiv.org/abs/2105.13277">arxiv:2105.13277</a>
&#x1F4C8; 7 <br>
<p>Amir Barda, Yotam Erel, Amit H. Bermano</p></summary>
<p>

**Abstract:** Mesh-based learning is one of the popular approaches nowadays to learn shapes. The most established backbone in this field is MeshCNN. In this paper, we propose infusing MeshCNN with geometric reasoning to achieve higher quality learning. Through careful analysis of the way geometry is represented through-out the network, we submit that this representation should be rigid motion invariant, and should allow reconstructing the original geometry. Accordingly, we introduce the first and second fundamental forms as an edge-centric, rotation and translation invariant, reconstructable representation. In addition, we update the originally proposed pooling scheme to be more geometrically driven. We validate our analysis through experimentation, and present consistent improvement upon the MeshCNN baseline, as well as other more elaborate state-of-the-art architectures. Furthermore, we demonstrate this fundamental forms-based representation opens the door to accessible generative machine learning over meshes.

</p>
</details>

<details><summary><b>HDRUNet: Single Image HDR Reconstruction with Denoising and Dequantization</b>
<a href="https://arxiv.org/abs/2105.13084">arxiv:2105.13084</a>
&#x1F4C8; 7 <br>
<p>Xiangyu Chen, Yihao Liu, Zhengwen Zhang, Yu Qiao, Chao Dong</p></summary>
<p>

**Abstract:** Most consumer-grade digital cameras can only capture a limited range of luminance in real-world scenes due to sensor constraints. Besides, noise and quantization errors are often introduced in the imaging process. In order to obtain high dynamic range (HDR) images with excellent visual quality, the most common solution is to combine multiple images with different exposures. However, it is not always feasible to obtain multiple images of the same scene and most HDR reconstruction methods ignore the noise and quantization loss. In this work, we propose a novel learning-based approach using a spatially dynamic encoder-decoder network, HDRUNet, to learn an end-to-end mapping for single image HDR reconstruction with denoising and dequantization. The network consists of a UNet-style base network to make full use of the hierarchical multi-scale information, a condition network to perform pattern-specific modulation and a weighting network for selectively retaining information. Moreover, we propose a Tanh_L1 loss function to balance the impact of over-exposed values and well-exposed values on the network learning. Our method achieves the state-of-the-art performance in quantitative comparisons and visual quality. The proposed HDRUNet model won the second place in the single frame track of NITRE2021 High Dynamic Range Challenge.

</p>
</details>

<details><summary><b>Maria: A Visual Experience Powered Conversational Agent</b>
<a href="https://arxiv.org/abs/2105.13073">arxiv:2105.13073</a>
&#x1F4C8; 7 <br>
<p>Zujie Liang, Huang Hu, Can Xu, Chongyang Tao, Xiubo Geng, Yining Chen, Fan Liang, Daxin Jiang</p></summary>
<p>

**Abstract:** Arguably, the visual perception of conversational agents to the physical world is a key way for them to exhibit the human-like intelligence. Image-grounded conversation is thus proposed to address this challenge. Existing works focus on exploring the multimodal dialog models that ground the conversation on a given image. In this paper, we take a step further to study image-grounded conversation under a fully open-ended setting where no paired dialog and image are assumed available. Specifically, we present Maria, a neural conversation agent powered by the visual world experiences which are retrieved from a large-scale image index. Maria consists of three flexible components, i.e., text-to-image retriever, visual concept detector and visual-knowledge-grounded response generator. The retriever aims to retrieve a correlated image to the dialog from an image index, while the visual concept detector extracts rich visual knowledge from the image. Then, the response generator is grounded on the extracted visual knowledge and dialog context to generate the target response. Extensive experiments demonstrate Maria outperforms previous state-of-the-art methods on automatic metrics and human evaluation, and can generate informative responses that have some visual commonsense of the physical world.

</p>
</details>

<details><summary><b>Efficient High-Resolution Image-to-Image Translation using Multi-Scale Gradient U-Net</b>
<a href="https://arxiv.org/abs/2105.13067">arxiv:2105.13067</a>
&#x1F4C8; 7 <br>
<p>Kumarapu Laxman, Shiv Ram Dubey, Baddam Kalyan, Satya Raj Vineel Kojjarapu</p></summary>
<p>

**Abstract:** Recently, Conditional Generative Adversarial Network (Conditional GAN) have shown very promising performance in several image-to-image translation applications. However, the uses of these conditional GANs are quite limited to low-resolution images, such as 256X256.The Pix2Pix-HD is a recent attempt to utilize the conditional GAN for high-resolution image synthesis. In this paper, we propose a Multi-Scale Gradient based U-Net (MSG U-Net) model for high-resolution image-to-image translation up to 2048X1024 resolution. The proposed model is trained by allowing the flow of gradients from multiple-discriminators to a single generator at multiple scales. The proposed MSG U-Net architecture leads to photo-realistic high-resolution image-to-image translation. Moreover, the proposed model is computationally efficient as com-pared to the Pix2Pix-HD with an improvement in the inference time nearly by 2.5 times. We provide the code of MSG U-Net model at https://github.com/laxmaniron/MSG-U-Net.

</p>
</details>

<details><summary><b>Put your money where your mouth is: Using deep learning to identify consumer tribes from word usage</b>
<a href="https://arxiv.org/abs/2105.13036">arxiv:2105.13036</a>
&#x1F4C8; 7 <br>
<p>P. Gloor, A. Fronzetti Colladon, J. M. de Oliveira, P. Rovelli</p></summary>
<p>

**Abstract:** Internet and social media offer firms novel ways of managing their marketing strategy and gain competitive advantage. The groups of users expressing themselves on the Internet about a particular topic, product, or brand are frequently called a virtual tribe or E-tribe. However, there are no automatic tools for identifying and studying the characteristics of these virtual tribes. Towards this aim, this paper presents Tribefinder, a system to reveal Twitter users' tribal affiliations, by analyzing their tweets and language use. To show the potential of this instrument, we provide an example considering three specific tribal macro-categories: alternative realities, lifestyle, and recreation. In addition, we discuss the different characteristics of each identified tribe, in terms of use of language and social interaction metrics. Tribefinder illustrates the importance of adopting a new lens for studying virtual tribes, which is crucial for firms to properly design their marketing strategy, and for scholars to extend prior marketing research.

</p>
</details>

<details><summary><b>Geodesy of irregular small bodies via neural density fields: geodesyNets</b>
<a href="https://arxiv.org/abs/2105.13031">arxiv:2105.13031</a>
&#x1F4C8; 7 <br>
<p>Dario Izzo, Pablo Gómez</p></summary>
<p>

**Abstract:** We present a novel approach based on artificial neural networks, so-called geodesyNets, and present compelling evidence of their ability to serve as accurate geodetic models of highly irregular bodies using minimal prior information on the body. The approach does not rely on the body shape information but, if available, can harness it. GeodesyNets learn a three-dimensional, differentiable, function representing the body density, which we call neural density field. The body shape, as well as other geodetic properties, can easily be recovered. We investigate six different shapes including the bodies 101955 Bennu, 67P Churyumov-Gerasimenko, 433 Eros and 25143 Itokawa for which shape models developed during close proximity surveys are available. Both heterogeneous and homogeneous mass distributions are considered. The gravitational acceleration computed from the trained geodesyNets models, as well as the inferred body shape, show great accuracy in all cases with a relative error on the predicted acceleration smaller than 1\% even close to the asteroid surface. When the body shape information is available, geodesyNets can seamlessly exploit it and be trained to represent a high-fidelity neural density field able to give insights into the internal structure of the body. This work introduces a new unexplored approach to geodesy, adding a powerful tool to consolidated ones based on spherical harmonics, mascon models and polyhedral gravity.

</p>
</details>

<details><summary><b>Hybrid Encoding For Generating Large Scale Game Level Patterns With Local Variations</b>
<a href="https://arxiv.org/abs/2105.12960">arxiv:2105.12960</a>
&#x1F4C8; 7 <br>
<p>Jacob Schrum, Benjamin Capps, Kirby Steckel, Vanessa Volz, Sebastian Risi</p></summary>
<p>

**Abstract:** Generative Adversarial Networks (GANs) are a powerful indirect genotype-to-phenotype mapping for evolutionary search. Much previous work applying GANs to level generation focuses on fixed-size segments combined into a whole level, but individual segments may not fit together cohesively. In contrast, segments in human designed levels are often repeated, directly or with variation, and organized into patterns (the symmetric eagle in Level 1 of The Legend of Zelda, or repeated pipe motifs in Super Mario Bros). Such patterns can be produced with Compositional Pattern Producing Networks (CPPNs). CPPNs define latent vector GAN inputs as a function of geometry, organizing segments output by a GAN into complete levels. However, collections of latent vectors can also be evolved directly, producing more chaotic levels. We propose a hybrid approach that evolves CPPNs first, but allows latent vectors to evolve later, combining the benefits of both approaches. These approaches are evaluated in Super Mario Bros. and The Legend of Zelda. We previously demonstrated via divergent search (MAP-Elites) that CPPNs better cover the space of possible levels than directly evolved levels. Here, we show that the hybrid approach (1) covers areas that neither of the other methods can, and (2) achieves comparable or superior QD scores.

</p>
</details>

<details><summary><b>Learning Dynamic Graph Representation of Brain Connectome with Spatio-Temporal Attention</b>
<a href="https://arxiv.org/abs/2105.13495">arxiv:2105.13495</a>
&#x1F4C8; 6 <br>
<p>Byung-Hoon Kim, Jong Chul Ye, Jae-Jin Kim</p></summary>
<p>

**Abstract:** Functional connectivity (FC) between regions of the brain can be assessed by the degree of temporal correlation measured with functional neuroimaging modalities. Based on the fact that these connectivities build a network, graph-based approaches for analyzing the brain connectome have provided insights into the functions of the human brain. The development of graph neural networks (GNNs) capable of learning representation from graph structured data has led to increased interest in learning the graph representation of the brain connectome. Although recent attempts to apply GNN to the FC network have shown promising results, there is still a common limitation that they usually do not incorporate the dynamic characteristics of the FC network which fluctuates over time. In addition, a few studies that have attempted to use dynamic FC as an input for the GNN reported a reduction in performance compared to static FC methods, and did not provide temporal explainability. Here, we propose STAGIN, a method for learning dynamic graph representation of the brain connectome with spatio-temporal attention. Specifically, a temporal sequence of brain graphs is input to the STAGIN to obtain the dynamic graph representation, while novel READOUT functions and the Transformer encoder provide spatial and temporal explainability with attention, respectively. Experiments on the HCP-Rest and the HCP-Task datasets demonstrate exceptional performance of our proposed method. Analysis of the spatio-temporal attention also provide concurrent interpretation with the neuroscientific knowledge, which further validates our method. Code is available at https://github.com/egyptdj/stagin

</p>
</details>

<details><summary><b>Time Varying Particle Data Feature Extraction and Tracking with Neural Networks</b>
<a href="https://arxiv.org/abs/2105.13240">arxiv:2105.13240</a>
&#x1F4C8; 6 <br>
<p>Haoyu Li, Han-Wei Shen</p></summary>
<p>

**Abstract:** Analyzing particle data plays an important role in many scientific applications such as fluid simulation, cosmology simulation and molecular dynamics. While there exist methods that can perform feature extraction and tracking for volumetric data, performing those tasks for particle data is more challenging because of the lack of explicit connectivity information. Although one may convert the particle data to volume first, this approach is at risk of incurring error and increasing the size of the data. In this paper, we take a deep learning approach to create feature representations for scientific particle data to assist feature extraction and tracking. We employ a deep learning model, which produces latent vectors to represent the relation between spatial locations and physical attributes in a local neighborhood. With the latent vectors, features can be extracted by clustering these vectors. To achieve fast feature tracking, the mean-shift tracking algorithm is applied in the feature space, which only requires inference of the latent vector for selected regions of interest. We validate our approach using two datasets and compare our method with other existing methods.

</p>
</details>

<details><summary><b>Integrating Semantics and Neighborhood Information with Graph-Driven Generative Models for Document Retrieval</b>
<a href="https://arxiv.org/abs/2105.13066">arxiv:2105.13066</a>
&#x1F4C8; 6 <br>
<p>Zijing Ou, Qinliang Su, Jianxing Yu, Bang Liu, Jingwen Wang, Ruihui Zhao, Changyou Chen, Yefeng Zheng</p></summary>
<p>

**Abstract:** With the need of fast retrieval speed and small memory footprint, document hashing has been playing a crucial role in large-scale information retrieval. To generate high-quality hashing code, both semantics and neighborhood information are crucial. However, most existing methods leverage only one of them or simply combine them via some intuitive criteria, lacking a theoretical principle to guide the integration process. In this paper, we encode the neighborhood information with a graph-induced Gaussian distribution, and propose to integrate the two types of information with a graph-driven generative model. To deal with the complicated correlations among documents, we further propose a tree-structured approximation method for learning. Under the approximation, we prove that the training objective can be decomposed into terms involving only singleton or pairwise documents, enabling the model to be trained as efficiently as uncorrelated ones. Extensive experimental results on three benchmark datasets show that our method achieves superior performance over state-of-the-art methods, demonstrating the effectiveness of the proposed model for simultaneously preserving semantic and neighborhood information.\

</p>
</details>

<details><summary><b>A generalization of the randomized singular value decomposition</b>
<a href="https://arxiv.org/abs/2105.13052">arxiv:2105.13052</a>
&#x1F4C8; 6 <br>
<p>Nicolas Boullé, Alex Townsend</p></summary>
<p>

**Abstract:** The randomized singular value decomposition (SVD) is a popular and effective algorithm for computing a near-best rank $k$ approximation of a matrix $A$ using matrix-vector products with standard Gaussian vectors. Here, we generalize the theory of randomized SVD to multivariate Gaussian vectors, allowing one to incorporate prior knowledge of $A$ into the algorithm. This enables us to explore the continuous analogue of the randomized SVD for Hilbert--Schmidt (HS) operators using operator-function products with functions drawn from a Gaussian process (GP). We then construct a new covariance kernel for GPs, based on weighted Jacobi polynomials, which allows us to rapidly sample the GP and control the smoothness of the randomly generated functions. Numerical examples on matrices and HS operators demonstrate the applicability of the algorithm.

</p>
</details>

<details><summary><b>Feature Reuse and Fusion for Real-time Semantic segmentation</b>
<a href="https://arxiv.org/abs/2105.12964">arxiv:2105.12964</a>
&#x1F4C8; 6 <br>
<p>Tan Sixiang</p></summary>
<p>

**Abstract:** For real-time semantic segmentation, how to increase the speed while maintaining high resolution is a problem that has been discussed and solved. Backbone design and fusion design have always been two essential parts of real-time semantic segmentation. We hope to design a light-weight network based on previous design experience and reach the level of state-of-the-art real-time semantic segmentation without any pre-training. To achieve this goal, a encoder-decoder architectures are proposed to solve this problem by applying a decoder network onto a backbone model designed for real-time segmentation tasks and designed three different ways to fuse semantics and detailed information in the aggregation phase. We have conducted extensive experiments on two semantic segmentation benchmarks. Experiments on the Cityscapes and CamVid datasets show that the proposed FRFNet strikes a balance between speed calculation and accuracy. It achieves 72% Mean Intersection over Union (mIoU%) on the Cityscapes test dataset with the speed of 144 on a single RTX 1080Ti card. The Code is available at https://github.com/favoMJ/FRFNet.

</p>
</details>

<details><summary><b>Neural Entity Recognition with Gazetteer based Fusion</b>
<a href="https://arxiv.org/abs/2105.13225">arxiv:2105.13225</a>
&#x1F4C8; 5 <br>
<p>Qing Sun, Parminder Bhatia</p></summary>
<p>

**Abstract:** Incorporating external knowledge into Named Entity Recognition (NER) systems has been widely studied in the generic domain. In this paper, we focus on clinical domain where only limited data is accessible and interpretability is important. Recent advancement in technology and the acceleration of clinical trials has resulted in the discovery of new drugs, procedures as well as medical conditions. These factors motivate towards building robust zero-shot NER systems which can quickly adapt to new medical terminology. We propose an auxiliary gazetteer model and fuse it with an NER system, which results in better robustness and interpretability across different clinical datasets. Our gazetteer based fusion model is data efficient, achieving +1.7 micro-F1 gains on the i2b2 dataset using 20% training data, and brings + 4.7 micro-F1 gains on novel entity mentions never presented during training. Moreover, our fusion model is able to quickly adapt to new mentions in gazetteers without re-training and the gains from the proposed fusion model are transferable to related datasets.

</p>
</details>

<details><summary><b>Recurrent-type Neural Networks for Real-time Short-term Prediction of Ship Motions in High Sea State</b>
<a href="https://arxiv.org/abs/2105.13102">arxiv:2105.13102</a>
&#x1F4C8; 5 <br>
<p>Danny D'Agostino, Andrea Serani, Frederick Stern, Matteo Diez</p></summary>
<p>

**Abstract:** The prediction capability of recurrent-type neural networks is investigated for real-time short-term prediction (nowcasting) of ship motions in high sea state. Specifically, the performance of recurrent neural networks, long-short term memory, and gated recurrent units models are assessed and compared using a data set coming from computational fluid dynamics simulations of a self-propelled destroyer-type vessel in stern-quartering sea state 7. Time series of incident wave, ship motions, rudder angle, as well as immersion probes, are used as variables for a nowcasting problem. The objective is to obtain about 20 s ahead prediction. Overall, the three methods provide promising and comparable results.

</p>
</details>

<details><summary><b>Fair Feature Distillation for Visual Recognition</b>
<a href="https://arxiv.org/abs/2106.04411">arxiv:2106.04411</a>
&#x1F4C8; 4 <br>
<p>Sangwon Jung, Donggyu Lee, Taeeon Park, Taesup Moon</p></summary>
<p>

**Abstract:** Fairness is becoming an increasingly crucial issue for computer vision, especially in the human-related decision systems. However, achieving algorithmic fairness, which makes a model produce indiscriminative outcomes against protected groups, is still an unresolved problem. In this paper, we devise a systematic approach which reduces algorithmic biases via feature distillation for visual recognition tasks, dubbed as MMD-based Fair Distillation (MFD). While the distillation technique has been widely used in general to improve the prediction accuracy, to the best of our knowledge, there has been no explicit work that also tries to improve fairness via distillation. Furthermore, We give a theoretical justification of our MFD on the effect of knowledge distillation and fairness. Throughout the extensive experiments, we show our MFD significantly mitigates the bias against specific minorities without any loss of the accuracy on both synthetic and real-world face datasets.

</p>
</details>

<details><summary><b>Inertial Sensor Data To Image Encoding For Human Action Recognition</b>
<a href="https://arxiv.org/abs/2105.13533">arxiv:2105.13533</a>
&#x1F4C8; 4 <br>
<p>Zeeshan Ahmad, Naimul Khan</p></summary>
<p>

**Abstract:** Convolutional Neural Networks (CNNs) are successful deep learning models in the field of computer vision. To get the maximum advantage of CNN model for Human Action Recognition (HAR) using inertial sensor data, in this paper, we use 4 types of spatial domain methods for transforming inertial sensor data to activity images, which are then utilized in a novel fusion framework. These four types of activity images are Signal Images (SI), Gramian Angular Field (GAF) Images, Markov Transition Field (MTF) Images and Recurrence Plot (RP) Images. Furthermore, for creating a multimodal fusion framework and to exploit activity image, we made each type of activity images multimodal by convolving with two spatial domain filters : Prewitt filter and High-boost filter. Resnet-18, a CNN model, is used to learn deep features from multi-modalities. Learned features are extracted from the last pooling layer of each ReNet and then fused by canonical correlation based fusion (CCF) for improving the accuracy of human action recognition. These highly informative features are served as input to a multiclass Support Vector Machine (SVM). Experimental results on three publicly available inertial datasets show the superiority of the proposed method over the current state-of-the-art.

</p>
</details>

<details><summary><b>Flow based features and validation metric for machine learning reconstruction of PIV data</b>
<a href="https://arxiv.org/abs/2105.13429">arxiv:2105.13429</a>
&#x1F4C8; 4 <br>
<p>Ghasem Akbari, Nader Montazerin</p></summary>
<p>

**Abstract:** Reconstruction of flow field from real sparse data by a physics-oriented approach is a current challenge for fluid scientists in the AI community. The problem includes feature recognition and implementation of AI algorithms that link data to a physical feature space in order to produce reconstructed data. The present article applies machine learning approach to study contribution of different flow-based features with practical fluid mechanics applications for reconstruction of the missing data of turbomachinery PIV measurements. Support vector regression (SVR) and multi-layer perceptron (MLP) are selected as two robust regressors capable of modelling non-linear fluid flow phenomena. The proposed flow-based features are optimally scaled and filtered to extract the best configuration. In addition to conventional data-based validation of the regressors, a metric is proposed that reflects mass conservation law as an important requirement for a physical flow reproduction. For a velocity field including 25% of clustered missing data, the reconstruction accuracy achieved by SVR in terms of R2-score is as high as 0.993 for the in-plane velocity vectors in comparison with that obtained by MLP which is up to 0.981. In terms of mass conservation metric, the SVR model by R2-score up to 0.96 is considerably more accurate than the MLP estimator. For extremely sparse data with a gappiness of 75%, vector and contour plots from SVR and MLP were consistent with those of the original field.

</p>
</details>

<details><summary><b>Cardiac Segmentation on CT Images through Shape-Aware Contour Attentions</b>
<a href="https://arxiv.org/abs/2105.13153">arxiv:2105.13153</a>
&#x1F4C8; 4 <br>
<p>Sanguk Park, Minyoung Chung</p></summary>
<p>

**Abstract:** Cardiac segmentation of atriums, ventricles, and myocardium in computed tomography (CT) images is an important first-line task for presymptomatic cardiovascular disease diagnosis. In several recent studies, deep learning models have shown significant breakthroughs in medical image segmentation tasks. Unlike other organs such as the lungs and liver, the cardiac organ consists of multiple substructures, i.e., ventricles, atriums, aortas, arteries, veins, and myocardium. These cardiac substructures are proximate to each other and have indiscernible boundaries (i.e., homogeneous intensity values), making it difficult for the segmentation network focus on the boundaries between the substructures. In this paper, to improve the segmentation accuracy between proximate organs, we introduce a novel model to exploit shape and boundary-aware features. We primarily propose a shape-aware attention module, that exploits distance regression, which can guide the model to focus on the edges between substructures so that it can outperform the conventional contour-based attention method. In the experiments, we used the Multi-Modality Whole Heart Segmentation dataset that has 20 CT cardiac images for training and validation, and 40 CT cardiac images for testing. The experimental results show that the proposed network produces more accurate results than state-of-the-art networks by improving the Dice similarity coefficient score by 4.97%. Our proposed shape-aware contour attention mechanism demonstrates that distance transformation and boundary features improve the actual attention map to strengthen the responses in the boundary area. Moreover, our proposed method significantly reduces the false-positive responses of the final output, resulting in accurate segmentation.

</p>
</details>

<details><summary><b>An error analysis of generative adversarial networks for learning distributions</b>
<a href="https://arxiv.org/abs/2105.13010">arxiv:2105.13010</a>
&#x1F4C8; 4 <br>
<p>Jian Huang, Yuling Jiao, Zhen Li, Shiao Liu, Yang Wang, Yunfei Yang</p></summary>
<p>

**Abstract:** This paper studies how well generative adversarial networks (GANs) learn probability distributions from finite samples. Our main results establish the convergence rates of GANs under a collection of integral probability metrics defined through Hölder classes, including the Wasserstein distance as a special case. We also show that GANs are able to adaptively learn data distributions with low-dimensional structures or have Hölder densities, when the network architectures are chosen properly. In particular, for distributions concentrated around a low-dimensional set, we show that the learning rates of GANs do not depend on the high ambient dimension, but on the lower intrinsic dimension. Our analysis is based on a new oracle inequality decomposing the estimation error into the generator and discriminator approximation error and the statistical error, which may be of independent interest.

</p>
</details>

<details><summary><b>Intellige: A User-Facing Model Explainer for Narrative Explanations</b>
<a href="https://arxiv.org/abs/2105.12941">arxiv:2105.12941</a>
&#x1F4C8; 4 <br>
<p>Jilei Yang, Diana Negoescu, Parvez Ahammad</p></summary>
<p>

**Abstract:** Predictive machine learning models often lack interpretability, resulting in low trust from model end users despite having high predictive performance. While many model interpretation approaches return top important features to help interpret model predictions, these top features may not be well-organized or intuitive to end users, which limits model adoption rates. In this paper, we propose Intellige, a user-facing model explainer that creates user-digestible interpretations and insights reflecting the rationale behind model predictions. Intellige builds an end-to-end pipeline from machine learning platforms to end user platforms, and provides users with an interface for implementing model interpretation approaches and for customizing narrative insights. Intellige is a platform consisting of four components: Model Importer, Model Interpreter, Narrative Generator, and Narrative Exporter. We describe these components, and then demonstrate the effectiveness of Intellige through use cases at LinkedIn. Quantitative performance analyses indicate that Intellige's narrative insights lead to lifts in adoption rates of predictive model recommendations, as well as to increases in downstream key metrics such as revenue when compared to previous approaches, while qualitative analyses indicate positive feedback from end users.

</p>
</details>

<details><summary><b>Detection of marine floating plastic using Sentinel-2 imagery and machine learning models</b>
<a href="https://arxiv.org/abs/2106.03694">arxiv:2106.03694</a>
&#x1F4C8; 3 <br>
<p>Srikanta Sannigrahi, Bidroha Basu, Arunima Sarkar Basu, Francesco Pilla</p></summary>
<p>

**Abstract:** The increasing level of marine plastic pollution poses severe threats to the marine ecosystem and biodiversity. The present study attempted to explore the full functionality of open Sentinel satellite data and ML models for detecting and classifying floating plastic debris in Mytilene (Greece), Limassol (Cyprus), Calabria (Italy), and Beirut (Lebanon). Two ML models, i.e. Support Vector Machine (SVM) and Random Forest (RF) were utilized to carry out the classification analysis. In-situ plastic location data was collected from the control experiment conducted in Mytilene, Greece and Limassol, Cyprus, and the same was considered for training the models. Both remote sensing bands and spectral indices were used for developing the ML models. A spectral signature profile for plastic was created for discriminating the floating plastic from other marine debris. A newly developed index, kernel Normalized Difference Vegetation Index (kNDVI), was incorporated into the modelling to examine its contribution to model performances. Both SVM and RF were performed well in five models and test case combinations. Among the two ML models, the highest performance was measured for the RF. The inclusion of kNDVI was found effective and increased the model performances, reflected by high balanced accuracy measured for model 2 (~80% to ~98 % for SVM and ~87% to ~97 % for RF). Using the best-performed model, an automated floating plastic detection system was developed and tested in Calabria and Beirut. For both sites, the trained model had detected the floating plastic with ~99% accuracy. Among the six predictors, the FDI was found the most important variable for detecting marine floating plastic. These findings collectively suggest that high-resolution remote sensing imagery and the automated ML models can be an effective alternative for the cost-effective detection of marine floating plastic.

</p>
</details>

<details><summary><b>Embedded Vision for Self-Driving on Forest Roads</b>
<a href="https://arxiv.org/abs/2105.13754">arxiv:2105.13754</a>
&#x1F4C8; 3 <br>
<p>Sorin Grigorescu, Mihai Zaha, Bogdan Trasnea, Cosmin Ginerica</p></summary>
<p>

**Abstract:** Forest roads in Romania are unique natural wildlife sites used for recreation by countless tourists. In order to protect and maintain these roads, we propose RovisLab AMTU (Autonomous Mobile Test Unit), which is a robotic system designed to autonomously navigate off-road terrain and inspect if any deforestation or damage occurred along tracked route. AMTU's core component is its embedded vision module, optimized for real-time environment perception. For achieving a high computation speed, we use a learning system to train a multi-task Deep Neural Network (DNN) for scene and instance segmentation of objects, while the keypoints required for simultaneous localization and mapping are calculated using a handcrafted FAST feature detector and the Lucas-Kanade tracking algorithm. Both the DNN and the handcrafted backbone are run in parallel on the GPU of an NVIDIA AGX Xavier board. We show experimental results on the test track of our research facility.

</p>
</details>

<details><summary><b>2nd Place Solution for IJCAI-PRICAI 2020 3D AI Challenge: 3D Object Reconstruction from A Single Image</b>
<a href="https://arxiv.org/abs/2105.13575">arxiv:2105.13575</a>
&#x1F4C8; 3 <br>
<p>Yichen Cao, Yufei Wei, Shichao Liu, Lin Xu</p></summary>
<p>

**Abstract:** In this paper, we present our solution for the {\it IJCAI--PRICAI--20 3D AI Challenge: 3D Object Reconstruction from A Single Image}. We develop a variant of AtlasNet that consumes single 2D images and generates 3D point clouds through 2D to 3D mapping. To push the performance to the limit and present guidance on crucial implementation choices, we conduct extensive experiments to analyze the influence of decoder design and different settings on the normalization, projection, and sampling methods. Our method achieves 2nd place in the final track with a score of $70.88$, a chamfer distance of $36.87$, and a mean f-score of $59.18$. The source code of our method will be available at https://github.com/em-data/Enhanced_AtlasNet_3DReconstruction.

</p>
</details>

<details><summary><b>One-shot Learning with Absolute Generalization</b>
<a href="https://arxiv.org/abs/2105.13559">arxiv:2105.13559</a>
&#x1F4C8; 3 <br>
<p>Hao Su</p></summary>
<p>

**Abstract:** One-shot learning is proposed to make a pretrained classifier workable on a new dataset based on one labeled samples from each pattern. However, few of researchers consider whether the dataset itself supports one-shot learning. In this paper, we propose a set of definitions to explain what kind of datasets can support one-shot learning and propose the concept "absolute generalization". Based on these definitions, we proposed a method to build an absolutely generalizable classifier. The proposed method concatenates two samples as a new single sample, and converts a classification problem to an identity identification problem or a similarity metric problem. Experiments demonstrate that the proposed method is superior to baseline on one-shot learning datasets and artificial datasets.

</p>
</details>

<details><summary><b>Self-supervised Detransformation Autoencoder for Representation Learning in Open Set Recognition</b>
<a href="https://arxiv.org/abs/2105.13557">arxiv:2105.13557</a>
&#x1F4C8; 3 <br>
<p>Jingyun Jia, Philip K. Chan</p></summary>
<p>

**Abstract:** The objective of Open set recognition (OSR) is to learn a classifier that can reject the unknown samples while classifying the known classes accurately. In this paper, we propose a self-supervision method, Detransformation Autoencoder (DTAE), for the OSR problem. This proposed method engages in learning representations that are invariant to the transformations of the input data. Experiments on several standard image datasets indicate that the pre-training process significantly improves the model performance in the OSR tasks. Meanwhile, our proposed self-supervision method achieves significant gains in detecting the unknown class and classifying the known classes. Moreover, our analysis indicates that DTAE can yield representations that contain more target class information and less transformation information than RotNet.

</p>
</details>

<details><summary><b>ECG Heart-beat Classification Using Multimodal Image Fusion</b>
<a href="https://arxiv.org/abs/2105.13536">arxiv:2105.13536</a>
&#x1F4C8; 3 <br>
<p>Zeeshan Ahmad, Anika Tabassum, Naimul Khan, Ling Guan</p></summary>
<p>

**Abstract:** In this paper, we present a novel Image Fusion Model (IFM) for ECG heart-beat classification to overcome the weaknesses of existing machine learning techniques that rely either on manual feature extraction or direct utilization of 1D raw ECG signal. At the input of IFM, we first convert the heart beats of ECG into three different images using Gramian Angular Field (GAF), Recurrence Plot (RP) and Markov Transition Field (MTF) and then fuse these images to create a single imaging modality. We use AlexNet for feature extraction and classification and thus employ end to end deep learning. We perform experiments on PhysioNet MIT-BIH dataset for five different arrhythmias in accordance with the AAMI EC57 standard and on PTB diagnostics dataset for myocardial infarction (MI) classification. We achieved an state of an art results in terms of prediction accuracy, precision and recall.

</p>
</details>

<details><summary><b>Stochastic Intervention for Causal Inference via Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2105.13514">arxiv:2105.13514</a>
&#x1F4C8; 3 <br>
<p>Tri Dung Duong, Qian Li, Guandong Xu</p></summary>
<p>

**Abstract:** Causal inference methods are widely applied in various decision-making domains such as precision medicine, optimal policy and economics. Central to causal inference is the treatment effect estimation of intervention strategies, such as changes in drug dosing and increases in financial aid. Existing methods are mostly restricted to the deterministic treatment and compare outcomes under different treatments. However, they are unable to address the substantial recent interest of treatment effect estimation under stochastic treatment, e.g., "how all units health status change if they adopt 50\% dose reduction". In other words, they lack the capability of providing fine-grained treatment effect estimation to support sound decision-making. In our study, we advance the causal inference research by proposing a new effective framework to estimate the treatment effect on stochastic intervention. Particularly, we develop a stochastic intervention effect estimator (SIE) based on nonparametric influence function, with the theoretical guarantees of robustness and fast convergence rates. Additionally, we construct a customised reinforcement learning algorithm based on the random search solver which can effectively find the optimal policy to produce the greatest expected outcomes for the decision-making process. Finally, we conduct an empirical study to justify that our framework can achieve significant performance in comparison with state-of-the-art baselines.

</p>
</details>

<details><summary><b>Training With Data Dependent Dynamic Learning Rates</b>
<a href="https://arxiv.org/abs/2105.13464">arxiv:2105.13464</a>
&#x1F4C8; 3 <br>
<p>Shreyas Saxena, Nidhi Vyas, Dennis DeCoste</p></summary>
<p>

**Abstract:** Recently many first and second order variants of SGD have been proposed to facilitate training of Deep Neural Networks (DNNs). A common limitation of these works stem from the fact that they use the same learning rate across all instances present in the dataset. This setting is widely adopted under the assumption that loss functions for each instance are similar in nature, and hence, a common learning rate can be used. In this work, we relax this assumption and propose an optimization framework which accounts for difference in loss function characteristics across instances. More specifically, our optimizer learns a dynamic learning rate for each instance present in the dataset. Learning a dynamic learning rate for each instance allows our optimization framework to focus on different modes of training data during optimization. When applied to an image classification task, across different CNN architectures, learning dynamic learning rates leads to consistent gains over standard optimizers. When applied to a dataset containing corrupt instances, our framework reduces the learning rates on noisy instances, and improves over the state-of-the-art. Finally, we show that our optimization framework can be used for personalization of a machine learning model towards a known targeted data distribution.

</p>
</details>

<details><summary><b>On Privacy and Confidentiality of Communications in Organizational Graphs</b>
<a href="https://arxiv.org/abs/2105.13418">arxiv:2105.13418</a>
&#x1F4C8; 3 <br>
<p>Masoumeh Shafieinejad, Huseyin Inan, Marcello Hasegawa, Robert Sim</p></summary>
<p>

**Abstract:** Machine learned models trained on organizational communication data, such as emails in an enterprise, carry unique risks of breaching confidentiality, even if the model is intended only for internal use. This work shows how confidentiality is distinct from privacy in an enterprise context, and aims to formulate an approach to preserving confidentiality while leveraging principles from differential privacy. The goal is to perform machine learning tasks, such as learning a language model or performing topic analysis, using interpersonal communications in the organization, while not learning about confidential information shared in the organization. Works that apply differential privacy techniques to natural language processing tasks usually assume independently distributed data, and overlook potential correlation among the records. Ignoring this correlation results in a fictional promise of privacy. Naively extending differential privacy techniques to focus on group privacy instead of record-level privacy is a straightforward approach to mitigate this issue. This approach, although providing a more realistic privacy-guarantee, is over-cautious and severely impacts model utility. We show this gap between these two extreme measures of privacy over two language tasks, and introduce a middle-ground solution. We propose a model that captures the correlation in the social network graph, and incorporates this correlation in the privacy calculations through Pufferfish privacy principles.

</p>
</details>

<details><summary><b>Classification and Uncertainty Quantification of Corrupted Data using Semi-Supervised Autoencoders</b>
<a href="https://arxiv.org/abs/2105.13393">arxiv:2105.13393</a>
&#x1F4C8; 3 <br>
<p>Philipp Joppich, Sebastian Dorn, Oliver De Candido, Wolfgang Utschick, Jakob Knollmüller</p></summary>
<p>

**Abstract:** Parametric and non-parametric classifiers often have to deal with real-world data, where corruptions like noise, occlusions, and blur are unavoidable - posing significant challenges. We present a probabilistic approach to classify strongly corrupted data and quantify uncertainty, despite the model only having been trained with uncorrupted data. A semi-supervised autoencoder trained on uncorrupted data is the underlying architecture. We use the decoding part as a generative model for realistic data and extend it by convolutions, masking, and additive Gaussian noise to describe imperfections. This constitutes a statistical inference task in terms of the optimal latent space activations of the underlying uncorrupted datum. We solve this problem approximately with Metric Gaussian Variational Inference (MGVI). The supervision of the autoencoder's latent space allows us to classify corrupted data directly under uncertainty with the statistically inferred latent space activations. Furthermore, we demonstrate that the model uncertainty strongly depends on whether the classification is correct or wrong, setting a basis for a statistical "lie detector" of the classification. Independent of that, we show that the generative model can optimally restore the uncorrupted datum by decoding the inferred latent space activations.

</p>
</details>

<details><summary><b>TENSILE: A Tensor granularity dynamic GPU memory scheduling method towards multiple dynamic workloads system</b>
<a href="https://arxiv.org/abs/2105.13336">arxiv:2105.13336</a>
&#x1F4C8; 3 <br>
<p>Kaixin Zhang, Hongzhi Wang, Tongxin Li, Han Hu, Songling Zou, Jiye Qiu</p></summary>
<p>

**Abstract:** Recently, deep learning has been an area of intense research. However, as a kind of computing-intensive task, deep learning highly relies on the scale of GPU memory, which is usually prohibitive and scarce. Although there are some extensive works have been proposed for dynamic GPU memory management, they are hard to be applied to systems with multiple dynamic workloads, such as in-database machine learning systems.
  In this paper, we demonstrated TENSILE, a method of managing GPU memory in tensor granularity to reduce the GPU memory peak, considering the multiple dynamic workloads. TENSILE tackled the cold-starting and across-iteration scheduling problem existing in previous works. We implement TENSILE on a deep learning framework built by ourselves and evaluated its performance. The experiment results show that TENSILE can save more GPU memory with less extra time overhead than prior works in both single and multiple dynamic workloads scenarios.

</p>
</details>

<details><summary><b>How saccadic vision might help with theinterpretability of deep networks</b>
<a href="https://arxiv.org/abs/2105.13264">arxiv:2105.13264</a>
&#x1F4C8; 3 <br>
<p>Iana Sereda, Grigory Osipov</p></summary>
<p>

**Abstract:** We describe how some problems (interpretability,lack of object-orientedness) of modern deep networks potentiallycould be solved by adapting a biologically plausible saccadicmechanism of perception. A sketch of such a saccadic visionmodel is proposed. Proof of concept experimental results areprovided to support the proposed approach.

</p>
</details>

<details><summary><b>Video-Based Inpatient Fall Risk Assessment: A Case Study</b>
<a href="https://arxiv.org/abs/2106.07565">arxiv:2106.07565</a>
&#x1F4C8; 2 <br>
<p>Ziqing Wang, Mohammad Ali Armin, Simon Denman, Lars Petersson, David Ahmedt-Aristizabal</p></summary>
<p>

**Abstract:** Inpatient falls are a serious safety issue in hospitals and healthcare facilities. Recent advances in video analytics for patient monitoring provide a non-intrusive avenue to reduce this risk through continuous activity monitoring. However, in-bed fall risk assessment systems have received less attention in the literature. The majority of prior studies have focused on fall event detection, and do not consider the circumstances that may indicate an imminent inpatient fall. Here, we propose a video-based system that can monitor the risk of a patient falling, and alert staff of unsafe behaviour to help prevent falls before they occur. We propose an approach that leverages recent advances in human localisation and skeleton pose estimation to extract spatial features from video frames recorded in a simulated environment. We demonstrate that body positions can be effectively recognised and provide useful evidence for fall risk assessment. This work highlights the benefits of video-based models for analysing behaviours of interest, and demonstrates how such a system could enable sufficient lead time for healthcare professionals to respond and address patient needs, which is necessary for the development of fall intervention programs.

</p>
</details>

<details><summary><b>An optimized Capsule-LSTM model for facial expression recognition with video sequences</b>
<a href="https://arxiv.org/abs/2106.07564">arxiv:2106.07564</a>
&#x1F4C8; 2 <br>
<p>Siwei Liu, Yuanpeng Long, Gao Xu, Lijia Yang, Shimei Xu, Xiaoming Yao, Kunxian Shu</p></summary>
<p>

**Abstract:** To overcome the limitations of convolutional neural network in the process of facial expression recognition, a facial expression recognition model Capsule-LSTM based on video frame sequence is proposed. This model is composed of three networks includingcapsule encoders, capsule decoders and LSTM network. The capsule encoder extracts the spatial information of facial expressions in video frames. Capsule decoder reconstructs the images to optimize the network. LSTM extracts the temporal information between video frames and analyzes the differences in expression changes between frames. The experimental results from the MMI dataset show that the Capsule-LSTM model proposed in this paper can effectively improve the accuracy of video expression recognition.

</p>
</details>

<details><summary><b>BPLF: A Bi-Parallel Linear Flow Model for Facial Expression Generation from Emotion Set Images</b>
<a href="https://arxiv.org/abs/2106.07563">arxiv:2106.07563</a>
&#x1F4C8; 2 <br>
<p>Gao Xu, Yuanpeng Long, Siwei Liu, Lijia Yang, Shimei Xu, Xiaoming Yao, Kunxian Shu</p></summary>
<p>

**Abstract:** The flow-based generative model is a deep learning generative model, which obtains the ability to generate data by explicitly learning the data distribution. Theoretically its ability to restore data is stronger than other generative models. However, its implementation has many limitations, including limited model design, too many model parameters and tedious calculation. In this paper, a bi-parallel linear flow model for facial emotion generation from emotion set images is constructed, and a series of improvements have been made in terms of the expression ability of the model and the convergence speed in training. The model is mainly composed of several coupling layers superimposed to form a multi-scale structure, in which each coupling layer contains 1*1 reversible convolution and linear operation modules. Furthermore, this paper sorted out the current public data set of facial emotion images, made a new emotion data, and verified the model through this data set. The experimental results show that, under the traditional convolutional neural network, the 3-layer 3*3 convolution kernel is more conducive to extracte the features of the face images. The introduction of principal component decomposition can improve the convergence speed of the model.

</p>
</details>

<details><summary><b>Towards Interpretable Attention Networks for Cervical Cancer Analysis</b>
<a href="https://arxiv.org/abs/2106.00557">arxiv:2106.00557</a>
&#x1F4C8; 2 <br>
<p>Ruiqi Wang, Mohammad Ali Armin, Simon Denman, Lars Petersson, David Ahmedt-Aristizabal</p></summary>
<p>

**Abstract:** Recent advances in deep learning have enabled the development of automated frameworks for analysing medical images and signals, including analysis of cervical cancer. Many previous works focus on the analysis of isolated cervical cells, or do not offer sufficient methods to explain and understand how the proposed models reach their classification decisions on multi-cell images. Here, we evaluate various state-of-the-art deep learning models and attention-based frameworks for the classification of images of multiple cervical cells. As we aim to provide interpretable deep learning models to address this task, we also compare their explainability through the visualization of their gradients. We demonstrate the importance of using images that contain multiple cells over using isolated single-cell images. We show the effectiveness of the residual channel attention model for extracting important features from a group of cells, and demonstrate this model's efficiency for this classification task. This work highlights the benefits of channel attention mechanisms in analyzing multiple-cell images for potential relations and distributions within a group of cells. It also provides interpretable models to address the classification of cervical cells.

</p>
</details>

<details><summary><b>Predicting the hosts of prokaryotic viruses using GCN-based semi-supervised learning</b>
<a href="https://arxiv.org/abs/2105.13570">arxiv:2105.13570</a>
&#x1F4C8; 2 <br>
<p>Jiayu Shang, Yanni Sun</p></summary>
<p>

**Abstract:** Background: Prokaryotic viruses, which infect bacteria and archaea, are the most abundant and diverse biological entities in the biosphere. To understand their regulatory roles in various ecosystems and to harness the potential of bacteriophages for use in therapy, more knowledge of viral-host relationships is required. High-throughput sequencing and its application to the microbiome have offered new opportunities for computational approaches for predicting which hosts particular viruses can infect. However, there are two main challenges for computational host prediction. First, the empirically known virus-host relationships are very limited. Second, although sequence similarity between viruses and their prokaryote hosts have been used as a major feature for host prediction, the alignment is either missing or ambiguous in many cases. Thus, there is still a need to improve the accuracy of host prediction. Results: In this work, we present a semi-supervised learning model, named HostG, to conduct host prediction for novel viruses. We construct a knowledge graph by utilizing both virus-virus protein similarity and virus-host DNA sequence similarity. Then graph convolutional network (GCN) is adopted to exploit viruses with or without known hosts in training to enhance the learning ability. During the GCN training, we minimize the expected calibrated error (ECE) to ensure the confidence of the predictions. We tested HostG on both simulated and real sequencing data and compared its performance with other state-of-the-art methods specifcally designed for virus host classification (VHM-net, WIsH, PHP, HoPhage, RaFAH, vHULK, and VPF-Class). Conclusion: HostG outperforms other popular methods, demonstrating the efficacy of using a GCN-based semi-supervised learning approach. A particular advantage of HostG is its ability to predict hosts from new taxa.

</p>
</details>

<details><summary><b>Learning Model-Based Vehicle-Relocation Decisions for Real-Time Ride-Sharing: Hybridizing Learning and Optimization</b>
<a href="https://arxiv.org/abs/2105.13461">arxiv:2105.13461</a>
&#x1F4C8; 2 <br>
<p>Enpeng Yuan, Pascal Van Hentenryck</p></summary>
<p>

**Abstract:** Large-scale ride-sharing systems combine real-time dispatching and routing optimization over a rolling time horizon with a model predictive control (MPC) component that relocates idle vehicles to anticipate the demand. The MPC optimization operates over a longer time horizon to compensate for the inherent myopic nature of the real-time dispatching. These longer time horizons are beneficial for the quality of relocation decisions but increase computational complexity. Consequently, the ride-sharing operators are often forced to use a relatively short time horizon. To address this computational challenge, this paper proposes a hybrid approach that combines machine learning and optimization. The machine-learning component learns the optimal solution to the MPC on the aggregated level to overcome the sparsity and high-dimensionality of the solution. The optimization component transforms the machine-learning prediction back to the original granularity through a tractable transportation model. As a consequence, the original NP-hard MPC problem is reduced to a polynomial time prediction and optimization, which allows the ride-sharing operators to consider a longer time horizon. Experimental results show that the hybrid approach achieves significantly better service quality than the MPC optimization in terms of average rider waiting time, due to its ability to model a longer horizon.

</p>
</details>

<details><summary><b>Open-world Machine Learning: Applications, Challenges, and Opportunities</b>
<a href="https://arxiv.org/abs/2105.13448">arxiv:2105.13448</a>
&#x1F4C8; 2 <br>
<p>Jitendra Parmar, Satyendra Singh Chouhan, Santosh Singh Rathore</p></summary>
<p>

**Abstract:** Traditional machine learning especially supervised learning follows the assumptions of closed-world learning i.e., for each testing class a training class is available. However, such machine learning models fail to identify the classes which were not available during training time. These classes can be referred to as unseen classes. Whereas, open-world machine learning deals with arbitrary inputs (data with unseen classes) to machine learning systems. Moreover, traditional machine learning is static learning which is not appropriate for an active environment where the perspective and sources, and/or volume of data are changing rapidly. In this paper, first, we present an overview of open-world learning with importance to the real-world context. Next, different dimensions of open-world learning are explored and discussed. The area of open-world learning gained the attention of the research community in the last decade only. We have searched through different online digital libraries and scrutinized the work done in the last decade. This paper presents a systematic review of various techniques for open-world machine learning. It also presents the research gaps, challenges, and future directions in open-world learning. This paper will help researchers to understand the comprehensive developments of open-world learning and the likelihoods to extend the research in suitable areas. It will also help to select applicable methodologies and datasets to explore this further.

</p>
</details>

<details><summary><b>Exploitation vs Caution: Risk-sensitive Policies for Offline Learning</b>
<a href="https://arxiv.org/abs/2105.13431">arxiv:2105.13431</a>
&#x1F4C8; 2 <br>
<p>Giorgio Angelotti, Nicolas Drougard, Caroline Ponzoni Carvalho Chanel</p></summary>
<p>

**Abstract:** Offline model learning for planning is a branch of machine learning that trains agents to perform actions in an unknown environment using a fixed batch of previously collected experiences. The limited size of the data set hinders the estimate of the Value function of the relative Markov Decision Process (MDP), bounding the performance of the obtained policy in the real world. In this context, recent works showed that planning with a discount factor lower than the one used during the evaluation phase yields more performing policies. However, the optimal discount factor is finally chosen by cross-validation. Our aim is to show that looking for a sub-optimal solution of a Bayesian MDP might lead to better performances with respect to the current baselines that work in the offline setting. Hence, we propose Exploitation vs Caution (EvC), an algorithm that automatically selects the policy that solves a Risk-sensitive Bayesian MDP in a set of policies obtained by solving several MDPs characterized by different discount factors and transition dynamics. On one hand, the Bayesian formalism elegantly includes model uncertainty and on another hand the introduction of a risk-sensitive utility function guarantees robustness. We evaluated the proposed approach in different discrete simple environments offering a fair variety of MDP classes. We also compared the obtained results with state-of-the-art offline learning for planning baselines such as MOPO and MOReL. In the tested scenarios EvC is more robust than the said approaches suggesting that sub-optimally solving an Offline Risk-sensitive Bayesian MDP (ORBMDP) could define a sound framework for planning under model uncertainty.

</p>
</details>

<details><summary><b>Sinan: Data-Driven, QoS-Aware Cluster Management for Microservices</b>
<a href="https://arxiv.org/abs/2105.13424">arxiv:2105.13424</a>
&#x1F4C8; 2 <br>
<p>Yanqi Zhang, Weizhe Hua, Zhuangzhuang Zhou, Edward Suh, Christina Delimitrou</p></summary>
<p>

**Abstract:** Cloud applications are increasingly shifting from large monolithic services, to large numbers of loosely-coupled, specialized microservices. Despite their advantages in terms of facilitating development, deployment, modularity, and isolation, microservices complicate resource management, as dependencies between them introduce backpressure effects and cascading QoS violations.
  We present Sinan, a data-driven cluster manager for interactive cloud microservices that is online and QoS-aware. Sinan leverages a set of scalable and validated machine learning models to determine the performance impact of dependencies between microservices, and allocate appropriate resources per tier in a way that preserves the end-to-end tail latency target. We evaluate Sinan both on dedicated local clusters and large-scale deployments on Google Compute Engine (GCE) across representative end-to-end applications built with microservices, such as social networks and hotel reservation sites. We show that Sinan always meets QoS, while also maintaining cluster utilization high, in contrast to prior work which leads to unpredictable performance or sacrifices resource efficiency. Furthermore, the techniques in Sinan are explainable, meaning that cloud operators can yield insights from the ML models on how to better deploy and design their applications to reduce unpredictable performance.

</p>
</details>

<details><summary><b>Cross-Referencing Self-Training Network for Sound Event Detection in Audio Mixtures</b>
<a href="https://arxiv.org/abs/2105.13392">arxiv:2105.13392</a>
&#x1F4C8; 2 <br>
<p>Sangwook Park, David K. Han, Mounya Elhilali</p></summary>
<p>

**Abstract:** Sound event detection is an important facet of audio tagging that aims to identify sounds of interest and define both the sound category and time boundaries for each sound event in a continuous recording. With advances in deep neural networks, there has been tremendous improvement in the performance of sound event detection systems, although at the expense of costly data collection and labeling efforts. In fact, current state-of-the-art methods employ supervised training methods that leverage large amounts of data samples and corresponding labels in order to facilitate identification of sound category and time stamps of events. As an alternative, the current study proposes a semi-supervised method for generating pseudo-labels from unsupervised data using a student-teacher scheme that balances self-training and cross-training. Additionally, this paper explores post-processing which extracts sound intervals from network prediction, for further improvement in sound event detection performance. The proposed approach is evaluated on sound event detection task for the DCASE2020 challenge. The results of these methods on both "validation" and "public evaluation" sets of DESED database show significant improvement compared to the state-of-the art systems in semi-supervised learning.

</p>
</details>

<details><summary><b>Better Regularization for Sequential Decision Spaces: Fast Convergence Rates for Nash, Correlated, and Team Equilibria</b>
<a href="https://arxiv.org/abs/2105.12954">arxiv:2105.12954</a>
&#x1F4C8; 2 <br>
<p>Gabriele Farina, Christian Kroer, Tuomas Sandholm</p></summary>
<p>

**Abstract:** We study the application of iterative first-order methods to the problem of computing equilibria of large-scale two-player extensive-form games. First-order methods must typically be instantiated with a regularizer that serves as a distance-generating function for the decision sets of the players. For the case of two-player zero-sum games, the state-of-the-art theoretical convergence rate for Nash equilibrium is achieved by using the dilated entropy function. In this paper, we introduce a new entropy-based distance-generating function for two-player zero-sum games, and show that this function achieves significantly better strong convexity properties than the dilated entropy, while maintaining the same easily-implemented closed-form proximal mapping. Extensive numerical simulations show that these superior theoretical properties translate into better numerical performance as well. We then generalize our new entropy distance function, as well as general dilated distance functions, to the scaled extension operator. The scaled extension operator is a way to recursively construct convex sets, which generalizes the decision polytope of extensive-form games, as well as the convex polytopes corresponding to correlated and team equilibria. By instantiating first-order methods with our regularizers, we develop the first accelerated first-order methods for computing correlated equilibra and ex-ante coordinated team equilibria. Our methods have a guaranteed $1/T$ rate of convergence, along with linear-time proximal updates.

</p>
</details>

<details><summary><b>DMInet: An Accurate and Highly Flexible Deep Learning Framework for Drug Discovery with Membrane Selectivity</b>
<a href="https://arxiv.org/abs/2105.13928">arxiv:2105.13928</a>
&#x1F4C8; 1 <br>
<p>Guang Chen</p></summary>
<p>

**Abstract:** Drug membrane interaction is a very significant bioprocess to consider in drug discovery. Here, we propose a novel deep learning framework coined DMInet to study drug-membrane interactions that leverages large-scale Martini coarse-grained molecular simulations of permeation of drug-like molecules across six different lipid membranes. The network of DMInet receives three inputs, viz, the drug-like molecule, membrane type and spatial distance across membrane thickness, and predicts the potential of mean force with structural resolution across the lipid membrane and membrane selectivity. Inheriting from coarse-grained Martini representation of organic molecules and combined with deep learning, DMInet has the potential for more accelerated high throughput screening in drug discovery across a much larger chemical space than that can be explored by physics-based simulations alone. Moreover, DMInet is highly flexible in its nature and holds the possibilities for other properties prediction without significant change of the architecture. Last but not least, the architecture of DMInet is general and can be applied to other membrane problems involving permeation and selection.

</p>
</details>

<details><summary><b>Fragmentation; a Tool for Finding Information, Encryption and Data Flow in Systems</b>
<a href="https://arxiv.org/abs/2105.13585">arxiv:2105.13585</a>
&#x1F4C8; 1 <br>
<p>Douglas Kirkpatrick, Victoria Cao, Clifford Bohm</p></summary>
<p>

**Abstract:** We introduce a new information-theoretic measure, fragmentation (F) which can be used to determine how fragmented predictive information is in a system. The concept can be extended to generate fragmentation matrices that can illustrate information flows through digital brains, in the form of directed graphs. Fragmentation and fragmentation matrices can provide new insights into digital brains structure and function, in other words, how causal digital networks "think" and process information. In addition to describing F we demonstrate how it can be used to examine how complex processing arises in neural networks, including differences in lifetime processing and incidents of incidental encryption.

</p>
</details>

<details><summary><b>Lattice partition recovery with dyadic CART</b>
<a href="https://arxiv.org/abs/2105.13504">arxiv:2105.13504</a>
&#x1F4C8; 1 <br>
<p>Oscar Hernan Madrid Padilla, Yi Yu, Alessandro Rinaldo</p></summary>
<p>

**Abstract:** We study piece-wise constant signals corrupted by additive Gaussian noise over a $d$-dimensional lattice. Data of this form naturally arise in a host of applications, and the tasks of signal detection or testing, de-noising and estimation have been studied extensively in the statistical and signal processing literature. In this paper we consider instead the problem of partition recovery, i.e.~of estimating the partition of the lattice induced by the constancy regions of the unknown signal, using the computationally-efficient dyadic classification and regression tree (DCART) methodology proposed by \citep{donoho1997cart}. We prove that, under appropriate regularity conditions on the shape of the partition elements, a DCART-based procedure consistently estimates the underlying partition at a rate of order $σ^2 k^* \log (N)/κ^2$, where $k^*$ is the minimal number of rectangular sub-graphs obtained using recursive dyadic partitions supporting the signal partition, $σ^2$ is the noise variance, $κ$ is the minimal magnitude of the signal difference among contiguous elements of the partition and $N$ is the size of the lattice. Furthermore, under stronger assumptions, our method attains a sharper estimation error of order $σ^2\log(N)/κ^2$, independent of $k^*$, which we show to be minimax rate optimal. Our theoretical guarantees further extend to the partition estimator based on the optimal regression tree estimator (ORT) of \cite{chatterjee2019adaptive} and to the one obtained through an NP-hard exhaustive search method. We corroborate our theoretical findings and the effectiveness of DCART for partition recovery in simulations.

</p>
</details>

<details><summary><b>Avancee-1 Mission and SaDoD Method: LiDAR-based stimulated atomic disintegration of space debris (SaDoD) using Optical Neural Networks</b>
<a href="https://arxiv.org/abs/2105.13485">arxiv:2105.13485</a>
&#x1F4C8; 1 <br>
<p>Manuel Ntumba, Saurabh Gore</p></summary>
<p>

**Abstract:** The surface degradation of satellites in Low Earth Orbit (LEO) is affected by Atomic Oxygen (AO) and varies depending on the spacecraft orbital parameters. Atomic oxygen initiates several chemical and physical reactions with materials and produces erosion and self-disintegration of the debris at high energy. This paper discusses Avancee-1 Mission, LiDAR-based space debris removal using Optical Neural Networks (ONN) to optimize debris detection and mission accuracy. The SaDoD Method is a Stimulated Atomic Disintegration of Orbital Debris, which in this case has been achieved using LiDAR technology and Optical Neural Networks. We propose Optical Neural Network algorithms with a high ability of image detection and classification. The results show that orbital debris has a higher chance of disintegration when the laser beam is coming from Geostationary Orbit (GEO) satellites and in the presence of high solar activities. This paper proposes a LiDAR-based space debris removal method depending on the variation of atomic oxygen erosion with orbital parameters and solar energy levels. The results obtained show that orbital debris undergoes the most intense degradation at low altitudes and higher temperatures. The satellites in GEO use Optical Neural Network algorithms for object detection before sending the laser beams to achieve self-disintegration. The SaDoD Method can be implemented with other techniques, but especially for the Avancee-1 Mission, the SaDoD was implemented with LiDAR technologies and Optical Neural Network algorithms.

</p>
</details>

<details><summary><b>Type III solar radio burst detection and classification: A deep learning approach</b>
<a href="https://arxiv.org/abs/2105.13387">arxiv:2105.13387</a>
&#x1F4C8; 1 <br>
<p>Jeremiah Scully, Ronan Flynn, Eoin Carley, Peter Gallagher, Mark Daly</p></summary>
<p>

**Abstract:** Solar Radio Bursts (SRBs) are generally observed in dynamic spectra and have five major spectral classes, labelled Type I to Type V depending on their shape and extent in frequency and time. Due to their complex characterisation, a challenge in solar radio physics is the automatic detection and classification of such radio bursts. Classification of SRBs has become fundamental in recent years due to large data rates generated by advanced radio telescopes such as the LOw-Frequency ARray, (LOFAR). Current state-of-the-art algorithms implement the Hough or Radon transform as a means of detecting predefined parametric shapes in images. These algorithms achieve up to 84% accuracy, depending on the Type of radio burst being classified. Other techniques include procedures that rely on Constant-FalseAlarm-Rate detection, which is essentially detection of radio bursts using a de-noising and adaptive threshold in dynamic spectra. It works well for a variety of different Types of radio bursts and achieves an accuracy of up to 70%. In this research, we are introducing a methodology named You Only Look Once v2 (YOLOv2) for solar radio burst classification. By using Type III simulation methods we can train the algorithm to classify real Type III solar radio bursts in real-time at an accu

</p>
</details>

<details><summary><b>An Online Learning Approach to Optimizing Time-Varying Costs of AoI</b>
<a href="https://arxiv.org/abs/2105.13383">arxiv:2105.13383</a>
&#x1F4C8; 1 <br>
<p>Vishrant Tripathi, Eytan Modiano</p></summary>
<p>

**Abstract:** We consider systems that require timely monitoring of sources over a communication network, where the cost of delayed information is unknown, time-varying and possibly adversarial. For the single source monitoring problem, we design algorithms that achieve sublinear regret compared to the best fixed policy in hindsight. For the multiple source scheduling problem, we design a new online learning algorithm called Follow-the-Perturbed-Whittle-Leader and show that it has low regret compared to the best fixed scheduling policy in hindsight, while remaining computationally feasible. The algorithm and its regret analysis are novel and of independent interest to the study of online restless multi-armed bandit problems. We further design algorithms that achieve sublinear regret compared to the best dynamic policy when the environment is slowly varying. Finally, we apply our algorithms to a mobility tracking problem. We consider non-stationary and adversarial mobility models and illustrate the performance benefit of using our online learning algorithms compared to an oblivious scheduling policy.

</p>
</details>

<details><summary><b>Differentially Private Densest Subgraph Detection</b>
<a href="https://arxiv.org/abs/2105.13287">arxiv:2105.13287</a>
&#x1F4C8; 1 <br>
<p>Dung Nguyen, Anil Vullikanti</p></summary>
<p>

**Abstract:** Densest subgraph detection is a fundamental graph mining problem, with a large number of applications. There has been a lot of work on efficient algorithms for finding the densest subgraph in massive networks. However, in many domains, the network is private, and returning a densest subgraph can reveal information about the network. Differential privacy is a powerful framework to handle such settings. We study the densest subgraph problem in the edge privacy model, in which the edges of the graph are private. We present the first sequential and parallel differentially private algorithms for this problem. We show that our algorithms have an additive approximation guarantee. We evaluate our algorithms on a large number of real-world networks, and observe a good privacy-accuracy tradeoff when the network has high density.

</p>
</details>

<details><summary><b>Algebras of Sets and Coherent Sets of Gambles</b>
<a href="https://arxiv.org/abs/2105.12986">arxiv:2105.12986</a>
&#x1F4C8; 1 <br>
<p>Juerg Kohlas, Arianna Casanova, Marco Zaffalon</p></summary>
<p>

**Abstract:** In a recent work we have shown how to construct an information algebra of coherent sets of gambles defined on general possibility spaces. Here we analyze the connection of such an algebra with the set algebra of subsets of the possibility space on which gambles are defined and the set algebra of sets of its atoms. Set algebras are particularly important information algebras since they are their prototypical structures. Furthermore, they are the algebraic counterparts of classical propositional logic. As a consequence, this paper also details how propositional logic is naturally embedded into the theory of imprecise probabilities.

</p>
</details>

<details><summary><b>Unsupervised Domain Adaptation of Object Detectors: A Survey</b>
<a href="https://arxiv.org/abs/2105.13502">arxiv:2105.13502</a>
&#x1F4C8; 0 <br>
<p>Poojan Oza, Vishwanath A. Sindagi, Vibashan VS, Vishal M. Patel</p></summary>
<p>

**Abstract:** Recent advances in deep learning have led to the development of accurate and efficient models for various computer vision applications such as classification, segmentation, and detection. However, learning highly accurate models relies on the availability of large-scale annotated datasets. Due to this, model performance drops drastically when evaluated on label-scarce datasets having visually distinct images, termed as domain adaptation problem. There is a plethora of works to adapt classification and segmentation models to label-scarce target datasets through unsupervised domain adaptation. Considering that detection is a fundamental task in computer vision, many recent works have focused on developing novel domain adaptive detection techniques. Here, we describe in detail the domain adaptation problem for detection and present an extensive survey of the various methods. Furthermore, we highlight strategies proposed and the associated shortcomings. Subsequently, we identify multiple aspects of the problem that are most promising for future research. We believe that this survey shall be valuable to the pattern recognition experts working in the fields of computer vision, biometrics, medical imaging, and autonomous navigation by introducing them to the problem, and familiarizing them with the current status of the progress while providing promising directions for future research.

</p>
</details>

<details><summary><b>Anomalous phase separation dynamics in a correlated electron system: machine-learning enabled large-scale kinetic Monte Carlo simulations</b>
<a href="https://arxiv.org/abs/2105.13304">arxiv:2105.13304</a>
&#x1F4C8; 0 <br>
<p>Sheng Zhang, Puhan Zhang, Gia-Wei Chern</p></summary>
<p>

**Abstract:** Phase separation plays a central role in the emergence of novel functionalities of correlated electron materials. The structure of the mixed-phase states depends strongly on the nonequilibrium phase-separation dynamics, which has so far yet to be systematically investigated, especially on the theoretical side. With the aid of modern machine learning methods, we demonstrate the first-ever large-scale kinetic Monte Carlo simulations of the phase separation process for the Falicov-Kimball model, which is one of the canonical strongly correlated electron systems. We uncover an unusual phase-separation scenario where domain coarsening occurs simultaneously at two different scales: the growth of checkerboard clusters at smaller length scales and the expansion of super-clusters, which are aggregates of the checkerboard clusters of the same sign, at a larger scale. We show that the emergence of super-clusters is due to a hidden dynamical breaking of the sublattice symmetry. Arrested growth of the checkerboard patterns and of the super-clusters is shown to result from a correlation-induced self-trapping mechanism. Glassy behaviors similar to the one reported in this work could be generic for other correlated electron systems.

</p>
</details>

<details><summary><b>Neural Network Training Using $\ell_1$-Regularization and Bi-fidelity Data</b>
<a href="https://arxiv.org/abs/2105.13011">arxiv:2105.13011</a>
&#x1F4C8; 0 <br>
<p>Subhayan De, Alireza Doostan</p></summary>
<p>

**Abstract:** With the capability of accurately representing a functional relationship between the inputs of a physical system's model and output quantities of interest, neural networks have become popular for surrogate modeling in scientific applications. However, as these networks are over-parameterized, their training often requires a large amount of data. To prevent overfitting and improve generalization error, regularization based on, e.g., $\ell_1$- and $\ell_2$-norms of the parameters is applied. Similarly, multiple connections of the network may be pruned to increase sparsity in the network parameters. In this paper, we explore the effects of sparsity promoting $\ell_1$-regularization on training neural networks when only a small training dataset from a high-fidelity model is available. As opposed to standard $\ell_1$-regularization that is known to be inadequate, we consider two variants of $\ell_1$-regularization informed by the parameters of an identical network trained using data from lower-fidelity models of the problem at hand. These bi-fidelity strategies are generalizations of transfer learning of neural networks that uses the parameters learned from a large low-fidelity dataset to efficiently train networks for a small high-fidelity dataset. We also compare the bi-fidelity strategies with two $\ell_1$-regularization methods that only use the high-fidelity dataset. Three numerical examples for propagating uncertainty through physical systems are used to show that the proposed bi-fidelity $\ell_1$-regularization strategies produce errors that are one order of magnitude smaller than those of networks trained only using datasets from the high-fidelity models.

</p>
</details>


[Next Page](2021/2021-05/2021-05-26.md)
