Prev: [2021.02.15]({{ '/2021/02/15/2021.02.15.html' | relative_url }})  Next: [2021.02.17]({{ '/2021/02/17/2021.02.17.html' | relative_url }})
{% raw %}
## Summary for 2021-02-16, created on 2021-12-24


<details><summary><b>Semi Supervised Learning For Few-shot Audio Classification By Episodic Triplet Mining</b>
<a href="https://arxiv.org/abs/2102.08074">arxiv:2102.08074</a>
&#x1F4C8; 48 <br>
<p>Swapnil Bhosale, Rupayan Chakraborty, Sunil Kumar Kopparapu</p></summary>
<p>

**Abstract:** Few-shot learning aims to generalize unseen classes that appear during testing but are unavailable during training. Prototypical networks incorporate few-shot metric learning, by constructing a class prototype in the form of a mean vector of the embedded support points within a class. The performance of prototypical networks in extreme few-shot scenarios (like one-shot) degrades drastically, mainly due to the desuetude of variations within the clusters while constructing prototypes. In this paper, we propose to replace the typical prototypical loss function with an Episodic Triplet Mining (ETM) technique. The conventional triplet selection leads to overfitting, because of all possible combinations being used during training. We incorporate episodic training for mining the semi hard positive and the semi hard negative triplets to overcome the overfitting. We also propose an adaptation to make use of unlabeled training samples for better modeling. Experimenting on two different audio processing tasks, namely speaker recognition and audio event detection; show improved performances and hence the efficacy of ETM over the prototypical loss function and other meta-learning frameworks. Further, we show improved performances when unlabeled training samples are used.

</p>
</details>

<details><summary><b>Context-Aware Prosody Correction for Text-Based Speech Editing</b>
<a href="https://arxiv.org/abs/2102.08328">arxiv:2102.08328</a>
&#x1F4C8; 41 <br>
<p>Max Morrison, Lucas Rencker, Zeyu Jin, Nicholas J. Bryan, Juan-Pablo Caceres, Bryan Pardo</p></summary>
<p>

**Abstract:** Text-based speech editors expedite the process of editing speech recordings by permitting editing via intuitive cut, copy, and paste operations on a speech transcript. A major drawback of current systems, however, is that edited recordings often sound unnatural because of prosody mismatches around edited regions. In our work, we propose a new context-aware method for more natural sounding text-based editing of speech. To do so, we 1) use a series of neural networks to generate salient prosody features that are dependent on the prosody of speech surrounding the edit and amenable to fine-grained user control 2) use the generated features to control a standard pitch-shift and time-stretch method and 3) apply a denoising neural network to remove artifacts induced by the signal manipulation to yield a high-fidelity result. We evaluate our approach using a subjective listening test, provide a detailed comparative analysis, and conclude several interesting insights.

</p>
</details>

<details><summary><b>Globally-Robust Neural Networks</b>
<a href="https://arxiv.org/abs/2102.08452">arxiv:2102.08452</a>
&#x1F4C8; 40 <br>
<p>Klas Leino, Zifan Wang, Matt Fredrikson</p></summary>
<p>

**Abstract:** The threat of adversarial examples has motivated work on training certifiably robust neural networks to facilitate efficient verification of local robustness at inference time. We formalize a notion of global robustness, which captures the operational properties of on-line local robustness certification while yielding a natural learning objective for robust training. We show that widely-used architectures can be easily adapted to this objective by incorporating efficient global Lipschitz bounds into the network, yielding certifiably-robust models by construction that achieve state-of-the-art verifiable accuracy. Notably, this approach requires significantly less time and memory than recent certifiable training methods, and leads to negligible costs when certifying points on-line; for example, our evaluation shows that it is possible to train a large robust Tiny-Imagenet model in a matter of hours. Our models effectively leverage inexpensive global Lipschitz bounds for real-time certification, despite prior suggestions that tighter local bounds are needed for good performance; we posit this is possible because our models are specifically trained to achieve tighter global bounds. Namely, we prove that the maximum achievable verifiable accuracy for a given dataset is not improved by using a local bound.

</p>
</details>

<details><summary><b>IronMan: GNN-assisted Design Space Exploration in High-Level Synthesis via Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.08138">arxiv:2102.08138</a>
&#x1F4C8; 37 <br>
<p>Nan Wu, Yuan Xie, Cong Hao</p></summary>
<p>

**Abstract:** Despite the great success of High-Level Synthesis (HLS) tools, we observe several unresolved challenges: 1) the high-level abstraction of programming styles in HLS sometimes conceals optimization opportunities; 2) existing HLS tools do not provide flexible trade-off (Pareto) solutions among different objectives and constraints; 3) the actual quality of the resulting RTL designs is hard to predict. To address these challenges, we propose an end-to-end framework, namelyIronMan. The primary goal is to enable a flexible and automated design space exploration (DSE), to provide either optimal solutions under user-specified constraints, or various trade-offs among different objectives (such as different types of resources, area, and latency). Such DSE either requires tedious manual efforts or is not achievable to attain these goals through existing HLS tools. There are three components in IronMan: 1) GPP, a highly accurate graph-neural-network-based performance and resource predictor; 2) RLMD, a reinforcement-learning-based multi-objective DSE engine that explores the optimal resource allocation strategy, to provide Pareto solutions between different objectives; 3) CT, a code transformer to assist RLMD and GPP, which extracts the data flow graph from original HLS C/C++ and automatically generates synthesizable code with HLS directives. The experimental results show that: 1) GPP achieves high prediction accuracy, reducing prediction errors of HLS tools by 10.9x in resource utilization and 5.7x in timing; 2) RLMD obtains optimal or Pareto solutions that outperform the genetic algorithm and simulated annealing by 12.7% and 12.9%, respectively; 3) IronMan is able to find optimized solutions perfectly matching various DSP constraints, with 2.54x fewer DSPs and up to 6x shorter latency than those of HLS tools while being up to 400x faster than the heuristic algorithms and HLS tools.

</p>
</details>

<details><summary><b>End-to-End Automatic Speech Recognition with Deep Mutual Learning</b>
<a href="https://arxiv.org/abs/2102.08154">arxiv:2102.08154</a>
&#x1F4C8; 35 <br>
<p>Ryo Masumura, Mana Ihori, Akihiko Takashima, Tomohiro Tanaka, Takanori Ashihara</p></summary>
<p>

**Abstract:** This paper is the first study to apply deep mutual learning (DML) to end-to-end ASR models. In DML, multiple models are trained simultaneously and collaboratively by mimicking each other throughout the training process, which helps to attain the global optimum and prevent models from making over-confident predictions. While previous studies applied DML to simple multi-class classification problems, there are no studies that have used it on more complex sequence-to-sequence mapping problems. For this reason, this paper presents a method to apply DML to state-of-the-art Transformer-based end-to-end ASR models. In particular, we propose to combine DML with recent representative training techniques. i.e., label smoothing, scheduled sampling, and SpecAugment, each of which are essential for powerful end-to-end ASR models. We expect that these training techniques work well with DML because DML has complementary characteristics. We experimented with two setups for Japanese ASR tasks: large-scale modeling and compact modeling. We demonstrate that DML improves the ASR performance of both modeling setups compared with conventional learning methods including knowledge distillation. We also show that combining DML with the existing training techniques effectively improves ASR performance.

</p>
</details>

<details><summary><b>Large-Context Conversational Representation Learning: Self-Supervised Learning for Conversational Documents</b>
<a href="https://arxiv.org/abs/2102.08147">arxiv:2102.08147</a>
&#x1F4C8; 34 <br>
<p>Ryo Masumura, Naoki Makishima, Mana Ihori, Akihiko Takashima, Tomohiro Tanaka, Shota Orihashi</p></summary>
<p>

**Abstract:** This paper presents a novel self-supervised learning method for handling conversational documents consisting of transcribed text of human-to-human conversations. One of the key technologies for understanding conversational documents is utterance-level sequential labeling, where labels are estimated from the documents in an utterance-by-utterance manner. The main issue with utterance-level sequential labeling is the difficulty of collecting labeled conversational documents, as manual annotations are very costly. To deal with this issue, we propose large-context conversational representation learning (LC-CRL), a self-supervised learning method specialized for conversational documents. A self-supervised learning task in LC-CRL involves the estimation of an utterance using all the surrounding utterances based on large-context language modeling. In this way, LC-CRL enables us to effectively utilize unlabeled conversational documents and thereby enhances the utterance-level sequential labeling. The results of experiments on scene segmentation tasks using contact center conversational datasets demonstrate the effectiveness of the proposed method.

</p>
</details>

<details><summary><b>Making the most of your day: online learning for optimal allocation of time</b>
<a href="https://arxiv.org/abs/2102.08087">arxiv:2102.08087</a>
&#x1F4C8; 33 <br>
<p>Etienne Boursier, Tristan Garrec, Vianney Perchet, Marco Scarsini</p></summary>
<p>

**Abstract:** We study online learning for optimal allocation when the resource to be allocated is time. %Examples of possible applications include job scheduling for a computing server, a driver filling a day with rides, a landlord renting an estate, etc. An agent receives task proposals sequentially according to a Poisson process and can either accept or reject a proposed task. If she accepts the proposal, she is busy for the duration of the task and obtains a reward that depends on the task duration. If she rejects it, she remains on hold until a new task proposal arrives. We study the regret incurred by the agent, first when she knows her reward function but does not know the distribution of the task duration, and then when she does not know her reward function, either. This natural setting bears similarities with contextual (one-armed) bandits, but with the crucial difference that the normalized reward associated to a context depends on the whole distribution of contexts.

</p>
</details>

<details><summary><b>Axial Residual Networks for CycleGAN-based Voice Conversion</b>
<a href="https://arxiv.org/abs/2102.08075">arxiv:2102.08075</a>
&#x1F4C8; 33 <br>
<p>Jaeseong You, Gyuhyeon Nam, Dalhyun Kim, Gyeongsu Chae</p></summary>
<p>

**Abstract:** We propose a novel architecture and improved training objectives for non-parallel voice conversion. Our proposed CycleGAN-based model performs a shape-preserving transformation directly on a high frequency-resolution magnitude spectrogram, converting its style (i.e. speaker identity) while preserving the speech content. Throughout the entire conversion process, the model does not resort to compressed intermediate representations of any sort (e.g. mel spectrogram, low resolution spectrogram, decomposed network feature). We propose an efficient axial residual block architecture to support this expensive procedure and various modifications to the CycleGAN losses to stabilize the training process. We demonstrate via experiments that our proposed model outperforms Scyclone and shows a comparable or better performance to that of CycleGAN-VC2 even without employing a neural vocoder.

</p>
</details>

<details><summary><b>Learning the Noise of Failure: Intelligent System Tests for Robots</b>
<a href="https://arxiv.org/abs/2102.08080">arxiv:2102.08080</a>
&#x1F4C8; 32 <br>
<p>Felix Sygulla, Daniel Rixen</p></summary>
<p>

**Abstract:** Roboticists usually test new control software in simulation environments before evaluating its functionality on real-world robots. Simulations reduce the risk of damaging the hardware and can significantly increase the development process's efficiency in the form of automated system tests.
  However, many flaws in the software remain undetected in simulation data, revealing their harmful effects on the system only in time-consuming experiments. In reality, such irregularities are often easily recognized solely by the robot's airborne noise during operation. We propose a simulated noise estimate for the detection of failures in automated system tests of robots. The classification of flaws uses classical machine learning - a support vector machine - to identify different failure classes from the scalar noise estimate.
  The methodology is evaluated on simulation data from the humanoid robot LOLA. The approach yields high failure detection accuracy with a low false-positive rate, enabling its use for stricter automated system tests. Results indicate that a single trained model may work for different robots. The proposed technique is provided to the community in the form of the open-source tool NoisyTest, making it easy to test data from any robot. In a broader scope, the technique may empower real-world automated system tests without human evaluation of success or failure.

</p>
</details>

<details><summary><b>Exploring Transformers in Natural Language Generation: GPT, BERT, and XLNet</b>
<a href="https://arxiv.org/abs/2102.08036">arxiv:2102.08036</a>
&#x1F4C8; 31 <br>
<p>M. Onat Topal, Anil Bas, Imke van Heerden</p></summary>
<p>

**Abstract:** Recent years have seen a proliferation of attention mechanisms and the rise of Transformers in Natural Language Generation (NLG). Previously, state-of-the-art NLG architectures such as RNN and LSTM ran into vanishing gradient problems; as sentences grew larger, distance between positions remained linear, and sequential computation hindered parallelization since sentences were processed word by word. Transformers usher in a new era. In this paper, we explore three major Transformer-based models, namely GPT, BERT, and XLNet, that carry significant implications for the field. NLG is a burgeoning area that is now bolstered with rapid developments in attention mechanisms. From poetry generation to summarization, text generation derives benefit as Transformer-based language models achieve groundbreaking results.

</p>
</details>

<details><summary><b>Topological Obstructions to Autoencoding</b>
<a href="https://arxiv.org/abs/2102.08380">arxiv:2102.08380</a>
&#x1F4C8; 30 <br>
<p>Joshua Batson, C. Grace Haaf, Yonatan Kahn, Daniel A. Roberts</p></summary>
<p>

**Abstract:** Autoencoders have been proposed as a powerful tool for model-independent anomaly detection in high-energy physics. The operating principle is that events which do not belong to the space of training data will be reconstructed poorly, thus flagging them as anomalies. We point out that in a variety of examples of interest, the connection between large reconstruction error and anomalies is not so clear. In particular, for data sets with nontrivial topology, there will always be points that erroneously seem anomalous due to global issues. Conversely, neural networks typically have an inductive bias or prior to locally interpolate such that undersampled or rare events may be reconstructed with small error, despite actually being the desired anomalies. Taken together, these facts are in tension with the simple picture of the autoencoder as an anomaly detector. Using a series of illustrative low-dimensional examples, we show explicitly how the intrinsic and extrinsic topology of the dataset affects the behavior of an autoencoder and how this topology is manifested in the latent space representation during training. We ground this analysis in the discussion of a mock "bump hunt" in which the autoencoder fails to identify an anomalous "signal" for reasons tied to the intrinsic topology of $n$-particle phase space.

</p>
</details>

<details><summary><b>Boosting Low-Resource Biomedical QA via Entity-Aware Masking Strategies</b>
<a href="https://arxiv.org/abs/2102.08366">arxiv:2102.08366</a>
&#x1F4C8; 29 <br>
<p>Gabriele Pergola, Elena Kochkina, Lin Gui, Maria Liakata, Yulan He</p></summary>
<p>

**Abstract:** Biomedical question-answering (QA) has gained increased attention for its capability to provide users with high-quality information from a vast scientific literature. Although an increasing number of biomedical QA datasets has been recently made available, those resources are still rather limited and expensive to produce. Transfer learning via pre-trained language models (LMs) has been shown as a promising approach to leverage existing general-purpose knowledge. However, finetuning these large models can be costly and time consuming, often yielding limited benefits when adapting to specific themes of specialised domains, such as the COVID-19 literature. To bootstrap further their domain adaptation, we propose a simple yet unexplored approach, which we call biomedical entity-aware masking (BEM). We encourage masked language models to learn entity-centric knowledge based on the pivotal entities characterizing the domain at hand, and employ those entities to drive the LM fine-tuning. The resulting strategy is a downstream process applicable to a wide variety of masked LMs, not requiring additional memory or components in the neural architectures. Experimental results show performance on par with state-of-the-art models on several biomedical QA datasets.

</p>
</details>

<details><summary><b>Topological Deep Learning: Classification Neural Networks</b>
<a href="https://arxiv.org/abs/2102.08354">arxiv:2102.08354</a>
&#x1F4C8; 29 <br>
<p>Mustafa Hajij, Kyle Istvan</p></summary>
<p>

**Abstract:** Topological deep learning is a formalism that is aimed at introducing topological language to deep learning for the purpose of utilizing the minimal mathematical structures to formalize problems that arise in a generic deep learning problem. This is the first of a sequence of articles with the purpose of introducing and studying this formalism. In this article, we define and study the classification problem in machine learning in a topological setting. Using this topological framework, we show when the classification problem is possible or not possible in the context of neural networks. Finally, we demonstrate how our topological setting immediately illuminates aspects of this problem that are not as readily apparent using traditional tools.

</p>
</details>

<details><summary><b>Galaxy Zoo DECaLS: Detailed Visual Morphology Measurements from Volunteers and Deep Learning for 314,000 Galaxies</b>
<a href="https://arxiv.org/abs/2102.08414">arxiv:2102.08414</a>
&#x1F4C8; 28 <br>
<p>Mike Walmsley, Chris Lintott, Tobias Geron, Sandor Kruk, Coleman Krawczyk, Kyle W. Willett, Steven Bamford, William Keel, Lee S. Kelvin, Lucy Fortson, Karen L. Masters, Vihang Mehta, Brooke D. Simmons, Rebecca Smethurst, Elisabeth M. Baeten, Christine Macmillan</p></summary>
<p>

**Abstract:** We present Galaxy Zoo DECaLS: detailed visual morphological classifications for Dark Energy Camera Legacy Survey images of galaxies within the SDSS DR8 footprint. Deeper DECaLS images (r=23.6 vs. r=22.2 from SDSS) reveal spiral arms, weak bars, and tidal features not previously visible in SDSS imaging. To best exploit the greater depth of DECaLS images, volunteers select from a new set of answers designed to improve our sensitivity to mergers and bars. Galaxy Zoo volunteers provide 7.5 million individual classifications over 314,000 galaxies. 140,000 galaxies receive at least 30 classifications, sufficient to accurately measure detailed morphology like bars, and the remainder receive approximately 5. All classifications are used to train an ensemble of Bayesian convolutional neural networks (a state-of-the-art deep learning method) to predict posteriors for the detailed morphology of all 314,000 galaxies. When measured against confident volunteer classifications, the networks are approximately 99% accurate on every question. Morphology is a fundamental feature of every galaxy; our human and machine classifications are an accurate and detailed resource for understanding how galaxies evolve.

</p>
</details>

<details><summary><b>Twin Augmented Architectures for Robust Classification of COVID-19 Chest X-Ray Images</b>
<a href="https://arxiv.org/abs/2102.07975">arxiv:2102.07975</a>
&#x1F4C8; 28 <br>
<p>Kartikeya Badola, Sameer Ambekar, Himanshu Pant, Sumit Soman, Anuradha Sural, Rajiv Narang, Suresh Chandra,  Jayadeva</p></summary>
<p>

**Abstract:** The gold standard for COVID-19 is RT-PCR, testing facilities for which are limited and not always optimally distributed. Test results are delayed, which impacts treatment. Expert radiologists, one of whom is a co-author, are able to diagnose COVID-19 positivity from Chest X-Rays (CXR) and CT scans, that can facilitate timely treatment. Such diagnosis is particularly valuable in locations lacking radiologists with sufficient expertise and familiarity with COVID-19 patients. This paper has two contributions. One, we analyse literature on CXR based COVID-19 diagnosis. We show that popular choices of dataset selection suffer from data homogeneity, leading to misleading results. We compile and analyse a viable benchmark dataset from multiple existing heterogeneous sources. Such a benchmark is important for realistically testing models. Our second contribution relates to learning from imbalanced data. Datasets for COVID X-Ray classification face severe class imbalance, since most subjects are COVID -ve. Twin Support Vector Machines (Twin SVM) and Twin Neural Networks (Twin NN) have, in recent years, emerged as effective ways of handling skewed data. We introduce a state-of-the-art technique, termed as Twin Augmentation, for modifying popular pre-trained deep learning models. Twin Augmentation boosts the performance of a pre-trained deep neural network without requiring re-training. Experiments show, that across a multitude of classifiers, Twin Augmentation is very effective in boosting the performance of given pre-trained model for classification in imbalanced settings.

</p>
</details>

<details><summary><b>Machine Learning Based Cyber Attacks Targeting on Controlled Information: A Survey</b>
<a href="https://arxiv.org/abs/2102.07969">arxiv:2102.07969</a>
&#x1F4C8; 28 <br>
<p>Yuantian Miao, Chao Chen, Lei Pan, Qing-Long Han, Jun Zhang, Yang Xiang</p></summary>
<p>

**Abstract:** Stealing attack against controlled information, along with the increasing number of information leakage incidents, has become an emerging cyber security threat in recent years. Due to the booming development and deployment of advanced analytics solutions, novel stealing attacks utilize machine learning (ML) algorithms to achieve high success rate and cause a lot of damage. Detecting and defending against such attacks is challenging and urgent so that governments, organizations, and individuals should attach great importance to the ML-based stealing attacks. This survey presents the recent advances in this new type of attack and corresponding countermeasures. The ML-based stealing attack is reviewed in perspectives of three categories of targeted controlled information, including controlled user activities, controlled ML model-related information, and controlled authentication information. Recent publications are summarized to generalize an overarching attack methodology and to derive the limitations and future directions of ML-based stealing attacks. Furthermore, countermeasures are proposed towards developing effective protections from three aspects -- detection, disruption, and isolation.

</p>
</details>

<details><summary><b>Prioritizing Original News on Facebook</b>
<a href="https://arxiv.org/abs/2102.08465">arxiv:2102.08465</a>
&#x1F4C8; 27 <br>
<p>Xiuyan Ni, Shujian Bu, Igor L. Markov</p></summary>
<p>

**Abstract:** This work outlines how we prioritize original news, a critical indicator of news quality. By examining the landscape and life-cycle of news posts on our social media platform, we identify challenges of building and deploying an originality score. We pursue an approach based on normalized PageRank values and three-step clustering, and refresh the score on an hourly basis to capture the dynamics of online news. We describe a near real-time system architecture, evaluate our methodology, and deploy it to production. Our empirical results validate individual components and show that prioritizing original news increases user engagement with news and improves proprietary cumulative metrics.

</p>
</details>

<details><summary><b>A Review of Testing Object-Based Environment Perception for Safe Automated Driving</b>
<a href="https://arxiv.org/abs/2102.08460">arxiv:2102.08460</a>
&#x1F4C8; 26 <br>
<p>Michael Hoss, Maike Scholtes, Lutz Eckstein</p></summary>
<p>

**Abstract:** Safety assurance of automated driving systems must consider uncertain environment perception. This paper reviews literature addressing how perception testing is realized as part of safety assurance. We focus on testing for verification and validation purposes at the interface between perception and planning, and structure our analysis along the three axes 1) test criteria and metrics, 2) test scenarios, and 3) reference data. Furthermore, the analyzed literature includes related safety standards, safety-independent perception algorithm benchmarking, and sensor modeling. We find that the realization of safety-aware perception testing remains an open issue since challenges concerning the three testing axes and their interdependencies currently do not appear to be sufficiently solved.

</p>
</details>

<details><summary><b>Deep Neural Network Based Differential Equation Solver for HIV Enzyme Kinetics</b>
<a href="https://arxiv.org/abs/2102.08471">arxiv:2102.08471</a>
&#x1F4C8; 25 <br>
<p>Joseph Stember, Parvathy Jayan, Hrithwik Shalu</p></summary>
<p>

**Abstract:** Purpose: We seek to use neural networks (NNs) to solve a well-known system of differential equations describing the balance between T cells and HIV viral burden.
  Materials and Methods: In this paper, we employ a 3-input parallel NN to approximate solutions for the system of first-order ordinary differential equations describing the above biochemical relationship.
  Results: The numerical results obtained by the NN are very similar to a host of numerical approximations from the literature.
  Conclusion: We have demonstrated use of NN integration of a well-known and medically important system of first order coupled ordinary differential equations. Our trial-and-error approach counteracts the system's inherent scale imbalance. However, it highlights the need to address scale imbalance more substantively in future work. Doing so will allow more automated solutions to larger systems of equations, which could describe increasingly complex and biologically interesting systems.

</p>
</details>

<details><summary><b>COMBO: Conservative Offline Model-Based Policy Optimization</b>
<a href="https://arxiv.org/abs/2102.08363">arxiv:2102.08363</a>
&#x1F4C8; 24 <br>
<p>Tianhe Yu, Aviral Kumar, Rafael Rafailov, Aravind Rajeswaran, Sergey Levine, Chelsea Finn</p></summary>
<p>

**Abstract:** Model-based algorithms, which learn a dynamics model from logged experience and perform some sort of pessimistic planning under the learned model, have emerged as a promising paradigm for offline reinforcement learning (offline RL). However, practical variants of such model-based algorithms rely on explicit uncertainty quantification for incorporating pessimism. Uncertainty estimation with complex models, such as deep neural networks, can be difficult and unreliable. We overcome this limitation by developing a new model-based offline RL algorithm, COMBO, that regularizes the value function on out-of-support state-action tuples generated via rollouts under the learned model. This results in a conservative estimate of the value function for out-of-support state-action tuples, without requiring explicit uncertainty estimation. We theoretically show that our method optimizes a lower bound on the true policy value, that this bound is tighter than that of prior methods, and our approach satisfies a policy improvement guarantee in the offline setting. Through experiments, we find that COMBO consistently performs as well or better as compared to prior offline model-free and model-based methods on widely studied offline RL benchmarks, including image-based tasks.

</p>
</details>

<details><summary><b>GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training</b>
<a href="https://arxiv.org/abs/2102.08098">arxiv:2102.08098</a>
&#x1F4C8; 22 <br>
<p>Chen Zhu, Renkun Ni, Zheng Xu, Kezhi Kong, W. Ronny Huang, Tom Goldstein</p></summary>
<p>

**Abstract:** Innovations in neural architectures have fostered significant breakthroughs in language modeling and computer vision. Unfortunately, novel architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized. A number of architecture-specific initialization schemes have been proposed, but these schemes are not always portable to new architectures. This paper presents GradInit, an automated and architecture agnostic method for initializing neural networks. GradInit is based on a simple heuristic; the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. GradInit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients. Code is available at https://github.com/zhuchen03/gradinit.

</p>
</details>

<details><summary><b>An AutoML-based Approach to Multimodal Image Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2102.08092">arxiv:2102.08092</a>
&#x1F4C8; 21 <br>
<p>Vasco Lopes, António Gaspar, Luís A. Alexandre, João Cordeiro</p></summary>
<p>

**Abstract:** Sentiment analysis is a research topic focused on analysing data to extract information related to the sentiment that it causes. Applications of sentiment analysis are wide, ranging from recommendation systems, and marketing to customer satisfaction. Recent approaches evaluate textual content using Machine Learning techniques that are trained over large corpora. However, as social media grown, other data types emerged in large quantities, such as images. Sentiment analysis in images has shown to be a valuable complement to textual data since it enables the inference of the underlying message polarity by creating context and connections. Multimodal sentiment analysis approaches intend to leverage information of both textual and image content to perform an evaluation. Despite recent advances, current solutions still flounder in combining both image and textual information to classify social media data, mainly due to subjectivity, inter-class homogeneity and fusion data differences. In this paper, we propose a method that combines both textual and image individual sentiment analysis into a final fused classification based on AutoML, that performs a random search to find the best model. Our method achieved state-of-the-art performance in the B-T4SA dataset, with 95.19% accuracy.

</p>
</details>

<details><summary><b>Boosting Deep Transfer Learning for COVID-19 Classification</b>
<a href="https://arxiv.org/abs/2102.08085">arxiv:2102.08085</a>
&#x1F4C8; 20 <br>
<p>Fouzia Altaf, Syed M. S. Islam, Naeem K. Janjua, Naveed Akhtar</p></summary>
<p>

**Abstract:** COVID-19 classification using chest Computed Tomography (CT) has been found pragmatically useful by several studies. Due to the lack of annotated samples, these studies recommend transfer learning and explore the choices of pre-trained models and data augmentation. However, it is still unknown if there are better strategies than vanilla transfer learning for more accurate COVID-19 classification with limited CT data. This paper provides an affirmative answer, devising a novel `model' augmentation technique that allows a considerable performance boost to transfer learning for the task. Our method systematically reduces the distributional shift between the source and target domains and considers augmenting deep learning with complementary representation learning techniques. We establish the efficacy of our method with publicly available datasets and models, along with identifying contrasting observations in the previous studies.

</p>
</details>

<details><summary><b>Training Stacked Denoising Autoencoders for Representation Learning</b>
<a href="https://arxiv.org/abs/2102.08012">arxiv:2102.08012</a>
&#x1F4C8; 20 <br>
<p>Jason Liang, Keith Kelly</p></summary>
<p>

**Abstract:** We implement stacked denoising autoencoders, a class of neural networks that are capable of learning powerful representations of high dimensional data. We describe stochastic gradient descent for unsupervised training of autoencoders, as well as a novel genetic algorithm based approach that makes use of gradient information. We analyze the performance of both optimization algorithms and also the representation learning ability of the autoencoder when it is trained on standard image classification datasets.

</p>
</details>

<details><summary><b>A Regret Analysis of Bilateral Trade</b>
<a href="https://arxiv.org/abs/2102.08754">arxiv:2102.08754</a>
&#x1F4C8; 19 <br>
<p>Nicolò Cesa-Bianchi, Tommaso Cesari, Roberto Colomboni, Federico Fusco, Stefano Leonardi</p></summary>
<p>

**Abstract:** Bilateral trade, a fundamental topic in economics, models the problem of intermediating between two strategic agents, a seller and a buyer, willing to trade a good for which they hold private valuations. Despite the simplicity of this problem, a classical result by Myerson and Satterthwaite (1983) affirms the impossibility of designing a mechanism which is simultaneously efficient, incentive compatible, individually rational, and budget balanced. This impossibility result fostered an intense investigation of meaningful trade-offs between these desired properties. Much work has focused on approximately efficient fixed-price mechanisms, i.e., Blumrosen and Dobzinski (2014; 2016), Colini-Baldeschi et al. (2016), which have been shown to fully characterize strong budget balanced and ex-post individually rational direct revelation mechanisms. All these results, however, either assume some knowledge on the priors of the seller/buyer valuations, or a black box access to some samples of the distributions, as in D{ü}tting et al. (2021). In this paper, we cast for the first time the bilateral trade problem in a regret minimization framework over rounds of seller/buyer interactions, with no prior knowledge on the private seller/buyer valuations. Our main contribution is a complete characterization of the regret regimes for fixed-price mechanisms with different models of feedback and private valuations, using as benchmark the best fixed price in hindsight. More precisely, we prove the following bounds on the regret:
  $\bullet$ $\widetildeΘ(\sqrt{T})$ for full-feedback (i.e., direct revelation mechanisms);
  $\bullet$ $\widetildeΘ(T^{2/3})$ for realistic feedback (i.e., posted-price mechanisms) and independent seller/buyer valuations with bounded densities; 
  $\bullet$ $Θ(T)$ for realistic feedback and seller/buyer valuations with bounded densities; 
  $\bullet$ $Θ(T)$ for realistic feedback and independent seller/buyer valuations;
  $\bullet$ $Θ(T)$ for the adversarial setting.

</p>
</details>

<details><summary><b>Steadily Learn to Drive with Virtual Memory</b>
<a href="https://arxiv.org/abs/2102.08072">arxiv:2102.08072</a>
&#x1F4C8; 18 <br>
<p>Yuhang Zhang, Yao Mu, Yujie Yang, Yang Guan, Shengbo Eben Li, Qi Sun, Jianyu Chen</p></summary>
<p>

**Abstract:** Reinforcement learning has shown great potential in developing high-level autonomous driving. However, for high-dimensional tasks, current RL methods suffer from low data efficiency and oscillation in the training process. This paper proposes an algorithm called Learn to drive with Virtual Memory (LVM) to overcome these problems. LVM compresses the high-dimensional information into compact latent states and learns a latent dynamic model to summarize the agent's experience. Various imagined latent trajectories are generated as virtual memory by the latent dynamic model. The policy is learned by propagating gradient through the learned latent model with the imagined latent trajectories and thus leads to high data efficiency. Furthermore, a double critic structure is designed to reduce the oscillation during the training process. The effectiveness of LVM is demonstrated by an image-input autonomous driving task, in which LVM outperforms the existing method in terms of data efficiency, learning stability, and control performance.

</p>
</details>

<details><summary><b>EDITH :ECG biometrics aided by Deep learning for reliable Individual auTHentication</b>
<a href="https://arxiv.org/abs/2102.08026">arxiv:2102.08026</a>
&#x1F4C8; 18 <br>
<p>Nabil Ibtehaz, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan Kiranyaz, M. Sohel Rahman, Anas Tahir, Yazan Qiblawey, Tawsifur Rahman</p></summary>
<p>

**Abstract:** In recent years, physiological signal based authentication has shown great promises,for its inherent robustness against forgery. Electrocardiogram (ECG) signal, being the most widely studied biosignal, has also received the highest level of attention in this regard. It has been proven with numerous studies that by analyzing ECG signals from different persons, it is possible to identify them, with acceptable accuracy. In this work, we present, EDITH, a deep learning-based framework for ECG biometrics authentication system. Moreover, we hypothesize and demonstrate that Siamese architectures can be used over typical distance metrics for improved performance. We have evaluated EDITH using 4 commonly used datasets and outperformed the prior works using less number of beats. EDITH performs competitively using just a single heartbeat (96-99.75% accuracy) and can be further enhanced by fusing multiple beats (100% accuracy from 3 to 6 beats). Furthermore, the proposed Siamese architecture manages to reduce the identity verification Equal Error Rate (EER) to 1.29%. A limited case study of EDITH with real-world experimental data also suggests its potential as a practical authentication system.

</p>
</details>

<details><summary><b>Hierarchical VAEs Know What They Don't Know</b>
<a href="https://arxiv.org/abs/2102.08248">arxiv:2102.08248</a>
&#x1F4C8; 17 <br>
<p>Jakob D. Havtorn, Jes Frellsen, Søren Hauberg, Lars Maaløe</p></summary>
<p>

**Abstract:** Deep generative models have been demonstrated as state-of-the-art density estimators. Yet, recent work has found that they often assign a higher likelihood to data from outside the training distribution. This seemingly paradoxical behavior has caused concerns over the quality of the attained density estimates. In the context of hierarchical variational autoencoders, we provide evidence to explain this behavior by out-of-distribution data having in-distribution low-level features. We argue that this is both expected and desirable behavior. With this insight in hand, we develop a fast, scalable and fully unsupervised likelihood-ratio score for OOD detection that requires data to be in-distribution across all feature-levels. We benchmark the method on a vast set of data and model combinations and achieve state-of-the-art results on out-of-distribution detection.

</p>
</details>

<details><summary><b>Integrating Pre-trained Model into Rule-based Dialogue Management</b>
<a href="https://arxiv.org/abs/2102.08553">arxiv:2102.08553</a>
&#x1F4C8; 15 <br>
<p>Jun Quan, Meng Yang, Qiang Gan, Deyi Xiong, Yiming Liu, Yuchen Dong, Fangxin Ouyang, Jun Tian, Ruiling Deng, Yongzhi Li, Yang Yang, Daxin Jiang</p></summary>
<p>

**Abstract:** Rule-based dialogue management is still the most popular solution for industrial task-oriented dialogue systems for their interpretablility. However, it is hard for developers to maintain the dialogue logic when the scenarios get more and more complex. On the other hand, data-driven dialogue systems, usually with end-to-end structures, are popular in academic research and easier to deal with complex conversations, but such methods require plenty of training data and the behaviors are less interpretable. In this paper, we propose a method to leverages the strength of both rule-based and data-driven dialogue managers (DM). We firstly introduce the DM of Carina Dialog System (CDS, an advanced industrial dialogue system built by Microsoft). Then we propose the "model-trigger" design to make the DM trainable thus scalable to scenario changes. Furthermore, we integrate pre-trained models and empower the DM with few-shot capability. The experimental results demonstrate the effectiveness and strong few-shot capability of our method.

</p>
</details>

<details><summary><b>End-to-end lyrics Recognition with Voice to Singing Style Transfer</b>
<a href="https://arxiv.org/abs/2102.08575">arxiv:2102.08575</a>
&#x1F4C8; 14 <br>
<p>Sakya Basak, Shrutina Agarwal, Sriram Ganapathy, Naoya Takahashi</p></summary>
<p>

**Abstract:** Automatic transcription of monophonic/polyphonic music is a challenging task due to the lack of availability of large amounts of transcribed data. In this paper, we propose a data augmentation method that converts natural speech to singing voice based on vocoder based speech synthesizer. This approach, called voice to singing (V2S), performs the voice style conversion by modulating the F0 contour of the natural speech with that of a singing voice. The V2S model based style transfer can generate good quality singing voice thereby enabling the conversion of large corpora of natural speech to singing voice that is useful in building an E2E lyrics transcription system. In our experiments on monophonic singing voice data, the V2S style transfer provides a significant gain (relative improvements of 21%) for the E2E lyrics transcription system. We also discuss additional components like transfer learning and lyrics based language modeling to improve the performance of the lyrics transcription system.

</p>
</details>

<details><summary><b>Composing Pick-and-Place Tasks By Grounding Language</b>
<a href="https://arxiv.org/abs/2102.08094">arxiv:2102.08094</a>
&#x1F4C8; 14 <br>
<p>Oier Mees, Wolfram Burgard</p></summary>
<p>

**Abstract:** Controlling robots to perform tasks via natural language is one of the most challenging topics in human-robot interaction. In this work, we present a robot system that follows unconstrained language instructions to pick and place arbitrary objects and effectively resolves ambiguities through dialogues. Our approach infers objects and their relationships from input images and language expressions and can place objects in accordance with the spatial relations expressed by the user. Unlike previous approaches, we consider grounding not only for the picking but also for the placement of everyday objects from language. Specifically, by grounding objects and their spatial relations, we allow specification of complex placement instructions, e.g. "place it behind the middle red bowl". Our results obtained using a real-world PR2 robot demonstrate the effectiveness of our method in understanding pick-and-place language instructions and sequentially composing them to solve tabletop manipulation tasks. Videos are available at http://speechrobot.cs.uni-freiburg.de

</p>
</details>

<details><summary><b>TableLab: An Interactive Table Extraction System with Adaptive Deep Learning</b>
<a href="https://arxiv.org/abs/2102.08445">arxiv:2102.08445</a>
&#x1F4C8; 13 <br>
<p>Nancy Xin Ru Wang, Douglas Burdick, Yunyao Li</p></summary>
<p>

**Abstract:** Table extraction from PDF and image documents is a ubiquitous task in the real-world. Perfect extraction quality is difficult to achieve with one single out-of-box model due to (1) the wide variety of table styles, (2) the lack of training data representing this variety and (3) the inherent ambiguity and subjectivity of table definitions between end-users. Meanwhile, building customized models from scratch can be difficult due to the expensive nature of annotating table data. We attempt to solve these challenges with TableLab by providing a system where users and models seamlessly work together to quickly customize high-quality extraction models with a few labelled examples for the user's document collection, which contains pages with tables. Given an input document collection, TableLab first detects tables with similar structures (templates) by clustering embeddings from the extraction model. Document collections often contain tables created with a limited set of templates or similar structures. It then selects a few representative table examples already extracted with a pre-trained base deep learning model. Via an easy-to-use user interface, users provide feedback to these selections without necessarily having to identify every single error. TableLab then applies such feedback to finetune the pre-trained model and returns the results of the finetuned model back to the user. The user can choose to repeat this process iteratively until obtaining a customized model with satisfactory performance.

</p>
</details>

<details><summary><b>On the use of generative deep neural networks to synthesize artificial multichannel EEG signals</b>
<a href="https://arxiv.org/abs/2102.08061">arxiv:2102.08061</a>
&#x1F4C8; 13 <br>
<p>Ozan Ozdenizci, Deniz Erdogmus</p></summary>
<p>

**Abstract:** Recent promises of generative deep learning lately brought interest to its potential uses in neural engineering. In this paper we firstly review recently emerging studies on generating artificial electroencephalography (EEG) signals with deep neural networks. Subsequently, we present our feasibility experiments on generating condition-specific multichannel EEG signals using conditional variational autoencoders. By manipulating real resting-state EEG epochs, we present an approach to synthetically generate time-series multichannel signals that show spectro-temporal EEG patterns which are expected to be observed during distinct motor imagery conditions.

</p>
</details>

<details><summary><b>TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2102.08005">arxiv:2102.08005</a>
&#x1F4C8; 13 <br>
<p>Yundong Zhang, Huiye Liu, Qiang Hu</p></summary>
<p>

**Abstract:** Medical image segmentation - the prerequisite of numerous clinical needs - has been significantly prospered by recent advances in convolutional neural networks (CNNs). However, it exhibits general limitations on modeling explicit long-range relation, and existing cures, resorting to building deep encoders along with aggressive downsampling operations, leads to redundant deepened networks and loss of localized details. Hence, the segmentation task awaits a better solution to improve the efficiency of modeling global contexts while maintaining a strong grasp of low-level details. In this paper, we propose a novel parallel-in-branch architecture, TransFuse, to address this challenge. TransFuse combines Transformers and CNNs in a parallel style, where both global dependency and low-level spatial details can be efficiently captured in a much shallower manner. Besides, a novel fusion technique - BiFusion module is created to efficiently fuse the multi-level features from both branches. Extensive experiments demonstrate that TransFuse achieves the newest state-of-the-art results on both 2D and 3D medical image sets including polyp, skin lesion, hip, and prostate segmentation, with significant parameter decrease and inference speed improvement.

</p>
</details>

<details><summary><b>Ensemble Transfer Learning of Elastography and B-mode Breast Ultrasound Images</b>
<a href="https://arxiv.org/abs/2102.08567">arxiv:2102.08567</a>
&#x1F4C8; 12 <br>
<p>Sampa Misra, Seungwan Jeon, Ravi Managuli, Seiyon Lee, Gyuwon Kim, Seungchul Lee, Richard G Barr, Chulhong Kim</p></summary>
<p>

**Abstract:** Computer-aided detection (CAD) of benign and malignant breast lesions becomes increasingly essential in breast ultrasound (US) imaging. The CAD systems rely on imaging features identified by the medical experts for their performance, whereas deep learning (DL) methods automatically extract features from the data. The challenge of the DL is the insufficiency of breast US images available to train the DL models. Here, we present an ensemble transfer learning model to classify benign and malignant breast tumors using B-mode breast US (B-US) and strain elastography breast US (SE-US) images. This model combines semantic features from AlexNet & ResNet models to classify benign from malignant tumors. We use both B-US and SE-US images to train the model and classify the tumors. We retrospectively gathered 85 patients' data, with 42 benign and 43 malignant cases confirmed with the biopsy. Each patient had multiple B-US and their corresponding SE-US images, and the total dataset contained 261 B-US images and 261 SE-US images. Experimental results show that our ensemble model achieves a sensitivity of 88.89% and specificity of 91.10%. These diagnostic performances of the proposed method are equivalent to or better than manual identification. Thus, our proposed ensemble learning method would facilitate detecting early breast cancer, reliably improving patient care.

</p>
</details>

<details><summary><b>Dataset Condensation with Differentiable Siamese Augmentation</b>
<a href="https://arxiv.org/abs/2102.08259">arxiv:2102.08259</a>
&#x1F4C8; 12 <br>
<p>Bo Zhao, Hakan Bilen</p></summary>
<p>

**Abstract:** In many machine learning problems, large-scale datasets have become the de-facto standard to train state-of-the-art deep networks at the price of heavy computation load. In this paper, we focus on condensing large training sets into significantly smaller synthetic sets which can be used to train deep neural networks from scratch with minimum drop in performance. Inspired from the recent training set synthesis methods, we propose Differentiable Siamese Augmentation that enables effective use of data augmentation to synthesize more informative synthetic images and thus achieves better performance when training networks with augmentations. Experiments on multiple image classification benchmarks demonstrate that the proposed method obtains substantial gains over the state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show with only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5% relative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively. We also explore the use of our method in continual learning and neural architecture search, and show promising results.

</p>
</details>

<details><summary><b>Mode-Assisted Joint Training of Deep Boltzmann Machines</b>
<a href="https://arxiv.org/abs/2102.08562">arxiv:2102.08562</a>
&#x1F4C8; 10 <br>
<p>Haik Manukian, Massimiliano Di Ventra</p></summary>
<p>

**Abstract:** The deep extension of the restricted Boltzmann machine (RBM), known as the deep Boltzmann machine (DBM), is an expressive family of machine learning models which can serve as compact representations of complex probability distributions. However, jointly training DBMs in the unsupervised setting has proven to be a formidable task. A recent technique we have proposed, called mode-assisted training, has shown great success in improving the unsupervised training of RBMs. Here, we show that the performance gains of the mode-assisted training are even more dramatic for DBMs. In fact, DBMs jointly trained with the mode-assisted algorithm can represent the same data set with orders of magnitude lower number of total parameters compared to state-of-the-art training procedures and even with respect to RBMs, provided a fan-in network topology is also introduced. This substantial saving in number of parameters makes this training method very appealing also for hardware implementations.

</p>
</details>

<details><summary><b>Going Beyond Saliency Maps: Training Deep Models to Interpret Deep Models</b>
<a href="https://arxiv.org/abs/2102.08239">arxiv:2102.08239</a>
&#x1F4C8; 10 <br>
<p>Zixuan Liu, Ehsan Adeli, Kilian M. Pohl, Qingyu Zhao</p></summary>
<p>

**Abstract:** Interpretability is a critical factor in applying complex deep learning models to advance the understanding of brain disorders in neuroimaging studies. To interpret the decision process of a trained classifier, existing techniques typically rely on saliency maps to quantify the voxel-wise or feature-level importance for classification through partial derivatives. Despite providing some level of localization, these maps are not human-understandable from the neuroscience perspective as they do not inform the specific meaning of the alteration linked to the brain disorder. Inspired by the image-to-image translation scheme, we propose to train simulator networks that can warp a given image to inject or remove patterns of the disease. These networks are trained such that the classifier produces consistently increased or decreased prediction logits for the simulated images. Moreover, we propose to couple all the simulators into a unified model based on conditional convolution. We applied our approach to interpreting classifiers trained on a synthetic dataset and two neuroimaging datasets to visualize the effect of the Alzheimer's disease and alcohol use disorder. Compared to the saliency maps generated by baseline approaches, our simulations and visualizations based on the Jacobian determinants of the warping field reveal meaningful and understandable patterns related to the diseases.

</p>
</details>

<details><summary><b>The Yin-Yang dataset</b>
<a href="https://arxiv.org/abs/2102.08211">arxiv:2102.08211</a>
&#x1F4C8; 10 <br>
<p>Laura Kriener, Julian Göltz, Mihai A. Petrovici</p></summary>
<p>

**Abstract:** The Yin-Yang dataset was developed for research on biologically plausible error backpropagation and deep learning in spiking neural networks. It serves as an alternative to classic deep learning datasets, especially in algorithm- and model-prototyping scenarios, by providing several advantages. First, it is smaller and therefore faster to learn, thereby being better suited for the deployment on neuromorphic chips with limited network sizes. Second, it exhibits a very clear gap between the accuracies achievable using shallow as compared to deep neural networks.

</p>
</details>

<details><summary><b>EfficientLPS: Efficient LiDAR Panoptic Segmentation</b>
<a href="https://arxiv.org/abs/2102.08009">arxiv:2102.08009</a>
&#x1F4C8; 10 <br>
<p>Kshitij Sirohi, Rohit Mohan, Daniel Büscher, Wolfram Burgard, Abhinav Valada</p></summary>
<p>

**Abstract:** Panoptic segmentation of point clouds is a crucial task that enables autonomous vehicles to comprehend their vicinity using their highly accurate and reliable LiDAR sensors. Existing top-down approaches tackle this problem by either combining independent task-specific networks or translating methods from the image domain ignoring the intricacies of LiDAR data and thus often resulting in sub-optimal performance. In this paper, we present the novel top-down Efficient LiDAR Panoptic Segmentation (EfficientLPS) architecture that addresses multiple challenges in segmenting LiDAR point clouds including distance-dependent sparsity, severe occlusions, large scale-variations, and re-projection errors. EfficientLPS comprises of a novel shared backbone that encodes with strengthened geometric transformation modeling capacity and aggregates semantically rich range-aware multi-scale features. It incorporates new scale-invariant semantic and instance segmentation heads along with the panoptic fusion module which is supervised by our proposed panoptic periphery loss function. Additionally, we formulate a regularized pseudo labeling framework to further improve the performance of EfficientLPS by training on unlabelled data. We benchmark our proposed model on two large-scale LiDAR datasets: nuScenes, for which we also provide ground truth annotations, and SemanticKITTI. Notably, EfficientLPS sets the new state-of-the-art on both these datasets.

</p>
</details>

<details><summary><b>Reward Poisoning in Reinforcement Learning: Attacks Against Unknown Learners in Unknown Environments</b>
<a href="https://arxiv.org/abs/2102.08492">arxiv:2102.08492</a>
&#x1F4C8; 9 <br>
<p>Amin Rakhsha, Xuezhou Zhang, Xiaojin Zhu, Adish Singla</p></summary>
<p>

**Abstract:** We study black-box reward poisoning attacks against reinforcement learning (RL), in which an adversary aims to manipulate the rewards to mislead a sequence of RL agents with unknown algorithms to learn a nefarious policy in an environment unknown to the adversary a priori. That is, our attack makes minimum assumptions on the prior knowledge of the adversary: it has no initial knowledge of the environment or the learner, and neither does it observe the learner's internal mechanism except for its performed actions. We design a novel black-box attack, U2, that can provably achieve a near-matching performance to the state-of-the-art white-box attack, demonstrating the feasibility of reward poisoning even in the most challenging black-box setting.

</p>
</details>

<details><summary><b>COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining</b>
<a href="https://arxiv.org/abs/2102.08473">arxiv:2102.08473</a>
&#x1F4C8; 9 <br>
<p>Yu Meng, Chenyan Xiong, Payal Bajaj, Saurabh Tiwary, Paul Bennett, Jiawei Han, Xia Song</p></summary>
<p>

**Abstract:** We present a self-supervised learning framework, COCO-LM, that pretrains Language Models by COrrecting and COntrasting corrupted text sequences. Following ELECTRA-style pretraining, COCO-LM employs an auxiliary language model to corrupt text sequences, upon which it constructs two new tasks for pretraining the main model. The first token-level task, Corrective Language Modeling, is to detect and correct tokens replaced by the auxiliary model, in order to better capture token-level semantics. The second sequence-level task, Sequence Contrastive Learning, is to align text sequences originated from the same source input while ensuring uniformity in the representation space. Experiments on GLUE and SQuAD demonstrate that COCO-LM not only outperforms recent state-of-the-art pretrained models in accuracy, but also improves pretraining efficiency. It achieves the MNLI accuracy of ELECTRA with 50% of its pretraining GPU hours. With the same pretraining steps of standard base/large-sized models, COCO-LM outperforms the previous best models by 1+ GLUE average points.

</p>
</details>

<details><summary><b>Hough2Map -- Iterative Event-based Hough Transform for High-Speed Railway Mapping</b>
<a href="https://arxiv.org/abs/2102.08145">arxiv:2102.08145</a>
&#x1F4C8; 9 <br>
<p>Florian Tschopp, Cornelius von Einem, Andrei Cramariuc, David Hug, Andrew William Palmer, Roland Siegwart, Margarita Chli, Juan Nieto</p></summary>
<p>

**Abstract:** To cope with the growing demand for transportation on the railway system, accurate, robust, and high-frequency positioning is required to enable a safe and efficient utilization of the existing railway infrastructure. As a basis for a localization system we propose a complete on-board mapping pipeline able to map robust meaningful landmarks, such as poles from power lines, in the vicinity of the vehicle. Such poles are good candidates for reliable and long term landmarks even through difficult weather conditions or seasonal changes. To address the challenges of motion blur and illumination changes in railway scenarios we employ a Dynamic Vision Sensor, a novel event-based camera. Using a sideways oriented on-board camera, poles appear as vertical lines. To map such lines in a real-time event stream, we introduce Hough2Map, a novel consecutive iterative event-based Hough transform framework capable of detecting, tracking, and triangulating close-by structures. We demonstrate the mapping reliability and accuracy of Hough2Map on real-world data in typical usage scenarios and evaluate using surveyed infrastructure ground truth maps. Hough2Map achieves a detection reliability of up to 92% and a mapping root mean square error accuracy of 1.1518m.

</p>
</details>

<details><summary><b>TradeR: Practical Deep Hierarchical Reinforcement Learning for Trade Execution</b>
<a href="https://arxiv.org/abs/2104.00620">arxiv:2104.00620</a>
&#x1F4C8; 8 <br>
<p>Karush Suri, Xiao Qi Shi, Konstantinos Plataniotis, Yuri Lawryshyn</p></summary>
<p>

**Abstract:** Advances in Reinforcement Learning (RL) span a wide variety of applications which motivate development in this area. While application tasks serve as suitable benchmarks for real world problems, RL is seldomly used in practical scenarios consisting of abrupt dynamics. This allows one to rethink the problem setup in light of practical challenges. We present Trade Execution using Reinforcement Learning (TradeR) which aims to address two such practical challenges of catastrophy and surprise minimization by formulating trading as a real-world hierarchical RL problem. Through this lens, TradeR makes use of hierarchical RL to execute trade bids on high frequency real market experiences comprising of abrupt price variations during the 2019 fiscal year COVID19 stock market crash. The framework utilizes an energy-based scheme in conjunction with surprise value function for estimating and minimizing surprise. In a large-scale study of 35 stock symbols from the S&P500 index, TradeR demonstrates robustness to abrupt price changes and catastrophic losses while maintaining profitable outcomes. We hope that our work serves as a motivating example for application of RL to practical problems.

</p>
</details>

<details><summary><b>FIXME: Enhance Software Reliability with Hybrid Approaches in Cloud</b>
<a href="https://arxiv.org/abs/2102.09336">arxiv:2102.09336</a>
&#x1F4C8; 8 <br>
<p>Jinho Hwang, Larisa Shwartz, Qing Wang, Raghav Batta, Harshit Kumar, Michael Nidd</p></summary>
<p>

**Abstract:** With the promise of reliability in cloud, more enterprises are migrating to cloud. The process of continuous integration/deployment (CICD) in cloud connects developers who need to deliver value faster and more transparently with site reliability engineers (SREs) who need to manage applications reliably. SREs feed back development issues to developers, and developers commit fixes and trigger CICD to redeploy. The release cycle is more continuous than ever, thus the code to production is faster and more automated. To provide this higher level agility, the cloud platforms become more complex in the face of flexibility with deeper layers of virtualization. However, reliability does not come for free with all these complexities. Software engineers and SREs need to deal with wider information spectrum from virtualized layers. Therefore, providing correlated information with true positive evidences is critical to identify the root cause of issues quickly in order to reduce mean time to recover (MTTR), performance metrics for SREs. Similarity, knowledge, or statistics driven approaches have been effective, but with increasing data volume and types, an individual approach is limited to correlate semantic relations of different data sources. In this paper, we introduce FIXME to enhance software reliability with hybrid diagnosis approaches for enterprises. Our evaluation results show using hybrid diagnosis approach is about 17% better in precision. The results are helpful for both practitioners and researchers to develop hybrid diagnosis in the highly dynamic cloud environment.

</p>
</details>

<details><summary><b>Learning Invariant Representations using Inverse Contrastive Loss</b>
<a href="https://arxiv.org/abs/2102.08343">arxiv:2102.08343</a>
&#x1F4C8; 8 <br>
<p>Aditya Kumar Akash, Vishnu Suresh Lokhande, Sathya N. Ravi, Vikas Singh</p></summary>
<p>

**Abstract:** Learning invariant representations is a critical first step in a number of machine learning tasks. A common approach corresponds to the so-called information bottleneck principle in which an application dependent function of mutual information is carefully chosen and optimized. Unfortunately, in practice, these functions are not suitable for optimization purposes since these losses are agnostic of the metric structure of the parameters of the model. We introduce a class of losses for learning representations that are invariant to some extraneous variable of interest by inverting the class of contrastive losses, i.e., inverse contrastive loss (ICL). We show that if the extraneous variable is binary, then optimizing ICL is equivalent to optimizing a regularized MMD divergence. More generally, we also show that if we are provided a metric on the sample space, our formulation of ICL can be decomposed into a sum of convex functions of the given distance metric. Our experimental results indicate that models obtained by optimizing ICL achieve significantly better invariance to the extraneous variable for a fixed desired level of accuracy. In a variety of experimental settings, we show applicability of ICL for learning invariant representations for both continuous and discrete extraneous variables.

</p>
</details>

<details><summary><b>Active Privacy-utility Trade-off Against a Hypothesis Testing Adversary</b>
<a href="https://arxiv.org/abs/2102.08308">arxiv:2102.08308</a>
&#x1F4C8; 8 <br>
<p>Ecenaz Erdemir, Pier Luigi Dragotti, Deniz Gunduz</p></summary>
<p>

**Abstract:** We consider a user releasing her data containing some personal information in return of a service. We model user's personal information as two correlated random variables, one of them, called the secret variable, is to be kept private, while the other, called the useful variable, is to be disclosed for utility. We consider active sequential data release, where at each time step the user chooses from among a finite set of release mechanisms, each revealing some information about the user's personal information, i.e., the true hypotheses, albeit with different statistics. The user manages data release in an online fashion such that maximum amount of information is revealed about the latent useful variable, while the confidence for the sensitive variable is kept below a predefined level. For the utility, we consider both the probability of correct detection of the useful variable and the mutual information (MI) between the useful variable and released data. We formulate both problems as a Markov decision process (MDP), and numerically solve them by advantage actor-critic (A2C) deep reinforcement learning (RL).

</p>
</details>

<details><summary><b>Outside the Echo Chamber: Optimizing the Performative Risk</b>
<a href="https://arxiv.org/abs/2102.08570">arxiv:2102.08570</a>
&#x1F4C8; 7 <br>
<p>John Miller, Juan C. Perdomo, Tijana Zrnic</p></summary>
<p>

**Abstract:** In performative prediction, predictions guide decision-making and hence can influence the distribution of future data. To date, work on performative prediction has focused on finding performatively stable models, which are the fixed points of repeated retraining. However, stable solutions can be far from optimal when evaluated in terms of the performative risk, the loss experienced by the decision maker when deploying a model. In this paper, we shift attention beyond performative stability and focus on optimizing the performative risk directly. We identify a natural set of properties of the loss function and model-induced distribution shift under which the performative risk is convex, a property which does not follow from convexity of the loss alone. Furthermore, we develop algorithms that leverage our structural assumptions to optimize the performative risk with better sample efficiency than generic methods for derivative-free convex optimization.

</p>
</details>

<details><summary><b>Towards an AI Coach to Infer Team Mental Model Alignment in Healthcare</b>
<a href="https://arxiv.org/abs/2102.08507">arxiv:2102.08507</a>
&#x1F4C8; 7 <br>
<p>Sangwon Seo, Lauren R. Kennedy-Metz, Marco A. Zenati, Julie A. Shah, Roger D. Dias, Vaibhav V. Unhelkar</p></summary>
<p>

**Abstract:** Shared mental models are critical to team success; however, in practice, team members may have misaligned models due to a variety of factors. In safety-critical domains (e.g., aviation, healthcare), lack of shared mental models can lead to preventable errors and harm. Towards the goal of mitigating such preventable errors, here, we present a Bayesian approach to infer misalignment in team members' mental models during complex healthcare task execution. As an exemplary application, we demonstrate our approach using two simulated team-based scenarios, derived from actual teamwork in cardiac surgery. In these simulated experiments, our approach inferred model misalignment with over 75% recall, thereby providing a building block for enabling computer-assisted interventions to augment human cognition in the operating room and improve teamwork.

</p>
</details>

<details><summary><b>Quantifying environment and population diversity in multi-agent reinforcement learning</b>
<a href="https://arxiv.org/abs/2102.08370">arxiv:2102.08370</a>
&#x1F4C8; 7 <br>
<p>Kevin R. McKee, Joel Z. Leibo, Charlie Beattie, Richard Everett</p></summary>
<p>

**Abstract:** Generalization is a major challenge for multi-agent reinforcement learning. How well does an agent perform when placed in novel environments and in interactions with new co-players? In this paper, we investigate and quantify the relationship between generalization and diversity in the multi-agent domain. Across the range of multi-agent environments considered here, procedurally generating training levels significantly improves agent performance on held-out levels. However, agent performance on the specific levels used in training sometimes declines as a result. To better understand the effects of co-player variation, our experiments introduce a new environment-agnostic measure of behavioral diversity. Results demonstrate that population size and intrinsic motivation are both effective methods of generating greater population diversity. In turn, training with a diverse set of co-players strengthens agent performance in some (but not all) cases.

</p>
</details>

<details><summary><b>Conditional Distributional Treatment Effect with Kernel Conditional Mean Embeddings and U-Statistic Regression</b>
<a href="https://arxiv.org/abs/2102.08208">arxiv:2102.08208</a>
&#x1F4C8; 7 <br>
<p>Junhyung Park, Uri Shalit, Bernhard Schölkopf, Krikamol Muandet</p></summary>
<p>

**Abstract:** We propose to analyse the conditional distributional treatment effect (CoDiTE), which, in contrast to the more common conditional average treatment effect (CATE), is designed to encode a treatment's distributional aspects beyond the mean. We first introduce a formal definition of the CoDiTE associated with a distance function between probability measures. Then we discuss the CoDiTE associated with the maximum mean discrepancy via kernel conditional mean embeddings, which, coupled with a hypothesis test, tells us whether there is any conditional distributional effect of the treatment. Finally, we investigate what kind of conditional distributional effect the treatment has, both in an exploratory manner via the conditional witness function, and in a quantitative manner via U-statistic regression, generalising the CATE to higher-order moments. Experiments on synthetic, semi-synthetic and real datasets demonstrate the merits of our approach.

</p>
</details>

<details><summary><b>EPE-NAS: Efficient Performance Estimation Without Training for Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2102.08099">arxiv:2102.08099</a>
&#x1F4C8; 7 <br>
<p>Vasco Lopes, Saeid Alirezazadeh, Luís A. Alexandre</p></summary>
<p>

**Abstract:** Neural Architecture Search (NAS) has shown excellent results in designing architectures for computer vision problems. NAS alleviates the need for human-defined settings by automating architecture design and engineering. However, NAS methods tend to be slow, as they require large amounts of GPU computation. This bottleneck is mainly due to the performance estimation strategy, which requires the evaluation of the generated architectures, mainly by training them, to update the sampler method. In this paper, we propose EPE-NAS, an efficient performance estimation strategy, that mitigates the problem of evaluating networks, by scoring untrained networks and creating a correlation with their trained performance. We perform this process by looking at intra and inter-class correlations of an untrained network. We show that EPE-NAS can produce a robust correlation and that by incorporating it into a simple random sampling strategy, we are able to search for competitive networks, without requiring any training, in a matter of seconds using a single GPU. Moreover, EPE-NAS is agnostic to the search method, since it focuses on the evaluation of untrained networks, making it easy to integrate into almost any NAS method.

</p>
</details>

<details><summary><b>Intuitively Assessing ML Model Reliability through Example-Based Explanations and Editing Model Inputs</b>
<a href="https://arxiv.org/abs/2102.08540">arxiv:2102.08540</a>
&#x1F4C8; 6 <br>
<p>Harini Suresh, Kathleen M. Lewis, John V. Guttag, Arvind Satyanarayan</p></summary>
<p>

**Abstract:** Interpretability methods aim to help users build trust in and understand the capabilities of machine learning models. However, existing approaches often rely on abstract, complex visualizations that poorly map to the task at hand or require non-trivial ML expertise to interpret. Here, we present two visual analytics modules that facilitate an intuitive assessment of model reliability. To help users better characterize and reason about a model's uncertainty, we visualize raw and aggregate information about a given input's nearest neighbors. Using an interactive editor, users can manipulate this input in semantically-meaningful ways, determine the effect on the output, and compare against their prior expectations. We evaluate our interface using an electrocardiogram beat classification case study. Compared to a baseline feature importance interface, we find that 14 physicians are better able to align the model's uncertainty with domain-relevant factors and build intuition about its capabilities and limitations.

</p>
</details>

<details><summary><b>IntSGD: Floatless Compression of Stochastic Gradients</b>
<a href="https://arxiv.org/abs/2102.08374">arxiv:2102.08374</a>
&#x1F4C8; 6 <br>
<p>Konstantin Mishchenko, Bokun Wang, Dmitry Kovalev, Peter Richtárik</p></summary>
<p>

**Abstract:** We propose a family of lossy integer compressions for Stochastic Gradient Descent (SGD) that do not communicate a single float. This is achieved by multiplying floating-point vectors with a number known to every device and then rounding to an integer number. Our theory shows that the iteration complexity of SGD does not change up to constant factors when the vectors are scaled properly. Moreover, this holds for both convex and non-convex functions, with and without overparameterization. In contrast to other compression-based algorithms, ours preserves the convergence rate of SGD even on non-smooth problems. Finally, we show that when the data is significantly heterogeneous, it may become increasingly hard to keep the integers bounded and propose an alternative algorithm, IntDIANA, to solve this type of problems.

</p>
</details>

<details><summary><b>Revisiting Language Encoding in Learning Multilingual Representations</b>
<a href="https://arxiv.org/abs/2102.08357">arxiv:2102.08357</a>
&#x1F4C8; 6 <br>
<p>Shengjie Luo, Kaiyuan Gao, Shuxin Zheng, Guolin Ke, Di He, Liwei Wang, Tie-Yan Liu</p></summary>
<p>

**Abstract:** Transformer has demonstrated its great power to learn contextual word representations for multiple languages in a single model. To process multilingual sentences in the model, a learnable vector is usually assigned to each language, which is called "language embedding". The language embedding can be either added to the word embedding or attached at the beginning of the sentence. It serves as a language-specific signal for the Transformer to capture contextual representations across languages. In this paper, we revisit the use of language embedding and identify several problems in the existing formulations. By investigating the interaction between language embedding and word embedding in the self-attention module, we find that the current methods cannot reflect the language-specific word correlation well. Given these findings, we propose a new approach called Cross-lingual Language Projection (XLP) to replace language embedding. For a sentence, XLP projects the word embeddings into language-specific semantic space, and then the projected embeddings will be fed into the Transformer model to process with their language-specific meanings. In such a way, XLP achieves the purpose of appropriately encoding "language" in a multilingual Transformer model. Experimental results show that XLP can freely and significantly boost the model performance on extensive multilingual benchmark datasets. Codes and models will be released at https://github.com/lsj2408/XLP.

</p>
</details>

<details><summary><b>Constructing Multiclass Classifiers using Binary Classifiers Under Log-Loss</b>
<a href="https://arxiv.org/abs/2102.08184">arxiv:2102.08184</a>
&#x1F4C8; 6 <br>
<p>Assaf Ben-Yishai, Or Ordentlich</p></summary>
<p>

**Abstract:** The construction of multiclass classifiers from binary elements is studied in this paper, and performance is quantified by the regret, defined with respect to the Bayes optimal log-loss. We discuss two known methods. The first is one vs. all (OVA), for which we prove that the multiclass regret is upper bounded by the sum of binary regrets of the constituent classifiers. The second is hierarchical classification, based on a binary tree. For this method we prove that the multiclass regret is exactly a weighted sum of constituent binary regrets where the weighing is determined by the tree structure.
  We also introduce a leverage-hierarchical classification method, which potentially yields smaller log-loss and regret. The advantages of these classification methods are demonstrated by simulation on both synthetic and real-life datasets.

</p>
</details>

<details><summary><b>TCN: Table Convolutional Network for Web Table Interpretation</b>
<a href="https://arxiv.org/abs/2102.09460">arxiv:2102.09460</a>
&#x1F4C8; 5 <br>
<p>Daheng Wang, Prashant Shiralkar, Colin Lockard, Binxuan Huang, Xin Luna Dong, Meng Jiang</p></summary>
<p>

**Abstract:** Information extraction from semi-structured webpages provides valuable long-tailed facts for augmenting knowledge graph. Relational Web tables are a critical component containing additional entities and attributes of rich and diverse knowledge. However, extracting knowledge from relational tables is challenging because of sparse contextual information. Existing work linearize table cells and heavily rely on modifying deep language models such as BERT which only captures related cells information in the same table. In this work, we propose a novel relational table representation learning approach considering both the intra- and inter-table contextual information. On one hand, the proposed Table Convolutional Network model employs the attention mechanism to adaptively focus on the most informative intra-table cells of the same row or column; and, on the other hand, it aggregates inter-table contextual information from various types of implicit connections between cells across different tables. Specifically, we propose three novel aggregation modules for (i) cells of the same value, (ii) cells of the same schema position, and (iii) cells linked to the same page topic. We further devise a supervised multi-task training objective for jointly predicting column type and pairwise column relation, as well as a table cell recovery objective for pre-training. Experiments on real Web table datasets demonstrate our method can outperform competitive baselines by +4.8% of F1 for column type prediction and by +4.1% of F1 for pairwise column relation prediction.

</p>
</details>

<details><summary><b>DEUP: Direct Epistemic Uncertainty Prediction</b>
<a href="https://arxiv.org/abs/2102.08501">arxiv:2102.08501</a>
&#x1F4C8; 5 <br>
<p>Moksh Jain, Salem Lahlou, Hadi Nekoei, Victor Butoi, Paul Bertin, Jarrid Rector-Brooks, Maksym Korablyov, Yoshua Bengio</p></summary>
<p>

**Abstract:** Epistemic uncertainty is the part of out-of-sample prediction error due to the lack of knowledge of the learner. Whereas previous work was focusing on model variance, we propose a principled approach for directly estimating epistemic uncertainty by learning to predict generalization error and subtracting an estimate of aleatoric uncertainty, i.e., intrinsic unpredictability. This estimator of epistemic uncertainty includes the effect of model bias and can be applied in non-stationary learning environments arising in active learning or reinforcement learning. In addition to demonstrating these properties of Direct Epistemic Uncertainty Prediction (DEUP), we illustrate its advantage against existing methods for uncertainty estimation on downstream tasks including sequential model optimization and reinforcement learning. We also evaluate the quality of uncertainty estimates from DEUP for probabilistic classification of images and for estimating uncertainty about synergistic drug combinations.

</p>
</details>

<details><summary><b>Lexicographically Fair Learning: Algorithms and Generalization</b>
<a href="https://arxiv.org/abs/2102.08454">arxiv:2102.08454</a>
&#x1F4C8; 5 <br>
<p>Emily Diana, Wesley Gill, Ira Globus-Harris, Michael Kearns, Aaron Roth, Saeed Sharifi-Malvajerdi</p></summary>
<p>

**Abstract:** We extend the notion of minimax fairness in supervised learning problems to its natural conclusion: lexicographic minimax fairness (or lexifairness for short). Informally, given a collection of demographic groups of interest, minimax fairness asks that the error of the group with the highest error be minimized. Lexifairness goes further and asks that amongst all minimax fair solutions, the error of the group with the second highest error should be minimized, and amongst all of those solutions, the error of the group with the third highest error should be minimized, and so on. Despite its naturalness, correctly defining lexifairness is considerably more subtle than minimax fairness, because of inherent sensitivity to approximation error. We give a notion of approximate lexifairness that avoids this issue, and then derive oracle-efficient algorithms for finding approximately lexifair solutions in a very general setting. When the underlying empirical risk minimization problem absent fairness constraints is convex (as it is, for example, with linear and logistic regression), our algorithms are provably efficient even in the worst case. Finally, we show generalization bounds -- approximate lexifairness on the training sample implies approximate lexifairness on the true distribution with high probability. Our ability to prove generalization bounds depends on our choosing definitions that avoid the instability of naive definitions.

</p>
</details>

<details><summary><b>Faster Kernel Matrix Algebra via Density Estimation</b>
<a href="https://arxiv.org/abs/2102.08341">arxiv:2102.08341</a>
&#x1F4C8; 5 <br>
<p>Arturs Backurs, Piotr Indyk, Cameron Musco, Tal Wagner</p></summary>
<p>

**Abstract:** We study fast algorithms for computing fundamental properties of a positive semidefinite kernel matrix $K \in \mathbb{R}^{n \times n}$ corresponding to $n$ points $x_1,\ldots,x_n \in \mathbb{R}^d$. In particular, we consider estimating the sum of kernel matrix entries, along with its top eigenvalue and eigenvector.
  We show that the sum of matrix entries can be estimated to $1+ε$ relative error in time $sublinear$ in $n$ and linear in $d$ for many popular kernels, including the Gaussian, exponential, and rational quadratic kernels. For these kernels, we also show that the top eigenvalue (and an approximate eigenvector) can be approximated to $1+ε$ relative error in time $subquadratic$ in $n$ and linear in $d$.
  Our algorithms represent significant advances in the best known runtimes for these problems. They leverage the positive definiteness of the kernel matrix, along with a recent line of work on efficient kernel density estimation.

</p>
</details>

<details><summary><b>Tighter Bounds on the Log Marginal Likelihood of Gaussian Process Regression Using Conjugate Gradients</b>
<a href="https://arxiv.org/abs/2102.08314">arxiv:2102.08314</a>
&#x1F4C8; 5 <br>
<p>Artem Artemev, David R. Burt, Mark van der Wilk</p></summary>
<p>

**Abstract:** We propose a lower bound on the log marginal likelihood of Gaussian process regression models that can be computed without matrix factorisation of the full kernel matrix. We show that approximate maximum likelihood learning of model parameters by maximising our lower bound retains many of the sparse variational approach benefits while reducing the bias introduced into parameter learning. The basis of our bound is a more careful analysis of the log-determinant term appearing in the log marginal likelihood, as well as using the method of conjugate gradients to derive tight lower bounds on the term involving a quadratic form. Our approach is a step forward in unifying methods relying on lower bound maximisation (e.g. variational methods) and iterative approaches based on conjugate gradients for training Gaussian processes. In experiments, we show improved predictive performance with our model for a comparable amount of training time compared to other conjugate gradient based approaches.

</p>
</details>

<details><summary><b>Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation</b>
<a href="https://arxiv.org/abs/2102.08310">arxiv:2102.08310</a>
&#x1F4C8; 5 <br>
<p>Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane, Alexandros Iosifidis</p></summary>
<p>

**Abstract:** Data augmentation methods have been shown to be a fundamental technique to improve generalization in tasks such as image, text and audio classification. Recently, automated augmentation methods have led to further improvements on image classification and object detection leading to state-of-the-art performances. Nevertheless, little work has been done on time-series data, an area that could greatly benefit from automated data augmentation given the usually limited size of the datasets. We present two sample-adaptive automatic weighting schemes for data augmentation: the first learns to weight the contribution of the augmented samples to the loss, and the second method selects a subset of transformations based on the ranking of the predicted training loss. We validate our proposed methods on a large, noisy financial dataset and on time-series datasets from the UCR archive. On the financial dataset, we show that the methods in combination with a trading strategy lead to improvements in annualized returns of over 50$\%$, and on the time-series data we outperform state-of-the-art models on over half of the datasets, and achieve similar performance in accuracy on the others.

</p>
</details>

<details><summary><b>A Federated Data-Driven Evolutionary Algorithm</b>
<a href="https://arxiv.org/abs/2102.08288">arxiv:2102.08288</a>
&#x1F4C8; 5 <br>
<p>Jinjin Xu, Yaochu Jin, Wenli Du, Sai Gu</p></summary>
<p>

**Abstract:** Data-driven evolutionary optimization has witnessed great success in solving complex real-world optimization problems. However, existing data-driven optimization algorithms require that all data are centrally stored, which is not always practical and may be vulnerable to privacy leakage and security threats if the data must be collected from different devices. To address the above issue, this paper proposes a federated data-driven evolutionary optimization framework that is able to perform data driven optimization when the data is distributed on multiple devices. On the basis of federated learning, a sorted model aggregation method is developed for aggregating local surrogates based on radial-basis-function networks. In addition, a federated surrogate management strategy is suggested by designing an acquisition function that takes into account the information of both the global and local surrogate models. Empirical studies on a set of widely used benchmark functions in the presence of various data distributions demonstrate the effectiveness of the proposed framework.

</p>
</details>

<details><summary><b>An Effort to Measure Customer Relationship Performance in Indonesia's Fintech Industry</b>
<a href="https://arxiv.org/abs/2102.08262">arxiv:2102.08262</a>
&#x1F4C8; 5 <br>
<p>Alisya Putri Rabbani, Andry Alamsyah, Sri Widiyanesti</p></summary>
<p>

**Abstract:** The availability of social media simplifies the companies-customers relationship. An effort to engage customers in conversation networks using social media is called Social Customer Relationship Management (SCRM). Social Network Analysis helps to understand network characteristics and how active the conversation network on social media. Calculating its network properties is beneficial for measuring customer relationship performance. Financial Technology, a new emerging industry that provides digital-based financial services utilize social media to interact with its customers. Measuring SCRM performance is needed in order to stay competitive among others. Therefore, we aim to explore the SCRM performance of the Indonesia Fintech company. In terms of discovering the market majority thought in conversation networks, we perform sentiment analysis by classifying into positive and negative opinion. As case studies, we investigate Twitter conversations about GoPay, OVO, Dana, and LinkAja during the observation period from 1st October until 1st November 2019. The result of this research is beneficial for business intelligence purposes especially in managing relationships with customers.

</p>
</details>

<details><summary><b>Improving Deep-learning-based Semi-supervised Audio Tagging with Mixup</b>
<a href="https://arxiv.org/abs/2102.08183">arxiv:2102.08183</a>
&#x1F4C8; 5 <br>
<p>Léo Cances, Etienne Labbé, Thomas Pellegrini</p></summary>
<p>

**Abstract:** Recently, semi-supervised learning (SSL) methods, in the framework of deep learning (DL), have been shown to provide state-of-the-art results on image datasets by exploiting unlabeled data. Most of the time tested on object recognition tasks in images, these algorithms are rarely compared when applied to audio tasks. In this article, we adapted four recent SSL methods to the task of audio tagging. The first two methods, namely Deep Co-Training (DCT) and Mean Teacher (MT) involve two collaborative neural networks. The two other algorithms, called MixMatch (MM) and FixMatch (FM), are single-model methods that rely primarily on data augmentation strategies. Using the Wide ResNet 28-2 architecture in all our experiments, 10% of labeled data and the remaining 90\% as unlabeled, we first compare the four methods' accuracy on three standard benchmark audio event datasets: Environmental Sound Classification (ESC-10), UrbanSound8K (UBS8K), and Google Speech Commands (GSC). MM and FM outperformed MT and DCT significantly, MM being the best method in most experiments. On UBS8K and GSC, in particular, MM achieved 18.02% and 3.25% error rates (ER), outperforming models trained with 100% of the available labeled data, which reached 23.29% and 4.94% ER, respectively. Second, we explored the benefits of using the mixup augmentation in the four algorithms. In almost all cases, mixup brought significant gains. For instance, on GSC, FM reached 4.44% and 3.31% ER without and with mixup.

</p>
</details>

<details><summary><b>Spatio-Temporal Multi-step Prediction of Influenza Outbreaks</b>
<a href="https://arxiv.org/abs/2102.08137">arxiv:2102.08137</a>
&#x1F4C8; 5 <br>
<p>Jie Zhang, Kazumitsu Nawata, Hongyan Wu</p></summary>
<p>

**Abstract:** Flu circulates all over the world. The worldwide infection places a substantial burden on people's health every year. Regardless of the characteristic of the worldwide circulation of flu, most previous studies focused on regional prediction of flu outbreaks. The methodology of considering the spatio-temporal correlation could help forecast flu outbreaks more precisely. Furthermore, forecasting a long-term flu outbreak, and understanding flu infection trends more accurately could help hospitals, clinics, and pharmaceutical companies to better prepare for annual flu outbreaks. Predicting a sequence of values in the future, namely, the multi-step prediction of flu outbreaks should cause concern. Therefore, we highlight the importance of developing spatio-temporal methodologies to perform multi-step prediction of worldwide flu outbreaks. We compared the MAPEs of SVM, RF, LSTM models of predicting flu data of the 1-4 weeks ahead with and without other countries' flu data. We found the LSTM models achieved the lowest MAPEs in most cases. As for countries in the Southern hemisphere, the MAPEs of predicting flu data with other countries are higher than those of predicting without other countries. For countries in the Northern hemisphere, the MAPEs of predicting flu data of the 2-4 weeks ahead with other countries are lower than those of predicting without other countries; and the MAPEs of predicting flu data of the 1-weeks ahead with other countries are higher than those of predicting without other countries, except for the UK. In this study, we performed the spatio-temporal multi-step prediction of influenza outbreaks. The methodology considering the spatio-temporal features improves the multi-step prediction of flu outbreaks.

</p>
</details>

<details><summary><b>Supervised Training of Dense Object Nets using Optimal Descriptors for Industrial Robotic Applications</b>
<a href="https://arxiv.org/abs/2102.08096">arxiv:2102.08096</a>
&#x1F4C8; 5 <br>
<p>Andras Kupcsik, Markus Spies, Alexander Klein, Marco Todescato, Nicolai Waniek, Philipp Schillinger, Mathias Buerger</p></summary>
<p>

**Abstract:** Dense Object Nets (DONs) by Florence, Manuelli and Tedrake (2018) introduced dense object descriptors as a novel visual object representation for the robotics community. It is suitable for many applications including object grasping, policy learning, etc. DONs map an RGB image depicting an object into a descriptor space image, which implicitly encodes key features of an object invariant to the relative camera pose. Impressively, the self-supervised training of DONs can be applied to arbitrary objects and can be evaluated and deployed within hours. However, the training approach relies on accurate depth images and faces challenges with small, reflective objects, typical for industrial settings, when using consumer grade depth cameras. In this paper we show that given a 3D model of an object, we can generate its descriptor space image, which allows for supervised training of DONs. We rely on Laplacian Eigenmaps (LE) to embed the 3D model of an object into an optimally generated space. While our approach uses more domain knowledge, it can be efficiently applied even for smaller and reflective objects, as it does not rely on depth information. We compare the training methods on generating 6D grasps for industrial objects and show that our novel supervised training approach improves the pick-and-place performance in industry-relevant tasks.

</p>
</details>

<details><summary><b>A Law of Robustness for Weight-bounded Neural Networks</b>
<a href="https://arxiv.org/abs/2102.08093">arxiv:2102.08093</a>
&#x1F4C8; 5 <br>
<p>Hisham Husain, Borja Balle</p></summary>
<p>

**Abstract:** Robustness of deep neural networks against adversarial perturbations is a pressing concern motivated by recent findings showing the pervasive nature of such vulnerabilities. One method of characterizing the robustness of a neural network model is through its Lipschitz constant, which forms a robustness certificate. A natural question to ask is, for a fixed model class (such as neural networks) and a dataset of size $n$, what is the smallest achievable Lipschitz constant among all models that fit the dataset? Recently, (Bubeck et al., 2020) conjectured that when using two-layer networks with $k$ neurons to fit a generic dataset, the smallest Lipschitz constant is $Ω(\sqrt{\frac{n}{k}})$. This implies that one would require one neuron per data point to robustly fit the data. In this work we derive a lower bound on the Lipschitz constant for any arbitrary model class with bounded Rademacher complexity. Our result coincides with that conjectured in (Bubeck et al., 2020) for two-layer networks under the assumption of bounded weights. However, due to our result's generality, we also derive bounds for multi-layer neural networks, discovering that one requires $\log n$ constant-sized layers to robustly fit the data. Thus, our work establishes a law of robustness for weight bounded neural networks and provides formal evidence on the necessity of over-parametrization in deep learning.

</p>
</details>

<details><summary><b>A Benchmark of Ocular Disease Intelligent Recognition: One Shot for Multi-disease Detection</b>
<a href="https://arxiv.org/abs/2102.07978">arxiv:2102.07978</a>
&#x1F4C8; 5 <br>
<p>Ning Li, Tao Li, Chunyu Hu, Kai Wang, Hong Kang</p></summary>
<p>

**Abstract:** In ophthalmology, early fundus screening is an economic and effective way to prevent blindness caused by ophthalmic diseases. Clinically, due to the lack of medical resources, manual diagnosis is time-consuming and may delay the condition. With the development of deep learning, some researches on ophthalmic diseases have achieved good results, however, most of them are just based on one disease. During fundus screening, ophthalmologists usually give diagnoses of multi-disease on binocular fundus image, so we release a dataset with 8 diseases to meet the real medical scene, which contains 10,000 fundus images from both eyes of 5,000 patients. We did some benchmark experiments on it through some state-of-the-art deep neural networks. We found simply increasing the scale of network cannot bring good results for multi-disease classification, and a well-structured feature fusion method combines characteristics of multi-disease is needed. Through this work, we hope to advance the research of related fields.

</p>
</details>

<details><summary><b>Follow-the-Regularized-Leader Routes to Chaos in Routing Games</b>
<a href="https://arxiv.org/abs/2102.07974">arxiv:2102.07974</a>
&#x1F4C8; 5 <br>
<p>Jakub Bielawski, Thiparat Chotibut, Fryderyk Falniowski, Grzegorz Kosiorowski, Michał Misiurewicz, Georgios Piliouras</p></summary>
<p>

**Abstract:** We study the emergence of chaotic behavior of Follow-the-Regularized Leader (FoReL) dynamics in games. We focus on the effects of increasing the population size or the scale of costs in congestion games, and generalize recent results on unstable, chaotic behaviors in the Multiplicative Weights Update dynamics to a much larger class of FoReL dynamics. We establish that, even in simple linear non-atomic congestion games with two parallel links and any fixed learning rate, unless the game is fully symmetric, increasing the population size or the scale of costs causes learning dynamics to become unstable and eventually chaotic, in the sense of Li-Yorke and positive topological entropy. Furthermore, we show the existence of novel non-standard phenomena such as the coexistence of stable Nash equilibria and chaos in the same game. We also observe the simultaneous creation of a chaotic attractor as another chaotic attractor gets destroyed. Lastly, although FoReL dynamics can be strange and non-equilibrating, we prove that the time average still converges to an exact equilibrium for any choice of learning rate and any scale of costs.

</p>
</details>

<details><summary><b>Evaluating Fairness of Machine Learning Models Under Uncertain and Incomplete Information</b>
<a href="https://arxiv.org/abs/2102.08410">arxiv:2102.08410</a>
&#x1F4C8; 4 <br>
<p>Pranjal Awasthi, Alex Beutel, Matthaeus Kleindessner, Jamie Morgenstern, Xuezhi Wang</p></summary>
<p>

**Abstract:** Training and evaluation of fair classifiers is a challenging problem. This is partly due to the fact that most fairness metrics of interest depend on both the sensitive attribute information and label information of the data points. In many scenarios it is not possible to collect large datasets with such information. An alternate approach that is commonly used is to separately train an attribute classifier on data with sensitive attribute information, and then use it later in the ML pipeline to evaluate the bias of a given classifier. While such decoupling helps alleviate the problem of demographic scarcity, it raises several natural questions such as: how should the attribute classifier be trained?, and how should one use a given attribute classifier for accurate bias estimation? In this work we study this question from both theoretical and empirical perspectives.
  We first experimentally demonstrate that the test accuracy of the attribute classifier is not always correlated with its effectiveness in bias estimation for a downstream model. In order to further investigate this phenomenon, we analyze an idealized theoretical model and characterize the structure of the optimal classifier. Our analysis has surprising and counter-intuitive implications where in certain regimes one might want to distribute the error of the attribute classifier as unevenly as possible among the different subgroups. Based on our analysis we develop heuristics for both training and using attribute classifiers for bias estimation in the data scarce regime. We empirically demonstrate the effectiveness of our approach on real and simulated data.

</p>
</details>

<details><summary><b>Learning Symbolic Expressions: Mixed-Integer Formulations, Cuts, and Heuristics</b>
<a href="https://arxiv.org/abs/2102.08351">arxiv:2102.08351</a>
&#x1F4C8; 4 <br>
<p>Jongeun Kim, Sven Leyffer, Prasanna Balaprakash</p></summary>
<p>

**Abstract:** In this paper we consider the problem of learning a regression function without assuming its functional form. This problem is referred to as symbolic regression. An expression tree is typically used to represent a solution function, which is determined by assigning operators and operands to the nodes. The symbolic regression problem can be formulated as a nonconvex mixed-integer nonlinear program (MINLP), where binary variables are used to assign operators and nonlinear expressions are used to propagate data values through nonlinear operators such as square, square root, and exponential. We extend this formulation by adding new cuts that improve the solution of this challenging MINLP. We also propose a heuristic that iteratively builds an expression tree by solving a restricted MINLP. We perform computational experiments and compare our approach with a mixed-integer program-based method and a neural-network-based method from the literature.

</p>
</details>

<details><summary><b>Submodular Maximization subject to a Knapsack Constraint: Combinatorial Algorithms with Near-optimal Adaptive Complexity</b>
<a href="https://arxiv.org/abs/2102.08327">arxiv:2102.08327</a>
&#x1F4C8; 4 <br>
<p>Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, Alberto Marchetti Spaccamela, Rebecca Reiffenhäuser</p></summary>
<p>

**Abstract:** The growing need to deal with massive instances motivates the design of algorithms balancing the quality of the solution with applicability. For the latter, an important measure is the \emph{adaptive complexity}, capturing the number of sequential rounds of parallel computation needed. In this work we obtain the first \emph{constant factor} approximation algorithm for non-monotone submodular maximization subject to a knapsack constraint with \emph{near-optimal} $O(\log n)$ adaptive complexity. Low adaptivity by itself, however, is not enough: one needs to account for the total number of function evaluations (or value queries) as well. Our algorithm asks $\tilde{O}(n^2)$ value queries, but can be modified to run with only $\tilde{O}(n)$ instead, while retaining a low adaptive complexity of $O(\log^2n)$. Besides the above improvement in adaptivity, this is also the first \emph{combinatorial} approach with sublinear adaptive complexity for the problem and yields algorithms comparable to the state-of-the-art even for the special cases of cardinality constraints or monotone objectives. Finally, we showcase our algorithms' applicability on real-world datasets.

</p>
</details>

<details><summary><b>Evaluating Node Embeddings of Complex Networks</b>
<a href="https://arxiv.org/abs/2102.08275">arxiv:2102.08275</a>
&#x1F4C8; 4 <br>
<p>Arash Dehghan-Kooshkghazi, Bogumił Kamiński, Łukasz Kraiński, Paweł Prałat, François Théberge</p></summary>
<p>

**Abstract:** Graph embedding is a transformation of nodes of a graph into a set of vectors. A~good embedding should capture the graph topology, node-to-node relationship, and other relevant information about the graph, its subgraphs, and nodes. If these objectives are achieved, an embedding is a meaningful, understandable, compressed representations of a network that can be used for other machine learning tools such as node classification, community detection, or link prediction. The main challenge is that one needs to make sure that embeddings describe the properties of the graphs well. As a result, selecting the best embedding is a challenging task and very often requires domain experts. In this paper, we do a series of extensive experiments with selected graph embedding algorithms, both on real-world networks as well as artificially generated ones. Based on those experiments we formulate two general conclusions. First, if one needs to pick one embedding algorithm before running the experiments, then node2vec is the best choice as it performed best in our tests. Having said that, there is no single winner in all tests and, additionally, most embedding algorithms have hyperparameters that should be tuned and are randomized. Therefore, our main recommendation for practitioners is, if possible, to generate several embeddings for a problem at hand and then use a general framework that provides a tool for an unsupervised graph embedding comparison. This framework (introduced recently in the literature and easily available on GitHub repository) assigns the divergence score to embeddings to help distinguish good ones from bad ones.

</p>
</details>

<details><summary><b>Chickenpox Cases in Hungary: a Benchmark Dataset for Spatiotemporal Signal Processing with Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2102.08100">arxiv:2102.08100</a>
&#x1F4C8; 4 <br>
<p>Benedek Rozemberczki, Paul Scherer, Oliver Kiss, Rik Sarkar, Tamas Ferenci</p></summary>
<p>

**Abstract:** Recurrent graph convolutional neural networks are highly effective machine learning techniques for spatiotemporal signal processing. Newly proposed graph neural network architectures are repetitively evaluated on standard tasks such as traffic or weather forecasting. In this paper, we propose the Chickenpox Cases in Hungary dataset as a new dataset for comparing graph neural network architectures. Our time series analysis and forecasting experiments demonstrate that the Chickenpox Cases in Hungary dataset is adequate for comparing the predictive performance and forecasting capabilities of novel recurrent graph neural network architectures.

</p>
</details>

<details><summary><b>A Thorough View of Exact Inference in Graphs from the Degree-4 Sum-of-Squares Hierarchy</b>
<a href="https://arxiv.org/abs/2102.08019">arxiv:2102.08019</a>
&#x1F4C8; 4 <br>
<p>Kevin Bello, Chuyang Ke, Jean Honorio</p></summary>
<p>

**Abstract:** Performing inference in graphs is a common task within several machine learning problems, e.g., image segmentation, community detection, among others. For a given undirected connected graph, we tackle the statistical problem of exactly recovering an unknown ground-truth binary labeling of the nodes from a single corrupted observation of each edge. Such problem can be formulated as a quadratic combinatorial optimization problem over the boolean hypercube, where it has been shown before that one can (with high probability and in polynomial time) exactly recover the ground-truth labeling of graphs that have an isoperimetric number that grows with respect to the number of nodes (e.g., complete graphs, regular expanders). In this work, we apply a powerful hierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the combinatorial problem. Motivated by empirical evidence on the improvement in exact recoverability, we center our attention on the degree-4 SoS relaxation and set out to understand the origin of such improvement from a graph theoretical perspective. We show that the solution of the dual of the relaxed problem is related to finding edge weights of the Johnson and Kneser graphs, where the weights fulfill the SoS constraints and intuitively allow the input graph to increase its algebraic connectivity. Finally, as byproduct of our analysis, we derive a novel Cheeger-type lower bound for the algebraic connectivity of graphs with signed edge weights.

</p>
</details>

<details><summary><b>Enhancing Hierarchical Information by Using Metric Cones for Graph Embedding</b>
<a href="https://arxiv.org/abs/2102.08014">arxiv:2102.08014</a>
&#x1F4C8; 4 <br>
<p>Daisuke Takehara, Kei Kobayashi</p></summary>
<p>

**Abstract:** Graph embedding is becoming an important method with applications in various areas, including social networks and knowledge graph completion. In particular, Poincaré embedding has been proposed to capture the hierarchical structure of graphs, and its effectiveness has been reported. However, most of the existing methods have isometric mappings in the embedding space, and the choice of the origin point can be arbitrary. This fact is not desirable when the distance from the origin is used as an indicator of hierarchy, as in the case of Poincaré embedding. In this paper, we propose graph embedding in a metric cone to solve such a problem, and we gain further benefits: 1) we provide an indicator of hierarchical information that is both geometrically and intuitively natural to interpret, 2) we can extract the hierarchical structure from a graph embedding output of other methods by learning additional one-dimensional parameters, and 3) we can change the curvature of the embedding space via a hyperparameter.

</p>
</details>

<details><summary><b>D2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis</b>
<a href="https://arxiv.org/abs/2102.07995">arxiv:2102.07995</a>
&#x1F4C8; 4 <br>
<p>Yunhui Zheng, Saurabh Pujar, Burn Lewis, Luca Buratti, Edward Epstein, Bo Yang, Jim Laredo, Alessandro Morari, Zhong Su</p></summary>
<p>

**Abstract:** Static analysis tools are widely used for vulnerability detection as they understand programs with complex behavior and millions of lines of code. Despite their popularity, static analysis tools are known to generate an excess of false positives. The recent ability of Machine Learning models to understand programming languages opens new possibilities when applied to static analysis. However, existing datasets to train models for vulnerability identification suffer from multiple limitations such as limited bug context, limited size, and synthetic and unrealistic source code. We propose D2A, a differential analysis based approach to label issues reported by static analysis tools. The D2A dataset is built by analyzing version pairs from multiple open source projects. From each project, we select bug fixing commits and we run static analysis on the versions before and after such commits. If some issues detected in a before-commit version disappear in the corresponding after-commit version, they are very likely to be real bugs that got fixed by the commit. We use D2A to generate a large labeled dataset to train models for vulnerability identification. We show that the dataset can be used to build a classifier to identify possible false alarms among the issues reported by static analysis, hence helping developers prioritize and investigate potential true positives first.

</p>
</details>

<details><summary><b>Jointly Learning Clinical Entities and Relations with Contextual Language Models and Explicit Context</b>
<a href="https://arxiv.org/abs/2102.11031">arxiv:2102.11031</a>
&#x1F4C8; 3 <br>
<p>Paul Barry, Sam Henry, Meliha Yetisgen, Bridget McInnes, Ozlem Uzuner</p></summary>
<p>

**Abstract:** We hypothesize that explicit integration of contextual information into an Multi-task Learning framework would emphasize the significance of context for boosting performance in jointly learning Named Entity Recognition (NER) and Relation Extraction (RE). Our work proves this hypothesis by segmenting entities from their surrounding context and by building contextual representations using each independent segment. This relation representation allows for a joint NER/RE system that achieves near state-of-the-art (SOTA) performance on both NER and RE tasks while beating the SOTA RE system at end-to-end NER & RE with a 49.07 F1.

</p>
</details>

<details><summary><b>Evaluating Multi-label Classifiers with Noisy Labels</b>
<a href="https://arxiv.org/abs/2102.08427">arxiv:2102.08427</a>
&#x1F4C8; 3 <br>
<p>Wenting Zhao, Carla Gomes</p></summary>
<p>

**Abstract:** Multi-label classification (MLC) is a generalization of standard classification where multiple labels may be assigned to a given sample. In the real world, it is more common to deal with noisy datasets than clean datasets, given how modern datasets are labeled by a large group of annotators on crowdsourcing platforms, but little attention has been given to evaluating multi-label classifiers with noisy labels. Exploiting label correlations now becomes a standard component of a multi-label classifier to achieve competitive performance. However, this component makes the classifier more prone to poor generalization - it overfits labels as well as label dependencies. We identify three common real-world label noise scenarios and show how previous approaches per-form poorly with noisy labels. To address this issue, we present a Context-Based Multi-LabelClassifier (CbMLC) that effectively handles noisy labels when learning label dependencies, without requiring additional supervision. We compare CbMLC against other domain-specific state-of-the-art models on a variety of datasets, under both the clean and the noisy settings. We show CbMLC yields substantial improvements over the previous methods in most cases.

</p>
</details>

<details><summary><b>Analysis of feature learning in weight-tied autoencoders via the mean field lens</b>
<a href="https://arxiv.org/abs/2102.08373">arxiv:2102.08373</a>
&#x1F4C8; 3 <br>
<p>Phan-Minh Nguyen</p></summary>
<p>

**Abstract:** Autoencoders are among the earliest introduced nonlinear models for unsupervised learning. Although they are widely adopted beyond research, it has been a longstanding open problem to understand mathematically the feature extraction mechanism that trained nonlinear autoencoders provide.
  In this work, we make progress in this problem by analyzing a class of two-layer weight-tied nonlinear autoencoders in the mean field framework. Upon a suitable scaling, in the regime of a large number of neurons, the models trained with stochastic gradient descent are shown to admit a mean field limiting dynamics. This limiting description reveals an asymptotically precise picture of feature learning by these models: their training dynamics exhibit different phases that correspond to the learning of different principal subspaces of the data, with varying degrees of nonlinear shrinkage dependent on the $\ell_{2}$-regularization and stopping time. While we prove these results under an idealized assumption of (correlated) Gaussian data, experiments on real-life data demonstrate an interesting match with the theory.
  The autoencoder setup of interests poses a nontrivial mathematical challenge to proving these results. In this setup, the "Lipschitz" constants of the models grow with the data dimension $d$. Consequently an adaptation of previous analyses requires a number of neurons $N$ that is at least exponential in $d$. Our main technical contribution is a new argument which proves that the required $N$ is only polynomial in $d$. We conjecture that $N\gg d$ is sufficient and that $N$ is necessarily larger than a data-dependent intrinsic dimension, a behavior that is fundamentally different from previously studied setups.

</p>
</details>

<details><summary><b>Stochastic Variance Reduction for Variational Inequality Methods</b>
<a href="https://arxiv.org/abs/2102.08352">arxiv:2102.08352</a>
&#x1F4C8; 3 <br>
<p>Ahmet Alacaoglu, Yura Malitsky</p></summary>
<p>

**Abstract:** We propose stochastic variance reduced algorithms for solving convex-concave saddle point problems, monotone variational inequalities, and monotone inclusions. Our framework applies to extragradient, forward-backward-forward, and forward-reflected-backward methods both in Euclidean and Bregman setups. All proposed methods converge in exactly the same setting as their deterministic counterparts and they either match or improve the best-known complexities for solving structured min-max problems. Our results reinforce the correspondence between variance reduction in variational inequalities and minimization. We also illustrate the improvements of our approach with numerical evaluations on matrix games.

</p>
</details>

<details><summary><b>On Mathews Correlation Coefficient and Improved Distance Map Loss for Automatic Glacier Calving Front Segmentation in SAR Imagery</b>
<a href="https://arxiv.org/abs/2102.08312">arxiv:2102.08312</a>
&#x1F4C8; 3 <br>
<p>Amirabbas Davari, Saahil Islam, Thorsten Seehaus, Matthias Braun, Andreas Maier, Vincent Christlein</p></summary>
<p>

**Abstract:** The vast majority of the outlet glaciers and ice streams of the polar ice sheets end in the ocean. Ice mass loss via calving of the glaciers into the ocean has increased over the last few decades. Information on the temporal variability of the calving front position provides fundamental information on the state of the glacier and ice stream, which can be exploited as calibration and validation data to enhance ice dynamics modeling. To identify the calving front position automatically, deep neural network-based semantic segmentation pipelines can be used to delineate the acquired SAR imagery. However, the extreme class imbalance is highly challenging for the accurate calving front segmentation in these images. Therefore, we propose the use of the Mathews correlation coefficient (MCC) as an early stopping criterion because of its symmetrical properties and its invariance towards class imbalance. Moreover, we propose an improvement to the distance map-based binary cross-entropy (BCE) loss function. The distance map adds context to the loss function about the important regions for segmentation and helps accounting for the imbalanced data. Using Mathews correlation coefficient as early stopping demonstrates an average 15% dice coefficient improvement compared to the commonly used BCE. The modified distance map loss further improves the segmentation performance by another 2%. These results are encouraging as they support the effectiveness of the proposed methods for segmentation problems suffering from extreme class imbalances.

</p>
</details>

<details><summary><b>Joint self-supervised blind denoising and noise estimation</b>
<a href="https://arxiv.org/abs/2102.08023">arxiv:2102.08023</a>
&#x1F4C8; 3 <br>
<p>Jean Ollion, Charles Ollion, Elisabeth Gassiat, Luc Lehéricy, Sylvain Le Corff</p></summary>
<p>

**Abstract:** We propose a novel self-supervised image blind denoising approach in which two neural networks jointly predict the clean signal and infer the noise distribution. Assuming that the noisy observations are independent conditionally to the signal, the networks can be jointly trained without clean training data. Therefore, our approach is particularly relevant for biomedical image denoising where the noise is difficult to model precisely and clean training data are usually unavailable. Our method significantly outperforms current state-of-the-art self-supervised blind denoising algorithms, on six publicly available biomedical image datasets. We also show empirically with synthetic noisy data that our model captures the noise distribution efficiently. Finally, the described framework is simple, lightweight and computationally efficient, making it useful in practical cases.

</p>
</details>

<details><summary><b>Uncertainty-based method for improving poorly labeled segmentation datasets</b>
<a href="https://arxiv.org/abs/2102.08021">arxiv:2102.08021</a>
&#x1F4C8; 3 <br>
<p>Ekaterina Redekop, Alexey Chernyavskiy</p></summary>
<p>

**Abstract:** The success of modern deep learning algorithms for image segmentation heavily depends on the availability of large datasets with clean pixel-level annotations (masks), where the objects of interest are accurately delineated. Lack of time and expertise during data annotation leads to incorrect boundaries and label noise. It is known that deep convolutional neural networks (DCNNs) can memorize even completely random labels, resulting in poor accuracy. We propose a framework to train binary segmentation DCNNs using sets of unreliable pixel-level annotations. Erroneously labeled pixels are identified based on the estimated aleatoric uncertainty of the segmentation and are relabeled to the true value.

</p>
</details>

<details><summary><b>New Methods for Detecting Concentric Objects With High Accuracy</b>
<a href="https://arxiv.org/abs/2103.05104">arxiv:2103.05104</a>
&#x1F4C8; 2 <br>
<p>Ali A. Al-Sharadqah, Lorenzo Rull</p></summary>
<p>

**Abstract:** Fitting concentric geometric objects to digitized data is an important problem in many areas such as iris detection, autonomous navigation, and industrial robotics operations. There are two common approaches to fitting geometric shapes to data: the geometric (iterative) approach and algebraic (non-iterative) approach. The geometric approach is a nonlinear iterative method that minimizes the sum of the squares of Euclidean distances of the observed points to the ellipses and regarded as the most accurate method, but it needs a good initial guess to improve the convergence rate. The algebraic approach is based on minimizing the algebraic distances with some constraints imposed on parametric space. Each algebraic method depends on the imposed constraint, and it can be solved with the aid of the generalized eigenvalue problem. Only a few methods in literature were developed to solve the problem of concentric ellipses. Here we study the statistical properties of existing methods by firstly establishing a general mathematical and statistical framework for this problem. Using rigorous perturbation analysis, we derive the variances and biasedness of each method under the small-sigma model. We also develop new estimators, which can be used as reliable initial guesses for other iterative methods. Then we compare the performance of each method according to their theoretical accuracy. Not only do our methods described here outperform other existing non-iterative methods, they are also quite robust against large noise. These methods and their practical performances are assessed by a series of numerical experiments on both synthetic and real data.

</p>
</details>

<details><summary><b>Investigating Underlying Drivers of Variability in Residential Energy Usage Patterns with Daily Load Shape Clustering of Smart Meter Data</b>
<a href="https://arxiv.org/abs/2102.11027">arxiv:2102.11027</a>
&#x1F4C8; 2 <br>
<p>Ling Jin, C. Anna Spurlock, Sam Borgeson, Alina Lazar, Daniel Fredman, Annika Todd, Alexander Sim, Kesheng Wu</p></summary>
<p>

**Abstract:** Residential customers have traditionally not been treated as individual entities due to the high volatility in residential consumption patterns as well as a historic focus on aggregated loads from the utility and system feeder perspective. Large-scale deployment of smart meters has motivated increasing studies to explore disaggregated daily load patterns, which can reveal important heterogeneity across different time scales, weather conditions, as well as within and across individual households. This paper aims to shed light on the mechanisms by which electricity consumption patterns exhibit variability and the different constraints that may affect demand-response (DR) flexibility. We systematically evaluate the relationship between daily time-of-use patterns and their variability to external and internal influencing factors, including time scales of interest, meteorological conditions, and household characteristics by application of an improved version of the adaptive K-means clustering method to profile "household-days" of a summer peaking utility. We find that for this summer-peaking utility, outdoor temperature is the most important external driver of the load shape variability relative to seasonality and day-of-week. The top three consumption patterns represent approximately 50% of usage on the highest temperature days. The variability in summer load shapes across customers can be explained by the responsiveness of the households to outside temperature. Our results suggest that depending on the influencing factors, not all the consumption variability can be readily translated to consumption flexibility. Such information needs to be further explored in segmenting customers for better program targeting and tailoring to meet the needs of the rapidly evolving electricity grid.

</p>
</details>

<details><summary><b>Self-Triggered Markov Decision Processes</b>
<a href="https://arxiv.org/abs/2102.08571">arxiv:2102.08571</a>
&#x1F4C8; 2 <br>
<p>Yunhan Huang, Quanyan Zhu</p></summary>
<p>

**Abstract:** In this paper, we study Markov Decision Processes (MDPs) with self-triggered strategies, where the idea of self-triggered control is extended to more generic MDP models. This extension broadens the application of self-triggering policies to a broader range of systems. We study the co-design problems of the control policy and the triggering policy to optimize two pre-specified cost criteria. The first cost criterion is introduced by incorporating a pre-specified update penalty into the traditional MDP cost criteria to reduce the use of communication resources. Under this criteria, a novel dynamic programming (DP) equation called DP equation with optimized lookahead to proposed to solve for the self-triggering policy under this criteria. The second self-triggering policy is to maximize the triggering time while still guaranteeing a pre-specified level of sub-optimality. Theoretical underpinnings are established for the computation and implementation of both policies. Through a gridworld numerical example, we illustrate the two policies' effectiveness in reducing sources consumption and demonstrate the trade-offs between resource consumption and system performance.

</p>
</details>

<details><summary><b>Contextual Skipgram: Training Word Representation Using Context Information</b>
<a href="https://arxiv.org/abs/2102.08565">arxiv:2102.08565</a>
&#x1F4C8; 2 <br>
<p>Dongjae Kim, Jong-Kook Kim</p></summary>
<p>

**Abstract:** The skip-gram (SG) model learns word representation by predicting the words surrounding a center word from unstructured text data. However, not all words in the context window contribute to the meaning of the center word. For example, less relevant words could be in the context window, hindering the SG model from learning a better quality representation. In this paper, we propose an enhanced version of the SG that leverages context information to produce word representation. The proposed model, Contextual Skip-gram, is designed to predict contextual words with both the center words and the context information. This simple idea helps to reduce the impact of irrelevant words on the training process, thus enhancing the final performance

</p>
</details>

<details><summary><b>Deep cross-modality (MR-CT) educed distillation learning for cone beam CT lung tumor segmentation</b>
<a href="https://arxiv.org/abs/2102.08556">arxiv:2102.08556</a>
&#x1F4C8; 2 <br>
<p>Jue Jiang, Sadegh Riyahi Alam, Ishita Chen, Perry Zhang, Andreas Rimner, Joseph O. Deasy, Harini Veeraraghavan</p></summary>
<p>

**Abstract:** Despite the widespread availability of in-treatment room cone beam computed tomography (CBCT) imaging, due to the lack of reliable segmentation methods, CBCT is only used for gross set up corrections in lung radiotherapies. Accurate and reliable auto-segmentation tools could potentiate volumetric response assessment and geometry-guided adaptive radiation therapies. Therefore, we developed a new deep learning CBCT lung tumor segmentation method. Methods: The key idea of our approach called cross modality educed distillation (CMEDL) is to use magnetic resonance imaging (MRI) to guide a CBCT segmentation network training to extract more informative features during training. We accomplish this by training an end-to-end network comprised of unpaired domain adaptation (UDA) and cross-domain segmentation distillation networks (SDN) using unpaired CBCT and MRI datasets. Feature distillation regularizes the student network to extract CBCT features that match the statistical distribution of MRI features extracted by the teacher network and obtain better differentiation of tumor from background.} We also compared against an alternative framework that used UDA with MR segmentation network, whereby segmentation was done on the synthesized pseudo MRI representation. All networks were trained with 216 weekly CBCTs and 82 T2-weighted turbo spin echo MRI acquired from different patient cohorts. Validation was done on 20 weekly CBCTs from patients not used in training. Independent testing was done on 38 weekly CBCTs from patients not used in training or validation. Segmentation accuracy was measured using surface Dice similarity coefficient (SDSC) and Hausdroff distance at 95th percentile (HD95) metrics.

</p>
</details>

<details><summary><b>Separated Proportional-Integral Lagrangian for Chance Constrained Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.08539">arxiv:2102.08539</a>
&#x1F4C8; 2 <br>
<p>Baiyu Peng, Yao Mu, Jingliang Duan, Yang Guan, Shengbo Eben Li, Jianyu Chen</p></summary>
<p>

**Abstract:** Safety is essential for reinforcement learning (RL) applied in real-world tasks like autonomous driving. Chance constraints which guarantee the satisfaction of state constraints at a high probability are suitable to represent the requirements in real-world environment with uncertainty. Existing chance constrained RL methods like the penalty method and the Lagrangian method either exhibit periodic oscillations or cannot satisfy the constraints. In this paper, we address these shortcomings by proposing a separated proportional-integral Lagrangian (SPIL) algorithm. Taking a control perspective, we first interpret the penalty method and the Lagrangian method as proportional feedback and integral feedback control, respectively. Then, a proportional-integral Lagrangian method is proposed to steady learning process while improving safety. To prevent integral overshooting and reduce conservatism, we introduce the integral separation technique inspired by PID control. Finally, an analytical gradient of the chance constraint is utilized for model-based policy optimization. The effectiveness of SPIL is demonstrated by a narrow car-following task. Experiments indicate that compared with previous methods, SPIL improves the performance while guaranteeing safety, with a steady learning process.

</p>
</details>

<details><summary><b>StatEcoNet: Statistical Ecology Neural Networks for Species Distribution Modeling</b>
<a href="https://arxiv.org/abs/2102.08534">arxiv:2102.08534</a>
&#x1F4C8; 2 <br>
<p>Eugene Seo, Rebecca A. Hutchinson, Xiao Fu, Chelsea Li, Tyler A. Hallman, John Kilbride, W. Douglas Robinson</p></summary>
<p>

**Abstract:** This paper focuses on a core task in computational sustainability and statistical ecology: species distribution modeling (SDM). In SDM, the occurrence pattern of a species on a landscape is predicted by environmental features based on observations at a set of locations. At first, SDM may appear to be a binary classification problem, and one might be inclined to employ classic tools (e.g., logistic regression, support vector machines, neural networks) to tackle it. However, wildlife surveys introduce structured noise (especially under-counting) in the species observations. If unaccounted for, these observation errors systematically bias SDMs. To address the unique challenges of SDM, this paper proposes a framework called StatEcoNet. Specifically, this work employs a graphical generative model in statistical ecology to serve as the skeleton of the proposed computational framework and carefully integrates neural networks under the framework. The advantages of StatEcoNet over related approaches are demonstrated on simulated datasets as well as bird species data. Since SDMs are critical tools for ecological science and natural resource management, StatEcoNet may offer boosted computational and analytical powers to a wide range of applications that have significant social impacts, e.g., the study and conservation of threatened species.

</p>
</details>

<details><summary><b>Causal Estimation with Functional Confounders</b>
<a href="https://arxiv.org/abs/2102.08533">arxiv:2102.08533</a>
&#x1F4C8; 2 <br>
<p>Aahlad Puli, Adler J. Perotte, Rajesh Ranganath</p></summary>
<p>

**Abstract:** Causal inference relies on two fundamental assumptions: ignorability and positivity. We study causal inference when the true confounder value can be expressed as a function of the observed data; we call this setting estimation with functional confounders (EFC). In this setting, ignorability is satisfied, however positivity is violated, and causal inference is impossible in general. We consider two scenarios where causal effects are estimable. First, we discuss interventions on a part of the treatment called functional interventions and a sufficient condition for effect estimation of these interventions called functional positivity. Second, we develop conditions for nonparametric effect estimation based on the gradient fields of the functional confounder and the true outcome function. To estimate effects under these conditions, we develop Level-set Orthogonal Descent Estimation (LODE). Further, we prove error bounds on LODE's effect estimates, evaluate our methods on simulated and real data, and empirically demonstrate the value of EFC.

</p>
</details>

<details><summary><b>Pattern Sampling for Shapelet-based Time Series Classification</b>
<a href="https://arxiv.org/abs/2102.08498">arxiv:2102.08498</a>
&#x1F4C8; 2 <br>
<p>Atif Raza, Stefan Kramer</p></summary>
<p>

**Abstract:** Subsequence-based time series classification algorithms provide accurate and interpretable models, but training these models is extremely computation intensive. The asymptotic time complexity of subsequence-based algorithms remains a higher-order polynomial, because these algorithms are based on exhaustive search for highly discriminative subsequences. Pattern sampling has been proposed as an effective alternative to mitigate the pattern explosion phenomenon. Therefore, we employ pattern sampling to extract discriminative features from discretized time series data. A weighted trie is created based on the discretized time series data to sample highly discriminative patterns. These sampled patterns are used to identify the shapelets which are used to transform the time series classification problem into a feature-based classification problem. Finally, a classification model can be trained using any off-the-shelf algorithm. Creating a pattern sampler requires a small number of patterns to be evaluated compared to an exhaustive search as employed by previous approaches. Compared to previously proposed algorithms, our approach requires considerably less computational and memory resources. Experiments demonstrate how the proposed approach fares in terms of classification accuracy and runtime performance.

</p>
</details>

<details><summary><b>Smoothed Analysis with Adaptive Adversaries</b>
<a href="https://arxiv.org/abs/2102.08446">arxiv:2102.08446</a>
&#x1F4C8; 2 <br>
<p>Nika Haghtalab, Tim Roughgarden, Abhishek Shetty</p></summary>
<p>

**Abstract:** We prove novel algorithmic guarantees for several online problems in the smoothed analysis model. In this model, at each time an adversary chooses an input distribution with density function bounded above by $\tfrac{1}σ$ times that of the uniform distribution; nature then samples an input from this distribution. Crucially, our results hold for {\em adaptive} adversaries that can choose an input distribution based on the decisions of the algorithm and the realizations of the inputs in the previous time steps.
  This paper presents a general technique for proving smoothed algorithmic guarantees against adaptive adversaries, in effect reducing the setting of adaptive adversaries to the simpler case of oblivious adversaries. We apply this technique to prove strong smoothed guarantees for three problems:
  -Online learning: We consider the online prediction problem, where instances are generated from an adaptive sequence of $σ$-smooth distributions and the hypothesis class has VC dimension $d$. We bound the regret by $\tilde{O}\big(\sqrt{T d\ln(1/σ)} + d\sqrt{\ln(T/σ)}\big)$. This answers open questions of [RST11,Hag18].
  -Online discrepancy minimization: We consider the online Komlós problem, where the input is generated from an adaptive sequence of $σ$-smooth and isotropic distributions on the $\ell_2$ unit ball. We bound the $\ell_\infty$ norm of the discrepancy vector by $\tilde{O}\big(\ln^2\!\big( \frac{nT}σ\big) \big)$.
  -Dispersion in online optimization: We consider online optimization of piecewise Lipschitz functions where functions with $\ell$ discontinuities are chosen by a smoothed adaptive adversary and show that the resulting sequence is $\big( σ/{\sqrt{T\ell}}, \tilde O\big(\sqrt{T\ell} \big)\big)$-dispersed. This matches the parameters of [BDV18] for oblivious adversaries, up to log factors.

</p>
</details>

<details><summary><b>A comparative study on movement feature in different directions for micro-expression recognition</b>
<a href="https://arxiv.org/abs/2102.08068">arxiv:2102.08068</a>
&#x1F4C8; 2 <br>
<p>Jinsheng Wei, Guanming Lu, Jingjie Yan</p></summary>
<p>

**Abstract:** Micro-expression can reflect people's real emotions. Recognizing micro-expressions is difficult because they are small motions and have a short duration. As the research is deepening into micro-expression recognition, many effective features and methods have been proposed. To determine which direction of movement feature is easier for distinguishing micro-expressions, this paper selects 18 directions (including three types of horizontal, vertical and oblique movements) and proposes a new low-dimensional feature called the Histogram of Single Direction Gradient (HSDG) to study this topic. In this paper, HSDG in every direction is concatenated with LBP-TOP to obtain the LBP with Single Direction Gradient (LBP-SDG) and analyze which direction of movement feature is more discriminative for micro-expression recognition. As with some existing work, Euler Video Magnification (EVM) is employed as a preprocessing step. The experiments on the CASME II and SMIC-HS databases summarize the effective and optimal directions and demonstrate that HSDG in an optimal direction is discriminative, and the corresponding LBP-SDG achieves state-of-the-art performance using EVM.

</p>
</details>

<details><summary><b>Temporal-Amount Snapshot MultiGraph for Ethereum Transaction Tracking</b>
<a href="https://arxiv.org/abs/2102.08013">arxiv:2102.08013</a>
&#x1F4C8; 2 <br>
<p>Yunyi Xie, Jie Jin, Jian Zhang, Shanqing Yu, Qi Xuan</p></summary>
<p>

**Abstract:** With the wide application of blockchain in the financial field, the rise of various types of cybercrimes has brought great challenges to the security of blockchain. In order to better understand this emerging market and explore more efficient countermeasures for effective supervision, it is imperative to track transactions on blockchain-based systems. Due to the openness of Ethereum, we can easily access the publicly available transaction records, model them as a complex network, and further study the problem of transaction tracking via link prediction, which provides a deeper understanding of Ethereum transactions from a network perspective. Specifically, we introduce an embedding based link prediction framework that is composed of temporal-amount snapshot multigraph (TASMG) and present temporal-amount walk (TAW). By taking the realistic rules and features of transaction networks into consideration, we propose TASMG to model Ethereum transaction records as a temporal-amount network and then present TAW to effectively embed accounts via their transaction records, which integrates temporal and amount information of the proposed network. Experimental results demonstrate the superiority of the proposed framework in learning more informative representations and could be an effective method for transaction tracking.

</p>
</details>

<details><summary><b>DAN-Net: Dual-Domain Adaptive-Scaling Non-local Network for CT Metal Artifact Reduction</b>
<a href="https://arxiv.org/abs/2102.08003">arxiv:2102.08003</a>
&#x1F4C8; 2 <br>
<p>Tao Wang, Wenjun Xia, Yongqiang Huang, Huaiqiang Sun, Yan Liu, Hu Chen, Jiliu Zhou, Yi Zhang</p></summary>
<p>

**Abstract:** Metal implants can heavily attenuate X-rays in computed tomography (CT) scans, leading to severe artifacts in reconstructed images, which significantly jeopardize image quality and negatively impact subsequent diagnoses and treatment planning. With the rapid development of deep learning in the field of medical imaging, several network models have been proposed for metal artifact reduction (MAR) in CT. Despite the encouraging results achieved by these methods, there is still much room to further improve performance. In this paper, a novel Dual-domain Adaptive-scaling Non-local network (DAN-Net) for MAR. We correct the corrupted sinogram using adaptive scaling first to preserve more tissue and bone details as a more informative input. Then, an end-to-end dual-domain network is adopted to successively process the sinogram and its corresponding reconstructed image generated by the analytical reconstruction layer. In addition, to better suppress the existing artifacts and restrain the potential secondary artifacts caused by inaccurate results of the sinogram-domain network, a novel residual sinogram learning strategy and nonlocal module are leveraged in the proposed network model. In the experiments, the proposed DAN-Net demonstrates performance competitive with several state-of-the-art MAR methods in both qualitative and quantitative aspects.

</p>
</details>

<details><summary><b>A Sub-band Approach to Deep Denoising Wavelet Networks and a Frequency-adaptive Loss for Perceptual Quality</b>
<a href="https://arxiv.org/abs/2102.07973">arxiv:2102.07973</a>
&#x1F4C8; 2 <br>
<p>Caglar Aytekin, Sakari Alenius, Dmytro Paliy, Juuso Gren</p></summary>
<p>

**Abstract:** In this paper, we propose two contributions to neural network based denoising. First, we propose applying separate convolutional layers to each sub-band of discrete wavelet transform (DWT) as opposed to the common usage of DWT which concatenates all sub-bands and applies a single convolution layer. We show that our approach to using DWT in neural networks improves the accuracy notably, due to keeping the sub-band order uncorrupted prior to inverse DWT. Our second contribution is a denoising loss based on top k-percent of errors in frequency domain. A neural network trained with this loss, adaptively focuses on frequencies that it fails to recover the most in each iteration. We show that this loss results into better perceptual quality by providing an image that is more balanced in terms of the errors in frequency components.

</p>
</details>

<details><summary><b>Preventing Unauthorized Use of Proprietary Data: Poisoning for Secure Dataset Release</b>
<a href="https://arxiv.org/abs/2103.02683">arxiv:2103.02683</a>
&#x1F4C8; 1 <br>
<p>Liam Fowl, Ping-yeh Chiang, Micah Goldblum, Jonas Geiping, Arpit Bansal, Wojtek Czaja, Tom Goldstein</p></summary>
<p>

**Abstract:** Large organizations such as social media companies continually release data, for example user images. At the same time, these organizations leverage their massive corpora of released data to train proprietary models that give them an edge over their competitors. These two behaviors can be in conflict as an organization wants to prevent competitors from using their own data to replicate the performance of their proprietary models. We solve this problem by developing a data poisoning method by which publicly released data can be minimally modified to prevent others from train-ing models on it. Moreover, our method can be used in an online fashion so that companies can protect their data in real time as they release it.We demonstrate the success of our approach onImageNet classification and on facial recognition.

</p>
</details>

<details><summary><b>Moral Decision-Making in Medical Hybrid Intelligent Systems: A Team Design Patterns Approach to the Bias Mitigation and Data Sharing Design Problems</b>
<a href="https://arxiv.org/abs/2102.11211">arxiv:2102.11211</a>
&#x1F4C8; 1 <br>
<p>Jip van Stijn</p></summary>
<p>

**Abstract:** Increasing automation in the healthcare sector calls for a Hybrid Intelligence (HI) approach to closely study and design the collaboration of humans and autonomous machines. Ensuring that medical HI systems' decision-making is ethical is key. The use of Team Design Patterns (TDPs) can advance this goal by describing successful and reusable configurations of design problems in which decisions have a moral component, as well as through facilitating communication in multidisciplinary teams designing HI systems. For this research, TDPs were developed to describe a set of solutions for two design problems in a medical HI system: (1) mitigating harmful biases in machine learning algorithms and (2) sharing health and behavioral patient data with healthcare professionals and system developers. The Socio-Cognitive Engineering methodology was employed, integrating operational demands, human factors knowledge, and a technological analysis into a set of TDPs. A survey was created to assess the usability of the patterns on their understandability, effectiveness, and generalizability. The results showed that TDPs are a useful method to unambiguously describe solutions for diverse HI design problems with a moral component on varying abstraction levels, that are usable by a heterogeneous group of multidisciplinary researchers. Additionally, results indicated that the SCE approach and the developed questionnaire are suitable methods for creating and assessing TDPs. The study concludes with a set of proposed improvements to TDPs, including their integration with Interaction Design Patterns, the inclusion of several additional concepts, and a number of methodological improvements. Finally, the thesis recommends directions for future research.

</p>
</details>

<details><summary><b>Predicting Material Properties Using a 3D Graph Neural Network with Invariant Local Descriptors</b>
<a href="https://arxiv.org/abs/2102.11023">arxiv:2102.11023</a>
&#x1F4C8; 1 <br>
<p>Boyu Zhang, Mushen Zhou, Jianzhong Wu, Fuchang Gao</p></summary>
<p>

**Abstract:** Accurate prediction of physical properties is critical for discovering and designing novel materials. Machine learning technologies have attracted significant attention in the materials science community for their potential for large-scale screening. Graph Convolution Neural Network (GCNN) is one of the most successful machine learning methods because of its flexibility and effectiveness in describing 3D structural data. Most existing GCNN models focus on the topological structure but overly simplify the three-dimensional geometric structure. However, in materials science, the 3D-spatial distribution of atoms is crucial for determining the atomic states and interatomic forces. This paper proposes an adaptive GCNN with a novel convolution mechanism that simultaneously models atomic interactions among all neighbor atoms in three-dimensional space. We apply the proposed model to two distinctly challenging problems on predicting material properties. The first is Henry's constant for gas adsorption in Metal-Organic Frameworks (MOFs), which is notoriously difficult because of its high sensitivity to atomic configurations. The second is the ion conductivity in solid-state crystal materials, which is difficult because of few labeled data available for training. The new model outperforms existing graph-based models on both data sets, suggesting that the critical three-dimensional geometric information is indeed captured.

</p>
</details>

<details><summary><b>Learning deep multiresolution representations for pansharpening</b>
<a href="https://arxiv.org/abs/2102.08423">arxiv:2102.08423</a>
&#x1F4C8; 1 <br>
<p>Hannan Adeel, Syed Sohaib Ali, Muhammad Mohsin Riaz, Syed Abdul Mannan Kirmani, Muhammad Imran Qureshi, Junaid Imtiaz</p></summary>
<p>

**Abstract:** Retaining spatial characteristics of panchromatic image and spectral information of multispectral bands is a critical issue in pansharpening. This paper proposes a pyramid based deep fusion framework that preserves spectral and spatial characteristics at different scales. The spectral information is preserved by passing the corresponding low resolution multispectral image as residual component of the network at each scale. The spatial information is preserved by training the network at each scale with the high frequencies of panchromatic image alongside the corresponding low resolution multispectral image. The parameters of different networks are shared across the pyramid in order to add spatial details consistently across scales. The parameters are also shared across fusion layers within a network at a specific scale. Experiments suggest that the proposed architecture outperforms state of the art pansharpening models. The proposed model, code and dataset is publicly available at https://github.com/sohaibali01/deep_pyramid_fusion.

</p>
</details>

<details><summary><b>Darknet Traffic Big-Data Analysis and Network Management to Real-Time Automating the Malicious Intent Detection Process by a Weight Agnostic Neural Networks Framework</b>
<a href="https://arxiv.org/abs/2102.08411">arxiv:2102.08411</a>
&#x1F4C8; 1 <br>
<p>Konstantinos Demertzis, Konstantinos Tsiknas, Dimitrios Takezis, Charalabos Skianis, Lazaros Iliadis</p></summary>
<p>

**Abstract:** Attackers are perpetually modifying their tactics to avoid detection and frequently leverage legitimate credentials with trusted tools already deployed in a network environment, making it difficult for organizations to proactively identify critical security risks. Network traffic analysis products have emerged in response to attackers relentless innovation, offering organizations a realistic path forward for combatting creative attackers. Additionally, thanks to the widespread adoption of cloud computing, Device Operators processes, and the Internet of Things, maintaining effective network visibility has become a highly complex and overwhelming process. What makes network traffic analysis technology particularly meaningful is its ability to combine its core capabilities to deliver malicious intent detection. In this paper, we propose a novel darknet traffic analysis and network management framework to real-time automating the malicious intent detection process, using a weight agnostic neural networks architecture. It is an effective and accurate computational intelligent forensics tool for network traffic analysis, the demystification of malware traffic, and encrypted traffic identification in real-time. Based on Weight Agnostic Neural Networks methodology, we propose an automated searching neural net architectures strategy that can perform various tasks such as identify zero-day attacks. By automating the malicious intent detection process from the darknet, the advanced proposed solution is reducing the skills and effort barrier that prevents many organizations from effectively protecting their most critical assets.

</p>
</details>

<details><summary><b>Rate-Distortion Theoretic Model Compression: Successive Refinement for Pruning</b>
<a href="https://arxiv.org/abs/2102.08329">arxiv:2102.08329</a>
&#x1F4C8; 1 <br>
<p>Berivan Isik, Albert No, Tsachy Weissman</p></summary>
<p>

**Abstract:** We study the neural network (NN) compression problem, viewing the tension between the compression ratio and NN performance through the lens of rate-distortion theory. We choose a distortion metric that reflects the effect of NN compression on the model output and then derive the tradeoff between rate (compression ratio) and distortion. In addition to characterizing theoretical limits of NN compression, this formulation shows that \emph{pruning}, implicitly or explicitly, must be a part of a good compression algorithm. This observation bridges a gap between parts of the literature pertaining to NN and data compression, respectively, providing insight into the empirical success of pruning for NN compression. Finally, we propose a novel pruning strategy derived from our information-theoretic formulation and show that it outperforms the relevant baselines on CIFAR-10 and ImageNet datasets.

</p>
</details>

<details><summary><b>Automated Identification of Vulnerable Devices in Networks using Traffic Data and Deep Learning</b>
<a href="https://arxiv.org/abs/2102.08199">arxiv:2102.08199</a>
&#x1F4C8; 1 <br>
<p>Jakob Greis, Artem Yushchenko, Daniel Vogel, Michael Meier, Volker Steinhage</p></summary>
<p>

**Abstract:** Many IoT devices are vulnerable to attacks due to flawed security designs and lacking mechanisms for firmware updates or patches to eliminate the security vulnerabilities. Device-type identification combined with data from vulnerability databases can pinpoint vulnerable IoT devices in a network and can be used to constrain the communications of vulnerable devices for preventing damage. In this contribution, we present and evaluate two deep learning approaches to the reliable IoT device-type identification, namely a recurrent and a convolutional network architecture. Both deep learning approaches show accuracies of 97% and 98%, respectively, and thereby outperform an up-to-date IoT device-type identification approach using hand-crafted fingerprint features obtaining an accuracy of 82%. The runtime performance for the IoT identification of both deep learning approaches outperforms the hand-crafted approach by three magnitudes. Finally, importance metrics explain the results of both deep learning approaches in terms of the utilization of the analyzed traffic data flow.

</p>
</details>

<details><summary><b>Nominal Unification and Matching of Higher Order Expressions with Recursive Let</b>
<a href="https://arxiv.org/abs/2102.08146">arxiv:2102.08146</a>
&#x1F4C8; 1 <br>
<p>Manfred Schmidt-Schauß, Temur Kutsia, Jordi Levy, Mateu Villaret, Yunus Kutz</p></summary>
<p>

**Abstract:** A sound and complete algorithm for nominal unification of higher-order expressions with a recursive let is described, and shown to run in nondeterministic polynomial time. We also explore specializations like nominal letrec-matching for expressions, for DAGs, and for garbage-free expressions and determine their complexity. Finally, we also provide a nominal unification algorithm for higher-order expressions with recursive let and atom-variables, where we show that it also runs in nondeterministic polynomial time.

</p>
</details>

<details><summary><b>Learning curves of generic features maps for realistic datasets with a teacher-student model</b>
<a href="https://arxiv.org/abs/2102.08127">arxiv:2102.08127</a>
&#x1F4C8; 1 <br>
<p>Bruno Loureiro, Cédric Gerbelot, Hugo Cui, Sebastian Goldt, Florent Krzakala, Marc Mézard, Lenka Zdeborová</p></summary>
<p>

**Abstract:** Teacher-student models provide a framework in which the typical-case performance of high-dimensional supervised learning can be described in closed form. The assumptions of Gaussian i.i.d. input data underlying the canonical teacher-student model may, however, be perceived as too restrictive to capture the behaviour of realistic data sets. In this paper, we introduce a Gaussian covariate generalisation of the model where the teacher and student can act on different spaces, generated with fixed, but generic feature maps. While still solvable in a closed form, this generalization is able to capture the learning curves for a broad range of realistic data sets, thus redeeming the potential of the teacher-student framework. Our contribution is then two-fold: First, we prove a rigorous formula for the asymptotic training loss and generalisation error. Second, we present a number of situations where the learning curve of the model captures the one of a realistic data set learned with kernel regression and classification, with out-of-the-box feature maps such as random projections or scattering transforms, or with pre-learned ones - such as the features learned by training multi-layer neural networks. We discuss both the power and the limitations of the framework.

</p>
</details>

<details><summary><b>Meta-Path-Free Representation Learning on Heterogeneous Networks</b>
<a href="https://arxiv.org/abs/2102.08120">arxiv:2102.08120</a>
&#x1F4C8; 1 <br>
<p>Jie Zhang, Jinru Ding, Suyuan Liu, Hongyan Wu</p></summary>
<p>

**Abstract:** Real-world networks and knowledge graphs are usually heterogeneous networks. Representation learning on heterogeneous networks is not only a popular but a pragmatic research field. The main challenge comes from the heterogeneity -- the diverse types of nodes and edges. Besides, for a given node in a HIN, the significance of a neighborhood node depends not only on the structural distance but semantics. How to effectively capture both structural and semantic relations is another challenge. The current state-of-the-art methods are based on the algorithm of meta-path and therefore have a serious disadvantage -- the performance depends on the arbitrary choosing of meta-path(s). However, the selection of meta-path(s) is experience-based and time-consuming. In this work, we propose a novel meta-path-free representation learning on heterogeneous networks, namely Heterogeneous graph Convolutional Networks (HCN). The proposed method fuses the heterogeneity and develops a $k$-strata algorithm ($k$ is an integer) to capture the $k$-hop structural and semantic information in heterogeneous networks. To the best of our knowledge, this is the first attempt to break out of the confinement of meta-paths for representation learning on heterogeneous networks. We carry out extensive experiments on three real-world heterogeneous networks. The experimental results demonstrate that the proposed method significantly outperforms the current state-of-the-art methods in a variety of analytic tasks.

</p>
</details>

<details><summary><b>Recommender Systems for Configuration Knowledge Engineering</b>
<a href="https://arxiv.org/abs/2102.08113">arxiv:2102.08113</a>
&#x1F4C8; 1 <br>
<p>Alexander Felfernig, Stefan Reiterer, Martin Stettinger, Florian Reinfrank, Michael Jeran, Gerald Ninaus</p></summary>
<p>

**Abstract:** The knowledge engineering bottleneck is still a major challenge in configurator projects. In this paper we show how recommender systems can support knowledge base development and maintenance processes. We discuss a couple of scenarios for the application of recommender systems in knowledge engineering and report the results of empirical studies which show the importance of user-centered configuration knowledge organization.

</p>
</details>

<details><summary><b>A Mental Trespass? Unveiling Truth, Exposing Thoughts and Threatening Civil Liberties with Non-Invasive AI Lie Detection</b>
<a href="https://arxiv.org/abs/2102.08004">arxiv:2102.08004</a>
&#x1F4C8; 1 <br>
<p>Taylan Sen, Kurtis Haut, Denis Lomakin, Ehsan Hoque</p></summary>
<p>

**Abstract:** Imagine an app on your phone or computer that can tell if you are being dishonest, just by processing affective features of your facial expressions, body movements, and voice. People could ask about your political preferences, your sexual orientation, and immediately determine which of your responses are honest and which are not. In this paper we argue why artificial intelligence-based, non-invasive lie detection technologies are likely to experience a rapid advancement in the coming years, and that it would be irresponsible to wait any longer before discussing its implications. Legal and popular perspectives are reviewed to evaluate the potential for these technologies to cause societal harm. To understand the perspective of a reasonable person, we conducted a survey of 129 individuals, and identified consent and accuracy as the major factors in their decision-making process regarding the use of these technologies. In our analysis, we distinguish two types of lie detection technology, accurate truth metering and accurate thought exposing. We generally find that truth metering is already largely within the scope of existing US federal and state laws, albeit with some notable exceptions. In contrast, we find that current regulation of thought exposing technologies is ambiguous and inadequate to safeguard civil liberties. In order to rectify these shortcomings, we introduce the legal concept of mental trespass and use this concept as the basis for proposed regulation.

</p>
</details>

<details><summary><b>SiMaN: Sign-to-Magnitude Network Binarization</b>
<a href="https://arxiv.org/abs/2102.07981">arxiv:2102.07981</a>
&#x1F4C8; 1 <br>
<p>Mingbao Lin, Rongrong Ji, Zihan Xu, Baochang Zhang, Fei Chao, Mingliang Xu, Chia-Wen Lin, Ling Shao</p></summary>
<p>

**Abstract:** Binary neural networks (BNNs) have attracted broad research interest due to their efficient storage and computational ability. Nevertheless, a significant challenge of BNNs lies in handling discrete constraints while ensuring bit entropy maximization, which typically makes their weight optimization very difficult. Existing methods relax the learning using the sign function, which simply encodes positive weights into +1s, and -1s otherwise. Alternatively, we formulate an angle alignment objective to constrain the weight binarization to {0,+1} to solve the challenge. In this paper, we show that our weight binarization provides an analytical solution by encoding high-magnitude weights into +1s, and 0s otherwise. Therefore, a high-quality discrete solution is established in a computationally efficient manner without the sign function. We prove that the learned weights of binarized networks roughly follow a Laplacian distribution that does not allow entropy maximization, and further demonstrate that it can be effectively solved by simply removing the $\ell_2$ regularization during network training. Our method, dubbed sign-to-magnitude network binarization (SiMaN), is evaluated on CIFAR-10 and ImageNet, demonstrating its superiority over the sign-based state-of-the-arts. Our source code, experimental settings, training logs and binary models are available at https://github.com/lmbxmu/SiMaN.

</p>
</details>

<details><summary><b>Federated Learning over Wireless Networks: A Band-limited Coordinated Descent Approach</b>
<a href="https://arxiv.org/abs/2102.07972">arxiv:2102.07972</a>
&#x1F4C8; 1 <br>
<p>Junshan Zhang, Na Li, Mehmet Dedeoglu</p></summary>
<p>

**Abstract:** We consider a many-to-one wireless architecture for federated learning at the network edge, where multiple edge devices collaboratively train a model using local data. The unreliable nature of wireless connectivity, together with constraints in computing resources at edge devices, dictates that the local updates at edge devices should be carefully crafted and compressed to match the wireless communication resources available and should work in concert with the receiver. Thus motivated, we propose SGD-based bandlimited coordinate descent algorithms for such settings. Specifically, for the wireless edge employing over-the-air computing, a common subset of k-coordinates of the gradient updates across edge devices are selected by the receiver in each iteration, and then transmitted simultaneously over k sub-carriers, each experiencing time-varying channel conditions. We characterize the impact of communication error and compression, in terms of the resulting gradient bias and mean squared error, on the convergence of the proposed algorithms. We then study learning-driven communication error minimization via joint optimization of power allocation and learning rates. Our findings reveal that optimal power allocation across different sub-carriers should take into account both the gradient values and channel conditions, thus generalizing the widely used water-filling policy. We also develop sub-optimal distributed solutions amenable to implementation.

</p>
</details>

<details><summary><b>Recoverability Landscape of Tree Structured Markov Random Fields under Symmetric Noise</b>
<a href="https://arxiv.org/abs/2102.08554">arxiv:2102.08554</a>
&#x1F4C8; 0 <br>
<p>Ashish Katiyar, Soumya Basu, Vatsal Shah, Constantine Caramanis</p></summary>
<p>

**Abstract:** We study the problem of learning tree-structured Markov random fields (MRF) on discrete random variables with common support when the observations are corrupted by a $k$-ary symmetric noise channel with unknown probability of error. For Ising models (support size = 2), past work has shown that graph structure can only be recovered up to the leaf clusters (a leaf node, its parent, and its siblings form a leaf cluster) and exact recovery is impossible. No prior work has addressed the setting of support size of 3 or more, and indeed this setting is far richer. As we show, when the support size is 3 or more, the structure of the leaf clusters may be partially or fully identifiable. We provide a precise characterization of this phenomenon and show that the extent of recoverability is dictated by the joint PMF of the random variables. In particular, we provide necessary and sufficient conditions for exact recoverability. Furthermore, we present a polynomial time, sample efficient algorithm that recovers the exact tree when this is possible, or up to the unidentifiability as promised by our characterization, when full recoverability is impossible. Finally, we demonstrate the efficacy of our algorithm experimentally.

</p>
</details>

<details><summary><b>Transferability of Neural Network Clinical De-identification Systems</b>
<a href="https://arxiv.org/abs/2102.08517">arxiv:2102.08517</a>
&#x1F4C8; 0 <br>
<p>Kahyun Lee, Nicholas J. Dobbins, Bridget McInnes, Meliha Yetisgen, Ozlem Uzuner</p></summary>
<p>

**Abstract:** Objective: Neural network de-identification studies have focused on individual datasets. These studies assume the availability of a sufficient amount of human-annotated data to train models that can generalize to corresponding test data. In real-world situations, however, researchers often have limited or no in-house training data. Existing systems and external data can help jump-start de-identification on in-house data; however, the most efficient way of utilizing existing systems and external data is unclear. This article investigates the transferability of a state-of-the-art neural clinical de-identification system, NeuroNER, across a variety of datasets, when it is modified architecturally for domain generalization and when it is trained strategically for domain transfer. Methods and Materials: We conducted a comparative study of the transferability of NeuroNER using four clinical note corpora with multiple note types from two institutions. We modified NeuroNER architecturally to integrate two types of domain generalization approaches. We evaluated each architecture using three training strategies. We measured: transferability from external sources; transferability across note types; the contribution of external source data when in-domain training data are available; and transferability across institutions. Results and Conclusions: Transferability from a single external source gave inconsistent results. Using additional external sources consistently yielded an F1-score of approximately 80%. Fine-tuning emerged as a dominant transfer strategy, with or without domain generalization. We also found that external sources were useful even in cases where in-domain training data were available. Transferability across institutions differed by note type and annotation label but resulted in improved performance.

</p>
</details>

<details><summary><b>Adversarially Robust Kernel Smoothing</b>
<a href="https://arxiv.org/abs/2102.08474">arxiv:2102.08474</a>
&#x1F4C8; 0 <br>
<p>Jia-Jie Zhu, Christina Kouridi, Yassine Nemmour, Bernhard Schölkopf</p></summary>
<p>

**Abstract:** We propose the adversarially robust kernel smoothing (ARKS) algorithm, combining kernel smoothing, robust optimization, and adversarial training for robust learning. Our methods are motivated by the convex analysis perspective of distributionally robust optimization based on probability metrics, such as the Wasserstein distance and the maximum mean discrepancy. We adapt the integral operator using supremal convolution in convex analysis to form a novel function majorant used for enforcing robustness. Our method is simple in form and applies to general loss functions and machine learning models. Furthermore, we report experiments with general machine learning models, such as deep neural networks, to demonstrate that ARKS performs competitively with the state-of-the-art methods based on the Wasserstein distance.

</p>
</details>

<details><summary><b>Multivariable Fractional Polynomials for lithium-ion batteries degradation models under dynamic conditions</b>
<a href="https://arxiv.org/abs/2102.08111">arxiv:2102.08111</a>
&#x1F4C8; 0 <br>
<p>Clara Bertinelli Salucci, Azzeddine Bakdi, Ingrid K. Glad, Erik Vanem, Riccardo De Bin</p></summary>
<p>

**Abstract:** Longevity and safety of lithium-ion batteries are facilitated by efficient monitoring and adjustment of the battery operating conditions. Hence, it is crucial to implement fast and accurate algorithms for State of Health (SoH) monitoring on the Battery Management System. The task is challenging due to the complexity and multitude of the factors contributing to the battery degradation, especially because the different degradation processes occur at various timescales and their interactions play an important role. Data-driven methods bypass this issue by approximating the complex processes with statistical or machine learning models. This paper proposes a data-driven approach which is understudied in the context of battery degradation, despite its simplicity and ease of computation: the Multivariable Fractional Polynomial (MFP) regression. Models are trained from historical data of one exhausted cell and used to predict the SoH of other cells. The data are characterised by varying loads simulating dynamic operating conditions. Two hypothetical scenarios are considered: one assumes that a recent capacity measurement is known, the other is based only on the nominal capacity. It was shown that the degradation behaviour of the batteries under examination is influenced by their historical data, as supported by the low prediction errors achieved (root mean squared errors from 1.2% to 7.22% when considering data up to the battery End of Life). Moreover, we offer a multi-factor perspective where the degree of impact of each different factor is analysed. Finally, we compare with a Long Short-Term Memory Neural Network and other works from the literature on the same dataset. We conclude that the MFP regression is effective and competitive with contemporary works, and provides several additional advantages e.g. in terms of interpretability, generalisability, and implementability.

</p>
</details>

<details><summary><b>The Elliptical Potential Lemma for General Distributions with an Application to Linear Thompson Sampling</b>
<a href="https://arxiv.org/abs/2102.07987">arxiv:2102.07987</a>
&#x1F4C8; 0 <br>
<p>Nima Hamidi, Mohsen Bayati</p></summary>
<p>

**Abstract:** In this note, we introduce a general version of the well-known elliptical potential lemma that is a widely used technique in the analysis of algorithms in sequential learning and decision-making problems. We consider a stochastic linear bandit setting where a decision-maker sequentially chooses among a set of given actions, observes their noisy rewards, and aims to maximize her cumulative expected reward over a decision-making horizon. The elliptical potential lemma is a key tool for quantifying uncertainty in estimating parameters of the reward function, but it requires the noise and the prior distributions to be Gaussian. Our general elliptical potential lemma relaxes this Gaussian requirement which is a highly non-trivial extension for a number of reasons; unlike the Gaussian case, there is no closed-form solution for the covariance matrix of the posterior distribution, the covariance matrix is not a deterministic function of the actions, and the covariance matrix is not decreasing with respect to the semidefinite inequality. While this result is of broad interest, we showcase an application of it to prove an improved Bayesian regret bound for the well-known Thompson sampling algorithm in stochastic linear bandits with changing action sets where prior and noise distributions are general. This bound is minimax optimal up to constants.

</p>
</details>

<details><summary><b>A General Descent Aggregation Framework for Gradient-based Bi-level Optimization</b>
<a href="https://arxiv.org/abs/2102.07976">arxiv:2102.07976</a>
&#x1F4C8; 0 <br>
<p>Risheng Liu, Pan Mu, Xiaoming Yuan, Shangzhi Zeng, Jin Zhang</p></summary>
<p>

**Abstract:** In recent years, a variety of gradient-based methods have been developed to solve Bi-Level Optimization (BLO) problems in machine learning and computer vision areas. However, the theoretical correctness and practical effectiveness of these existing approaches always rely on some restrictive conditions (e.g., Lower-Level Singleton, LLS), which could hardly be satisfied in real-world applications. Moreover, previous literature only proves theoretical results based on their specific iteration strategies, thus lack a general recipe to uniformly analyze the convergence behaviors of different gradient-based BLOs. In this work, we formulate BLOs from an optimistic bi-level viewpoint and establish a new gradient-based algorithmic framework, named Bi-level Descent Aggregation (BDA), to partially address the above issues. Specifically, BDA provides a modularized structure to hierarchically aggregate both the upper- and lower-level subproblems to generate our bi-level iterative dynamics. Theoretically, we establish a general convergence analysis template and derive a new proof recipe to investigate the essential theoretical properties of gradient-based BLO methods. Furthermore, this work systematically explores the convergence behavior of BDA in different optimization scenarios, i.e., considering various solution qualities (i.e., global/local/stationary solution) returned from solving approximation subproblems. Extensive experiments justify our theoretical results and demonstrate the superiority of the proposed algorithm for hyper-parameter optimization and meta-learning tasks.

</p>
</details>


{% endraw %}
Prev: [2021.02.15]({{ '/2021/02/15/2021.02.15.html' | relative_url }})  Next: [2021.02.17]({{ '/2021/02/17/2021.02.17.html' | relative_url }})