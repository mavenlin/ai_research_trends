## Summary for 2021-04-12, created on 2021-12-22


<details><summary><b>Self-Training with Weak Supervision</b>
<a href="https://arxiv.org/abs/2104.05514">arxiv:2104.05514</a>
&#x1F4C8; 74 <br>
<p>Giannis Karamanolakis, Subhabrata Mukherjee, Guoqing Zheng, Ahmed Hassan Awadallah</p></summary>
<p>

**Abstract:** State-of-the-art deep neural networks require large-scale labeled training data that is often expensive to obtain or not available for many tasks. Weak supervision in the form of domain-specific rules has been shown to be useful in such settings to automatically generate weakly labeled training data. However, learning with weak rules is challenging due to their inherent heuristic and noisy nature. An additional challenge is rule coverage and overlap, where prior work on weak supervision only considers instances that are covered by weak rules, thus leaving valuable unlabeled data behind.
  In this work, we develop a weak supervision framework (ASTRA) that leverages all the available data for a given task. To this end, we leverage task-specific unlabeled data through self-training with a model (student) that considers contextualized representations and predicts pseudo-labels for instances that may not be covered by weak rules. We further develop a rule attention network (teacher) that learns how to aggregate student pseudo-labels with weak rule labels, conditioned on their fidelity and the underlying context of an instance. Finally, we construct a semi-supervised learning objective for end-to-end training with unlabeled data, domain-specific rules, and a small amount of labeled data. Extensive experiments on six benchmark datasets for text classification demonstrate the effectiveness of our approach with significant improvements over state-of-the-art baselines.

</p>
</details>

<details><summary><b>Machine Translation Decoding beyond Beam Search</b>
<a href="https://arxiv.org/abs/2104.05336">arxiv:2104.05336</a>
&#x1F4C8; 42 <br>
<p>RÃ©mi Leblond, Jean-Baptiste Alayrac, Laurent Sifre, Miruna Pislar, Jean-Baptiste Lespiau, Ioannis Antonoglou, Karen Simonyan, Oriol Vinyals</p></summary>
<p>

**Abstract:** Beam search is the go-to method for decoding auto-regressive machine translation models. While it yields consistent improvements in terms of BLEU, it is only concerned with finding outputs with high model likelihood, and is thus agnostic to whatever end metric or score practitioners care about. Our aim is to establish whether beam search can be replaced by a more powerful metric-driven search technique. To this end, we explore numerous decoding algorithms, including some which rely on a value function parameterised by a neural network, and report results on a variety of metrics. Notably, we introduce a Monte-Carlo Tree Search (MCTS) based method and showcase its competitiveness. We provide a blueprint for how to use MCTS fruitfully in language applications, which opens promising future directions. We find that which algorithm is best heavily depends on the characteristics of the goal metric; we believe that our extensive experiments and analysis will inform further research in this area.

</p>
</details>

<details><summary><b>Escaping the Big Data Paradigm with Compact Transformers</b>
<a href="https://arxiv.org/abs/2104.05704">arxiv:2104.05704</a>
&#x1F4C8; 35 <br>
<p>Ali Hassani, Steven Walton, Nikhil Shah, Abulikemu Abuduweili, Jiachen Li, Humphrey Shi</p></summary>
<p>

**Abstract:** With the rise of Transformers as the standard for language processing, and their advancements in computer vision, along with their unprecedented size and amounts of training data, many have come to believe that they are not suitable for small sets of data. This trend leads to great concerns, including but not limited to: limited availability of data in certain scientific domains and the exclusion of those with limited resource from research in the field. In this paper, we dispel the myth that transformers are "data hungry" and therefore can only be applied to large sets of data. We show for the first time that with the right size and tokenization, transformers can perform head-to-head with state-of-the-art CNNs on small datasets, often with better accuracy and fewer parameters. Our model eliminates the requirement for class token and positional embeddings through a novel sequence pooling strategy and the use of convolution/s. It is flexible in terms of model size, and can have as little as 0.28M parameters while achieving good results. Our model can reach 98.00% accuracy when training from scratch on CIFAR-10, which is a significant improvement over previous Transformer based models. It also outperforms many modern CNN based approaches, such as ResNet, and even some recent NAS-based approaches, such as Proxyless-NAS. Our simple and compact design democratizes transformers by making them accessible to those with limited computing resources and/or dealing with small datasets. Our method also works on larger datasets, such as ImageNet (82.71% accuracy with 29% parameters of ViT), and NLP tasks as well. Our code and pre-trained models are publicly available at https://github.com/SHI-Labs/Compact-Transformers.

</p>
</details>

<details><summary><b>A coevolutionary approach to deep multi-agent reinforcement learning</b>
<a href="https://arxiv.org/abs/2104.05610">arxiv:2104.05610</a>
&#x1F4C8; 34 <br>
<p>Daan Klijn, A. E. Eiben</p></summary>
<p>

**Abstract:** Traditionally, Deep Artificial Neural Networks (DNN's) are trained through gradient descent. Recent research shows that Deep Neuroevolution (DNE) is also capable of evolving multi-million-parameter DNN's, which proved to be particularly useful in the field of Reinforcement Learning (RL). This is mainly due to its excellent scalability and simplicity compared to the traditional MDP-based RL methods. So far, DNE has only been applied to complex single-agent problems. As evolutionary methods are a natural choice for multi-agent problems, the question arises whether DNE can also be applied in a complex multi-agent setting. In this paper, we describe and validate a new approach based on Coevolution. To validate our approach, we benchmark two Deep Coevolutionary Algorithms on a range of multi-agent Atari games and compare our results against the results of Ape-X DQN. Our results show that these Deep Coevolutionary algorithms (1) can be successfully trained to play various games, (2) outperform Ape-X DQN in some of them, and therefore (3) show that Coevolution can be a viable approach to solving complex multi-agent decision-making problems.

</p>
</details>

<details><summary><b>Semantic Segmentation with Generative Models: Semi-Supervised Learning and Strong Out-of-Domain Generalization</b>
<a href="https://arxiv.org/abs/2104.05833">arxiv:2104.05833</a>
&#x1F4C8; 30 <br>
<p>Daiqing Li, Junlin Yang, Karsten Kreis, Antonio Torralba, Sanja Fidler</p></summary>
<p>

**Abstract:** Training deep networks with limited labeled data while achieving a strong generalization ability is key in the quest to reduce human annotation efforts. This is the goal of semi-supervised learning, which exploits more widely available unlabeled data to complement small labeled data sets. In this paper, we propose a novel framework for discriminative pixel-level tasks using a generative model of both images and labels. Concretely, we learn a generative adversarial network that captures the joint image-label distribution and is trained efficiently using a large set of unlabeled images supplemented with only few labeled ones. We build our architecture on top of StyleGAN2, augmented with a label synthesis branch. Image labeling at test time is achieved by first embedding the target image into the joint latent space via an encoder network and test-time optimization, and then generating the label from the inferred embedding. We evaluate our approach in two important domains: medical image segmentation and part-based face segmentation. We demonstrate strong in-domain performance compared to several baselines, and are the first to showcase extreme out-of-domain generalization, such as transferring from CT to MRI in medical imaging, and photographs of real faces to paintings, sculptures, and even cartoons and animal faces. Project Page: \url{https://nv-tlabs.github.io/semanticGAN/}

</p>
</details>

<details><summary><b>Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation</b>
<a href="https://arxiv.org/abs/2104.05801">arxiv:2104.05801</a>
&#x1F4C8; 30 <br>
<p>Sarik Ghazarian, Zixi Liu, Akash SM, Ralph Weischedel, Aram Galstyan, Nanyun Peng</p></summary>
<p>

**Abstract:** With the recent advances of open-domain story generation, the lack of reliable automatic evaluation metrics becomes an increasingly imperative issue that hinders the fast development of story generation. According to conducted researches in this regard, learnable evaluation metrics have promised more accurate assessments by having higher correlations with human judgments. A critical bottleneck of obtaining a reliable learnable evaluation metric is the lack of high-quality training data for classifiers to efficiently distinguish plausible and implausible machine-generated stories. Previous works relied on \textit{heuristically manipulated} plausible examples to mimic possible system drawbacks such as repetition, contradiction, or irrelevant content in the text level, which can be \textit{unnatural} and \textit{oversimplify} the characteristics of implausible machine-generated stories. We propose to tackle these issues by generating a more comprehensive set of implausible stories using {\em plots}, which are structured representations of controllable factors used to generate stories. Since these plots are compact and structured, it is easier to manipulate them to generate text with targeted undesirable properties, while at the same time maintain the grammatical correctness and naturalness of the generated sentences. To improve the quality of generated implausible stories, we further apply the adversarial filtering procedure presented by \citet{zellers2018swag} to select a more nuanced set of implausible texts. Experiments show that the evaluation metrics trained on our generated data result in more reliable automatic assessments that correlate remarkably better with human judgments compared to the baselines.

</p>
</details>

<details><summary><b>Rapid Exploration for Open-World Navigation with Latent Goal Models</b>
<a href="https://arxiv.org/abs/2104.05859">arxiv:2104.05859</a>
&#x1F4C8; 24 <br>
<p>Dhruv Shah, Benjamin Eysenbach, Nicholas Rhinehart, Sergey Levine</p></summary>
<p>

**Abstract:** We describe a robotic learning system for autonomous exploration and navigation in diverse, open-world environments. At the core of our method is a learned latent variable model of distances and actions, along with a non-parametric topological memory of images. We use an information bottleneck to regularize the learned policy, giving us (i) a compact visual representation of goals, (ii) improved generalization capabilities, and (iii) a mechanism for sampling feasible goals for exploration. Trained on a large offline dataset of prior experience, the model acquires a representation of visual goals that is robust to task-irrelevant distractors. We demonstrate our method on a mobile ground robot in open-world exploration scenarios. Given an image of a goal that is up to 80 meters away, our method leverages its representation to explore and discover the goal in under 20 minutes, even amidst previously-unseen obstacles and weather conditions. Please check out the project website for videos of our experiments and information about the real-world dataset used at https://sites.google.com/view/recon-robot.

</p>
</details>

<details><summary><b>GPflux: A Library for Deep Gaussian Processes</b>
<a href="https://arxiv.org/abs/2104.05674">arxiv:2104.05674</a>
&#x1F4C8; 24 <br>
<p>Vincent Dutordoir, Hugh Salimbeni, Eric Hambro, John McLeod, Felix Leibfried, Artem Artemev, Mark van der Wilk, James Hensman, Marc P. Deisenroth, ST John</p></summary>
<p>

**Abstract:** We introduce GPflux, a Python library for Bayesian deep learning with a strong emphasis on deep Gaussian processes (DGPs). Implementing DGPs is a challenging endeavour due to the various mathematical subtleties that arise when dealing with multivariate Gaussian distributions and the complex bookkeeping of indices. To date, there are no actively maintained, open-sourced and extendable libraries available that support research activities in this area. GPflux aims to fill this gap by providing a library with state-of-the-art DGP algorithms, as well as building blocks for implementing novel Bayesian and GP-based hierarchical models and inference schemes. GPflux is compatible with and built on top of the Keras deep learning eco-system. This enables practitioners to leverage tools from the deep learning community for building and training customised Bayesian models, and create hierarchical models that consist of Bayesian and standard neural network layers in a single coherent framework. GPflux relies on GPflow for most of its GP objects and operations, which makes it an efficient, modular and extensible library, while having a lean codebase.

</p>
</details>

<details><summary><b>Relational World Knowledge Representation in Contextual Language Models: A Review</b>
<a href="https://arxiv.org/abs/2104.05837">arxiv:2104.05837</a>
&#x1F4C8; 23 <br>
<p>Tara Safavi, Danai Koutra</p></summary>
<p>

**Abstract:** Relational knowledge bases (KBs) are commonly used to represent world knowledge in machines. However, while advantageous for their high degree of precision and interpretability, KBs are usually organized according to manually-defined schemas, which limit their expressiveness and require significant human efforts to engineer and maintain. In this review, we take a natural language processing perspective to these limitations, examining how they may be addressed in part by training deep contextual language models (LMs) to internalize and express relational knowledge in more flexible forms. We propose to organize knowledge representation strategies in LMs by the level of KB supervision provided, from no KB supervision at all to entity- and relation-level supervision. Our contributions are threefold: (1) We provide a high-level, extensible taxonomy for knowledge representation in LMs; (2) Within our taxonomy, we highlight notable models, evaluation tasks, and findings, in order to provide an up-to-date review of current knowledge representation capabilities in LMs; and (3) We suggest future research directions that build upon the complementary aspects of LMs and KBs as knowledge representations.

</p>
</details>

<details><summary><b>Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis</b>
<a href="https://arxiv.org/abs/2104.05703">arxiv:2104.05703</a>
&#x1F4C8; 22 <br>
<p>Xiaoyu Xiang, Ding Liu, Xiao Yang, Yiheng Zhu, Xiaohui Shen, Jan P. Allebach</p></summary>
<p>

**Abstract:** In this paper, we explore the open-domain sketch-to-photo translation, which aims to synthesize a realistic photo from a freehand sketch with its class label, even if the sketches of that class are missing in the training data. It is challenging due to the lack of training supervision and the large geometry distortion between the freehand sketch and photo domains. To synthesize the absent freehand sketches from photos, we propose a framework that jointly learns sketch-to-photo and photo-to-sketch generation. However, the generator trained from fake sketches might lead to unsatisfying results when dealing with sketches of missing classes, due to the domain gap between synthesized sketches and real ones. To alleviate this issue, we further propose a simple yet effective open-domain sampling and optimization strategy to "fool" the generator into treating fake sketches as real ones. Our method takes advantage of the learned sketch-to-photo and photo-to-sketch mapping of in-domain data and generalizes them to the open-domain classes. We validate our method on the Scribble and SketchyCOCO datasets. Compared with the recent competing methods, our approach shows impressive results in synthesizing realistic color, texture, and maintaining the geometric composition for various categories of open-domain sketches.

</p>
</details>

<details><summary><b>A Recipe for Global Convergence Guarantee in Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2104.05785">arxiv:2104.05785</a>
&#x1F4C8; 15 <br>
<p>Kenji Kawaguchi, Qingyun Sun</p></summary>
<p>

**Abstract:** Existing global convergence guarantees of (stochastic) gradient descent do not apply to practical deep networks in the practical regime of deep learning beyond the neural tangent kernel (NTK) regime. This paper proposes an algorithm, which is ensured to have global convergence guarantees in the practical regime beyond the NTK regime, under a verifiable condition called the expressivity condition. The expressivity condition is defined to be both data-dependent and architecture-dependent, which is the key property that makes our results applicable for practical settings beyond the NTK regime. On the one hand, the expressivity condition is theoretically proven to hold data-independently for fully-connected deep neural networks with narrow hidden layers and a single wide layer. On the other hand, the expressivity condition is numerically shown to hold data-dependently for deep (convolutional) ResNet with batch normalization with various standard image datasets. We also show that the proposed algorithm has generalization performances comparable with those of the heuristic algorithm, with the same hyper-parameters and total number of iterations. Therefore, the proposed algorithm can be viewed as a step towards providing theoretical guarantees for deep learning in the practical regime.

</p>
</details>

<details><summary><b>Self-supervised Multi-view Stereo via Effective Co-Segmentation and Data-Augmentation</b>
<a href="https://arxiv.org/abs/2104.05374">arxiv:2104.05374</a>
&#x1F4C8; 14 <br>
<p>Hongbin Xu, Zhipeng Zhou, Yu Qiao, Wenxiong Kang, Qiuxia Wu</p></summary>
<p>

**Abstract:** Recent studies have witnessed that self-supervised methods based on view synthesis obtain clear progress on multi-view stereo (MVS). However, existing methods rely on the assumption that the corresponding points among different views share the same color, which may not always be true in practice. This may lead to unreliable self-supervised signal and harm the final reconstruction performance. To address the issue, we propose a framework integrated with more reliable supervision guided by semantic co-segmentation and data-augmentation. Specially, we excavate mutual semantic from multi-view images to guide the semantic consistency. And we devise effective data-augmentation mechanism which ensures the transformation robustness by treating the prediction of regular samples as pseudo ground truth to regularize the prediction of augmented samples. Experimental results on DTU dataset show that our proposed methods achieve the state-of-the-art performance among unsupervised methods, and even compete on par with supervised methods. Furthermore, extensive experiments on Tanks&Temples dataset demonstrate the effective generalization ability of the proposed method.

</p>
</details>

<details><summary><b>On the Inductive Bias of Masked Language Modeling: From Statistical to Syntactic Dependencies</b>
<a href="https://arxiv.org/abs/2104.05694">arxiv:2104.05694</a>
&#x1F4C8; 12 <br>
<p>Tianyi Zhang, Tatsunori Hashimoto</p></summary>
<p>

**Abstract:** We study how masking and predicting tokens in an unsupervised fashion can give rise to linguistic structures and downstream performance gains. Recent theories have suggested that pretrained language models acquire useful inductive biases through masks that implicitly act as cloze reductions for downstream tasks. While appealing, we show that the success of the random masking strategy used in practice cannot be explained by such cloze-like masks alone. We construct cloze-like masks using task-specific lexicons for three different classification datasets and show that the majority of pretrained performance gains come from generic masks that are not associated with the lexicon. To explain the empirical success of these generic masks, we demonstrate a correspondence between the Masked Language Model (MLM) objective and existing methods for learning statistical dependencies in graphical models. Using this, we derive a method for extracting these learned statistical dependencies in MLMs and show that these dependencies encode useful inductive biases in the form of syntactic structures. In an unsupervised parsing evaluation, simply forming a minimum spanning tree on the implied statistical dependence structure outperforms a classic method for unsupervised parsing (58.74 vs. 55.91 UUAS).

</p>
</details>

<details><summary><b>Investigating Methods to Improve Language Model Integration for Attention-based Encoder-Decoder ASR Models</b>
<a href="https://arxiv.org/abs/2104.05544">arxiv:2104.05544</a>
&#x1F4C8; 11 <br>
<p>Mohammad Zeineldeen, Aleksandr Glushko, Wilfried Michel, Albert Zeyer, Ralf SchlÃ¼ter, Hermann Ney</p></summary>
<p>

**Abstract:** Attention-based encoder-decoder (AED) models learn an implicit internal language model (ILM) from the training transcriptions. The integration with an external LM trained on much more unpaired text usually leads to better performance. A Bayesian interpretation as in the hybrid autoregressive transducer (HAT) suggests dividing by the prior of the discriminative acoustic model, which corresponds to this implicit LM, similarly as in the hybrid hidden Markov model approach. The implicit LM cannot be calculated efficiently in general and it is yet unclear what are the best methods to estimate it. In this work, we compare different approaches from the literature and propose several novel methods to estimate the ILM directly from the AED model. Our proposed methods outperform all previous approaches. We also investigate other methods to suppress the ILM mainly by decreasing the capacity of the AED model, limiting the label context, and also by training the AED model together with a pre-existing LM.

</p>
</details>

<details><summary><b>Simpler Certified Radius Maximization by Propagating Covariances</b>
<a href="https://arxiv.org/abs/2104.05888">arxiv:2104.05888</a>
&#x1F4C8; 10 <br>
<p>Xingjian Zhen, Rudrasis Chakraborty, Vikas Singh</p></summary>
<p>

**Abstract:** One strategy for adversarially training a robust model is to maximize its certified radius -- the neighborhood around a given training sample for which the model's prediction remains unchanged. The scheme typically involves analyzing a "smoothed" classifier where one estimates the prediction corresponding to Gaussian samples in the neighborhood of each sample in the mini-batch, accomplished in practice by Monte Carlo sampling. In this paper, we investigate the hypothesis that this sampling bottleneck can potentially be mitigated by identifying ways to directly propagate the covariance matrix of the smoothed distribution through the network. To this end, we find that other than certain adjustments to the network, propagating the covariances must also be accompanied by additional accounting that keeps track of how the distributional moments transform and interact at each stage in the network. We show how satisfying these criteria yields an algorithm for maximizing the certified radius on datasets including Cifar-10, ImageNet, and Places365 while offering runtime savings on networks with moderate depth, with a small compromise in overall accuracy. We describe the details of the key modifications that enable practical use. Via various experiments, we evaluate when our simplifications are sensible, and what the key benefits and limitations are.

</p>
</details>

<details><summary><b>Macro-Average: Rare Types Are Important Too</b>
<a href="https://arxiv.org/abs/2104.05700">arxiv:2104.05700</a>
&#x1F4C8; 10 <br>
<p>Thamme Gowda, Weiqiu You, Constantine Lignos, Jonathan May</p></summary>
<p>

**Abstract:** While traditional corpus-level evaluation metrics for machine translation (MT) correlate well with fluency, they struggle to reflect adequacy. Model-based MT metrics trained on segment-level human judgments have emerged as an attractive replacement due to strong correlation results. These models, however, require potentially expensive re-training for new domains and languages. Furthermore, their decisions are inherently non-transparent and appear to reflect unwelcome biases. We explore the simple type-based classifier metric, MacroF1, and study its applicability to MT evaluation. We find that MacroF1 is competitive on direct assessment, and outperforms others in indicating downstream cross-lingual information retrieval task performance. Further, we show that MacroF1 can be used to effectively compare supervised and unsupervised neural machine translation, and reveal significant qualitative differences in the methods' outputs.

</p>
</details>

<details><summary><b>Understanding Prediction Discrepancies in Machine Learning Classifiers</b>
<a href="https://arxiv.org/abs/2104.05467">arxiv:2104.05467</a>
&#x1F4C8; 10 <br>
<p>Xavier Renard, Thibault Laugel, Marcin Detyniecki</p></summary>
<p>

**Abstract:** A multitude of classifiers can be trained on the same data to achieve similar performances during test time, while having learned significantly different classification patterns. This phenomenon, which we call prediction discrepancies, is often associated with the blind selection of one model instead of another with similar performances. When making a choice, the machine learning practitioner has no understanding on the differences between models, their limits, where they agree and where they don't. But his/her choice will result in concrete consequences for instances to be classified in the discrepancy zone, since the final decision will be based on the selected classification pattern. Besides the arbitrary nature of the result, a bad choice could have further negative consequences such as loss of opportunity or lack of fairness. This paper proposes to address this question by analyzing the prediction discrepancies in a pool of best-performing models trained on the same data. A model-agnostic algorithm, DIG, is proposed to capture and explain discrepancies locally, to enable the practitioner to make the best educated decision when selecting a model by anticipating its potential undesired consequences. All the code to reproduce the experiments is available.

</p>
</details>

<details><summary><b>How Sensitive are Meta-Learners to Dataset Imbalance?</b>
<a href="https://arxiv.org/abs/2104.05344">arxiv:2104.05344</a>
&#x1F4C8; 10 <br>
<p>Mateusz Ochal, Massimiliano Patacchiola, Amos Storkey, Jose Vazquez, Sen Wang</p></summary>
<p>

**Abstract:** Meta-Learning (ML) has proven to be a useful tool for training Few-Shot Learning (FSL) algorithms by exposure to batches of tasks sampled from a meta-dataset. However, the standard training procedure overlooks the dynamic nature of the real-world where object classes are likely to occur at different frequencies. While it is generally understood that imbalanced tasks harm the performance of supervised methods, there is no significant research examining the impact of imbalanced meta-datasets on the FSL evaluation task. This study exposes the magnitude and extent of this problem. Our results show that ML methods are more robust against meta-dataset imbalance than imbalance at the task-level with a similar imbalance ratio ($Ï<20$), with the effect holding even in long-tail datasets under a larger imbalance ($Ï=65$). Overall, these results highlight an implicit strength of ML algorithms, capable of learning generalizable features under dataset imbalance and domain-shift. The code to reproduce the experiments is released under an open-source license.

</p>
</details>

<details><summary><b>Fibro-CoSANet: Pulmonary Fibrosis Prognosis Prediction using a Convolutional Self Attention Network</b>
<a href="https://arxiv.org/abs/2104.05889">arxiv:2104.05889</a>
&#x1F4C8; 9 <br>
<p>Zabir Al Nazi, Fazla Rabbi Mashrur, Md Amirul Islam, Shumit Saha</p></summary>
<p>

**Abstract:** Idiopathic pulmonary fibrosis (IPF) is a restrictive interstitial lung disease that causes lung function decline by lung tissue scarring. Although lung function decline is assessed by the forced vital capacity (FVC), determining the accurate progression of IPF remains a challenge. To address this challenge, we proposed Fibro-CoSANet, a novel end-to-end multi-modal learning-based approach, to predict the FVC decline. Fibro-CoSANet utilized CT images and demographic information in convolutional neural network frameworks with a stacked attention layer. Extensive experiments on the OSIC Pulmonary Fibrosis Progression Dataset demonstrated the superiority of our proposed Fibro-CoSANet by achieving the new state-of-the-art modified Laplace Log-Likelihood score of -6.68. This network may benefit research areas concerned with designing networks to improve the prognostic accuracy of IPF. The source-code for Fibro-CoSANet is available at: \url{https://github.com/zabir-nabil/Fibro-CoSANet}.

</p>
</details>

<details><summary><b>Visual Goal-Step Inference using wikiHow</b>
<a href="https://arxiv.org/abs/2104.05845">arxiv:2104.05845</a>
&#x1F4C8; 9 <br>
<p>Yue Yang, Artemis Panagopoulou, Qing Lyu, Li Zhang, Mark Yatskar, Chris Callison-Burch</p></summary>
<p>

**Abstract:** Understanding what sequence of steps are needed to complete a goal can help artificial intelligence systems reason about human activities. Past work in NLP has examined the task of goal-step inference for text. We introduce the visual analogue. We propose the Visual Goal-Step Inference (VGSI) task, where a model is given a textual goal and must choose which of four images represents a plausible step towards that goal. With a new dataset harvested from wikiHow consisting of 772,277 images representing human actions, we show that our task is challenging for state-of-the-art multimodal models. Moreover, the multimodal representation learned from our data can be effectively transferred to other datasets like HowTo100m, increasing the VGSI accuracy by 15 - 20%. Our task will facilitate multimodal reasoning about procedural events.

</p>
</details>

<details><summary><b>SpartQA: : A Textual Question Answering Benchmark for Spatial Reasoning</b>
<a href="https://arxiv.org/abs/2104.05832">arxiv:2104.05832</a>
&#x1F4C8; 9 <br>
<p>Roshanak Mirzaee, Hossein Rajaby Faghihi, Qiang Ning, Parisa Kordjmashidi</p></summary>
<p>

**Abstract:** This paper proposes a question-answering (QA) benchmark for spatial reasoning on natural language text which contains more realistic spatial phenomena not covered by prior work and is challenging for state-of-the-art language models (LM). We propose a distant supervision method to improve on this task. Specifically, we design grammar and reasoning rules to automatically generate a spatial description of visual scenes and corresponding QA pairs. Experiments show that further pretraining LMs on these automatically generated data significantly improves LMs' capability on spatial understanding, which in turn helps to better solve two external datasets, bAbI, and boolQ. We hope that this work can foster investigations into more sophisticated models for spatial reasoning over text.

</p>
</details>

<details><summary><b>Image-Level or Object-Level? A Tale of Two Resampling Strategies for Long-Tailed Detection</b>
<a href="https://arxiv.org/abs/2104.05702">arxiv:2104.05702</a>
&#x1F4C8; 9 <br>
<p>Nadine Chang, Zhiding Yu, Yu-Xiong Wang, Anima Anandkumar, Sanja Fidler, Jose M. Alvarez</p></summary>
<p>

**Abstract:** Training on datasets with long-tailed distributions has been challenging for major recognition tasks such as classification and detection. To deal with this challenge, image resampling is typically introduced as a simple but effective approach. However, we observe that long-tailed detection differs from classification since multiple classes may be present in one image. As a result, image resampling alone is not enough to yield a sufficiently balanced distribution at the object level. We address object-level resampling by introducing an object-centric memory replay strategy based on dynamic, episodic memory banks. Our proposed strategy has two benefits: 1) convenient object-level resampling without significant extra computation, and 2) implicit feature-level augmentation from model updates. We show that image-level and object-level resamplings are both important, and thus unify them with a joint resampling strategy (RIO). Our method outperforms state-of-the-art long-tailed detection and segmentation methods on LVIS v0.5 across various backbones. Code is available at https://github.com/NVlabs/RIO.

</p>
</details>

<details><summary><b>End-to-End Mandarin Tone Classification with Short Term Context Information</b>
<a href="https://arxiv.org/abs/2104.05657">arxiv:2104.05657</a>
&#x1F4C8; 8 <br>
<p>Jiyang Tang, Ming Li</p></summary>
<p>

**Abstract:** In this paper, we propose an end-to-end Mandarin tone classification method from continuous speech utterances utilizing both the spectrogram and the short-term context information as the input. Both spectrograms and context segment features are used to train the tone classifier. We first divide the spectrogram frames into syllable segments using force alignment results produced by an ASR model. Then we extract the short-term segment features to capture the context information across multiple syllables. Feeding both the spectrogram and the short-term context segment features into an end-to-end model could significantly improve the performance. Experiments are performed on a large-scale open-source Mandarin speech dataset to evaluate the proposed method. Results show that this method improves the classification accuracy from 79.5% to 92.6% on the AISHELL3 database.

</p>
</details>

<details><summary><b>Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment</b>
<a href="https://arxiv.org/abs/2104.05632">arxiv:2104.05632</a>
&#x1F4C8; 8 <br>
<p>Philip J. Ball, Cong Lu, Jack Parker-Holder, Stephen Roberts</p></summary>
<p>

**Abstract:** Reinforcement learning from large-scale offline datasets provides us with the ability to learn policies without potentially unsafe or impractical exploration. Significant progress has been made in the past few years in dealing with the challenge of correcting for differing behavior between the data collection and learned policies. However, little attention has been paid to potentially changing dynamics when transferring a policy to the online setting, where performance can be up to 90% reduced for existing methods. In this paper we address this problem with Augmented World Models (AugWM). We augment a learned dynamics model with simple transformations that seek to capture potential changes in physical properties of the robot, leading to more robust policies. We not only train our policy in this new setting, but also provide it with the sampled augmentation as a context, allowing it to adapt to changes in the environment. At test time we learn the context in a self-supervised fashion by approximating the augmentation which corresponds to the new environment. We rigorously evaluate our approach on over 100 different changed dynamics settings, and show that this simple approach can significantly improve the zero-shot generalization of a recent state-of-the-art baseline, often achieving successful policies where the baseline fails.

</p>
</details>

<details><summary><b>Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures</b>
<a href="https://arxiv.org/abs/2104.05379">arxiv:2104.05379</a>
&#x1F4C8; 8 <br>
<p>Nick Rossenbach, Mohammad Zeineldeen, Benedikt Hilmes, Ralf SchlÃ¼ter, Hermann Ney</p></summary>
<p>

**Abstract:** Recent publications on automatic-speech-recognition (ASR) have a strong focus on attention encoder-decoder (AED) architectures which tend to suffer from over-fitting in low resource scenarios. One solution to tackle this issue is to generate synthetic data with a trained text-to-speech system (TTS) if additional text is available. This was successfully applied in many publications with AED systems, but only very limited in the context of other ASR architectures. We investigate the effect of varying pre-processing, the speaker embedding and input encoding of the TTS system w.r.t. the effectiveness of the synthesized data for AED-ASR training. Additionally, we also consider internal language model subtraction for the first time, resulting in up to 38% relative improvement. We compare the AED results to a state-of-the-art hybrid ASR system, a monophone based system using connectionist-temporal-classification (CTC) and a monotonic transducer based system. We show that for the later systems the addition of synthetic data has no relevant effect, but they still outperform the AED systems on LibriSpeech-100h. We achieve a final word-error-rate of 3.3%/10.0% with a hybrid system on the clean/noisy test-sets, surpassing any previous state-of-the-art systems on Librispeech-100h that do not include unlabeled audio data.

</p>
</details>

<details><summary><b>Class-Balanced Distillation for Long-Tailed Visual Recognition</b>
<a href="https://arxiv.org/abs/2104.05279">arxiv:2104.05279</a>
&#x1F4C8; 8 <br>
<p>Ahmet Iscen, AndrÃ© Araujo, Boqing Gong, Cordelia Schmid</p></summary>
<p>

**Abstract:** Real-world imagery is often characterized by a significant imbalance of the number of images per class, leading to long-tailed distributions. An effective and simple approach to long-tailed visual recognition is to learn feature representations and a classifier separately, with instance and class-balanced sampling, respectively. In this work, we introduce a new framework, by making the key observation that a feature representation learned with instance sampling is far from optimal in a long-tailed setting. Our main contribution is a new training method, referred to as Class-Balanced Distillation (CBD), that leverages knowledge distillation to enhance feature representations. CBD allows the feature representation to evolve in the second training stage, guided by the teacher learned in the first stage. The second stage uses class-balanced sampling, in order to focus on under-represented classes. This framework can naturally accommodate the usage of multiple teachers, unlocking the information from an ensemble of models to enhance recognition capabilities. Our experiments show that the proposed technique consistently outperforms the state of the art on long-tailed recognition benchmarks such as ImageNet-LT, iNaturalist17 and iNaturalist18. The experiments also show that our method does not sacrifice the accuracy of head classes to improve the performance of tail classes, unlike most existing work.

</p>
</details>

<details><summary><b>Robust Classification from Noisy Labels: Integrating Additional Knowledge for Chest Radiography Abnormality Assessment</b>
<a href="https://arxiv.org/abs/2104.05261">arxiv:2104.05261</a>
&#x1F4C8; 8 <br>
<p>Sebastian GÃ¼ndel, Arnaud A. A. Setio, Florin C. Ghesu, Sasa Grbic, Bogdan Georgescu, Andreas Maier, Dorin Comaniciu</p></summary>
<p>

**Abstract:** Chest radiography is the most common radiographic examination performed in daily clinical practice for the detection of various heart and lung abnormalities. The large amount of data to be read and reported, with more than 100 studies per day for a single radiologist, poses a challenge in consistently maintaining high interpretation accuracy. The introduction of large-scale public datasets has led to a series of novel systems for automated abnormality classification. However, the labels of these datasets were obtained using natural language processed medical reports, yielding a large degree of label noise that can impact the performance. In this study, we propose novel training strategies that handle label noise from such suboptimal data. Prior label probabilities were measured on a subset of training data re-read by 4 board-certified radiologists and were used during training to increase the robustness of the training model to the label noise. Furthermore, we exploit the high comorbidity of abnormalities observed in chest radiography and incorporate this information to further reduce the impact of label noise. Additionally, anatomical knowledge is incorporated by training the system to predict lung and heart segmentation, as well as spatial knowledge labels. To deal with multiple datasets and images derived from various scanners that apply different post-processing techniques, we introduce a novel image normalization strategy. Experiments were performed on an extensive collection of 297,541 chest radiographs from 86,876 patients, leading to a state-of-the-art performance level for 17 abnormalities from 2 datasets. With an average AUC score of 0.880 across all abnormalities, our proposed training strategies can be used to significantly improve performance scores.

</p>
</details>

<details><summary><b>VR3Dense: Voxel Representation Learning for 3D Object Detection and Monocular Dense Depth Reconstruction</b>
<a href="https://arxiv.org/abs/2104.05932">arxiv:2104.05932</a>
&#x1F4C8; 7 <br>
<p>Shubham Shrivastava</p></summary>
<p>

**Abstract:** 3D object detection and dense depth estimation are one of the most vital tasks in autonomous driving. Multiple sensor modalities can jointly attribute towards better robot perception, and to that end, we introduce a method for jointly training 3D object detection and monocular dense depth reconstruction neural networks. It takes as inputs, a LiDAR point-cloud, and a single RGB image during inference and produces object pose predictions as well as a densely reconstructed depth map. LiDAR point-cloud is converted into a set of voxels, and its features are extracted using 3D convolution layers, from which we regress object pose parameters. Corresponding RGB image features are extracted using another 2D convolutional neural network. We further use these combined features to predict a dense depth map. While our object detection is trained in a supervised manner, the depth prediction network is trained with both self-supervised and supervised loss functions. We also introduce a loss function, edge-preserving smooth loss, and show that this results in better depth estimation compared to the edge-aware smooth loss function, frequently used in depth prediction works.

</p>
</details>

<details><summary><b>On Representation Learning for Scientific News Articles Using Heterogeneous Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2104.05866">arxiv:2104.05866</a>
&#x1F4C8; 7 <br>
<p>Angelika Romanou, Panayiotis Smeros, Karl Aberer</p></summary>
<p>

**Abstract:** In the era of misinformation and information inflation, the credibility assessment of the produced news is of the essence. However, fact-checking can be challenging considering the limited references presented in the news. This challenge can be transcended by utilizing the knowledge graph that is related to the news articles. In this work, we present a methodology for creating scientific news article representations by modeling the directed graph between the scientific news articles and the cited scientific publications. The network used for the experiments is comprised of the scientific news articles, their topic, the cited research literature, and their corresponding authors. We implement and present three different approaches: 1) a baseline Relational Graph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network (HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models in the downstream task of link prediction on the: a) news article - paper links and b) news article - article topic links. The results show promising applications of graph neural network approaches in the domains of knowledge tracing and scientific news credibility assessment.

</p>
</details>

<details><summary><b>Consequence-aware Sequential Counterfactual Generation</b>
<a href="https://arxiv.org/abs/2104.05592">arxiv:2104.05592</a>
&#x1F4C8; 7 <br>
<p>Philip Naumann, Eirini Ntoutsi</p></summary>
<p>

**Abstract:** Counterfactuals have become a popular technique nowadays for interacting with black-box machine learning models and understanding how to change a particular instance to obtain a desired outcome from the model. However, most existing approaches assume instant materialization of these changes, ignoring that they may require effort and a specific order of application. Recently, methods have been proposed that also consider the order in which actions are applied, leading to the so-called sequential counterfactual generation problem.
  In this work, we propose a model-agnostic method for sequential counterfactual generation. We formulate the task as a multi-objective optimization problem and present a genetic algorithm approach to find optimal sequences of actions leading to the counterfactuals. Our cost model considers not only the direct effect of an action, but also its consequences. Experimental results show that compared to state-of-the-art, our approach generates less costly solutions, is more efficient and provides the user with a diverse set of solutions to choose from.

</p>
</details>

<details><summary><b>Continual Learning for Text Classification with Information Disentanglement Based Regularization</b>
<a href="https://arxiv.org/abs/2104.05489">arxiv:2104.05489</a>
&#x1F4C8; 7 <br>
<p>Yufan Huang, Yanzhe Zhang, Jiaao Chen, Xuezhi Wang, Diyi Yang</p></summary>
<p>

**Abstract:** Continual learning has become increasingly important as it enables NLP models to constantly learn and gain knowledge over time. Previous continual learning methods are mainly designed to preserve knowledge from previous tasks, without much emphasis on how to well generalize models to new tasks. In this work, we propose an information disentanglement based regularization method for continual learning on text classification. Our proposed method first disentangles text hidden spaces into representations that are generic to all tasks and representations specific to each individual task, and further regularizes these representations differently to better constrain the knowledge required to generalize. We also introduce two simple auxiliary tasks: next sentence prediction and task-id prediction, for learning better generic and specific representation spaces. Experiments conducted on large-scale benchmarks demonstrate the effectiveness of our method in continual text classification tasks with various sequences and lengths over state-of-the-art baselines. We have publicly released our code at https://github.com/GT-SALT/IDBR.

</p>
</details>

<details><summary><b>A Fast Evidential Approach for Stock Forecasting</b>
<a href="https://arxiv.org/abs/2104.05204">arxiv:2104.05204</a>
&#x1F4C8; 7 <br>
<p>Tianxiang Zhan, Fuyuan Xiao</p></summary>
<p>

**Abstract:** Within the framework of evidence theory, the confidence functions of different information can be combined into a combined confidence function to solve uncertain problems. The Dempster combination rule is a classic method of fusing different information. This paper proposes a similar confidence function for the time point in the time series. The Dempster combination rule can be used to fuse the growth rate of the last time point, and finally a relatively accurate forecast data can be obtained. Stock price forecasting is a concern of economics. The stock price data is large in volume, and more accurate forecasts are required at the same time. The classic methods of time series, such as ARIMA, cannot balance forecasting efficiency and forecasting accuracy at the same time. In this paper, the fusion method of evidence theory is applied to stock price prediction. Evidence theory deals with the uncertainty of stock price prediction and improves the accuracy of prediction. At the same time, the fusion method of evidence theory has low time complexity and fast prediction processing speed.

</p>
</details>

<details><summary><b>From partners to populations: A hierarchical Bayesian account of coordination and convention</b>
<a href="https://arxiv.org/abs/2104.05857">arxiv:2104.05857</a>
&#x1F4C8; 6 <br>
<p>Robert D. Hawkins, Michael Franke, Michael C. Frank, Adele E. Goldberg, Kenny Smith, Thomas L. Griffiths, Noah D. Goodman</p></summary>
<p>

**Abstract:** Languages are powerful solutions to coordination problems: they provide stable, shared expectations about how the words we say correspond to the beliefs and intentions in our heads. Yet language use in a variable and non-stationary social environment requires linguistic representations to be flexible: old words acquire new ad hoc or partner-specific meanings on the fly. In this paper, we introduce CHAI (Continual Hierarchical Adaptation through Inference), a hierarchical Bayesian theory of coordination and convention formation that aims to reconcile the long-standing tension between these two basic observations. We argue that the central computational problem of communication is not simply transmission, as in classical formulations, but continual learning and adaptation over multiple timescales. Partner-specific common ground quickly emerges from social inferences within dyadic interactions, while community-wide social conventions are stable priors that have been abstracted away from interactions with multiple partners. We present new empirical data alongside simulations showing how our model provides a computational foundation for several phenomena that have posed a challenge for previous accounts: (1) the convergence to more efficient referring expressions across repeated interaction with the same partner, (2) the gradual transfer of partner-specific common ground to strangers, and (3) the influence of communicative context on which conventions eventually form.

</p>
</details>

<details><summary><b>Noether: The More Things Change, the More Stay the Same</b>
<a href="https://arxiv.org/abs/2104.05508">arxiv:2104.05508</a>
&#x1F4C8; 6 <br>
<p>Grzegorz GÅuch, RÃ¼diger Urbanke</p></summary>
<p>

**Abstract:** Symmetries have proven to be important ingredients in the analysis of neural networks. So far their use has mostly been implicit or seemingly coincidental.
  We undertake a systematic study of the role that symmetry plays. In particular, we clarify how symmetry interacts with the learning algorithm. The key ingredient in our study is played by Noether's celebrated theorem which, informally speaking, states that symmetry leads to conserved quantities (e.g., conservation of energy or conservation of momentum). In the realm of neural networks under gradient descent, model symmetries imply restrictions on the gradient path. E.g., we show that symmetry of activation functions leads to boundedness of weight matrices, for the specific case of linear activations it leads to balance equations of consecutive layers, data augmentation leads to gradient paths that have "momentum"-type restrictions, and time symmetry leads to a version of the Neural Tangent Kernel.
  Symmetry alone does not specify the optimization path, but the more symmetries are contained in the model the more restrictions are imposed on the path. Since symmetry also implies over-parametrization, this in effect implies that some part of this over-parametrization is cancelled out by the existence of the conserved quantities.
  Symmetry can therefore be thought of as one further important tool in understanding the performance of neural networks under gradient descent.

</p>
</details>

<details><summary><b>Landmark Regularization: Ranking Guided Super-Net Training in Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2104.05309">arxiv:2104.05309</a>
&#x1F4C8; 6 <br>
<p>Kaicheng Yu, Rene Ranftl, Mathieu Salzmann</p></summary>
<p>

**Abstract:** Weight sharing has become a de facto standard in neural architecture search because it enables the search to be done on commodity hardware. However, recent works have empirically shown a ranking disorder between the performance of stand-alone architectures and that of the corresponding shared-weight networks. This violates the main assumption of weight-sharing NAS algorithms, thus limiting their effectiveness. We tackle this issue by proposing a regularization term that aims to maximize the correlation between the performance rankings of the shared-weight network and that of the standalone architectures using a small set of landmark architectures. We incorporate our regularization term into three different NAS algorithms and show that it consistently improves performance across algorithms, search-spaces, and tasks.

</p>
</details>

<details><summary><b>Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation</b>
<a href="https://arxiv.org/abs/2104.05232">arxiv:2104.05232</a>
&#x1F4C8; 6 <br>
<p>Chong Zhang, Jieyu Zhao, Huan Zhang, Kai-Wei Chang, Cho-Jui Hsieh</p></summary>
<p>

**Abstract:** Robustness and counterfactual bias are usually evaluated on a test dataset. However, are these evaluations robust? If the test dataset is perturbed slightly, will the evaluation results keep the same? In this paper, we propose a "double perturbation" framework to uncover model weaknesses beyond the test dataset. The framework first perturbs the test dataset to construct abundant natural sentences similar to the test data, and then diagnoses the prediction change regarding a single-word substitution. We apply this framework to study two perturbation-based approaches that are used to analyze models' robustness and counterfactual bias in English. (1) For robustness, we focus on synonym substitutions and identify vulnerable examples where prediction can be altered. Our proposed attack attains high success rates (96.0%-99.8%) in finding vulnerable examples on both original and robustly trained CNNs and Transformers. (2) For counterfactual bias, we focus on substituting demographic tokens (e.g., gender, race) and measure the shift of the expected prediction among constructed sentences. Our method is able to reveal the hidden model biases not directly shown in the test dataset. Our code is available at https://github.com/chong-z/nlp-second-order-attack.

</p>
</details>

<details><summary><b>GSA-Forecaster: Forecasting Graph-Based Time-Dependent Data with Graph Sequence Attention</b>
<a href="https://arxiv.org/abs/2104.05914">arxiv:2104.05914</a>
&#x1F4C8; 5 <br>
<p>Yang Li, Di Wang, JosÃ© M. F. Moura</p></summary>
<p>

**Abstract:** Forecasting graph-based time-dependent data has many practical applications. This task is challenging as models need not only to capture spatial dependency and temporal dependency within the data, but also to leverage useful auxiliary information for accurate predictions. In this paper, we analyze limitations of state-of-the-art models on dealing with temporal dependency. To address this limitation, we propose GSA-Forecaster, a new deep learning model for forecasting graph-based time-dependent data. GSA-Forecaster leverages graph sequence attention (GSA), a new attention mechanism proposed in this paper, for effectively capturing temporal dependency. GSA-Forecaster embeds the graph structure of the data into its architecture to address spatial dependency. GSA-Forecaster also accounts for auxiliary information to further improve predictions. We evaluate GSA-Forecaster with large-scale real-world graph-based time-dependent data and demonstrate its effectiveness over state-of-the-art models with 6.7% RMSE and 5.8% MAPE reduction.

</p>
</details>

<details><summary><b>Family of Origin and Family of Choice: Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Machine Translation</b>
<a href="https://arxiv.org/abs/2104.05848">arxiv:2104.05848</a>
&#x1F4C8; 5 <br>
<p>Zhong Zhou, Alex Waibel</p></summary>
<p>

**Abstract:** We translate a closed text that is known in advance into a severely low resource language by leveraging massive source parallelism. In other words, given a text in 124 source languages, we translate it into a severely low resource language using only ~1,000 lines of low resource data without any external help. Firstly, we propose a systematic method to rank and choose source languages that are close to the low resource language. We call the linguistic definition of language family Family of Origin (FAMO), and we call the empirical definition of higher-ranked languages using our metrics Family of Choice (FAMC). Secondly, we build an Iteratively Pretrained Multilingual Order-preserving Lexiconized Transformer (IPML) to train on ~1,000 lines (~3.5%) of low resource data. To translate named entities correctly, we build a massive lexicon table for 2,939 Bible named entities in 124 source languages, and include many that occur once and covers more than 66 severely low resource languages. Moreover, we also build a novel method of combining translations from different source languages into one. Using English as a hypothetical low resource language, we get a +23.9 BLEU increase over a multilingual baseline, and a +10.3 BLEU increase over our asymmetric baseline in the Bible dataset. We get a 42.8 BLEU score for Portuguese-English translation on the medical EMEA dataset. We also have good results for a real severely low resource Mayan language, Eastern Pokomchi.

</p>
</details>

<details><summary><b>Does My Representation Capture X? Probe-Ably</b>
<a href="https://arxiv.org/abs/2104.05807">arxiv:2104.05807</a>
&#x1F4C8; 5 <br>
<p>Deborah Ferreira, Julia Rozanova, Mokanarangan Thayaparan, Marco Valentino, AndrÃ© Freitas</p></summary>
<p>

**Abstract:** Probing (or diagnostic classification) has become a popular strategy for investigating whether a given set of intermediate features is present in the representations of neural models. Probing studies may have misleading results, but various recent works have suggested more reliable methodologies that compensate for the possible pitfalls of probing. However, these best practices are numerous and fast-evolving. To simplify the process of running a set of probing experiments in line with suggested methodologies, we introduce Probe-Ably: an extendable probing framework which supports and automates the application of probing methods to the user's inputs.

</p>
</details>

<details><summary><b>Understanding Overparameterization in Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2104.05605">arxiv:2104.05605</a>
&#x1F4C8; 5 <br>
<p>Yogesh Balaji, Mohammadmahdi Sajedi, Neha Mukund Kalibhat, Mucong Ding, Dominik StÃ¶ger, Mahdi Soltanolkotabi, Soheil Feizi</p></summary>
<p>

**Abstract:** A broad class of unsupervised deep learning methods such as Generative Adversarial Networks (GANs) involve training of overparameterized models where the number of parameters of the model exceeds a certain threshold. A large body of work in supervised learning have shown the importance of model overparameterization in the convergence of the gradient descent (GD) to globally optimal solutions. In contrast, the unsupervised setting and GANs in particular involve non-convex concave mini-max optimization problems that are often trained using Gradient Descent/Ascent (GDA). The role and benefits of model overparameterization in the convergence of GDA to a global saddle point in non-convex concave problems is far less understood. In this work, we present a comprehensive analysis of the importance of model overparameterization in GANs both theoretically and empirically. We theoretically show that in an overparameterized GAN model with a $1$-layer neural network generator and a linear discriminator, GDA converges to a global saddle point of the underlying non-convex concave min-max problem. To the best of our knowledge, this is the first result for global convergence of GDA in such settings. Our theory is based on a more general result that holds for a broader class of nonlinear generators and discriminators that obey certain assumptions (including deeper generators and random feature discriminators). We also empirically study the role of model overparameterization in GANs using several large-scale experiments on CIFAR-10 and Celeb-A datasets. Our experiments show that overparameterization improves the quality of generated samples across various model architectures and datasets. Remarkably, we observe that overparameterization leads to faster and more stable convergence behavior of GDA across the board.

</p>
</details>

<details><summary><b>A-FMI: Learning Attributions from Deep Networks via Feature Map Importance</b>
<a href="https://arxiv.org/abs/2104.05527">arxiv:2104.05527</a>
&#x1F4C8; 5 <br>
<p>An Zhang, Xiang Wang, Chengfang Fang, Jie Shi, Tat-seng Chua, Zehua Chen</p></summary>
<p>

**Abstract:** Gradient-based attribution methods can aid in the understanding of convolutional neural networks (CNNs). However, the redundancy of attribution features and the gradient saturation problem, which weaken the ability to identify significant features and cause an explanation focus shift, are challenges that attribution methods still face. In this work, we propose: 1) an essential characteristic, Strong Relevance, when selecting attribution features; 2) a new concept, feature map importance (FMI), to refine the contribution of each feature map, which is faithful to the CNN model; and 3) a novel attribution method via FMI, termed A-FMI, to address the gradient saturation problem, which couples the target image with a reference image, and assigns the FMI to the difference-from-reference at the granularity of feature map. Through visual inspections and qualitative evaluations on the ImageNet dataset, we show the compelling advantages of A-FMI on its faithfulness, insensitivity to the choice of reference, class discriminability, and superior explanation performance compared with popular attribution methods across varying CNN architectures.

</p>
</details>

<details><summary><b>Unsuitability of NOTEARS for Causal Graph Discovery</b>
<a href="https://arxiv.org/abs/2104.05441">arxiv:2104.05441</a>
&#x1F4C8; 5 <br>
<p>Marcus Kaiser, Maksim Sipos</p></summary>
<p>

**Abstract:** Causal Discovery methods aim to identify a DAG structure that represents causal relationships from observational data. In this article, we stress that it is important to test such methods for robustness in practical settings. As our main example, we analyze the NOTEARS method, for which we demonstrate a lack of scale-invariance. We show that NOTEARS is a method that aims to identify a parsimonious DAG from the data that explains the residual variance. We conclude that NOTEARS is not suitable for identifying truly causal relationships from the data.

</p>
</details>

<details><summary><b>All Labels Are Not Created Equal: Enhancing Semi-supervision via Label Grouping and Co-training</b>
<a href="https://arxiv.org/abs/2104.05248">arxiv:2104.05248</a>
&#x1F4C8; 5 <br>
<p>Islam Nassar, Samitha Herath, Ehsan Abbasnejad, Wray Buntine, Gholamreza Haffari</p></summary>
<p>

**Abstract:** Pseudo-labeling is a key component in semi-supervised learning (SSL). It relies on iteratively using the model to generate artificial labels for the unlabeled data to train against. A common property among its various methods is that they only rely on the model's prediction to make labeling decisions without considering any prior knowledge about the visual similarity among the classes. In this paper, we demonstrate that this degrades the quality of pseudo-labeling as it poorly represents visually similar classes in the pool of pseudo-labeled data. We propose SemCo, a method which leverages label semantics and co-training to address this problem. We train two classifiers with two different views of the class labels: one classifier uses the one-hot view of the labels and disregards any potential similarity among the classes, while the other uses a distributed view of the labels and groups potentially similar classes together. We then co-train the two classifiers to learn based on their disagreements. We show that our method achieves state-of-the-art performance across various SSL tasks including 5.6% accuracy improvement on Mini-ImageNet dataset with 1000 labeled examples. We also show that our method requires smaller batch size and fewer training iterations to reach its best performance. We make our code available at https://github.com/islam-nassar/semco.

</p>
</details>

<details><summary><b>FUDGE: Controlled Text Generation With Future Discriminators</b>
<a href="https://arxiv.org/abs/2104.05218">arxiv:2104.05218</a>
&#x1F4C8; 5 <br>
<p>Kevin Yang, Dan Klein</p></summary>
<p>

**Abstract:** We propose Future Discriminators for Generation (FUDGE), a flexible and modular method for controlled text generation. Given a pre-existing model G for generating text from a distribution of interest, FUDGE enables conditioning on a desired attribute a (for example, formality) while requiring access only to G's output logits. FUDGE learns an attribute predictor operating on a partial sequence, and uses this predictor's outputs to adjust G's original probabilities. We show that FUDGE models terms corresponding to a Bayesian decomposition of the conditional distribution of G given attribute a. Moreover, FUDGE can easily compose predictors for multiple desired attributes. We evaluate FUDGE on three tasks -- couplet completion in poetry, topic control in language generation, and formality change in machine translation -- and observe gains in all three tasks.

</p>
</details>

<details><summary><b>What Is Consciousness? Artificial Intelligence, Real Intelligence, Quantum Mind, And Qualia</b>
<a href="https://arxiv.org/abs/2106.15515">arxiv:2106.15515</a>
&#x1F4C8; 4 <br>
<p>Stuart A. Kauffman, Andrea Roli</p></summary>
<p>

**Abstract:** We approach the question "What is Consciousness?" in a new way, not as Descartes' "systematic doubt", but as how organisms find their way in their world. Finding one's way involves finding possible uses of features of the world that might be beneficial or avoiding those that might be harmful. "Possible uses of X to accomplish Y" are "Affordances". The number of uses of X is indefinite (or unknown), the different uses are unordered and are not deducible from one another. All biological adaptations are either affordances seized by heritable variation and selection or, far faster, by the organism acting in its world finding uses of X to accomplish Y. Based on this, we reach rather astonishing conclusions: (1) Artificial General Intelligence based on Universal Turing Machines (UTMs) is not possible, since UTMs cannot "find" novel affordances. (2) Brain-mind is not purely classical physics for no classical physics system can be an analogue computer whose dynamical behavior can be isomorphic to "possible uses". (3) Brain mind must be partly quantum - supported by increasing evidence at 6.0 sigma to 7.3 Sigma. (4) Based on Heisenberg's interpretation of the quantum state as "Potentia" converted to "Actuals" by Measurement, a natural hypothesis is that mind actualizes Potentia. This is supported at 5.2 Sigma. Then Mind's actualizations of entangled brain-mind-world states are experienced as qualia and allow "seeing" or "perceiving" of uses of X to accomplish Y. We can and do jury-rig. Computers cannot. (5) Beyond familiar quantum computers, we discuss the potentialities of Trans-Turing-Systems.

</p>
</details>

<details><summary><b>Semantic maps and metrics for science Semantic maps and metrics for science using deep transformer encoders</b>
<a href="https://arxiv.org/abs/2104.05928">arxiv:2104.05928</a>
&#x1F4C8; 4 <br>
<p>Brendan Chambers, James Evans</p></summary>
<p>

**Abstract:** The growing deluge of scientific publications demands text analysis tools that can help scientists and policy-makers navigate, forecast and beneficially guide scientific research. Recent advances in natural language understanding driven by deep transformer networks offer new possibilities for mapping science. Because the same surface text can take on multiple and sometimes contradictory specialized senses across distinct research communities, sensitivity to context is critical for infometric applications. Transformer embedding models such as BERT capture shades of association and connotation that vary across the different linguistic contexts of any particular word or span of text. Here we report a procedure for encoding scientific documents with these tools, measuring their improvement over static word embeddings in a nearest-neighbor retrieval task. We find discriminability of contextual representations is strongly influenced by choice of pooling strategy for summarizing the high-dimensional network activations. Importantly, we note that fundamentals such as domain-matched training data are more important than state-of-the-art NLP tools. Yet state-of-the-art models did offer significant gains. The best approach we investigated combined domain-matched pretraining, sound pooling, and state-of-the-art deep transformer network encoders. Finally, with the goal of leveraging contextual representations from deep encoders, we present a range of measurements for understanding and forecasting research communities in science.

</p>
</details>

<details><summary><b>Towards Extremely Compact RNNs for Video Recognition with Fully Decomposed Hierarchical Tucker Structure</b>
<a href="https://arxiv.org/abs/2104.05758">arxiv:2104.05758</a>
&#x1F4C8; 4 <br>
<p>Miao Yin, Siyu Liao, Xiao-Yang Liu, Xiaodong Wang, Bo Yuan</p></summary>
<p>

**Abstract:** Recurrent Neural Networks (RNNs) have been widely used in sequence analysis and modeling. However, when processing high-dimensional data, RNNs typically require very large model sizes, thereby bringing a series of deployment challenges. Although various prior works have been proposed to reduce the RNN model sizes, executing RNN models in resource-restricted environments is still a very challenging problem. In this paper, we propose to develop extremely compact RNN models with fully decomposed hierarchical Tucker (FDHT) structure. The HT decomposition does not only provide much higher storage cost reduction than the other tensor decomposition approaches but also brings better accuracy performance improvement for the compact RNN models. Meanwhile, unlike the existing tensor decomposition-based methods that can only decompose the input-to-hidden layer of RNNs, our proposed fully decomposition approach enables the comprehensive compression for the entire RNN models with maintaining very high accuracy. Our experimental results on several popular video recognition datasets show that our proposed fully decomposed hierarchical tucker-based LSTM (FDHT-LSTM) is extremely compact and highly efficient. To the best of our knowledge, FDHT-LSTM, for the first time, consistently achieves very high accuracy with only few thousand parameters (3,132 to 8,808) on different datasets. Compared with the state-of-the-art compressed RNN models, such as TT-LSTM, TR-LSTM and BT-LSTM, our FDHT-LSTM simultaneously enjoys both order-of-magnitude (3,985x to 10,711x) fewer parameters and significant accuracy improvement (0.6% to 12.7%).

</p>
</details>

<details><summary><b>Towards a parallel corpus of Portuguese and the Bantu language Emakhuwa of Mozambique</b>
<a href="https://arxiv.org/abs/2104.05753">arxiv:2104.05753</a>
&#x1F4C8; 4 <br>
<p>Felermino D. M. A. Ali, Andrew Caines, Jaimito L. A. Malavi</p></summary>
<p>

**Abstract:** Major advancement in the performance of machine translation models has been made possible in part thanks to the availability of large-scale parallel corpora. But for most languages in the world, the existence of such corpora is rare. Emakhuwa, a language spoken in Mozambique, is like most African languages low-resource in NLP terms. It lacks both computational and linguistic resources and, to the best of our knowledge, few parallel corpora including Emakhuwa already exist. In this paper we describe the creation of the Emakhuwa-Portuguese parallel corpus, which is a collection of texts from the Jehovah's Witness website and a variety of other sources including the African Story Book website, the Universal Declaration of Human Rights and Mozambican legal documents. The dataset contains 47,415 sentence pairs, amounting to 699,976 word tokens of Emakhuwa and 877,595 word tokens in Portuguese. After normalization processes which remain to be completed, the corpus will be made freely available for research use.

</p>
</details>

<details><summary><b>PAC Bayesian Performance Guarantees for Deep (Stochastic) Networks in Medical Imaging</b>
<a href="https://arxiv.org/abs/2104.05600">arxiv:2104.05600</a>
&#x1F4C8; 4 <br>
<p>Anthony Sicilia, Xingchen Zhao, Anastasia Sosnovskikh, Seong Jae Hwang</p></summary>
<p>

**Abstract:** Application of deep neural networks to medical imaging tasks has in some sense become commonplace. Still, a "thorn in the side" of the deep learning movement is the argument that deep networks are prone to overfitting and are thus unable to generalize well when datasets are small (as is common in medical imaging tasks). One way to bolster confidence is to provide mathematical guarantees, or bounds, on network performance after training which explicitly quantify the possibility of overfitting. In this work, we explore recent advances using the PAC-Bayesian framework to provide bounds on generalization error for large (stochastic) networks. While previous efforts focus on classification in larger natural image datasets (e.g., MNIST and CIFAR-10), we apply these techniques to both classification and segmentation in a smaller medical imagining dataset: the ISIC 2018 challenge set. We observe the resultant bounds are competitive compared to a simpler baseline, while also being more explainable and alleviating the need for holdout sets.

</p>
</details>

<details><summary><b>L3DAS21 Challenge: Machine Learning for 3D Audio Signal Processing</b>
<a href="https://arxiv.org/abs/2104.05499">arxiv:2104.05499</a>
&#x1F4C8; 4 <br>
<p>Eric Guizzo, Riccardo F. Gramaccioni, Saeid Jamili, Christian Marinoni, Edoardo Massaro, Claudia Medaglia, Giuseppe Nachira, Leonardo Nucciarelli, Ludovica Paglialunga, Marco Pennese, Sveva Pepe, Enrico Rocchi, Aurelio Uncini, Danilo Comminiello</p></summary>
<p>

**Abstract:** The L3DAS21 Challenge is aimed at encouraging and fostering collaborative research on machine learning for 3D audio signal processing, with particular focus on 3D speech enhancement (SE) and 3D sound localization and detection (SELD). Alongside with the challenge, we release the L3DAS21 dataset, a 65 hours 3D audio corpus, accompanied with a Python API that facilitates the data usage and results submission stage. Usually, machine learning approaches to 3D audio tasks are based on single-perspective Ambisonics recordings or on arrays of single-capsule microphones. We propose, instead, a novel multichannel audio configuration based multiple-source and multiple-perspective Ambisonics recordings, performed with an array of two first-order Ambisonics microphones. To the best of our knowledge, it is the first time that a dual-mic Ambisonics configuration is used for these tasks. We provide baseline models and results for both tasks, obtained with state-of-the-art architectures: FaSNet for SE and SELDNet for SELD. This report is aimed at providing all needed information to participate in the L3DAS21 Challenge, illustrating the details of the L3DAS21 dataset, the challenge tasks and the baseline models.

</p>
</details>

<details><summary><b>A Conceptual Framework for Establishing Trust in Real World Intelligent Systems</b>
<a href="https://arxiv.org/abs/2104.05432">arxiv:2104.05432</a>
&#x1F4C8; 4 <br>
<p>Michael Guckert, Nils Gumpfer, Jennifer Hannig, Till Keller, Neil Urquhart</p></summary>
<p>

**Abstract:** Intelligent information systems that contain emergent elements often encounter trust problems because results do not get sufficiently explained and the procedure itself can not be fully retraced. This is caused by a control flow depending either on stochastic elements or on the structure and relevance of the input data. Trust in such algorithms can be established by letting users interact with the system so that they can explore results and find patterns that can be compared with their expected solution. Reflecting features and patterns of human understanding of a domain against algorithmic results can create awareness of such patterns and may increase the trust that a user has in the solution. If expectations are not met, close inspection can be used to decide whether a solution conforms to the expectations or whether it goes beyond the expected. By either accepting or rejecting a solution, the user's set of expectations evolves and a learning process for the users is established. In this paper we present a conceptual framework that reflects and supports this process. The framework is the result of an analysis of two exemplary case studies from two different disciplines with information systems that assist experts in their complex tasks.

</p>
</details>

<details><summary><b>Better Feature Integration for Named Entity Recognition</b>
<a href="https://arxiv.org/abs/2104.05316">arxiv:2104.05316</a>
&#x1F4C8; 4 <br>
<p>Lu Xu, Zhanming Jie, Wei Lu, Lidong Bing</p></summary>
<p>

**Abstract:** It has been shown that named entity recognition (NER) could benefit from incorporating the long-distance structured information captured by dependency trees. We believe this is because both types of features - the contextual information captured by the linear sequences and the structured information captured by the dependency trees may complement each other. However, existing approaches largely focused on stacking the LSTM and graph neural networks such as graph convolutional networks (GCNs) for building improved NER models, where the exact interaction mechanism between the two types of features is not very clear, and the performance gain does not appear to be significant. In this work, we propose a simple and robust solution to incorporate both types of features with our Synergized-LSTM (Syn-LSTM), which clearly captures how the two types of features interact. We conduct extensive experiments on several standard datasets across four languages. The results demonstrate that the proposed model achieves better performance than previous approaches while requiring fewer parameters. Our further analysis demonstrates that our model can capture longer dependencies compared with strong baselines.

</p>
</details>

<details><summary><b>BERT based freedom to operate patent analysis</b>
<a href="https://arxiv.org/abs/2105.00817">arxiv:2105.00817</a>
&#x1F4C8; 3 <br>
<p>Michael Freunek, AndrÃ© Bodmer</p></summary>
<p>

**Abstract:** In this paper we present a method to apply BERT to freedom to operate patent analysis and patent searches. According to the method, BERT is fine-tuned by training patent descriptions to the independent claims. Each description represents an invention which is protected by the corresponding claims. Such a trained BERT could be able to identify or order freedom to operate relevant patents based on a short description of an invention or product. We tested the method by training BERT on the patent class G06T1/00 and applied the trained BERT on five inventions classified in G06T1/60, described via DOCDB abstracts. The DOCDB abstract are available on ESPACENET of the European Patent Office.

</p>
</details>

<details><summary><b>COVID-19 detection using chest X-rays: is lung segmentation important for generalization?</b>
<a href="https://arxiv.org/abs/2104.06176">arxiv:2104.06176</a>
&#x1F4C8; 3 <br>
<p>Pedro R. A. S. Bassi, Romis Attux</p></summary>
<p>

**Abstract:** We evaluated the generalization capability of deep neural networks (DNNs), trained to classify chest X-rays as COVID-19, normal or pneumonia, using a relatively small and mixed dataset. We proposed a DNN to perform lung segmentation and classification, stacking a segmentation module (U-Net), an original intermediate module and a classification module (DenseNet201). To evaluate generalization, we tested the DNN with an external dataset (from distinct localities) and used Bayesian inference to estimate probability distributions of performance metrics. Our DNN achieved 0.917 AUC on the external test dataset, and a DenseNet without segmentation, 0.906. Bayesian inference indicated mean accuracy of 76.1% and [0.695, 0.826] 95% HDI (high density interval, which concentrates 95% of the metric's probability mass) with segmentation and, without segmentation, 71.7% and [0.646, 0.786]. We proposed a novel DNN evaluation technique, using Layer-wise Relevance Propagation (LRP) and Brixia scores. LRP heatmaps indicated that areas where radiologists found strong COVID-19 symptoms and attributed high Brixia scores are the most important for the stacked DNN classification. External validation showed smaller accuracies than internal, indicating difficulty in generalization, which segmentation improves. Performance in the external dataset and LRP analysis suggest that DNNs can be trained in small and mixed datasets and detect COVID-19.

</p>
</details>

<details><summary><b>Revisiting Bayesian Autoencoders with MCMC</b>
<a href="https://arxiv.org/abs/2104.05915">arxiv:2104.05915</a>
&#x1F4C8; 3 <br>
<p>Rohitash Chandra, Mahir Jain, Manavendra Maharana, Pavel N. Krivitsky</p></summary>
<p>

**Abstract:** Autoencoders gained popularity in the deep learning revolution given their ability to compress data and provide dimensionality reduction. Although prominent deep learning methods have been used to enhance autoencoders, the need to provide robust uncertainty quantification remains a challenge. This has been addressed with variational autoencoders so far. Bayesian inference via MCMC methods have faced limitations but recent advances with parallel computing and advanced proposal schemes that incorporate gradients have opened routes less travelled. In this paper, we present Bayesian autoencoders powered MCMC sampling implemented using parallel computing and Langevin gradient proposal scheme. Our proposed Bayesian autoencoder provides similar performance accuracy when compared to related methods from the literature, with the additional feature of robust uncertainty quantification in compressed datasets. This motivates further application of the Bayesian autoencoder framework for other deep learning models.

</p>
</details>

<details><summary><b>On the Linear Ordering Problem and the Rankability of Data</b>
<a href="https://arxiv.org/abs/2104.05816">arxiv:2104.05816</a>
&#x1F4C8; 3 <br>
<p>Thomas R. Cameron, Sebastian Charmot, Jonad Pulaj</p></summary>
<p>

**Abstract:** In 2019, Anderson et al. proposed the concept of rankability, which refers to a dataset's inherent ability to be meaningfully ranked. In this article, we give an expository review of the linear ordering problem (LOP) and then use it to analyze the rankability of data. Specifically, the degree of linearity is used to quantify what percentage of the data aligns with an optimal ranking. In a sports context, this is analogous to the number of games that a ranking can correctly predict in hindsight. In fact, under the appropriate objective function, we show that the optimal rankings computed via the LOP maximize the hindsight accuracy of a ranking. Moreover, we develop a binary program to compute the maximal Kendall tau ranking distance between two optimal rankings, which can be used to measure the diversity among optimal rankings without having to enumerate all optima. Finally, we provide several examples from the world of sports and college rankings to illustrate these concepts and demonstrate our results.

</p>
</details>

<details><summary><b>Censored Semi-Bandits for Resource Allocation</b>
<a href="https://arxiv.org/abs/2104.05781">arxiv:2104.05781</a>
&#x1F4C8; 3 <br>
<p>Arun Verma, Manjesh K. Hanawal, Arun Rajkumar, Raman Sankaran</p></summary>
<p>

**Abstract:** We consider the problem of sequentially allocating resources in a censored semi-bandits setup, where the learner allocates resources at each step to the arms and observes loss. The loss depends on two hidden parameters, one specific to the arm but independent of the resource allocation, and the other depends on the allocated resource. More specifically, the loss equals zero for an arm if the resource allocated to it exceeds a constant (but unknown) arm dependent threshold. The goal is to learn a resource allocation that minimizes the expected loss. The problem is challenging because the loss distribution and threshold value of each arm are unknown. We study this setting by establishing its `equivalence' to Multiple-Play Multi-Armed Bandits (MP-MAB) and Combinatorial Semi-Bandits. Exploiting these equivalences, we derive optimal algorithms for our problem setting using known algorithms for MP-MAB and Combinatorial Semi-Bandits. The experiments on synthetically generated data validate the performance guarantees of the proposed algorithms.

</p>
</details>

<details><summary><b>Efficient Space-time Video Super Resolution using Low-Resolution Flow and Mask Upsampling</b>
<a href="https://arxiv.org/abs/2104.05778">arxiv:2104.05778</a>
&#x1F4C8; 3 <br>
<p>Saikat Dutta, Nisarg A. Shah, Anurag Mittal</p></summary>
<p>

**Abstract:** This paper explores an efficient solution for Space-time Super-Resolution, aiming to generate High-resolution Slow-motion videos from Low Resolution and Low Frame rate videos. A simplistic solution is the sequential running of Video Super Resolution and Video Frame interpolation models. However, this type of solutions are memory inefficient, have high inference time, and could not make the proper use of space-time relation property. To this extent, we first interpolate in LR space using quadratic modeling. Input LR frames are super-resolved using a state-of-the-art Video Super-Resolution method. Flowmaps and blending mask which are used to synthesize LR interpolated frame is reused in HR space using bilinear upsampling. This leads to a coarse estimate of HR intermediate frame which often contains artifacts along motion boundaries. We use a refinement network to improve the quality of HR intermediate frame via residual learning. Our model is lightweight and performs better than current state-of-the-art models in REDS STSR Validation set.

</p>
</details>

<details><summary><b>Unsupervised Lane-Change Identification for On-Ramp Merge Analysis in Naturalistic Driving Data</b>
<a href="https://arxiv.org/abs/2104.05661">arxiv:2104.05661</a>
&#x1F4C8; 3 <br>
<p>Lars Klitzke, Kay Gimm, Carsten Koch, Frank KÃ¶ster</p></summary>
<p>

**Abstract:** Connected and Automated Vehicles (CAVs) are envisioned to transform the future industrial and private transportation sectors. Due to the complexity of the systems, functional verification and validation of safety aspects are essential before the technology merges into the public domain. In recent years, a scenario-driven approach has gained acceptance for CAVs emphasizing the requirement of a solid data basis of scenarios. The large-scale research facility Test Bed Lower Saxony (TFNDS) enables the provision of substantial information for a database of scenarios on motorways. For that purpose, however, the scenarios of interest must be identified and categorized in the collected trajectory data. This work addresses this problem and proposes a framework for on-ramp scenario identification that also enables for scenario categorization and assessment. The efficacy of the framework is shown with a dataset collected on the TFNDS.

</p>
</details>

<details><summary><b>Fruit Quality and Defect Image Classification with Conditional GAN Data Augmentation</b>
<a href="https://arxiv.org/abs/2104.05647">arxiv:2104.05647</a>
&#x1F4C8; 3 <br>
<p>Jordan J. Bird, Chloe M. Barnes, Luis J. Manso, AnikÃ³ EkÃ¡rt, Diego R. Faria</p></summary>
<p>

**Abstract:** Contemporary Artificial Intelligence technologies allow for the employment of Computer Vision to discern good crops from bad, providing a step in the pipeline of selecting healthy fruit from undesirable fruit, such as those which are mouldy or gangrenous. State-of-the-art works in the field report high accuracy results on small datasets (<1000 images), which are not representative of the population regarding real-world usage. The goals of this study are to further enable real-world usage by improving generalisation with data augmentation as well as to reduce overfitting and energy usage through model pruning. In this work, we suggest a machine learning pipeline that combines the ideas of fine-tuning, transfer learning, and generative model-based training data augmentation towards improving fruit quality image classification. A linear network topology search is performed to tune a VGG16 lemon quality classification model using a publicly-available dataset of 2690 images. We find that appending a 4096 neuron fully connected layer to the convolutional layers leads to an image classification accuracy of 83.77%. We then train a Conditional Generative Adversarial Network on the training data for 2000 epochs, and it learns to generate relatively realistic images. Grad-CAM analysis of the model trained on real photographs shows that the synthetic images can exhibit classifiable characteristics such as shape, mould, and gangrene. A higher image classification accuracy of 88.75% is then attained by augmenting the training with synthetic images, arguing that Conditional Generative Adversarial Networks have the ability to produce new data to alleviate issues of data scarcity. Finally, model pruning is performed via polynomial decay, where we find that the Conditional GAN-augmented classification network can retain 81.16% classification accuracy when compressed to 50% of its original size.

</p>
</details>

<details><summary><b>Survey on reinforcement learning for language processing</b>
<a href="https://arxiv.org/abs/2104.05565">arxiv:2104.05565</a>
&#x1F4C8; 3 <br>
<p>Victor Uc-Cetina, Nicolas Navarro-Guerrero, Anabel Martin-Gonzalez, Cornelius Weber, Stefan Wermter</p></summary>
<p>

**Abstract:** In recent years some researchers have explored the use of reinforcement learning (RL) algorithms as key components in the solution of various natural language processing tasks. For instance, some of these algorithms leveraging deep neural learning have found their way into conversational systems. This paper reviews the state of the art of RL methods for their possible use for different problems of natural language processing, focusing primarily on conversational systems, mainly due to their growing relevance. We provide detailed descriptions of the problems as well as discussions of why RL is well-suited to solve them. Also, we analyze the advantages and limitations of these methods. Finally, we elaborate on promising research directions in natural language processing that might benefit from reinforcement learning.

</p>
</details>

<details><summary><b>Optimizing the Whole-life Cost in End-to-end CNN Acceleration</b>
<a href="https://arxiv.org/abs/2104.05541">arxiv:2104.05541</a>
&#x1F4C8; 3 <br>
<p>Jiaqi Zhang, Xiangru Chen, Sandip Ray</p></summary>
<p>

**Abstract:** The acceleration of CNNs has gained increasing atten-tion since their success in computer vision. With the heterogeneous functional layers that cannot be pro-cessed by the accelerators proposed for convolution layers only, modern end-to-end CNN acceleration so-lutions either transform the diverse computation into matrix/vector arithmetic, which loses data reuse op-portunities in convolution, or introduce dedicated functional unit to each kind of layer, which results in underutilization and high update expense. To enhance the whole-life cost efficiency, we need an acceleration solution that is efficient in processing CNN layers and has the generality to apply to all kinds of existing and emerging layers. To this end, we pro-pose GCONV Chain, a method to convert the entire CNN computation into a chain of standard general convolutions (GCONV) that can be efficiently pro-cessed by the existing CNN accelerators. This paper comprehensively analyzes the GCONV Chain model and proposes a full-stack implementation to support GCONV Chain. On one hand, the results on seven var-ious CNNs demonstrate that GCONV Chain improves the performance and energy efficiency of existing CNN accelerators by an average of 3.4x and 3.2x re-spectively. On the other hand, we show that GCONV Chain provides low whole-life costs for CNN accelera-tion, including both developer efforts and total cost of ownership for the users.

</p>
</details>

<details><summary><b>Updater-Extractor Architecture for Inductive World State Representations</b>
<a href="https://arxiv.org/abs/2104.05500">arxiv:2104.05500</a>
&#x1F4C8; 3 <br>
<p>Arseny Moskvichev, James A. Liu</p></summary>
<p>

**Abstract:** Developing NLP models traditionally involves two stages - training and application. Retention of information acquired after training (at application time) is architecturally limited by the size of the model's context window (in the case of transformers), or by the practical difficulties associated with long sequences (in the case of RNNs). In this paper, we propose a novel transformer-based Updater-Extractor architecture and a training procedure that can work with sequences of arbitrary length and refine its knowledge about the world based on linguistic inputs. We explicitly train the model to incorporate incoming information into its world state representation, obtaining strong inductive generalization and the ability to handle extremely long-range dependencies. We prove a lemma that provides a theoretical basis for our approach. The result also provides insight into success and failure modes of models trained with variants of Truncated Back-Propagation Through Time (such as Transformer XL). Empirically, we investigate the model performance on three different tasks, demonstrating its promise. This preprint is still a work in progress. At present, we focused on easily interpretable tasks, leaving the application of the proposed ideas to practical NLP applications for the future.

</p>
</details>

<details><summary><b>Sparse Coding Frontend for Robust Neural Networks</b>
<a href="https://arxiv.org/abs/2104.05353">arxiv:2104.05353</a>
&#x1F4C8; 3 <br>
<p>Can Bakiskan, Metehan Cekic, Ahmet Dundar Sezer, Upamanyu Madhow</p></summary>
<p>

**Abstract:** Deep Neural Networks are known to be vulnerable to small, adversarially crafted, perturbations. The current most effective defense methods against these adversarial attacks are variants of adversarial training. In this paper, we introduce a radically different defense trained only on clean images: a sparse coding based frontend which significantly attenuates adversarial attacks before they reach the classifier. We evaluate our defense on CIFAR-10 dataset under a wide range of attack types (including Linf , L2, and L1 bounded attacks), demonstrating its promise as a general-purpose approach for defense.

</p>
</details>

<details><summary><b>Distilling Wikipedia mathematical knowledge into neural network models</b>
<a href="https://arxiv.org/abs/2104.05930">arxiv:2104.05930</a>
&#x1F4C8; 2 <br>
<p>Joanne T. Kim, Mikel Landajuela Larma, Brenden K. Petersen</p></summary>
<p>

**Abstract:** Machine learning applications to symbolic mathematics are becoming increasingly popular, yet there lacks a centralized source of real-world symbolic expressions to be used as training data. In contrast, the field of natural language processing leverages resources like Wikipedia that provide enormous amounts of real-world textual data. Adopting the philosophy of "mathematics as language," we bridge this gap by introducing a pipeline for distilling mathematical expressions embedded in Wikipedia into symbolic encodings to be used in downstream machine learning tasks. We demonstrate that a $\textit{mathematical}$ $\textit{language}$ $\textit{model}$ trained on this "corpus" of expressions can be used as a prior to improve the performance of neural-guided search for the task of symbolic regression.

</p>
</details>

<details><summary><b>Thief, Beware of What Get You There: Towards Understanding Model Extraction Attack</b>
<a href="https://arxiv.org/abs/2104.05921">arxiv:2104.05921</a>
&#x1F4C8; 2 <br>
<p>Xinyi Zhang, Chengfang Fang, Jie Shi</p></summary>
<p>

**Abstract:** Model extraction increasingly attracts research attentions as keeping commercial AI models private can retain a competitive advantage. In some scenarios, AI models are trained proprietarily, where neither pre-trained models nor sufficient in-distribution data is publicly available. Model extraction attacks against these models are typically more devastating. Therefore, in this paper, we empirically investigate the behaviors of model extraction under such scenarios. We find the effectiveness of existing techniques significantly affected by the absence of pre-trained models. In addition, the impacts of the attacker's hyperparameters, e.g. model architecture and optimizer, as well as the utilities of information retrieved from queries, are counterintuitive. We provide some insights on explaining the possible causes of these phenomena. With these observations, we formulate model extraction attacks into an adaptive framework that captures these factors with deep reinforcement learning. Experiments show that the proposed framework can be used to improve existing techniques, and show that model extraction is still possible in such strict scenarios. Our research can help system designers to construct better defense strategies based on their scenarios.

</p>
</details>

<details><summary><b>Bi-level Off-policy Reinforcement Learning for Volt/VAR Control Involving Continuous and Discrete Devices</b>
<a href="https://arxiv.org/abs/2104.05902">arxiv:2104.05902</a>
&#x1F4C8; 2 <br>
<p>Haotian Liu, Wenchuan Wu</p></summary>
<p>

**Abstract:** In Volt/Var control (VVC) of active distribution networks(ADNs), both slow timescale discrete devices (STDDs) and fast timescale continuous devices (FTCDs) are involved. The STDDs such as on-load tap changers (OLTC) and FTCDs such as distributed generators should be coordinated in time sequence. Such VCC is formulated as a two-timescale optimization problem to jointly optimize FTCDs and STDDs in ADNs. Traditional optimization methods are heavily based on accurate models of the system, but sometimes impractical because of their unaffordable effort on modelling. In this paper, a novel bi-level off-policy reinforcement learning (RL) algorithm is proposed to solve this problem in a model-free manner. A Bi-level Markov decision process (BMDP) is defined to describe the two-timescale VVC problem and separate agents are set up for the slow and fast timescale sub-problems. For the fast timescale sub-problem, we adopt an off-policy RL method soft actor-critic with high sample efficiency. For the slow one, we develop an off-policy multi-discrete soft actor-critic (MDSAC) algorithm to address the curse of dimensionality with various STDDs. To mitigate the non-stationary issue existing the two agents' learning processes, we propose a multi-timescale off-policy correction (MTOPC) method by adopting importance sampling technique. Comprehensive numerical studies not only demonstrate that the proposed method can achieve stable and satisfactory optimization of both STDDs and FTCDs without any model information, but also support that the proposed method outperforms existing two-timescale VVC methods.

</p>
</details>

<details><summary><b>Unifying domain adaptation and self-supervised learning for CXR segmentation via AdaIN-based knowledge distillation</b>
<a href="https://arxiv.org/abs/2104.05892">arxiv:2104.05892</a>
&#x1F4C8; 2 <br>
<p>Yujin Oh, Jong Chul Ye</p></summary>
<p>

**Abstract:** As the segmentation labels are scarce, extensive researches have been conducted to train segmentation networks without labels or with only limited labels. In particular, domain adaptation, self-supervised learning, and teacher-student architecture have been introduced to distill knowledge from various tasks to improve the segmentation performance. However, these approaches appear different from each other, so it is not clear how these seemingly different approaches can be combined for better performance. Inspired by the recent StarGANv2 for multi-domain image translation, here we propose a novel segmentation framework via AdaIN-based knowledge distillation, where a single generator with AdaIN layers is trained along with the AdaIN code generator and style encoder so that the generator can perform both domain adaptation and segmentation. Specifically, our framework is designed to deal with difficult situations in chest X-ray (CXR) segmentation tasks where segmentation masks are only available for normal CXR data, but the trained model should be applied for both normal and abnormal CXR images. Since a single generator is used for abnormal to normal domain conversion and segmentation by simply changing the AdaIN codes, the generator can synergistically learn the common features to improve segmentation performance. Experimental results using CXR data confirm that the trained network can achieve the state-of-the art segmentation performance for both normal and abnormal CXR images.

</p>
</details>

<details><summary><b>CAPRI-Net: Learning Compact CAD Shapes with Adaptive Primitive Assembly</b>
<a href="https://arxiv.org/abs/2104.05652">arxiv:2104.05652</a>
&#x1F4C8; 2 <br>
<p>Fenggen Yu, Zhiqin Chen, Manyi Li, Aditya Sanghi, Hooman Shayani, Ali Mahdavi-Amiri, Hao Zhang</p></summary>
<p>

**Abstract:** We introduce CAPRI-Net, a neural network for learning compact and interpretable implicit representations of 3D computer-aided design (CAD) models, in the form of adaptive primitive assemblies. Our network takes an input 3D shape that can be provided as a point cloud or voxel grids, and reconstructs it by a compact assembly of quadric surface primitives via constructive solid geometry (CSG) operations. The network is self-supervised with a reconstruction loss, leading to faithful 3D reconstructions with sharp edges and plausible CSG trees, without any ground-truth shape assemblies. While the parametric nature of CAD models does make them more predictable locally, at the shape level, there is a great deal of structural and topological variations, which present a significant generalizability challenge to state-of-the-art neural models for 3D shapes. Our network addresses this challenge by adaptive training with respect to each test shape, with which we fine-tune the network that was pre-trained on a model collection. We evaluate our learning framework on both ShapeNet and ABC, the largest and most diverse CAD dataset to date, in terms of reconstruction quality, shape edges, compactness, and interpretability, to demonstrate superiority over current alternatives suitable for neural CAD reconstruction.

</p>
</details>

<details><summary><b>Equivariant geometric learning for digital rock physics: estimating formation factor and effective permeability tensors from Morse graph</b>
<a href="https://arxiv.org/abs/2104.05608">arxiv:2104.05608</a>
&#x1F4C8; 2 <br>
<p>Chen Cai, Nikolaos Vlassis, Lucas Magee, Ran Ma, Zeyu Xiong, Bahador Bahmani, Teng-Fong Wong, Yusu Wang, WaiChing Sun</p></summary>
<p>

**Abstract:** We present a SE(3)-equivariant graph neural network (GNN) approach that directly predicting the formation factor and effective permeability from micro-CT images. FFT solvers are established to compute both the formation factor and effective permeability, while the topology and geometry of the pore space are represented by a persistence-based Morse graph. Together, they constitute the database for training, validating, and testing the neural networks. While the graph and Euclidean convolutional approaches both employ neural networks to generate low-dimensional latent space to represent the features of the micro-structures for forward predictions, the SE(3) equivariant neural network is found to generate more accurate predictions, especially when the training data is limited. Numerical experiments have also shown that the new SE(3) approach leads to predictions that fulfill the material frame indifference whereas the predictions from classical convolutional neural networks (CNN) may suffer from spurious dependence on the coordinate system of the training data. Comparisons among predictions inferred from training the CNN and those from graph convolutional neural networks (GNN) with and without the equivariant constraint indicate that the equivariant graph neural network seems to perform better than the CNN and GNN without enforcing equivariant constraints.

</p>
</details>

<details><summary><b>Learning from Subjective Ratings Using Auto-Decoded Deep Latent Embeddings</b>
<a href="https://arxiv.org/abs/2104.05570">arxiv:2104.05570</a>
&#x1F4C8; 2 <br>
<p>Bowen Li, Xinping Ren, Ke Yan, Le Lu, Lingyun Huang, Guotong Xie, Jing Xiao, Dar-In Tai, Adam P. Harrison</p></summary>
<p>

**Abstract:** Depending on the application, radiological diagnoses can be associated with high inter- and intra-rater variabilities. Most computer-aided diagnosis (CAD) solutions treat such data as incontrovertible, exposing learning algorithms to considerable and possibly contradictory label noise and biases. Thus, managing subjectivity in labels is a fundamental problem in medical imaging analysis. To address this challenge, we introduce auto-decoded deep latent embeddings (ADDLE), which explicitly models the tendencies of each rater using an auto-decoder framework. After a simple linear transformation, the latent variables can be injected into any backbone at any and multiple points, allowing the model to account for rater-specific effects on the diagnosis. Importantly, ADDLE does not expect multiple raters per image in training, meaning it can readily learn from data mined from hospital archives. Moreover, the complexity of training ADDLE does not increase as more raters are added. During inference each rater can be simulated and a 'mean' or 'greedy' virtual rating can be produced. We test ADDLE on the problem of liver steatosis diagnosis from 2D ultrasound (US) by collecting 46 084 studies along with clinical US diagnoses originating from 65 different raters. We evaluated diagnostic performance using a separate dataset with gold-standard biopsy diagnoses. ADDLE can improve the partial areas under the curve (AUCs) for diagnosing severe steatosis by 10.5% over standard classifiers while outperforming other annotator-noise approaches, including those requiring 65 times the parameters.

</p>
</details>

<details><summary><b>Efficient Model Monitoring for Quality Control in Cardiac Image Segmentation</b>
<a href="https://arxiv.org/abs/2104.05533">arxiv:2104.05533</a>
&#x1F4C8; 2 <br>
<p>Francesco Galati, Maria A. Zuluaga</p></summary>
<p>

**Abstract:** Deep learning methods have reached state-of-the-art performance in cardiac image segmentation. Currently, the main bottleneck towards their effective translation into clinics requires assuring continuous high model performance and segmentation results. In this work, we present a novel learning framework to monitor the performance of heart segmentation models in the absence of ground truth. Formulated as an anomaly detection problem, the monitoring framework allows deriving surrogate quality measures for a segmentation and allows flagging suspicious results. We propose two different types of quality measures, a global score and a pixel-wise map. We demonstrate their use by reproducing the final rankings of a cardiac segmentation challenge in the absence of ground truth. Results show that our framework is accurate, fast, and scalable, confirming it is a viable option for quality control monitoring in clinical practice and large population studies.

</p>
</details>

<details><summary><b>Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx</b>
<a href="https://arxiv.org/abs/2104.05522">arxiv:2104.05522</a>
&#x1F4C8; 2 <br>
<p>Kin G. Olivares, Cristian Challu, Grzegorz Marcjasz, RafaÅ Weron, Artur Dubrawski</p></summary>
<p>

**Abstract:** We extend the neural basis expansion analysis (NBEATS) to incorporate exogenous factors. The resulting method, called NBEATSx, improves on a well performing deep learning model, extending its capabilities by including exogenous variables and allowing it to integrate multiple sources of useful information. To showcase the utility of the NBEATSx model, we conduct a comprehensive study of its application to electricity price forecasting (EPF) tasks across a broad range of years and markets. We observe state-of-the-art performance, significantly improving the forecast accuracy by nearly 20% over the original NBEATS model, and by up to 5% over other well established statistical and machine learning methods specialized for these tasks. Additionally, the proposed neural network has an interpretable configuration that can structurally decompose time series, visualizing the relative impact of trend and seasonal components and revealing the modeled processes' interactions with exogenous factors. To assist related work we made the code available in https://github.com/cchallu/nbeatsx.

</p>
</details>

<details><summary><b>Deep learning using Havrda-Charvat entropy for classification of pulmonary endomicroscopy</b>
<a href="https://arxiv.org/abs/2104.05450">arxiv:2104.05450</a>
&#x1F4C8; 2 <br>
<p>Thibaud Brochet, Jerome Lapuyade-Lahorgue, Sebastien Bougleux, Mathieu Salaun, Su Ruan</p></summary>
<p>

**Abstract:** Pulmonary optical endomicroscopy (POE) is an imaging technology in real time. It allows to examine pulmonary alveoli at a microscopic level. Acquired in clinical settings, a POE image sequence can have as much as 25% of the sequence being uninformative frames (i.e. pure-noise and motion artefacts). For future data analysis, these uninformative frames must be first removed from the sequence. Therefore, the objective of our work is to develop an automatic detection method of uninformative images in endomicroscopy images. We propose to take the detection problem as a classification one. Considering advantages of deep learning methods, a classifier based on CNN (Convolutional Neural Network) is designed with a new loss function based on Havrda-Charvat entropy which is a parametrical generalization of the Shannon entropy. We propose to use this formula to get a better hold on all sorts of data since it provides a model more stable than the Shannon entropy. Our method is tested on one POE dataset including 2947 distinct images, is showing better results than using Shannon entropy and behaves better with regard to the problem of overfitting.
  Keywords: Deep Learning, CNN, Shannon entropy, Havrda-Charvat entropy, Pulmonary optical endomicroscopy.

</p>
</details>

<details><summary><b>An Approach to Symbolic Regression Using Feyn</b>
<a href="https://arxiv.org/abs/2104.05417">arxiv:2104.05417</a>
&#x1F4C8; 2 <br>
<p>Kevin RenÃ© BrolÃ¸s, Meera Vieira Machado, Chris Cave, Jaan Kasak, Valdemar Stentoft-Hansen, Victor Galindo Batanero, Tom Jelen, Casper Wilstrup</p></summary>
<p>

**Abstract:** In this article we introduce the supervised machine learning tool called Feyn. The simulation engine that powers this tool is called the QLattice. The QLattice is a supervised machine learning tool inspired by Richard Feynman's path integral formulation, that explores many potential models that solves a given problem. It formulates these models as graphs that can be interpreted as mathematical equations, allowing the user to completely decide on the trade-off between interpretability, complexity and model performance.
  We touch briefly upon the inner workings of the QLattice, and show how to apply the python package, Feyn, to scientific problems. We show how it differs from traditional machine learning approaches, what it has in common with them, as well as some of its commonalities with symbolic regression. We describe the benefits of this approach as opposed to black box models.
  To illustrate this, we go through an investigative workflow using a basic data set and show how the QLattice can help you reason about the relationships between your features and do data discovery.

</p>
</details>

<details><summary><b>UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models</b>
<a href="https://arxiv.org/abs/2104.05358">arxiv:2104.05358</a>
&#x1F4C8; 2 <br>
<p>Hiroshi Sasaki, Chris G. Willcocks, Toby P. Breckon</p></summary>
<p>

**Abstract:** We propose a novel unpaired image-to-image translation method that uses denoising diffusion probabilistic models without requiring adversarial training. Our method, UNpaired Image Translation with Denoising Diffusion Probabilistic Models (UNIT-DDPM), trains a generative model to infer the joint distribution of images over both domains as a Markov chain by minimising a denoising score matching objective conditioned on the other domain. In particular, we update both domain translation models simultaneously, and we generate target domain images by a denoising Markov Chain Monte Carlo approach that is conditioned on the input source domain images, based on Langevin dynamics. Our approach provides stable model training for image-to-image translation and generates high-quality image outputs. This enables state-of-the-art FrÃ©chet Inception Distance (FID) performance on several public datasets, including both colour and multispectral imagery, significantly outperforming the contemporary adversarial image-to-image translation methods.

</p>
</details>

<details><summary><b>Combining exogenous and endogenous signals with a semi-supervised co-attention network for early detection of COVID-19 fake tweets</b>
<a href="https://arxiv.org/abs/2104.05321">arxiv:2104.05321</a>
&#x1F4C8; 2 <br>
<p>Rachit Bansal, William Scott Paka,  Nidhi, Shubhashis Sengupta, Tanmoy Chakraborty</p></summary>
<p>

**Abstract:** Fake tweets are observed to be ever-increasing, demanding immediate countermeasures to combat their spread. During COVID-19, tweets with misinformation should be flagged and neutralized in their early stages to mitigate the damages. Most of the existing methods for early detection of fake news assume to have enough propagation information for large labeled tweets -- which may not be an ideal setting for cases like COVID-19 where both aspects are largely absent. In this work, we present ENDEMIC, a novel early detection model which leverages exogenous and endogenous signals related to tweets, while learning on limited labeled data. We first develop a novel dataset, called CTF for early COVID-19 Twitter fake news, with additional behavioral test sets to validate early detection. We build a heterogeneous graph with follower-followee, user-tweet, and tweet-retweet connections and train a graph embedding model to aggregate propagation information. Graph embeddings and contextual features constitute endogenous, while time-relative web-scraped information constitutes exogenous signals. ENDEMIC is trained in a semi-supervised fashion, overcoming the challenge of limited labeled data. We propose a co-attention mechanism to fuse signal representations optimally. Experimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is highly reliable in detecting early fake tweets, outperforming nine state-of-the-art methods significantly.

</p>
</details>

<details><summary><b>Personalized Bundle Recommendation in Online Games</b>
<a href="https://arxiv.org/abs/2104.05307">arxiv:2104.05307</a>
&#x1F4C8; 2 <br>
<p>Qilin Deng, Kai Wang, Minghao Zhao, Zhene Zou, Runze Wu, Jianrong Tao, Changjie Fan, Liang Chen</p></summary>
<p>

**Abstract:** In business domains, \textit{bundling} is one of the most important marketing strategies to conduct product promotions, which is commonly used in online e-commerce and offline retailers. Existing recommender systems mostly focus on recommending individual items that users may be interested in. In this paper, we target at a practical but less explored recommendation problem named bundle recommendation, which aims to offer a combination of items to users. To tackle this specific recommendation problem in the context of the \emph{virtual mall} in online games, we formalize it as a link prediction problem on a user-item-bundle tripartite graph constructed from the historical interactions, and solve it with a neural network model that can learn directly on the graph-structure data. Extensive experiments on three public datasets and one industrial game dataset demonstrate the effectiveness of the proposed method. Further, the bundle recommendation model has been deployed in production for more than one year in a popular online game developed by Netease Games, and the launch of the model yields more than 60\% improvement on conversion rate of bundles, and a relative improvement of more than 15\% on gross merchandise volume (GMV).

</p>
</details>

<details><summary><b>Boltzmann Tuning of Generative Models</b>
<a href="https://arxiv.org/abs/2104.05252">arxiv:2104.05252</a>
&#x1F4C8; 2 <br>
<p>Victor Berger, Michele Sebag</p></summary>
<p>

**Abstract:** The paper focuses on the a posteriori tuning of a generative model in order to favor the generation of good instances in the sense of some external differentiable criterion. The proposed approach, called Boltzmann Tuning of Generative Models (BTGM), applies to a wide range of applications. It covers conditional generative modelling as a particular case, and offers an affordable alternative to rejection sampling. The contribution of the paper is twofold. Firstly, the objective is formalized and tackled as a well-posed optimization problem; a practical methodology is proposed to choose among the candidate criteria representing the same goal, the one best suited to efficiently learn a tuned generative model. Secondly, the merits of the approach are demonstrated on a real-world application, in the context of robust design for energy policies, showing the ability of BTGM to sample the extreme regions of the considered criteria.

</p>
</details>

<details><summary><b>Edgeless-GNN: Unsupervised Inductive Edgeless Network Embedding</b>
<a href="https://arxiv.org/abs/2104.05225">arxiv:2104.05225</a>
&#x1F4C8; 2 <br>
<p>Yong-Min Shin, Cong Tran, Won-Yong Shin, Xin Cao</p></summary>
<p>

**Abstract:** We study the problem of embedding edgeless nodes such as users who newly enter the underlying network, while using graph neural networks (GNNs) widely studied for effective representation learning of graphs thanks to its highly expressive capability via message passing. Our study is motivated by the fact that existing GNNs cannot be adopted for our problem since message passing to such edgeless nodes having no connections is impossible. To tackle this challenge, we propose Edgeless-GNN, a new framework that enables GNNs to generate node embeddings even for edgeless nodes through unsupervised inductive learning. Specifically, we start by constructing a $k$-nearest neighbor graph ($k$NNG) based on the similarity of node attributes to replace the GNN's computation graph defined by the neighborhood-based aggregation of each node. As our main contributions, the known network structure is used to train model parameters, while a new loss function is established using energy-based learning in such a way that our model learns the network structure. For the edgeless nodes, we inductively infer embeddings for the edgeless nodes by using edges via $k$NNG construction as a computation graph. By evaluating the performance of various downstream machine learning (ML) tasks, we empirically demonstrate that Edgeless-GNN consistently outperforms state-of-the-art methods of inductive network embedding. Moreover, our findings corroborate the effectiveness of Edgeless-GNN in judiciously combining the replaced computation graph with our newly designed loss. Our framework is GNN-model-agnostic; thus, GNN models can be appropriately chosen according to ones' needs and ML tasks.

</p>
</details>

<details><summary><b>HTCInfoMax: A Global Model for Hierarchical Text Classification via Information Maximization</b>
<a href="https://arxiv.org/abs/2104.05220">arxiv:2104.05220</a>
&#x1F4C8; 2 <br>
<p>Zhongfen Deng, Hao Peng, Dongxiao He, Jianxin Li, Philip S. Yu</p></summary>
<p>

**Abstract:** The current state-of-the-art model HiAGM for hierarchical text classification has two limitations. First, it correlates each text sample with all labels in the dataset which contains irrelevant information. Second, it does not consider any statistical constraint on the label representations learned by the structure encoder, while constraints for representation learning are proved to be helpful in previous work. In this paper, we propose HTCInfoMax to address these issues by introducing information maximization which includes two modules: text-label mutual information maximization and label prior matching. The first module can model the interaction between each text sample and its ground truth labels explicitly which filters out irrelevant information. The second one encourages the structure encoder to learn better representations with desired characteristics for all labels which can better handle label imbalance in hierarchical text classification. Experimental results on two benchmark datasets demonstrate the effectiveness of the proposed HTCInfoMax.

</p>
</details>

<details><summary><b>ENOS: Energy-Aware Network Operator Search for Hybrid Digital and Compute-in-Memory DNN Accelerators</b>
<a href="https://arxiv.org/abs/2104.05217">arxiv:2104.05217</a>
&#x1F4C8; 2 <br>
<p>Shamma Nasrin, Ahish Shylendra, Yuti Kadakia, Nick Iliev, Wilfred Gomes, Theja Tulabandhula, Amit Ranjan Trivedi</p></summary>
<p>

**Abstract:** This work proposes a novel Energy-Aware Network Operator Search (ENOS) approach to address the energy-accuracy trade-offs of a deep neural network (DNN) accelerator. In recent years, novel inference operators have been proposed to improve the computational efficiency of a DNN. Augmenting the operators, their corresponding novel computing modes have also been explored. However, simplification of DNN operators invariably comes at the cost of lower accuracy, especially on complex processing tasks. Our proposed ENOS framework allows an optimal layer-wise integration of inference operators and computing modes to achieve the desired balance of energy and accuracy. The search in ENOS is formulated as a continuous optimization problem, solvable using typical gradient descent methods, thereby scalable to larger DNNs with minimal increase in training cost. We characterize ENOS under two settings. In the first setting, for digital accelerators, we discuss ENOS on multiply-accumulate (MAC) cores that can be reconfigured to different operators. ENOS training methods with single and bi-level optimization objectives are discussed and compared. We also discuss a sequential operator assignment strategy in ENOS that only learns the assignment for one layer in one training step, enabling greater flexibility in converging towards the optimal operator allocations. Furthermore, following Bayesian principles, a sampling-based variational mode of ENOS is also presented. ENOS is characterized on popular DNNs ShuffleNet and SqueezeNet on CIFAR10 and CIFAR100.

</p>
</details>

<details><summary><b>Toward asynchronous EEG-based BCI: Detecting imagined words segments in continuous EEG signals</b>
<a href="https://arxiv.org/abs/2105.04294">arxiv:2105.04294</a>
&#x1F4C8; 1 <br>
<p>Tonatiuh HernÃ¡ndez-Del-Toro, Carlos A. Reyes-GarcÃ­a, Luis VillaseÃ±or-Pineda</p></summary>
<p>

**Abstract:** An asynchronous Brain--Computer Interface (BCI) based on imagined speech is a tool that allows to control an external device or to emit a message at the moment the user desires to by decoding EEG signals of imagined speech. In order to correctly implement these types of BCI, we must be able to detect from a continuous signal, when the subject starts to imagine words. In this work, five methods of feature extraction based on wavelet decomposition, empirical mode decomposition, frequency energies, fractal dimension and chaos theory features are presented to solve the task of detecting imagined words segments from continuous EEG signals as a preliminary study for a latter implementation of an asynchronous BCI based on imagined speech. These methods are tested in three datasets using four different classifiers and the higher F1 scores obtained are 0.73, 0.79, and 0.68 for each dataset, respectively. This results are promising to build a system that automatizes the segmentation of imagined words segments for latter classification.

</p>
</details>

<details><summary><b>Multiple regression techniques for modeling dates of first performances of Shakespeare-era plays</b>
<a href="https://arxiv.org/abs/2104.05929">arxiv:2104.05929</a>
&#x1F4C8; 1 <br>
<p>Pablo Moscato, Hugh Craig, Gabriel Egan, Mohammad Nazmul Haque, Kevin Huang, Julia Sloan, Jon Corrales de Oliveira</p></summary>
<p>

**Abstract:** The date of the first performance of a play of Shakespeare's time must usually be guessed with reference to multiple indirect external sources, or to some aspect of the content or style of the play. Identifying these dates is important to literary history and to accounts of developing authorial styles, such as Shakespeare's. In this study, we took a set of Shakespeare-era plays (181 plays from the period 1585--1610), added the best-guess dates for them from a standard reference work as metadata, and calculated a set of probabilities of individual words in these samples. We applied 11 regression methods to predict the dates of the plays at an 80/20 training/test split. We withdrew one play at a time, used the best-guess date metadata with the probabilities and weightings to infer its date, and thus built a model of date-probabilities interaction. We introduced a memetic algorithm-based Continued Fraction Regression (CFR) which delivered models using a small number of variables, leading to an interpretable model and reduced dimensionality. An in-depth analysis of the most commonly occurring 20 words in the CFR models in 100 independent runs helps explain the trends in linguistic and stylistic terms. The analysis with the subset of words revealed an interesting correlation of signature words with the Shakespeare-era play's genre.

</p>
</details>

<details><summary><b>On the validity of kernel approximations for orthogonally-initialized neural networks</b>
<a href="https://arxiv.org/abs/2104.05878">arxiv:2104.05878</a>
&#x1F4C8; 1 <br>
<p>James Martens</p></summary>
<p>

**Abstract:** In this note we extend kernel function approximation results for neural networks with Gaussian-distributed weights to single-layer networks initialized using Haar-distributed random orthogonal matrices (with possible rescaling). This is accomplished using recent results from random matrix theory.

</p>
</details>

<details><summary><b>Equivalence of quantum barren plateaus to cost concentration and narrow gorges</b>
<a href="https://arxiv.org/abs/2104.05868">arxiv:2104.05868</a>
&#x1F4C8; 1 <br>
<p>Andrew Arrasmith, ZoÃ« Holmes, M. Cerezo, Patrick J. Coles</p></summary>
<p>

**Abstract:** Optimizing parameterized quantum circuits (PQCs) is the leading approach to make use of near-term quantum computers. However, very little is known about the cost function landscape for PQCs, which hinders progress towards quantum-aware optimizers. In this work, we investigate the connection between three different landscape features that have been observed for PQCs: (1) exponentially vanishing gradients (called barren plateaus), (2) exponential cost concentration about the mean, and (3) the exponential narrowness of minina (called narrow gorges). We analytically prove that these three phenomena occur together, i.e., when one occurs then so do the other two. A key implication of this result is that one can numerically diagnose barren plateaus via cost differences rather than via the computationally more expensive gradients. More broadly, our work shows that quantum mechanics rules out certain cost landscapes (which otherwise would be mathematically possible), and hence our results are interesting from a quantum foundations perspective.

</p>
</details>

<details><summary><b>Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews</b>
<a href="https://arxiv.org/abs/2104.05861">arxiv:2104.05861</a>
&#x1F4C8; 1 <br>
<p>Mohammad Abdul Hadi, Fatemeh H. Fard</p></summary>
<p>

**Abstract:** Context: Mobile app reviews written by users on app stores or social media are significant resources for app developers.Analyzing app reviews have proved to be useful for many areas of software engineering (e.g., requirement engineering, testing). Automatic classification of app reviews requires extensive efforts to manually curate a labeled dataset. When the classification purpose changes (e.g. identifying bugs versus usability issues or sentiment), new datasets should be labeled, which prevents the extensibility of the developed models for new desired classes/tasks in practice. Recent pre-trained neural language models (PTM) are trained on large corpora in an unsupervised manner and have found success in solving similar Natural Language Processing problems. However, the applicability of PTMs is not explored for app review classification Objective: We investigate the benefits of PTMs for app review classification compared to the existing models, as well as the transferability of PTMs in multiple settings. Method: We empirically study the accuracy and time efficiency of PTMs compared to prior approaches using six datasets from literature. In addition, we investigate the performance of the PTMs trained on app reviews (i.e. domain-specific PTMs) . We set up different studies to evaluate PTMs in multiple settings: binary vs. multi-class classification, zero-shot classification (when new labels are introduced to the model), multi-task setting, and classification of reviews from different resources. The datasets are manually labeled app review datasets from Google Play Store, Apple App Store, and Twitter data. In all cases, Micro and Macro Precision, Recall, and F1-scores will be used and we will report the time required for training and prediction with the models.

</p>
</details>

<details><summary><b>Evidence-based Prescriptive Analytics, CAUSAL Digital Twin and a Learning Estimation Algorithm</b>
<a href="https://arxiv.org/abs/2104.05828">arxiv:2104.05828</a>
&#x1F4C8; 1 <br>
<p>PG Madhavan</p></summary>
<p>

**Abstract:** Evidence-based Prescriptive Analytics (EbPA) is necessary to determine optimal operational set-points that will improve business productivity. EbPA results from what-if analysis and counterfactual experimentation on CAUSAL Digital Twins (CDTs) that quantify cause-effect relationships in the DYNAMICS of a system of connected assets. We describe the basics of Causality and Causal Graphs and develop a Learning Causal Digital Twin (LCDT) solution; our algorithm uses a simple recurrent neural network with some innovative modifications incorporating Causal Graph simulation. Since LCDT is a learning digital twin where parameters are learned online in real-time with minimal pre-configuration, the work of deploying digital twins will be significantly simplified. A proof-of-principle of LCDT was conducted using real vibration data from a system of bearings; results of causal factor estimation, what-if analysis study and counterfactual experiment are very encouraging.

</p>
</details>

<details><summary><b>Understanding Fission Gas Bubble Distribution, Lanthanide Transportation, and Thermal Conductivity Degradation in Neutron-irradiated Î±-U Using Machine Learning</b>
<a href="https://arxiv.org/abs/2104.05786">arxiv:2104.05786</a>
&#x1F4C8; 1 <br>
<p>Lu Cai, Fei Xu, Fidelma Dilemma, Daniel J. Murray, Cynthia A. Adkins, Larry K Aagesen Jr, Min Xian, Luca Caprriot, Tiankai Yao</p></summary>
<p>

**Abstract:** UZr based metallic nuclear fuel is the leading candidate for next-generation sodium-cooled fast reactors in the United States. US research reactors have been using and testing this fuel type since the 1960s and accumulated considerable experience and knowledge about the fuel performance. However, most of knowledge remains empirical. The lack of mechanistic understanding of fuel performance is preventing the qualification of UZr fuel for commercial use. This paper proposes a data-driven approach, coupled with advanced post irradiation examination, powered by machine learning algorithms, to facilitate the development of such understandings by providing unpreceded quantified new insights into fission gas bubbles. Specifically, based on the advanced postirradiation examination data collected on a neutron-irradiated U-10Zr annular fuel, we developed a method to automatically detect, classify ~19,000 fission gas bubbles into different categories, and quantitatively link the data to lanthanide transpiration along the radial temperature gradient. The approach is versatile and can be modified to study different coupled irradiation effects, such as secondary phase redistribution and degradation of thermal conductivity, in irradiated nuclear fuel.

</p>
</details>

<details><summary><b>Predicting the Accuracy of Early-est Earthquake Magnitude Estimates with an LSTM Neural Network: A Preliminary Analysis</b>
<a href="https://arxiv.org/abs/2104.05712">arxiv:2104.05712</a>
&#x1F4C8; 1 <br>
<p>Massimo Nazaria</p></summary>
<p>

**Abstract:** This report presents a preliminary analysis of an LSTM neural network designed to predict the accuracy of magnitude estimates computed by Early-est during the first minutes after an earthquake occurs.

</p>
</details>

<details><summary><b>Towards Algorithmic Transparency: A Diversity Perspective</b>
<a href="https://arxiv.org/abs/2104.05658">arxiv:2104.05658</a>
&#x1F4C8; 1 <br>
<p>Fausto Giunchiglia, Jahna Otterbacher, Styliani Kleanthous, Khuyagbaatar Batsuren, Veronika Bogin, Tsvi Kuflik, Avital Shulner Tal</p></summary>
<p>

**Abstract:** As the role of algorithmic systems and processes increases in society, so does the risk of bias, which can result in discrimination against individuals and social groups. Research on algorithmic bias has exploded in recent years, highlighting both the problems of bias, and the potential solutions, in terms of algorithmic transparency (AT). Transparency is important for facilitating fairness management as well as explainability in algorithms; however, the concept of diversity, and its relationship to bias and transparency, has been largely left out of the discussion. We reflect on the relationship between diversity and bias, arguing that diversity drives the need for transparency. Using a perspective-taking lens, which takes diversity as a given, we propose a conceptual framework to characterize the problem and solution spaces of AT, to aid its application in algorithmic systems. Example cases from three research domains are described using our framework.

</p>
</details>

<details><summary><b>Using a Neural Network to Detect Anomalies given an N-gram Profile</b>
<a href="https://arxiv.org/abs/2104.05571">arxiv:2104.05571</a>
&#x1F4C8; 1 <br>
<p>Byunggu Yu, Junwhan Kim</p></summary>
<p>

**Abstract:** In order to detect unknown intrusions and runtime errors of computer programs, the cyber-security community has developed various detection techniques. Anomaly detection is an approach that is designed to profile the normal runtime behavior of computer programs in order to detect intrusions and errors as anomalous deviations from the observed normal. However, normal but unobserved behavior can trigger false positives. This limitation has significantly decreased the practical viability of anomaly detection techniques. Reported approaches to this limitation span a simple alert threshold definition to distribution models for approximating all normal behavior based on the limited observation. However, each assumption or approximation poses the potential for even greater false positive rates. This paper presents our study on how to explain the presence of anomalies using a neural network, particularly Long Short-Term Memory, independent of actual data distributions. We present and compare three anomaly detection models, and report on our experience running different types of attacks on an Apache Hypertext Transfer Protocol server. We performed a comparative study, focusing on each model's ability to detect the onset of each attack while avoiding false positives resulting from unknown normal behavior. Our best-performing model detected the true onset of every attack with zero false positives.

</p>
</details>

<details><summary><b>Modelling Brain Connectivity Networks by Graph Embedding for Dyslexia Diagnosis</b>
<a href="https://arxiv.org/abs/2104.05497">arxiv:2104.05497</a>
&#x1F4C8; 1 <br>
<p>Marco A. Formoso, AndrÃ©s Ortiz, Francisco J. MartÃ­nez-Murcia, NicolÃ¡s Gallego-Molina, Juan L. Luque</p></summary>
<p>

**Abstract:** Several methods have been developed to extract information from electroencephalograms (EEG). One of them is Phase-Amplitude Coupling (PAC) which is a type of Cross-Frequency Coupling (CFC) method, consisting in measure the synchronization of phase and amplitude for the different EEG bands and electrodes. This provides information regarding brain areas that are synchronously activated, and eventually, a marker of functional connectivity between these areas. In this work, intra and inter electrode PAC is computed obtaining the relationship among different electrodes used in EEG. The connectivity information is then treated as a graph in which the different nodes are the electrodes and the edges PAC values between them. These structures are embedded to create a feature vector that can be further used to classify multichannel EEG samples. The proposed method has been applied to classified EEG samples acquired using specific auditory stimuli in a task designed for dyslexia disorder diagnosis in seven years old children EEG's. The proposed method provides AUC values up to 0.73 and allows selecting the most discriminant electrodes and EEG bands.

</p>
</details>

<details><summary><b>Building Mental Models through Preview of Autopilot Behaviors</b>
<a href="https://arxiv.org/abs/2104.05470">arxiv:2104.05470</a>
&#x1F4C8; 1 <br>
<p>Yuan Shen, Niviru Wijayaratne, Katherine Driggs-Campbell</p></summary>
<p>

**Abstract:** Effective human-vehicle collaboration requires an appropriate un-derstanding of vehicle behavior for safety and trust. Improvingon our prior work by adding a future prediction module, we in-troduce our framework, calledAutoPreview, to enable humans topreview autopilot behaviors prior to direct interaction with thevehicle. Previewing autopilot behavior can help to ensure smoothhuman-vehicle collaboration during the initial exploration stagewith the vehicle. To demonstrate its practicality, we conducted acase study on human-vehicle collaboration and built a prototypeof our framework with the CARLA simulator. Additionally, weconducted a between-subject control experiment (n=10) to studywhether ourAutoPreviewframework can provide a deeper under-standing of autopilot behavior compared to direct interaction. Ourresults suggest that theAutoPreviewframework does, in fact, helpusers understand autopilot behavior and develop appropriate men-tal models

</p>
</details>

<details><summary><b>Dual-Octave Convolution for Accelerated Parallel MR Image Reconstruction</b>
<a href="https://arxiv.org/abs/2104.05345">arxiv:2104.05345</a>
&#x1F4C8; 1 <br>
<p>Chun-Mei Feng, Zhanyuan Yang, Geng Chen, Yong Xu, Ling Shao</p></summary>
<p>

**Abstract:** Magnetic resonance (MR) image acquisition is an inherently prolonged process, whose acceleration by obtaining multiple undersampled images simultaneously through parallel imaging has always been the subject of research. In this paper, we propose the Dual-Octave Convolution (Dual-OctConv), which is capable of learning multi-scale spatial-frequency features from both real and imaginary components, for fast parallel MR image reconstruction. By reformulating the complex operations using octave convolutions, our model shows a strong ability to capture richer representations of MR images, while at the same time greatly reducing the spatial redundancy. More specifically, the input feature maps and convolutional kernels are first split into two components (i.e., real and imaginary), which are then divided into four groups according to their spatial frequencies. Then, our Dual-OctConv conducts intra-group information updating and inter-group information exchange to aggregate the contextual information across different groups. Our framework provides two appealing benefits: (i) it encourages interactions between real and imaginary components at various spatial frequencies to achieve richer representational capacity, and (ii) it enlarges the receptive field by learning multiple spatial-frequency features of both the real and imaginary components. We evaluate the performance of the proposed model on the acceleration of multi-coil MR image reconstruction. Extensive experiments are conducted on an {in vivo} knee dataset under different undersampling patterns and acceleration factors. The experimental results demonstrate the superiority of our model in accelerated parallel MR image reconstruction. Our code is available at: github.com/chunmeifeng/Dual-OctConv.

</p>
</details>

<details><summary><b>Unsupervised foreign object detection based on dual-energy absorptiometry in the food industry</b>
<a href="https://arxiv.org/abs/2104.05326">arxiv:2104.05326</a>
&#x1F4C8; 1 <br>
<p>Vladyslav Andriiashen, Robert van Liere, Tristan van Leeuwen, Kees Joost Batenburg</p></summary>
<p>

**Abstract:** X-ray imaging is a widely used technique for non-destructive inspection of agricultural food products. One application of X-ray imaging is the autonomous, in-line detection of foreign objects in food samples. Examples of such inclusions are bone fragments in meat products, plastic and metal debris in fish, fruit infestations. This article presents a processing methodology for unsupervised foreign object detection based on dual-energy X-ray absorptiometry (DEXA). A foreign object is defined as a fragment of material with different X-ray attenuation properties than those belonging to the food product. A novel thickness correction model is introduced as a pre-processing technique for DEXA data. The aim of the model is to homogenize regions in the image that belong to the food product and enhance contrast where the foreign object is present. In this way, the segmentation of the foreign object is more robust to noise and lack of contrast. The proposed methodology was applied to a dataset of 488 samples of meat products. The samples were acquired from a conveyor belt in a food processing factory. Approximately 60\% of the samples contain foreign objects of different types and sizes, while the rest of the samples are void of foreign objects. The results show that samples without foreign objects are correctly identified in 97% of cases, the overall accuracy of foreign object detection reaches 95%.

</p>
</details>

<details><summary><b>LearningCity: Knowledge Generation for Smart Cities</b>
<a href="https://arxiv.org/abs/2104.05286">arxiv:2104.05286</a>
&#x1F4C8; 1 <br>
<p>Dimitrios Amaxilatis, Georgios Mylonas, Evangelos Theodoridis, Luis Diez, Katerina Deligiannidou</p></summary>
<p>

**Abstract:** Although we have reached new levels in smart city installations and systems, efforts so far have focused on providing diverse sources of data to smart city services consumers while neglecting to provide ways to simplify making good use of them. In this context, one first step that will bring added value to smart cities is knowledge creation in smart cities through anomaly detection and data annotation, supported in both an automated and a crowdsourced manner. We present here LearningCity, our solution that has been validated over an existing smart city deployment in Santander, and the OrganiCity experimentation-as-a-service ecosystem. We discuss key challenges along with characteristic use cases, and report on our design and implementation, together with some preliminary results derived from combining large smart city datasets with machine learning.

</p>
</details>

<details><summary><b>Online Machine Learning Techniques for Coq: A Comparison</b>
<a href="https://arxiv.org/abs/2104.05207">arxiv:2104.05207</a>
&#x1F4C8; 1 <br>
<p>Liao Zhang, Lasse Blaauwbroek, Bartosz Piotrowski, Prokop ÄernÃ½, Cezary Kaliszyk, Josef Urban</p></summary>
<p>

**Abstract:** We present a comparison of several online machine learning techniques for tactical learning and proving in the Coq proof assistant. This work builds on top of Tactician, a plugin for Coq that learns from proofs written by the user to synthesize new proofs. Learning happens in an online manner, meaning that Tactician's machine learning model is updated immediately every time the user performs a step in an interactive proof. This has important advantages compared to the more studied offline learning systems: (1) it provides the user with a seamless, interactive experience with Tactician and, (2) it takes advantage of locality of proof similarity, which means that proofs similar to the current proof are likely to be found close by. We implement two online methods, namely approximate k-nearest neighbors based on locality sensitive hashing forests and random decision forests. Additionally, we conduct experiments with gradient boosted trees in an offline setting using XGBoost. We compare the relative performance of Tactician using these three learning methods on Coq's standard library.

</p>
</details>

<details><summary><b>Approximate Computing for Robotic path planning -- Experimentation, Case Study and Practical Implications</b>
<a href="https://arxiv.org/abs/2104.05773">arxiv:2104.05773</a>
&#x1F4C8; 0 <br>
<p>Hrishav Bakul Barua</p></summary>
<p>

**Abstract:** Approximate computing is a computation domain which can be used to trade time and energy with quality and therefore is useful in embedded systems. Energy is the prime resource in battery-driven embedded systems, like robots. Approximate computing can be used as a technique to generate approximate version of the control functionalities of a robot, enabling it to ration energy for computation at the cost of degraded quality. Usually, the programmer of the function specifies the extent of degradation that is safe for the overall safety of the system. However, in a collaborative environment, where several sub-systems co-exist and some of the functionality of each of them have been approximated, the safety of the overall system may be compromised. In this paper, we consider multiple identical robots operate in a warehouse, and the path planning function of the robot is approximated. Although the planned paths are safe for individual robots (i.e. they do not collide with the racks), we show that this leads to a collision among the robots. So, a controlled approximation needs to be carried out in such situations to harness the full power of this new paradigm if it needs to be a mainstream paradigm in future.

</p>
</details>


[Next Page]({{ '/2021/04/11/2021.04.11.html' | relative_url }})
