## Summary for 2021-11-26, created on 2021-12-17


<details><summary><b>AI and the Everything in the Whole Wide World Benchmark</b>
<a href="https://arxiv.org/abs/2111.15366">arxiv:2111.15366</a>
&#x1F4C8; 1920 <br>
<p>Inioluwa Deborah Raji, Emily M. Bender, Amandalynne Paullada, Emily Denton, Alex Hanna</p></summary>
<p>

**Abstract:** There is a tendency across different subfields in AI to valorize a small collection of influential benchmarks. These benchmarks operate as stand-ins for a range of anointed common problems that are frequently framed as foundational milestones on the path towards flexible and generalizable AI systems. State-of-the-art performance on these benchmarks is widely understood as indicative of progress towards these long-term goals. In this position paper, we explore the limits of such benchmarks in order to reveal the construct validity issues in their framing as the functionally "general" broad measures of progress they are set up to be.

</p>
</details>

<details><summary><b>Learning from learning machines: a new generation of AI technology to meet the needs of science</b>
<a href="https://arxiv.org/abs/2111.13786">arxiv:2111.13786</a>
&#x1F4C8; 106 <br>
<p>Luca Pion-Tonachini, Kristofer Bouchard, Hector Garcia Martin, Sean Peisert, W. Bradley Holtz, Anil Aswani, Dipankar Dwivedi, Haruko Wainwright, Ghanshyam Pilania, Benjamin Nachman, Babetta L. Marrone, Nicola Falco,  Prabhat, Daniel Arnold, Alejandro Wolf-Yadlin, Sarah Powers, Sharlee Climer, Quinn Jackson, Ty Carlson, Michael Sohn, Petrus Zwart, Neeraj Kumar, Amy Justice, Claire Tomlin, Daniel Jacobson</p></summary>
<p>

**Abstract:** We outline emerging opportunities and challenges to enhance the utility of AI for scientific discovery. The distinct goals of AI for industry versus the goals of AI for science create tension between identifying patterns in data versus discovering patterns in the world from data. If we address the fundamental challenges associated with "bridging the gap" between domain-driven scientific models and data-driven AI learning machines, then we expect that these AI models can transform hypothesis generation, scientific discovery, and the scientific process itself.

</p>
</details>

<details><summary><b>Representation Learning of Logic Circuits</b>
<a href="https://arxiv.org/abs/2111.14616">arxiv:2111.14616</a>
&#x1F4C8; 82 <br>
<p>Min Li, Sadaf Khan, Zhengyuan Shi, Naixing Wang, Yu Huang, Qiang Xu</p></summary>
<p>

**Abstract:** Applying deep learning (DL) techniques in the electronic design automation (EDA) field has become a trending topic in recent years. Most existing solutions apply well-developed DL models to solve specific EDA problems. While demonstrating promising results, they require careful model tuning for every problem. The fundamental question on \textit{"How to obtain a general and effective neural representation of circuits?"} has not been answered yet. In this work, we take the first step towards solving this problem. We propose \textit{DeepGate}, a novel representation learning solution that effectively embeds both logic function and structural information of a circuit as vectors on each gate. Specifically, we propose transforming circuits into unified and-inverter graph format for learning and using signal probabilities as the supervision task in DeepGate. We then introduce a novel graph neural network that uses strong inductive biases in practical circuits as learning priors for signal probability prediction. Our experimental results show the efficacy and generalization capability of DeepGate.

</p>
</details>

<details><summary><b>Conditional Image Generation with Score-Based Diffusion Models</b>
<a href="https://arxiv.org/abs/2111.13606">arxiv:2111.13606</a>
&#x1F4C8; 69 <br>
<p>Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, Christian Etmann</p></summary>
<p>

**Abstract:** Score-based diffusion models have emerged as one of the most promising frameworks for deep generative modelling. In this work we conduct a systematic comparison and theoretical analysis of different approaches to learning conditional probability distributions with score-based diffusion models. In particular, we prove results which provide a theoretical justification for one of the most successful estimators of the conditional score. Moreover, we introduce a multi-speed diffusion framework, which leads to a new estimator for the conditional score, performing on par with previous state-of-the-art approaches. Our theoretical and experimental findings are accompanied by an open source library MSDiff which allows for application and further research of multi-speed diffusion models.

</p>
</details>

<details><summary><b>Neural Fields as Learnable Kernels for 3D Reconstruction</b>
<a href="https://arxiv.org/abs/2111.13674">arxiv:2111.13674</a>
&#x1F4C8; 65 <br>
<p>Francis Williams, Zan Gojcic, Sameh Khamis, Denis Zorin, Joan Bruna, Sanja Fidler, Or Litany</p></summary>
<p>

**Abstract:** We present Neural Kernel Fields: a novel method for reconstructing implicit 3D shapes based on a learned kernel ridge regression. Our technique achieves state-of-the-art results when reconstructing 3D objects and large scenes from sparse oriented points, and can reconstruct shape categories outside the training set with almost no drop in accuracy. The core insight of our approach is that kernel methods are extremely effective for reconstructing shapes when the chosen kernel has an appropriate inductive bias. We thus factor the problem of shape reconstruction into two parts: (1) a backbone neural network which learns kernel parameters from data, and (2) a kernel ridge regression that fits the input points on-the-fly by solving a simple positive definite linear system using the learned kernel. As a result of this factorization, our reconstruction gains the benefits of data-driven methods under sparse point density while maintaining interpolatory behavior, which converges to the ground truth shape as input sampling density increases. Our experiments demonstrate a strong generalization capability to objects outside the train-set category and scanned scenes. Source code and pretrained models are available at https://nv-tlabs.github.io/nkf.

</p>
</details>

<details><summary><b>Do Language Models Have Beliefs? Methods for Detecting, Updating, and Visualizing Model Beliefs</b>
<a href="https://arxiv.org/abs/2111.13654">arxiv:2111.13654</a>
&#x1F4C8; 60 <br>
<p>Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, Srinivasan Iyer</p></summary>
<p>

**Abstract:** Do language models have beliefs about the world? Dennett (1995) famously argues that even thermostats have beliefs, on the view that a belief is simply an informational state decoupled from any motivational state. In this paper, we discuss approaches to detecting when models have beliefs about the world, and we improve on methods for updating model beliefs to be more truthful, with a focus on methods based on learned optimizers or hypernetworks. Our main contributions include: (1) new metrics for evaluating belief-updating methods that focus on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing model updates (SLAG) that improves the performance of learned optimizers, and (3) the introduction of the belief graph, which is a new form of interface with language models that shows the interdependencies between model beliefs. Our experiments suggest that models possess belief-like qualities to only a limited extent, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work. Code is available at https://github.com/peterbhase/SLAG-Belief-Updating

</p>
</details>

<details><summary><b>LAFITE: Towards Language-Free Training for Text-to-Image Generation</b>
<a href="https://arxiv.org/abs/2111.13792">arxiv:2111.13792</a>
&#x1F4C8; 13 <br>
<p>Yufan Zhou, Ruiyi Zhang, Changyou Chen, Chunyuan Li, Chris Tensmeyer, Tong Yu, Jiuxiang Gu, Jinhui Xu, Tong Sun</p></summary>
<p>

**Abstract:** One of the major challenges in training text-to-image generation models is the need of a large number of high-quality image-text pairs. While image samples are often easily accessible, the associated text descriptions typically require careful human captioning, which is particularly time- and cost-consuming. In this paper, we propose the first work to train text-to-image generation models without any text data. Our method leverages the well-aligned multi-modal semantic space of the powerful pre-trained CLIP model: the requirement of text-conditioning is seamlessly alleviated via generating text features from image features. Extensive experiments are conducted to illustrate the effectiveness of the proposed method. We obtain state-of-the-art results in the standard text-to-image generation tasks. Importantly, the proposed language-free model outperforms most existing models trained with full image-text pairs. Furthermore, our method can be applied in fine-tuning pre-trained models, which saves both training time and cost in training text-to-image generation models. Our pre-trained model obtains competitive results in zero-shot text-to-image generation on the MS-COCO dataset, yet with around only 1% of the model size and training data size relative to the recently proposed large DALL-E model.

</p>
</details>

<details><summary><b>Machines and Influence</b>
<a href="https://arxiv.org/abs/2111.13365">arxiv:2111.13365</a>
&#x1F4C8; 9 <br>
<p>Shashank Yadav</p></summary>
<p>

**Abstract:** Policymakers face a broader challenge of how to view AI capabilities today and where does society stand in terms of those capabilities. This paper surveys AI capabilities and tackles this very issue, exploring it in context of political security in digital societies. We introduce a Matrix of Machine Influence to frame and navigate the adversarial applications of AI, and further extend the ideas of Information Management to better understand contemporary AI systems deployment as part of a complex information system. Providing a comprehensive review of man-machine interactions in our networked society and political systems, we suggest that better regulation and management of information systems can more optimally offset the risks of AI and utilise the emerging capabilities which these systems have to offer to policymakers and political institutions across the world. Hopefully this long essay will actuate further debates and discussions over these ideas, and prove to be a useful contribution towards governing the future of AI.

</p>
</details>

<details><summary><b>Particle Dynamics for Learning EBMs</b>
<a href="https://arxiv.org/abs/2111.13772">arxiv:2111.13772</a>
&#x1F4C8; 7 <br>
<p>Kirill Neklyudov, Priyank Jaini, Max Welling</p></summary>
<p>

**Abstract:** Energy-based modeling is a promising approach to unsupervised learning, which yields many downstream applications from a single model. The main difficulty in learning energy-based models with the "contrastive approaches" is the generation of samples from the current energy function at each iteration. Many advances have been made to accomplish this subroutine cheaply. Nevertheless, all such sampling paradigms run MCMC targeting the current model, which requires infinitely long chains to generate samples from the true energy distribution and is problematic in practice. This paper proposes an alternative approach to getting these samples and avoiding crude MCMC sampling from the current model. We accomplish this by viewing the evolution of the modeling distribution as (i) the evolution of the energy function, and (ii) the evolution of the samples from this distribution along some vector field. We subsequently derive this time-dependent vector field such that the particles following this field are approximately distributed as the current density model. Thereby we match the evolution of the particles with the evolution of the energy function prescribed by the learning procedure. Importantly, unlike Monte Carlo sampling, our method targets to match the current distribution in a finite time. Finally, we demonstrate its effectiveness empirically compared to MCMC-based learning methods.

</p>
</details>

<details><summary><b>ManiFest: Manifold Deformation for Few-shot Image Translation</b>
<a href="https://arxiv.org/abs/2111.13681">arxiv:2111.13681</a>
&#x1F4C8; 7 <br>
<p>Fabio Pizzati, Jean-François Lalonde, Raoul de Charette</p></summary>
<p>

**Abstract:** Most image-to-image translation methods require a large number of training images, which restricts their applicability. We instead propose ManiFest: a framework for few-shot image translation that learns a context-aware representation of a target domain from a few images only. To enforce feature consistency, our framework learns a style manifold between source and proxy anchor domains (assumed to be composed of large numbers of images). The learned manifold is interpolated and deformed towards the few-shot target domain via patch-based adversarial and feature statistics alignment losses. All of these components are trained simultaneously during a single end-to-end loop. In addition to the general few-shot translation task, our approach can alternatively be conditioned on a single exemplar image to reproduce its specific style. Extensive experiments demonstrate the efficacy of ManiFest on multiple tasks, outperforming the state-of-the-art on all metrics and in both the general- and exemplar-based scenarios. Our code is available at https://github.com/cv-rits/Manifest .

</p>
</details>

<details><summary><b>Soliciting User Preferences in Conversational Recommender Systems via Usage-related Questions</b>
<a href="https://arxiv.org/abs/2111.13463">arxiv:2111.13463</a>
&#x1F4C8; 7 <br>
<p>Ivica Kostric, Krisztian Balog, Filip Radlinski</p></summary>
<p>

**Abstract:** A key distinguishing feature of conversational recommender systems over traditional recommender systems is their ability to elicit user preferences using natural language. Currently, the predominant approach to preference elicitation is to ask questions directly about items or item attributes. These strategies do not perform well in cases where the user does not have sufficient knowledge of the target domain to answer such questions. Conversely, in a shopping setting, talking about the planned use of items does not present any difficulties, even for those that are new to a domain. In this paper, we propose a novel approach to preference elicitation by asking implicit questions based on item usage. Our approach consists of two main steps. First, we identify the sentences from a large review corpus that contain information about item usage. Then, we generate implicit preference elicitation questions from those sentences using a neural text-to-text model. The main contributions of this work also include a multi-stage data annotation protocol using crowdsourcing for collecting high-quality labeled training data for the neural model. We show that our approach is effective in selecting review sentences and transforming them to elicitation questions, even with limited training data. Additionally, we provide an analysis of patterns where the model does not perform optimally.

</p>
</details>

<details><summary><b>3D shape sensing and deep learning-based segmentation of strawberries</b>
<a href="https://arxiv.org/abs/2111.13663">arxiv:2111.13663</a>
&#x1F4C8; 6 <br>
<p>Justin Le Louëdec, Grzegorz Cielniak</p></summary>
<p>

**Abstract:** Automation and robotisation of the agricultural sector are seen as a viable solution to socio-economic challenges faced by this industry. This technology often relies on intelligent perception systems providing information about crops, plants and the entire environment. The challenges faced by traditional 2D vision systems can be addressed by modern 3D vision systems which enable straightforward localisation of objects, size and shape estimation, or handling of occlusions. So far, the use of 3D sensing was mainly limited to indoor or structured environments. In this paper, we evaluate modern sensing technologies including stereo and time-of-flight cameras for 3D perception of shape in agriculture and study their usability for segmenting out soft fruit from background based on their shape. To that end, we propose a novel 3D deep neural network which exploits the organised nature of information originating from the camera-based 3D sensors. We demonstrate the superior performance and efficiency of the proposed architecture compared to the state-of-the-art 3D networks. Through a simulated study, we also show the potential of the 3D sensing paradigm for object segmentation in agriculture and provide insights and analysis of what shape quality is needed and expected for further analysis of crops. The results of this work should encourage researchers and companies to develop more accurate and robust 3D sensing technologies to assure their wider adoption in practical agricultural applications.

</p>
</details>

<details><summary><b>SurfEmb: Dense and Continuous Correspondence Distributions for Object Pose Estimation with Learnt Surface Embeddings</b>
<a href="https://arxiv.org/abs/2111.13489">arxiv:2111.13489</a>
&#x1F4C8; 6 <br>
<p>Rasmus Laurvig Haugaard, Anders Glent Buch</p></summary>
<p>

**Abstract:** We present an approach to learn dense, continuous 2D-3D correspondence distributions over the surface of objects from data with no prior knowledge of visual ambiguities like symmetry. We also present a new method for 6D pose estimation of rigid objects using the learnt distributions to sample, score and refine pose hypotheses. The correspondence distributions are learnt with a contrastive loss, represented in object-specific latent spaces by an encoder-decoder query model and a small fully connected key model. Our method is unsupervised with respect to visual ambiguities, yet we show that the query- and key models learn to represent accurate multi-modal surface distributions. Our pose estimation method improves the state-of-the-art significantly on the comprehensive BOP Challenge, trained purely on synthetic data, even compared with methods trained on real data. The project site is at https://surfemb.github.io/ .

</p>
</details>

<details><summary><b>Learning to Transfer for Traffic Forecasting via Multi-task Learning</b>
<a href="https://arxiv.org/abs/2111.15542">arxiv:2111.15542</a>
&#x1F4C8; 5 <br>
<p>Yichao Lu</p></summary>
<p>

**Abstract:** Deep neural networks have demonstrated superior performance in short-term traffic forecasting. However, most existing traffic forecasting systems assume that the training and testing data are drawn from the same underlying distribution, which limits their practical applicability. The NeurIPS 2021 Traffic4cast challenge is the first of its kind dedicated to benchmarking the robustness of traffic forecasting models towards domain shifts in space and time. This technical report describes our solution to this challenge. In particular, we present a multi-task learning framework for temporal and spatio-temporal domain adaptation of traffic forecasting models. Experimental results demonstrate that our multi-task learning approach achieves strong empirical performance, outperforming a number of baseline domain adaptation methods, while remaining highly efficient. The source code for this technical report is available at https://github.com/YichaoLu/Traffic4cast2021.

</p>
</details>

<details><summary><b>A Review on Graph Neural Network Methods in Financial Applications</b>
<a href="https://arxiv.org/abs/2111.15367">arxiv:2111.15367</a>
&#x1F4C8; 5 <br>
<p>Jianian Wang, Sheng Zhang, Yanghua Xiao, Rui Song</p></summary>
<p>

**Abstract:** Keeping the individual features and the complicated relations, graph data are widely utilized and investigated. Being able to capture the structural information by updating and aggregating nodes' representations, graph neural network (GNN) models are gaining popularity. In the financial context, the graph is constructed based on real-world data, which leads to complex graph structure and thus requires sophisticated methodology. In this work, we provide a comprehensive review of GNN models in recent financial context. We first categorize the commonly-used financial graphs and summarize the feature processing step for each node. Then we summarize the GNN methodology for each graph type, application in each area, and propose some potential research areas.

</p>
</details>

<details><summary><b>Video Content Classification using Deep Learning</b>
<a href="https://arxiv.org/abs/2111.13813">arxiv:2111.13813</a>
&#x1F4C8; 5 <br>
<p>Pradyumn Patil, Vishwajeet Pawar, Yashraj Pawar, Shruti Pisal</p></summary>
<p>

**Abstract:** Video content classification is an important research content in computer vision, which is widely used in many fields, such as image and video retrieval, computer vision. This paper presents a model that is a combination of Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) which develops, trains, and optimizes a deep learning network that can identify the type of video content and classify them into categories such as "Animation, Gaming, natural content, flat content, etc". To enhance the performance of the model novel keyframe extraction method is included to classify only the keyframes, thereby reducing the overall processing time without sacrificing any significant performance.

</p>
</details>

<details><summary><b>Unsupervised MKL in Multi-layer Kernel Machines</b>
<a href="https://arxiv.org/abs/2111.13769">arxiv:2111.13769</a>
&#x1F4C8; 5 <br>
<p>Akhil Meethal, Asharaf S, Sumitra S</p></summary>
<p>

**Abstract:** Kernel based Deep Learning using multi-layer kernel machines(MKMs) was proposed by Y.Cho and L.K. Saul in \cite{saul}. In MKMs they used only one kernel(arc-cosine kernel) at a layer for the kernel PCA-based feature extraction. We propose to use multiple kernels in each layer by taking a convex combination of many kernels following an unsupervised learning strategy. Empirical study is conducted on \textit{mnist-back-rand}, \textit{mnist-back-image} and \textit{mnist-rot-back-image} datasets generated by adding random noise in the image background of MNIST dataset. Experimental results indicate that using MKL in MKMs earns a better representation of the raw data and improves the classifier performance.

</p>
</details>

<details><summary><b>Enforcing and Discovering Structure in Machine Learning</b>
<a href="https://arxiv.org/abs/2111.13693">arxiv:2111.13693</a>
&#x1F4C8; 5 <br>
<p>Francesco Locatello</p></summary>
<p>

**Abstract:** The world is structured in countless ways. It may be prudent to enforce corresponding structural properties to a learning algorithm's solution, such as incorporating prior beliefs, natural constraints, or causal structures. Doing so may translate to faster, more accurate, and more flexible models, which may directly relate to real-world impact. In this dissertation, we consider two different research areas that concern structuring a learning algorithm's solution: when the structure is known and when it has to be discovered.

</p>
</details>

<details><summary><b>Latent Space Smoothing for Individually Fair Representations</b>
<a href="https://arxiv.org/abs/2111.13650">arxiv:2111.13650</a>
&#x1F4C8; 5 <br>
<p>Momchil Peychev, Anian Ruoss, Mislav Balunović, Maximilian Baader, Martin Vechev</p></summary>
<p>

**Abstract:** Fair representation learning encodes user data to ensure fairness and utility, regardless of the downstream application. However, learning individually fair representations, i.e., guaranteeing that similar individuals are treated similarly, remains challenging in high-dimensional settings such as computer vision. In this work, we introduce LASSI, the first representation learning method for certifying individual fairness of high-dimensional data. Our key insight is to leverage recent advances in generative modeling to capture the set of similar individuals in the generative latent space. This allows learning individually fair representations where similar individuals are mapped close together, by using adversarial training to minimize the distance between their representations. Finally, we employ randomized smoothing to provably map similar individuals close together, in turn ensuring that local robustness verification of the downstream application results in end-to-end fairness certification. Our experimental evaluation on challenging real-world image data demonstrates that our method increases certified individual fairness by up to 60%, without significantly affecting task utility.

</p>
</details>

<details><summary><b>Predicting Document Coverage for Relation Extraction</b>
<a href="https://arxiv.org/abs/2111.13611">arxiv:2111.13611</a>
&#x1F4C8; 5 <br>
<p>Sneha Singhania, Simon Razniewski, Gerhard Weikum</p></summary>
<p>

**Abstract:** This paper presents a new task of predicting the coverage of a text document for relation extraction (RE): does the document contain many relational tuples for a given entity? Coverage predictions are useful in selecting the best documents for knowledge base construction with large input corpora. To study this problem, we present a dataset of 31,366 diverse documents for 520 entities. We analyze the correlation of document coverage with features like length, entity mention frequency, Alexa rank, language complexity and information retrieval scores. Each of these features has only moderate predictive power. We employ methods combining features with statistical models like TF-IDF and language models like BERT. The model combining features and BERT, HERB, achieves an F1 score of up to 46%. We demonstrate the utility of coverage predictions on two use cases: KB construction and claim refutation.

</p>
</details>

<details><summary><b>Using Fictitious Class Representations to Boost Discriminative Zero-Shot Learners</b>
<a href="https://arxiv.org/abs/2111.13550">arxiv:2111.13550</a>
&#x1F4C8; 5 <br>
<p>Mohammed Dabbah, Ran El-yaniv</p></summary>
<p>

**Abstract:** Focusing on discriminative zero-shot learning, in this work we introduce a novel mechanism that dynamically augments during training the set of seen classes to produce additional fictitious classes. These fictitious classes diminish the model's tendency to fixate during training on attribute correlations that appear in the training set but will not appear in newly exposed classes. The proposed model is tested within the two formulations of the zero-shot learning framework; namely, generalized zero-shot learning (GZSL) and classical zero-shot learning (CZSL). Our model improves the state-of-the-art performance on the CUB dataset and reaches comparable results on the other common datasets, AWA2 and SUN. We investigate the strengths and weaknesses of our method, including the effects of catastrophic forgetting when training an end-to-end zero-shot model.

</p>
</details>

<details><summary><b>How Well Do Sparse Imagenet Models Transfer?</b>
<a href="https://arxiv.org/abs/2111.13445">arxiv:2111.13445</a>
&#x1F4C8; 5 <br>
<p>Eugenia Iofinova, Alexandra Peste, Mark Kurtz, Dan Alistarh</p></summary>
<p>

**Abstract:** Transfer learning is a classic paradigm by which models pretrained on large "upstream" datasets are adapted to yield good results on "downstream," specialized datasets. Generally, it is understood that more accurate models on the "upstream" dataset will provide better transfer accuracy "downstream". In this work, we perform an in-depth investigation of this phenomenon in the context of convolutional neural networks (CNNs) trained on the ImageNet dataset, which have been pruned - that is, compressed by sparsifiying their connections. Specifically, we consider transfer using unstructured pruned models obtained by applying several state-of-the-art pruning methods, including magnitude-based, second-order, re-growth and regularization approaches, in the context of twelve standard transfer tasks. In a nutshell, our study shows that sparse models can match or even outperform the transfer performance of dense models, even at high sparsities, and, while doing so, can lead to significant inference and even training speedups. At the same time, we observe and analyze significant differences in the behaviour of different pruning methods.

</p>
</details>

<details><summary><b>ContIG: Self-supervised Multimodal Contrastive Learning for Medical Imaging with Genetics</b>
<a href="https://arxiv.org/abs/2111.13424">arxiv:2111.13424</a>
&#x1F4C8; 5 <br>
<p>Aiham Taleb, Matthias Kirchler, Remo Monti, Christoph Lippert</p></summary>
<p>

**Abstract:** High annotation costs are a substantial bottleneck in applying modern deep learning architectures to clinically relevant medical use cases, substantiating the need for novel algorithms to learn from unlabeled data. In this work, we propose ContIG, a self-supervised method that can learn from large datasets of unlabeled medical images and genetic data. Our approach aligns images and several genetic modalities in the feature space using a contrastive loss. We design our method to integrate multiple modalities of each individual person in the same model end-to-end, even when the available modalities vary across individuals. Our procedure outperforms state-of-the-art self-supervised methods on all evaluated downstream benchmark tasks. We also adapt gradient-based explainability algorithms to better understand the learned cross-modal associations between the images and genetic modalities. Finally, we perform genome-wide association studies on the features learned by our models, uncovering interesting relationships between images and genetic data.

</p>
</details>

<details><summary><b>Jointly Learning Agent and Lane Information for Multimodal Trajectory Prediction</b>
<a href="https://arxiv.org/abs/2111.13350">arxiv:2111.13350</a>
&#x1F4C8; 5 <br>
<p>Jie Wang, Caili Guo, Minan Guo, Jiujiu Chen</p></summary>
<p>

**Abstract:** Predicting the plausible future trajectories of nearby agents is a core challenge for the safety of Autonomous Vehicles and it mainly depends on two external cues: the dynamic neighbor agents and static scene context. Recent approaches have made great progress in characterizing the two cues separately. However, they ignore the correlation between the two cues and most of them are difficult to achieve map-adaptive prediction. In this paper, we use lane as scene data and propose a staged network that Jointly learning Agent and Lane information for Multimodal Trajectory Prediction (JAL-MTP). JAL-MTP use a Social to Lane (S2L) module to jointly represent the static lane and the dynamic motion of the neighboring agents as instance-level lane, a Recurrent Lane Attention (RLA) mechanism for utilizing the instance-level lanes to predict the map-adaptive future trajectories and two selectors to identify the typical and reasonable trajectories. The experiments conducted on the public Argoverse dataset demonstrate that JAL-MTP significantly outperforms the existing models in both quantitative and qualitative.

</p>
</details>

<details><summary><b>ArchRepair: Block-Level Architecture-Oriented Repairing for Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2111.13330">arxiv:2111.13330</a>
&#x1F4C8; 5 <br>
<p>Hua Qi, Zhijie Wang, Qing Guo, Jianlang Chen, Felix Juefei-Xu, Lei Ma, Jianjun Zhao</p></summary>
<p>

**Abstract:** Over the past few years, deep neural networks (DNNs) have achieved tremendous success and have been continuously applied in many application domains. However, during the practical deployment in the industrial tasks, DNNs are found to be erroneous-prone due to various reasons such as overfitting, lacking robustness to real-world corruptions during practical usage. To address these challenges, many recent attempts have been made to repair DNNs for version updates under practical operational contexts by updating weights (i.e., network parameters) through retraining, fine-tuning, or direct weight fixing at a neural level. In this work, as the first attempt, we initiate to repair DNNs by jointly optimizing the architecture and weights at a higher (i.e., block) level.
  We first perform empirical studies to investigate the limitation of whole network-level and layer-level repairing, which motivates us to explore a novel repairing direction for DNN repair at the block level. To this end, we first propose adversarial-aware spectrum analysis for vulnerable block localization that considers the neurons' status and weights' gradients in blocks during the forward and backward processes, which enables more accurate candidate block localization for repairing even under a few examples. Then, we further propose the architecture-oriented search-based repairing that relaxes the targeted block to a continuous repairing search space at higher deep feature levels. By jointly optimizing the architecture and weights in that space, we can identify a much better block architecture. We implement our proposed repairing techniques as a tool, named ArchRepair, and conduct extensive experiments to validate the proposed method. The results show that our method can not only repair but also enhance accuracy & robustness, outperforming the state-of-the-art DNN repair techniques.

</p>
</details>

<details><summary><b>Common Sense Knowledge Learning for Open Vocabulary Neural Reasoning: A First View into Chronic Disease Literature</b>
<a href="https://arxiv.org/abs/2111.13781">arxiv:2111.13781</a>
&#x1F4C8; 4 <br>
<p>Ignacio Arroyo-Fernández, José Armando Sánchez-Rojas, Arturo Tellez-Velázquez, Flavio Juárez-Martínez, Raúl Cruz-Barbosa, Enrique Guzmán-Ramírez, Yalbi Itzel Balderas-Martínez</p></summary>
<p>

**Abstract:** In this paper, we address reasoning tasks from open vocabulary Knowledge Bases (openKBs) using state-of-the-art Neural Language Models (NLMs) with applications in scientific literature. For this purpose, self-attention based NLMs are trained using a common sense KB as a source task. The NLMs are then tested on a target KB for open vocabulary reasoning tasks involving scientific knowledge related to the most prevalent chronic diseases (also known as non-communicable diseases, NCDs). Our results identified NLMs that performed consistently and with significance in knowledge inference for both source and target tasks. Furthermore, in our analysis by inspection we discussed the semantic regularities and reasoning capabilities learned by the models, while showing a first insight into the potential benefits of our approach to aid NCD research.

</p>
</details>

<details><summary><b>BCH-NLP at BioCreative VII Track 3: medications detection in tweets using transformer networks and multi-task learning</b>
<a href="https://arxiv.org/abs/2111.13726">arxiv:2111.13726</a>
&#x1F4C8; 4 <br>
<p>Dongfang Xu, Shan Chen, Timothy Miller</p></summary>
<p>

**Abstract:** In this paper, we present our work participating in the BioCreative VII Track 3 - automatic extraction of medication names in tweets, where we implemented a multi-task learning model that is jointly trained on text classification and sequence labelling. Our best system run achieved a strict F1 of 80.4, ranking first and more than 10 points higher than the average score of all participants. Our analyses show that the ensemble technique, multi-task learning, and data augmentation are all beneficial for medication detection in tweets.

</p>
</details>

<details><summary><b>Efficient Multi-Organ Segmentation Using SpatialConfiguration-Net with Low GPU Memory Requirements</b>
<a href="https://arxiv.org/abs/2111.13630">arxiv:2111.13630</a>
&#x1F4C8; 4 <br>
<p>Franz Thaler, Christian Payer, Horst Bischof, Darko Stern</p></summary>
<p>

**Abstract:** Even though many semantic segmentation methods exist that are able to perform well on many medical datasets, often, they are not designed for direct use in clinical practice. The two main concerns are generalization to unseen data with a different visual appearance, e.g., images acquired using a different scanner, and efficiency in terms of computation time and required Graphics Processing Unit (GPU) memory. In this work, we employ a multi-organ segmentation model based on the SpatialConfiguration-Net (SCN), which integrates prior knowledge of the spatial configuration among the labelled organs to resolve spurious responses in the network outputs. Furthermore, we modified the architecture of the segmentation model to reduce its memory footprint as much as possible without drastically impacting the quality of the predictions. Lastly, we implemented a minimal inference script for which we optimized both, execution time and required GPU memory.

</p>
</details>

<details><summary><b>$μ$NCA: Texture Generation with Ultra-Compact Neural Cellular Automata</b>
<a href="https://arxiv.org/abs/2111.13545">arxiv:2111.13545</a>
&#x1F4C8; 4 <br>
<p>Alexander Mordvintsev, Eyvind Niklasson</p></summary>
<p>

**Abstract:** We study the problem of example-based procedural texture synthesis using highly compact models. Given a sample image, we use differentiable programming to train a generative process, parameterised by a recurrent Neural Cellular Automata (NCA) rule. Contrary to the common belief that neural networks should be significantly over-parameterised, we demonstrate that our model architecture and training procedure allows for representing complex texture patterns using just a few hundred learned parameters, making their expressivity comparable to hand-engineered procedural texture generating programs. The smallest models from the proposed $μ$NCA family scale down to 68 parameters. When using quantisation to one byte per parameter, proposed models can be shrunk to a size range between 588 and 68 bytes. Implementation of a texture generator that uses these parameters to produce images is possible with just a few lines of GLSL or C code.

</p>
</details>

<details><summary><b>A model of semantic completion in generative episodic memory</b>
<a href="https://arxiv.org/abs/2111.13537">arxiv:2111.13537</a>
&#x1F4C8; 4 <br>
<p>Zahra Fayyaz, Aya Altamimi, Sen Cheng, Laurenz Wiskott</p></summary>
<p>

**Abstract:** Many different studies have suggested that episodic memory is a generative process, but most computational models adopt a storage view. In this work, we propose a computational model for generative episodic memory. It is based on the central hypothesis that the hippocampus stores and retrieves selected aspects of an episode as a memory trace, which is necessarily incomplete. At recall, the neocortex reasonably fills in the missing information based on general semantic information in a process we call semantic completion.
  As episodes we use images of digits (MNIST) augmented by different backgrounds representing context. Our model is based on a VQ-VAE which generates a compressed latent representation in form of an index matrix, which still has some spatial resolution. We assume that attention selects some part of the index matrix while others are discarded, this then represents the gist of the episode and is stored as a memory trace. At recall the missing parts are filled in by a PixelCNN, modeling semantic completion, and the completed index matrix is then decoded into a full image by the VQ-VAE.
  The model is able to complete missing parts of a memory trace in a semantically plausible way up to the point where it can generate plausible images from scratch. Due to the combinatorics in the index matrix, the model generalizes well to images not trained on. Compression as well as semantic completion contribute to a strong reduction in memory requirements and robustness to noise. Finally we also model an episodic memory experiment and can reproduce that semantically congruent contexts are always recalled better than incongruent ones, high attention levels improve memory accuracy in both cases, and contexts that are not remembered correctly are more often remembered semantically congruently than completely wrong.

</p>
</details>

<details><summary><b>Using Shapley Values and Variational Autoencoders to Explain Predictive Models with Dependent Mixed Features</b>
<a href="https://arxiv.org/abs/2111.13507">arxiv:2111.13507</a>
&#x1F4C8; 4 <br>
<p>Lars Henry Berge Olsen, Ingrid Kristine Glad, Martin Jullum, Kjersti Aas</p></summary>
<p>

**Abstract:** Shapley values are today extensively used as a model-agnostic explanation framework to explain complex predictive machine learning models. Shapley values have desirable theoretical properties and a sound mathematical foundation. Precise Shapley value estimates for dependent data rely on accurate modeling of the dependencies between all feature combinations. In this paper, we use a variational autoencoder with arbitrary conditioning (VAEAC) to model all feature dependencies simultaneously. We demonstrate through comprehensive simulation studies that VAEAC outperforms the state-of-the-art methods for a wide range of settings for both continuous and mixed dependent features. Finally, we apply VAEAC to the Abalone data set from the UCI Machine Learning Repository.

</p>
</details>

<details><summary><b>When Creators Meet the Metaverse: A Survey on Computational Arts</b>
<a href="https://arxiv.org/abs/2111.13486">arxiv:2111.13486</a>
&#x1F4C8; 4 <br>
<p>Lik-Hang Lee, Zijun Lin, Rui Hu, Zhengya Gong, Abhishek Kumar, Tangyao Li, Sijia Li, Pan Hui</p></summary>
<p>

**Abstract:** The metaverse, enormous virtual-physical cyberspace, has brought unprecedented opportunities for artists to blend every corner of our physical surroundings with digital creativity. This article conducts a comprehensive survey on computational arts, in which seven critical topics are relevant to the metaverse, describing novel artworks in blended virtual-physical realities. The topics first cover the building elements for the metaverse, e.g., virtual scenes and characters, auditory, textual elements. Next, several remarkable types of novel creations in the expanded horizons of metaverse cyberspace have been reflected, such as immersive arts, robotic arts, and other user-centric approaches fuelling contemporary creative outputs. Finally, we propose several research agendas: democratising computational arts, digital privacy, and safety for metaverse artists, ownership recognition for digital artworks, technological challenges, and so on. The survey also serves as introductory material for artists and metaverse technologists to begin creations in the realm of surrealistic cyberspace.

</p>
</details>

<details><summary><b>Learning Long-Term Reward Redistribution via Randomized Return Decomposition</b>
<a href="https://arxiv.org/abs/2111.13485">arxiv:2111.13485</a>
&#x1F4C8; 4 <br>
<p>Zhizhou Ren, Ruihan Guo, Yuan Zhou, Jian Peng</p></summary>
<p>

**Abstract:** Many practical applications of reinforcement learning require agents to learn from sparse and delayed rewards. It challenges the ability of agents to attribute their actions to future outcomes. In this paper, we consider the problem formulation of episodic reinforcement learning with trajectory feedback. It refers to an extreme delay of reward signals, in which the agent can only obtain one reward signal at the end of each trajectory. A popular paradigm for this problem setting is learning with a designed auxiliary dense reward function, namely proxy reward, instead of sparse environmental signals. Based on this framework, this paper proposes a novel reward redistribution algorithm, randomized return decomposition (RRD), to learn a proxy reward function for episodic reinforcement learning. We establish a surrogate problem by Monte-Carlo sampling that scales up least-squares-based reward redistribution to long-horizon problems. We analyze our surrogate loss function by connection with existing methods in the literature, which illustrates the algorithmic properties of our approach. In experiments, we extensively evaluate our proposed method on a variety of benchmark tasks with episodic rewards and demonstrate substantial improvement over baseline algorithms.

</p>
</details>

<details><summary><b>QMagFace: Simple and Accurate Quality-Aware Face Recognition</b>
<a href="https://arxiv.org/abs/2111.13475">arxiv:2111.13475</a>
&#x1F4C8; 4 <br>
<p>Philipp Terhörst, Malte Ihlefeld, Marco Huber, Naser Damer, Florian Kirchbuchner, Kiran Raja, Arjan Kuijper</p></summary>
<p>

**Abstract:** Face recognition systems have to deal with large variabilities (such as different poses, illuminations, and expressions) that might lead to incorrect matching decisions. These variabilities can be measured in terms of face image quality which is defined over the utility of a sample for recognition. Previous works on face recognition either do not employ this valuable information or make use of non-inherently fit quality estimates. In this work, we propose a simple and effective face recognition solution (QMag-Face) that combines a quality-aware comparison score with a recognition model based on a magnitude-aware angular margin loss. The proposed approach includes model-specific face image qualities in the comparison process to enhance the recognition performance under unconstrained circumstances. Exploiting the linearity between the qualities and their comparison scores induced by the utilized loss, our quality-aware comparison function is simple and highly generalizable. The experiments conducted on several face recognition databases and benchmarks demonstrate that the introduced quality-awareness leads to consistent improvements in the recognition performance. Moreover, the proposed QMagFace approach performs especially well under challenging circumstances, such as cross-pose, cross-age, or cross-quality. Consequently, it leads to state-of-the-art performances on several face recognition benchmarks, such as 98.50% on AgeDB, 83.95% on XQLFQ, and 98.74% on CFP-FP. The code for QMagFace is publicly available

</p>
</details>

<details><summary><b>Morphology Decoder: A Machine Learning Guided 3D Vision Quantifying Heterogenous Rock Permeability for Planetary Surveillance and Robotic Functions</b>
<a href="https://arxiv.org/abs/2111.13460">arxiv:2111.13460</a>
&#x1F4C8; 4 <br>
<p>Omar Alfarisi, Aikifa Raza, Djamel Ouzzane, Hongxia Li, Mohamed Sassi, Tiejun Zhang</p></summary>
<p>

**Abstract:** Permeability has a dominant influence on the flow properties of a natural fluid. Lattice Boltzmann simulator determines permeability from the nano and micropore network. The simulator holds millions of flow dynamics calculations with its accumulated errors and high consumption of computing power. To efficiently and consistently predict permeability, we propose a morphology decoder, a parallel and serial flow reconstruction of machine learning segmented heterogeneous Cretaceous texture from 3D micro computerized tomography and nuclear magnetic resonance images. For 3D vision, we introduce controllable-measurable-volume as new supervised segmentation, in which a unique set of voxel intensity corresponds to grain and pore throat sizes. The morphology decoder demarks and aggregates the morphologies boundaries in a novel way to produce permeability. Morphology decoder method consists of five novel processes, which describes in this paper, these novel processes are: (1) Geometrical 3D Permeability, (2) Machine Learning guided 3D Properties Recognition of Rock Morphology, (3) 3D Image Properties Integration Model for Permeability, (4) MRI Permeability Imager, and (5) Morphology Decoder (the process that integrates the other four novel processes).

</p>
</details>

<details><summary><b>Towards Explainable End-to-End Prostate Cancer Relapse Prediction from H&E Images Combining Self-Attention Multiple Instance Learning with a Recurrent Neural Network</b>
<a href="https://arxiv.org/abs/2111.13439">arxiv:2111.13439</a>
&#x1F4C8; 4 <br>
<p>Esther Dietrich, Patrick Fuhlert, Anne Ernst, Guido Sauter, Maximilian Lennartz, H. Siegfried Stiehl, Marina Zimmermann, Stefan Bonn</p></summary>
<p>

**Abstract:** Clinical decision support for histopathology image data mainly focuses on strongly supervised annotations, which offers intuitive interpretability, but is bound by expert performance. Here, we propose an explainable cancer relapse prediction network (eCaReNet) and show that end-to-end learning without strong annotations offers state-of-the-art performance while interpretability can be included through an attention mechanism. On the use case of prostate cancer survival prediction, using 14,479 images and only relapse times as annotations, we reach a cumulative dynamic AUC of 0.78 on a validation set, being on par with an expert pathologist (and an AUC of 0.77 on a separate test set). Our model is well-calibrated and outputs survival curves as well as a risk score and group per patient. Making use of the attention weights of a multiple instance learning layer, we show that malignant patches have a higher influence on the prediction than benign patches, thus offering an intuitive interpretation of the prediction. Our code is available at www.github.com/imsb-uke/ecarenet.

</p>
</details>

<details><summary><b>Confounder Identification-free Causal Visual Feature Learning</b>
<a href="https://arxiv.org/abs/2111.13420">arxiv:2111.13420</a>
&#x1F4C8; 4 <br>
<p>Xin Li, Zhizheng Zhang, Guoqiang Wei, Cuiling Lan, Wenjun Zeng, Xin Jin, Zhibo Chen</p></summary>
<p>

**Abstract:** Confounders in deep learning are in general detrimental to model's generalization where they infiltrate feature representations. Therefore, learning causal features that are free of interference from confounders is important. Most previous causal learning based approaches employ back-door criterion to mitigate the adverse effect of certain specific confounder, which require the explicit identification of confounder. However, in real scenarios, confounders are typically diverse and difficult to be identified. In this paper, we propose a novel Confounder Identification-free Causal Visual Feature Learning (CICF) method, which obviates the need for identifying confounders. CICF models the interventions among different samples based on front-door criterion, and then approximates the global-scope intervening effect upon the instance-level interventions from the perspective of optimization. In this way, we aim to find a reliable optimization direction, which avoids the intervening effects of confounders, to learn causal features. Furthermore, we uncover the relation between CICF and the popular meta-learning strategy MAML, and provide an interpretation of why MAML works from the theoretical perspective of causal learning for the first time. Thanks to the effective learning of causal features, our CICF enables models to have superior generalization capability. Extensive experiments on domain generalization benchmark datasets demonstrate the effectiveness of our CICF, which achieves the state-of-the-art performance.

</p>
</details>

<details><summary><b>Active Learning for Event Extraction with Memory-based Loss Prediction Model</b>
<a href="https://arxiv.org/abs/2112.03073">arxiv:2112.03073</a>
&#x1F4C8; 3 <br>
<p>Shirong Shen, Zhen Li, Guilin Qi</p></summary>
<p>

**Abstract:** Event extraction (EE) plays an important role in many industrial application scenarios, and high-quality EE methods require a large amount of manual annotation data to train supervised learning models. However, the cost of obtaining annotation data is very high, especially for annotation of domain events, which requires the participation of experts from corresponding domain. So we introduce active learning (AL) technology to reduce the cost of event annotation. But the existing AL methods have two main problems, which make them not well used for event extraction. Firstly, the existing pool-based selection strategies have limitations in terms of computational cost and sample validity. Secondly, the existing evaluation of sample importance lacks the use of local sample information. In this paper, we present a novel deep AL method for EE. We propose a batch-based selection strategy and a Memory-Based Loss Prediction model (MBLP) to select unlabeled samples efficiently. During the selection process, we use an internal-external sample loss ranking method to evaluate the sample importance by using local information. Finally, we propose a delayed training strategy to train the MBLP model. Extensive experiments are performed on three domain datasets, and our method outperforms other state-of-the-art methods.

</p>
</details>

<details><summary><b>Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization</b>
<a href="https://arxiv.org/abs/2111.13807">arxiv:2111.13807</a>
&#x1F4C8; 3 <br>
<p>Thanh Nguyen-Tang, Sunil Gupta, A. Tuan Nguyen, Svetha Venkatesh</p></summary>
<p>

**Abstract:** Offline policy learning (OPL) leverages existing data collected a priori for policy optimization without any active exploration. Despite the prevalence and recent interest in this problem, its theoretical and algorithmic foundations in function approximation settings remain under-developed. In this paper, we consider this problem on the axes of distributional shift, optimization, and generalization in offline contextual bandits with neural networks. In particular, we propose a provably efficient offline contextual bandit with neural network function approximation that does not require any functional assumption on the reward. We show that our method provably generalizes over unseen contexts under a milder condition for distributional shift than the existing OPL works. Notably, unlike any other OPL method, our method learns from the offline data in an online manner using stochastic gradient descent, allowing us to leverage the benefits of online learning into an offline setting. Moreover, we show that our method is more computationally efficient and has a better dependence on the effective dimension of the neural network than an online counterpart. Finally, we demonstrate the empirical effectiveness of our method in a range of synthetic and real-world OPL problems.

</p>
</details>

<details><summary><b>Feature Selection for Causal Inference from High Dimensional Observational Data with Outcome Adaptive Elastic Net</b>
<a href="https://arxiv.org/abs/2111.13800">arxiv:2111.13800</a>
&#x1F4C8; 3 <br>
<p>Md Saiful Islam, Md. Noor-E-Alam</p></summary>
<p>

**Abstract:** Feature selection is an extensively studied technique in the machine learning literature where the main objective is to identify the subset of features that provides the highest predictive power. However, in causal inference, our goal is to identify the set of variables that are associated with both the treatment variable and outcome (i.e., the confounders). While controlling for the confounding variables helps us to achieve an unbiased estimate of causal effect, recent research shows that controlling for purely outcome predictors along with the confounders can reduce the variance of the estimate. In this paper, we propose an Outcome Adaptive Elastic-Net (OAENet) method specifically designed for causal inference to select the confounders and outcome predictors for inclusion in the propensity score model or in the matching mechanism. OAENet provides two major advantages over existing methods: it performs superiorly on correlated data, and it can be applied to any matching method and any estimates. In addition, OAENet is computationally efficient compared to state-of-the-art methods.

</p>
</details>

<details><summary><b>OmiTrans: generative adversarial networks based omics-to-omics translation framework</b>
<a href="https://arxiv.org/abs/2111.13785">arxiv:2111.13785</a>
&#x1F4C8; 3 <br>
<p>Xiaoyu Zhang, Yike Guo</p></summary>
<p>

**Abstract:** With the rapid development of high-throughput experimental technologies, different types of omics (e.g., genomics, epigenomics, transcriptomics, proteomics, and metabolomics) data can be produced from clinical samples. The correlations between different omics types attracts a lot of research interest, whereas the stduy on genome-wide omcis data translation (i.e, generation and prediction of one type of omics data from another type of omics data) is almost blank. Generative adversarial networks and the variants are one of the most state-of-the-art deep learning technologies, which have shown great success in image-to-image translation, text-to-image translation, etc. Here we proposed OmiTrans, a deep learning framework adopted the idea of generative adversarial networks to achieve omics-to-omics translation with promising results. OmiTrans was able to faithfully reconstruct gene expression profiles from DNA methylation data with high accuracy and great model generalisation, as demonstrated in the experiments.

</p>
</details>

<details><summary><b>SARS-CoV-2 Dissemination using a Network of the United States Counties</b>
<a href="https://arxiv.org/abs/2111.13723">arxiv:2111.13723</a>
&#x1F4C8; 3 <br>
<p>Patrick Urrutia, David Wren, Chrysafis Vogiatzis, Ruriko Yoshida</p></summary>
<p>

**Abstract:** During 2020 and 2021, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission has been increasing amongst the world's population at an alarming rate. Reducing the spread of SARS-CoV-2 and other diseases that are spread in similar manners is paramount for public health officials as they seek to effectively manage resources and potential population control measures such as social distancing and quarantines. By analyzing the United States' county network structure, one can model and interdict potential higher infection areas. County officials can provide targeted information, preparedness training, as well as increase testing in these areas. While these approaches may provide adequate countermeasures for localized areas, they are inadequate for the holistic United States. We solve this problem by collecting coronavirus disease 2019 (COVID-19) infections and deaths from the Center for Disease Control and Prevention and a network adjacency structure from the United States Census Bureau. Generalized network autoregressive (GNAR) time series models have been proposed as an efficient learning algorithm for networked datasets. This work fuses network science and operations research techniques to univariately model COVID-19 cases, deaths, and current survivors across the United States' county network structure.

</p>
</details>

<details><summary><b>On the combination of graph data for assessing thin-file borrowers' creditworthiness</b>
<a href="https://arxiv.org/abs/2111.13666">arxiv:2111.13666</a>
&#x1F4C8; 3 <br>
<p>Ricardo Muñoz-Cancino, Cristián Bravo, Sebastián A. Ríos, Manuel Graña</p></summary>
<p>

**Abstract:** The thin-file borrowers are customers for whom a creditworthiness assessment is uncertain due to their lack of credit history; many researchers have used borrowers' relationships and interactions networks in the form of graphs as an alternative data source to address this. Incorporating network data is traditionally made by hand-crafted feature engineering, and lately, the graph neural network has emerged as an alternative, but it still does not improve over the traditional method's performance. Here we introduce a framework to improve credit scoring models by blending several Graph Representation Learning methods: feature engineering, graph embeddings, and graph neural networks. We stacked their outputs to produce a single score in this approach. We validated this framework using a unique multi-source dataset that characterizes the relationships and credit history for the entire population of a Latin American country, applying it to credit risk models, application, and behavior, targeting both individuals and companies.
  Our results show that the graph representation learning methods should be used as complements, and these should not be seen as self-sufficient methods as is currently done. In terms of AUC and KS, we enhance the statistical performance, outperforming traditional methods.
  In Corporate lending, where the gain is much higher, it confirms that evaluating an unbanked company cannot solely consider its features. The business ecosystem where these firms interact with their owners, suppliers, customers, and other companies provides novel knowledge that enables financial institutions to enhance their creditworthiness assessment.
  Our results let us know when and which group to use graph data and what effects on performance to expect. They also show the enormous value of graph data on the unbanked credit scoring problem, principally to help companies' banking.

</p>
</details>

<details><summary><b>Amazon SageMaker Model Monitor: A System for Real-Time Insights into Deployed Machine Learning Models</b>
<a href="https://arxiv.org/abs/2111.13657">arxiv:2111.13657</a>
&#x1F4C8; 3 <br>
<p>David Nigenda, Zohar Karnin, Muhammad Bilal Zafar, Raghu Ramesha, Alan Tan, Michele Donini, Krishnaram Kenthapadi</p></summary>
<p>

**Abstract:** With the increasing adoption of machine learning (ML) models and systems in high-stakes settings across different industries, guaranteeing a model's performance after deployment has become crucial. Monitoring models in production is a critical aspect of ensuring their continued performance and reliability. We present Amazon SageMaker Model Monitor, a fully managed service that continuously monitors the quality of machine learning models hosted on Amazon SageMaker. Our system automatically detects data, concept, bias, and feature attribution drift in models in real-time and provides alerts so that model owners can take corrective actions and thereby maintain high quality models. We describe the key requirements obtained from customers, system design and architecture, and methodology for detecting different types of drift. Further, we provide quantitative evaluations followed by use cases, insights, and lessons learned from more than 1.5 years of production deployment.

</p>
</details>

<details><summary><b>Uncovering the Dark Side of Telegram: Fakes, Clones, Scams, and Conspiracy Movements</b>
<a href="https://arxiv.org/abs/2111.13530">arxiv:2111.13530</a>
&#x1F4C8; 3 <br>
<p>Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini, Jie Wu</p></summary>
<p>

**Abstract:** Telegram is one of the most used instant messaging apps worldwide. Some of its success lies in providing high privacy protection and social network features like the channels -- virtual rooms in which only the admins can post and broadcast messages to all its subscribers. However, these same features contributed to the emergence of borderline activities and, as is common with Online Social Networks, the heavy presence of fake accounts. Telegram started to address these issues by introducing the verified and scam marks for the channels. Unfortunately, the problem is far from being solved. In this work, we perform a large-scale analysis of Telegram by collecting 35,382 different channels and over 130,000,000 messages. We study the channels that Telegram marks as verified or scam, highlighting analogies and differences. Then, we move to the unmarked channels. Here, we find some of the infamous activities also present on privacy-preserving services of the Dark Web, such as carding, sharing of illegal adult and copyright protected content. In addition, we identify and analyze two other types of channels: the clones and the fakes. Clones are channels that publish the exact content of another channel to gain subscribers and promote services. Instead, fakes are channels that attempt to impersonate celebrities or well-known services. Fakes are hard to identify even by the most advanced users. To detect the fake channels automatically, we propose a machine learning model that is able to identify them with an accuracy of 86%. Lastly, we study Sabmyk, a conspiracy theory that exploited fakes and clones to spread quickly on the platform reaching over 1,000,000 users.

</p>
</details>

<details><summary><b>Learning source-aware representations of music in a discrete latent space</b>
<a href="https://arxiv.org/abs/2111.13321">arxiv:2111.13321</a>
&#x1F4C8; 3 <br>
<p>Jinsung Kim, Yeong-Seok Jeong, Woosung Choi, Jaehwa Chung, Soonyoung Jung</p></summary>
<p>

**Abstract:** In recent years, neural network based methods have been proposed as a method that cangenerate representations from music, but they are not human readable and hardly analyzable oreditable by a human. To address this issue, we propose a novel method to learn source-awarelatent representations of music through Vector-Quantized Variational Auto-Encoder(VQ-VAE).We train our VQ-VAE to encode an input mixture into a tensor of integers in a discrete latentspace, and design them to have a decomposed structure which allows humans to manipulatethe latent vector in a source-aware manner. This paper also shows that we can generate basslines by estimating latent vectors in a discrete space.

</p>
</details>

<details><summary><b>Machine Unlearning: Learning, Polluting, and Unlearning for Spam Email</b>
<a href="https://arxiv.org/abs/2111.14609">arxiv:2111.14609</a>
&#x1F4C8; 2 <br>
<p>Nishchal Parne, Kyathi Puppaala, Nithish Bhupathi, Ripon Patgiri</p></summary>
<p>

**Abstract:** Machine unlearning for security is studied in this context. Several spam email detection methods exist, each of which employs a different algorithm to detect undesired spam emails. But these models are vulnerable to attacks. Many attackers exploit the model by polluting the data, which are trained to the model in various ways. So to act deftly in such situations model needs to readily unlearn the polluted data without the need for retraining. Retraining is impractical in most cases as there is already a massive amount of data trained to the model in the past, which needs to be trained again just for removing a small amount of polluted data, which is often significantly less than 1%. This problem can be solved by developing unlearning frameworks for all spam detection models. In this research, unlearning module is integrated into spam detection models that are based on Naive Bayes, Decision trees, and Random Forests algorithms. To assess the benefits of unlearning over retraining, three spam detection models are polluted and exploited by taking attackers' positions and proving models' vulnerability. Reduction in accuracy and true positive rates are shown in each case showing the effect of pollution on models. Then unlearning modules are integrated into the models, and polluted data is unlearned; on testing the models after unlearning, restoration of performance is seen. Also, unlearning and retraining times are compared with different pollution data sizes on all models. On analyzing the findings, it can be concluded that unlearning is considerably superior to retraining. Results show that unlearning is fast, easy to implement, easy to use, and effective.

</p>
</details>

<details><summary><b>Towards Efficient Ansatz Architecture for Variational Quantum Algorithms</b>
<a href="https://arxiv.org/abs/2111.13730">arxiv:2111.13730</a>
&#x1F4C8; 2 <br>
<p>Anbang Wu, Gushu Li, Yuke Wang, Boyuan Feng, Yufei Ding, Yuan Xie</p></summary>
<p>

**Abstract:** Variational quantum algorithms are expected to demonstrate the advantage of quantum computing on near-term noisy quantum computers. However, training such variational quantum algorithms suffers from gradient vanishing as the size of the algorithm increases. Previous work cannot handle the gradient vanishing induced by the inevitable noise effects on realistic quantum hardware. In this paper, we propose a novel training scheme to mitigate such noise-induced gradient vanishing. We first introduce a new cost function of which the gradients are significantly augmented by employing traceless observables in truncated subspace. We then prove that the same minimum can be reached by optimizing the original cost function with the gradients from the new cost function. Experiments show that our new training scheme is highly effective for major variational quantum algorithms of various tasks.

</p>
</details>

<details><summary><b>A Ubiquitous Unifying Degeneracy in 2-body Microlensing Systems</b>
<a href="https://arxiv.org/abs/2111.13696">arxiv:2111.13696</a>
&#x1F4C8; 2 <br>
<p>Keming Zhang, B. Scott Gaudi, Joshua S. Bloom</p></summary>
<p>

**Abstract:** While gravitational microlensing by planetary systems can provide unique vistas on the properties of exoplanets, observations of such 2-body microlensing events can often be explained with multiple and distinct physical configurations, so-called model degeneracies. An understanding of the intrinsic and exogenous origins of different classes of degeneracy provides a foundation for phenomenological interpretation. Here, leveraging a fast machine-learning based inference framework, we present the discovery of a new regime of degeneracy--the offset degeneracy--which unifies the previously known close-wide and inner-outer degeneracies, generalises to resonant caustics, and upon reanalysis, is ubiquitous in previously published planetary events with 2-fold degenerate solutions. Importantly, our discovery suggests that the commonly reported close-wide degeneracy essentially never arises in actual events and should, instead, be more suitably viewed as a transition point of the offset degeneracy. While previous studies of microlensing degeneracies are largely studies of degenerate caustics, our discovery demonstrates that degenerate caustics do not necessarily result in degenerate events, which for the latter it is more relevant to study magnifications at the location of the source. This discovery fundamentally changes the way in which degeneracies in planetary microlensing events should be interpreted, suggests a deeper symmetry in the mathematics of 2-body lenses than has previously been recognised, and will increasingly manifest itself in data from new generations of microlensing surveys.

</p>
</details>

<details><summary><b>Conditional Manifold Learning</b>
<a href="https://arxiv.org/abs/2111.13646">arxiv:2111.13646</a>
&#x1F4C8; 2 <br>
<p>Anh Tuan Bui</p></summary>
<p>

**Abstract:** This paper addresses a problem called "conditional manifold learning", which aims to learn a low-dimensional manifold embedding of high-dimensional data, conditioning on auxiliary manifold information. This auxiliary manifold information is from controllable or measurable conditions, which are ubiquitous in many science and engineering applications. A broad class of solutions for this problem, conditional multidimensional scaling (including a conditional ISOMAP variant), is proposed. A conditional version of the SMACOF algorithm is introduced to optimize the objective function of conditional multidimensional scaling.

</p>
</details>

<details><summary><b>DP-SGD vs PATE: Which Has Less Disparate Impact on GANs?</b>
<a href="https://arxiv.org/abs/2111.13617">arxiv:2111.13617</a>
&#x1F4C8; 2 <br>
<p>Georgi Ganev</p></summary>
<p>

**Abstract:** Generative Adversarial Networks (GANs) are among the most popular approaches to generate synthetic data, especially images, for data sharing purposes. Given the vital importance of preserving the privacy of the individual data points in the original data, GANs are trained utilizing frameworks with robust privacy guarantees such as Differential Privacy (DP). However, these approaches remain widely unstudied beyond single performance metrics when presented with imbalanced datasets. To this end, we systematically compare GANs trained with the two best-known DP frameworks for deep learning, DP-SGD, and PATE, in different data imbalance settings from two perspectives -- the size of the classes in the generated synthetic data and their classification performance.
  Our analyses show that applying PATE, similarly to DP-SGD, has a disparate effect on the under/over-represented classes but in a much milder magnitude making it more robust. Interestingly, our experiments consistently show that for PATE, unlike DP-SGD, the privacy-utility trade-off is not monotonically decreasing but is much smoother and inverted U-shaped, meaning that adding a small degree of privacy actually helps generalization. However, we have also identified some settings (e.g., large imbalance) where PATE-GAN completely fails to learn some subparts of the training data.

</p>
</details>

<details><summary><b>The Geometry of Adversarial Training in Binary Classification</b>
<a href="https://arxiv.org/abs/2111.13613">arxiv:2111.13613</a>
&#x1F4C8; 2 <br>
<p>Leon Bungert, Nicolás García Trillos, Ryan Murray</p></summary>
<p>

**Abstract:** We establish an equivalence between a family of adversarial training problems for non-parametric binary classification and a family of regularized risk minimization problems where the regularizer is a nonlocal perimeter functional. The resulting regularized risk minimization problems admit exact convex relaxations of the type $L^1+$ (nonlocal) $\operatorname{TV}$, a form frequently studied in image analysis and graph-based learning. A rich geometric structure is revealed by this reformulation which in turn allows us to establish a series of properties of optimal solutions of the original problem, including the existence of minimal and maximal solutions (interpreted in a suitable sense), and the existence of regular solutions (also interpreted in a suitable sense). In addition, we highlight how the connection between adversarial training and perimeter minimization problems provides a novel, directly interpretable, statistical motivation for a family of regularized risk minimization problems involving perimeter/total variation. The majority of our theoretical results are independent of the distance used to define adversarial attacks.

</p>
</details>

<details><summary><b>On Recurrent Neural Networks for learning-based control: recent results and ideas for future developments</b>
<a href="https://arxiv.org/abs/2111.13557">arxiv:2111.13557</a>
&#x1F4C8; 2 <br>
<p>Fabio Bonassi, Marcello Farina, Jing Xie, Riccardo Scattolini</p></summary>
<p>

**Abstract:** This paper aims to discuss and analyze the potentialities of Recurrent Neural Networks (RNN) in control design applications. The main families of RNN are considered, namely Neural Nonlinear AutoRegressive eXogenous, (NNARX), Echo State Networks (ESN), Long Short Term Memory (LSTM), and Gated Recurrent Units (GRU). The goal is twofold. Firstly, to survey recent results concerning the training of RNN that enjoy Input-to-State Stability (ISS) and Incremental Input-to-State Stability (δISS) guarantees. Secondly, to discuss the issues that still hinder the widespread use of RNN for control, namely their robustness, verifiability, and interpretability. The former properties are related to the so-called generalization capabilities of the networks, i.e. their consistency with the underlying real plants, even in presence of unseen or perturbed input trajectories. The latter is instead related to the possibility of providing a clear formal connection between the RNN model and the plant. In this context, we illustrate how ISS and δISS represent a significant step towards the robustness and verifiability of the RNN models, while the requirement of interpretability paves the way to the use of physics-based networks. The design of model predictive controllers with RNN as plant's model is also briefly discussed. Lastly, some of the main topics of the paper are illustrated on a simulated chemical system.

</p>
</details>

<details><summary><b>A Taxonomy of Anomalies in Log Data</b>
<a href="https://arxiv.org/abs/2111.13462">arxiv:2111.13462</a>
&#x1F4C8; 2 <br>
<p>Thorsten Wittkopp, Philipp Wiesner, Dominik Scheinert, Odej Kao</p></summary>
<p>

**Abstract:** Log data anomaly detection is a core component in the area of artificial intelligence for IT operations. However, the large amount of existing methods makes it hard to choose the right approach for a specific system. A better understanding of different kinds of anomalies, and which algorithms are suitable for detecting them, would support researchers and IT operators. Although a common taxonomy for anomalies already exists, it has not yet been applied specifically to log data, pointing out the characteristics and peculiarities in this domain.
  In this paper, we present a taxonomy for different kinds of log data anomalies and introduce a method for analyzing such anomalies in labeled datasets. We applied our taxonomy to the three common benchmark datasets Thunderbird, Spirit, and BGL, and trained five state-of-the-art unsupervised anomaly detection algorithms to evaluate their performance in detecting different kinds of anomalies. Our results show, that the most common anomaly type is also the easiest to predict. Moreover, deep learning-based approaches outperform data mining-based approaches in all anomaly types, but especially when it comes to detecting contextual anomalies.

</p>
</details>

<details><summary><b>A Novel Machine Learning Approach to Data Inconsistency with respect to a Fuzzy Relation</b>
<a href="https://arxiv.org/abs/2111.13447">arxiv:2111.13447</a>
&#x1F4C8; 2 <br>
<p>Marko Palangetić, Chris Cornelis, Salvatore Greco, Roman Słowiński</p></summary>
<p>

**Abstract:** Inconsistency in prediction problems occurs when instances that relate in a certain way on condition attributes, do not follow the same relation on the decision attribute. For example, in ordinal classification with monotonicity constraints, it occurs when an instance dominating another instance on condition attributes has been assigned to a worse decision class. It typically appears as a result of perturbation in data caused by incomplete knowledge (missing attributes) or by random effects that occur during data generation (instability in the assessment of decision attribute values). Inconsistencies with respect to a crisp preorder relation (expressing either dominance or indiscernibility between instances) can be handled using symbolic approaches like rough set theory and by using statistical/machine learning approaches that involve optimization methods. Fuzzy rough sets can also be seen as a symbolic approach to inconsistency handling with respect to a fuzzy relation. In this article, we introduce a new machine learning method for inconsistency handling with respect to a fuzzy preorder relation. The novel approach is motivated by the existing machine learning approach used for crisp relations. We provide statistical foundations for it and develop optimization procedures that can be used to eliminate inconsistencies. The article also proves important properties and contains didactic examples of those procedures.

</p>
</details>

<details><summary><b>Geometric Multimodal Deep Learning with Multi-Scaled Graph Wavelet Convolutional Network</b>
<a href="https://arxiv.org/abs/2111.13361">arxiv:2111.13361</a>
&#x1F4C8; 2 <br>
<p>Maysam Behmanesh, Peyman Adibi, Mohammad Saeed Ehsani, Jocelyn Chanussot</p></summary>
<p>

**Abstract:** Multimodal data provide complementary information of a natural phenomenon by integrating data from various domains with very different statistical properties. Capturing the intra-modality and cross-modality information of multimodal data is the essential capability of multimodal learning methods. The geometry-aware data analysis approaches provide these capabilities by implicitly representing data in various modalities based on their geometric underlying structures. Also, in many applications, data are explicitly defined on an intrinsic geometric structure. Generalizing deep learning methods to the non-Euclidean domains is an emerging research field, which has recently been investigated in many studies. Most of those popular methods are developed for unimodal data. In this paper, a multimodal multi-scaled graph wavelet convolutional network (M-GWCN) is proposed as an end-to-end network. M-GWCN simultaneously finds intra-modality representation by applying the multiscale graph wavelet transform to provide helpful localization properties in the graph domain of each modality, and cross-modality representation by learning permutations that encode correlations among various modalities. M-GWCN is not limited to either the homogeneous modalities with the same number of data, or any prior knowledge indicating correspondences between modalities. Several semi-supervised node classification experiments have been conducted on three popular unimodal explicit graph-based datasets and five multimodal implicit ones. The experimental results indicate the superiority and effectiveness of the proposed methods compared with both spectral graph domain convolutional neural networks and state-of-the-art multimodal methods.

</p>
</details>

<details><summary><b>Implicit Data-Driven Regularization in Deep Neural Networks under SGD</b>
<a href="https://arxiv.org/abs/2111.13331">arxiv:2111.13331</a>
&#x1F4C8; 2 <br>
<p>Xuran Meng, Jianfeng Yao</p></summary>
<p>

**Abstract:** Much research effort has been devoted to explaining the success of deep learning. Random Matrix Theory (RMT) provides an emerging way to this end: spectral analysis of large random matrices involved in a trained deep neural network (DNN) such as weight matrices or Hessian matrices with respect to the stochastic gradient descent algorithm. In this paper, we conduct extensive experiments on weight matrices in different modules, e.g., layers, networks and data sets, to analyze the evolution of their spectra. We find that these spectra can be classified into three main types: Marčenko-Pastur spectrum (MP), Marčenko-Pastur spectrum with few bleeding outliers (MPB), and Heavy tailed spectrum (HT). Moreover, these discovered spectra are directly connected to the degree of regularization in the DNN. We argue that the degree of regularization depends on the quality of data fed to the DNN, namely Data-Driven Regularization. These findings are validated in several NNs, using Gaussian synthetic data and real data sets (MNIST and CIFAR10). Finally, we propose a spectral criterion and construct an early stopping procedure when the NN is found highly regularized without test data by using the connection between the spectra types and the degrees of regularization. Such early stopped DNNs avoid unnecessary extra training while preserving a much comparable generalization ability.

</p>
</details>

<details><summary><b>Nonequilibrium Monte Carlo for unfreezing variables in hard combinatorial optimization</b>
<a href="https://arxiv.org/abs/2111.13628">arxiv:2111.13628</a>
&#x1F4C8; 1 <br>
<p>Masoud Mohseni, Daniel Eppens, Johan Strumpfer, Raffaele Marino, Vasil Denchev, Alan K. Ho, Sergei V. Isakov, Sergio Boixo, Federico Ricci-Tersenghi, Hartmut Neven</p></summary>
<p>

**Abstract:** Optimizing highly complex cost/energy functions over discrete variables is at the heart of many open problems across different scientific disciplines and industries. A major obstacle is the emergence of many-body effects among certain subsets of variables in hard instances leading to critical slowing down or collective freezing for known stochastic local search strategies. An exponential computational effort is generally required to unfreeze such variables and explore other unseen regions of the configuration space. Here, we introduce a quantum-inspired family of nonlocal Nonequilibrium Monte Carlo (NMC) algorithms by developing an adaptive gradient-free strategy that can efficiently learn key instance-wise geometrical features of the cost function. That information is employed on-the-fly to construct spatially inhomogeneous thermal fluctuations for collectively unfreezing variables at various length scales, circumventing costly exploration versus exploitation trade-offs. We apply our algorithm to two of the most challenging combinatorial optimization problems: random k-satisfiability (k-SAT) near the computational phase transitions and Quadratic Assignment Problems (QAP). We observe significant speedup and robustness over both specialized deterministic solvers and generic stochastic solvers. In particular, for 90% of random 4-SAT instances we find solutions that are inaccessible for the best specialized deterministic algorithm known as Survey Propagation (SP) with an order of magnitude improvement in the quality of solutions for the hardest 10% instances. We also demonstrate two orders of magnitude improvement in time-to-solution over the state-of-the-art generic stochastic solver known as Adaptive Parallel Tempering (APT).

</p>
</details>

<details><summary><b>Graph-based Solutions with Residuals for Intrusion Detection: the Modified E-GraphSAGE and E-ResGAT Algorithms</b>
<a href="https://arxiv.org/abs/2111.13597">arxiv:2111.13597</a>
&#x1F4C8; 1 <br>
<p>Liyan Chang, Paula Branco</p></summary>
<p>

**Abstract:** The high volume of increasingly sophisticated cyber threats is drawing growing attention to cybersecurity, where many challenges remain unresolved. Namely, for intrusion detection, new algorithms that are more robust, effective, and able to use more information are needed. Moreover, the intrusion detection task faces a serious challenge associated with the extreme class imbalance between normal and malicious traffics. Recently, graph-neural network (GNN) achieved state-of-the-art performance to model the network topology in cybersecurity tasks. However, only a few works exist using GNNs to tackle the intrusion detection problem. Besides, other promising avenues such as applying the attention mechanism are still under-explored. This paper presents two novel graph-based solutions for intrusion detection, the modified E-GraphSAGE, and E-ResGATalgorithms, which rely on the established GraphSAGE and graph attention network (GAT), respectively. The key idea is to integrate residual learning into the GNN leveraging the available graph information. Residual connections are added as a strategy to deal with the high-class imbalance, aiming at retaining the original information and improving the minority classes' performance. An extensive experimental evaluation of four recent intrusion detection datasets shows the excellent performance of our approaches, especially when predicting minority classes.

</p>
</details>

<details><summary><b>Deep Learning for Reaction-Diffusion Glioma Growth Modelling: Towards a Fully Personalised Model?</b>
<a href="https://arxiv.org/abs/2111.13404">arxiv:2111.13404</a>
&#x1F4C8; 1 <br>
<p>Corentin Martens, Antonin Rovai, Daniele Bonatto, Thierry Metens, Olivier Debeir, Christine Decaestecker, Serge Goldman, Gaetan Van Simaeys</p></summary>
<p>

**Abstract:** Reaction-diffusion models have been proposed for decades to capture the growth of gliomas, the most common primary brain tumours. However, severe limitations regarding the estimation of the initial conditions and parameter values of such models have restrained their clinical use as a personalised tool. In this work, we investigate the ability of deep convolutional neural networks (DCNNs) to address the pitfalls commonly encountered in the field. Based on 1,200 synthetic tumours grown over real brain geometries derived from magnetic resonance (MR) data of 6 healthy subjects, we demonstrate the ability of DCNNs to reconstruct a whole tumour cell density distribution from only two imaging contours at a single time point. With an additional imaging contour extracted at a prior time point, we also demonstrate the ability of DCNNs to accurately estimate the individual diffusivity and proliferation parameters of the model. From this knowledge, the spatio-temporal evolution of the tumour cell density distribution at later time points can ultimately be precisely captured using the model. We finally show the applicability of our approach to MR data of a real glioblastoma patient. This approach may open the perspective of a clinical application of reaction-diffusion growth models for tumour prognosis and treatment planning.

</p>
</details>

<details><summary><b>Testability-Aware Low Power Controller Design with Evolutionary Learning</b>
<a href="https://arxiv.org/abs/2111.13332">arxiv:2111.13332</a>
&#x1F4C8; 1 <br>
<p>Min Li, Zhengyuan Shi, Zezhong Wang, Weiwei Zhang, Yu Huang, Qiang Xu</p></summary>
<p>

**Abstract:** XORNet-based low power controller is a popular technique to reduce circuit transitions in scan-based testing. However, existing solutions construct the XORNet evenly for scan chain control, and it may result in sub-optimal solutions without any design guidance. In this paper, we propose a novel testability-aware low power controller with evolutionary learning. The XORNet generated from the proposed genetic algorithm (GA) enables adaptive control for scan chains according to their usages, thereby significantly improving XORNet encoding capacity, reducing the number of failure cases with ATPG and decreasing test data volume. Experimental results indicate that under the same control bits, our GA-guided XORNet design can improve the fault coverage by up to 2.11%. The proposed GA-guided XORNets also allows reducing the number of control bits, and the total testing time decreases by 20.78% on average and up to 47.09% compared to the existing design without sacrificing test coverage.

</p>
</details>

<details><summary><b>Cyclic Graph Attentive Match Encoder (CGAME): A Novel Neural Network For OD Estimation</b>
<a href="https://arxiv.org/abs/2111.14625">arxiv:2111.14625</a>
&#x1F4C8; 0 <br>
<p>Guanzhou Li, Yujing He, Jianping Wu</p></summary>
<p>

**Abstract:** Origin-Destination Estimation plays an important role in traffic management and traffic simulation in the era of Intelligent Transportation System (ITS). Nevertheless, previous model-based models face the under-determined challenge, thus desperate demand for additional assumptions and extra data exists. Deep learning provides an ideal data-based method for connecting inputs and results by probabilistic distribution transformation. While relevant researches of applying deep learning into OD estimation are limited due to the challenges lying in data transformation across representation space, especially from dynamic spatial-temporal space to heterogeneous graph in this issue. To address it, we propose Cyclic Graph Attentive Matching Encoder (C-GAME) based on a novel Graph Matcher with double-layer attention mechanism. It realizes effective information exchange in underlying feature space and establishes coupling relationship across spaces. The proposed model achieves state-of-the-art results in experiments, and offers a novel framework for inference task across spaces in prospective employments.

</p>
</details>

<details><summary><b>PicArrange -- Visually Sort, Search, and Explore Private Images on a Mac Computer</b>
<a href="https://arxiv.org/abs/2111.13363">arxiv:2111.13363</a>
&#x1F4C8; 0 <br>
<p>Klaus Jung, Kai Uwe Barthel, Nico Hezel, Konstantin Schall</p></summary>
<p>

**Abstract:** The native macOS application PicArrange integrates state-of-the-art image sorting and similarity search to enable users to get a better overview of their images. Many file and image management features have been added to make it a tool that addresses a full image management workflow. A modification of the Self Sorting Map algorithm enables a list-like image arrangement without loosing the visual sorting. Efficient calculation and storage of visual features as well as the use of many macOS APIs result in an application that is fluid to use.

</p>
</details>


[Next Page]({{ '/2021/11/25/2021.11.25.html' | relative_url }})
