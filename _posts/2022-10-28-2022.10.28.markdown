Prev: [2022.10.27]({{ '/2022/10/27/2022.10.27.html' | relative_url }})  Next: [2022.10.29]({{ '/2022/10/29/2022.10.29.html' | relative_url }})
{% raw %}
## Summary for 2022-10-28, created on 2022-11-07


<details><summary><b>NNSVS: A Neural Network-Based Singing Voice Synthesis Toolkit</b>
<a href="https://arxiv.org/abs/2210.15987">arxiv:2210.15987</a>
&#x1F4C8; 143 <br>
<p>Ryuichi Yamamoto, Reo Yoneyama, Tomoki Toda</p></summary>
<p>

**Abstract:** This paper describes the design of NNSVS, an open-source software for neural network-based singing voice synthesis research. NNSVS is inspired by Sinsy, an open-source pioneer in singing voice synthesis research, and provides many additional features such as multi-stream models, autoregressive fundamental frequency models, and neural vocoders. Furthermore, NNSVS provides extensive documentation and numerous scripts to build complete singing voice synthesis systems. Experimental results demonstrate that our best system significantly outperforms our reproduction of Sinsy and other baseline systems. The toolkit is available at https://github.com/nnsvs/nnsvs.

</p>
</details>

<details><summary><b>Data-driven discovery of Green's functions</b>
<a href="https://arxiv.org/abs/2210.16016">arxiv:2210.16016</a>
&#x1F4C8; 130 <br>
<p>Nicolas Boull√©</p></summary>
<p>

**Abstract:** Discovering hidden partial differential equations (PDEs) and operators from data is an important topic at the frontier between machine learning and numerical analysis. This doctoral thesis introduces theoretical results and deep learning algorithms to learn Green's functions associated with linear partial differential equations and rigorously justify PDE learning techniques. A theoretically rigorous algorithm is derived to obtain a learning rate, which characterizes the amount of training data needed to approximately learn Green's functions associated with elliptic PDEs. The construction connects the fields of PDE learning and numerical linear algebra by extending the randomized singular value decomposition to non-standard Gaussian vectors and Hilbert--Schmidt operators, and exploiting the low-rank hierarchical structure of Green's functions using hierarchical matrices. Rational neural networks (NNs) are introduced and consist of neural networks with trainable rational activation functions. The highly compositional structure of these networks, combined with rational approximation theory, implies that rational functions have higher approximation power than standard activation functions. In addition, rational NNs may have poles and take arbitrarily large values, which is ideal for approximating functions with singularities such as Green's functions. Finally, theoretical results on Green's functions and rational NNs are combined to design a human-understandable deep learning method for discovering Green's functions from data. This approach complements state-of-the-art PDE learning techniques, as a wide range of physics can be captured from the learned Green's functions such as dominant modes, symmetries, and singularity locations.

</p>
</details>

<details><summary><b>Lightweight and High-Fidelity End-to-End Text-to-Speech with Multi-Band Generation and Inverse Short-Time Fourier Transform</b>
<a href="https://arxiv.org/abs/2210.15975">arxiv:2210.15975</a>
&#x1F4C8; 61 <br>
<p>Masaya Kawamura, Yuma Shirahata, Ryuichi Yamamoto, Kentaro Tachibana</p></summary>
<p>

**Abstract:** We propose a lightweight end-to-end text-to-speech model using multi-band generation and inverse short-time Fourier transform. Our model is based on VITS, a high-quality end-to-end text-to-speech model, but adopts two changes for more efficient inference: 1) the most computationally expensive component is partially replaced with a simple inverse short-time Fourier transform, and 2) multi-band generation, with fixed or trainable synthesis filters, is used to generate waveforms. Unlike conventional lightweight models, which employ optimization or knowledge distillation separately to train two cascaded components, our method enjoys the full benefits of end-to-end optimization. Experimental results show that our model synthesized speech as natural as that synthesized by VITS, while achieving a real-time factor of 0.066 on an Intel Core i7 CPU, 4.1 times faster than VITS. Moreover, a smaller version of the model significantly outperformed a lightweight baseline model with respect to both naturalness and inference speed. Code and audio samples are available from https://github.com/MasayaKawamura/MB-iSTFT-VITS.

</p>
</details>

<details><summary><b>Stop Measuring Calibration When Humans Disagree</b>
<a href="https://arxiv.org/abs/2210.16133">arxiv:2210.16133</a>
&#x1F4C8; 29 <br>
<p>Joris Baan, Wilker Aziz, Barbara Plank, Raquel Fernandez</p></summary>
<p>

**Abstract:** Calibration is a popular framework to evaluate whether a classifier knows when it does not know - i.e., its predictive probabilities are a good indication of how likely a prediction is to be correct. Correctness is commonly estimated against the human majority class. Recently, calibration to human majority has been measured on tasks where humans inherently disagree about which class applies. We show that measuring calibration to human majority given inherent disagreements is theoretically problematic, demonstrate this empirically on the ChaosNLI dataset, and derive several instance-level measures of calibration that capture key statistical properties of human judgements - class frequency, ranking and entropy.

</p>
</details>

<details><summary><b>Subsidiary Prototype Alignment for Universal Domain Adaptation</b>
<a href="https://arxiv.org/abs/2210.15909">arxiv:2210.15909</a>
&#x1F4C8; 26 <br>
<p>Jogendra Nath Kundu, Suvaansh Bhambri, Akshay Kulkarni, Hiran Sarkar, Varun Jampani, R. Venkatesh Babu</p></summary>
<p>

**Abstract:** Universal Domain Adaptation (UniDA) deals with the problem of knowledge transfer between two datasets with domain-shift as well as category-shift. The goal is to categorize unlabeled target samples, either into one of the "known" categories or into a single "unknown" category. A major problem in UniDA is negative transfer, i.e. misalignment of "known" and "unknown" classes. To this end, we first uncover an intriguing tradeoff between negative-transfer-risk and domain-invariance exhibited at different layers of a deep network. It turns out we can strike a balance between these two metrics at a mid-level layer. Towards designing an effective framework based on this insight, we draw motivation from Bag-of-visual-Words (BoW). Word-prototypes in a BoW-like representation of a mid-level layer would represent lower-level visual primitives that are likely to be unaffected by the category-shift in the high-level features. We develop modifications that encourage learning of word-prototypes followed by word-histogram based classification. Following this, subsidiary prototype-space alignment (SPA) can be seen as a closed-set alignment problem, thereby avoiding negative transfer. We realize this with a novel word-histogram-related pretext task to enable closed-set SPA, operating in conjunction with goal task UniDA. We demonstrate the efficacy of our approach on top of existing UniDA techniques, yielding state-of-the-art performance across three standard UniDA and Open-Set DA object recognition benchmarks.

</p>
</details>

<details><summary><b>Toward Equation of Motion for Deep Neural Networks: Continuous-time Gradient Descent and Discretization Error Analysis</b>
<a href="https://arxiv.org/abs/2210.15898">arxiv:2210.15898</a>
&#x1F4C8; 13 <br>
<p>Taiki Miyagawa</p></summary>
<p>

**Abstract:** We derive and solve an ``Equation of Motion'' (EoM) for deep neural networks (DNNs), a differential equation that precisely describes the discrete learning dynamics of DNNs. Differential equations are continuous but have played a prominent role even in the study of discrete optimization (gradient descent (GD) algorithms). However, there still exist gaps between differential equations and the actual learning dynamics of DNNs due to discretization error. In this paper, we start from gradient flow (GF) and derive a counter term that cancels the discretization error between GF and GD. As a result, we obtain EoM, a continuous differential equation that precisely describes the discrete learning dynamics of GD. We also derive discretization error to show to what extent EoM is precise. In addition, we apply EoM to two specific cases: scale- and translation-invariant layers. EoM highlights differences between continuous-time and discrete-time GD, indicating the importance of the counter term for a better description of the discrete learning dynamics of GD. Our experimental results support our theoretical findings.

</p>
</details>

<details><summary><b>Addressing Bias in Face Detectors using Decentralised Data collection with incentives</b>
<a href="https://arxiv.org/abs/2210.16024">arxiv:2210.16024</a>
&#x1F4C8; 12 <br>
<p>M. R. Ahan, Robin Lehmann, Richard Blythman</p></summary>
<p>

**Abstract:** Recent developments in machine learning have shown that successful models do not rely only on huge amounts of data but the right kind of data. We show in this paper how this data-centric approach can be facilitated in a decentralized manner to enable efficient data collection for algorithms. Face detectors are a class of models that suffer heavily from bias issues as they have to work on a large variety of different data. We also propose a face detection and anonymization approach using a hybrid MultiTask Cascaded CNN with FaceNet Embeddings to benchmark multiple datasets to describe and evaluate the bias in the models towards different ethnicities, gender, and age groups along with ways to enrich fairness in a decentralized system of data labeling, correction, and verification by users to create a robust pipeline for model retraining.

</p>
</details>

<details><summary><b>Feature Engineering vs BERT on Twitter Data</b>
<a href="https://arxiv.org/abs/2210.16168">arxiv:2210.16168</a>
&#x1F4C8; 11 <br>
<p>Ryiaadh Gani, Lisa Chalaguine</p></summary>
<p>

**Abstract:** In this paper, we compare the performances of traditional machine learning models using feature engineering and word vectors and the state-of-the-art language model BERT using word embeddings on three datasets. We also consider the time and cost efficiency of feature engineering compared to BERT. From our results we conclude that the use of the BERT model was only worth the time and cost trade-off for one of the three datasets we used for comparison, where the BERT model significantly outperformed any kind of traditional classifier that uses feature vectors, instead of embeddings. Using the BERT model for the other datasets only achieved an increase of 0.03 and 0.05 of accuracy and F1 score respectively, which could be argued makes its use not worth the time and cost of GPU.

</p>
</details>

<details><summary><b>I am Only Happy When There is Light: The Impact of Environmental Changes on Affective Facial Expressions Recognition</b>
<a href="https://arxiv.org/abs/2210.17421">arxiv:2210.17421</a>
&#x1F4C8; 10 <br>
<p>Doreen Jirak, Alessandra Sciutti, Pablo Barros, Francesco Rea</p></summary>
<p>

**Abstract:** Human-robot interaction (HRI) benefits greatly from advances in the machine learning field as it allows researchers to employ high-performance models for perceptual tasks like detection and recognition. Especially deep learning models, either pre-trained for feature extraction or used for classification, are now established methods to characterize human behaviors in HRI scenarios and to have social robots that understand better those behaviors. As HRI experiments are usually small-scale and constrained to particular lab environments, the questions are how well can deep learning models generalize to specific interaction scenarios, and further, how good is their robustness towards environmental changes? These questions are important to address if the HRI field wishes to put social robotic companions into real environments acting consistently, i.e. changing lighting conditions or moving people should still produce the same recognition results. In this paper, we study the impact of different image conditions on the recognition of arousal and valence from human facial expressions using the FaceChannel framework \cite{Barro20}. Our results show how the interpretation of human affective states can differ greatly in either the positive or negative direction even when changing only slightly the image properties. We conclude the paper with important points to consider when employing deep learning models to ensure sound interpretation of HRI experiments.

</p>
</details>

<details><summary><b>SEMPAI: a Self-Enhancing Multi-Photon Artificial Intelligence for prior-informed assessment of muscle function and pathology</b>
<a href="https://arxiv.org/abs/2210.16273">arxiv:2210.16273</a>
&#x1F4C8; 10 <br>
<p>Alexander M√ºhlberg, Paul Ritter, Simon Langer, Chlo√´ Goossens, Stefanie N√ºbler, Dominik Schneidereit, Oliver Taubmann, Felix Denzinger, Dominik N√∂renberg, Michael Haug, Wolfgang H. Goldmann, Andreas K. Maier, Oliver Friedrich, Lucas Kreiss</p></summary>
<p>

**Abstract:** Deep learning (DL) shows notable success in biomedical studies. However, most DL algorithms work as a black box, exclude biomedical experts, and need extensive data. We introduce the Self-Enhancing Multi-Photon Artificial Intelligence (SEMPAI), that integrates hypothesis-driven priors in a data-driven DL approach for research on multiphoton microscopy (MPM) of muscle fibers. SEMPAI utilizes meta-learning to optimize prior integration, data representation, and neural network architecture simultaneously. This allows hypothesis testing and provides interpretable feedback about the origin of biological information in MPM images. SEMPAI performs joint learning of several tasks to enable prediction for small datasets. The method is applied on an extensive multi-study dataset resulting in the largest joint analysis of pathologies and function for single muscle fibers. SEMPAI outperforms state-of-the-art biomarkers in six of seven predictive tasks, including those with scarce data. SEMPAI's DL models with integrated priors are superior to those without priors and to prior-only machine learning approaches.

</p>
</details>

<details><summary><b>Latent Space is Feature Space: Regularization Term for GANs Training on Limited Dataset</b>
<a href="https://arxiv.org/abs/2210.16251">arxiv:2210.16251</a>
&#x1F4C8; 10 <br>
<p>Pengwei Wang</p></summary>
<p>

**Abstract:** Generative Adversarial Networks (GAN) is currently widely used as an unsupervised image generation method. Current state-of-the-art GANs can generate photorealistic images with high resolution. However, a large amount of data is required, or the model would prone to generate images with similar patterns (mode collapse) and bad quality. I proposed an additional structure and loss function for GANs called LFM, trained to maximize the feature diversity between the different dimensions of the latent space to avoid mode collapse without affecting the image quality. Orthogonal latent vector pairs are created, and feature vector pairs extracted by discriminator are examined by dot product, with which discriminator and generator are in a novel adversarial relationship. In experiments, this system has been built upon DCGAN and proved to have improvement on Frechet Inception Distance (FID) training from scratch on CelebA Dataset. This system requires mild extra performance and can work with data augmentation methods. The code is available on github.com/penway/LFM.

</p>
</details>

<details><summary><b>Multimodal Transformer for Parallel Concatenated Variational Autoencoders</b>
<a href="https://arxiv.org/abs/2210.16174">arxiv:2210.16174</a>
&#x1F4C8; 10 <br>
<p>Stephen D. Liang, Jerry M. Mendel</p></summary>
<p>

**Abstract:** In this paper, we propose a multimodal transformer using parallel concatenated architecture. Instead of using patches, we use column stripes for images in R, G, B channels as the transformer input. The column stripes keep the spatial relations of original image. We incorporate the multimodal transformer with variational autoencoder for synthetic cross-modal data generation. The multimodal transformer is designed using multiple compression matrices, and it serves as encoders for Parallel Concatenated Variational AutoEncoders (PC-VAE). The PC-VAE consists of multiple encoders, one latent space, and two decoders. The encoders are based on random Gaussian matrices and don't need any training. We propose a new loss function based on the interaction information from partial information decomposition. The interaction information evaluates the input cross-modal information and decoder output. The PC-VAE are trained via minimizing the loss function. Experiments are performed to validate the proposed multimodal transformer for PC-VAE.

</p>
</details>

<details><summary><b>Object Segmentation of Cluttered Airborne LiDAR Point Clouds</b>
<a href="https://arxiv.org/abs/2210.16081">arxiv:2210.16081</a>
&#x1F4C8; 10 <br>
<p>Mariona Caros, Ariadna Just, Santi Segui, Jordi Vitria</p></summary>
<p>

**Abstract:** Airborne topographic LiDAR is an active remote sensing technology that emits near-infrared light to map objects on the Earth's surface. Derived products of LiDAR are suitable to service a wide range of applications because of their rich three-dimensional spatial information and their capacity to obtain multiple returns. However, processing point cloud data still requires a significant effort in manual editing. Certain human-made objects are difficult to detect because of their variety of shapes, irregularly-distributed point clouds, and low number of class samples. In this work, we propose an end-to-end deep learning framework to automatize the detection and segmentation of objects defined by an arbitrary number of LiDAR points surrounded by clutter. Our method is based on a light version of PointNet that achieves good performance on both object recognition and segmentation tasks. The results are tested against manually delineated power transmission towers and show promising accuracy.

</p>
</details>

<details><summary><b>Period VITS: Variational Inference with Explicit Pitch Modeling for End-to-end Emotional Speech Synthesis</b>
<a href="https://arxiv.org/abs/2210.15964">arxiv:2210.15964</a>
&#x1F4C8; 10 <br>
<p>Yuma Shirahata, Ryuichi Yamamoto, Eunwoo Song, Ryo Terashima, Jae-Min Kim, Kentaro Tachibana</p></summary>
<p>

**Abstract:** Several fully end-to-end text-to-speech (TTS) models have been proposed that have shown better performance compared to cascade models (i.e., training acoustic and vocoder models separately). However, they often generate unstable pitch contour with audible artifacts when the dataset contains emotional attributes, i.e., large diversity of pronunciation and prosody. To address this problem, we propose Period VITS, a novel end-to-end TTS model that incorporates an explicit periodicity generator. In the proposed method, we introduce a frame pitch predictor that predicts prosodic features, such as pitch and voicing flags, from the input text. From these features, the proposed periodicity generator produces a sample-level sinusoidal source that enables the waveform decoder to accurately reproduce the pitch. Finally, the entire model is jointly optimized in an end-to-end manner with variational inference and adversarial objectives. As a result, the decoder becomes capable of generating more stable, expressive, and natural output waveforms. The experimental results showed that the proposed model significantly outperforms baseline models in terms of naturalness, with improved pitch stability in the generated samples.

</p>
</details>

<details><summary><b>Multiresolution Signal Processing of Financial Market Objects</b>
<a href="https://arxiv.org/abs/2210.15934">arxiv:2210.15934</a>
&#x1F4C8; 9 <br>
<p>Ioana Boier</p></summary>
<p>

**Abstract:** Financial markets are among the most complex entities in our environment, yet mainstream quantitative models operate at predetermined scale, rely on linear correlation measures, and struggle to recognize non-linear or causal structures. In this paper, we combine neural networks known to capture non-linear associations with a multiscale decomposition approach to facilitate a better understanding of financial market data substructures. Quantization keeps our decompositions calibrated to market at every scale. We illustrate our approach in the context of a wide spectrum of applications.

</p>
</details>

<details><summary><b>Kuaipedia: a Large-scale Multi-modal Short-video Encyclopedia</b>
<a href="https://arxiv.org/abs/2211.00732">arxiv:2211.00732</a>
&#x1F4C8; 8 <br>
<p>Haojie Pan, Yuzhou Zhang, Zepeng Zhai, Ruiji Fu, Ming Liu, Yangqiu Song, Zhongyuan Wang, Bing Qin</p></summary>
<p>

**Abstract:** Online encyclopedias, such as Wikipedia, have been well-developed and researched in the last two decades. One can find any attributes or other information of a wiki item on a wiki page edited by a community of volunteers. However, the traditional text, images and tables can hardly express some aspects of an wiki item. For example, when we talk about ``Shiba Inu'', one may care more about ``How to feed it'' or ``How to train it not to protect its food''. Currently, short-video platforms have become a hallmark in the online world. Whether you're on TikTok, Instagram, Kuaishou, or YouTube Shorts, short-video apps have changed how we consume and create content today. Except for producing short videos for entertainment, we can find more and more authors sharing insightful knowledge widely across all walks of life. These short videos, which we call knowledge videos, can easily express any aspects (e.g. hair or how-to-feed) consumers want to know about an item (e.g. Shiba Inu), and they can be systematically analyzed and organized like an online encyclopedia. In this paper, we propose Kuaipedia, a large-scale multi-modal encyclopedia consisting of items, aspects, and short videos lined to them, which was extracted from billions of videos of Kuaishou (Kwai), a well-known short-video platform in China. We first collected items from multiple sources and mined user-centered aspects from millions of users' queries to build an item-aspect tree. Then we propose a new task called ``multi-modal item-aspect linking'' as an expansion of ``entity linking'' to link short videos into item-aspect pairs and build the whole short-video encyclopedia. Intrinsic evaluations show that our encyclopedia is of large scale and highly accurate. We also conduct sufficient extrinsic experiments to show how Kuaipedia can help fundamental applications such as entity typing and entity linking.

</p>
</details>

<details><summary><b>Bayesian Model Selection of Lithium-Ion Battery Models via Bayesian Quadrature</b>
<a href="https://arxiv.org/abs/2210.17299">arxiv:2210.17299</a>
&#x1F4C8; 8 <br>
<p>Masaki Adachi, Yannick Kuhn, Birger Horstmann, Michael A. Osborne, David A. Howey</p></summary>
<p>

**Abstract:** This paper presents a Bayesian model selection approach via Bayesian quadrature and sensitivity analysis of the selection criterion for a lithium-ion battery model. The Bayesian model evidence is adopted as the metric, which can select the simplest but well-describing model based on Occam's razor principle. While the model evidence requires prohibitive integral computations over parameter space, Bayesian quadrature offers sample-efficient integration via model-based inference to minimise the number of battery model evaluations. The posterior distribution of battery model parameters can also be inferred as a byproduct in one go, which is also beneficial in creating a digital twin. The simplest lithium-ion battery models, equivalent circuit models, were used to analyse the sensitivity of the selection criterion at given different datasets and model configurations. We show that popular selection criteria, such as root-mean-square error, and Bayesian information criterion, can fail to select a correct model in a multimodal posterior case. The model evidence can spot the true model in such cases, simultaneously providing the variance of evidence inference itself as an indication of confidence. Bayesian quadrature can compute the evidence faster than popular MCMC solvers.

</p>
</details>

<details><summary><b>Learning Probabilistic Models from Generator Latent Spaces with Hat EBM</b>
<a href="https://arxiv.org/abs/2210.16486">arxiv:2210.16486</a>
&#x1F4C8; 8 <br>
<p>Mitch Hill, Erik Nijkamp, Jonathan Mitchell, Bo Pang, Song-Chun Zhu</p></summary>
<p>

**Abstract:** This work proposes a method for using any generator network as the foundation of an Energy-Based Model (EBM). Our formulation posits that observed images are the sum of unobserved latent variables passed through the generator network and a residual random variable that spans the gap between the generator output and the image manifold. One can then define an EBM that includes the generator as part of its forward pass, which we call the Hat EBM. The model can be trained without inferring the latent variables of the observed data or calculating the generator Jacobian determinant. This enables explicit probabilistic modeling of the output distribution of any type of generator network. Experiments show strong performance of the proposed method on (1) unconditional ImageNet synthesis at 128x128 resolution, (2) refining the output of existing generators, and (3) learning EBMs that incorporate non-probabilistic generators. Code and pretrained models to reproduce our results are available at https://github.com/point0bar1/hat-ebm.

</p>
</details>

<details><summary><b>Nonparametric Probabilistic Regression with Coarse Learners</b>
<a href="https://arxiv.org/abs/2210.16247">arxiv:2210.16247</a>
&#x1F4C8; 8 <br>
<p>Brian Lucena</p></summary>
<p>

**Abstract:** Probabilistic Regression refers to predicting a full probability density function for the target conditional on the features. We present a nonparametric approach to this problem which combines base classifiers (typically gradient boosted forests) trained on different coarsenings of the target value. By combining such classifiers and averaging the resulting densities, we are able to compute precise conditional densities with minimal assumptions on the shape or form of the density. We combine this approach with a structured cross-entropy loss function which serves to regularize and smooth the resulting densities. Prediction intervals computed from these densities are shown to have high fidelity in practice. Furthermore, examining the properties of these densities on particular observations can provide valuable insight. We demonstrate this approach on a variety of datasets and show competitive performance, particularly on larger datasets.

</p>
</details>

<details><summary><b>Convergence analysis of a quasi-Monte Carlo-based deep learning algorithm for solving partial differential equations</b>
<a href="https://arxiv.org/abs/2210.16196">arxiv:2210.16196</a>
&#x1F4C8; 8 <br>
<p>Fengjiang Fu, Xiaoqun Wang</p></summary>
<p>

**Abstract:** Deep learning methods have achieved great success in solving partial differential equations (PDEs), where the loss is often defined as an integral. The accuracy and efficiency of these algorithms depend greatly on the quadrature method. We propose to apply quasi-Monte Carlo (QMC) methods to the Deep Ritz Method (DRM) for solving the Neumann problems for the Poisson equation and the static Schr√∂dinger equation. For error estimation, we decompose the error of using the deep learning algorithm to solve PDEs into the generalization error, the approximation error and the training error. We establish the upper bounds and prove that QMC-based DRM achieves an asymptotically smaller error bound than DRM. Numerical experiments show that the proposed method converges faster in all cases and the variances of the gradient estimators of randomized QMC-based DRM are much smaller than those of DRM, which illustrates the superiority of QMC in deep learning over MC.

</p>
</details>

<details><summary><b>Understanding Adverse Biological Effect Predictions Using Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2210.15985">arxiv:2210.15985</a>
&#x1F4C8; 8 <br>
<p>Erik Bryhn Myklebust, Ernesto Jimenez-Ruiz, Jiaoyan Chen, Raoul Wolf, Knut Erik Tollefsen</p></summary>
<p>

**Abstract:** Extrapolation of adverse biological (toxic) effects of chemicals is an important contribution to expand available hazard data in (eco)toxicology without the use of animals in laboratory experiments. In this work, we extrapolate effects based on a knowledge graph (KG) consisting of the most relevant effect data as domain-specific background knowledge. An effect prediction model, with and without background knowledge, was used to predict mean adverse biological effect concentration of chemicals as a prototypical type of stressors. The background knowledge improves the model prediction performance by up to 40\% in terms of $R^2$ (\ie coefficient of determination). We use the KG and KG embeddings to provide quantitative and qualitative insights into the predictions. These insights are expected to improve the confidence in effect prediction. Larger scale implementation of such extrapolation models should be expected to support hazard and risk assessment, by simplifying and reducing testing needs.

</p>
</details>

<details><summary><b>IB-U-Nets: Improving medical image segmentation tasks with 3D Inductive Biased kernels</b>
<a href="https://arxiv.org/abs/2210.15949">arxiv:2210.15949</a>
&#x1F4C8; 8 <br>
<p>Shrajan Bhandary, Zahra Babaiee, Dejan Kostyszyn, Tobias Fechter, Constantinos Zamboglou, Anca-Ligia Grosu, Radu Grosu</p></summary>
<p>

**Abstract:** Despite the success of convolutional neural networks for 3D medical-image segmentation, the architectures currently used are still not robust enough to the protocols of different scanners, and the variety of image properties they produce. Moreover, access to large-scale datasets with annotated regions of interest is scarce, and obtaining good results is thus difficult. To overcome these challenges, we introduce IB-U-Nets, a novel architecture with inductive bias, inspired by the visual processing in vertebrates. With the 3D U-Net as the base, we add two 3D residual components to the second encoder blocks. They provide an inductive bias, helping U-Nets to segment anatomical structures from 3D images with increased robustness and accuracy. We compared IB-U-Nets with state-of-the-art 3D U-Nets on multiple modalities and organs, such as the prostate and spleen, using the same training and testing pipeline, including data processing, augmentation and cross-validation. Our results demonstrate the superior robustness and accuracy of IB-U-Nets, especially on small datasets, as is typically the case in medical-image analysis. IB-U-Nets source code and models are publicly available.

</p>
</details>

<details><summary><b>DOORS: Dataset fOr bOuldeRs Segmentation. Statistical properties and Blender setup</b>
<a href="https://arxiv.org/abs/2210.16253">arxiv:2210.16253</a>
&#x1F4C8; 7 <br>
<p>Mattia Pugliatti, Francesco Topputo</p></summary>
<p>

**Abstract:** The capability to detect boulders on the surface of small bodies is beneficial for vision-based applications such as hazard detection during critical operations and navigation. This task is challenging due to the wide assortment of irregular shapes, the characteristics of the boulders population, and the rapid variability in the illumination conditions. Moreover, the lack of publicly available labeled datasets for these applications damps the research about data-driven algorithms. In this work, the authors provide a statistical characterization and setup used for the generation of two datasets about boulders on small bodies that are made publicly available.

</p>
</details>

<details><summary><b>Fairness Certificates for Differentially Private Classification</b>
<a href="https://arxiv.org/abs/2210.16242">arxiv:2210.16242</a>
&#x1F4C8; 7 <br>
<p>Paul Mangold, Micha√´l Perrot, Aur√©lien Bellet, Marc Tommasi</p></summary>
<p>

**Abstract:** In this work, we theoretically study the impact of differential privacy on fairness in binary classification. We prove that, given a class of models, popular group fairness measures are pointwise Lipschitz-continuous with respect to the parameters of the model. This result is a consequence of a more general statement on the probability that a decision function makes a negative prediction conditioned on an arbitrary event (such as membership to a sensitive group), which may be of independent interest. We use the aforementioned Lipschitz property to prove a high probability bound showing that, given enough examples, the fairness level of private models is close to the one of their non-private counterparts.

</p>
</details>

<details><summary><b>Deep Learning-Based Anomaly Detection in Synthetic Aperture Radar Imaging</b>
<a href="https://arxiv.org/abs/2210.16038">arxiv:2210.16038</a>
&#x1F4C8; 7 <br>
<p>Max Muzeau, Chengfang Ren, S√©bastien Angelliaume, Mihai Datcu, Jean-Philippe Ovarlez</p></summary>
<p>

**Abstract:** In this paper, we proposed to investigate unsupervised anomaly detection in Synthetic Aperture Radar (SAR) images. Our approach considers anomalies as abnormal patterns that deviate from their surroundings but without any prior knowledge of their characteristics. In the literature, most model-based algorithms face three main issues. First, the speckle noise corrupts the image and potentially leads to numerous false detections. Second, statistical approaches may exhibit deficiencies in modeling spatial correlation in SAR images. Finally, neural networks based on supervised learning approaches are not recommended due to the lack of annotated SAR data, notably for the class of abnormal patterns. Our proposed method aims to address these issues through a self-supervised algorithm. The speckle is first removed through the deep learning SAR2SAR algorithm. Then, an adversarial autoencoder is trained to reconstruct an anomaly-free SAR image. Finally, a change detection processing step is applied between the input and the output to detect anomalies. Experiments are performed to show the advantages of our method compared to the conventional Reed-Xiaoli algorithm, highlighting the importance of an efficient despeckling pre-processing step.

</p>
</details>

<details><summary><b>Spectrograms Are Sequences of Patches</b>
<a href="https://arxiv.org/abs/2210.15988">arxiv:2210.15988</a>
&#x1F4C8; 7 <br>
<p>Leyi Zhao, Yi Li</p></summary>
<p>

**Abstract:** Self-supervised pre-training models have been used successfully in several machine learning domains. However, only a tiny amount of work is related to music. In our work, we treat a spectrogram of music as a series of patches and design a self-supervised model that captures the features of these sequential patches: Patchifier, which makes good use of self-supervised learning methods from both NLP and CV domains. We do not use labeled data for the pre-training process, only a subset of the MTAT dataset containing 16k music clips. After pre-training, we apply the model to several downstream tasks. Our model achieves a considerably acceptable result compared to other audio representation models. Meanwhile, our work demonstrates that it makes sense to consider audio as a series of patch segments.

</p>
</details>

<details><summary><b>Self-Supervised Learning with Multi-View Rendering for 3D Point Cloud Analysis</b>
<a href="https://arxiv.org/abs/2210.15904">arxiv:2210.15904</a>
&#x1F4C8; 7 <br>
<p>Bach Tran, Binh-Son Hua, Anh Tuan Tran, Minh Hoai</p></summary>
<p>

**Abstract:** Recently, great progress has been made in 3D deep learning with the emergence of deep neural networks specifically designed for 3D point clouds. These networks are often trained from scratch or from pre-trained models learned purely from point cloud data. Inspired by the success of deep learning in the image domain, we devise a novel pre-training technique for better model initialization by utilizing the multi-view rendering of the 3D data. Our pre-training is self-supervised by a local pixel/point level correspondence loss computed from perspective projection and a global image/point cloud level loss based on knowledge distillation, thus effectively improving upon popular point cloud networks, including PointNet, DGCNN and SR-UNet. These improved models outperform existing state-of-the-art methods on various datasets and downstream tasks. We also analyze the benefits of synthetic and real data for pre-training, and observe that pre-training on synthetic data is also useful for high-level downstream tasks. Code and pre-trained models are available at https://github.com/VinAIResearch/selfsup_pcd.

</p>
</details>

<details><summary><b>UniASM: Binary Code Similarity Detection without Fine-tuning</b>
<a href="https://arxiv.org/abs/2211.01144">arxiv:2211.01144</a>
&#x1F4C8; 6 <br>
<p>Yeming Gu, Hui Shu, Fan Hu</p></summary>
<p>

**Abstract:** Binary code similarity detection (BCSD) is widely used in various binary analysis tasks such as vulnerability search, malware detection, clone detection, and patch analysis. Recent studies have shown that the learning-based binary code embedding models perform better than the traditional feature-based approaches. In this paper, we proposed a novel transformer-based binary code embedding model, named UniASM, to learn representations of the binary functions. We designed two new training tasks to make the spatial distribution of the generated vectors more uniform, which can be used directly in BCSD without any fine-tuning. In addition, we proposed a new tokenization approach for binary functions, increasing the token's semantic information while mitigating the out-of-vocabulary (OOV) problem. The experimental results show that UniASM outperforms state-of-the-art (SOTA) approaches on the evaluation dataset. We achieved the average scores of recall@1 on cross-compilers, cross-optimization-levels and cross-obfuscations are 0.72, 0.63, and 0.77, which is higher than existing SOTA baselines. In a real-world task of known vulnerability searching, UniASM outperforms all the current baselines.

</p>
</details>

<details><summary><b>Universal Adversarial Directions</b>
<a href="https://arxiv.org/abs/2210.15997">arxiv:2210.15997</a>
&#x1F4C8; 6 <br>
<p>Ching Lam Choi, Farzan Farnia</p></summary>
<p>

**Abstract:** Despite their great success in image recognition tasks, deep neural networks (DNNs) have been observed to be susceptible to universal adversarial perturbations (UAPs) which perturb all input samples with a single perturbation vector. However, UAPs often struggle in transferring across DNN architectures and lead to challenging optimization problems. In this work, we study the transferability of UAPs by analyzing equilibrium in the universal adversarial example game between the classifier and UAP adversary players. We show that under mild assumptions the universal adversarial example game lacks a pure Nash equilibrium, indicating UAPs' suboptimal transferability across DNN classifiers. To address this issue, we propose Universal Adversarial Directions (UADs) which only fix a universal direction for adversarial perturbations and allow the perturbations' magnitude to be chosen freely across samples. We prove that the UAD adversarial example game can possess a Nash equilibrium with a pure UAD strategy, implying the potential transferability of UADs. We also connect the UAD optimization problem to the well-known principal component analysis (PCA) and develop an efficient PCA-based algorithm for optimizing UADs. We evaluate UADs over multiple benchmark image datasets. Our numerical results show the superior transferability of UADs over standard gradient-based UAPs.

</p>
</details>

<details><summary><b>Single-Image HDR Reconstruction by Multi-Exposure Generation</b>
<a href="https://arxiv.org/abs/2210.15897">arxiv:2210.15897</a>
&#x1F4C8; 6 <br>
<p>Phuoc-Hieu Le, Quynh Le, Rang Nguyen, Binh-Son Hua</p></summary>
<p>

**Abstract:** High dynamic range (HDR) imaging is an indispensable technique in modern photography. Traditional methods focus on HDR reconstruction from multiple images, solving the core problems of image alignment, fusion, and tone mapping, yet having a perfect solution due to ghosting and other visual artifacts in the reconstruction. Recent attempts at single-image HDR reconstruction show a promising alternative: by learning to map pixel values to their irradiance using a neural network, one can bypass the align-and-merge pipeline completely yet still obtain a high-quality HDR image. In this work, we propose a weakly supervised learning method that inverts the physical image formation process for HDR reconstruction via learning to generate multiple exposures from a single image. Our neural network can invert the camera response to reconstruct pixel irradiance before synthesizing multiple exposures and hallucinating details in under- and over-exposed regions from a single input image. To train the network, we propose a representation loss, a reconstruction loss, and a perceptual loss applied on pairs of under- and over-exposure images and thus do not require HDR images for training. Our experiments show that our proposed model can effectively reconstruct HDR images. Our qualitative and quantitative results show that our method achieves state-of-the-art performance on the DrTMO dataset. Our code is available at https://github.com/VinAIResearch/single_image_hdr.

</p>
</details>

<details><summary><b>When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels</b>
<a href="https://arxiv.org/abs/2210.15893">arxiv:2210.15893</a>
&#x1F4C8; 6 <br>
<p>Weiyan Shi, Emily Dinan, Kurt Shuster, Jason Weston, Jing Xu</p></summary>
<p>

**Abstract:** Deployed dialogue agents have the potential to integrate human feedback to continuously improve themselves. However, humans may not always provide explicit signals when the chatbot makes mistakes during interactions. In this work, we propose Juicer, a framework to make use of both binary and free-form textual human feedback. It works by: (i) extending sparse binary feedback by training a satisfaction classifier to label the unlabeled data; and (ii) training a reply corrector to map the bad replies to good ones. We find that augmenting training with model-corrected replies improves the final dialogue model, and we can further improve performance by using both positive and negative replies through the recently proposed Director model.

</p>
</details>

<details><summary><b>A Functional-Space Mean-Field Theory of Partially-Trained Three-Layer Neural Networks</b>
<a href="https://arxiv.org/abs/2210.16286">arxiv:2210.16286</a>
&#x1F4C8; 5 <br>
<p>Zhengdao Chen, Eric Vanden-Eijnden, Joan Bruna</p></summary>
<p>

**Abstract:** To understand the training dynamics of neural networks (NNs), prior studies have considered the infinite-width mean-field (MF) limit of two-layer NN, establishing theoretical guarantees of its convergence under gradient flow training as well as its approximation and generalization capabilities. In this work, we study the infinite-width limit of a type of three-layer NN model whose first layer is random and fixed. To define the limiting model rigorously, we generalize the MF theory of two-layer NNs by treating the neurons as belonging to functional spaces. Then, by writing the MF training dynamics as a kernel gradient flow with a time-varying kernel that remains positive-definite, we prove that its training loss in $L_2$ regression decays to zero at a linear rate. Furthermore, we define function spaces that include the solutions obtainable through the MF training dynamics and prove Rademacher complexity bounds for these spaces. Our theory accommodates different scaling choices of the model, resulting in two regimes of the MF limit that demonstrate distinctive behaviors while both exhibiting feature learning.

</p>
</details>

<details><summary><b>Game-Theoretical Perspectives on Active Equilibria: A Preferred Solution Concept over Nash Equilibria</b>
<a href="https://arxiv.org/abs/2210.16175">arxiv:2210.16175</a>
&#x1F4C8; 5 <br>
<p>Dong-Ki Kim, Matthew Riemer, Miao Liu, Jakob N. Foerster, Gerald Tesauro, Jonathan P. How</p></summary>
<p>

**Abstract:** Multiagent learning settings are inherently more difficult than single-agent learning because each agent interacts with other simultaneously learning agents in a shared environment. An effective approach in multiagent reinforcement learning is to consider the learning process of agents and influence their future policies toward desirable behaviors from each agent's perspective. Importantly, if each agent maximizes its long-term rewards by accounting for the impact of its behavior on the set of convergence policies, the resulting multiagent system reaches an active equilibrium. While this new solution concept is general such that standard solution concepts, such as a Nash equilibrium, are special cases of active equilibria, it is unclear when an active equilibrium is a preferred equilibrium over other solution concepts. In this paper, we analyze active equilibria from a game-theoretic perspective by closely studying examples where Nash equilibria are known. By directly comparing active equilibria to Nash equilibria in these examples, we find that active equilibria find more effective solutions than Nash equilibria, concluding that an active equilibrium is the desired solution for multiagent learning settings.

</p>
</details>

<details><summary><b>Reliability of CKA as a Similarity Measure in Deep Learning</b>
<a href="https://arxiv.org/abs/2210.16156">arxiv:2210.16156</a>
&#x1F4C8; 5 <br>
<p>MohammadReza Davari, Stefan Horoi, Amine Natik, Guillaume Lajoie, Guy Wolf, Eugene Belilovsky</p></summary>
<p>

**Abstract:** Comparing learned neural representations in neural networks is a challenging but important problem, which has been approached in different ways. The Centered Kernel Alignment (CKA) similarity metric, particularly its linear variant, has recently become a popular approach and has been widely used to compare representations of a network's different layers, of architecturally similar networks trained differently, or of models with different architectures trained on the same data. A wide variety of conclusions about similarity and dissimilarity of these various representations have been made using CKA. In this work we present analysis that formally characterizes CKA sensitivity to a large class of simple transformations, which can naturally occur in the context of modern machine learning. This provides a concrete explanation of CKA sensitivity to outliers, which has been observed in past works, and to transformations that preserve the linear separability of the data, an important generalization attribute. We empirically investigate several weaknesses of the CKA similarity metric, demonstrating situations in which it gives unexpected or counter-intuitive results. Finally we study approaches for modifying representations to maintain functional behaviour while changing the CKA value. Our results illustrate that, in many cases, the CKA value can be easily manipulated without substantial changes to the functional behaviour of the models, and call for caution when leveraging activation alignment metrics.

</p>
</details>

<details><summary><b>Localized Randomized Smoothing for Collective Robustness Certification</b>
<a href="https://arxiv.org/abs/2210.16140">arxiv:2210.16140</a>
&#x1F4C8; 5 <br>
<p>Jan Schuchardt, Tom Wollschl√§ger, Aleksandar Bojchevski, Stephan G√ºnnemann</p></summary>
<p>

**Abstract:** Models for image segmentation, node classification and many other tasks map a single input to multiple labels. By perturbing this single shared input (e.g. the image) an adversary can manipulate several predictions (e.g. misclassify several pixels). Collective robustness certification is the task of provably bounding the number of robust predictions under this threat model. The only dedicated method that goes beyond certifying each output independently is limited to strictly local models, where each prediction is associated with a small receptive field. We propose a more general collective robustness certificate for all types of models and further show that this approach is beneficial for the larger class of softly local models, where each output is dependent on the entire input but assigns different levels of importance to different input regions (e.g. based on their proximity in the image). The certificate is based on our novel localized randomized smoothing approach, where the random perturbation strength for different input regions is proportional to their importance for the outputs. Localized smoothing Pareto-dominates existing certificates on both image segmentation and node classification tasks, simultaneously offering higher accuracy and stronger guarantees.

</p>
</details>

<details><summary><b>A CNN-LSTM Combination Network for Cataract Detection using Eye Fundus Images</b>
<a href="https://arxiv.org/abs/2210.16093">arxiv:2210.16093</a>
&#x1F4C8; 5 <br>
<p>Dishant Padalia, Abhishek Mazumdar, Bharati Singh</p></summary>
<p>

**Abstract:** According to multiple authoritative authorities, including the World Health Organization, vision-related impairments and disorders are becoming a significant issue. According to a recent report, one of the leading causes of irreversible blindness in persons over the age of 50 is delayed cataract treatment. A cataract is a cloudy spot in the eye's lens that causes visual loss. Cataracts often develop slowly and consequently result in difficulty in driving, reading, and even recognizing faces. This necessitates the development of rapid and dependable diagnosis and treatment solutions for ocular illnesses. Previously, such visual illness diagnosis were done manually, which was time-consuming and prone to human mistake. However, as technology advances, automated, computer-based methods that decrease both time and human labor while producing trustworthy results are now accessible. In this study, we developed a CNN-LSTM-based model architecture with the goal of creating a low-cost diagnostic system that can classify normal and cataractous cases of ocular disease from fundus images. The proposed model was trained on the publicly available ODIR dataset, which included fundus images of patients' left and right eyes. The suggested architecture outperformed previous systems with a state-of-the-art 97.53% accuracy.

</p>
</details>

<details><summary><b>OhMG: Zero-shot Open-vocabulary Human Motion Generation</b>
<a href="https://arxiv.org/abs/2210.15929">arxiv:2210.15929</a>
&#x1F4C8; 5 <br>
<p>Junfan Lin, Jianlong Chang, Lingbo Liu, Guanbin Li, Liang Lin, Qi Tian, Chang-wen Chen</p></summary>
<p>

**Abstract:** Generating motion in line with text has attracted increasing attention nowadays. However, open-vocabulary human motion generation still remains touchless and undergoes the lack of diverse labeled data. The good news is that, recent studies of large multi-model foundation models (e.g., CLIP) have demonstrated superior performance on few/zero-shot image-text alignment, largely reducing the need for manually labeled data. In this paper, we take advantage of CLIP for open-vocabulary 3D human motion generation in a zero-shot manner. Specifically, our model is composed of two stages, i.e., text2pose and pose2motion. For text2pose, to address the difficulty of optimization with direct supervision from CLIP, we propose to carve the versatile CLIP model into a slimmer but more specific model for aligning 3D poses and texts, via a novel pipeline distillation strategy. Optimizing with the distilled 3D pose-text model, we manage to concretize the text-pose knowledge of CLIP into a text2pose generator effectively and efficiently. As for pose2motion, drawing inspiration from the advanced language model, we pretrain a transformer-based motion model, which makes up for the lack of motion dynamics of CLIP. After that, by formulating the generated poses from the text2pose stage as prompts, the motion generator can generate motions referring to the poses in a controllable and flexible manner. Our method is validated against advanced baselines and obtains sharp improvements. The code will be released here.

</p>
</details>

<details><summary><b>Investigating Ensemble Methods for Model Robustness Improvement of Text Classifiers</b>
<a href="https://arxiv.org/abs/2210.16298">arxiv:2210.16298</a>
&#x1F4C8; 4 <br>
<p>Jieyu Zhao, Xuezhi Wang, Yao Qin, Jilin Chen, Kai-Wei Chang</p></summary>
<p>

**Abstract:** Large pre-trained language models have shown remarkable performance over the past few years. These models, however, sometimes learn superficial features from the dataset and cannot generalize to the distributions that are dissimilar to the training scenario. There have been several approaches proposed to reduce model's reliance on these bias features which can improve model robustness in the out-of-distribution setting. However, existing methods usually use a fixed low-capacity model to deal with various bias features, which ignore the learnability of those features. In this paper, we analyze a set of existing bias features and demonstrate there is no single model that works best for all the cases. We further show that by choosing an appropriate bias model, we can obtain a better robustness result than baselines with a more sophisticated model design.

</p>
</details>

<details><summary><b>Design of Convolutional Extreme Learning Machines for Vision-Based Navigation Around Small Bodies</b>
<a href="https://arxiv.org/abs/2210.16244">arxiv:2210.16244</a>
&#x1F4C8; 4 <br>
<p>Mattia Pugliatti, Francesco Topputo</p></summary>
<p>

**Abstract:** Deep learning architectures such as convolutional neural networks are the standard in computer vision for image processing tasks. Their accuracy however often comes at the cost of long and computationally expensive training, the need for large annotated datasets, and extensive hyper-parameter searches. On the other hand, a different method known as convolutional extreme learning machine has shown the potential to perform equally with a dramatic decrease in training time. Space imagery, especially about small bodies, could be well suited for this method. In this work, convolutional extreme learning machine architectures are designed and tested against their deep-learning counterparts. Because of the relatively fast training time of the former, convolutional extreme learning machine architectures enable efficient exploration of the architecture design space, which would have been impractical with the latter, introducing a methodology for an efficient design of a neural network architecture for computer vision tasks. Also, the coupling between the image processing method and labeling strategy is investigated and demonstrated to play a major role when considering vision-based navigation around small bodies.

</p>
</details>

<details><summary><b>Local Model Reconstruction Attacks in Federated Learning and their Uses</b>
<a href="https://arxiv.org/abs/2210.16205">arxiv:2210.16205</a>
&#x1F4C8; 4 <br>
<p>Ilias Driouich, Chuan Xu, Giovanni Neglia, Frederic Giroire, Eoin Thomas</p></summary>
<p>

**Abstract:** In this paper, we initiate the study of local model reconstruction attacks for federated learning, where a honest-but-curious adversary eavesdrops the messages exchanged between a targeted client and the server, and then reconstructs the local/personalized model of the victim. The local model reconstruction attack allows the adversary to trigger other classical attacks in a more effective way, since the local model only depends on the client's data and can leak more private information than the global model learned by the server. Additionally, we propose a novel model-based attribute inference attack in federated learning leveraging the local model reconstruction attack. We provide an analytical lower-bound for this attribute inference attack. Empirical results using real world datasets confirm that our local reconstruction attack works well for both regression and classification tasks. Moreover, we benchmark our novel attribute inference attack against the state-of-the-art attacks in federated learning. Our attack results in higher reconstruction accuracy especially when the clients' datasets are heterogeneous. Our work provides a new angle for designing powerful and explainable attacks to effectively quantify the privacy risk in FL.

</p>
</details>

<details><summary><b>Toward Reliable Neural Specifications</b>
<a href="https://arxiv.org/abs/2210.16114">arxiv:2210.16114</a>
&#x1F4C8; 4 <br>
<p>Chuqin Geng, Nham Le, Xiaojie Xu, Zhaoyue Wang, Arie Gurfinkel, Xujie Si</p></summary>
<p>

**Abstract:** Having reliable specifications is an unavoidable challenge in achieving verifiable correctness, robustness, and interpretability of AI systems. Existing specifications for neural networks are in the paradigm of data as specification. That is, the local neighborhood centering around a reference input is considered to be correct (or robust). However, our empirical study shows that such a specification is extremely overfitted since usually no data points from the testing set lie in the certified region of the reference input, making them impractical for real-world applications. We propose a new family of specifications called neural representation as specification, which uses the intrinsic information of neural networks - neural activation patterns (NAP), rather than input data to specify the correctness and/or robustness of neural network predictions. We present a simple statistical approach to mining dominant neural activation patterns. We analyze NAPs from a statistical point of view and find that a single NAP can cover a large number of training and testing data points whereas ad hoc data-as-specification only covers the given reference data point. To show the effectiveness of discovered NAPs, we formally verify several important properties, such as various types of misclassifications will never happen for a given NAP, and there is no-ambiguity between different NAPs. We show that by using NAP, we can verify the prediction of the entire input space, while still recalling 84% of the data. Thus, we argue that using NAPs is a more reliable and extensible specification for neural network verification.

</p>
</details>

<details><summary><b>Towards prediction of turbulent flows at high Reynolds numbers using high performance computing data and deep learning</b>
<a href="https://arxiv.org/abs/2210.16110">arxiv:2210.16110</a>
&#x1F4C8; 4 <br>
<p>Mathis Bode, Michael Gauding, Jens Henrik G√∂bbert, Baohao Liao, Jenia Jitsev, Heinz Pitsch</p></summary>
<p>

**Abstract:** In this paper, deep learning (DL) methods are evaluated in the context of turbulent flows. Various generative adversarial networks (GANs) are discussed with respect to their suitability for understanding and modeling turbulence. Wasserstein GANs (WGANs) are then chosen to generate small-scale turbulence. Highly resolved direct numerical simulation (DNS) turbulent data is used for training the WGANs and the effect of network parameters, such as learning rate and loss function, is studied. Qualitatively good agreement between DNS input data and generated turbulent structures is shown. A quantitative statistical assessment of the predicted turbulent fields is performed.

</p>
</details>

<details><summary><b>Improving Chest X-Ray Classification by RNN-based Patient Monitoring</b>
<a href="https://arxiv.org/abs/2210.16074">arxiv:2210.16074</a>
&#x1F4C8; 4 <br>
<p>David Biesner, Helen Schneider, Benjamin Wulff, Ulrike Attenberger, Rafet Sifa</p></summary>
<p>

**Abstract:** Chest X-Ray imaging is one of the most common radiological tools for detection of various pathologies related to the chest area and lung function. In a clinical setting, automated assessment of chest radiographs has the potential of assisting physicians in their decision making process and optimize clinical workflows, for example by prioritizing emergency patients.
  Most work analyzing the potential of machine learning models to classify chest X-ray images focuses on vision methods processing and predicting pathologies for one image at a time. However, many patients undergo such a procedure multiple times during course of a treatment or during a single hospital stay. The patient history, that is previous images and especially the corresponding diagnosis contain useful information that can aid a classification system in its prediction.
  In this study, we analyze how information about diagnosis can improve CNN-based image classification models by constructing a novel dataset from the well studied CheXpert dataset of chest X-rays. We show that a model trained on additional patient history information outperforms a model trained without the information by a significant margin.
  We provide code to replicate the dataset creation and model training.

</p>
</details>

<details><summary><b>Deep network series for large-scale high-dynamic range imaging</b>
<a href="https://arxiv.org/abs/2210.16060">arxiv:2210.16060</a>
&#x1F4C8; 4 <br>
<p>Amir Aghabiglou, Matthieu Terris, Adrian Jackson, Yves Wiaux</p></summary>
<p>

**Abstract:** We propose a new approach for large-scale high-dynamic range computational imaging. Deep Neural Networks (DNNs) trained end-to-end can solve linear inverse imaging problems almost instantaneously. While unfolded architectures provide necessary robustness to variations of the measurement setting, embedding large-scale measurement operators in DNN architectures is impractical. Alternative Plug-and-Play (PnP) approaches, where the denoising DNNs are blind to the measurement setting, have proven effective to address scalability and high-dynamic range challenges, but rely on highly iterative algorithms. We propose a residual DNN series approach, where the reconstructed image is built as a sum of residual images progressively increasing the dynamic range, and estimated iteratively by DNNs taking the back-projected data residual of the previous iteration as input. We demonstrate on simulations for radio-astronomical imaging that a series of only few terms provides a high-dynamic range reconstruction of similar quality to state-of-the-art PnP approaches, at a fraction of the cost.

</p>
</details>

<details><summary><b>Thermal Infrared Image Inpainting via Edge-Aware Guidance</b>
<a href="https://arxiv.org/abs/2210.16000">arxiv:2210.16000</a>
&#x1F4C8; 4 <br>
<p>Zeyu Wang, Haibin Shen, Changyou Men, Quan Sun, Kejie Huang</p></summary>
<p>

**Abstract:** Image inpainting has achieved fundamental advances with deep learning. However, almost all existing inpainting methods aim to process natural images, while few target Thermal Infrared (TIR) images, which have widespread applications. When applied to TIR images, conventional inpainting methods usually generate distorted or blurry content. In this paper, we propose a novel task -- Thermal Infrared Image Inpainting, which aims to reconstruct missing regions of TIR images. Crucially, we propose a novel deep-learning-based model TIR-Fill. We adopt the edge generator to complete the canny edges of broken TIR images. The completed edges are projected to the normalization weights and biases to enhance edge awareness of the model. In addition, a refinement network based on gated convolution is employed to improve TIR image consistency. The experiments demonstrate that our method outperforms state-of-the-art image inpainting approaches on FLIR thermal dataset.

</p>
</details>

<details><summary><b>Differentially Private CutMix for Split Learning with Vision Transformer</b>
<a href="https://arxiv.org/abs/2210.15986">arxiv:2210.15986</a>
&#x1F4C8; 4 <br>
<p>Seungeun Oh, Jihong Park, Sihun Baek, Hyelin Nam, Praneeth Vepakomma, Ramesh Raskar, Mehdi Bennis, Seong-Lyun Kim</p></summary>
<p>

**Abstract:** Recently, vision transformer (ViT) has started to outpace the conventional CNN in computer vision tasks. Considering privacy-preserving distributed learning with ViT, federated learning (FL) communicates models, which becomes ill-suited due to ViT' s large model size and computing costs. Split learning (SL) detours this by communicating smashed data at a cut-layer, yet suffers from data privacy leakage and large communication costs caused by high similarity between ViT' s smashed data and input data. Motivated by this problem, we propose DP-CutMixSL, a differentially private (DP) SL framework by developing DP patch-level randomized CutMix (DP-CutMix), a novel privacy-preserving inter-client interpolation scheme that replaces randomly selected patches in smashed data. By experiment, we show that DP-CutMixSL not only boosts privacy guarantees and communication efficiency, but also achieves higher accuracy than its Vanilla SL counterpart. Theoretically, we analyze that DP-CutMix amplifies R√©nyi DP (RDP), which is upper-bounded by its Vanilla Mixup counterpart.

</p>
</details>

<details><summary><b>Joint Semantic Transfer Network for IoT Intrusion Detection</b>
<a href="https://arxiv.org/abs/2210.15911">arxiv:2210.15911</a>
&#x1F4C8; 4 <br>
<p>Jiashu Wu, Yang Wang, Binhui Xie, Shuang Li, Hao Dai, Kejiang Ye, Chengzhong Xu</p></summary>
<p>

**Abstract:** In this paper, we propose a Joint Semantic Transfer Network (JSTN) towards effective intrusion detection for large-scale scarcely labelled IoT domain. As a multi-source heterogeneous domain adaptation (MS-HDA) method, the JSTN integrates a knowledge rich network intrusion (NI) domain and another small-scale IoT intrusion (II) domain as source domains, and preserves intrinsic semantic properties to assist target II domain intrusion detection. The JSTN jointly transfers the following three semantics to learn a domain-invariant and discriminative feature representation. The scenario semantic endows source NI and II domain with characteristics from each other to ease the knowledge transfer process via a confused domain discriminator and categorical distribution knowledge preservation. It also reduces the source-target discrepancy to make the shared feature space domain-invariant. Meanwhile, the weighted implicit semantic transfer boosts discriminability via a fine-grained knowledge preservation, which transfers the source categorical distribution to the target domain. The source-target divergence guides the importance weighting during knowledge preservation to reflect the degree of knowledge learning. Additionally, the hierarchical explicit semantic alignment performs centroid-level and representative-level alignment with the help of a geometric similarity-aware pseudo-label refiner, which exploits the value of unlabelled target II domain and explicitly aligns feature representations from a global and local perspective in a concentrated manner. Comprehensive experiments on various tasks verify the superiority of the JSTN against state-of-the-art comparing methods, on average a 10.3% of accuracy boost is achieved. The statistical soundness of each constituting component and the computational efficiency are also verified.

</p>
</details>

<details><summary><b>Conservative Likelihood Ratio Estimator for Infrequent Data Slightly above a Frequency Threshold</b>
<a href="https://arxiv.org/abs/2211.00545">arxiv:2211.00545</a>
&#x1F4C8; 3 <br>
<p>Masato Kikuchi, Yuhi Kusakabe, Tadachika Ozono</p></summary>
<p>

**Abstract:** A naive likelihood ratio (LR) estimation using the observed frequencies of events can overestimate LRs for infrequent data. One approach to avoid this problem is to use a frequency threshold and set the estimates to zero for frequencies below the threshold. This approach eliminates the computation of some estimates, thereby making practical tasks using LRs more efficient. However, it still overestimates LRs for low frequencies near the threshold. This study proposes a conservative estimator for low frequencies, slightly above the threshold. Our experiment used LRs to predict the occurrence contexts of named entities from a corpus. The experimental results demonstrate that our estimator improves the prediction accuracy while maintaining efficiency in the context prediction task.

</p>
</details>

<details><summary><b>Region of Interest Detection in Melanocytic Skin Tumor Whole Slide Images</b>
<a href="https://arxiv.org/abs/2210.16457">arxiv:2210.16457</a>
&#x1F4C8; 3 <br>
<p>Yi Cui, Yao Li, Jayson R. Miedema, Sherif Farag, J. S. Marron, Nancy E. Thomas</p></summary>
<p>

**Abstract:** Automated region of interest detection in histopathological image analysis is a challenging and important topic with tremendous potential impact on clinical practice. The deep-learning methods used in computational pathology help us to reduce costs and increase the speed and accuracy of regions of interest detection and cancer diagnosis. In this work, we propose a patch-based region of interest detection method for melanocytic skin tumor whole-slide images. We work with a dataset that contains 165 primary melanomas and nevi Hematoxylin and Eosin whole-slide images and build a deep-learning method. The proposed method performs well on a hold-out test data set including five TCGA-SKCM slides (accuracy of 93.94\% in slide classification task and intersection over union rate of 41.27\% in the region of interest detection task), showing the outstanding performance of our model on melanocytic skin tumor. Even though we test the experiments on the skin tumor dataset, our work could also be extended to other medical image detection problems, such as various tumors' classification and prediction, to help and benefit the clinical evaluation and diagnosis of different tumors.

</p>
</details>

<details><summary><b>On the Vulnerability of Data Points under Multiple Membership Inference Attacks and Target Models</b>
<a href="https://arxiv.org/abs/2210.16258">arxiv:2210.16258</a>
&#x1F4C8; 3 <br>
<p>Mauro Conti, Jiaxin Li, Stjepan Picek</p></summary>
<p>

**Abstract:** Membership Inference Attacks (MIAs) infer whether a data point is in the training data of a machine learning model. It is a threat while being in the training data is private information of a data point. MIA correctly infers some data points as members or non-members of the training data. Intuitively, data points that MIA accurately detects are vulnerable. Considering those data points may exist in different target models susceptible to multiple MIAs, the vulnerability of data points under multiple MIAs and target models is worth exploring.
  This paper defines new metrics that can reflect the actual situation of data points' vulnerability and capture vulnerable data points under multiple MIAs and target models. From the analysis, MIA has an inference tendency to some data points despite a low overall inference performance. Additionally, we implement 54 MIAs, whose average attack accuracy ranges from 0.5 to 0.9, to support our analysis with our scalable and flexible platform, Membership Inference Attacks Platform (VMIAP). Furthermore, previous methods are unsuitable for finding vulnerable data points under multiple MIAs and different target models. Finally, we observe that the vulnerability is not characteristic of the data point but related to the MIA and target model.

</p>
</details>

<details><summary><b>Applying Physics-Informed Enhanced Super-Resolution Generative Adversarial Networks to Finite-Rate-Chemistry Flows and Predicting Lean Premixed Gas Turbine Combustors</b>
<a href="https://arxiv.org/abs/2210.16219">arxiv:2210.16219</a>
&#x1F4C8; 3 <br>
<p>Mathis Bode</p></summary>
<p>

**Abstract:** The accurate prediction of small scales in underresolved flows is still one of the main challenges in predictive simulations of complex configurations. Over the last few years, data-driven modeling has become popular in many fields as large, often extensively labeled datasets are now available and training of large neural networks has become possible on graphics processing units (GPUs) that speed up the learning process tremendously. In fact, the successful application of deep neural networks in fluid dynamics, such as for underresolved reactive flows, is still challenging. This work advances the recently introduced PIESRGAN to reactive finite-rate-chemistry flows. However, since combustion chemistry typically acts on the smallest scales, the original approach needs to be extended. Therefore, the modeling approach of PIESRGAN is modified to accurately account for the challenges in the context of laminar finite-rate-chemistry flows. The modified PIESRGAN-based model gives good agreement in a priori and a posteriori tests in a laminar lean premixed combustion setup. Furthermore, a reduced PIESRGAN-based model is presented that solves only the major species on a reconstructed field and employs PIERSGAN lookup for the remaining species, utilizing staggering in time. The advantages of the discriminator-supported training are shown, and the usability of the new model demonstrated in the context of a model gas turbine combustor.

</p>
</details>

<details><summary><b>Preferential Subsampling for Stochastic Gradient Langevin Dynamics</b>
<a href="https://arxiv.org/abs/2210.16189">arxiv:2210.16189</a>
&#x1F4C8; 3 <br>
<p>Srshti Putcha, Christopher Nemeth, Paul Fearnhead</p></summary>
<p>

**Abstract:** Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsample of the data. While efficient to compute, the resulting gradient estimator may exhibit a high variance and impact sampler performance. The problem of variance control has been traditionally addressed by constructing a better stochastic gradient estimator, often using control variates. We propose to use a discrete, non-uniform probability distribution to preferentially subsample data points that have a greater impact on the stochastic gradient. In addition, we present a method of adaptively adjusting the subsample size at each iteration of the algorithm, so that we increase the subsample size in areas of the sample space where the gradient is harder to estimate. We demonstrate that such an approach can maintain the same level of accuracy while substantially reducing the average subsample size that is used.

</p>
</details>

<details><summary><b>RESUS: Warm-Up Cold Users via Meta-Learning Residual User Preferences in CTR Prediction</b>
<a href="https://arxiv.org/abs/2210.16080">arxiv:2210.16080</a>
&#x1F4C8; 3 <br>
<p>Yanyan Shen, Lifan Zhao, Weiyu Cheng, Zibin Zhang, Wenwen Zhou, Kangyi Lin</p></summary>
<p>

**Abstract:** Click-Through Rate (CTR) prediction on cold users is a challenging task in recommender systems. Recent researches have resorted to meta-learning to tackle the cold-user challenge, which either perform few-shot user representation learning or adopt optimization-based meta-learning. However, existing methods suffer from information loss or inefficient optimization process, and they fail to explicitly model global user preference knowledge which is crucial to complement the sparse and insufficient preference information of cold users. In this paper, we propose a novel and efficient approach named RESUS, which decouples the learning of global preference knowledge contributed by collective users from the learning of residual preferences for individual users. Specifically, we employ a shared predictor to infer basis user preferences, which acquires global preference knowledge from the interactions of different users. Meanwhile, we develop two efficient algorithms based on the nearest neighbor and ridge regression predictors, which infer residual user preferences via learning quickly from a few user-specific interactions. Extensive experiments on three public datasets demonstrate that our RESUS approach is efficient and effective in improving CTR prediction accuracy on cold users, compared with various state-of-the-art methods.

</p>
</details>

<details><summary><b>Neural Network based Formation of Cognitive Maps of Semantic Spaces and the Emergence of Abstract Concepts</b>
<a href="https://arxiv.org/abs/2210.16062">arxiv:2210.16062</a>
&#x1F4C8; 3 <br>
<p>Paul Stoewer, Achim Schilling, Andreas Maier, Patrick Krauss</p></summary>
<p>

**Abstract:** The hippocampal-entorhinal complex plays a major role in the organization of memory and thought. The formation of and navigation in cognitive maps of arbitrary mental spaces via place and grid cells can serve as a representation of memories and experiences and their relations to each other. The multi-scale successor representation is proposed to be the mathematical principle underlying place and grid cell computations. Here, we present a neural network, which learns a cognitive map of a semantic space based on 32 different animal species encoded as feature vectors. The neural network successfully learns the similarities between different animal species, and constructs a cognitive map of 'animal space' based on the principle of successor representations with an accuracy of around 30% which is near to the theoretical maximum regarding the fact that all animal species have more than one possible successor, i.e. nearest neighbor in feature space. Furthermore, a hierarchical structure, i.e. different scales of cognitive maps, can be modeled based on multi-scale successor representations. We find that, in fine-grained cognitive maps, the animal vectors are evenly distributed in feature space. In contrast, in coarse-grained maps, animal vectors are highly clustered according to their biological class, i.e. amphibians, mammals and insects. This could be a possible mechanism explaining the emergence of new abstract semantic concepts. Finally, even completely new or incomplete input can be represented by interpolation of the representations from the cognitive map with remarkable high accuracy of up to 95%. We conclude that the successor representation can serve as a weighted pointer to past memories and experiences, and may therefore be a crucial building block for future machine learning to include prior knowledge, and to derive context knowledge from novel input.

</p>
</details>

<details><summary><b>Goal Exploration Augmentation via Pre-trained Skills for Sparse-Reward Long-Horizon Goal-Conditioned Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.16058">arxiv:2210.16058</a>
&#x1F4C8; 3 <br>
<p>Lisheng Wu, Ke Chen</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) often struggles to accomplish a sparse-reward long-horizon task in a complex environment. Goal-conditioned reinforcement learning (GCRL) has been employed to tackle this difficult problem via a curriculum of easy-to-reach sub-goals. In GCRL, exploring novel sub-goals is essential for the agent to ultimately find the pathway to the desired goal. How to explore novel sub-goals efficiently is one of the most challenging issues in GCRL. Several goal exploration methods have been proposed to address this issue but still struggle to find the desired goals efficiently. In this paper, we propose a novel learning objective by optimizing the entropy of both achieved and new goals to be explored for more efficient goal exploration in sub-goal selection based GCRL. To optimize this objective, we first explore and exploit the frequently occurring goal-transition patterns mined in the environments similar to the current task to compose skills via skill learning. Then, the pretrained skills are applied in goal exploration. Evaluation on a variety of spare-reward long-horizon benchmark tasks suggests that incorporating our method into several state-of-the-art GCRL baselines significantly boosts their exploration efficiency while improving or maintaining their performance. The source code is available at: https://github.com/GEAPS/GEAPS.

</p>
</details>

<details><summary><b>Automated analysis of diabetic retinopathy using vessel segmentation maps as inductive bias</b>
<a href="https://arxiv.org/abs/2210.16053">arxiv:2210.16053</a>
&#x1F4C8; 3 <br>
<p>Linus Kreitner, Ivan Ezhov, Daniel Rueckert, Johannes C. Paetzold, Martin J. Menten</p></summary>
<p>

**Abstract:** Recent studies suggest that early stages of diabetic retinopathy (DR) can be diagnosed by monitoring vascular changes in the deep vascular complex. In this work, we investigate a novel method for automated DR grading based on optical coherence tomography angiography (OCTA) images. Our work combines OCTA scans with their vessel segmentations, which then serve as inputs to task specific networks for lesion segmentation, image quality assessment and DR grading. For this, we generate synthetic OCTA images to train a segmentation network that can be directly applied on real OCTA data. We test our approach on MICCAI 2022's DR analysis challenge (DRAC). In our experiments, the proposed method performs equally well as the baseline model.

</p>
</details>

<details><summary><b>Measuring the Confidence of Traffic Forecasting Models: Techniques, Experimental Comparison and Guidelines towards Their Actionability</b>
<a href="https://arxiv.org/abs/2210.16049">arxiv:2210.16049</a>
&#x1F4C8; 3 <br>
<p>Ibai La√±a,  Ignacio,  Olabarrieta, Javier Del Ser</p></summary>
<p>

**Abstract:** The estimation of the amount of uncertainty featured by predictive machine learning models has acquired a great momentum in recent years. Uncertainty estimation provides the user with augmented information about the model's confidence in its predicted outcome. Despite the inherent utility of this information for the trustworthiness of the user, there is a thin consensus around the different types of uncertainty that one can gauge in machine learning models and the suitability of different techniques that can be used to quantify the uncertainty of a specific model. This subject is mostly non existent within the traffic modeling domain, even though the measurement of the confidence associated to traffic forecasts can favor significantly their actionability in practical traffic management systems. This work aims to cover this lack of research by reviewing different techniques and metrics of uncertainty available in the literature, and by critically discussing how confidence levels computed for traffic forecasting models can be helpful for researchers and practitioners working in this research area. To shed light with empirical evidence, this critical discussion is further informed by experimental results produced by different uncertainty estimation techniques over real traffic data collected in Madrid (Spain), rendering a general overview of the benefits and caveats of every technique, how they can be compared to each other, and how the measured uncertainty decreases depending on the amount, quality and diversity of data used to produce the forecasts.

</p>
</details>

<details><summary><b>DPVIm: Differentially Private Variational Inference Improved</b>
<a href="https://arxiv.org/abs/2210.15961">arxiv:2210.15961</a>
&#x1F4C8; 3 <br>
<p>Joonas J√§lk√∂, Lukas Prediger, Antti Honkela, Samuel Kaski</p></summary>
<p>

**Abstract:** Differentially private (DP) release of multidimensional statistics typically considers an aggregate sensitivity, e.g. the vector norm of a high-dimensional vector. However, different dimensions of that vector might have widely different magnitudes and therefore DP perturbation disproportionately affects the signal across dimensions. We observe this problem in the gradient release of the DP-SGD algorithm when using it for variational inference (VI), where it manifests in poor convergence as well as high variance in outputs for certain variational parameters, and make the following contributions: (i) We mathematically isolate the cause for the difference in magnitudes between gradient parts corresponding to different variational parameters. Using this as prior knowledge we establish a link between the gradients of the variational parameters, and propose an efficient while simple fix for the problem to obtain a less noisy gradient estimator, which we call $\textit{aligned}$ gradients. This approach allows us to obtain the updates for the covariance parameter of a Gaussian posterior approximation without a privacy cost. We compare this to alternative approaches for scaling the gradients using analytically derived preconditioning, e.g. natural gradients. (ii) We suggest using iterate averaging over the DP parameter traces recovered during the training, to reduce the DP-induced noise in parameter estimates at no additional cost in privacy. Finally, (iii) to accurately capture the additional uncertainty DP introduces to the model parameters, we infer the DP-induced noise from the parameter traces and include that in the learned posteriors to make them $\textit{noise aware}$. We demonstrate the efficacy of our proposed improvements through various experiments on real data.

</p>
</details>

<details><summary><b>A Two Step Approach to Weighted Bipartite Link Recommendations</b>
<a href="https://arxiv.org/abs/2211.01153">arxiv:2211.01153</a>
&#x1F4C8; 2 <br>
<p>Nathan Ma</p></summary>
<p>

**Abstract:** Many real world person-person or person-product relationships can be modeled graphically. More specifically, bipartite graphs can be especially useful when modeling scenarios that involve two disjoint groups. As a result, many existing papers have utilized bipartite graphs for the classical link recommendation problem. In this paper, using the principle of bipartite graphs, we present another approach to this problem with a two step algorithm that takes into account frequency and similarity between common edges to make recommendations. We test this approach with bipartite data gathered from the Epinions and Movielens data sources, and find it to perform with roughly 14 percent error, which improves upon baseline results. This is a promising result, and can be refined to generate even more accurate recommendations.

</p>
</details>

<details><summary><b>UNFIS: A Novel Neuro-Fuzzy Inference System with Unstructured Fuzzy Rules for Classification</b>
<a href="https://arxiv.org/abs/2211.00599">arxiv:2211.00599</a>
&#x1F4C8; 2 <br>
<p>Armin Salimi-Badr</p></summary>
<p>

**Abstract:** An important constraint of Fuzzy Inference Systems (FIS) is their structured rules defined based on evaluating all input variables. Indeed, the length of all fuzzy rules and the number of input variables are equal. However, in many decision-making problems evaluating some conditions on a limited set of input variables is sufficient to decide properly (unstructured rules). Therefore, this constraint limits the performance, generalization, and interpretability of the FIS. To address this issue, this paper presents a neuro-fuzzy inference system for classification applications that can select different sets of input variables for constructing each fuzzy rule. To realize this capability, a new fuzzy selector neuron with an adaptive parameter is proposed that can select input variables in the antecedent part of each fuzzy rule. Moreover, in this paper, the consequent part of the Takagi-Sugeno-Kang FIS is also changed properly to consider only the selected set of input variables. To learn the parameters of the proposed architecture, a trust-region-based learning method (General quasi-Levenberg-Marquardt (GqLM)) is proposed to minimize cross-entropy in multiclass problems. The performance of the proposed method is compared with some related previous approaches in some real-world classification problems. Based on these comparisons the proposed method has better or very close performance with a parsimonious structure consisting of unstructured fuzzy.

</p>
</details>

<details><summary><b>STPrompt: Semantic-guided and Task-driven prompts for Effective Few-shot Classification</b>
<a href="https://arxiv.org/abs/2210.16489">arxiv:2210.16489</a>
&#x1F4C8; 2 <br>
<p>Jinta Weng, Yue Hu, Jing Qiu, Heyan Huan</p></summary>
<p>

**Abstract:** The effectiveness of prompt learning has been demonstrated in different pre-trained language models. By formulating suitable template and choosing representative label mapping, prompt learning can be used as an efficient knowledge probe. However, finding suitable prompt in existing methods requires multiple experimental attempts or appropriate vector initialization on formulating suitable template and choosing representative label mapping, which it is more common in few-shot learning tasks. Motivating by PLM working process, we try to construct the prompt from task semantic perspective and thus propose the STPrompt -Semantic-guided and Task-driven Prompt model. Specifically, two novel prompts generated from the semantic dependency tree (Dep-prompt) and task-specific metadata description (Meta-prompt), are firstly constructed in a prompt augmented pool, and the proposed model would automatically select a suitable semantic prompt to motivating the prompt learning process. Our results show that the proposed model achieves the state-of-the-art performance in five different datasets of few-shot text classification tasks, which prove that more semantic and significant prompts could assume as a better knowledge proving tool.

</p>
</details>

<details><summary><b>Learning Audio-Visual Dynamics Using Scene Graphs for Audio Source Separation</b>
<a href="https://arxiv.org/abs/2210.16472">arxiv:2210.16472</a>
&#x1F4C8; 2 <br>
<p>Moitreya Chatterjee, Narendra Ahuja, Anoop Cherian</p></summary>
<p>

**Abstract:** There exists an unequivocal distinction between the sound produced by a static source and that produced by a moving one, especially when the source moves towards or away from the microphone. In this paper, we propose to use this connection between audio and visual dynamics for solving two challenging tasks simultaneously, namely: (i) separating audio sources from a mixture using visual cues, and (ii) predicting the 3D visual motion of a sounding source using its separated audio. Towards this end, we present Audio Separator and Motion Predictor (ASMP) -- a deep learning framework that leverages the 3D structure of the scene and the motion of sound sources for better audio source separation. At the heart of ASMP is a 2.5D scene graph capturing various objects in the video and their pseudo-3D spatial proximities. This graph is constructed by registering together 2.5D monocular depth predictions from the 2D video frames and associating the 2.5D scene regions with the outputs of an object detector applied on those frames. The ASMP task is then mathematically modeled as the joint problem of: (i) recursively segmenting the 2.5D scene graph into several sub-graphs, each associated with a constituent sound in the input audio mixture (which is then separated) and (ii) predicting the 3D motions of the corresponding sound sources from the separated audio. To empirically evaluate ASMP, we present experiments on two challenging audio-visual datasets, viz. Audio Separation in the Wild (ASIW) and Audio Visual Event (AVE). Our results demonstrate that ASMP achieves a clear improvement in source separation quality, outperforming prior works on both datasets, while also estimating the direction of motion of the sound sources better than other methods.

</p>
</details>

<details><summary><b>Improving Hyperspectral Adversarial Robustness using Ensemble Networks in the Presences of Multiple Attacks</b>
<a href="https://arxiv.org/abs/2210.16346">arxiv:2210.16346</a>
&#x1F4C8; 2 <br>
<p>Nicholas Soucy, Salimeh Yasaei Sekeh</p></summary>
<p>

**Abstract:** Semantic segmentation of hyperspectral images (HSI) has seen great strides in recent years by incorporating knowledge from deep learning RGB classification models. Similar to their classification counterparts, semantic segmentation models are vulnerable to adversarial examples and need adversarial training to counteract them. Traditional approaches to adversarial robustness focus on training or retraining a single network on attacked data, however, in the presence of multiple attacks these approaches decrease the performance compared to networks trained individually on each attack. To combat this issue we propose an Adversarial Discriminator Ensemble Network (ADE-Net) which focuses on attack type detection and adversarial robustness under a unified model to preserve per data-type weight optimally while robustifiying the overall network. In the proposed method, a discriminator network is used to separate data by attack type into their specific attack-expert ensemble network. Our approach allows for the presence of multiple attacks mixed together while also labeling attack types during testing. We experimentally show that ADE-Net outperforms the baseline, which is a single network adversarially trained under a mix of multiple attacks, for HSI Indian Pines, Kennedy Space, and Houston datasets.

</p>
</details>

<details><summary><b>Learning to Detect Interesting Anomalies</b>
<a href="https://arxiv.org/abs/2210.16334">arxiv:2210.16334</a>
&#x1F4C8; 2 <br>
<p>Alireza Vafaei Sadr, Bruce A. Bassett, Emmanuel Sekyi</p></summary>
<p>

**Abstract:** Anomaly detection algorithms are typically applied to static, unchanging, data features hand-crafted by the user. But how does a user systematically craft good features for anomalies that have never been seen? Here we couple deep learning with active learning -- in which an Oracle iteratively labels small amounts of data selected algorithmically over a series of rounds -- to automatically and dynamically improve the data features for efficient outlier detection. This approach, AHUNT, shows excellent performance on MNIST, CIFAR10, and Galaxy-DESI data, significantly outperforming both standard anomaly detection and active learning algorithms with static feature spaces. Beyond improved performance, AHUNT also allows the number of anomaly classes to grow organically in response to Oracle's evaluations. Extensive ablation studies explore the impact of Oracle question selection strategy and loss function on performance. We illustrate how the dynamic anomaly class taxonomy represents another step towards fully personalized rankings of different anomaly classes that reflect a user's interests, allowing the algorithm to learn to ignore statistically significant but uninteresting outliers (e.g., noise). This should prove useful in the era of massive astronomical datasets serving diverse sets of users who can only review a tiny subset of the incoming data.

</p>
</details>

<details><summary><b>Universal speaker recognition encoders for different speech segments duration</b>
<a href="https://arxiv.org/abs/2210.16231">arxiv:2210.16231</a>
&#x1F4C8; 2 <br>
<p>Sergey Novoselov, Vladimir Volokhov, Galina Lavrentyeva</p></summary>
<p>

**Abstract:** Creating universal speaker encoders which are robust for different acoustic and speech duration conditions is a big challenge today. According to our observations systems trained on short speech segments are optimal for short phrase speaker verification and systems trained on long segments are superior for long segments verification. A system trained simultaneously on pooled short and long speech segments does not give optimal verification results and usually degrades both for short and long segments. This paper addresses the problem of creating universal speaker encoders for different speech segments duration. We describe our simple recipe for training universal speaker encoder for any type of selected neural network architecture. According to our evaluation results of wav2vec-TDNN based systems obtained for NIST SRE and VoxCeleb1 benchmarks the proposed universal encoder provides speaker verification improvements in case of different enrollment and test speech segment duration. The key feature of the proposed encoder is that it has the same inference time as the selected neural network architecture.

</p>
</details>

<details><summary><b>Physics-Informed Convolutional Neural Networks for Corruption Removal on Dynamical Systems</b>
<a href="https://arxiv.org/abs/2210.16215">arxiv:2210.16215</a>
&#x1F4C8; 2 <br>
<p>Daniel Kelshaw, Luca Magri</p></summary>
<p>

**Abstract:** Measurements on dynamical systems, experimental or otherwise, are often subjected to inaccuracies capable of introducing corruption; removal of which is a problem of fundamental importance in the physical sciences. In this work we propose physics-informed convolutional neural networks for stationary corruption removal, providing the means to extract physical solutions from data, given access to partial ground-truth observations at collocation points. We showcase the methodology for 2D incompressible Navier-Stokes equations in the chaotic-turbulent flow regime, demonstrating robustness to modality and magnitude of corruption.

</p>
</details>

<details><summary><b>Environment-aware Interactive Movement Primitives for Object Reaching in Clutter</b>
<a href="https://arxiv.org/abs/2210.16194">arxiv:2210.16194</a>
&#x1F4C8; 2 <br>
<p>Sariah Mghames, Marc Hanheide</p></summary>
<p>

**Abstract:** The majority of motion planning strategies developed over the literature for reaching an object in clutter are applied to two dimensional (2-d) space where the state space of the environment is constrained in one direction. Fewer works have been investigated to reach a target in 3-d cluttered space, and when so, they have limited performance when applied to complex cases. In this work, we propose a constrained multi-objective optimization framework (OptI-ProMP) to approach the problem of reaching a target in a compact clutter with a case study on soft fruits grown in clusters, leveraging the local optimisation-based planner CHOMP. OptI-ProMP features costs related to both static, dynamic and pushable objects in the target neighborhood, and it relies on probabilistic primitives for problem initialisation. We tested, in a simulated poly-tunnel, both ProMP-based planners from literature and the OptI-ProMP, on low (3-dofs) and high (7-dofs) dexterity robot body, respectively. Results show collision and pushing costs minimisation with 7-dofs robot kinematics, in addition to successful static obstacles avoidance and systematic drifting from the pushable objects center of mass.

</p>
</details>

<details><summary><b>A Novel Sparse Bayesian Learning and Its Application to Fault Diagnosis for Multistation Assembly Systems</b>
<a href="https://arxiv.org/abs/2210.16176">arxiv:2210.16176</a>
&#x1F4C8; 2 <br>
<p>Jihoon Chung, Bo Shen,  Zhenyu,  Kong</p></summary>
<p>

**Abstract:** This paper addresses the problem of fault diagnosis in multistation assembly systems. Fault diagnosis is to identify process faults that cause the excessive dimensional variation of the product using dimensional measurements. For such problems, the challenge is solving an underdetermined system caused by a common phenomenon in practice; namely, the number of measurements is less than that of the process errors. To address this challenge, this paper attempts to solve the following two problems: (1) how to utilize the temporal correlation in the time series data of each process error and (2) how to apply prior knowledge regarding which process errors are more likely to be process faults. A novel sparse Bayesian learning method is proposed to achieve the above objectives. The method consists of three hierarchical layers. The first layer has parameterized prior distribution that exploits the temporal correlation of each process error. Furthermore, the second and third layers achieve the prior distribution representing the prior knowledge of process faults. Then, these prior distributions are updated with the likelihood function of the measurement samples from the process, resulting in the accurate posterior distribution of process faults from an underdetermined system. Since posterior distributions of process faults are intractable, this paper derives approximate posterior distributions via Variational Bayes inference. Numerical and simulation case studies using an actual autobody assembly process are performed to demonstrate the effectiveness of the proposed method.

</p>
</details>

<details><summary><b>LOFT: Finding Lottery Tickets through Filter-wise Training</b>
<a href="https://arxiv.org/abs/2210.16169">arxiv:2210.16169</a>
&#x1F4C8; 2 <br>
<p>Qihan Wang, Chen Dun, Fangshuo Liao, Chris Jermaine, Anastasios Kyrillidis</p></summary>
<p>

**Abstract:** Recent work on the Lottery Ticket Hypothesis (LTH) shows that there exist ``\textit{winning tickets}'' in large neural networks. These tickets represent ``sparse'' versions of the full model that can be trained independently to achieve comparable accuracy with respect to the full model. However, finding the winning tickets requires one to \emph{pretrain} the large model for at least a number of epochs, which can be a burdensome task, especially when the original neural network gets larger.
  In this paper, we explore how one can efficiently identify the emergence of such winning tickets, and use this observation to design efficient pretraining algorithms. For clarity of exposition, our focus is on convolutional neural networks (CNNs). To identify good filters, we propose a novel filter distance metric that well-represents the model convergence. As our theory dictates, our filter analysis behaves consistently with recent findings of neural network learning dynamics. Motivated by these observations, we present the \emph{LOttery ticket through Filter-wise Training} algorithm, dubbed as \textsc{LoFT}. \textsc{LoFT} is a model-parallel pretraining algorithm that partitions convolutional layers by filters to train them independently in a distributed setting, resulting in reduced memory and communication costs during pretraining. Experiments show that \textsc{LoFT} $i)$ preserves and finds good lottery tickets, while $ii)$ it achieves non-trivial computation and communication savings, and maintains comparable or even better accuracy than other pretraining methods.

</p>
</details>

<details><summary><b>Towards Trustworthy Multi-Modal Motion Prediction: Evaluation and Interpretability</b>
<a href="https://arxiv.org/abs/2210.16144">arxiv:2210.16144</a>
&#x1F4C8; 2 <br>
<p>Sandra Carrasco Limeros, Sylwia Majchrowska, Joakim Johnander, Christoffer Petersson, Miguel √Ångel Sotelo, David Fern√°ndez Llorca</p></summary>
<p>

**Abstract:** Predicting the motion of other road agents enables autonomous vehicles to perform safe and efficient path planning. This task is very complex, as the behaviour of road agents depends on many factors and the number of possible future trajectories can be considerable (multi-modal). Most approaches proposed to address multi-modal motion prediction are based on complex machine learning systems that have limited interpretability. Moreover, the metrics used in current benchmarks do not evaluate all aspects of the problem, such as the diversity and admissibility of the output. In this work, we aim to advance towards the design of trustworthy motion prediction systems, based on some of the requirements for the design of Trustworthy Artificial Intelligence. We focus on evaluation criteria, robustness, and interpretability of outputs. First, we comprehensively analyse the evaluation metrics, identify the main gaps of current benchmarks, and propose a new holistic evaluation framework. In addition, we formulate a method for the assessment of spatial and temporal robustness by simulating noise in the perception system. We propose an intent prediction layer that can be attached to multi-modal motion prediction models to enhance the interpretability of the outputs and generate more balanced results in the proposed evaluation framework. Finally, the interpretability of the outputs is assessed by means of a survey that explores different elements in the visualization of the multi-modal trajectories and intentions.

</p>
</details>

<details><summary><b>Efficient and Light-Weight Federated Learning via Asynchronous Distributed Dropout</b>
<a href="https://arxiv.org/abs/2210.16105">arxiv:2210.16105</a>
&#x1F4C8; 2 <br>
<p>Chen Dun, Mirian Hipolito, Chris Jermaine, Dimitrios Dimitriadis, Anastasios Kyrillidis</p></summary>
<p>

**Abstract:** Asynchronous learning protocols have regained attention lately, especially in the Federated Learning (FL) setup, where slower clients can severely impede the learning process. Herein, we propose \texttt{AsyncDrop}, a novel asynchronous FL framework that utilizes dropout regularization to handle device heterogeneity in distributed settings. Overall, \texttt{AsyncDrop} achieves better performance compared to state of the art asynchronous methodologies, while resulting in less communication and training time overheads. The key idea revolves around creating ``submodels'' out of the global model, and distributing their training to workers, based on device heterogeneity. We rigorously justify that such an approach can be theoretically characterized. We implement our approach and compare it against other asynchronous baselines, both by design and by adapting existing synchronous FL algorithms to asynchronous scenarios. Empirically, \texttt{AsyncDrop} reduces the communication cost and training time, while matching or improving the final test accuracy in diverse non-i.i.d. FL scenarios.

</p>
</details>

<details><summary><b>Fuzzy Logic Model for Predicting the Heat Index</b>
<a href="https://arxiv.org/abs/2210.16051">arxiv:2210.16051</a>
&#x1F4C8; 2 <br>
<p>Nnamdi Uzoukwu, Acep Purqon</p></summary>
<p>

**Abstract:** A fuzzy inference system was developed for predicting the heat index from temperature and relative humidity data. The effectiveness of fuzzy logic in using imprecise mapping of input to output to encode interconnectedness of system variables was exploited to uncover a linguistic model of how the temperature and humidity conditions impact the heat index in a growth room. The developed model achieved an R2 of 0.974 and a RMSE of 0.084 when evaluated on a test set, and the results were statistically significant (F1,5915 = 222900.858, p < 0.001). By providing the advantage of linguistic summarization of data trends as well as high prediction accuracy, the fuzzy logic model proved to be an effective machine learning method for heat control problems.

</p>
</details>

<details><summary><b>Review on Classification Techniques used in Biophysiological Stress Monitoring</b>
<a href="https://arxiv.org/abs/2210.16040">arxiv:2210.16040</a>
&#x1F4C8; 2 <br>
<p>Talha Iqbal, Adnan Elahi, Atif Shahzad, William Wijns</p></summary>
<p>

**Abstract:** Cardiovascular activities are directly related to the response of a body in a stressed condition. Stress, based on its intensity, can be divided into two types i.e. Acute stress (short-term stress) and Chronic stress (long-term stress). Repeated acute stress and continuous chronic stress may play a vital role in inflammation in the circulatory system and thus leads to a heart attack or to a stroke. In this study, we have reviewed commonly used machine learning classification techniques applied to different stress-indicating parameters used in stress monitoring devices. These parameters include Photoplethysmograph (PPG), Electrocardiographs (ECG), Electromyograph (EMG), Galvanic Skin Response (GSR), Heart Rate Variation (HRV), skin temperature, respiratory rate, Electroencephalograph (EEG) and salivary cortisol, used in stress monitoring devices. This study also provides a discussion on choosing a classifier, which depends upon a number of factors other than accuracy, like the number of subjects involved in an experiment, type of signals processing and computational limitations.

</p>
</details>

<details><summary><b>Improving Multi-class Classifier Using Likelihood Ratio Estimation with Regularization</b>
<a href="https://arxiv.org/abs/2210.16033">arxiv:2210.16033</a>
&#x1F4C8; 2 <br>
<p>Masato Kikuchi, Tadachika Ozono</p></summary>
<p>

**Abstract:** The universal-set naive Bayes classifier (UNB)~\cite{Komiya:13}, defined using likelihood ratios (LRs), was proposed to address imbalanced classification problems. However, the LR estimator used in the UNB overestimates LRs for low-frequency data, degrading the classification performance. Our previous study~\cite{Kikuchi:19} proposed an effective LR estimator even for low-frequency data. This estimator uses regularization to suppress the overestimation, but we did not consider imbalanced data. In this paper, we integrated the estimator with the UNB. Our experiments with imbalanced data showed that our proposed classifier effectively adjusts the classification scores according to the class balance using regularization parameters and improves the classification performance.

</p>
</details>

<details><summary><b>Incorporating Interactive Facts for Stock Selection via Neural Recursive ODEs</b>
<a href="https://arxiv.org/abs/2210.15925">arxiv:2210.15925</a>
&#x1F4C8; 2 <br>
<p>Qiang Gao, Xinzhu Zhou, Kunpeng Zhang, Li Huang, Siyuan Liu, Fan Zhou</p></summary>
<p>

**Abstract:** Stock selection attempts to rank a list of stocks for optimizing investment decision making, aiming at minimizing investment risks while maximizing profit returns. Recently, researchers have developed various (recurrent) neural network-based methods to tackle this problem. Without exceptions, they primarily leverage historical market volatility to enhance the selection performance. However, these approaches greatly rely on discrete sampled market observations, which either fail to consider the uncertainty of stock fluctuations or predict continuous stock dynamics in the future. Besides, some studies have considered the explicit stock interdependence derived from multiple domains (e.g., industry and shareholder). Nevertheless, the implicit cross-dependencies among different domains are under-explored. To address such limitations, we present a novel stock selection solution -- StockODE, a latent variable model with Gaussian prior. Specifically, we devise a Movement Trend Correlation module to expose the time-varying relationships regarding stock movements. We design Neural Recursive Ordinary Differential Equation Networks (NRODEs) to capture the temporal evolution of stock volatility in a continuous dynamic manner. Moreover, we build a hierarchical hypergraph to incorporate the domain-aware dependencies among the stocks. Experiments conducted on two real-world stock market datasets demonstrate that StockODE significantly outperforms several baselines, such as up to 18.57% average improvement regarding Sharpe Ratio.

</p>
</details>

<details><summary><b>Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences</b>
<a href="https://arxiv.org/abs/2210.15906">arxiv:2210.15906</a>
&#x1F4C8; 2 <br>
<p>Lin Guan, Karthik Valmeekam, Subbarao Kambhampati</p></summary>
<p>

**Abstract:** Generating complex behaviors from goals specified by non-expert users is a crucial aspect of intelligent agents. Interactive reward learning from trajectory comparisons is one way to allow non-expert users to convey complex objectives by expressing preferences over short clips of agent behaviors. Even though this method can encode complex tacit knowledge present in the underlying tasks, it implicitly assumes that the human is unable to provide rich-form feedback other than binary preference labels, leading to extremely high feedback complexity and poor user experience. While providing a detailed symbolic specification of the objectives might be tempting, it is not always feasible even for an expert user. However, in most cases, humans are aware of how the agent should change its behavior along meaningful axes to fulfill the underlying purpose, even if they are not able to fully specify task objectives symbolically. Using this as motivation, we introduce the notion of Relative Behavioral Attributes, which acts as a middle ground, between exact goal specification and reward learning purely from preference labels, by enabling the users to tweak the agent's behavior through nameable concepts (e.g., increasing the softness of the movement of a two-legged "sneaky" agent). We propose two different parametric methods that can potentially encode any kind of behavioral attributes from ordered behavior clips. We demonstrate the effectiveness of our methods on 4 tasks with 9 different behavioral attributes and show that once the attributes are learned, end users can effortlessly produce desirable agent behaviors, by providing feedback just around 10 times. The feedback complexity of our approach is over 10 times less than the learning-from-human-preferences baseline and this demonstrates that our approach is readily applicable in real-world applications.

</p>
</details>

<details><summary><b>Learning to Immunize Images for Tamper Localization and Self-Recovery</b>
<a href="https://arxiv.org/abs/2210.15902">arxiv:2210.15902</a>
&#x1F4C8; 2 <br>
<p>Qichao Ying, Hang Zhou, Zhenxing Qian, Sheng Li, Xinpeng Zhang</p></summary>
<p>

**Abstract:** Digital images are vulnerable to nefarious tampering attacks such as content addition or removal that severely alter the original meaning. It is somehow like a person without protection that is open to various kinds of viruses. Image immunization (Imuge) is a technology of protecting the images by introducing trivial perturbation, so that the protected images are immune to the viruses in that the tampered contents can be auto-recovered. This paper presents Imuge+, an enhanced scheme for image immunization. By observing the invertible relationship between image immunization and the corresponding self-recovery, we employ an invertible neural network to jointly learn image immunization and recovery respectively in the forward and backward pass. We also introduce an efficient attack layer that involves both malicious tamper and benign image post-processing, where a novel distillation-based JPEG simulator is proposed for improved JPEG robustness. Our method achieves promising results in real-world tests where experiments show accurate tamper localization as well as high-fidelity content recovery. Additionally, we show superior performance on tamper localization compared to state-of-the-art schemes based on passive forensics.

</p>
</details>

<details><summary><b>Mixed Reality Interface for Digital Twin of Plant Factory</b>
<a href="https://arxiv.org/abs/2211.00597">arxiv:2211.00597</a>
&#x1F4C8; 1 <br>
<p>Byunghyun Ban</p></summary>
<p>

**Abstract:** An easier and intuitive interface architecture is necessary for digital twin of plant factory. I suggest an immersive and interactive mixed reality interface for digital twin models of smart farming, for remote work rather than simulation of components. The environment is constructed with UI display and a streaming background scene, which is a real time scene taken from camera device located in the plant factory, processed with deformable neural radiance fields. User can monitor and control the remote plant factory facilities with HMD or 2D display based mixed reality environment. This paper also introduces detailed concept and describes the system architecture to implement suggested mixed reality interface.

</p>
</details>

<details><summary><b>Digital twins of physical printing-imaging channel</b>
<a href="https://arxiv.org/abs/2210.17420">arxiv:2210.17420</a>
&#x1F4C8; 1 <br>
<p>Yury Belousov, Brian Pulfer, Roman Chaban, Joakim Tutt, Olga Taran, Taras Holotyak, Slava Voloshynovskiy</p></summary>
<p>

**Abstract:** In this paper, we address the problem of modeling a printing-imaging channel built on a machine learning approach a.k.a. digital twin for anti-counterfeiting applications based on copy detection patterns (CDP). The digital twin is formulated on an information-theoretic framework called Turbo that uses variational approximations of mutual information developed for both encoder and decoder in a two-directional information passage. The proposed model generalizes several state-of-the-art architectures such as adversarial autoencoder (AAE), CycleGAN and adversarial latent space autoencoder (ALAE). This model can be applied to any type of printing and imaging and it only requires training data consisting of digital templates or artworks that are sent to a printing device and data acquired by an imaging device. Moreover, these data can be paired, unpaired or hybrid paired-unpaired which makes the proposed architecture very flexible and scalable to many practical setups. We demonstrate the impact of various architectural factors, metrics and discriminators on the overall system performance in the task of generation/prediction of printed CDP from their digital counterparts and vice versa. We also compare the proposed system with several state-of-the-art methods used for image-to-image translation applications.

</p>
</details>

<details><summary><b>Impact of PolSAR pre-processing and balancing methods on complex-valued neural networks segmentation tasks</b>
<a href="https://arxiv.org/abs/2210.17419">arxiv:2210.17419</a>
&#x1F4C8; 1 <br>
<p>Jos√© Agustin Barrachina, Chengfang Ren, Christ√®le Morisseau, Gilles Vieillard, Jean-Philippe Ovarlez</p></summary>
<p>

**Abstract:** In this paper, we investigated the semantic segmentation of Polarimetric Synthetic Aperture Radar (PolSAR) using Complex-Valued Neural Network (CVNN). Although the coherency matrix is more widely used as the input of CVNN, the Pauli vector has recently been shown to be a valid alternative. We exhaustively compare both methods for six model architectures, three complex-valued, and their respective real-equivalent models. We are comparing, therefore, not only the input representation impact but also the complex- against the real-valued models. We then argue that the dataset splitting produces a high correlation between training and validation sets, saturating the task and thus achieving very high performance. We, therefore, use a different data pre-processing technique designed to reduce this effect and reproduce the results with the same configurations as before (input representation and model architectures). After seeing that the performance per class is highly different according to class occurrences, we propose two methods for reducing this gap and performing the results for all input representations, models, and dataset pre-processing.

</p>
</details>

<details><summary><b>Sentiment Classification of Code-Switched Text using Pre-trained Multilingual Embeddings and Segmentation</b>
<a href="https://arxiv.org/abs/2210.16461">arxiv:2210.16461</a>
&#x1F4C8; 1 <br>
<p>Saurav K. Aryal, Howard Prioleau, Gloria Washington</p></summary>
<p>

**Abstract:** With increasing globalization and immigration, various studies have estimated that about half of the world population is bilingual. Consequently, individuals concurrently use two or more languages or dialects in casual conversational settings. However, most research is natural language processing is focused on monolingual text. To further the work in code-switched sentiment analysis, we propose a multi-step natural language processing algorithm utilizing points of code-switching in mixed text and conduct sentiment analysis around those identified points. The proposed sentiment analysis algorithm uses semantic similarity derived from large pre-trained multilingual models with a handcrafted set of positive and negative words to determine the polarity of code-switched text. The proposed approach outperforms a comparable baseline model by 11.2% for accuracy and 11.64% for F1-score on a Spanish-English dataset. Theoretically, the proposed algorithm can be expanded for sentiment analysis of multiple languages with limited human expertise.

</p>
</details>

<details><summary><b>Joint Sub-component Level Segmentation and Classification for Anomaly Detection within Dual-Energy X-Ray Security Imagery</b>
<a href="https://arxiv.org/abs/2210.16453">arxiv:2210.16453</a>
&#x1F4C8; 1 <br>
<p>Neelanjan Bhowmik, Toby P. Breckon</p></summary>
<p>

**Abstract:** X-ray baggage security screening is in widespread use and crucial to maintaining transport security for threat/anomaly detection tasks. The automatic detection of anomaly, which is concealed within cluttered and complex electronics/electrical items, using 2D X-ray imagery is of primary interest in recent years. We address this task by introducing joint object sub-component level segmentation and classification strategy using deep Convolution Neural Network architecture. The performance is evaluated over a dataset of cluttered X-ray baggage security imagery, consisting of consumer electrical and electronics items using variants of dual-energy X-ray imagery (pseudo-colour, high, low, and effective-Z). The proposed joint sub-component level segmentation and classification approach achieve ~99% true positive and ~5% false positive for anomaly detection task.

</p>
</details>

<details><summary><b>Robust Boosting Forests with Richer Deep Feature Hierarchy</b>
<a href="https://arxiv.org/abs/2210.16451">arxiv:2210.16451</a>
&#x1F4C8; 1 <br>
<p>Jianqiao Wangni</p></summary>
<p>

**Abstract:** We propose a robust variant of boosting forest to the various adversarial defense methods, and apply it to enhance the robustness of the deep neural network. We retain the deep network architecture, weights, and middle layer features, then install gradient boosting forest to select the features from each layer of the deep network, and predict the target. For training each decision tree, we propose a novel conservative and greedy trade-off, with consideration for less misprediction instead of pure gain functions, therefore being suboptimal and conservative. We actively increase tree depth to remedy the accuracy with splits in more features, being more greedy in growing tree depth. We propose a new task on 3D face model, whose robustness has not been carefully studied, despite the great security and privacy concerns related to face analytics. We tried a simple attack method on a pure convolutional neural network (CNN) face shape estimator, making it degenerate to only output average face shape with invisible perturbation. Our conservative-greedy boosting forest (CGBF) on face landmark datasets showed a great improvement over original pure deep learning methods under the adversarial attacks.

</p>
</details>

<details><summary><b>Meta-Learning Biologically Plausible Plasticity Rules with Random Feedback Pathways</b>
<a href="https://arxiv.org/abs/2210.16414">arxiv:2210.16414</a>
&#x1F4C8; 1 <br>
<p>Navid Shervani-Tabar, Robert Rosenbaum</p></summary>
<p>

**Abstract:** Backpropagation is widely used to train artificial neural networks, but its relationship to synaptic plasticity in the brain is unknown. Some biological models of backpropagation rely on feedback projections that are symmetric with feedforward connections, but experiments do not corroborate the existence of such symmetric backward connectivity. Random feedback alignment offers an alternative model in which errors are propagated backward through fixed, random backward connections. This approach successfully trains shallow models, but learns slowly and does not perform well with deeper models or online learning. In this study, we develop a novel meta-plasticity approach to discover interpretable, biologically plausible plasticity rules that improve online learning performance with fixed random feedback connections. The resulting plasticity rules show improved online training of deep models in the low data regime. Our results highlight the potential of meta-plasticity to discover effective, interpretable learning rules satisfying biological constraints.

</p>
</details>

<details><summary><b>A State-Augmented Approach for Learning Optimal Resource Management Decisions in Wireless Networks</b>
<a href="https://arxiv.org/abs/2210.16412">arxiv:2210.16412</a>
&#x1F4C8; 1 <br>
<p>Yiƒüit Berkay Uslu, Navid NaderiAlizadeh, Mark Eisen, Alejandro Riberio</p></summary>
<p>

**Abstract:** We consider a radio resource management (RRM) problem in a multi-user wireless network, where the goal is to optimize a network-wide utility function subject to constraints on the ergodic average performance of users. We propose a state-augmented parameterization for the RRM policy, where alongside the instantaneous network states, the RRM policy takes as input the set of dual variables corresponding to the constraints. We provide theoretical justification for the feasibility and near-optimality of the RRM decisions generated by the proposed state-augmented algorithm. Focusing on the power allocation problem with RRM policies parameterized by a graph neural network (GNN) and dual variables sampled from the dual descent dynamics, we numerically demonstrate that the proposed approach achieves a superior trade-off between mean, minimum, and 5th percentile rates than baseline methods.

</p>
</details>

<details><summary><b>U-Net-based Models for Skin Lesion Segmentation: More Attention and Augmentation</b>
<a href="https://arxiv.org/abs/2210.16399">arxiv:2210.16399</a>
&#x1F4C8; 1 <br>
<p>Pooya Mohammadi Kazaj, MohammadHossein Koosheshi, Ali Shahedi, Alireza Vafaei Sadr</p></summary>
<p>

**Abstract:** According to WHO[1], since the 1970s, diagnosis of melanoma skin cancer has been more frequent. However, if detected early, the 5-year survival rate for melanoma can increase to 99 percent. In this regard, skin lesion segmentation can be pivotal in monitoring and treatment planning. In this work, ten models and four augmentation configurations are trained on the ISIC 2016 dataset. The performance and overfitting are compared utilizing five metrics. Our results show that the U-Net-Resnet50 and the R2U-Net have the highest metrics value, along with two data augmentation scenarios. We also investigate CBAM and AG blocks in the U-Net architecture, which enhances segmentation performance at a meager computational cost. In addition, we propose using pyramid, AG, and CBAM blocks in a sequence, which significantly surpasses the results of using the two individually. Finally, our experiments show that models that have exploited attention modules successfully overcome common skin lesion segmentation problems. Lastly, in the spirit of reproducible research, we implement models and codes publicly available.

</p>
</details>

<details><summary><b>An Approach for Noisy, Crowdsourced Datasets Utilizing Ensemble Modeling, 'Human Softmax' Distributions, and Entropic Measures of Uncertainty</b>
<a href="https://arxiv.org/abs/2210.16380">arxiv:2210.16380</a>
&#x1F4C8; 1 <br>
<p>Graham West, Matthew I. Swindall, Ben Keener, Timothy Player, Alex C. Williams, James H. Brusuelas, John F. Wallin</p></summary>
<p>

**Abstract:** Noisy, crowdsourced image datasets prove challenging, even for the best neural networks. Two issues which complicate classification on such datasets are class imbalance and ground-truth uncertainty in labeling. The AL-ALL and AL-PUB datasets-consisting of tightly cropped, individual characters from images of ancient Greek papyri are strongly affected by both issues. The application of ensemble modeling to such a dataset can help identify images where the ground-truth is questionable and quantify the trustworthiness of those samples. We apply stacked generalization consisting of nearly identical ResNets: one utilizing cross-entropy (CXE) and the other Kullback-Liebler Divergence (KLD). The CXE network uses standard labeling drawn from the crowdsourced consensus. In contrast, the KLD network uses probabilistic labeling for each image derived from the distribution of crowdsourced annotations. We refer to this labeling as the Human Softmax (HSM) distribution. For our ensemble model, we apply a k-nearest neighbors model to the outputs of the CXE and KLD networks. Individually, the ResNet models have approximately 93% accuracy, while the ensemble model achieves an accuracy of >95%. We also perform an analysis of the Shannon entropy of the various models' output distributions to measure classification uncertainty.

</p>
</details>

<details><summary><b>Nonuniqueness and Convergence to Equivalent Solutions in Observer-based Inverse Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.16299">arxiv:2210.16299</a>
&#x1F4C8; 1 <br>
<p>Jared Town, Zachary Morrison, Rushikesh Kamalapurkar</p></summary>
<p>

**Abstract:** A key challenge in solving the deterministic inverse reinforcement learning problem online and in real time is the existence of non-unique solutions. Nonuniqueness necessitates the study of the notion of equivalent solutions and convergence to such solutions.
  While \emph{offline} algorithms that result in convergence to equivalent solutions have been developed in the literature, online, real-time techniques that address nonuniqueness are not available. In this paper, a regularized history stack observer is developed to generate solutions that are approximately equivalent. Novel data-richness conditions are developed to facilitate the analysis and simulation results are provided to demonstrate the effectiveness of the developed technique.

</p>
</details>

<details><summary><b>Learning with Multigraph Convolutional Filters</b>
<a href="https://arxiv.org/abs/2210.16272">arxiv:2210.16272</a>
&#x1F4C8; 1 <br>
<p>Landon Butler, Alejandro Parada-Mayorga, Alejandro Ribeiro</p></summary>
<p>

**Abstract:** In this paper, we introduce a convolutional architecture to perform learning when information is supported on multigraphs. Exploiting algebraic signal processing (ASP), we propose a convolutional signal processing model on multigraphs (MSP). Then, we introduce multigraph convolutional neural networks (MGNNs) as stacked and layered structures where information is processed according to an MSP model. We also develop a procedure for tractable computation of filter coefficients in the MGNN and a low cost method to reduce the dimensionality of the information transferred between layers. We conclude by comparing the performance of MGNNs against other learning architectures on an optimal resource allocation task for multi-channel communication systems.

</p>
</details>

<details><summary><b>Applying Physics-Informed Enhanced Super-Resolution Generative Adversarial Networks to Turbulent Non-Premixed Combustion on Non-Uniform Meshes and Demonstration of an Accelerated Simulation Workflow</b>
<a href="https://arxiv.org/abs/2210.16248">arxiv:2210.16248</a>
&#x1F4C8; 1 <br>
<p>Mathis Bode</p></summary>
<p>

**Abstract:** This paper extends the methodology to use physics-informed enhanced super-resolution generative adversarial networks (PIESRGANs) for LES subfilter modeling in turbulent flows with finite-rate chemistry and shows a successful application to a non-premixed temporal jet case. This is an important topic considering the need for more efficient and carbon-neutral energy devices to fight the climate change. Multiple a priori and a posteriori results are presented and discussed. As part of this, the impact of the underlying mesh on the prediction quality is emphasized, and a multi-mesh approach is developed. It is demonstrated how LES based on PIESRGAN can be employed to predict cases at Reynolds numbers which were not used for training. Finally, the amount of data needed for a successful prediction is elaborated.

</p>
</details>

<details><summary><b>Applying Physics-Informed Enhanced Super-Resolution Generative Adversarial Networks to Turbulent Premixed Combustion and Engine-like Flame Kernel Direct Numerical Simulation Data</b>
<a href="https://arxiv.org/abs/2210.16206">arxiv:2210.16206</a>
&#x1F4C8; 1 <br>
<p>Mathis Bode, Michael Gauding, Dominik Goeb, Tobias Falkenstein, Heinz Pitsch</p></summary>
<p>

**Abstract:** Models for finite-rate-chemistry in underresolved flows still pose one of the main challenges for predictive simulations of complex configurations. The problem gets even more challenging if turbulence is involved. This work advances the recently developed PIESRGAN modeling approach to turbulent premixed combustion. For that, the physical information processed by the network and considered in the loss function are adjusted, the training process is smoothed, and especially effects from density changes are considered. The resulting model provides good results for a priori and a posteriori tests on direct numerical simulation data of a fully turbulent premixed flame kernel. The limits of the modeling approach are discussed. Finally, the model is employed to compute further realizations of the premixed flame kernel, which are analyzed with a scale-sensitive framework regarding their cycle-to-cycle variations. The work shows that the data-driven PIESRGAN subfilter model can very accurately reproduce direct numerical simulation data on much coarser meshes, which is hardly possible with classical subfilter models, and enables studying statistical processes more efficiently due to the smaller computing cost.

</p>
</details>

<details><summary><b>Transferable E(3) equivariant parameterization for Hamiltonian of molecules and solids</b>
<a href="https://arxiv.org/abs/2210.16190">arxiv:2210.16190</a>
&#x1F4C8; 1 <br>
<p>Yang Zhong, Hongyu Yu, Mao Su, Xingao Gong, Hongjun Xiang</p></summary>
<p>

**Abstract:** Machine learning, especially deep learning, can build a direct mapping from structure to properties with its huge parameter space, making it possible to perform high-throughput screening for the desired properties of materials. However, since the electronic Hamiltonian transforms non-trivially under rotation operations, it is challenging to accurately predict the electronic Hamiltonian while strictly satisfying this constraint. There is currently a lack of transferable machine learning models that can bypass the computationally demanding density functional theory (DFT) to obtain the ab initio Hamiltonian of molecules and materials by complete data-driven methods. In this work, we point out the necessity of explicitly considering the parity symmetry of the electronic Hamiltonian in addition to rotational equivariance. We propose a parameterized Hamiltonian that strictly satisfies rotational equivariance and parity symmetry simultaneously, based on which we develop an E(3) equivariant neural network called HamNet to predict the ab initio tight-binding Hamiltonian of various molecules and solids. The tests show that this model has similar transferability to that of machine learning potentials and can be applied to a class of materials with different configurations using the same set of trained network weights. The proposed framework provides a general transferable model for accelerating electronic structure calculations.

</p>
</details>

<details><summary><b>A Long-term Dependent and Trustworthy Approach to Reactor Accident Prognosis based on Temporal Fusion Transformer</b>
<a href="https://arxiv.org/abs/2210.17298">arxiv:2210.17298</a>
&#x1F4C8; 0 <br>
<p>Chengyuan Li, Zhifang Qiu, Yugao Ma, Meifu Li</p></summary>
<p>

**Abstract:** Prognosis of the reactor accident is a crucial way to ensure appropriate strategies are adopted to avoid radioactive releases. However, there is very limited research in the field of nuclear industry. In this paper, we propose a method for accident prognosis based on the Temporal Fusion Transformer (TFT) model with multi-headed self-attention and gating mechanisms. The method utilizes multiple covariates to improve prediction accuracy on the one hand, and quantile regression methods for uncertainty assessment on the other. The method proposed in this paper is applied to the prognosis after loss of coolant accidents (LOCAs) in HPR1000 reactor. Extensive experimental results show that the method surpasses novel deep learning-based prediction methods in terms of prediction accuracy and confidence. Furthermore, the interference experiments with different signal-to-noise ratios and the ablation experiments for static covariates further illustrate that the robustness comes from the ability to extract the features of static and historical covariates. In summary, this work for the first time applies the novel composite deep learning model TFT to the prognosis of key parameters after a reactor accident, and makes a positive contribution to the establishment of a more intelligent and staff-light maintenance method for reactor systems.

</p>
</details>

<details><summary><b>Using Contrastive Samples for Identifying and Leveraging Possible Causal Relationships in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.17296">arxiv:2210.17296</a>
&#x1F4C8; 0 <br>
<p>Harshad Khadilkar, Hardik Meisheri</p></summary>
<p>

**Abstract:** A significant challenge in reinforcement learning is quantifying the complex relationship between actions and long-term rewards. The effects may manifest themselves over a long sequence of state-action pairs, making them hard to pinpoint. In this paper, we propose a method to link transitions with significant deviations in state with unusually large variations in subsequent rewards. Such transitions are marked as possible causal effects, and the corresponding state-action pairs are added to a separate replay buffer. In addition, we include \textit{contrastive} samples corresponding to transitions from a similar state but with differing actions. Including this Contrastive Experience Replay (CER) during training is shown to outperform standard value-based methods on 2D navigation tasks. We believe that CER can be useful for a broad class of learning tasks, including for any off-policy reinforcement learning algorithm.

</p>
</details>

<details><summary><b>Forecasting local behavior of multi-agent system and its application to forest fire model</b>
<a href="https://arxiv.org/abs/2210.17289">arxiv:2210.17289</a>
&#x1F4C8; 0 <br>
<p>Beomseok Kang, Minah Lee, Harshit Kumar, Saibal Mukhopadhyay</p></summary>
<p>

**Abstract:** In this paper, we study a CNN-LSTM model to forecast the state of a specific agent in a large multi-agent system. The proposed model consists of a CNN encoder to represent the system into a low-dimensional vector, a LSTM module to learn the agent dynamics in the vector space, and a MLP decoder to predict the future state of an agent. A forest fire model is considered as an example where we need to predict when a specific tree agent will be burning. We observe that the proposed model achieves higher AUC with less computation than a frame-based model and significantly saves computational costs such as the activation than ConvLSTM.

</p>
</details>

<details><summary><b>Neural network quantum state with proximal optimization: a ground-state searching scheme based on variational Monte Carlo</b>
<a href="https://arxiv.org/abs/2210.16493">arxiv:2210.16493</a>
&#x1F4C8; 0 <br>
<p>Feng Chen, Ming Xue</p></summary>
<p>

**Abstract:** Neural network quantum states (NQS), incorporating with variational Monte Carlo (VMC) method, are shown to be a promising way to investigate quantum many-body physics. Whereas vanilla VMC methods perform one gradient update per sample, we introduce a novel objective function with proximal optimization (PO) that enables multiple updates via reusing the mismatched samples. Our VMC-PO method keeps the advantage of the previous importance sampling gradient optimization algorithm [L. Yang, {\it et al}, Phys. Rev. Research {\bf 2}, 012039(R)(2020)] that efficiently uses sampled states. PO mitigates the numerical instabilities during network updates, which is similar to stochastic reconfiguration (SR) methods, but achieves an alternative and simpler implement with lower computational complexity. We investigate the performance of our VMC-PO algorithm for ground-state searching with a 1-dimensional transverse-field Ising model and 2-dimensional Heisenberg antiferromagnet on a square lattice, and demonstrate that the reached ground-state energies are comparable to state-of-the-art results.

</p>
</details>

<details><summary><b>A Systematic Survey of Molecular Pre-trained Models</b>
<a href="https://arxiv.org/abs/2210.16484">arxiv:2210.16484</a>
&#x1F4C8; 0 <br>
<p>Jun Xia, Yanqiao Zhu, Yuanqi Du, Yue Liu, Stan Z. Li</p></summary>
<p>

**Abstract:** Obtaining effective molecular representations is at the core of a series of important chemical tasks ranging from property prediction to drug design. So far, deep learning has achieved remarkable success in learning representations for molecules through automated feature learning in a data-driven fashion. However, training deep neural networks from scratch often requires sufficient labeled molecules which are expensive to acquire in real-world scenarios. To alleviate this issue, inspired by the success of the pretrain-then-finetune paradigm in natural language processing, tremendous efforts have been devoted to Molecular Pre-trained Models (MPMs), where neural networks are pre-trained using large-scale unlabeled molecular databases and then fine-tuned for diverse downstream tasks. Despite the prosperity, this field is fast-growing and a systematic roadmap is urgently needed for both methodology advancements and practical applications in both machine learning and scientific communities. To this end, this paper provides a systematic survey of pre-trained models for molecular representations. Firstly, to motivate MPMs studies, we highlight the limitations of training deep neural networks for molecular representations. Next, we systematically review recent advances on this topic from several key perspectives including molecular descriptors, encoder architectures, pre-training strategies, and applications. Finally, we identify several challenges and discuss promising future research directions.

</p>
</details>

<details><summary><b>Curiosity-Driven Multi-Agent Exploration with Mixed Objectives</b>
<a href="https://arxiv.org/abs/2210.16468">arxiv:2210.16468</a>
&#x1F4C8; 0 <br>
<p>Roben Delos Reyes, Kyunghwan Son, Jinhwan Jung, Wan Ju Kang, Yung Yi</p></summary>
<p>

**Abstract:** Intrinsic rewards have been increasingly used to mitigate the sparse reward problem in single-agent reinforcement learning. These intrinsic rewards encourage the agent to look for novel experiences, guiding the agent to explore the environment sufficiently despite the lack of extrinsic rewards. Curiosity-driven exploration is a simple yet efficient approach that quantifies this novelty as the prediction error of the agent's curiosity module, an internal neural network that is trained to predict the agent's next state given its current state and action. We show here, however, that naively using this curiosity-driven approach to guide exploration in sparse reward cooperative multi-agent environments does not consistently lead to improved results. Straightforward multi-agent extensions of curiosity-driven exploration take into consideration either individual or collective novelty only and thus, they do not provide a distinct but collaborative intrinsic reward signal that is essential for learning in cooperative multi-agent tasks. In this work, we propose a curiosity-driven multi-agent exploration method that has the mixed objective of motivating the agents to explore the environment in ways that are individually and collectively novel. First, we develop a two-headed curiosity module that is trained to predict the corresponding agent's next observation in the first head and the next joint observation in the second head. Second, we design the intrinsic reward formula to be the sum of the individual and joint prediction errors of this curiosity module. We empirically show that the combination of our curiosity module architecture and intrinsic reward formulation guides multi-agent exploration more efficiently than baseline approaches, thereby providing the best performance boost to MARL algorithms in cooperative navigation environments with sparse rewards.

</p>
</details>

<details><summary><b>Reformulating van Rijsbergen's $F_Œ≤$ metric for weighted binary cross-entropy</b>
<a href="https://arxiv.org/abs/2210.16458">arxiv:2210.16458</a>
&#x1F4C8; 0 <br>
<p>Satesh Ramdhani</p></summary>
<p>

**Abstract:** The separation of performance metrics from gradient based loss functions may not always give optimal results and may miss vital aggregate information. This paper investigates incorporating a performance metric alongside differentiable loss functions to inform training outcomes. The goal is to guide model performance and interpretation by assuming statistical distributions on this performance metric for dynamic weighting. The focus is on van Rijsbergens $F_Œ≤$ metric -- a popular choice for gauging classification performance. Through distributional assumptions on the $F_Œ≤$, an intermediary link can be established to the standard binary cross-entropy via dynamic penalty weights. First, the $F_Œ≤$ metric is reformulated to facilitate assuming statistical distributions with accompanying proofs for the cumulative density function. These probabilities are used within a knee curve algorithm to find an optimal $Œ≤$ or $Œ≤_{opt}$. This $Œ≤_{opt}$ is used as a weight or penalty in the proposed weighted binary cross-entropy. Experimentation on publicly available data with imbalanced classes mostly yields better and interpretable results as compared to the baseline. For example, for the IMDB text data with known labeling errors, a 14% boost is shown. This methodology can accelerate training and provide better interpretation.

</p>
</details>

<details><summary><b>ODNet: A Convolutional Neural Network for Asteroid Occultation Detection</b>
<a href="https://arxiv.org/abs/2210.16440">arxiv:2210.16440</a>
&#x1F4C8; 0 <br>
<p>Dorian Cazeneuve, Franck Marchis, Guillaume Blaclard, Paul A. Dalba, Victor Martin, Jo√© Asencioa</p></summary>
<p>

**Abstract:** We propose to design and build an algorithm that will use a Convolutional Neural Network (CNN) and observations from the Unistellar network to reliably detect asteroid occultations. The Unistellar Network, made of more than 10,000 digital telescopes owned by citizen scientists, and is regularly used to record asteroid occultations. In order to process the increasing amount of observational produced by this network, we need a quick and reliable way to analyze occultations. In an effort to solve this problem, we trained a CNN with artificial images of stars with twenty different types of photometric signals. Inputs to the network consists of two stacks of snippet images of stars, one around the star that is supposed to be occulted and a reference star used for comparison. We need the reference star to distinguish between a true occultation and artefacts introduced by poor atmospheric condition. Our Occultation Detection Neural Network (ODNet), can analyze three sequence of stars per second with 91\% of precision and 87\% of recall. The algorithm is sufficiently fast and robust so we can envision incorporating onboard the eVscopes to deliver real-time results. We conclude that citizen science represents an important opportunity for the future studies and discoveries in the occultations, and that application of artificial intelligence will permit us to to take better advantage of the ever-growing quantity of data to categorize asteroids.

</p>
</details>

<details><summary><b>Scalable Spectral Clustering with Group Fairness Constraints</b>
<a href="https://arxiv.org/abs/2210.16435">arxiv:2210.16435</a>
&#x1F4C8; 0 <br>
<p>Ji Wang, Ding Lu, Zhaojun Bai, Ian Davidson</p></summary>
<p>

**Abstract:** There are synergies of research interests and industrial efforts in modeling fairness and correcting algorithmic bias in machine learning. In this paper, we present a scalable algorithm for spectral clustering (SC) with group fairness constraints. Group fairness is also known as statistical parity where in each cluster, each protected group is represented with the same proportion as in the entirety. While FairSC algorithm (Kleindessner et al., 2019) is able to find the fairer clustering, it is compromised by high costs due to the kernels of computing nullspaces and the square roots of dense matrices explicitly. We present a new formulation of underlying spectral computation by incorporating nullspace projection and Hotelling's deflation such that the resulting algorithm, called s-FairSC, only involves the sparse matrix-vector products and is able to fully exploit the sparsity of the fair SC model. The experimental results on the modified stochastic block model demonstrate that s-FairSC is comparable with FairSC in recovering fair clustering. Meanwhile, it is sped up by a factor of 12 for moderate model sizes. s-FairSC is further demonstrated to be scalable in the sense that the computational costs of s-FairSC only increase marginally compared to the SC without fairness constraints.

</p>
</details>

<details><summary><b>Visually-Aware Audio Captioning With Adaptive Audio-Visual Attention</b>
<a href="https://arxiv.org/abs/2210.16428">arxiv:2210.16428</a>
&#x1F4C8; 0 <br>
<p>Xubo Liu, Qiushi Huang, Xinhao Mei, Haohe Liu, Qiuqiang Kong, Jianyuan Sun, Shengchen Li, Tom Ko, Yu Zhang, Lilian H. Tang, Mark D. Plumbley, Volkan Kƒ±lƒ±√ß, Wenwu Wang</p></summary>
<p>

**Abstract:** Audio captioning is the task of generating captions that describe the content of audio clips. In the real world, many objects produce similar sounds. It is difficult to identify these auditory ambiguous sound events with access to audio information only. How to accurately recognize ambiguous sounds is a major challenge for audio captioning systems. In this work, inspired by the audio-visual multi-modal perception of human beings, we propose visually-aware audio captioning, which makes use of visual information to help the recognition of ambiguous sounding objects. Specifically, we introduce an off-the-shelf visual encoder to process the video inputs, and incorporate the extracted visual features into an audio captioning system. Furthermore, to better exploit complementary contexts from redundant audio-visual streams, we propose an audio-visual attention mechanism that integrates audio and visual information adaptively according to their confidence levels. Experimental results on AudioCaps, the largest publicly available audio captioning dataset, show that the proposed method achieves significant improvement over a strong baseline audio captioning system and is on par with the state-of-the-art result.

</p>
</details>

<details><summary><b>System Demo: Tool and Infrastructure for Offensive Language Error Analysis (OLEA) in English</b>
<a href="https://arxiv.org/abs/2210.16398">arxiv:2210.16398</a>
&#x1F4C8; 0 <br>
<p>Marie Grace, Xajavion "Jay" Seabrum, Dananjay Srinivas, Alexis Palmer</p></summary>
<p>

**Abstract:** The automatic detection of offensive language is a pressing societal need. Many systems perform well on explicit offensive language but struggle to detect more complex, nuanced, or implicit cases of offensive and hateful language. OLEA is an open-source Python library that provides easy-to-use tools for error analysis in the context of detecting offensive language in English. OLEA also provides an infrastructure for re-distribution of new datasets and analysis methods requiring very little coding.

</p>
</details>

<details><summary><b>Continuous Attribution of Episodical Outcomes for More Efficient and Targeted Online Measurement</b>
<a href="https://arxiv.org/abs/2210.16373">arxiv:2210.16373</a>
&#x1F4C8; 0 <br>
<p>Alex Deng, Michelle Du, Anna Matlin</p></summary>
<p>

**Abstract:** Online experimentation platforms collect user feedback at low cost and large scale. Some systems even support real-time or near real-time data processing, and can update metrics and statistics continuously. Many commonly used metrics, such as clicks and page views, can be observed without much delay. However, many important signals can only be observed after several hours or days, with noise adding up over the duration of the episode. When episodical outcomes follow a complex sequence of user-product interactions, it is difficult to understand which interactions lead to the final outcome. There is no obvious attribution logic for us to associate a positive or negative outcome back to the actions and choices we made at different times. This attribution logic is critical to unlocking more targeted and efficient measurement at a finer granularity that could eventually lead to the full capability of reinforcement learning. In this paper, we borrow the idea of Causal Surrogacy to model a long-term outcome using leading indicators that are incrementally observed and apply it as the value function to track the progress towards the final outcome and attribute incrementally to various user-product interaction steps. Applying this approach to the guest booking metric at Airbnb resulted in significant variance reductions of 50% to 85%, while aligning well with the booking metric itself. Continuous attribution allows us to assign a utility score to each product page-view, and this score can be flexibly further aggregated to a variety of units of interest, such as searches and listings. We provide multiple real-world applications of attribution to illustrate its versatility.

</p>
</details>

<details><summary><b>Estimating oil recovery factor using machine learning: Applications of XGBoost classification</b>
<a href="https://arxiv.org/abs/2210.16345">arxiv:2210.16345</a>
&#x1F4C8; 0 <br>
<p>Alireza Roustazadeh, Behzad Ghanbarian, Frank Male, Mohammad B. Shadmand, Vahid Taslimitehrani, Larry W. Lake</p></summary>
<p>

**Abstract:** In petroleum engineering, it is essential to determine the ultimate recovery factor, RF, particularly before exploitation and exploration. However, accurately estimating requires data that is not necessarily available or measured at early stages of reservoir development. We, therefore, applied machine learning (ML), using readily available features, to estimate oil RF for ten classes defined in this study. To construct the ML models, we applied the XGBoost classification algorithm. Classification was chosen because recovery factor is bounded from 0 to 1, much like probability. Three databases were merged, leaving us with four different combinations to first train and test the ML models and then further evaluate them using an independent database including unseen data. The cross-validation method with ten folds was applied on the training datasets to assess the effectiveness of the models. To evaluate the accuracy and reliability of the models, the accuracy, neighborhood accuracy, and macro averaged f1 score were determined. Overall, results showed that the XGBoost classification algorithm could estimate the RF class with reasonable accuracies as high as 0.49 in the training datasets, 0.34 in the testing datasets and 0.2 in the independent databases used. We found that the reliability of the XGBoost model depended on the data in the training dataset meaning that the ML models were database dependent. The feature importance analysis and the SHAP approach showed that the most important features were reserves and reservoir area and thickness.

</p>
</details>

<details><summary><b>Filter and evolve: progressive pseudo label refining for semi-supervised automatic speech recognition</b>
<a href="https://arxiv.org/abs/2210.16318">arxiv:2210.16318</a>
&#x1F4C8; 0 <br>
<p>Zezhong Jin, Dading Zhong, Xiao Song, Zhaoyi Liu, Naipeng Ye, Qingcheng Zeng</p></summary>
<p>

**Abstract:** Fine tuning self supervised pretrained models using pseudo labels can effectively improve speech recognition performance. But, low quality pseudo labels can misguide decision boundaries and degrade performance. We propose a simple yet effective strategy to filter low quality pseudo labels to alleviate this problem. Specifically, pseudo-labels are produced over the entire training set and filtered via average probability scores calculated from the model output. Subsequently, an optimal percentage of utterances with high probability scores are considered reliable training data with trustworthy labels. The model is iteratively updated to correct the unreliable pseudo labels to minimize the effect of noisy labels. The process above is repeated until unreliable pseudo abels have been adequately corrected. Extensive experiments on LibriSpeech show that these filtered samples enable the refined model to yield more correct predictions, leading to better ASR performances under various experimental settings.

</p>
</details>

<details><summary><b>Beyond calibration: estimating the grouping loss of modern neural networks</b>
<a href="https://arxiv.org/abs/2210.16315">arxiv:2210.16315</a>
&#x1F4C8; 0 <br>
<p>Alexandre Perez-Lebel, Marine Le Morvan, Ga√´l Varoquaux</p></summary>
<p>

**Abstract:** Good decision making requires machine-learning models to provide trustworthy confidence scores. To this end, recent work has focused on miscalibration, i.e, the over or under confidence of model scores. Yet, contrary to widespread belief, calibration is not enough: even a classifier with the best possible accuracy and perfect calibration can have confidence scores far from the true posterior probabilities. This is due to the grouping loss, created by samples with the same confidence scores but different true posterior probabilities. Proper scoring rule theory shows that given the calibration loss, the missing piece to characterize individual errors is the grouping loss. While there are many estimators of the calibration loss, none exists for the grouping loss in standard settings. Here, we propose an estimator to approximate the grouping loss. We use it to study modern neural network architectures in vision and NLP. We find that the grouping loss varies markedly across architectures, and that it is a key model-comparison factor across the most accurate, calibrated, models. We also show that distribution shifts lead to high grouping loss.

</p>
</details>

<details><summary><b>cRedAnno+: Annotation Exploitation in Self-Explanatory Lung Nodule Diagnosis</b>
<a href="https://arxiv.org/abs/2210.16097">arxiv:2210.16097</a>
&#x1F4C8; 0 <br>
<p>Jiahao Lu, Chong Yin, Kenny Erleben, Michael Bachmann Nielsen, Sune Darkner</p></summary>
<p>

**Abstract:** Recently, attempts have been made to reduce annotation requirements in feature-based self-explanatory models for lung nodule diagnosis. As a representative, cRedAnno achieves competitive performance with considerably reduced annotation needs by introducing self-supervised contrastive learning to do unsupervised feature extraction. However, it exhibits unstable performance under scarce annotation conditions. To improve the accuracy and robustness of cRedAnno, we propose an annotation exploitation mechanism by conducting semi-supervised active learning in the learned semantically meaningful space to jointly utilise the extracted features, annotations, and unlabelled data. The proposed approach achieves comparable or even higher malignancy prediction accuracy with 10x fewer annotations, meanwhile showing better robustness and nodule attribute prediction accuracy. Our complete code is open-source available: https://github.com/diku-dk/credanno.

</p>
</details>


{% endraw %}
Prev: [2022.10.27]({{ '/2022/10/27/2022.10.27.html' | relative_url }})  Next: [2022.10.29]({{ '/2022/10/29/2022.10.29.html' | relative_url }})