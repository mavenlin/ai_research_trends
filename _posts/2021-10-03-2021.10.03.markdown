## Summary for 2021-10-03, created on 2021-12-16


<details><summary><b>Learn then Test: Calibrating Predictive Algorithms to Achieve Risk Control</b>
<a href="https://arxiv.org/abs/2110.01052">arxiv:2110.01052</a>
&#x1F4C8; 23 <br>
<p>Anastasios N. Angelopoulos, Stephen Bates, Emmanuel J. Candès, Michael I. Jordan, Lihua Lei</p></summary>
<p>

**Abstract:** We introduce Learn then Test, a framework for calibrating machine learning models so that their predictions satisfy explicit, finite-sample statistical guarantees regardless of the underlying model and (unknown) data-generating distribution. The framework addresses, among other examples, false discovery rate control in multi-label classification, intersection-over-union control in instance segmentation, and the simultaneous control of the type-1 error of outlier detection and confidence set coverage in classification or regression. To accomplish this, we solve a key technical challenge: the control of arbitrary risks that are not necessarily monotonic. Our main insight is to reframe the risk-control problem as multiple hypothesis testing, enabling techniques and mathematical arguments different from those in the previous literature. We use our framework to provide new calibration methods for several core machine learning tasks with detailed worked examples in computer vision.

</p>
</details>

<details><summary><b>Automatically Polyconvex Strain Energy Functions using Neural Ordinary Differential Equations</b>
<a href="https://arxiv.org/abs/2110.03774">arxiv:2110.03774</a>
&#x1F4C8; 6 <br>
<p>Vahidullah Tac, Francisco S. Costabal, Adrian Buganza Tepole</p></summary>
<p>

**Abstract:** Data-driven methods are becoming an essential part of computational mechanics due to their unique advantages over traditional material modeling. Deep neural networks are able to learn complex material response without the constraints of closed-form approximations. However, imposing the physics-based mathematical requirements that any material model must comply with is not straightforward for data-driven approaches. In this study, we use a novel class of neural networks, known as neural ordinary differential equations (N-ODEs), to develop data-driven material models that automatically satisfy polyconvexity of the strain energy function with respect to the deformation gradient, a condition needed for the existence of minimizers for boundary value problems in elasticity. We take advantage of the properties of ordinary differential equations to create monotonic functions that approximate the derivatives of the strain energy function with respect to the invariants of the right Cauchy-Green deformation tensor. The monotonicity of the derivatives guarantees the convexity of the energy. The N-ODE material model is able to capture synthetic data generated from closed-form material models, and it outperforms conventional models when tested against experimental data on skin, a highly nonlinear and anisotropic material. We also showcase the use of the N-ODE material model in finite element simulations. The framework is general and can be used to model a large class of materials. Here we focus on hyperelasticity, but polyconvex strain energies are a core building block for other problems in elasticity such as viscous and plastic deformations. We therefore expect our methodology to further enable data-driven methods in computational mechanics

</p>
</details>

<details><summary><b>Treeging</b>
<a href="https://arxiv.org/abs/2110.01053">arxiv:2110.01053</a>
&#x1F4C8; 5 <br>
<p>Gregory L. Watson, Michael Jerrett, Colleen E. Reid, Donatello Telesca</p></summary>
<p>

**Abstract:** Treeging combines the flexible mean structure of regression trees with the covariance-based prediction strategy of kriging into the base learner of an ensemble prediction algorithm. In so doing, it combines the strengths of the two primary types of spatial and space-time prediction models: (1) models with flexible mean structures (often machine learning algorithms) that assume independently distributed data, and (2) kriging or Gaussian Process (GP) prediction models with rich covariance structures but simple mean structures. We investigate the predictive accuracy of treeging across a thorough and widely varied battery of spatial and space-time simulation scenarios, comparing it to ordinary kriging, random forest and ensembles of ordinary kriging base learners. Treeging performs well across the board, whereas kriging suffers when dependence is weak or in the presence of spurious covariates, and random forest suffers when the covariates are less informative. Treeging also outperforms these competitors in predicting atmospheric pollutants (ozone and PM$_{2.5}$) in several case studies. We examine sensitivity to tuning parameters (number of base learners and training data sampling proportion), finding they follow the familiar intuition of their random forest counterparts. We include a discussion of scaleability, noting that any covariance approximation techniques that expedite kriging (GP) may be similarly applied to expedite treeging.

</p>
</details>

<details><summary><b>Marginally calibrated response distributions for end-to-end learning in autonomous driving</b>
<a href="https://arxiv.org/abs/2110.01050">arxiv:2110.01050</a>
&#x1F4C8; 5 <br>
<p>Clara Hoffmann, Nadja Klein</p></summary>
<p>

**Abstract:** End-to-end learners for autonomous driving are deep neural networks that predict the instantaneous steering angle directly from images of the ahead-lying street. These learners must provide reliable uncertainty estimates for their predictions in order to meet safety requirements and initiate a switch to manual control in areas of high uncertainty. Yet end-to-end learners typically only deliver point predictions, since distributional predictions are associated with large increases in training time or additional computational resources during prediction. To address this shortcoming we investigate efficient and scalable approximate inference for the implicit copula neural linear model of Klein, Nott and Smith (2021) in order to quantify uncertainty for the predictions of end-to-end learners. The result are densities for the steering angle that are marginally calibrated, i.e.~the average of the estimated densities equals the empirical distribution of steering angles. To ensure the scalability to large $n$ regimes, we develop efficient estimation based on variational inference as a fast alternative to computationally intensive, exact inference via Hamiltonian Monte Carlo. We demonstrate the accuracy and speed of the variational approach in comparison to Hamiltonian Monte Carlo on two end-to-end learners trained for highway driving using the comma2k19 data set. The implicit copula neural linear model delivers accurate calibration, high-quality prediction intervals and allows to identify overconfident learners. Our approach also contributes to the explainability of black-box end-to-end learners, since predictive densities can be used to understand which steering actions the end-to-end learner sees as valid.

</p>
</details>

<details><summary><b>Counterfactual Samples Synthesizing and Training for Robust Visual Question Answering</b>
<a href="https://arxiv.org/abs/2110.01013">arxiv:2110.01013</a>
&#x1F4C8; 5 <br>
<p>Long Chen, Yuhang Zheng, Yulei Niu, Hanwang Zhang, Jun Xiao</p></summary>
<p>

**Abstract:** Today's VQA models still tend to capture superficial linguistic correlations in the training set and fail to generalize to the test set with different QA distributions. To reduce these language biases, recent VQA works introduce an auxiliary question-only model to regularize the training of targeted VQA model, and achieve dominating performance on diagnostic benchmarks for out-of-distribution testing. However, due to complex model design, these ensemble-based methods are unable to equip themselves with two indispensable characteristics of an ideal VQA model: 1) Visual-explainable: The model should rely on the right visual regions when making decisions. 2) Question-sensitive: The model should be sensitive to the linguistic variations in questions. To this end, we propose a novel model-agnostic Counterfactual Samples Synthesizing and Training (CSST) strategy. After training with CSST, VQA models are forced to focus on all critical objects and words, which significantly improves both visual-explainable and question-sensitive abilities. Specifically, CSST is composed of two parts: Counterfactual Samples Synthesizing (CSS) and Counterfactual Samples Training (CST). CSS generates counterfactual samples by carefully masking critical objects in images or words in questions and assigning pseudo ground-truth answers. CST not only trains the VQA models with both complementary samples to predict respective ground-truth answers, but also urges the VQA models to further distinguish the original samples and superficially similar counterfactual ones. To facilitate the CST training, we propose two variants of supervised contrastive loss for VQA, and design an effective positive and negative sample selection mechanism based on CSS. Extensive experiments have shown the effectiveness of CSST. Particularly, by building on top of model LMH+SAR, we achieve record-breaking performance on all OOD benchmarks.

</p>
</details>

<details><summary><b>Beyond Topics: Discovering Latent Healthcare Objectives from Event Sequences</b>
<a href="https://arxiv.org/abs/2110.01160">arxiv:2110.01160</a>
&#x1F4C8; 4 <br>
<p>Adrian Caruana, Madhushi Bandara, Daniel Catchpoole, Paul J Kennedy</p></summary>
<p>

**Abstract:** A meaningful understanding of clinical protocols and patient pathways helps improve healthcare outcomes. Electronic health records (EHR) reflect real-world treatment behaviours that are used to enhance healthcare management but present challenges; protocols and pathways are often loosely defined and with elements frequently not recorded in EHRs, complicating the enhancement. To solve this challenge, healthcare objectives associated with healthcare management activities can be indirectly observed in EHRs as latent topics. Topic models, such as Latent Dirichlet Allocation (LDA), are used to identify latent patterns in EHR data. However, they do not examine the ordered nature of EHR sequences, nor do they appraise individual events in isolation. Our novel approach, the Categorical Sequence Encoder (CaSE) addresses these shortcomings. The sequential nature of EHRs is captured by CaSE's event-level representations, revealing latent healthcare objectives. In synthetic EHR sequences, CaSE outperforms LDA by up to 37% at identifying healthcare objectives. In the real-world MIMIC-III dataset, CaSE identifies meaningful representations that could critically enhance protocol and pathway development.

</p>
</details>

<details><summary><b>Spatio-Temporal Video Representation Learning for AI Based Video Playback Style Prediction</b>
<a href="https://arxiv.org/abs/2110.01015">arxiv:2110.01015</a>
&#x1F4C8; 4 <br>
<p>Rishubh Parihar, Gaurav Ramola, Ranajit Saha, Ravi Kini, Aniket Rege, Sudha Velusamy</p></summary>
<p>

**Abstract:** Ever-increasing smartphone-generated video content demands intelligent techniques to edit and enhance videos on power-constrained devices. Most of the best performing algorithms for video understanding tasks like action recognition, localization, etc., rely heavily on rich spatio-temporal representations to make accurate predictions. For effective learning of the spatio-temporal representation, it is crucial to understand the underlying object motion patterns present in the video. In this paper, we propose a novel approach for understanding object motions via motion type classification. The proposed motion type classifier predicts a motion type for the video based on the trajectories of the objects present. Our classifier assigns a motion type for the given video from the following five primitive motion classes: linear, projectile, oscillatory, local and random. We demonstrate that the representations learned from the motion type classification generalizes well for the challenging downstream task of video retrieval. Further, we proposed a recommendation system for video playback style based on the motion type classifier predictions.

</p>
</details>

<details><summary><b>Simple Recurrent Neural Networks is all we need for clinical events predictions using EHR data</b>
<a href="https://arxiv.org/abs/2110.00998">arxiv:2110.00998</a>
&#x1F4C8; 4 <br>
<p>Laila Rasmy, Jie Zhu, Zhiheng Li, Xin Hao, Hong Thoai Tran, Yujia Zhou, Firat Tiryaki, Yang Xiang, Hua Xu, Degui Zhi</p></summary>
<p>

**Abstract:** Recently, there is great interest to investigate the application of deep learning models for the prediction of clinical events using electronic health records (EHR) data. In EHR data, a patient's history is often represented as a sequence of visits, and each visit contains multiple events. As a result, deep learning models developed for sequence modeling, like recurrent neural networks (RNNs) are common architecture for EHR-based clinical events predictive models. While a large variety of RNN models were proposed in the literature, it is unclear if complex architecture innovations will offer superior predictive performance. In order to move this field forward, a rigorous evaluation of various methods is needed. In this study, we conducted a thorough benchmark of RNN architectures in modeling EHR data. We used two prediction tasks: the risk for developing heart failure and the risk of early readmission for inpatient hospitalization. We found that simple gated RNN models, including GRUs and LSTMs, often offer competitive results when properly tuned with Bayesian Optimization, which is in line with similar to findings in the natural language processing (NLP) domain. For reproducibility, Our codebase is shared at https://github.com/ZhiGroup/pytorch_ehr.

</p>
</details>

<details><summary><b>Precise Object Placement with Pose Distance Estimations for Different Objects and Grippers</b>
<a href="https://arxiv.org/abs/2110.00992">arxiv:2110.00992</a>
&#x1F4C8; 4 <br>
<p>Kilian Kleeberger, Jonathan Schnitzler, Muhammad Usman Khalid, Richard Bormann, Werner Kraus, Marco F. Huber</p></summary>
<p>

**Abstract:** This paper introduces a novel approach for the grasping and precise placement of various known rigid objects using multiple grippers within highly cluttered scenes. Using a single depth image of the scene, our method estimates multiple 6D object poses together with an object class, a pose distance for object pose estimation, and a pose distance from a target pose for object placement for each automatically obtained grasp pose with a single forward pass of a neural network. By incorporating model knowledge into the system, our approach has higher success rates for grasping than state-of-the-art model-free approaches. Furthermore, our method chooses grasps that result in significantly more precise object placements than prior model-based work.

</p>
</details>

<details><summary><b>Motif-based Graph Self-Supervised Learning for Molecular Property Prediction</b>
<a href="https://arxiv.org/abs/2110.00987">arxiv:2110.00987</a>
&#x1F4C8; 4 <br>
<p>Zaixi Zhang, Qi Liu, Hao Wang, Chengqiang Lu, Chee-Kong Lee</p></summary>
<p>

**Abstract:** Predicting molecular properties with data-driven methods has drawn much attention in recent years. Particularly, Graph Neural Networks (GNNs) have demonstrated remarkable success in various molecular generation and prediction tasks. In cases where labeled data is scarce, GNNs can be pre-trained on unlabeled molecular data to first learn the general semantic and structural information before being fine-tuned for specific tasks. However, most existing self-supervised pre-training frameworks for GNNs only focus on node-level or graph-level tasks. These approaches cannot capture the rich information in subgraphs or graph motifs. For example, functional groups (frequently-occurred subgraphs in molecular graphs) often carry indicative information about the molecular properties. To bridge this gap, we propose Motif-based Graph Self-supervised Learning (MGSSL) by introducing a novel self-supervised motif generation framework for GNNs. First, for motif extraction from molecular graphs, we design a molecule fragmentation method that leverages a retrosynthesis-based algorithm BRICS and additional rules for controlling the size of motif vocabulary. Second, we design a general motif-based generative pre-training framework in which GNNs are asked to make topological and label predictions. This generative framework can be implemented in two different ways, i.e., breadth-first or depth-first. Finally, to take the multi-scale information in molecular graphs into consideration, we introduce a multi-level self-supervised pre-training. Extensive experiments on various downstream benchmark tasks show that our methods outperform all state-of-the-art baselines.

</p>
</details>

<details><summary><b>An Unsupervised Video Game Playstyle Metric via State Discretization</b>
<a href="https://arxiv.org/abs/2110.00950">arxiv:2110.00950</a>
&#x1F4C8; 4 <br>
<p>Chiu-Chou Lin, Wei-Chen Chiu, I-Chen Wu</p></summary>
<p>

**Abstract:** On playing video games, different players usually have their own playstyles. Recently, there have been great improvements for the video game AIs on the playing strength. However, past researches for analyzing the behaviors of players still used heuristic rules or the behavior features with the game-environment support, thus being exhausted for the developers to define the features of discriminating various playstyles. In this paper, we propose the first metric for video game playstyles directly from the game observations and actions, without any prior specification on the playstyle in the target game. Our proposed method is built upon a novel scheme of learning discrete representations that can map game observations into latent discrete states, such that playstyles can be exhibited from these discrete states. Namely, we measure the playstyle distance based on game observations aligned to the same states. We demonstrate high playstyle accuracy of our metric in experiments on some video game platforms, including TORCS, RGSK, and seven Atari games, and for different agents including rule-based AI bots, learning-based AI bots, and human players.

</p>
</details>

<details><summary><b>Interactive Segmentation for COVID-19 Infection Quantification on Longitudinal CT scans</b>
<a href="https://arxiv.org/abs/2110.00948">arxiv:2110.00948</a>
&#x1F4C8; 4 <br>
<p>Michelle Xiao-Lin Foo, Seong Tae Kim, Magdalini Paschali, Leili Goli, Egon Burian, Marcus Makowski, Rickmer Braren, Nassir Navab, Thomas Wendler</p></summary>
<p>

**Abstract:** Consistent segmentation of COVID-19 patient's CT scans across multiple time points is essential to assess disease progression and response to therapy accurately. Existing automatic and interactive segmentation models for medical images only use data from a single time point (static). However, valuable segmentation information from previous time points is often not used to aid the segmentation of a patient's follow-up scans. Also, fully automatic segmentation techniques frequently produce results that would need further editing for clinical use. In this work, we propose a new single network model for interactive segmentation that fully utilizes all available past information to refine the segmentation of follow-up scans. In the first segmentation round, our model takes 3D volumes of medical images from two-time points (target and reference) as concatenated slices with the additional reference time point segmentation as a guide to segment the target scan. In subsequent segmentation refinement rounds, user feedback in the form of scribbles that correct the segmentation and the target's previous segmentation results are additionally fed into the model. This ensures that the segmentation information from previous refinement rounds is retained. Experimental results on our in-house multiclass longitudinal COVID-19 dataset show that the proposed model outperforms its static version and can assist in localizing COVID-19 infections in patient's follow-up scans.

</p>
</details>

<details><summary><b>Kalman Bayesian Neural Networks for Closed-form Online Learning</b>
<a href="https://arxiv.org/abs/2110.00944">arxiv:2110.00944</a>
&#x1F4C8; 4 <br>
<p>Philipp Wagner, Xinyang Wu, Marco F. Huber</p></summary>
<p>

**Abstract:** Compared to point estimates calculated by standard neural networks, Bayesian neural networks (BNN) provide probability distributions over the output predictions and model parameters, i.e., the weights. Training the weight distribution of a BNN, however, is more involved due to the intractability of the underlying Bayesian inference problem and thus, requires efficient approximations. In this paper, we propose a novel approach for BNN learning via closed-form Bayesian inference. For this purpose, the calculation of the predictive distribution of the output and the update of the weight distribution are treated as Bayesian filtering and smoothing problems, where the weights are modeled as Gaussian random variables. This allows closed-form expressions for training the network's parameters in a sequential/online fashion without gradient descent. We demonstrate our method on several UCI datasets and compare it to the state of the art.

</p>
</details>

<details><summary><b>Meta-Reinforcement Learning via Buffering Graph Signatures for Live Video Streaming Events</b>
<a href="https://arxiv.org/abs/2111.09412">arxiv:2111.09412</a>
&#x1F4C8; 3 <br>
<p>Stefanos Antaris, Dimitrios Rafailidis, Sarunas Girdzijauskas</p></summary>
<p>

**Abstract:** In this study, we present a meta-learning model to adapt the predictions of the network's capacity between viewers who participate in a live video streaming event. We propose the MELANIE model, where an event is formulated as a Markov Decision Process, performing meta-learning on reinforcement learning tasks. By considering a new event as a task, we design an actor-critic learning scheme to compute the optimal policy on estimating the viewers' high-bandwidth connections. To ensure fast adaptation to new connections or changes among viewers during an event, we implement a prioritized replay memory buffer based on the Kullback-Leibler divergence of the reward/throughput of the viewers' connections. Moreover, we adopt a model-agnostic meta-learning framework to generate a global model from past events. As viewers scarcely participate in several events, the challenge resides on how to account for the low structural similarity of different events. To combat this issue, we design a graph signature buffer to calculate the structural similarities of several streaming events and adjust the training of the global model accordingly. We evaluate the proposed model on the link weight prediction task on three real-world datasets of live video streaming events. Our experiments demonstrate the effectiveness of our proposed model, with an average relative gain of 25% against state-of-the-art strategies. For reproduction purposes, our evaluation datasets and implementation are publicly available at https://github.com/stefanosantaris/melanie

</p>
</details>

<details><summary><b>LawSum: A weakly supervised approach for Indian Legal Document Summarization</b>
<a href="https://arxiv.org/abs/2110.01188">arxiv:2110.01188</a>
&#x1F4C8; 3 <br>
<p>Vedant Parikh, Vidit Mathur, Parth Mehta, Namita Mittal, Prasenjit Majumder</p></summary>
<p>

**Abstract:** Unlike the courts in western countries, public records of Indian judiciary are completely unstructured and noisy. No large scale publicly available annotated datasets of Indian legal documents exist till date. This limits the scope for legal analytics research. In this work, we propose a new dataset consisting of over 10,000 judgements delivered by the supreme court of India and their corresponding hand written summaries. The proposed dataset is pre-processed by normalising common legal abbreviations, handling spelling variations in named entities, handling bad punctuations and accurate sentence tokenization. Each sentence is tagged with their rhetorical roles. We also annotate each judgement with several attributes like date, names of the plaintiffs, defendants and the people representing them, judges who delivered the judgement, acts/statutes that are cited and the most common citations used to refer the judgement. Further, we propose an automatic labelling technique for identifying sentences which have summary worthy information. We demonstrate that this auto labeled data can be used effectively to train a weakly supervised sentence extractor with high accuracy. Some possible applications of this dataset besides legal document summarization can be in retrieval, citation analysis and prediction of decisions by a particular judge.

</p>
</details>

<details><summary><b>The state-of-the-art in text-based automatic personality prediction</b>
<a href="https://arxiv.org/abs/2110.01186">arxiv:2110.01186</a>
&#x1F4C8; 3 <br>
<p>Ali-Reza Feizi-Derakhshi, Mohammad-Reza Feizi-Derakhshi, Majid Ramezani, Narjes Nikzad-Khasmakhi, Meysam Asgari-Chenaghlu, Taymaz Akan, Mehrdad Ranjbar-Khadivi, Elnaz Zafarni-Moattar, Zoleikha Jahanbakhsh-Naghadeh</p></summary>
<p>

**Abstract:** Personality detection is an old topic in psychology and Automatic Personality Prediction (or Perception) (APP) is the automated (computationally) forecasting of the personality on different types of human generated/exchanged contents (such as text, speech, image, video). The principal objective of this study is to offer a shallow (overall) review of natural language processing approaches on APP since 2010. With the advent of deep learning and following it transfer-learning and pre-trained model in NLP, APP research area has been a hot topic, so in this review, methods are categorized into three; pre-trained independent, pre-trained model based, multimodal approaches. Also, to achieve a comprehensive comparison, reported results are informed by datasets.

</p>
</details>

<details><summary><b>Adding Quaternion Representations to Attention Networks for Classification</b>
<a href="https://arxiv.org/abs/2110.01185">arxiv:2110.01185</a>
&#x1F4C8; 3 <br>
<p>Nazmul Shahadat, Anthony S. Maida</p></summary>
<p>

**Abstract:** This paper introduces a novel modification to axial-attention networks to improve their image classification accuracy. The modification involves supplementing axial-attention modules with quaternion input representations to improve image classification accuracy. We chose axial-attention networks because they factor 2D attention operations into two consecutive 1D operations (similar to separable convolution) and are thus less resource intensive than non-axial attention networks. We chose a quaternion encoder because of they share weights across four real-valued input channels and the weight-sharing has been shown to produce a more interlinked/interwoven output representation. We hypothesize that an attention module can be more effective using these interlinked representations as input. Our experiments support this hypothesis as reflected in the improved classification accuracy compared to standard axial-attention networks. We think this happens because the attention modules have better input representations to work with.

</p>
</details>

<details><summary><b>Decoupling Speaker-Independent Emotions for Voice Conversion Via Source-Filter Networks</b>
<a href="https://arxiv.org/abs/2110.01164">arxiv:2110.01164</a>
&#x1F4C8; 3 <br>
<p>Zhaojie Luo, Shoufeng Lin, Rui Liu, Jun Baba, Yuichiro Yoshikawa, Ishiguro Hiroshi</p></summary>
<p>

**Abstract:** Emotional voice conversion (VC) aims to convert a neutral voice to an emotional (e.g. happy) one while retaining the linguistic information and speaker identity. We note that the decoupling of emotional features from other speech information (such as speaker, content, etc.) is the key to achieving remarkable performance. Some recent attempts about speech representation decoupling on the neutral speech can not work well on the emotional speech, due to the more complex acoustic properties involved in the latter. To address this problem, here we propose a novel Source-Filter-based Emotional VC model (SFEVC) to achieve proper filtering of speaker-independent emotion features from both the timbre and pitch features. Our SFEVC model consists of multi-channel encoders, emotion separate encoders, and one decoder. Note that all encoder modules adopt a designed information bottlenecks auto-encoder. Additionally, to further improve the conversion quality for various emotions, a novel two-stage training strategy based on the 2D Valence-Arousal (VA) space was proposed. Experimental results show that the proposed SFEVC along with a two-stage training strategy outperforms all baselines and achieves the state-of-the-art performance in speaker-independent emotional VC with nonparallel data.

</p>
</details>

<details><summary><b>Active Learning for Contextual Search with Binary Feedbacks</b>
<a href="https://arxiv.org/abs/2110.01072">arxiv:2110.01072</a>
&#x1F4C8; 3 <br>
<p> Chen,  Xi,  Liu,  Quanquan,  Wang,  Yining</p></summary>
<p>

**Abstract:** In this paper, we study the learning problem in contextual search, which is motivated by applications such as first-price auction, personalized medicine experiments, and feature-based pricing experiments. In particular, for a sequence of arriving context vectors, with each context associated with an underlying value, the decision-maker either makes a query at a certain point or skips the context. The decision-maker will only observe the binary feedback on the relationship between the query point and the value associated with the context. We study a PAC learning setting, where the goal is to learn the underlying mean value function in context with a minimum number of queries. To address this challenge, we propose a tri-section search approach combined with a margin-based active learning method. We show that the algorithm only needs to make $O(1/\varepsilon^2)$ queries to achieve an $ε$-estimation accuracy. This sample complexity significantly reduces the required sample complexity in the passive setting, at least $Ω(1/\varepsilon^4)$.

</p>
</details>

<details><summary><b>RAP-Net: Region Attention Predictive Network for Precipitation Nowcasting</b>
<a href="https://arxiv.org/abs/2110.01035">arxiv:2110.01035</a>
&#x1F4C8; 3 <br>
<p>Chuyao Luo,  ZhengZhang, Rui Ye, Xutao Li, Yunming Ye</p></summary>
<p>

**Abstract:** Natural disasters caused by heavy rainfall often cost huge loss of life and property. To avoid it, the task of precipitation nowcasting is imminent. To solve the problem, increasingly deep learning methods are proposed to forecast future radar echo images and then the predicted maps have converted the distribution of rainfall. The prevailing spatiotemporal sequence prediction methods apply ConvRNN structure which combines the Convolution and Recurrent neural network. Although improvements based on ConvRNN achieve remarkable success, these methods ignore capturing both local and global spatial features simultaneously, which degrades the nowcasting in the region of heavy rainfall. To address this issue, we proposed the Region Attention Block (RAB) and embed it into ConvRNN to enhance the forecast in the area with strong rainfall. Besides, the ConvRNN models are hard to memory longer history representations with limited parameters. Considering it, we propose Recall Attention Mechanism (RAM) to improve the prediction. By preserving longer temporal information, RAM contributes to the forecasting, especially in the middle rainfall intensity. The experiments show that the proposed model Region Attention Predictive Network (RAP-Net) has outperformed the state-of-art method.

</p>
</details>

<details><summary><b>Adaptive Unfolding Total Variation Network for Low-Light Image Enhancement</b>
<a href="https://arxiv.org/abs/2110.00984">arxiv:2110.00984</a>
&#x1F4C8; 3 <br>
<p>Chuanjun Zheng, Daming Shi, Wentian Shi</p></summary>
<p>

**Abstract:** Real-world low-light images suffer from two main degradations, namely, inevitable noise and poor visibility. Since the noise exhibits different levels, its estimation has been implemented in recent works when enhancing low-light images from raw Bayer space. When it comes to sRGB color space, the noise estimation becomes more complicated due to the effect of the image processing pipeline. Nevertheless, most existing enhancing algorithms in sRGB space only focus on the low visibility problem or suppress the noise under a hypothetical noise level, leading them impractical due to the lack of robustness. To address this issue,we propose an adaptive unfolding total variation network (UTVNet), which approximates the noise level from the real sRGB low-light image by learning the balancing parameter in the model-based denoising method with total variation regularization. Meanwhile, we learn the noise level map by unrolling the corresponding minimization process for providing the inferences of smoothness and fidelity constraints. Guided by the noise level map, our UTVNet can recover finer details and is more capable to suppress noise in real captured low-light scenes. Extensive experiments on real-world low-light images clearly demonstrate the superior performance of UTVNet over state-of-the-art methods.

</p>
</details>

<details><summary><b>SecFL: Confidential Federated Learning using TEEs</b>
<a href="https://arxiv.org/abs/2110.00981">arxiv:2110.00981</a>
&#x1F4C8; 3 <br>
<p>Do Le Quoc, Christof Fetzer</p></summary>
<p>

**Abstract:** Federated Learning (FL) is an emerging machine learning paradigm that enables multiple clients to jointly train a model to take benefits from diverse datasets from the clients without sharing their local training datasets. FL helps reduce data privacy risks. Unfortunately, FL still exist several issues regarding privacy and security. First, it is possible to leak sensitive information from the shared training parameters. Second, malicious clients can collude with each other to steal data, models from regular clients or corrupt the global training model. To tackle these challenges, we propose SecFL - a confidential federated learning framework that leverages Trusted Execution Environments (TEEs). SecFL performs the global and local training inside TEE enclaves to ensure the confidentiality and integrity of the computations against powerful adversaries with privileged access. SecFL provides a transparent remote attestation mechanism, relying on the remote attestation provided by TEEs, to allow clients to attest the global training computation as well as the local training computation of each other. Thus, all malicious clients can be detected using the remote attestation mechanisms.

</p>
</details>

<details><summary><b>A Robust Scheme for 3D Point Cloud Copy Detection</b>
<a href="https://arxiv.org/abs/2110.00972">arxiv:2110.00972</a>
&#x1F4C8; 3 <br>
<p>Jiaqi Yang, Xuequan Lu, Wenzhi Chen</p></summary>
<p>

**Abstract:** Most existing 3D geometry copy detection research focused on 3D watermarking, which first embeds ``watermarks'' and then detects the added watermarks. However, this kind of methods is non-straightforward and may be less robust to attacks such as cropping and noise. In this paper, we focus on a fundamental and practical research problem: judging whether a point cloud is plagiarized or copied to another point cloud in the presence of several manipulations (e.g., similarity transformation, smoothing). We propose a novel method to address this critical problem. Our key idea is first to align the two point clouds and then calculate their similarity distance. We design three different measures to compute the similarity. We also introduce two strategies to speed up our method. Comprehensive experiments and comparisons demonstrate the effectiveness and robustness of our method in estimating the similarity of two given 3D point clouds.

</p>
</details>

<details><summary><b>Graph Representation Learning for Spatial Image Steganalysis</b>
<a href="https://arxiv.org/abs/2110.00957">arxiv:2110.00957</a>
&#x1F4C8; 3 <br>
<p>Qiyun Liu, Hanzhou Wu</p></summary>
<p>

**Abstract:** In this paper, we introduce a graph representation learning architecture for spatial image steganalysis, which is motivated by the assumption that steganographic modifications unavoidably distort the statistical characteristics of the hidden graph features derived from cover images. In the detailed architecture, we translate each image to a graph, where nodes represent the patches of the image and edges indicate the local associations between the patches. Each node is associated with a feature vector determined from the corresponding patch by a shallow convolutional neural network (CNN) structure. By feeding the graph to an attention network, the discriminative features can be learned for efficient steganalysis. Experiments indicate that the reported architecture achieves a competitive performance compared to the benchmark CNN model, which has shown the potential of graph learning for steganalysis.

</p>
</details>

<details><summary><b>Accurate Cup-to-Disc Ratio Measurement with Tight Bounding Box Supervision in Fundus Photography</b>
<a href="https://arxiv.org/abs/2110.00943">arxiv:2110.00943</a>
&#x1F4C8; 3 <br>
<p>Juan Wang, Bin Xia</p></summary>
<p>

**Abstract:** The cup-to-disc ratio (CDR) is one of the most significant indicator for glaucoma diagnosis. Different from the use of costly fully supervised learning formulation with pixel-wise annotations in the literature, this study investigates the feasibility of accurate CDR measurement in fundus images using only tight bounding box supervision. For this purpose, we develop a two-task network for accurate CDR measurement, one for weakly supervised image segmentation, and the other for bounding-box regression. The weakly supervised image segmentation task is implemented based on generalized multiple instance learning formulation and smooth maximum approximation, and the bounding-box regression task outputs class-specific bounding box prediction in a single scale at the original image resolution. To get accurate bounding box prediction, a class-specific bounding-box normalizer and an expected intersection-over-union are proposed. In the experiments, the proposed approach was evaluated by a testing set with 1200 images using CDR error and F1 score for CDR measurement and dice coefficient for image segmentation. A grader study was conducted to compare the performance of the proposed approach with those of individual graders. The results demonstrate that the proposed approach outperforms the state-of-the-art performance obtained from the fully supervised image segmentation (FSIS) approach using pixel-wise annotation for CDR measurement, which is also better than those of individual graders. It also gets performance close to the state-of-the-art obtained from FSIS for optic cup and disc segmentation, similar to those of individual graders. The codes are available at \url{https://github.com/wangjuan313/CDRNet}.

</p>
</details>

<details><summary><b>Artificial Intelligence For Breast Cancer Detection: Trends & Directions</b>
<a href="https://arxiv.org/abs/2110.00942">arxiv:2110.00942</a>
&#x1F4C8; 3 <br>
<p>Shahid Munir Shah, Rizwan Ahmed Khan, Sheeraz Arif, Unaiza Sajid</p></summary>
<p>

**Abstract:** In the last decade, researchers working in the domain of computer vision and Artificial Intelligence (AI) have beefed up their efforts to come up with the automated framework that not only detects but also identifies stage of breast cancer. The reason for this surge in research activities in this direction are mainly due to advent of robust AI algorithms (deep learning), availability of hardware that can train those robust and complex AI algorithms and accessibility of large enough dataset required for training AI algorithms. Different imaging modalities that have been exploited by researchers to automate the task of breast cancer detection are mammograms, ultrasound, magnetic resonance imaging, histopathological images or any combination of them. This article analyzes these imaging modalities and presents their strengths, limitations and enlists resources from where their datasets can be accessed for research purpose. This article then summarizes AI and computer vision based state-of-the-art methods proposed in the last decade, to detect breast cancer using various imaging modalities. Generally, in this article we have focused on to review frameworks that have reported results using mammograms as it is most widely used breast imaging modality that serves as first test that medical practitioners usually prescribe for the detection of breast cancer. Second reason of focusing on mammogram imaging modalities is the availability of its labeled datasets. Datasets availability is one of the most important aspect for the development of AI based frameworks as such algorithms are data hungry and generally quality of dataset affects performance of AI based algorithms. In a nutshell, this research article will act as a primary resource for the research community working in the field of automated breast imaging analysis.

</p>
</details>

<details><summary><b>Bounding Box Tightness Prior for Weakly Supervised Image Segmentation</b>
<a href="https://arxiv.org/abs/2110.00934">arxiv:2110.00934</a>
&#x1F4C8; 3 <br>
<p>Juan Wang, Bin Xia</p></summary>
<p>

**Abstract:** This paper presents a weakly supervised image segmentation method that adopts tight bounding box annotations. It proposes generalized multiple instance learning (MIL) and smooth maximum approximation to integrate the bounding box tightness prior into the deep neural network in an end-to-end manner. In generalized MIL, positive bags are defined by parallel crossing lines with a set of different angles, and negative bags are defined as individual pixels outside of any bounding boxes. Two variants of smooth maximum approximation, i.e., $α$-softmax function and $α$-quasimax function, are exploited to conquer the numeral instability introduced by maximum function of bag prediction. The proposed approach was evaluated on two pubic medical datasets using Dice coefficient. The results demonstrate that it outperforms the state-of-the-art methods. The codes are available at \url{https://github.com/wangjuan313/wsis-boundingbox}.

</p>
</details>

<details><summary><b>Meta-learning an Intermediate Representation for Few-shot Block-wise Prediction of Landslide Susceptibility</b>
<a href="https://arxiv.org/abs/2110.04922">arxiv:2110.04922</a>
&#x1F4C8; 2 <br>
<p>Li Chen, Yulin Ding, Han Hu, Qing Zhu, Haowei Zeng, Haojia Yu, Qisen Shang, Yongfei Song</p></summary>
<p>

**Abstract:** Predicting a landslide susceptibility map (LSM) is essential for risk recognition and disaster prevention. Despite the successful application of data-driven prediction approaches, current data-driven methods generally apply a single global model to predict the LSM for an entire target region. However, we argue that, in complex circumstances, especially in large-scale areas, each part of the region holds different landslide-inducing environments, and therefore, should be predicted individually with respective models. In this study, target scenarios were segmented into blocks for individual analysis using topographical factors. But simply conducting training and testing using limited samples within each block is hardly possible for a satisfactory LSM prediction, due to the adverse effect of \textit{overfitting}. To solve the problems, we train an intermediate representation by the meta-learning paradigm, which is superior for capturing information from LSM tasks in order to generalize proficiently. We chose this based on the hypothesis that there are more general concepts among LSM tasks that are sensitive to variations in input features. Thus, using the intermediate representation, we can easily adapt the model for different blocks or even unseen tasks using few exemplar samples. Experimental results on two study areas demonstrated the validity of our block-wise analysis in large scenarios and revealed the top few-shot adaption performances of the proposed methods.

</p>
</details>

<details><summary><b>Deep Kernel Representation for Image Reconstruction in PET</b>
<a href="https://arxiv.org/abs/2110.01174">arxiv:2110.01174</a>
&#x1F4C8; 2 <br>
<p>Siqi Li, Guobao Wang</p></summary>
<p>

**Abstract:** Image reconstruction for positron emission tomography (PET) is challenging because of the ill-conditioned tomographic problem and low counting statistics. Kernel methods address this challenge by using kernel representation to incorporate image prior information in the forward model of iterative PET image reconstruction. Existing kernel methods construct the kernels commonly using an empirical process, which may lead to suboptimal performance. In this paper, we describe the equivalence between the kernel representation and a trainable neural network model. A deep kernel method is proposed by exploiting deep neural networks to enable an automated learning of an optimized kernel model. The proposed method is directly applicable to single subjects. The training process utilizes available image prior data to seek the best way to form a set of robust kernels optimally rather than empirically. The results from computer simulations and a real patient dataset demonstrate that the proposed deep kernel method can outperform existing kernel method and neural network method for dynamic PET image reconstruction.

</p>
</details>

<details><summary><b>Trustworthy AI: From Principles to Practices</b>
<a href="https://arxiv.org/abs/2110.01167">arxiv:2110.01167</a>
&#x1F4C8; 2 <br>
<p>Bo Li, Peng Qi, Bo Liu, Shuai Di, Jingen Liu, Jiquan Pei, Jinfeng Yi, Bowen Zhou</p></summary>
<p>

**Abstract:** Fast developing artificial intelligence (AI) technology has enabled various applied systems deployed in the real world, impacting people's everyday lives. However, many current AI systems were found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection, etc., which not only degrades user experience but erodes the society's trust in all AI systems. In this review, we strive to provide AI practitioners a comprehensive guide towards building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, alignment with human values, and accountability. We then survey leading approaches in these aspects in the industry. To unify the current fragmented approaches towards trustworthy AI, we propose a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items to practitioners and societal stakeholders (e.g., researchers and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges in the future development of trustworthy AI systems, where we identify the need for paradigm shift towards comprehensive trustworthy AI systems.

</p>
</details>

<details><summary><b>DESTRESS: Computation-Optimal and Communication-Efficient Decentralized Nonconvex Finite-Sum Optimization</b>
<a href="https://arxiv.org/abs/2110.01165">arxiv:2110.01165</a>
&#x1F4C8; 2 <br>
<p>Boyue Li, Zhize Li, Yuejie Chi</p></summary>
<p>

**Abstract:** Emerging applications in multi-agent environments such as internet-of-things, networked sensing, autonomous systems and federated learning, call for decentralized algorithms for finite-sum optimizations that are resource-efficient in terms of both computation and communication. In this paper, we consider the prototypical setting where the agents work collaboratively to minimize the sum of local loss functions by only communicating with their neighbors over a predetermined network topology. We develop a new algorithm, called DEcentralized STochastic REcurSive gradient methodS (DESTRESS) for nonconvex finite-sum optimization, which matches the optimal incremental first-order oracle (IFO) complexity of centralized algorithms for finding first-order stationary points, while maintaining communication efficiency. Detailed theoretical and numerical comparisons corroborate that the resource efficiencies of DESTRESS improve upon prior decentralized algorithms over a wide range of parameter regimes. DESTRESS leverages several key algorithm design ideas including randomly activated stochastic recursive gradient updates with mini-batches for local computation, gradient tracking with extra mixing (i.e., multiple gossiping rounds) for per-iteration communication, together with careful choices of hyper-parameters and new analysis frameworks to provably achieve a desirable computation-communication trade-off.

</p>
</details>

<details><summary><b>Spiked Covariance Estimation from Modulo-Reduced Measurements</b>
<a href="https://arxiv.org/abs/2110.01150">arxiv:2110.01150</a>
&#x1F4C8; 2 <br>
<p>Elad Romanov, Or Ordentlich</p></summary>
<p>

**Abstract:** Consider the rank-1 spiked model: $\bf{X}=\sqrtνξ\bf{u}+ \bf{Z}$, where $ν$ is the spike intensity, $\bf{u}\in\mathbb{S}^{k-1}$ is an unknown direction and $ξ\sim \mathcal{N}(0,1),\bf{Z}\sim \mathcal{N}(\bf{0},\bf{I})$. Motivated by recent advances in analog-to-digital conversion, we study the problem of recovering $\bf{u}\in \mathbb{S}^{k-1}$ from $n$ i.i.d. modulo-reduced measurements $\bf{Y}=[\bf{X}]\mod Δ$, focusing on the high-dimensional regime ($k\gg 1$). We develop and analyze an algorithm that, for most directions $\bf{u}$ and $ν=\mathrm{poly}(k)$, estimates $\bf{u}$ to high accuracy using $n=\mathrm{poly}(k)$ measurements, provided that $Δ\gtrsim \sqrt{\log k}$. Up to constants, our algorithm accurately estimates $\bf{u}$ at the smallest possible $Δ$ that allows (in an information-theoretic sense) to recover $\bf{X}$ from $\bf{Y}$. A key step in our analysis involves estimating the probability that a line segment of length $\approx\sqrtν$ in a random direction $\bf{u}$ passes near a point in the lattice $Δ\mathbb{Z}^k$. Numerical experiments show that the developed algorithm performs well even in a non-asymptotic setting.

</p>
</details>

<details><summary><b>Human-Centered AI for Data Science: A Systematic Approach</b>
<a href="https://arxiv.org/abs/2110.01108">arxiv:2110.01108</a>
&#x1F4C8; 2 <br>
<p>Dakuo Wang, Xiaojuan Ma, April Yi Wang</p></summary>
<p>

**Abstract:** Human-Centered AI (HCAI) refers to the research effort that aims to design and implement AI techniques to support various human tasks, while taking human needs into consideration and preserving human control. In this short position paper, we illustrate how we approach HCAI using a series of research projects around Data Science (DS) works as a case study. The AI techniques built for supporting DS works are collectively referred to as AutoML systems, and their goals are to automate some parts of the DS workflow. We illustrate a three-step systematical research approach(i.e., explore, build, and integrate) and four practical ways of implementation for HCAI systems. We argue that our work is a cornerstone towards the ultimate future of Human-AI Collaboration for DS and beyond, where AI and humans can take complementary and indispensable roles to achieve a better outcome and experience.

</p>
</details>

<details><summary><b>A New Approach for Image Authentication Framework for Media Forensics Purpose</b>
<a href="https://arxiv.org/abs/2110.01065">arxiv:2110.01065</a>
&#x1F4C8; 2 <br>
<p>Ahmad M Nagm, Khaled Y Youssef, Mohammad I Youssef</p></summary>
<p>

**Abstract:** With the increasing widely spread digital media become using in most fields such as medical care, Oceanography, Exploration processing, security purpose, military fields and astronomy, evidence in criminals and more vital fields and then digital Images become have different appreciation values according to what is important of carried information by digital images. Due to the easy manipulation property of digital images (by proper computer software) makes us doubtful when are juries using digital images as forensic evidence in courts, especially, if the digital images are main evidence to demonstrate the relationship between suspects and the criminals. Obviously, here demonstrate importance of data Originality Protection methods to detect unauthorized process like modification or duplication and then enhancement protection of evidence to guarantee rights of incriminatory. In this paper, we shall introduce a novel digital forensic security framework for digital image authentication and originality identification techniques and related methodologies, algorithms and protocols that are applied on camera captured images. The approach depends on implanting secret code into RGB images that should indicate any unauthorized modification on the image under investigation. The secret code generation depends mainly on two main parameter types, namely the image characteristics and capturing device identifier. In this paper, the architecture framework will be analyzed, explained and discussed together with the associated protocols, algorithms and methodologies. Also, the secret code deduction and insertion techniques will be analyzed and discussed, in addition to the image benchmarking and quality testing techniques.

</p>
</details>

<details><summary><b>EAR-U-Net: EfficientNet and attention-based residual U-Net for automatic liver segmentation in CT</b>
<a href="https://arxiv.org/abs/2110.01014">arxiv:2110.01014</a>
&#x1F4C8; 2 <br>
<p>Jinke Wang, Xiangyang Zhang, Peiqing Lv, Lubiao Zhou, Haiying Wang</p></summary>
<p>

**Abstract:** Purpose: This paper proposes a new network framework called EAR-U-Net, which leverages EfficientNetB4, attention gate, and residual learning techniques to achieve automatic and accurate liver segmentation. Methods: The proposed method is based on the U-Net framework. First, we use EfficientNetB4 as the encoder to extract more feature information during the encoding stage. Then, an attention gate is introduced in the skip connection to eliminate irrelevant regions and highlight features of a specific segmentation task. Finally, to alleviate the problem of gradient vanishment, we replace the traditional convolution of the decoder with a residual block to improve the segmentation accuracy. Results: We verified the proposed method on the LiTS17 and SLiver07 datasets and compared it with classical networks such as FCN, U-Net, Attention U-Net, and Attention Res-U-Net. In the Sliver07 evaluation, the proposed method achieved the best segmentation performance on all five standard metrics. Meanwhile, in the LiTS17 assessment, the best performance is obtained except for a slight inferior on RVD. Moreover, we also participated in the MICCIA-LiTS17 challenge, and the Dice per case score was 0.952. Conclusion: The proposed method's qualitative and quantitative results demonstrated its applicability in liver segmentation and proved its good prospect in computer-assisted liver segmentation.

</p>
</details>

<details><summary><b>Boost Neural Networks by Checkpoints</b>
<a href="https://arxiv.org/abs/2110.00959">arxiv:2110.00959</a>
&#x1F4C8; 2 <br>
<p>Feng Wang, Guoyizhe Wei, Qiao Liu, Jinxiang Ou, Xian Wei, Hairong Lv</p></summary>
<p>

**Abstract:** Training multiple deep neural networks (DNNs) and averaging their outputs is a simple way to improve the predictive performance. Nevertheless, the multiplied training cost prevents this ensemble method to be practical and efficient. Several recent works attempt to save and ensemble the checkpoints of DNNs, which only requires the same computational cost as training a single network. However, these methods suffer from either marginal accuracy improvements due to the low diversity of checkpoints or high risk of divergence due to the cyclical learning rates they adopted. In this paper, we propose a novel method to ensemble the checkpoints, where a boosting scheme is utilized to accelerate model convergence and maximize the checkpoint diversity. We theoretically prove that it converges by reducing exponential loss. The empirical evaluation also indicates our proposed ensemble outperforms single model and existing ensembles in terms of accuracy and efficiency. With the same training budget, our method achieves 4.16% lower error on Cifar-100 and 6.96% on Tiny-ImageNet with ResNet-110 architecture. Moreover, the adaptive sample weights in our method make it an effective solution to address the imbalanced class distribution. In the experiments, it yields up to 5.02% higher accuracy over single EfficientNet-B0 on the imbalanced datasets.

</p>
</details>

<details><summary><b>Information Elicitation Meets Clustering</b>
<a href="https://arxiv.org/abs/2110.00952">arxiv:2110.00952</a>
&#x1F4C8; 2 <br>
<p>Yuqing Kong</p></summary>
<p>

**Abstract:** In the setting where we want to aggregate people's subjective evaluations, plurality vote may be meaningless when a large amount of low-effort people always report "good" regardless of the true quality. "Surprisingly popular" method, picking the most surprising answer compared to the prior, handle this issue to some extent. However, it is still not fully robust to people's strategies. Here in the setting where a large number of people are asked to answer a small number of multi-choice questions (multi-task, large group), we propose an information aggregation method that is robust to people's strategies. Interestingly, this method can be seen as a rotated "surprisingly popular". It is based on a new clustering method, Determinant MaxImization (DMI)-clustering, and a key conceptual idea that information elicitation without ground-truth can be seen as a clustering problem. Of independent interest, DMI-clustering is a general clustering method that aims to maximize the volume of the simplex consisting of each cluster's mean multiplying the product of the cluster sizes. We show that DMI-clustering is invariant to any non-degenerate affine transformation for all data points. When the data point's dimension is a constant, DMI-clustering can be solved in polynomial time. In general, we present a simple heuristic for DMI-clustering which is very similar to Lloyd's algorithm for k-means. Additionally, we also apply the clustering idea in the single-task setting and use the spectral method to propose a new aggregation method that utilizes the second-moment information elicited from the crowds.

</p>
</details>

<details><summary><b>PL-EESR: Perceptual Loss Based END-TO-END Robust Speaker Representation Extraction</b>
<a href="https://arxiv.org/abs/2110.00940">arxiv:2110.00940</a>
&#x1F4C8; 2 <br>
<p>Yi Ma, Kong Aik Lee, Ville Hautamaki, Haizhou Li</p></summary>
<p>

**Abstract:** Speech enhancement aims to improve the perceptual quality of the speech signal by suppression of the background noise. However, excessive suppression may lead to speech distortion and speaker information loss, which degrades the performance of speaker embedding extraction. To alleviate this problem, we propose an end-to-end deep learning framework, dubbed PL-EESR, for robust speaker representation extraction. This framework is optimized based on the feedback of the speaker identification task and the high-level perceptual deviation between the raw speech signal and its noisy version. We conducted speaker verification tasks in both noisy and clean environment respectively to evaluate our system. Compared to the baseline, our method shows better performance in both clean and noisy environments, which means our method can not only enhance the speaker relative information but also avoid adding distortions.

</p>
</details>

<details><summary><b>RC-Struct: A Structure-based Neural Network Approach for MIMO-OFDM Detection</b>
<a href="https://arxiv.org/abs/2110.02219">arxiv:2110.02219</a>
&#x1F4C8; 1 <br>
<p>Jiarui Xu, Zhou Zhou, Lianjun Li, Lizhong Zheng, Lingjia Liu</p></summary>
<p>

**Abstract:** In this paper, we introduce a structure-based neural network architecture, namely RC-Struct, for MIMO-OFDM symbol detection. The RC-Struct exploits the temporal structure of the MIMO-OFDM signals through reservoir computing (RC). A binary classifier leverages the repetitive constellation structure in the system to perform multi-class detection. The incorporation of RC allows the RC-Struct to be learned in a purely online fashion with extremely limited pilot symbols in each OFDM subframe. The binary classifier enables the efficient utilization of the precious online training symbols and allows an easy extension to high-order modulations without a substantial increase in complexity. Experiments show that the introduced RC-Struct outperforms both the conventional model-based symbol detection approaches and the state-of-the-art learning-based strategies in terms of bit error rate (BER). The advantages of RC-Struct over existing methods become more significant when rank and link adaptation are adopted. The introduced RC-Struct sheds light on combining communication domain knowledge and learning-based receive processing for 5G and 5G Beyond.

</p>
</details>

<details><summary><b>Neural Implicit Surfaces for Efficient and Accurate Collisions in Physically Based Simulations</b>
<a href="https://arxiv.org/abs/2110.01614">arxiv:2110.01614</a>
&#x1F4C8; 1 <br>
<p>Hugo Bertiche, Meysam Madadi, Sergio Escalera</p></summary>
<p>

**Abstract:** Current trends in the computer graphics community propose leveraging the massive parallel computational power of GPUs to accelerate physically based simulations. Collision detection and solving is a fundamental part of this process. It is also the most significant bottleneck on physically based simulations and it easily becomes intractable as the number of vertices in the scene increases. Brute force approaches carry a quadratic growth in both computational time and memory footprint. While their parallelization is trivial in GPUs, their complexity discourages from using such approaches. Acceleration structures -- such as BVH -- are often applied to increase performance, achieving logarithmic computational times for individual point queries. Nonetheless, their memory footprint also grows rapidly and their parallelization in a GPU is problematic due to their branching nature. We propose using implicit surface representations learnt through deep learning for collision handling in physically based simulations. Our proposed architecture has a complexity of O(n) -- or O(1) for a single point query -- and has no parallelization issues. We will show how this permits accurate and efficient collision handling in physically based simulations, more specifically, for cloth. In our experiments, we query up to 1M points in 300 milliseconds.

</p>
</details>

<details><summary><b>Safe Control with Neural Network Dynamic Models</b>
<a href="https://arxiv.org/abs/2110.01110">arxiv:2110.01110</a>
&#x1F4C8; 1 <br>
<p>Tianhao Wei, Changliu Liu</p></summary>
<p>

**Abstract:** Safety is critical in autonomous robotic systems. A safe control law ensures forward invariance of a safe set (a subset in the state space). It has been extensively studied regarding how to derive a safe control law with a control-affine analytical dynamic model. However, in complex environments and tasks, it is challenging and time-consuming to obtain a principled analytical model of the system. In these situations, data-driven learning is extensively used and the learned models are encoded in neural networks. How to formally derive a safe control law with Neural Network Dynamic Models (NNDM) remains unclear due to the lack of computationally tractable methods to deal with these black-box functions. In fact, even finding the control that minimizes an objective for NNDM without any safety constraint is still challenging. In this work, we propose MIND-SIS (Mixed Integer for Neural network Dynamic model with Safety Index Synthesis), the first method to derive safe control laws for NNDM. The method includes two parts: 1) SIS: an algorithm for the offline synthesis of the safety index (also called as barrier function), which uses evolutionary methods and 2) MIND: an algorithm for online computation of the optimal and safe control signal, which solves a constrained optimization using a computationally efficient encoding of neural networks. It has been theoretically proved that MIND-SIS guarantees forward invariance and finite convergence. And it has been numerically validated that MIND-SIS achieves safe and optimal control of NNDM. From our experiments, the optimality gap is less than $10^{-8}$, and the safety constraint violation is $0$.

</p>
</details>

<details><summary><b>Dr.Aid: Supporting Data-governance Rule Compliance for Decentralized Collaboration in an Automated Way</b>
<a href="https://arxiv.org/abs/2110.01056">arxiv:2110.01056</a>
&#x1F4C8; 1 <br>
<p>Rui Zhao, Malcolm Atkinson, Petros Papapanagiotou, Federica Magnoni, Jacques Fleuriot</p></summary>
<p>

**Abstract:** Collaboration across institutional boundaries is widespread and increasing today. It depends on federations sharing data that often have governance rules or external regulations restricting their use. However, the handling of data governance rules (aka. data-use policies) remains manual, time-consuming and error-prone, limiting the rate at which collaborations can form and respond to challenges and opportunities, inhibiting citizen science and reducing data providers' trust in compliance. Using an automated system to facilitate compliance handling reduces substantially the time needed for such non-mission work, thereby accelerating collaboration and improving productivity. We present a framework, Dr.Aid, that helps individuals, organisations and federations comply with data rules, using automation to track which rules are applicable as data is passed between processes and as derived data is generated. It encodes data-governance rules using a formal language and performs reasoning on multi-input-multi-output data-flow graphs in decentralised contexts. We test its power and utility by working with users performing cyclone tracking and earthquake modelling to support mitigation and emergency response. We query standard provenance traces to detach Dr.Aid from details of the tools and systems they are using, as these inevitably vary across members of a federation and through time. We evaluate the model in three aspects by encoding real-life data-use policies from diverse fields, showing its capability for real-world usage and its advantages compared with traditional frameworks. We argue that this approach will lead to more agile, more productive and more trustworthy collaborations and show that the approach can be adopted incrementally. This, in-turn, will allow more appropriate data policies to emerge opening up new forms of collaboration.

</p>
</details>

<details><summary><b>Exploration of AI-Oriented Power System Transient Stability Simulations</b>
<a href="https://arxiv.org/abs/2110.00931">arxiv:2110.00931</a>
&#x1F4C8; 1 <br>
<p>Tannan Xiao, Ying Chen, Jianquan Wang, Shaowei Huang, Weilin Tong, Tirui He</p></summary>
<p>

**Abstract:** Artificial Intelligence (AI) has made significant progress in the past 5 years and is playing a more and more important role in power system analysis and control. It is foreseeable that the future power system transient stability simulations will be deeply integrated with AI. However, the existing power system dynamic simulation tools are not AI-friendly enough. In this paper, a general design of an AI-oriented power system transient stability simulator is proposed. It is a parallel simulator with a flexible application programming interface so that the simulator has rapid simulation speed, neural network supportability, and network topology accessibility. A prototype of this design is implemented and made public based on our previously realized simulator. Tests of this AI-oriented simulator are carried out under multiple scenarios, which proves that the design and implementation of the simulator are reasonable, AI-friendly, and highly efficient.

</p>
</details>

<details><summary><b>Deep Neural Matching Models for Graph Retrieval</b>
<a href="https://arxiv.org/abs/2110.00925">arxiv:2110.00925</a>
&#x1F4C8; 1 <br>
<p>Chitrank Gupta, Yash Jain</p></summary>
<p>

**Abstract:** Graph Retrieval has witnessed continued interest and progress in the past few years. In thisreport, we focus on neural network based approaches for Graph matching and retrieving similargraphs from a corpus of graphs. We explore methods which can soft predict the similaritybetween two graphs. Later, we gauge the power of a particular baseline (Shortest Path Kernel)and try to model it in our product graph random walks setting while making it more generalised.

</p>
</details>

<details><summary><b>SDR: Efficient Neural Re-ranking using Succinct Document Representation</b>
<a href="https://arxiv.org/abs/2110.02065">arxiv:2110.02065</a>
&#x1F4C8; 0 <br>
<p>Nachshon Cohen, Amit Portnoy, Besnik Fetahu, Amir Ingber</p></summary>
<p>

**Abstract:** BERT based ranking models have achieved superior performance on various information retrieval tasks. However, the large number of parameters and complex self-attention operation come at a significant latency overhead. To remedy this, recent works propose late-interaction architectures, which allow pre-computation of intermediate document representations, thus reducing the runtime latency. Nonetheless, having solved the immediate latency issue, these methods now introduce storage costs and network fetching latency, which limits their adoption in real-life production systems.
  In this work, we propose the Succinct Document Representation (SDR) scheme that computes highly compressed intermediate document representations, mitigating the storage/network issue. Our approach first reduces the dimension of token representations by encoding them using a novel autoencoder architecture that uses the document's textual content in both the encoding and decoding phases. After this token encoding step, we further reduce the size of entire document representations using a modern quantization technique.
  Extensive evaluations on passage re-reranking on the MSMARCO dataset show that compared to existing approaches using compressed document representations, our method is highly efficient, achieving 4x-11.6x better compression rates for the same ranking quality.

</p>
</details>

<details><summary><b>Differential Privacy of Dirichlet Posterior Sampling</b>
<a href="https://arxiv.org/abs/2110.01984">arxiv:2110.01984</a>
&#x1F4C8; 0 <br>
<p>Donlapark Ponnoprat</p></summary>
<p>

**Abstract:** Besides the Laplace distribution and the Gaussian distribution, there are many more probability distributions which is not well-understood in terms of privacy-preserving property of a random draw -- one of which is the Dirichlet distribution. In this work, we study the inherent privacy of releasing a single draw from a Dirichlet posterior distribution. As a complement to the previous study that provides general theories on the differential privacy of posterior sampling from exponential families, this study focuses specifically on the Dirichlet posterior sampling and its privacy guarantees. With the notion of truncated concentrated differential privacy (tCDP), we are able to derive a simple privacy guarantee of the Dirichlet posterior sampling, which effectively allows us to analyze its utility in various settings. Specifically, we prove accuracy guarantees of private Multinomial-Dirichlet sampling, which is prevalent in Bayesian tasks, and private release of a normalized histogram. In addition, with our results, it is possible to make Bayesian reinforcement learning differentially private by modifying the Dirichlet sampling for state transition probabilities.

</p>
</details>


[Next Page]({{ '/2021/10/02/2021.10.02.html' | relative_url }})
