## Summary for 2021-11-17, created on 2021-12-17


<details><summary><b>Acquisition of Chess Knowledge in AlphaZero</b>
<a href="https://arxiv.org/abs/2111.09259">arxiv:2111.09259</a>
&#x1F4C8; 865 <br>
<p>Thomas McGrath, Andrei Kapishnikov, Nenad Tomašev, Adam Pearce, Demis Hassabis, Been Kim, Ulrich Paquet, Vladimir Kramnik</p></summary>
<p>

**Abstract:** What is learned by sophisticated neural network agents such as AlphaZero? This question is of both scientific and practical interest. If the representations of strong neural networks bear no resemblance to human concepts, our ability to understand faithful explanations of their decisions will be restricted, ultimately limiting what we can achieve with neural network interpretability. In this work we provide evidence that human knowledge is acquired by the AlphaZero neural network as it trains on the game of chess. By probing for a broad range of human chess concepts we show when and where these concepts are represented in the AlphaZero network. We also provide a behavioural analysis focusing on opening play, including qualitative analysis from chess Grandmaster Vladimir Kramnik. Finally, we carry out a preliminary investigation looking at the low-level details of AlphaZero's representations, and make the resulting behavioural and representational analyses available online.

</p>
</details>

<details><summary><b>GFlowNet Foundations</b>
<a href="https://arxiv.org/abs/2111.09266">arxiv:2111.09266</a>
&#x1F4C8; 368 <br>
<p>Yoshua Bengio, Tristan Deleu, Edward J. Hu, Salem Lahlou, Mo Tiwari, Emmanuel Bengio</p></summary>
<p>

**Abstract:** Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets. They can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entropy and mutual information, sampling from a Pareto frontier, connections to reward-maximizing policies, and extensions to stochastic environments, continuous actions and modular energy functions.

</p>
</details>

<details><summary><b>Compositional Transformers for Scene Generation</b>
<a href="https://arxiv.org/abs/2111.08960">arxiv:2111.08960</a>
&#x1F4C8; 238 <br>
<p>Drew A. Hudson, C. Lawrence Zitnick</p></summary>
<p>

**Abstract:** We introduce the GANformer2 model, an iterative object-oriented transformer, explored for the task of generative modeling. The network incorporates strong and explicit structural priors, to reflect the compositional nature of visual scenes, and synthesizes images through a sequential process. It operates in two stages: a fast and lightweight planning phase, where we draft a high-level scene layout, followed by an attention-based execution phase, where the layout is being refined, evolving into a rich and detailed picture. Our model moves away from conventional black-box GAN architectures that feature a flat and monolithic latent space towards a transparent design that encourages efficiency, controllability and interpretability. We demonstrate GANformer2's strengths and qualities through a careful evaluation over a range of datasets, from multi-object CLEVR scenes to the challenging COCO images, showing it successfully achieves state-of-the-art performance in terms of visual quality, diversity and consistency. Further experiments demonstrate the model's disentanglement and provide a deeper insight into its generative process, as it proceeds step-by-step from a rough initial sketch, to a detailed layout that accounts for objects' depths and dependencies, and up to the final high-resolution depiction of vibrant and intricate real-world scenes. See https://github.com/dorarad/gansformer for model implementation.

</p>
</details>

<details><summary><b>The People's Speech: A Large-Scale Diverse English Speech Recognition Dataset for Commercial Usage</b>
<a href="https://arxiv.org/abs/2111.09344">arxiv:2111.09344</a>
&#x1F4C8; 91 <br>
<p>Daniel Galvez, Greg Diamos, Juan Ciro, Juan Felipe Cerón, Keith Achorn, Anjali Gopi, David Kanter, Maximilian Lam, Mark Mazumder, Vijay Janapa Reddi</p></summary>
<p>

**Abstract:** The People's Speech is a free-to-download 30,000-hour and growing supervised conversational English speech recognition dataset licensed for academic and commercial usage under CC-BY-SA (with a CC-BY subset). The data is collected via searching the Internet for appropriately licensed audio data with existing transcriptions. We describe our data collection methodology and release our data collection system under the Apache 2.0 license. We show that a model trained on this dataset achieves a 9.98% word error rate on Librispeech's test-clean test set.Finally, we discuss the legal and ethical issues surrounding the creation of a sizable machine learning corpora and plans for continued maintenance of the project under MLCommons's sponsorship.

</p>
</details>

<details><summary><b>It's About Time: Analog Clock Reading in the Wild</b>
<a href="https://arxiv.org/abs/2111.09162">arxiv:2111.09162</a>
&#x1F4C8; 89 <br>
<p>Charig Yang, Weidi Xie, Andrew Zisserman</p></summary>
<p>

**Abstract:** In this paper, we present a framework for reading analog clocks in natural images or videos. Specifically, we make the following contributions: First, we create a scalable pipeline for generating synthetic clocks, significantly reducing the requirements for the labour-intensive annotations; Second, we introduce a clock recognition architecture based on spatial transformer networks (STN), which is trained end-to-end for clock alignment and recognition. We show that the model trained on the proposed synthetic dataset generalises towards real clocks with good accuracy, advocating a Sim2Real training regime; Third, to further reduce the gap between simulation and real data, we leverage the special property of time, i.e. uniformity, to generate reliable pseudo-labels on real unlabelled clock videos, and show that training on these videos offers further improvements while still requiring zero manual annotations. Lastly, we introduce three benchmark datasets based on COCO, Open Images, and The Clock movie, totalling 4,472 images with clocks, with full annotations for time, accurate to the minute.

</p>
</details>

<details><summary><b>Learning to Compose Visual Relations</b>
<a href="https://arxiv.org/abs/2111.09297">arxiv:2111.09297</a>
&#x1F4C8; 60 <br>
<p>Nan Liu, Shuang Li, Yilun Du, Joshua B. Tenenbaum, Antonio Torralba</p></summary>
<p>

**Abstract:** The visual world around us can be described as a structured set of objects and their associated relations. An image of a room may be conjured given only the description of the underlying objects and their associated relations. While there has been significant work on designing deep neural networks which may compose individual objects together, less work has been done on composing the individual relations between objects. A principal difficulty is that while the placement of objects is mutually independent, their relations are entangled and dependent on each other. To circumvent this issue, existing works primarily compose relations by utilizing a holistic encoder, in the form of text or graphs. In this work, we instead propose to represent each relation as an unnormalized density (an energy-based model), enabling us to compose separate relations in a factorized manner. We show that such a factorized decomposition allows the model to both generate and edit scenes that have multiple sets of relations more faithfully. We further show that decomposition enables our model to effectively understand the underlying relational scene structure. Project page at: https://composevisualrelations.github.io/.

</p>
</details>

<details><summary><b>Sustainable Artificial Intelligence through Continual Learning</b>
<a href="https://arxiv.org/abs/2111.09437">arxiv:2111.09437</a>
&#x1F4C8; 48 <br>
<p>Andrea Cossu, Marta Ziosi, Vincenzo Lomonaco</p></summary>
<p>

**Abstract:** The increasing attention on Artificial Intelligence (AI) regulation has led to the definition of a set of ethical principles grouped into the Sustainable AI framework. In this article, we identify Continual Learning, an active area of AI research, as a promising approach towards the design of systems compliant with the Sustainable AI principles. While Sustainable AI outlines general desiderata for ethical applications, Continual Learning provides means to put such desiderata into practice.

</p>
</details>

<details><summary><b>Lidar with Velocity: Motion Distortion Correction of Point Clouds from Oscillating Scanning Lidars</b>
<a href="https://arxiv.org/abs/2111.09497">arxiv:2111.09497</a>
&#x1F4C8; 40 <br>
<p>Wen Yang, Zheng Gong, Baifu Huang, Xiaoping Hong</p></summary>
<p>

**Abstract:** Lidar point cloud distortion from moving object is an important problem in autonomous driving, and recently becomes even more demanding with the emerging of newer lidars, which feature back-and-forth scanning patterns. Accurately estimating moving object velocity would not only provide a tracking capability but also correct the point cloud distortion with more accurate description of the moving object. Since lidar measures the time-of-flight distance but with a sparse angular resolution, the measurement is precise in the radial measurement but lacks angularly. Camera on the other hand provides a dense angular resolution. In this paper, Gaussian-based lidar and camera fusion is proposed to estimate the full velocity and correct the lidar distortion. A probabilistic Kalman-filter framework is provided to track the moving objects, estimate their velocities and simultaneously correct the point clouds distortions. The framework is evaluated on real road data and the fusion method outperforms the traditional ICP-based and point-cloud only method. The complete working framework is open-sourced (https://github.com/ISEE-Technology/lidar-with-velocity) to accelerate the adoption of the emerging lidars.

</p>
</details>

<details><summary><b>Fast Rates for Nonparametric Online Learning: From Realizability to Learning in Games</b>
<a href="https://arxiv.org/abs/2111.08911">arxiv:2111.08911</a>
&#x1F4C8; 32 <br>
<p>Constantinos Daskalakis, Noah Golowich</p></summary>
<p>

**Abstract:** We study fast rates of convergence in the setting of nonparametric online regression, namely where regret is defined with respect to an arbitrary function class which has bounded complexity. Our contributions are two-fold:
  - In the realizable setting of nonparametric online regression with the absolute loss, we propose a randomized proper learning algorithm which gets a near-optimal mistake bound in terms of the sequential fat-shattering dimension of the hypothesis class. In the setting of online classification with a class of Littlestone dimension $d$, our bound reduces to $d \cdot {\rm poly} \log T$. This result answers a question as to whether proper learners could achieve near-optimal mistake bounds; previously, even for online classification, the best known mistake bound was $\tilde O( \sqrt{dT})$. Further, for the real-valued (regression) setting, the optimal mistake bound was not even known for improper learners, prior to this work.
  - Using the above result, we exhibit an independent learning algorithm for general-sum binary games of Littlestone dimension $d$, for which each player achieves regret $\tilde O(d^{3/4} \cdot T^{1/4})$. This result generalizes analogous results of Syrgkanis et al. (2015) who showed that in finite games the optimal regret can be accelerated from $O(\sqrt{T})$ in the adversarial setting to $O(T^{1/4})$ in the game setting.
  To establish the above results, we introduce several new techniques, including: a hierarchical aggregation rule to achieve the optimal mistake bound for real-valued classes, a multi-scale extension of the proper online realizable learner of Hanneke et al. (2021), an approach to show that the output of such nonparametric learning algorithms is stable, and a proof that the minimax theorem holds in all online learnable games.

</p>
</details>

<details><summary><b>Minimum Bayes Risk Decoding with Neural Metrics of Translation Quality</b>
<a href="https://arxiv.org/abs/2111.09388">arxiv:2111.09388</a>
&#x1F4C8; 22 <br>
<p>Markus Freitag, David Grangier, Qijun Tan, Bowen Liang</p></summary>
<p>

**Abstract:** This work applies Minimum Bayes Risk (MBR) decoding to optimize diverse automated metrics of translation quality. Automatic metrics in machine translation have made tremendous progress recently. In particular, neural metrics, fine-tuned on human ratings (e.g. BLEURT, or COMET) are outperforming surface metrics in terms of correlations to human judgements. Our experiments show that the combination of a neural translation model with a neural reference-based metric, BLEURT, results in significant improvement in automatic and human evaluations. This improvement is obtained with translations different from classical beam-search output: these translations have much lower likelihood and are less favored by surface metrics like BLEU.

</p>
</details>

<details><summary><b>MEDCOD: A Medically-Accurate, Emotive, Diverse, and Controllable Dialog System</b>
<a href="https://arxiv.org/abs/2111.09381">arxiv:2111.09381</a>
&#x1F4C8; 20 <br>
<p>Rhys Compton, Ilya Valmianski, Li Deng, Costa Huang, Namit Katariya, Xavier Amatriain, Anitha Kannan</p></summary>
<p>

**Abstract:** We present MEDCOD, a Medically-Accurate, Emotive, Diverse, and Controllable Dialog system with a unique approach to the natural language generator module. MEDCOD has been developed and evaluated specifically for the history taking task. It integrates the advantage of a traditional modular approach to incorporate (medical) domain knowledge with modern deep learning techniques to generate flexible, human-like natural language expressions. Two key aspects of MEDCOD's natural language output are described in detail. First, the generated sentences are emotive and empathetic, similar to how a doctor would communicate to the patient. Second, the generated sentence structures and phrasings are varied and diverse while maintaining medical consistency with the desired medical concept (provided by the dialogue manager module of MEDCOD). Experimental results demonstrate the effectiveness of our approach in creating a human-like medical dialogue system. Relevant code is available at https://github.com/curai/curai-research/tree/main/MEDCOD

</p>
</details>

<details><summary><b>Rapping-Singing Voice Synthesis based on Phoneme-level Prosody Control</b>
<a href="https://arxiv.org/abs/2111.09146">arxiv:2111.09146</a>
&#x1F4C8; 20 <br>
<p>Konstantinos Markopoulos, Nikolaos Ellinas, Alexandra Vioni, Myrsini Christidou, Panos Kakoulidis, Georgios Vamvoukakis, Georgia Maniati, June Sig Sung, Hyoungmin Park, Pirros Tsiakoulis, Aimilios Chalamandaris</p></summary>
<p>

**Abstract:** In this paper, a text-to-rapping/singing system is introduced, which can be adapted to any speaker's voice. It utilizes a Tacotron-based multispeaker acoustic model trained on read-only speech data and which provides prosody control at the phoneme level. Dataset augmentation and additional prosody manipulation based on traditional DSP algorithms are also investigated. The neural TTS model is fine-tuned to an unseen speaker's limited recordings, allowing rapping/singing synthesis with the target's speaker voice. The detailed pipeline of the system is described, which includes the extraction of the target pitch and duration values from an a capella song and their conversion into target speaker's valid range of notes before synthesis. An additional stage of prosodic manipulation of the output via WSOLA is also investigated for better matching the target duration values. The synthesized utterances can be mixed with an instrumental accompaniment track to produce a complete song. The proposed system is evaluated via subjective listening tests as well as in comparison to an available alternate system which also aims to produce synthetic singing voice from read-only training data. Results show that the proposed approach can produce high quality rapping/singing voice with increased naturalness.

</p>
</details>

<details><summary><b>Preference Communication in Multi-Objective Normal-Form Games</b>
<a href="https://arxiv.org/abs/2111.09191">arxiv:2111.09191</a>
&#x1F4C8; 10 <br>
<p>Willem Röpke, Diederik M. Roijers, Ann Nowé, Roxana Rădulescu</p></summary>
<p>

**Abstract:** We study the problem of multiple agents learning concurrently in a multi-objective environment. Specifically, we consider two agents that repeatedly play a multi-objective normal-form game. In such games, the payoffs resulting from joint actions are vector valued. Taking a utility-based approach, we assume a utility function exists that maps vectors to scalar utilities and consider agents that aim to maximise the utility of expected payoff vectors. As agents do not necessarily know their opponent's utility function or strategy, they must learn optimal policies to interact with each other. To aid agents in arriving at adequate solutions, we introduce four novel preference communication protocols for both cooperative as well as self-interested communication. Each approach describes a specific protocol for one agent communicating preferences over their actions and how another agent responds. These protocols are subsequently evaluated on a set of five benchmark games against baseline agents that do not communicate. We find that preference communication can drastically alter the learning process and lead to the emergence of cyclic Nash equilibria which had not been previously observed in this setting. Additionally, we introduce a communication scheme where agents must learn when to communicate. For agents in games with Nash equilibria, we find that communication can be beneficial but difficult to learn when agents have different preferred equilibria. When this is not the case, agents become indifferent to communication. In games without Nash equilibria, our results show differences across learning rates. When using faster learners, we observe that explicit communication becomes more prevalent at around 50% of the time, as it helps them in learning a compromise joint policy. Slower learners retain this pattern to a lesser degree, but show increased indifference.

</p>
</details>

<details><summary><b>Cryo-shift: Reducing domain shift in cryo-electron subtomograms with unsupervised domain adaptation and randomization</b>
<a href="https://arxiv.org/abs/2111.09114">arxiv:2111.09114</a>
&#x1F4C8; 10 <br>
<p>Hmrishav Bandyopadhyay, Zihao Deng, Leiting Ding, Sinuo Liu, Mostofa Rafid Uddin, Xiangrui Zeng, Sima Behpour, Min Xu</p></summary>
<p>

**Abstract:** Cryo-Electron Tomography (cryo-ET) is a 3D imaging technology that enables the visualization of subcellular structures in situ at near-atomic resolution. Cellular cryo-ET images help in resolving the structures of macromolecules and determining their spatial relationship in a single cell, which has broad significance in cell and structural biology. Subtomogram classification and recognition constitute a primary step in the systematic recovery of these macromolecular structures. Supervised deep learning methods have been proven to be highly accurate and efficient for subtomogram classification, but suffer from limited applicability due to scarcity of annotated data. While generating simulated data for training supervised models is a potential solution, a sizeable difference in the image intensity distribution in generated data as compared to real experimental data will cause the trained models to perform poorly in predicting classes on real subtomograms. In this work, we present Cryo-Shift, a fully unsupervised domain adaptation and randomization framework for deep learning-based cross-domain subtomogram classification. We use unsupervised multi-adversarial domain adaption to reduce the domain shift between features of simulated and experimental data. We develop a network-driven domain randomization procedure with `warp' modules to alter the simulated data and help the classifier generalize better on experimental data. We do not use any labeled experimental data to train our model, whereas some of the existing alternative approaches require labeled experimental samples for cross-domain classification. Nevertheless, Cryo-Shift outperforms the existing alternative approaches in cross-domain subtomogram classification in extensive evaluation studies demonstrated herein using both simulated and experimental data.

</p>
</details>

<details><summary><b>Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI</b>
<a href="https://arxiv.org/abs/2111.09212">arxiv:2111.09212</a>
&#x1F4C8; 8 <br>
<p>Zhishen Huang, Saiprasad Ravishankar</p></summary>
<p>

**Abstract:** There is much recent interest in techniques to accelerate the data acquisition process in MRI by acquiring limited measurements. Often sophisticated reconstruction algorithms are deployed to maintain high image quality in such settings. In this work, we propose a data-driven sampler using a convolutional neural network, MNet, to provide object-specific sampling patterns adaptive to each scanned object. The network observes very limited low-frequency k-space data for each object and rapidly predicts the desired undersampling pattern in one go that achieves high image reconstruction quality.
  We propose an accompanying alternating-type training framework with a mask-backward procedure that efficiently generates training labels for the sampler network and jointly trains an image reconstruction network. Experimental results on the fastMRI knee dataset demonstrate the ability of the proposed learned undersampling network to generate object-specific masks at fourfold and eightfold acceleration that achieve superior image reconstruction performance than several existing schemes. The source code for the proposed joint sampling and reconstruction learning framework is available at https://github.com/zhishenhuang/mri.

</p>
</details>

<details><summary><b>End-to-end optimized image compression with competition of prior distributions</b>
<a href="https://arxiv.org/abs/2111.09172">arxiv:2111.09172</a>
&#x1F4C8; 8 <br>
<p>Benoit Brummer, Christophe De Vleeschouwer</p></summary>
<p>

**Abstract:** Convolutional autoencoders are now at the forefront of image compression research. To improve their entropy coding, encoder output is typically analyzed with a second autoencoder to generate per-variable parametrized prior probability distributions. We instead propose a compression scheme that uses a single convolutional autoencoder and multiple learned prior distributions working as a competition of experts. Trained prior distributions are stored in a static table of cumulative distribution functions. During inference, this table is used by an entropy coder as a look-up-table to determine the best prior for each spatial location. Our method offers rate-distortion performance comparable to that obtained with a predicted parametrized prior with only a fraction of its entropy coding and decoding complexity.

</p>
</details>

<details><summary><b>Docking-based Virtual Screening with Multi-Task Learning</b>
<a href="https://arxiv.org/abs/2111.09502">arxiv:2111.09502</a>
&#x1F4C8; 7 <br>
<p>Zijing Liu, Xianbin Ye, Xiaomin Fang, Fan Wang, Hua Wu, Haifeng Wang</p></summary>
<p>

**Abstract:** Machine learning shows great potential in virtual screening for drug discovery. Current efforts on accelerating docking-based virtual screening do not consider using existing data of other previously developed targets. To make use of the knowledge of the other targets and take advantage of the existing data, in this work, we apply multi-task learning to the problem of docking-based virtual screening. With two large docking datasets, the results of extensive experiments show that multi-task learning can achieve better performances on docking score prediction. By learning knowledge across multiple targets, the model trained by multi-task learning shows a better ability to adapt to a new target. Additional empirical study shows that other problems in drug discovery, such as the experimental drug-target affinity prediction, may also benefit from multi-task learning. Our results demonstrate that multi-task learning is a promising machine learning approach for docking-based virtual screening and accelerating the process of drug discovery.

</p>
</details>

<details><summary><b>Dynamically pruning segformer for efficient semantic segmentation</b>
<a href="https://arxiv.org/abs/2111.09499">arxiv:2111.09499</a>
&#x1F4C8; 7 <br>
<p>Haoli Bai, Hongda Mao, Dinesh Nair</p></summary>
<p>

**Abstract:** As one of the successful Transformer-based models in computer vision tasks, SegFormer demonstrates superior performance in semantic segmentation. Nevertheless, the high computational cost greatly challenges the deployment of SegFormer on edge devices. In this paper, we seek to design a lightweight SegFormer for efficient semantic segmentation. Based on the observation that neurons in SegFormer layers exhibit large variances across different images, we propose a dynamic gated linear layer, which prunes the most uninformative set of neurons based on the input instance. To improve the dynamically pruned SegFormer, we also introduce two-stage knowledge distillation to transfer the knowledge within the original teacher to the pruned student network. Experimental results show that our method can significantly reduce the computation overhead of SegFormer without an apparent performance drop. For instance, we can achieve 36.9% mIoU with only 3.3G FLOPs on ADE20K, saving more than 60% computation with the drop of only 0.5% in mIoU

</p>
</details>

<details><summary><b>Personalized Federated Learning through Local Memorization</b>
<a href="https://arxiv.org/abs/2111.09360">arxiv:2111.09360</a>
&#x1F4C8; 7 <br>
<p>Othmane Marfoq, Giovanni Neglia, Laetitia Kameni, Richard Vidal</p></summary>
<p>

**Abstract:** Federated learning allows clients to collaboratively learn statistical models while keeping their data local. Federated learning was originally used to train a unique global model to be served to all clients, but this approach might be sub-optimal when clients' local data distributions are heterogeneous. In order to tackle this limitation, recent personalized federated learning methods train a separate model for each client while still leveraging the knowledge available at other clients. In this work, we exploit the ability of deep neural networks to extract high quality vectorial representations (embeddings) from non-tabular data, e.g., images and text, to propose a personalization mechanism based on local memorization. Personalization is obtained interpolating a pre-trained global model with a $k$-nearest neighbors (kNN) model based on the shared representation provided by the global model. We provide generalization bounds for the proposed approach and we show on a suite of federated datasets that this approach achieves significantly higher accuracy and fairness than state-of-the-art methods.

</p>
</details>

<details><summary><b>Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection</b>
<a href="https://arxiv.org/abs/2111.09099">arxiv:2111.09099</a>
&#x1F4C8; 7 <br>
<p>Nicolae-Catalin Ristea, Neelu Madan, Radu Tudor Ionescu, Kamal Nasrollahi, Fahad Shahbaz Khan, Thomas B. Moeslund, Mubarak Shah</p></summary>
<p>

**Abstract:** Anomaly detection is commonly pursued as a one-class classification problem, where models can only learn from normal training samples, while being evaluated on both normal and abnormal test samples. Among the successful approaches for anomaly detection, a distinguished category of methods relies on predicting masked information (e.g. patches, future frames, etc.) and leveraging the reconstruction error with respect to the masked information as an abnormality score. Different from related methods, we propose to integrate the reconstruction-based functionality into a novel self-supervised predictive architectural building block. The proposed self-supervised block is generic and can easily be incorporated into various state-of-the-art anomaly detection methods. Our block starts with a convolutional layer with dilated filters, where the center area of the receptive field is masked. The resulting activation maps are passed through a channel attention module. Our block is equipped with a loss that minimizes the reconstruction error with respect to the masked area in the receptive field. We demonstrate the generality of our block by integrating it into several state-of-the-art frameworks for anomaly detection on image and video, providing empirical evidence that shows considerable performance improvements on MVTec AD, Avenue, and ShanghaiTech.

</p>
</details>

<details><summary><b>High Quality Streaming Speech Synthesis with Low, Sentence-Length-Independent Latency</b>
<a href="https://arxiv.org/abs/2111.09052">arxiv:2111.09052</a>
&#x1F4C8; 7 <br>
<p>Nikolaos Ellinas, Georgios Vamvoukakis, Konstantinos Markopoulos, Aimilios Chalamandaris, Georgia Maniati, Panos Kakoulidis, Spyros Raptis, June Sig Sung, Hyoungmin Park, Pirros Tsiakoulis</p></summary>
<p>

**Abstract:** This paper presents an end-to-end text-to-speech system with low latency on a CPU, suitable for real-time applications. The system is composed of an autoregressive attention-based sequence-to-sequence acoustic model and the LPCNet vocoder for waveform generation. An acoustic model architecture that adopts modules from both the Tacotron 1 and 2 models is proposed, while stability is ensured by using a recently proposed purely location-based attention mechanism, suitable for arbitrary sentence length generation. During inference, the decoder is unrolled and acoustic feature generation is performed in a streaming manner, allowing for a nearly constant latency which is independent from the sentence length. Experimental results show that the acoustic model can produce feature sequences with minimal latency about 31 times faster than real-time on a computer CPU and 6.5 times on a mobile CPU, enabling it to meet the conditions required for real-time applications on both devices. The full end-to-end system can generate almost natural quality speech, which is verified by listening tests.

</p>
</details>

<details><summary><b>Transparent Human Evaluation for Image Captioning</b>
<a href="https://arxiv.org/abs/2111.08940">arxiv:2111.08940</a>
&#x1F4C8; 7 <br>
<p>Jungo Kasai, Keisuke Sakaguchi, Lavinia Dunagan, Jacob Morrison, Ronan Le Bras, Yejin Choi, Noah A. Smith</p></summary>
<p>

**Abstract:** We establish a rubric-based human evaluation protocol for image captioning models. Our scoring rubrics and their definitions are carefully developed based on machine- and human-generated captions on the MSCOCO dataset. Each caption is evaluated along two main dimensions in a tradeoff (precision and recall) as well as other aspects that measure the text quality (fluency, conciseness, and inclusive language). Our evaluations demonstrate several critical problems of the current evaluation practice. Human-generated captions show substantially higher quality than machine-generated ones, especially in coverage of salient information (i.e., recall), while all automatic metrics say the opposite. Our rubric-based results reveal that CLIPScore, a recent metric that uses image features, better correlates with human judgments than conventional text-only metrics because it is more sensitive to recall. We hope that this work will promote a more transparent evaluation protocol for image captioning and its automatic metrics.

</p>
</details>

<details><summary><b>Aggressive Q-Learning with Ensembles: Achieving Both High Sample Efficiency and High Asymptotic Performance</b>
<a href="https://arxiv.org/abs/2111.09159">arxiv:2111.09159</a>
&#x1F4C8; 6 <br>
<p>Yanqiu Wu, Xinyue Chen, Che Wang, Yiming Zhang, Zijian Zhou, Keith W. Ross</p></summary>
<p>

**Abstract:** Recently, Truncated Quantile Critics (TQC), using distributional representation of critics, was shown to provide state-of-the-art asymptotic training performance on all environments from the MuJoCo continuous control benchmark suite. Also recently, Randomized Ensemble Double Q-Learning (REDQ), using a high update-to-data ratio and target randomization, was shown to achieve high sample efficiency that is competitive with state-of-the-art model-based methods. In this paper, we propose a novel model-free algorithm, Aggressive Q-Learning with Ensembles (AQE), which improves the sample-efficiency performance of REDQ and the asymptotic performance of TQC, thereby providing overall state-of-the-art performance during all stages of training. Moreover, AQE is very simple, requiring neither distributional representation of critics nor target randomization.

</p>
</details>

<details><summary><b>Cross-lingual Low Resource Speaker Adaptation Using Phonological Features</b>
<a href="https://arxiv.org/abs/2111.09075">arxiv:2111.09075</a>
&#x1F4C8; 6 <br>
<p>Georgia Maniati, Nikolaos Ellinas, Konstantinos Markopoulos, Georgios Vamvoukakis, June Sig Sung, Hyoungmin Park, Aimilios Chalamandaris, Pirros Tsiakoulis</p></summary>
<p>

**Abstract:** The idea of using phonological features instead of phonemes as input to sequence-to-sequence TTS has been recently proposed for zero-shot multilingual speech synthesis. This approach is useful for code-switching, as it facilitates the seamless uttering of foreign text embedded in a stream of native text. In our work, we train a language-agnostic multispeaker model conditioned on a set of phonologically derived features common across different languages, with the goal of achieving cross-lingual speaker adaptation. We first experiment with the effect of language phonological similarity on cross-lingual TTS of several source-target language combinations. Subsequently, we fine-tune the model with very limited data of a new speaker's voice in either a seen or an unseen language, and achieve synthetic speech of equal quality, while preserving the target speaker's identity. With as few as 32 and 8 utterances of target speaker data, we obtain high speaker similarity scores and naturalness comparable to the corresponding literature. In the extreme case of only 2 available adaptation utterances, we find that our model behaves as a few-shot learner, as the performance is similar in both the seen and unseen adaptation language scenarios.

</p>
</details>

<details><summary><b>Trustworthy Long-Tailed Classification</b>
<a href="https://arxiv.org/abs/2111.09030">arxiv:2111.09030</a>
&#x1F4C8; 6 <br>
<p>Bolian Li, Zongbo Han, Haining Li, Huazhu Fu, Changqing Zhang</p></summary>
<p>

**Abstract:** Classification on long-tailed distributed data is a challenging problem, which suffers from serious class-imbalance and accordingly unpromising performance especially on tail classes. Recently, the ensembling based methods achieve the state-of-the-art performance and show great potential. However, there are two limitations for current methods. First, their predictions are not trustworthy for failure-sensitive applications. This is especially harmful for the tail classes where the wrong predictions is basically frequent. Second, they assign unified numbers of experts to all samples, which is redundant for easy samples with excessive computational cost. To address these issues, we propose a Trustworthy Long-tailed Classification (TLC) method to jointly conduct classification and uncertainty estimation to identify hard samples in a multi-expert framework. Our TLC obtains the evidence-based uncertainty (EvU) and evidence for each expert, and then combines these uncertainties and evidences under the Dempster-Shafer Evidence Theory (DST). Moreover, we propose a dynamic expert engagement to reduce the number of engaged experts for easy samples and achieve efficiency while maintaining promising performances. Finally, we conduct comprehensive experiments on the tasks of classification, tail detection, OOD detection and failure prediction. The experimental results show that the proposed TLC outperforms the state-of-the-art methods and is trustworthy with reliable uncertainty.

</p>
</details>

<details><summary><b>Community-Detection via Hashtag-Graphs for Semi-Supervised NMF Topic Models</b>
<a href="https://arxiv.org/abs/2111.10401">arxiv:2111.10401</a>
&#x1F4C8; 5 <br>
<p>Mattias Luber, Anton Thielmann, Christoph Weisser, Benjamin Säfken</p></summary>
<p>

**Abstract:** Extracting topics from large collections of unstructured text-documents has become a central task in current NLP applications and algorithms like NMF, LDA as well as their generalizations are the well-established current state of the art. However, especially when it comes to short text documents like Tweets, these approaches often lead to unsatisfying results due to the sparsity of the document-feature matrices.
  Even though, several approaches have been proposed to overcome this sparsity by taking additional information into account, these are merely focused on the aggregation of similar documents and the estimation of word-co-occurrences. This ultimately completely neglects the fact that a lot of topical-information can be actually retrieved from so-called hashtag-graphs by applying common community detection algorithms. Therefore, this paper outlines a novel approach on how to integrate topic structures of hashtag graphs into the estimation of topic models by connecting graph-based community detection and semi-supervised NMF.
  By applying this approach on recently streamed Twitter data it will be seen that this procedure actually leads to more intuitive and humanly interpretable topics.

</p>
</details>

<details><summary><b>Self-Attending Task Generative Adversarial Network for Realistic Satellite Image Creation</b>
<a href="https://arxiv.org/abs/2111.09463">arxiv:2111.09463</a>
&#x1F4C8; 5 <br>
<p>Nathan Toner, Justin Fletcher</p></summary>
<p>

**Abstract:** We introduce a self-attending task generative adversarial network (SATGAN) and apply it to the problem of augmenting synthetic high contrast scientific imagery of resident space objects with realistic noise patterns and sensor characteristics learned from collected data. Augmenting these synthetic data is challenging due to the highly localized nature of semantic content in the data that must be preserved. Real collected images are used to train a network what a given class of sensor's images should look like. The trained network then acts as a filter on noiseless context images and outputs realistic-looking fakes with semantic content unaltered. The architecture is inspired by conditional GANs but is modified to include a task network that preserves semantic information through augmentation. Additionally, the architecture is shown to reduce instances of hallucinatory objects or obfuscation of semantic content in context images representing space observation scenes.

</p>
</details>

<details><summary><b>Low Precision Decentralized Distributed Training with Heterogeneous Data</b>
<a href="https://arxiv.org/abs/2111.09389">arxiv:2111.09389</a>
&#x1F4C8; 5 <br>
<p>Sai Aparna Aketi, Sangamesh Kodge, Kaushik Roy</p></summary>
<p>

**Abstract:** Decentralized distributed learning is the key to enabling large-scale machine learning (training) on the edge devices utilizing private user-generated local data, without relying on the cloud. However, practical realization of such on-device training is limited by the communication bottleneck, computation complexity of training deep models and significant data distribution skew across devices. Many feedback-based compression techniques have been proposed in the literature to reduce the communication cost and a few works propose algorithmic changes to aid the performance in the presence of skewed data distribution by improving convergence rate. To the best of our knowledge, there is no work in the literature that applies and shows compute efficient training techniques such quantization, pruning etc., for peer-to-peer decentralized learning setups. In this paper, we analyze and show the convergence of low precision decentralized training that aims to reduce the computational complexity of training and inference. Further, We study the effect of degree of skew and communication compression on the low precision decentralized training over various computer vision and Natural Language Processing (NLP) tasks. Our experiments indicate that 8-bit decentralized training has minimal accuracy loss compared to its full precision counterpart even with heterogeneous data. However, when low precision training is accompanied by communication compression through sparsification we observe 1-2% drop in accuracy. The proposed low precision decentralized training decreases computational complexity, memory usage, and communication cost by ~4x while trading off less than a 1% accuracy for both IID and non-IID data. In particular, with higher skew values, we observe an increase in accuracy (by ~0.5%) with low precision training, indicating the regularization effect of the quantization.

</p>
</details>

<details><summary><b>Interpretable Models via Pairwise permutations algorithm</b>
<a href="https://arxiv.org/abs/2111.09145">arxiv:2111.09145</a>
&#x1F4C8; 5 <br>
<p>Troy Maaslandand, João Pereira, Diogo Bastos, Marcus de Goffau, Max Nieuwdorp, Aeilko H. Zwinderman, Evgeni Levin</p></summary>
<p>

**Abstract:** One of the most common pitfalls often found in high dimensional biological data sets are correlations between the features. This may lead to statistical and machine learning methodologies overvaluing or undervaluing these correlated predictors, while the truly relevant ones are ignored. In this paper, we will define a new method called \textit{pairwise permutation algorithm} (PPA) with the aim of mitigating the correlation bias in feature importance values. Firstly, we provide a theoretical foundation, which builds upon previous work on permutation importance. PPA is then applied to a toy data set, where we demonstrate its ability to correct the correlation effect. We further test PPA on a microbiome shotgun dataset, to show that the PPA is already able to obtain biological relevant biomarkers.

</p>
</details>

<details><summary><b>Do Not Trust Prediction Scores for Membership Inference Attacks</b>
<a href="https://arxiv.org/abs/2111.09076">arxiv:2111.09076</a>
&#x1F4C8; 5 <br>
<p>Dominik Hintersdorf, Lukas Struppek, Kristian Kersting</p></summary>
<p>

**Abstract:** Membership inference attacks (MIAs) aim to determine whether a specific sample was used to train a predictive model. Knowing this may indeed lead to a privacy breach. Arguably, most MIAs, however, make use of the model's prediction scores - the probability of each output given some input - following the intuition that the trained model tends to behave differently on its training data. We argue that this is a fallacy for many modern deep network architectures, e.g., ReLU type neural networks produce almost always high prediction scores far away from the training data. Consequently, MIAs will miserably fail since this behavior leads to high false-positive rates not only on known domains but also on out-of-distribution data and implicitly acts as a defense against MIAs. Specifically, using generative adversarial networks, we are able to produce a potentially infinite number of samples falsely classified as part of the training data. In other words, the threat of MIAs is overestimated and less information is leaked than previously assumed. Moreover, there is actually a trade-off between the overconfidence of classifiers and their susceptibility to MIAs: the more classifiers know when they do not know, making low confidence predictions far away from the training data, the more they reveal the training data.

</p>
</details>

<details><summary><b>Gradient flows on graphons: existence, convergence, continuity equations</b>
<a href="https://arxiv.org/abs/2111.09459">arxiv:2111.09459</a>
&#x1F4C8; 4 <br>
<p>Sewoong Oh, Soumik Pal, Raghav Somani, Raghav Tripathi</p></summary>
<p>

**Abstract:** Wasserstein gradient flows on probability measures have found a host of applications in various optimization problems. They typically arise as the continuum limit of exchangeable particle systems evolving by some mean-field interaction involving a gradient-type potential. However, in many problems, such as in multi-layer neural networks, the so-called particles are edge weights on large graphs whose nodes are exchangeable. Such large graphs are known to converge to continuum limits called graphons as their size grow to infinity. We show that the Euclidean gradient flow of a suitable function of the edge-weights converges to a novel continuum limit given by a curve on the space of graphons that can be appropriately described as a gradient flow or, more technically, a curve of maximal slope. Several natural functions on graphons, such as homomorphism functions and the scalar entropy, are covered by our set-up, and the examples have been worked out in detail.

</p>
</details>

<details><summary><b>MPF6D: Masked Pyramid Fusion 6D Pose Estimation</b>
<a href="https://arxiv.org/abs/2111.09378">arxiv:2111.09378</a>
&#x1F4C8; 4 <br>
<p>Nuno Pereira, Luís A. Alexandre</p></summary>
<p>

**Abstract:** Object pose estimation has multiple important applications, such as robotic grasping and augmented reality. We present a new method to estimate the 6D pose of objects that improves upon the accuracy of current proposals and can still be used in real-time. Our method uses RGB-D data as input to segment objects and estimate their pose. It uses a neural network with multiple heads, one head estimates the object classification and generates the mask, the second estimates the values of the translation vector and the last head estimates the values of the quaternion that represents the rotation of the object. These heads leverage a pyramid architecture used during feature extraction and feature fusion. Our method can be used in real-time with its low inference time of 0.12 seconds and has high accuracy. With this combination of fast inference and good accuracy it is possible to use our method in robotic pick and place tasks and/or augmented reality applications.

</p>
</details>

<details><summary><b>Quantum-Assisted Support Vector Regression for Detecting Facial Landmarks</b>
<a href="https://arxiv.org/abs/2111.09304">arxiv:2111.09304</a>
&#x1F4C8; 4 <br>
<p>Archismita Dalal, Mohsen Bagherimehrab, Barry C. Sanders</p></summary>
<p>

**Abstract:** The classical machine-learning model for support vector regression (SVR) is widely used for regression tasks, including weather prediction, stock-market and real-estate pricing. However, a practically realisable quantum version for SVR remains to be formulated. We devise annealing-based algorithms, namely simulated and quantum-classical hybrid, for training two SVR models, and compare their empirical performances against the SVR implementation of Python's scikit-learn package and the SVR-based state-of-the-art algorithm for the facial landmark detection (FLD) problem. Our method is to derive a quadratic-unconstrained-binary formulation for the optimisation problem used for training a SVR model and solve this problem using annealing. Using D-Wave's Hybrid Solver, we construct a quantum-assisted SVR model, thereby demonstrating a slight advantage over classical models regarding landmark-detection accuracy. Furthermore, we observe that annealing-based SVR models predict landmarks with lower variances compared to the SVR models trained by greedy optimisation procedures. Our work is a proof-of-concept example for applying quantu-assisted SVR to a supervised learning task with a small training dataset.

</p>
</details>

<details><summary><b>Learning to Align Sequential Actions in the Wild</b>
<a href="https://arxiv.org/abs/2111.09301">arxiv:2111.09301</a>
&#x1F4C8; 4 <br>
<p>Weizhe Liu, Bugra Tekin, Huseyin Coskun, Vibhav Vineet, Pascal Fua, Marc Pollefeys</p></summary>
<p>

**Abstract:** State-of-the-art methods for self-supervised sequential action alignment rely on deep networks that find correspondences across videos in time. They either learn frame-to-frame mapping across sequences, which does not leverage temporal information, or assume monotonic alignment between each video pair, which ignores variations in the order of actions. As such, these methods are not able to deal with common real-world scenarios that involve background frames or videos that contain non-monotonic sequence of actions.
  In this paper, we propose an approach to align sequential actions in the wild that involve diverse temporal variations. To this end, we propose an approach to enforce temporal priors on the optimal transport matrix, which leverages temporal consistency, while allowing for variations in the order of actions. Our model accounts for both monotonic and non-monotonic sequences and handles background frames that should not be aligned. We demonstrate that our approach consistently outperforms the state-of-the-art in self-supervised sequential action representation learning on four different benchmark datasets.

</p>
</details>

<details><summary><b>Fast BATLLNN: Fast Box Analysis of Two-Level Lattice Neural Networks</b>
<a href="https://arxiv.org/abs/2111.09293">arxiv:2111.09293</a>
&#x1F4C8; 4 <br>
<p>James Ferlez, Haitham Khedr, Yasser Shoukry</p></summary>
<p>

**Abstract:** In this paper, we present the tool Fast Box Analysis of Two-Level Lattice Neural Networks (Fast BATLLNN) as a fast verifier of box-like output constraints for Two-Level Lattice (TLL) Neural Networks (NNs). In particular, Fast BATLLNN can verify whether the output of a given TLL NN always lies within a specified hyper-rectangle whenever its input constrained to a specified convex polytope (not necessarily a hyper-rectangle). Fast BATLLNN uses the unique semantics of the TLL architecture and the decoupled nature of box-like output constraints to dramatically improve verification performance relative to known polynomial-time verification algorithms for TLLs with generic polytopic output constraints. In this paper, we evaluate the performance and scalability of Fast BATLLNN, both in its own right and compared to state-of-the-art NN verifiers applied to TLL NNs. Fast BATLLNN compares very favorably to even the fastest NN verifiers, completing our synthetic TLL test bench more than 400x faster than its nearest competitor.

</p>
</details>

<details><summary><b>SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness</b>
<a href="https://arxiv.org/abs/2111.09277">arxiv:2111.09277</a>
&#x1F4C8; 4 <br>
<p>Jongheon Jeong, Sejun Park, Minkyu Kim, Heung-Chang Lee, Doguk Kim, Jinwoo Shin</p></summary>
<p>

**Abstract:** Randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against $\ell_2$-adversarial perturbations. Under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. This motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of a smoothed classifier. In this paper, we propose a simple training scheme, coined SmoothMix, to control the robustness of smoothed classifiers via self-mixup: it trains on convex combinations of samples along the direction of adversarial perturbation for each input. The proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Our experimental results demonstrate that the proposed method can significantly improve the certified $\ell_2$-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods.

</p>
</details>

<details><summary><b>DiverGAN: An Efficient and Effective Single-Stage Framework for Diverse Text-to-Image Generation</b>
<a href="https://arxiv.org/abs/2111.09267">arxiv:2111.09267</a>
&#x1F4C8; 4 <br>
<p>Zhenxing Zhang, Lambert Schomaker</p></summary>
<p>

**Abstract:** In this paper, we present an efficient and effective single-stage framework (DiverGAN) to generate diverse, plausible and semantically consistent images according to a natural-language description. DiverGAN adopts two novel word-level attention modules, i.e., a channel-attention module (CAM) and a pixel-attention module (PAM), which model the importance of each word in the given sentence while allowing the network to assign larger weights to the significant channels and pixels semantically aligning with the salient words. After that, Conditional Adaptive Instance-Layer Normalization (CAdaILN) is introduced to enable the linguistic cues from the sentence embedding to flexibly manipulate the amount of change in shape and texture, further improving visual-semantic representation and helping stabilize the training. Also, a dual-residual structure is developed to preserve more original visual features while allowing for deeper networks, resulting in faster convergence speed and more vivid details. Furthermore, we propose to plug a fully-connected layer into the pipeline to address the lack-of-diversity problem, since we observe that a dense layer will remarkably enhance the generative capability of the network, balancing the trade-off between a low-dimensional random latent code contributing to variants and modulation modules that use high-dimensional and textual contexts to strength feature maps. Inserting a linear layer after the second residual block achieves the best variety and quality. Both qualitative and quantitative results on benchmark data sets demonstrate the superiority of our DiverGAN for realizing diversity, without harming quality and semantic consistency.

</p>
</details>

<details><summary><b>Universal Inference Meets Random Projections: A Scalable Test for Log-concavity</b>
<a href="https://arxiv.org/abs/2111.09254">arxiv:2111.09254</a>
&#x1F4C8; 4 <br>
<p>Robin Dunn, Larry Wasserman, Aaditya Ramdas</p></summary>
<p>

**Abstract:** Shape constraints yield flexible middle grounds between fully nonparametric and fully parametric approaches to modeling distributions of data. The specific assumption of log-concavity is motivated by applications across economics, survival modeling, and reliability theory. However, there do not currently exist valid tests for whether the underlying density of given data is log-concave. The recent universal likelihood ratio test provides a valid test. The universal test relies on maximum likelihood estimation (MLE), and efficient methods already exist for finding the log-concave MLE. This yields the first test of log-concavity that is provably valid in finite samples in any dimension, for which we also establish asymptotic consistency results. Empirically, we find that the highest power is obtained by using random projections to convert the d-dimensional testing problem into many one-dimensional problems, leading to a simple procedure that is statistically and computationally efficient.

</p>
</details>

<details><summary><b>Secure Federated Learning for Residential Short Term Load Forecasting</b>
<a href="https://arxiv.org/abs/2111.09248">arxiv:2111.09248</a>
&#x1F4C8; 4 <br>
<p>Joaquin Delgado Fernandez, Sergio Potenciano Menci, Charles Lee, Gilbert Fridgen</p></summary>
<p>

**Abstract:** The inclusion of intermittent and renewable energy sources has increased the importance of demand forecasting in power systems. Smart meters can play a critical role in demand forecasting due to the measurement granularity they provide. Despite their virtue, smart meters used for forecasting face some constraints as consumers' privacy concerns, reluctance of utilities and vendors to share data with competitors or third parties, and regulatory constraints. This paper examines a collaborative machine learning method, federated learning extended with privacy preserving techniques for short-term demand forecasting using smart meter data as a solution to the previous constraints. The combination of privacy preserving techniques and federated learning enables to ensure consumers' confidentiality concerning both their data, the models generated using it (Differential Privacy), and the communication mean (Secure Aggregation). To evaluate this paper's collaborative secure federated learning setting, we explore current literature to select the baseline for our simulations and evaluation. We simulate and evaluate several scenarios that explore how traditional centralized approaches could be projected in the direction of a decentralized, collaborative and private system. The results obtained over the evaluations provided decent performance and in a privacy setting using differential privacy almost perfect privacy budgets (1.39,$10e^{-5}$) and (2.01,$10e^{-5}$) with a negligible performance compromise.

</p>
</details>

<details><summary><b>Tiny Obstacle Discovery by Occlusion-Aware Multilayer Regression</b>
<a href="https://arxiv.org/abs/2111.09204">arxiv:2111.09204</a>
&#x1F4C8; 4 <br>
<p>Feng Xue, Anlong Ming, Yu Zhou</p></summary>
<p>

**Abstract:** Edges are the fundamental visual element for discovering tiny obstacles using a monocular camera. Nevertheless, tiny obstacles often have weak and inconsistent edge cues due to various properties such as small size and similar appearance to the free space, making it hard to capture them. ...

</p>
</details>

<details><summary><b>IV-GNN : Interval Valued Data Handling Using Graph Neural Network</b>
<a href="https://arxiv.org/abs/2111.09194">arxiv:2111.09194</a>
&#x1F4C8; 4 <br>
<p>Sucheta Dawn, Sanghamitra Bandyopadhyay</p></summary>
<p>

**Abstract:** Graph Neural Network (GNN) is a powerful tool to perform standard machine learning on graphs. To have a Euclidean representation of every node in the Non-Euclidean graph-like data, GNN follows neighbourhood aggregation and combination of information recursively along the edges of the graph. Despite having many GNN variants in the literature, no model can deal with graphs having nodes with interval-valued features. This article proposes an Interval-ValuedGraph Neural Network, a novel GNN model where, for the first time, we relax the restriction of the feature space being countable. Our model is much more general than existing models as any countable set is always a subset of the universal set $R^{n}$, which is uncountable. Here, to deal with interval-valued feature vectors, we propose a new aggregation scheme of intervals and show its expressive power to capture different interval structures. We validate our theoretical findings about our model for graph classification tasks by comparing its performance with those of the state-of-the-art models on several benchmark network and synthetic datasets.

</p>
</details>

<details><summary><b>Understanding and Testing Generalization of Deep Networks on Out-of-Distribution Data</b>
<a href="https://arxiv.org/abs/2111.09190">arxiv:2111.09190</a>
&#x1F4C8; 4 <br>
<p>Rui Hu, Jitao Sang, Jinqiang Wang, Rui Hu, Chaoquan Jiang</p></summary>
<p>

**Abstract:** Deep network models perform excellently on In-Distribution (ID) data, but can significantly fail on Out-Of-Distribution (OOD) data. While developing methods focus on improving OOD generalization, few attention has been paid to evaluating the capability of models to handle OOD data. This study is devoted to analyzing the problem of experimental ID test and designing OOD test paradigm to accurately evaluate the practical performance. Our analysis is based on an introduced categorization of three types of distribution shifts to generate OOD data. Main observations include: (1) ID test fails in neither reflecting the actual performance of a single model nor comparing between different models under OOD data. (2) The ID test failure can be ascribed to the learned marginal and conditional spurious correlations resulted from the corresponding distribution shifts. Based on this, we propose novel OOD test paradigms to evaluate the generalization capacity of models to unseen data, and discuss how to use OOD test results to find bugs of models to guide model debugging.

</p>
</details>

<details><summary><b>Uncertainty Quantification of Surrogate Explanations: an Ordinal Consensus Approach</b>
<a href="https://arxiv.org/abs/2111.09121">arxiv:2111.09121</a>
&#x1F4C8; 4 <br>
<p>Jonas Schulz, Rafael Poyiadzi, Raul Santos-Rodriguez</p></summary>
<p>

**Abstract:** Explainability of black-box machine learning models is crucial, in particular when deployed in critical applications such as medicine or autonomous cars. Existing approaches produce explanations for the predictions of models, however, how to assess the quality and reliability of such explanations remains an open question. In this paper we take a step further in order to provide the practitioner with tools to judge the trustworthiness of an explanation. To this end, we produce estimates of the uncertainty of a given explanation by measuring the ordinal consensus amongst a set of diverse bootstrapped surrogate explainers. While we encourage diversity by using ensemble techniques, we propose and analyse metrics to aggregate the information contained within the set of explainers through a rating scheme. We empirically illustrate the properties of this approach through experiments on state-of-the-art Convolutional Neural Network ensembles. Furthermore, through tailored visualisations, we show specific examples of situations where uncertainty estimates offer concrete actionable insights to the user beyond those arising from standard surrogate explainers.

</p>
</details>

<details><summary><b>Network Generation with Differential Privacy</b>
<a href="https://arxiv.org/abs/2111.09085">arxiv:2111.09085</a>
&#x1F4C8; 4 <br>
<p>Xu Zheng, Nicholas McCarthy, Jer Hayes</p></summary>
<p>

**Abstract:** We consider the problem of generating private synthetic versions of real-world graphs containing private information while maintaining the utility of generated graphs. Differential privacy is a gold standard for data privacy, and the introduction of the differentially private stochastic gradient descent (DP-SGD) algorithm has facilitated the training of private neural models in a number of domains. Recent advances in graph generation via deep generative networks have produced several high performing models. We evaluate and compare state-of-the-art models including adjacency matrix based models and edge based models, and show a practical implementation that favours the edge-list approach utilizing the Gaussian noise mechanism when evaluated on commonly used graph datasets. Based on our findings, we propose a generative model that can reproduce the properties of real-world networks while maintaining edge-differential privacy. The proposed model is based on a stochastic neural network that generates discrete edge-list samples and is trained using the Wasserstein GAN objective with the DP-SGD optimizer. Being the first approach to combine these beneficial properties, our model contributes to further research on graph data privacy.

</p>
</details>

<details><summary><b>Image Super-Resolution Using T-Tetromino Pixels</b>
<a href="https://arxiv.org/abs/2111.09013">arxiv:2111.09013</a>
&#x1F4C8; 4 <br>
<p>Simon Grosche, Andy Regensky, Jürgen Seiler, André Kaup</p></summary>
<p>

**Abstract:** For modern high-resolution imaging sensors, pixel binning is performed in low-lighting conditions and in case high frame rates are required. To recover the original spatial resolution, single-image super-resolution techniques can be applied for upscaling. To achieve a higher image quality after upscaling, we propose a novel binning concept using tetromino-shaped pixels. In doing so, we investigate the reconstruction quality using tetromino pixels for the first time in literature. Instead of using different types of tetrominoes as proposed in the literature for a sensor layout, we show that using a small repeating cell consisting of only four T-tetrominoes is sufficient. For reconstruction, we use a locally fully connected reconstruction (LFCR) network as well as two classical reconstruction methods from the field of compressed sensing. Using the LFCR network in combination with the proposed tetromino layout, we achieve superior image quality in terms of PSNR, SSIM, and visually compared to conventional single-image super-resolution using the very deep super-resolution (VDSR) network. For the PSNR, a gain of up to +1.92 dB is achieved.

</p>
</details>

<details><summary><b>Fine-grained prediction of food insecurity using news streams</b>
<a href="https://arxiv.org/abs/2111.15602">arxiv:2111.15602</a>
&#x1F4C8; 3 <br>
<p>Ananth Balashankar, Lakshminarayanan Subramanian, Samuel P. Fraiberger</p></summary>
<p>

**Abstract:** Anticipating the outbreak of a food crisis is crucial to efficiently allocate emergency relief and reduce human suffering. However, existing food insecurity early warning systems rely on risk measures that are often delayed, outdated, or incomplete. Here, we leverage recent advances in deep learning to extract high-frequency precursors to food crises from the text of a large corpus of news articles about fragile states published between 1980 and 2020. Our text features are causally grounded, interpretable, validated by existing data, and allow us to predict 32% more food crises than existing models up to three months ahead of time at the district level across 15 fragile states. These results could have profound implications on how humanitarian aid gets allocated and open new avenues for machine learning to improve decision making in data-scarce environments.

</p>
</details>

<details><summary><b>Augmentation of base classifier performance via HMMs on a handwritten character data set</b>
<a href="https://arxiv.org/abs/2111.10204">arxiv:2111.10204</a>
&#x1F4C8; 3 <br>
<p>Hélder Campos, Nuno Paulino</p></summary>
<p>

**Abstract:** This paper presents results of a study of the performance of several base classifiers for recognition of handwritten characters of the modern Latin alphabet. Base classification performance is further enhanced by utilizing Viterbi error correction by determining the Viterbi sequence. Hidden Markov Models (HMMs) models exploit relationships between letters within a word to determine the most likely sequence of characters. Four base classifiers are studied along with eight feature sets extracted from the handwritten dataset. The best classification performance after correction was 89.8%, and the average was 68.1%

</p>
</details>

<details><summary><b>Large-scale Building Height Retrieval from Single SAR Imagery based on Bounding Box Regression Networks</b>
<a href="https://arxiv.org/abs/2111.09460">arxiv:2111.09460</a>
&#x1F4C8; 3 <br>
<p>Yao Sun, Lichao Mou, Yuanyuan Wang, Sina Montazeri, Xiao Xiang Zhu</p></summary>
<p>

**Abstract:** Building height retrieval from synthetic aperture radar (SAR) imagery is of great importance for urban applications, yet highly challenging owing to the complexity of SAR data. This paper addresses the issue of building height retrieval in large-scale urban areas from a single TerraSAR-X spotlight or stripmap image. Based on the radar viewing geometry, we propose that this problem can be formulated as a bounding box regression problem and therefore allows for integrating height data from multiple data sources in generating ground truth on a larger scale. We introduce building footprints from geographic information system (GIS) data as complementary information and propose a bounding box regression network that exploits the location relationship between a building's footprint and its bounding box, allowing for fast computation. This is important for large-scale applications. The method is validated on four urban data sets using TerraSAR-X images in both high-resolution spotlight and stripmap modes. Experimental results show that the proposed network can reduce the computation cost significantly while keeping the height accuracy of individual buildings compared to a Faster R-CNN based method. Moreover, we investigate the impact of inaccurate GIS data on our proposed network, and this study shows that the bounding box regression network is robust against positioning errors in GIS data. The proposed method has great potential to be applied to regional or even global scales.

</p>
</details>

<details><summary><b>Segmentation of Lung Tumor from CT Images using Deep Supervision</b>
<a href="https://arxiv.org/abs/2111.09262">arxiv:2111.09262</a>
&#x1F4C8; 3 <br>
<p>Farhanaz Farheen, Md. Salman Shamil, Nabil Ibtehaz, M. Sohel Rahman</p></summary>
<p>

**Abstract:** Lung cancer is a leading cause of death in most countries of the world. Since prompt diagnosis of tumors can allow oncologists to discern their nature, type and the mode of treatment, tumor detection and segmentation from CT Scan images is a crucial field of study worldwide. This paper approaches lung tumor segmentation by applying two-dimensional discrete wavelet transform (DWT) on the LOTUS dataset for more meticulous texture analysis whilst integrating information from neighboring CT slices before feeding them to a Deeply Supervised MultiResUNet model. Variations in learning rates, decay and optimization algorithms while training the network have led to different dice co-efficients, the detailed statistics of which have been included in this paper. We also discuss the challenges in this dataset and how we opted to overcome them. In essence, this study aims to maximize the success rate of predicting tumor regions from two dimensional CT Scan slices by experimenting with a number of adequate networks, resulting in a dice co-efficient of 0.8472.

</p>
</details>

<details><summary><b>Airport Taxi Time Prediction and Alerting: A Convolutional Neural Network Approach</b>
<a href="https://arxiv.org/abs/2111.09139">arxiv:2111.09139</a>
&#x1F4C8; 3 <br>
<p>Erik Vargo, Alex Tien, Arian Jafari</p></summary>
<p>

**Abstract:** This paper proposes a novel approach to predict and determine whether the average taxi- out time at an airport will exceed a pre-defined threshold within the next hour of operations. Prior work in this domain has focused exclusively on predicting taxi-out times on a flight-by-flight basis, which requires significant efforts and data on modeling taxiing activities from gates to runways. Learning directly from surface radar information with minimal processing, a computer vision-based model is proposed that incorporates airport surface data in such a way that adaptation-specific information (e.g., runway configuration, the state of aircraft in the taxiing process) is inferred implicitly and automatically by Artificial Intelligence (AI).

</p>
</details>

<details><summary><b>Fast and Light-Weight Network for Single Frame Structured Illumination Microscopy Super-Resolution</b>
<a href="https://arxiv.org/abs/2111.09103">arxiv:2111.09103</a>
&#x1F4C8; 3 <br>
<p>Xi Cheng, Jun Li, Qiang Dai, Zhenyong Fu, Jian Yang</p></summary>
<p>

**Abstract:** Structured illumination microscopy (SIM) is an important super-resolution based microscopy technique that breaks the diffraction limit and enhances optical microscopy systems. With the development of biology and medical engineering, there is a high demand for real-time and robust SIM imaging under extreme low light and short exposure environments. Existing SIM techniques typically require multiple structured illumination frames to produce a high-resolution image. In this paper, we propose a single-frame structured illumination microscopy (SF-SIM) based on deep learning. Our SF-SIM only needs one shot of a structured illumination frame and generates similar results compared with the traditional SIM systems that typically require 15 shots. In our SF-SIM, we propose a noise estimator which can effectively suppress the noise in the image and enable our method to work under the low light and short exposure environment, without the need for stacking multiple frames for non-local denoising. We also design a bandpass attention module that makes our deep network more sensitive to the change of frequency and enhances the imaging quality. Our proposed SF-SIM is almost 14 times faster than traditional SIM methods when achieving similar results. Therefore, our method is significantly valuable for the development of microbiology and medicine.

</p>
</details>

<details><summary><b>Sampling To Improve Predictions For Underrepresented Observations In Imbalanced Data</b>
<a href="https://arxiv.org/abs/2111.09065">arxiv:2111.09065</a>
&#x1F4C8; 3 <br>
<p>Rune D. Kjærsgaard, Manja G. Grønberg, Line K. H. Clemmensen</p></summary>
<p>

**Abstract:** Data imbalance is common in production data, where controlled production settings require data to fall within a narrow range of variation and data are collected with quality assessment in mind, rather than data analytic insights. This imbalance negatively impacts the predictive performance of models on underrepresented observations. We propose sampling to adjust for this imbalance with the goal of improving the performance of models trained on historical production data. We investigate the use of three sampling approaches to adjust for imbalance. The goal is to downsample the covariates in the training data and subsequently fit a regression model. We investigate how the predictive power of the model changes when using either the sampled or the original data for training. We apply our methods on a large biopharmaceutical manufacturing data set from an advanced simulation of penicillin production and find that fitting a model using the sampled data gives a small reduction in the overall predictive performance, but yields a systematically better performance on underrepresented observations. In addition, the results emphasize the need for alternative, fair, and balanced model evaluations.

</p>
</details>

<details><summary><b>Improved Learning Bounds for Branch-and-Cut</b>
<a href="https://arxiv.org/abs/2111.11207">arxiv:2111.11207</a>
&#x1F4C8; 2 <br>
<p>Maria-Florina Balcan, Siddharth Prasad, Tuomas Sandholm, Ellen Vitercik</p></summary>
<p>

**Abstract:** Branch-and-cut is the most widely used algorithm for solving integer programs, employed by commercial solvers like CPLEX and Gurobi. Branch-and-cut has a wide variety of tunable parameters that have a huge impact on the size of the search tree that it builds, but are challenging to tune by hand. An increasingly popular approach is to use machine learning to tune these parameters: using a training set of integer programs from the application domain at hand, the goal is to find a configuration with strong predicted performance on future, unseen integer programs from the same domain. If the training set is too small, a configuration may have good performance over the training set but poor performance on future integer programs. In this paper, we prove sample complexity guarantees for this procedure, which bound how large the training set should be to ensure that for any configuration, its average performance over the training set is close to its expected future performance. Our guarantees apply to parameters that control the most important aspects of branch-and-cut: node selection, branching constraint selection, and cutting plane selection, and are sharper and more general than those found in prior research.

</p>
</details>

<details><summary><b>The Application of Zig-Zag Sampler in Sequential Markov Chain Monte Carlo</b>
<a href="https://arxiv.org/abs/2111.10210">arxiv:2111.10210</a>
&#x1F4C8; 2 <br>
<p>Yu Han, Kazuyuki Nakamura</p></summary>
<p>

**Abstract:** Particle filtering methods are widely applied in sequential state estimation within nonlinear non-Gaussian state space model. However, the traditional particle filtering methods suffer the weight degeneracy in the high-dimensional state space model. Currently, there are many methods to improve the performance of particle filtering in high-dimensional state space model. Among these, the more advanced method is to construct the Sequential Makov chian Monte Carlo (SMCMC) framework by implementing the Composite Metropolis-Hasting (MH) Kernel. In this paper, we proposed to discrete the Zig-Zag Sampler and apply the Zig-Zag Sampler in the refinement stage of the Composite MH Kernel within the SMCMC framework which is implemented the invertible particle flow in the joint draw stage. We evaluate the performance of proposed method through numerical experiments of the challenging complex high-dimensional filtering examples. Nemurical experiments show that in high-dimensional state estimation examples, the proposed method improves estimation accuracy and increases the acceptance ratio compared with state-of-the-art filtering methods.

</p>
</details>

<details><summary><b>Attacking Deep Learning AI Hardware with Universal Adversarial Perturbation</b>
<a href="https://arxiv.org/abs/2111.09488">arxiv:2111.09488</a>
&#x1F4C8; 2 <br>
<p>Mehdi Sadi, B. M. S. Bahar Talukder, Kaniz Mishty, Md Tauhidur Rahman</p></summary>
<p>

**Abstract:** Universal Adversarial Perturbations are image-agnostic and model-independent noise that when added with any image can mislead the trained Deep Convolutional Neural Networks into the wrong prediction. Since these Universal Adversarial Perturbations can seriously jeopardize the security and integrity of practical Deep Learning applications, existing techniques use additional neural networks to detect the existence of these noises at the input image source. In this paper, we demonstrate an attack strategy that when activated by rogue means (e.g., malware, trojan) can bypass these existing countermeasures by augmenting the adversarial noise at the AI hardware accelerator stage. We demonstrate the accelerator-level universal adversarial noise attack on several deep Learning models using co-simulation of the software kernel of Conv2D function and the Verilog RTL model of the hardware under the FuseSoC environment.

</p>
</details>

<details><summary><b>BLOOM-Net: Blockwise Optimization for Masking Networks Toward Scalable and Efficient Speech Enhancement</b>
<a href="https://arxiv.org/abs/2111.09372">arxiv:2111.09372</a>
&#x1F4C8; 2 <br>
<p>Sunwoo Kim, Minje Kim</p></summary>
<p>

**Abstract:** In this paper, we present a blockwise optimization method for masking-based networks (BLOOM-Net) for training scalable speech enhancement networks. Here, we design our network with a residual learning scheme and train the internal separator blocks sequentially to obtain a scalable masking-based deep neural network for speech enhancement. Its scalability lets it adjust the run-time complexity based on the test-time resource constraints: once deployed, the model can alter its complexity dynamically depending on the test time environment. To this end, we modularize our models in that they can flexibly accommodate varying needs for enhancement performance and constraints on the resources, incurring minimal memory or training overhead due to the added scalability. Our experiments on speech enhancement demonstrate that the proposed blockwise optimization method achieves the desired scalability with only a slight performance degradation compared to corresponding models trained end-to-end.

</p>
</details>

<details><summary><b>Transformation of Node to Knowledge Graph Embeddings for Faster Link Prediction in Social Networks</b>
<a href="https://arxiv.org/abs/2111.09308">arxiv:2111.09308</a>
&#x1F4C8; 2 <br>
<p>Archit Parnami, Mayuri Deshpande, Anant Kumar Mishra, Minwoo Lee</p></summary>
<p>

**Abstract:** Recent advances in neural networks have solved common graph problems such as link prediction, node classification, node clustering, node recommendation by developing embeddings of entities and relations into vector spaces. Graph embeddings encode the structural information present in a graph. The encoded embeddings then can be used to predict the missing links in a graph. However, obtaining the optimal embeddings for a graph can be a computationally challenging task specially in an embedded system. Two techniques which we focus on in this work are 1) node embeddings from random walk based methods and 2) knowledge graph embeddings. Random walk based embeddings are computationally inexpensive to obtain but are sub-optimal whereas knowledge graph embeddings perform better but are computationally expensive. In this work, we investigate a transformation model which converts node embeddings obtained from random walk based methods to embeddings obtained from knowledge graph methods directly without an increase in the computational cost. Extensive experimentation shows that the proposed transformation model can be used for solving link prediction in real-time.

</p>
</details>

<details><summary><b>Interpreting multi-variate models with setPCA</b>
<a href="https://arxiv.org/abs/2111.09138">arxiv:2111.09138</a>
&#x1F4C8; 2 <br>
<p>Nordine Aouni, Luc Linders, David Robinson, Len Vandelaer, Jessica Wiezorek, Geetesh Gupta, Rachel Cavill</p></summary>
<p>

**Abstract:** Principal Component Analysis (PCA) and other multi-variate models are often used in the analysis of "omics" data. These models contain much information which is currently neither easily accessible nor interpretable. Here we present an algorithmic method which has been developed to integrate this information with existing databases of background knowledge, stored in the form of known sets (for instance genesets or pathways). To make this accessible we have produced a Graphical User Interface (GUI) in Matlab which allows the overlay of known set information onto the loadings plot and thus improves the interpretability of the multi-variate model. For each known set the optimal convex hull, covering a subset of elements from the known set, is found through a search algorithm and displayed. In this paper we discuss two main topics; the details of the search algorithm for the optimal convex hull for this problem and the GUI interface which is freely available for download for academic use.

</p>
</details>

<details><summary><b>Unsupervised Spectral Unmixing For Telluric Correction Using A Neural Network Autoencoder</b>
<a href="https://arxiv.org/abs/2111.09081">arxiv:2111.09081</a>
&#x1F4C8; 2 <br>
<p>Rune D. Kjærsgaard, Aaron Bello-Arufe, Alexander D. Rathcke, Lars A. Buchhave, Line K. H. Clemmensen</p></summary>
<p>

**Abstract:** The absorption of light by molecules in the atmosphere of Earth is a complication for ground-based observations of astrophysical objects. Comprehensive information on various molecular species is required to correct for this so called telluric absorption. We present a neural network autoencoder approach for extracting a telluric transmission spectrum from a large set of high-precision observed solar spectra from the HARPS-N radial velocity spectrograph. We accomplish this by reducing the data into a compressed representation, which allows us to unveil the underlying solar spectrum and simultaneously uncover the different modes of variation in the observed spectra relating to the absorption of $\mathrm{H_2O}$ and $\mathrm{O_2}$ in the atmosphere of Earth. We demonstrate how the extracted components can be used to remove $\mathrm{H_2O}$ and $\mathrm{O_2}$ tellurics in a validation observation with similar accuracy and at less computational expense than a synthetic approach with molecfit.

</p>
</details>

<details><summary><b>Surrogate-Assisted Genetic Algorithm for Wrapper Feature Selection</b>
<a href="https://arxiv.org/abs/2111.09074">arxiv:2111.09074</a>
&#x1F4C8; 2 <br>
<p>Mohammed Ghaith Altarabichi, Sławomir Nowaczyk, Sepideh Pashami, Peyman Sheikholharam Mashhad</p></summary>
<p>

**Abstract:** Feature selection is an intractable problem, therefore practical algorithms often trade off the solution accuracy against the computation time. In this paper, we propose a novel multi-stage feature selection framework utilizing multiple levels of approximations, or surrogates. Such a framework allows for using wrapper approaches in a much more computationally efficient way, significantly increasing the quality of feature selection solutions achievable, especially on large datasets. We design and evaluate a Surrogate-Assisted Genetic Algorithm (SAGA) which utilizes this concept to guide the evolutionary search during the early phase of exploration. SAGA only switches to evaluating the original function at the final exploitation phase.
  We prove that the run-time upper bound of SAGA surrogate-assisted stage is at worse equal to the wrapper GA, and it scales better for induction algorithms of high order of complexity in number of instances. We demonstrate, using 14 datasets from the UCI ML repository, that in practice SAGA significantly reduces the computation time compared to a baseline wrapper Genetic Algorithm (GA), while converging to solutions of significantly higher accuracy. Our experiments show that SAGA can arrive at near-optimal solutions three times faster than a wrapper GA, on average. We also showcase the importance of evolution control approach designed to prevent surrogates from misleading the evolutionary search towards false optima.

</p>
</details>

<details><summary><b>Subject Enveloped Deep Sample Fuzzy Ensemble Learning Algorithm of Parkinson's Speech Data</b>
<a href="https://arxiv.org/abs/2111.09014">arxiv:2111.09014</a>
&#x1F4C8; 2 <br>
<p>Yiwen Wang, Fan Li, Xiaoheng Zhang, Pin Wang, Yongming Li</p></summary>
<p>

**Abstract:** Parkinson disease (PD)'s speech recognition is an effective way for its diagnosis, which has become a hot and difficult research area in recent years. As we know, there are large corpuses (segments) within one subject. However, too large segments will increase the complexity of the classification model. Besides, the clinicians interested in finding diagnostic speech markers that reflect the pathology of the whole subject. Since the optimal relevant features of each speech sample segment are different, it is difficult to find the uniform diagnostic speech markers. Therefore, it is necessary to reconstruct the existing large segments within one subject into few segments even one segment within one subject, which can facilitate the extraction of relevant speech features to characterize diagnostic markers for the whole subject. To address this problem, an enveloped deep speech sample learning algorithm for Parkinson's subjects based on multilayer fuzzy c-mean (MlFCM) clustering and interlayer consistency preservation is proposed in this paper. The algorithm can be used to achieve intra-subject sample reconstruction for Parkinson's disease (PD) to obtain a small number of high-quality prototype sample segments. At the end of the paper, several representative PD speech datasets are selected and compared with the state-of-the-art related methods, respectively. The experimental results show that the proposed algorithm is effective signifcantly.

</p>
</details>

<details><summary><b>Self-Learning Tuning for Post-Silicon Validation</b>
<a href="https://arxiv.org/abs/2111.08995">arxiv:2111.08995</a>
&#x1F4C8; 2 <br>
<p>Peter Domanski, Dirk Pflüger, Jochen Rivoir, Raphaël Latty</p></summary>
<p>

**Abstract:** Increasing complexity of modern chips makes design validation more difficult. Existing approaches are not able anymore to cope with the complexity of tasks such as robust performance tuning in post-silicon validation. Therefore, we propose a novel approach based on learn-to-optimize and reinforcement learning in order to solve complex and mixed-type tuning tasks in a efficient and robust way.

</p>
</details>

<details><summary><b>LVAC: Learned Volumetric Attribute Compression for Point Clouds using Coordinate Based Networks</b>
<a href="https://arxiv.org/abs/2111.08988">arxiv:2111.08988</a>
&#x1F4C8; 2 <br>
<p>Berivan Isik, Philip A. Chou, Sung Jin Hwang, Nick Johnston, George Toderici</p></summary>
<p>

**Abstract:** We consider the attributes of a point cloud as samples of a vector-valued volumetric function at discrete positions. To compress the attributes given the positions, we compress the parameters of the volumetric function. We model the volumetric function by tiling space into blocks, and representing the function over each block by shifts of a coordinate-based, or implicit, neural network. Inputs to the network include both spatial coordinates and a latent vector per block. We represent the latent vectors using coefficients of the region-adaptive hierarchical transform (RAHT) used in the MPEG geometry-based point cloud codec G-PCC. The coefficients, which are highly compressible, are rate-distortion optimized by back-propagation through a rate-distortion Lagrangian loss in an auto-decoder configuration. The result outperforms RAHT by 2--4 dB. This is the first work to compress volumetric functions represented by local coordinate-based neural networks. As such, we expect it to be applicable beyond point clouds, for example to compression of high-resolution neural radiance fields.

</p>
</details>

<details><summary><b>Three approaches to supervised learning for compositional data with pairwise logratios</b>
<a href="https://arxiv.org/abs/2111.08953">arxiv:2111.08953</a>
&#x1F4C8; 2 <br>
<p>Germa Coenders, Michael Greenacre</p></summary>
<p>

**Abstract:** The common approach to compositional data analysis is to transform the data by means of logratios. Logratios between pairs of compositional parts (pairwise logratios) are the easiest to interpret in many research problems. When the number of parts is large, some form of logratio selection is a must, for instance by means of an unsupervised learning method based on a stepwise selection of the pairwise logratios that explain the largest percentage of the logratio variance in the compositional dataset. In this article we present three alternative stepwise supervised learning methods to select the pairwise logratios that best explain a dependent variable in a generalized linear model, each geared for a specific problem. The first method features unrestricted search, where any pairwise logratio can be selected. This method has a complex interpretation if some pairs of parts in the logratios overlap, but it leads to the most accurate predictions. The second method restricts parts to occur only once, which makes the corresponding logratios intuitively interpretable. The third method uses additive logratios, so that $K-1$ selected logratios involve exactly $K$ parts. This method in fact searches for the subcomposition with the highest explanatory power. Once the subcomposition is identified, the researcher's favourite logratio representation may be used in subsequent analyses, not only pairwise logratios. Our methodology allows logratios or non-compositional covariates to be forced into the models based on theoretical knowledge, and various stopping criteria are available based on information measures or statistical significance with the Bonferroni correction. We present an illustration of the three approaches on a dataset from a study predicting Crohn's disease. The first method excels in terms of predictive power, and the other two in interpretability.

</p>
</details>

<details><summary><b>A Generalized Proportionate-Type Normalized Subband Adaptive Filter</b>
<a href="https://arxiv.org/abs/2111.08952">arxiv:2111.08952</a>
&#x1F4C8; 2 <br>
<p>Kuan-Lin Chen, Ching-Hua Lee, Bhaskar D. Rao, Harinath Garudadri</p></summary>
<p>

**Abstract:** We show that a new design criterion, i.e., the least squares on subband errors regularized by a weighted norm, can be used to generalize the proportionate-type normalized subband adaptive filtering (PtNSAF) framework. The new criterion directly penalizes subband errors and includes a sparsity penalty term which is minimized using the damped regularized Newton's method. The impact of the proposed generalized PtNSAF (GPtNSAF) is studied for the system identification problem via computer simulations. Specifically, we study the effects of using different numbers of subbands and various sparsity penalty terms for quasi-sparse, sparse, and dispersive systems. The results show that the benefit of increasing the number of subbands is larger than promoting sparsity of the estimated filter coefficients when the target system is quasi-sparse or dispersive. On the other hand, for sparse target systems, promoting sparsity becomes more important. More importantly, the two aspects provide complementary and additive benefits to the GPtNSAF for speeding up convergence.

</p>
</details>

<details><summary><b>Traversing the Local Polytopes of ReLU Neural Networks: A Unified Approach for Network Verification</b>
<a href="https://arxiv.org/abs/2111.08922">arxiv:2111.08922</a>
&#x1F4C8; 2 <br>
<p>Shaojie Xu, Joel Vaughan, Jie Chen, Aijun Zhang, Agus Sudjianto</p></summary>
<p>

**Abstract:** Although neural networks (NNs) with ReLU activation functions have found success in a wide range of applications, their adoption in risk-sensitive settings has been limited by the concerns on robustness and interpretability. Previous works to examine robustness and to improve interpretability partially exploited the piecewise linear function form of ReLU NNs. In this paper, we explore the unique topological structure that ReLU NNs create in the input space, identifying the adjacency among the partitioned local polytopes and developing a traversing algorithm based on this adjacency. Our polytope traversing algorithm can be adapted to verify a wide range of network properties related to robustness and interpretability, providing an unified approach to examine the network behavior. As the traversing algorithm explicitly visits all local polytopes, it returns a clear and full picture of the network behavior within the traversed region. The time and space complexity of the traversing algorithm is determined by the number of a ReLU NN's partitioning hyperplanes passing through the traversing region.

</p>
</details>

<details><summary><b>Universal Efficient Variable-rate Neural Image Compression</b>
<a href="https://arxiv.org/abs/2111.11305">arxiv:2111.11305</a>
&#x1F4C8; 1 <br>
<p>Shanzhi Yin, Chao Li, Youneng Bao, Yongshang Liang</p></summary>
<p>

**Abstract:** Recently, Learning-based image compression has reached comparable performance with traditional image codecs(such as JPEG, BPG, WebP). However, computational complexity and rate flexibility are still two major challenges for its practical deployment. To tackle these problems, this paper proposes two universal modules named Energy-based Channel Gating(ECG) and Bit-rate Modulator(BM), which can be directly embedded into existing end-to-end image compression models. ECG uses dynamic pruning to reduce FLOPs for more than 50\% in convolution layers, and a BM pair can modulate the latent representation to control the bit-rate in a channel-wise manner. By implementing these two modules, existing learning-based image codecs can obtain ability to output arbitrary bit-rate with a single model and reduced computation.

</p>
</details>

<details><summary><b>Learning Free-Surface Flow with Physics-Informed Neural Networks</b>
<a href="https://arxiv.org/abs/2111.09705">arxiv:2111.09705</a>
&#x1F4C8; 1 <br>
<p>Raphael Leiteritz, Marcel Hurler, Dirk Pflüger</p></summary>
<p>

**Abstract:** The interface between data-driven learning methods and classical simulation poses an interesting field offering a multitude of new applications. In this work, we build on the notion of physics-informed neural networks (PINNs) and employ them in the area of shallow-water equation (SWE) models. These models play an important role in modeling and simulating free-surface flow scenarios such as in flood-wave propagation or tsunami waves. Different formulations of the PINN residual are compared to each other and multiple optimizations are being evaluated to speed up the convergence rate. We test these with different 1-D and 2-D experiments and finally demonstrate that regarding a SWE scenario with varying bathymetry, the method is able to produce competitive results in comparison to the direct numerical simulation with a total relative $L_2$ error of $8.9e-3$.

</p>
</details>

<details><summary><b>L4-Norm Weight Adjustments for Converted Spiking Neural Networks</b>
<a href="https://arxiv.org/abs/2111.09446">arxiv:2111.09446</a>
&#x1F4C8; 1 <br>
<p>Jason Allred, Kaushik Roy</p></summary>
<p>

**Abstract:** Spiking Neural Networks (SNNs) are being explored for their potential energy efficiency benefits due to sparse, event-driven computation. Non-spiking artificial neural networks are typically trained with stochastic gradient descent using backpropagation. The calculation of true gradients for backpropagation in spiking neural networks is impeded by the non-differentiable firing events of spiking neurons. On the other hand, using approximate gradients is effective, but computationally expensive over many time steps. One common technique, then, for training a spiking neural network is to train a topologically-equivalent non-spiking network, and then convert it to an spiking network, replacing real-valued inputs with proportionally rate-encoded Poisson spike trains. Converted SNNs function sufficiently well because the mean pre-firing membrane potential of a spiking neuron is proportional to the dot product of the input rate vector and the neuron weight vector, similar to the functionality of a non-spiking network. However, this conversion only considers the mean and not the temporal variance of the membrane potential. As the standard deviation of the pre-firing membrane potential is proportional to the L4-norm of the neuron weight vector, we propose a weight adjustment based on the L4-norm during the conversion process in order to improve classification accuracy of the converted network.

</p>
</details>

<details><summary><b>On the Effectiveness of Iterative Learning Control</b>
<a href="https://arxiv.org/abs/2111.09434">arxiv:2111.09434</a>
&#x1F4C8; 1 <br>
<p>Anirudh Vemula, Wen Sun, Maxim Likhachev, J. Andrew Bagnell</p></summary>
<p>

**Abstract:** Iterative learning control (ILC) is a powerful technique for high performance tracking in the presence of modeling errors for optimal control applications. There is extensive prior work showing its empirical effectiveness in applications such as chemical reactors, industrial robots and quadcopters. However, there is little prior theoretical work that explains the effectiveness of ILC even in the presence of large modeling errors, where optimal control methods using the misspecified model (MM) often perform poorly. Our work presents such a theoretical study of the performance of both ILC and MM on Linear Quadratic Regulator (LQR) problems with unknown transition dynamics. We show that the suboptimality gap, as measured with respect to the optimal LQR controller, for ILC is lower than that for MM by higher order terms that become significant in the regime of high modeling errors. A key part of our analysis is the perturbation bounds for the discrete Ricatti equation in the finite horizon setting, where the solution is not a fixed point and requires tracking the error using recursive bounds. We back our theoretical findings with empirical experiments on a toy linear dynamical system with an approximate model, a nonlinear inverted pendulum system with misspecified mass, and a nonlinear planar quadrotor system in the presence of wind. Experiments show that ILC outperforms MM significantly, in terms of the cost of computed trajectories, when modeling errors are high.

</p>
</details>

<details><summary><b>Multi-Attribute Relation Extraction (MARE) -- Simplifying the Application of Relation Extraction</b>
<a href="https://arxiv.org/abs/2111.09035">arxiv:2111.09035</a>
&#x1F4C8; 0 <br>
<p>Lars Klöser, Philipp Kohl, Bodo Kraft, Albert Zündorf</p></summary>
<p>

**Abstract:** Natural language understanding's relation extraction makes innovative and encouraging novel business concepts possible and facilitates new digitilized decision-making processes. Current approaches allow the extraction of relations with a fixed number of entities as attributes. Extracting relations with an arbitrary amount of attributes requires complex systems and costly relation-trigger annotations to assist these systems. We introduce multi-attribute relation extraction (MARE) as an assumption-less problem formulation with two approaches, facilitating an explicit mapping from business use cases to the data annotations. Avoiding elaborated annotation constraints simplifies the application of relation extraction approaches. The evaluation compares our models to current state-of-the-art event extraction and binary relation extraction methods. Our approaches show improvement compared to these on the extraction of general multi-attribute relations.

</p>
</details>


[Next Page]({{ '/2021/11/16/2021.11.16.html' | relative_url }})
