Prev: [2021.01.07]({{ '/2021/01/07/2021.01.07.html' | relative_url }})  Next: [2021.01.09]({{ '/2021/01/09/2021.01.09.html' | relative_url }})
{% raw %}
## Summary for 2021-01-08, created on 2021-12-24


<details><summary><b>Evolving Reinforcement Learning Algorithms</b>
<a href="https://arxiv.org/abs/2101.03958">arxiv:2101.03958</a>
&#x1F4C8; 93 <br>
<p>John D. Co-Reyes, Yingjie Miao, Daiyi Peng, Esteban Real, Sergey Levine, Quoc V. Le, Honglak Lee, Aleksandra Faust</p></summary>
<p>

**Abstract:** We propose a method for meta-learning reinforcement learning algorithms by searching over the space of computational graphs which compute the loss function for a value-based model-free RL agent to optimize. The learned algorithms are domain-agnostic and can generalize to new environments not seen during training. Our method can both learn from scratch and bootstrap off known existing algorithms, like DQN, enabling interpretable modifications which improve performance. Learning from scratch on simple classical control and gridworld tasks, our method rediscovers the temporal-difference (TD) algorithm. Bootstrapped from DQN, we highlight two learned algorithms which obtain good generalization performance over other classical control tasks, gridworld type tasks, and Atari games. The analysis of the learned algorithm behavior shows resemblance to recently proposed RL algorithms that address overestimation in value-based methods.

</p>
</details>

<details><summary><b>How to Train Your Energy-Based Models</b>
<a href="https://arxiv.org/abs/2101.03288">arxiv:2101.03288</a>
&#x1F4C8; 45 <br>
<p>Yang Song, Diederik P. Kingma</p></summary>
<p>

**Abstract:** Energy-Based Models (EBMs), also known as non-normalized probabilistic models, specify probability density or mass functions up to an unknown normalizing constant. Unlike most other probabilistic models, EBMs do not place a restriction on the tractability of the normalizing constant, thus are more flexible to parameterize and can model a more expressive family of probability distributions. However, the unknown normalizing constant of EBMs makes training particularly difficult. Our goal is to provide a friendly introduction to modern approaches for EBM training. We start by explaining maximum likelihood training with Markov chain Monte Carlo (MCMC), and proceed to elaborate on MCMC-free approaches, including Score Matching (SM) and Noise Constrastive Estimation (NCE). We highlight theoretical connections among these three approaches, and end with a brief survey on alternative training methods, which are still under active research. Our tutorial is targeted at an audience with basic understanding of generative models who want to apply EBMs or start a research project in this direction.

</p>
</details>

<details><summary><b>One-Class Classification: A Survey</b>
<a href="https://arxiv.org/abs/2101.03064">arxiv:2101.03064</a>
&#x1F4C8; 9 <br>
<p>Pramuditha Perera, Poojan Oza, Vishal M. Patel</p></summary>
<p>

**Abstract:** One-Class Classification (OCC) is a special case of multi-class classification, where data observed during training is from a single positive class. The goal of OCC is to learn a representation and/or a classifier that enables recognition of positively labeled queries during inference. This topic has received considerable amount of interest in the computer vision, machine learning and biometrics communities in recent years. In this article, we provide a survey of classical statistical and recent deep learning-based OCC methods for visual recognition. We discuss the merits and drawbacks of existing OCC approaches and identify promising avenues for research in this field. In addition, we present a discussion of commonly used datasets and evaluation metrics for OCC.

</p>
</details>

<details><summary><b>A Reinforcement Learning Based Encoder-Decoder Framework for Learning Stock Trading Rules</b>
<a href="https://arxiv.org/abs/2101.03867">arxiv:2101.03867</a>
&#x1F4C8; 8 <br>
<p>Mehran Taghian, Ahmad Asadi, Reza Safabakhsh</p></summary>
<p>

**Abstract:** A wide variety of deep reinforcement learning (DRL) models have recently been proposed to learn profitable investment strategies. The rules learned by these models outperform the previous strategies specially in high frequency trading environments. However, it is shown that the quality of the extracted features from a long-term sequence of raw prices of the instruments greatly affects the performance of the trading rules learned by these models. Employing a neural encoder-decoder structure to extract informative features from complex input time-series has proved very effective in other popular tasks like neural machine translation and video captioning in which the models face a similar problem. The encoder-decoder framework extracts highly informative features from a long sequence of prices along with learning how to generate outputs based on the extracted features. In this paper, a novel end-to-end model based on the neural encoder-decoder framework combined with DRL is proposed to learn single instrument trading strategies from a long sequence of raw prices of the instrument. The proposed model consists of an encoder which is a neural structure responsible for learning informative features from the input sequence, and a decoder which is a DRL model responsible for learning profitable strategies based on the features extracted by the encoder. The parameters of the encoder and the decoder structures are learned jointly, which enables the encoder to extract features fitted to the task of the decoder DRL. In addition, the effects of different structures for the encoder and various forms of the input sequences on the performance of the learned strategies are investigated. Experimental results showed that the proposed model outperforms other state-of-the-art models in highly dynamic environments.

</p>
</details>

<details><summary><b>Unobtrusive Pain Monitoring in Older Adults with Dementia using Pairwise and Contrastive Training</b>
<a href="https://arxiv.org/abs/2101.03251">arxiv:2101.03251</a>
&#x1F4C8; 8 <br>
<p>Siavash Rezaei, Abhishek Moturu, Shun Zhao, Kenneth M. Prkachin, Thomas Hadjistavropoulos, Babak Taati</p></summary>
<p>

**Abstract:** Although pain is frequent in old age, older adults are often undertreated for pain. This is especially the case for long-term care residents with moderate to severe dementia who cannot report their pain because of cognitive impairments that accompany dementia. Nursing staff acknowledge the challenges of effectively recognizing and managing pain in long-term care facilities due to lack of human resources and, sometimes, expertise to use validated pain assessment approaches on a regular basis. Vision-based ambient monitoring will allow for frequent automated assessments so care staff could be automatically notified when signs of pain are displayed. However, existing computer vision techniques for pain detection are not validated on faces of older adults or people with dementia, and this population is not represented in existing facial expression datasets of pain. We present the first fully automated vision-based technique validated on a dementia cohort. Our contributions are threefold. First, we develop a deep learning-based computer vision system for detecting painful facial expressions on a video dataset that is collected unobtrusively from older adult participants with and without dementia. Second, we introduce a pairwise comparative inference method that calibrates to each person and is sensitive to changes in facial expression while using training data more efficiently than sequence models. Third, we introduce a fast contrastive training method that improves cross-dataset performance. Our pain estimation model outperforms baselines by a wide margin, especially when evaluated on faces of people with dementia. Pre-trained model and demo code available at https://github.com/TaatiTeam/pain_detection_demo

</p>
</details>

<details><summary><b>Forecasting Commodity Prices Using Long Short-Term Memory Neural Networks</b>
<a href="https://arxiv.org/abs/2101.03087">arxiv:2101.03087</a>
&#x1F4C8; 8 <br>
<p>Racine Ly, Fousseini Traore, Khadim Dia</p></summary>
<p>

**Abstract:** This paper applies a recurrent neural network (RNN) method to forecast cotton and oil prices. We show how these new tools from machine learning, particularly Long-Short Term Memory (LSTM) models, complement traditional methods. Our results show that machine learning methods fit reasonably well the data but do not outperform systematically classical methods such as Autoregressive Integrated Moving Average (ARIMA) models in terms of out of sample forecasts. However, averaging the forecasts from the two type of models provide better results compared to either method. Compared to the ARIMA and the LSTM, the Root Mean Squared Error (RMSE) of the average forecast was 0.21 and 21.49 percent lower respectively for cotton. For oil, the forecast averaging does not provide improvements in terms of RMSE. We suggest using a forecast averaging method and extending our analysis to a wide range of commodity prices.

</p>
</details>

<details><summary><b>Spatial Object Recommendation with Hints: When Spatial Granularity Matters</b>
<a href="https://arxiv.org/abs/2101.02969">arxiv:2101.02969</a>
&#x1F4C8; 8 <br>
<p>Hui Luo, Jingbo Zhou, Zhifeng Bao, Shuangli Li, J. Shane Culpepper, Haochao Ying, Hao Liu, Hui Xiong</p></summary>
<p>

**Abstract:** Existing spatial object recommendation algorithms generally treat objects identically when ranking them. However, spatial objects often cover different levels of spatial granularity and thereby are heterogeneous. For example, one user may prefer to be recommended a region (say Manhattan), while another user might prefer a venue (say a restaurant). Even for the same user, preferences can change at different stages of data exploration. In this paper, we study how to support top-k spatial object recommendations at varying levels of spatial granularity, enabling spatial objects at varying granularity, such as a city, suburb, or building, as a Point of Interest (POI). To solve this problem, we propose the use of a POI tree, which captures spatial containment relationships between POIs. We design a novel multi-task learning model called MPR (short for Multi-level POI Recommendation), where each task aims to return the top-k POIs at a certain spatial granularity level. Each task consists of two subtasks: (i) attribute-based representation learning; (ii) interaction-based representation learning. The first subtask learns the feature representations for both users and POIs, capturing attributes directly from their profiles. The second subtask incorporates user-POI interactions into the model. Additionally, MPR can provide insights into why certain recommendations are being made to a user based on three types of hints: user-aspect, POI-aspect, and interaction-aspect. We empirically validate our approach using two real-life datasets, and show promising performance improvements over several state-of-the-art methods.

</p>
</details>

<details><summary><b>Detecting, Localising and Classifying Polyps from Colonoscopy Videos using Deep Learning</b>
<a href="https://arxiv.org/abs/2101.03285">arxiv:2101.03285</a>
&#x1F4C8; 7 <br>
<p>Yu Tian, Leonardo Zorron Cheng Tao Pu, Yuyuan Liu, Gabriel Maicas, Johan W. Verjans, Alastair D. Burt, Seon Ho Shin, Rajvinder Singh, Gustavo Carneiro</p></summary>
<p>

**Abstract:** In this paper, we propose and analyse a system that can automatically detect, localise and classify polyps from colonoscopy videos. The detection of frames with polyps is formulated as a few-shot anomaly classification problem, where the training set is highly imbalanced with the large majority of frames consisting of normal images and a small minority comprising frames with polyps. Colonoscopy videos may contain blurry images and frames displaying feces and water jet sprays to clean the colon -- such frames can mistakenly be detected as anomalies, so we have implemented a classifier to reject these two types of frames before polyp detection takes place. Next, given a frame containing a polyp, our method localises (with a bounding box around the polyp) and classifies it into five different classes. Furthermore, we study a method to improve the reliability and interpretability of the classification result using uncertainty estimation and classification calibration. Classification uncertainty and calibration not only help improve classification accuracy by rejecting low-confidence and high-uncertain results, but can be used by doctors to decide how to decide on the classification of a polyp. All the proposed detection, localisation and classification methods are tested using large data sets and compared with relevant baseline approaches.

</p>
</details>

<details><summary><b>From Black-box to White-box: Examining Confidence Calibration under different Conditions</b>
<a href="https://arxiv.org/abs/2101.02971">arxiv:2101.02971</a>
&#x1F4C8; 6 <br>
<p>Franziska Schwaiger, Maximilian Henne, Fabian Küppers, Felippe Schmoeller Roza, Karsten Roscher, Anselm Haselhoff</p></summary>
<p>

**Abstract:** Confidence calibration is a major concern when applying artificial neural networks in safety-critical applications. Since most research in this area has focused on classification in the past, confidence calibration in the scope of object detection has gained more attention only recently. Based on previous work, we study the miscalibration of object detection models with respect to image location and box scale. Our main contribution is to additionally consider the impact of box selection methods like non-maximum suppression to calibration. We investigate the default intrinsic calibration of object detection models and how it is affected by these post-processing techniques. For this purpose, we distinguish between black-box calibration with non-maximum suppression and white-box calibration with raw network outputs. Our experiments reveal that post-processing highly affects confidence calibration. We show that non-maximum suppression has the potential to degrade initially well-calibrated predictions, leading to overconfident and thus miscalibrated models.

</p>
</details>

<details><summary><b>Investigating the Effect of Sensor Modalities in Multi-Sensor Detection-Prediction Models</b>
<a href="https://arxiv.org/abs/2101.03279">arxiv:2101.03279</a>
&#x1F4C8; 5 <br>
<p>Abhishek Mohta, Fang-Chieh Chou, Brian C. Becker, Carlos Vallespi-Gonzalez, Nemanja Djuric</p></summary>
<p>

**Abstract:** Detection of surrounding objects and their motion prediction are critical components of a self-driving system. Recently proposed models that jointly address these tasks rely on a number of sensors to achieve state-of-the-art performance. However, this increases system complexity and may result in a brittle model that overfits to any single sensor modality while ignoring others, leading to reduced generalization. We focus on this important problem and analyze the contribution of sensor modalities towards the model performance. In addition, we investigate the use of sensor dropout to mitigate the above-mentioned issues, leading to a more robust, better-performing model on real-world driving data.

</p>
</details>

<details><summary><b>Extracting Pasture Phenotype and Biomass Percentages using Weakly Supervised Multi-target Deep Learning on a Small Dataset</b>
<a href="https://arxiv.org/abs/2101.03198">arxiv:2101.03198</a>
&#x1F4C8; 5 <br>
<p>Badri Narayanan, Mohamed Saadeldin, Paul Albert, Kevin McGuinness, Brian Mac Namee</p></summary>
<p>

**Abstract:** The dairy industry uses clover and grass as fodder for cows. Accurate estimation of grass and clover biomass yield enables smart decisions in optimizing fertilization and seeding density, resulting in increased productivity and positive environmental impact. Grass and clover are usually planted together, since clover is a nitrogen-fixing plant that brings nutrients to the soil. Adjusting the right percentages of clover and grass in a field reduces the need for external fertilization. Existing approaches for estimating the grass-clover composition of a field are expensive and time consuming - random samples of the pasture are clipped and then the components are physically separated to weigh and calculate percentages of dry grass, clover and weeds in each sample. There is growing interest in developing novel deep learning based approaches to non-destructively extract pasture phenotype indicators and biomass yield predictions of different plant species from agricultural imagery collected from the field. Providing these indicators and predictions from images alone remains a significant challenge. Heavy occlusions in the dense mixture of grass, clover and weeds make it difficult to estimate each component accurately. Moreover, although supervised deep learning models perform well with large datasets, it is tedious to acquire large and diverse collections of field images with precise ground truth for different biomass yields. In this paper, we demonstrate that applying data augmentation and transfer learning is effective in predicting multi-target biomass percentages of different plant species, even with a small training dataset. The scheme proposed in this paper used a training set of only 261 images and provided predictions of biomass percentages of grass, clover, white clover, red clover, and weeds with mean absolute error of 6.77%, 6.92%, 6.21%, 6.89%, and 4.80% respectively.

</p>
</details>

<details><summary><b>Modeling Spatial Nonstationarity via Deformable Convolutions for Deep Traffic Flow Prediction</b>
<a href="https://arxiv.org/abs/2101.12010">arxiv:2101.12010</a>
&#x1F4C8; 4 <br>
<p>Wei Zeng, Chengqiao Lin, Kang Liu, Juncong Lin, Anthony K. H. Tung</p></summary>
<p>

**Abstract:** Deep neural networks are being increasingly used for short-term traffic flow prediction, which can be generally categorized as convolutional (CNNs) or graph neural networks (GNNs). CNNs are preferable for region-wise traffic prediction by taking advantage of localized spatial correlations, whilst GNNs achieves better performance for graph-structured traffic data. When applied to region-wise traffic prediction, CNNs typically partition an underlying territory into grid-like spatial units, and employ standard convolutions to learn spatial dependence among the units. However, standard convolutions with fixed geometric structures cannot fully model the nonstationary characteristics of local traffic flows. To overcome the deficiency, we introduce deformable convolution that augments the spatial sampling locations with additional offsets, to enhance the modeling capability of spatial nonstationarity. On this basis, we design a deep deformable convolutional residual network, namely DeFlow-Net, that can effectively model global spatial dependence, local spatial nonstationarity, and temporal periodicity of traffic flows. Furthermore, to better fit with convolutions, we suggest to first aggregate traffic flows according to pre-conceived regions or self-organized regions based on traffic flows, then dispose to sequentially organized raster images for network input. Extensive experiments on real-world traffic flows demonstrate that DeFlow-Net outperforms GNNs and existing CNNs using standard convolutions, and spatial partition by pre-conceived regions or self-organized regions further enhances the performance. We also demonstrate the advantage of DeFlow-Net in maintaining spatial autocorrelation, and reveal the impacts of partition shapes and scales on deep traffic flow prediction.

</p>
</details>

<details><summary><b>Robust and Scalable Routing with Multi-Agent Deep Reinforcement Learning for MANETs</b>
<a href="https://arxiv.org/abs/2101.03273">arxiv:2101.03273</a>
&#x1F4C8; 4 <br>
<p>Saeed Kaviani, Bo Ryu, Ejaz Ahmed, Kevin A. Larson, Anh Le, Alex Yahja, Jae H. Kim</p></summary>
<p>

**Abstract:** Highly dynamic mobile ad-hoc networks (MANETs) are continuing to serve as one of the most challenging environments to develop and deploy robust, efficient, and scalable routing protocols. In this paper, we present DeepCQ+ routing which, in a novel manner, integrates emerging multi-agent deep reinforcement learning (MADRL) techniques into existing Q-learning-based routing protocols and their variants, and achieves persistently higher performance across a wide range of MANET configurations while training only on a limited range of network parameters and conditions. Quantitatively, DeepCQ+ shows consistently higher end-to-end throughput with lower overhead compared to its Q-learning-based counterparts with the overall gain of 10-15% in its efficiency. Qualitatively and more significantly, DeepCQ+ maintains remarkably similar performance gains under many scenarios that it was not trained for in terms of network sizes, mobility conditions, and traffic dynamics. To the best of our knowledge, this is the first successful demonstration of MADRL for the MANET routing problem that achieves and maintains a high degree of scalability and robustness even in the environments that are outside the trained range of scenarios. This implies that the proposed hybrid design approach of DeepCQ+ that combines MADRL and Q-learning significantly increases its practicality and explainability because the real-world MANET environment will likely vary outside the trained range of MANET scenarios.

</p>
</details>

<details><summary><b>Learning non-Gaussian graphical models via Hessian scores and triangular transport</b>
<a href="https://arxiv.org/abs/2101.03093">arxiv:2101.03093</a>
&#x1F4C8; 4 <br>
<p>Ricardo Baptista, Youssef Marzouk, Rebecca E. Morrison, Olivier Zahm</p></summary>
<p>

**Abstract:** Undirected probabilistic graphical models represent the conditional dependencies, or Markov properties, of a collection of random variables. Knowing the sparsity of such a graphical model is valuable for modeling multivariate distributions and for efficiently performing inference. While the problem of learning graph structure from data has been studied extensively for certain parametric families of distributions, most existing methods fail to consistently recover the graph structure for non-Gaussian data. Here we propose an algorithm for learning the Markov structure of continuous and non-Gaussian distributions. To characterize conditional independence, we introduce a score based on integrated Hessian information from the joint log-density, and we prove that this score upper bounds the conditional mutual information for a general class of distributions. To compute the score, our algorithm SING estimates the density using a deterministic coupling, induced by a triangular transport map, and iteratively exploits sparse structure in the map to reveal sparsity in the graph. For certain non-Gaussian datasets, we show that our algorithm recovers the graph structure even with a biased approximation to the density. Among other examples, we apply sing to learn the dependencies between the states of a chaotic dynamical system with local interactions.

</p>
</details>

<details><summary><b>Quantum Earth Mover's Distance: A New Approach to Learning Quantum Data</b>
<a href="https://arxiv.org/abs/2101.03037">arxiv:2101.03037</a>
&#x1F4C8; 4 <br>
<p>Bobak Toussi Kiani, Giacomo De Palma, Milad Marvian, Zi-Wen Liu, Seth Lloyd</p></summary>
<p>

**Abstract:** Quantifying how far the output of a learning algorithm is from its target is an essential task in machine learning. However, in quantum settings, the loss landscapes of commonly used distance metrics often produce undesirable outcomes such as poor local minima and exponentially decaying gradients. As a new approach, we consider here the quantum earth mover's (EM) or Wasserstein-1 distance, recently proposed in [De Palma et al., arXiv:2009.04469] as a quantum analog to the classical EM distance. We show that the quantum EM distance possesses unique properties, not found in other commonly used quantum distance metrics, that make quantum learning more stable and efficient. We propose a quantum Wasserstein generative adversarial network (qWGAN) which takes advantage of the quantum EM distance and provides an efficient means of performing learning on quantum data. Our qWGAN requires resources polynomial in the number of qubits, and our numerical experiments demonstrate that it is capable of learning a diverse set of quantum data.

</p>
</details>

<details><summary><b>Differentially Private Federated Learning for Cancer Prediction</b>
<a href="https://arxiv.org/abs/2101.02997">arxiv:2101.02997</a>
&#x1F4C8; 4 <br>
<p>Constance Beguier, Jean Ogier du Terrail, Iqraa Meah, Mathieu Andreux, Eric W. Tramel</p></summary>
<p>

**Abstract:** Since 2014, the NIH funded iDASH (integrating Data for Analysis, Anonymization, SHaring) National Center for Biomedical Computing has hosted yearly competitions on the topic of private computing for genomic data. For one track of the 2020 iteration of this competition, participants were challenged to produce an approach to federated learning (FL) training of genomic cancer prediction models using differential privacy (DP), with submissions ranked according to held-out test accuracy for a given set of DP budgets. More precisely, in this track, we are tasked with training a supervised model for the prediction of breast cancer occurrence from genomic data split between two virtual centers while ensuring data privacy with respect to model transfer via DP. In this article, we present our 3rd place submission to this competition. During the competition, we encountered two main challenges discussed in this article: i) ensuring correctness of the privacy budget evaluation and ii) achieving an acceptable trade-off between prediction performance and privacy budget.

</p>
</details>

<details><summary><b>NVAE-GAN Based Approach for Unsupervised Time Series Anomaly Detection</b>
<a href="https://arxiv.org/abs/2101.02908">arxiv:2101.02908</a>
&#x1F4C8; 4 <br>
<p>Liang Xu, Liying Zheng, Weijun Li, Zhenbo Chen, Weishun Song, Yue Deng, Yongzhe Chang, Jing Xiao, Bo Yuan</p></summary>
<p>

**Abstract:** In recent studies, Lots of work has been done to solve time series anomaly detection by applying Variational Auto-Encoders (VAEs). Time series anomaly detection is a very common but challenging task in many industries, which plays an important role in network monitoring, facility maintenance, information security, and so on. However, it is very difficult to detect anomalies in time series with high accuracy, due to noisy data collected from real world, and complicated abnormal patterns. From recent studies, we are inspired by Nouveau VAE (NVAE) and propose our anomaly detection model: Time series to Image VAE (T2IVAE), an unsupervised model based on NVAE for univariate series, transforming 1D time series to 2D image as input, and adopting the reconstruction error to detect anomalies. Besides, we also apply the Generative Adversarial Networks based techniques to T2IVAE training strategy, aiming to reduce the overfitting. We evaluate our model performance on three datasets, and compare it with other several popular models using F1 score. T2IVAE achieves 0.639 on Numenta Anomaly Benchmark, 0.651 on public dataset from NASA, and 0.504 on our dataset collected from real-world scenario, outperforms other comparison models.

</p>
</details>

<details><summary><b>Predicting Semen Motility using three-dimensional Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2101.02888">arxiv:2101.02888</a>
&#x1F4C8; 4 <br>
<p> Priyansi, Biswaroop Bhattacharjee, Junaid Rahim</p></summary>
<p>

**Abstract:** Manual and computer aided methods to perform semen analysis are time-consuming, requires extensive training and prone to human error. The use of classical machine learning and deep learning based methods using videos to perform semen analysis have yielded good results. The state-of-the-art method uses regular convolutional neural networks to perform quality assessments on a video of the provided sample. In this paper we propose an improved deep learning based approach using three-dimensional convolutional neural networks to predict sperm motility from microscopic videos of the semen sample. We make use of the VISEM dataset that consists of video and tabular data of semen samples collected from 85 participants. We were able to achieve good results from significantly less data points. Our models indicate that deep learning based automatic semen analysis may become a valuable and effective tool in fertility and IVF labs.

</p>
</details>

<details><summary><b>Unifying Relational Sentence Generation and Retrieval for Medical Image Report Composition</b>
<a href="https://arxiv.org/abs/2101.03287">arxiv:2101.03287</a>
&#x1F4C8; 3 <br>
<p>Fuyu Wang, Xiaodan Liang, Lin Xu, Liang Lin</p></summary>
<p>

**Abstract:** Beyond generating long and topic-coherent paragraphs in traditional captioning tasks, the medical image report composition task poses more task-oriented challenges by requiring both the highly-accurate medical term diagnosis and multiple heterogeneous forms of information including impression and findings. Current methods often generate the most common sentences due to dataset bias for individual case, regardless of whether the sentences properly capture key entities and relationships. Such limitations severely hinder their applicability and generalization capability in medical report composition where the most critical sentences lie in the descriptions of abnormal diseases that are relatively rare. Moreover, some medical terms appearing in one report are often entangled with each other and co-occurred, e.g. symptoms associated with a specific disease. To enforce the semantic consistency of medical terms to be incorporated into the final reports and encourage the sentence generation for rare abnormal descriptions, we propose a novel framework that unifies template retrieval and sentence generation to handle both common and rare abnormality while ensuring the semantic-coherency among the detected medical terms. Specifically, our approach exploits hybrid-knowledge co-reasoning: i) explicit relationships among all abnormal medical terms to induce the visual attention learning and topic representation encoding for better topic-oriented symptoms descriptions; ii) adaptive generation mode that changes between the template retrieval and sentence generation according to a contextual topic encoder. Experimental results on two medical report benchmarks demonstrate the superiority of the proposed framework in terms of both human and metrics evaluation.

</p>
</details>

<details><summary><b>Bayesian U-Net for Segmenting Glaciers in SAR Imagery</b>
<a href="https://arxiv.org/abs/2101.03249">arxiv:2101.03249</a>
&#x1F4C8; 3 <br>
<p>Andreas Hartmann, Amirabbas Davari, Thorsten Seehaus, Matthias Braun, Andreas Maier, Vincent Christlein</p></summary>
<p>

**Abstract:** Fluctuations of the glacier calving front have an important influence over the ice flow of whole glacier systems. It is therefore important to precisely monitor the position of the calving front. However, the manual delineation of SAR images is a difficult, laborious and subjective task. Convolutional neural networks have previously shown promising results in automating the glacier segmentation in SAR images, making them desirable for further exploration of their possibilities. In this work, we propose to compute uncertainty and use it in an Uncertainty Optimization regime as a novel two-stage process. By using dropout as a random sampling layer in a U-Net architecture, we create a probabilistic Bayesian Neural Network. With several forward passes, we create a sampling distribution, which can estimate the model uncertainty for each pixel in the segmentation mask. The additional uncertainty map information can serve as a guideline for the experts in the manual annotation of the data. Furthermore, feeding the uncertainty map to the network leads to 95.24% Dice similarity, which is an overall improvement in the segmentation performance compared to the state-of-the-art deterministic U-Net-based glacier segmentation pipelines.

</p>
</details>

<details><summary><b>Glacier Calving Front Segmentation Using Attention U-Net</b>
<a href="https://arxiv.org/abs/2101.03247">arxiv:2101.03247</a>
&#x1F4C8; 3 <br>
<p>Michael Holzmann, Amirabbas Davari, Thorsten Seehaus, Matthias Braun, Andreas Maier, Vincent Christlein</p></summary>
<p>

**Abstract:** An essential climate variable to determine the tidewater glacier status is the location of the calving front position and the separation of seasonal variability from long-term trends. Previous studies have proposed deep learning-based methods to semi-automatically delineate the calving fronts of tidewater glaciers. They used U-Net to segment the ice and non-ice regions and extracted the calving fronts in a post-processing step. In this work, we show a method to segment the glacier calving fronts from SAR images in an end-to-end fashion using Attention U-Net. The main objective is to investigate the attention mechanism in this application. Adding attention modules to the state-of-the-art U-Net network lets us analyze the learning process by extracting its attention maps. We use these maps as a tool to search for proper hyperparameters and loss functions in order to generate higher qualitative results. Our proposed attention U-Net performs comparably to the standard U-Net while providing additional insight into those regions on which the network learned to focus more. In the best case, the attention U-Net achieves a 1.5% better Dice score compared to the canonical U-Net with a glacier front line prediction certainty of up to 237.12 meters.

</p>
</details>

<details><summary><b>Machine learning approach for quantum non-Markovian noise classification</b>
<a href="https://arxiv.org/abs/2101.03221">arxiv:2101.03221</a>
&#x1F4C8; 3 <br>
<p>Stefano Martina, Stefano Gherardini, Filippo Caruso</p></summary>
<p>

**Abstract:** In this paper, machine learning and artificial neural network models are proposed for quantum noise classification in stochastic quantum dynamics. For this purpose, we train and then validate support vector machine, multi-layer perceptron and recurrent neural network, models with different complexity and accuracy, to solve supervised binary classification problems. By exploiting the quantum random walk formalism, we demonstrate the high efficacy of such tools in classifying noisy quantum dynamics using data sets collected in a single realisation of the quantum system evolution. In addition, we also show that for a successful classification one just needs to measure, in a sequence of discrete time instants, the probabilities that the analysed quantum system is in one of the allowed positions or energy configurations, without any external driving. Thus, neither measurements of quantum coherences nor sequences of control pulses are required. Since in principle the training of the machine learning models can be performed a-priori on synthetic data, our approach is expected to find direct application in a vast number of experimental schemes and also for the noise benchmarking of the already available noisy intermediate-scale quantum devices.

</p>
</details>

<details><summary><b>Leveraging Multilingual Transformers for Hate Speech Detection</b>
<a href="https://arxiv.org/abs/2101.03207">arxiv:2101.03207</a>
&#x1F4C8; 3 <br>
<p>Sayar Ghosh Roy, Ujwal Narayan, Tathagata Raha, Zubair Abid, Vasudeva Varma</p></summary>
<p>

**Abstract:** Detecting and classifying instances of hate in social media text has been a problem of interest in Natural Language Processing in the recent years. Our work leverages state of the art Transformer language models to identify hate speech in a multilingual setting. Capturing the intent of a post or a comment on social media involves careful evaluation of the language style, semantic content and additional pointers such as hashtags and emojis. In this paper, we look at the problem of identifying whether a Twitter post is hateful and offensive or not. We further discriminate the detected toxic content into one of the following three classes: (a) Hate Speech (HATE), (b) Offensive (OFFN) and (c) Profane (PRFN). With a pre-trained multilingual Transformer-based text encoder at the base, we are able to successfully identify and classify hate speech from multiple languages. On the provided testing corpora, we achieve Macro F1 scores of 90.29, 81.87 and 75.40 for English, German and Hindi respectively while performing hate speech detection and of 60.70, 53.28 and 49.74 during fine-grained classification. In our experiments, we show the efficacy of Perspective API features for hate speech classification and the effects of exploiting a multilingual training scheme. A feature selection study is provided to illustrate impacts of specific features upon the architecture's classification head.

</p>
</details>

<details><summary><b>Adversarial Attack Attribution: Discovering Attributable Signals in Adversarial ML Attacks</b>
<a href="https://arxiv.org/abs/2101.02899">arxiv:2101.02899</a>
&#x1F4C8; 3 <br>
<p>Marissa Dotter, Sherry Xie, Keith Manville, Josh Harguess, Colin Busho, Mikel Rodriguez</p></summary>
<p>

**Abstract:** Machine Learning (ML) models are known to be vulnerable to adversarial inputs and researchers have demonstrated that even production systems, such as self-driving cars and ML-as-a-service offerings, are susceptible. These systems represent a target for bad actors. Their disruption can cause real physical and economic harm. When attacks on production ML systems occur, the ability to attribute the attack to the responsible threat group is a critical step in formulating a response and holding the attackers accountable. We pose the following question: can adversarially perturbed inputs be attributed to the particular methods used to generate the attack? In other words, is there a way to find a signal in these attacks that exposes the attack algorithm, model architecture, or hyperparameters used in the attack? We introduce the concept of adversarial attack attribution and create a simple supervised learning experimental framework to examine the feasibility of discovering attributable signals in adversarial attacks. We find that it is possible to differentiate attacks generated with different attack algorithms, models, and hyperparameters on both the CIFAR-10 and MNIST datasets.

</p>
</details>

<details><summary><b>A general framework for modeling and dynamic simulation of multibody systems using factor graphs</b>
<a href="https://arxiv.org/abs/2101.02874">arxiv:2101.02874</a>
&#x1F4C8; 3 <br>
<p>José-Luis Blanco-Claraco, Antonio Leanza, Giulio Reina</p></summary>
<p>

**Abstract:** In this paper, we present a novel general framework grounded in the factor graph theory to solve kinematic and dynamic problems for multi-body systems. Although the motion of multi-body systems is considered to be a well-studied problem and various methods have been proposed for its solution, a unified approach providing an intuitive interpretation is still pursued. We describe how to build factor graphs to model and simulate multibody systems using both, independent and dependent coordinates. Then, batch optimization or a fixed-lag-smoother can be applied to solve the underlying optimization problem that results in a highly-sparse nonlinear minimization problem. The proposed framework has been tested in extensive simulations and validated against a commercial multibody software. We release a reference implementation as an open-source C++ library, based on the GTSAM framework, a well-known estimation library. Simulations of forward and inverse dynamics are presented, showing comparable accuracy with classical approaches. The proposed factor graph-based framework has the potential to be integrated into applications related with motion estimation and parameter identification of complex mechanical systems, ranging from mechanisms to vehicles, or robot manipulators.

</p>
</details>

<details><summary><b>Deep Learning Models May Spuriously Classify Covid-19 from X-ray Images Based on Confounders</b>
<a href="https://arxiv.org/abs/2102.04300">arxiv:2102.04300</a>
&#x1F4C8; 2 <br>
<p>Kaoutar Ben Ahmed, Lawrence O. Hall, Dmitry B. Goldgof, Gregory M. Goldgof, Rahul Paul</p></summary>
<p>

**Abstract:** Identifying who is infected with the Covid-19 virus is critical for controlling its spread. X-ray machines are widely available worldwide and can quickly provide images that can be used for diagnosis. A number of recent studies claim it may be possible to build highly accurate models, using deep learning, to detect Covid-19 from chest X-ray images. This paper explores the robustness and generalization ability of convolutional neural network models in diagnosing Covid-19 disease from frontal-view (AP/PA), raw chest X-ray images that were lung field cropped. Some concerning observations are made about high performing models that have learned to rely on confounding features related to the data source, rather than the patient's lung pathology, when differentiating between Covid-19 positive and negative labels. Specifically, these models likely made diagnoses based on confounding factors such as patient age or image processing artifacts, rather than medically relevant information.

</p>
</details>

<details><summary><b>Improving non-deterministic uncertainty modelling in Industry 4.0 scheduling</b>
<a href="https://arxiv.org/abs/2101.05677">arxiv:2101.05677</a>
&#x1F4C8; 2 <br>
<p>Ashwin Misra, Ankit Mittal, Vihaan Misra, Deepanshu Pandey</p></summary>
<p>

**Abstract:** The latest Industrial revolution has helped industries in achieving very high rates of productivity and efficiency. It has introduced data aggregation and cyber-physical systems to optimize planning and scheduling. Although, uncertainty in the environment and the imprecise nature of human operators are not accurately considered for into the decision making process. This leads to delays in consignments and imprecise budget estimations. This widespread practice in the industrial models is flawed and requires rectification. Various other articles have approached to solve this problem through stochastic or fuzzy set model methods. This paper presents a comprehensive method to logically and realistically quantify the non-deterministic uncertainty through probabilistic uncertainty modelling. This method is applicable on virtually all Industrial data sets, as the model is self adjusting and uses epsilon-contamination to cater to limited or incomplete data sets. The results are numerically validated through an Industrial data set in Flanders, Belgium. The data driven results achieved through this robust scheduling method illustrate the improvement in performance.

</p>
</details>

<details><summary><b>Identifying Human Edited Images using a CNN</b>
<a href="https://arxiv.org/abs/2101.03275">arxiv:2101.03275</a>
&#x1F4C8; 2 <br>
<p>Jordan Lee, Willy Lin, Konstantinos Ntalis, Anirudh Shah, William Tung, Maxwell Wulff</p></summary>
<p>

**Abstract:** Most non-professional photo manipulations are not made using propriety software like Adobe Photoshop, which is expensive and complicated to use for the average consumer selfie-taker or meme-maker. Instead, these individuals opt for user friendly mobile applications like FaceTune and Pixlr to make human face edits and alterations. Unfortunately, there is no existing dataset to train a model to classify these type of manipulations. In this paper, we present a generative model that approximates the distribution of human face edits and a method for detecting Facetune and Pixlr manipulations to human faces.

</p>
</details>

<details><summary><b>HypoSVI: Hypocenter inversion with Stein variational inference and Physics Informed Neural Networks</b>
<a href="https://arxiv.org/abs/2101.03271">arxiv:2101.03271</a>
&#x1F4C8; 2 <br>
<p>Jonathan D. Smith, Zachary E. Ross, Kamyar Azizzadenesheli, Jack B. Muir</p></summary>
<p>

**Abstract:** We introduce a scheme for probabilistic hypocenter inversion with Stein variational inference. Our approach uses a differentiable forward model in the form of a physics-informed neural network, which we train to solve the Eikonal equation. This allows for rapid approximation of the posterior by iteratively optimizing a collection of particles against a kernelized Stein discrepancy. We show that the method is well-equipped to handle highly non-convex posterior distributions, which are common in hypocentral inverse problems. A suite of experiments is performed to examine the influence of the various hyperparameters. Once trained, the method is valid for any network geometry within the study area without the need to build travel time tables. We show that the computational demands scale efficiently with the number of differential times, making it ideal for large-N sensing technologies like Distributed Acoustic Sensing.

</p>
</details>

<details><summary><b>Synthetic Glacier SAR Image Generation from Arbitrary Masks Using Pix2Pix Algorithm</b>
<a href="https://arxiv.org/abs/2101.03252">arxiv:2101.03252</a>
&#x1F4C8; 2 <br>
<p>Rosanna Dietrich-Sussner, Amirabbas Davari, Thorsten Seehaus, Matthias Braun, Vincent Christlein, Andreas Maier, Christian Riess</p></summary>
<p>

**Abstract:** Supervised machine learning requires a large amount of labeled data to achieve proper test results. However, generating accurately labeled segmentation maps on remote sensing imagery, including images from synthetic aperture radar (SAR), is tedious and highly subjective. In this work, we propose to alleviate the issue of limited training data by generating synthetic SAR images with the pix2pix algorithm. This algorithm uses conditional Generative Adversarial Networks (cGANs) to generate an artificial image while preserving the structure of the input. In our case, the input is a segmentation mask, from which a corresponding synthetic SAR image is generated. We present different models, perform a comparative study and demonstrate that this approach synthesizes convincing glaciers in SAR images with promising qualitative and quantitative results.

</p>
</details>

<details><summary><b>DiPSeN: Differentially Private Self-normalizing Neural Networks For Adversarial Robustness in Federated Learning</b>
<a href="https://arxiv.org/abs/2101.03218">arxiv:2101.03218</a>
&#x1F4C8; 2 <br>
<p>Olakunle Ibitoye, M. Omair Shafiq, Ashraf Matrawy</p></summary>
<p>

**Abstract:** The need for robust, secure and private machine learning is an important goal for realizing the full potential of the Internet of Things (IoT). Federated learning has proven to help protect against privacy violations and information leakage. However, it introduces new risk vectors which make machine learning models more difficult to defend against adversarial samples. In this study, we examine the role of differential privacy and self-normalization in mitigating the risk of adversarial samples specifically in a federated learning environment. We introduce DiPSeN, a Differentially Private Self-normalizing Neural Network which combines elements of differential privacy noise with self-normalizing techniques. Our empirical results on three publicly available datasets show that DiPSeN successfully improves the adversarial robustness of a deep learning classifier in a federated learning environment based on several evaluation metrics.

</p>
</details>

<details><summary><b>Graph-of-Tweets: A Graph Merging Approach to Sub-event Identification</b>
<a href="https://arxiv.org/abs/2101.03208">arxiv:2101.03208</a>
&#x1F4C8; 2 <br>
<p>Xiaonan Jing, Julia Taylor Rayz</p></summary>
<p>

**Abstract:** Graph structures are powerful tools for modeling the relationships between textual elements. Graph-of-Words (GoW) has been adopted in many Natural Language tasks to encode the association between terms. However, GoW provides few document-level relationships in cases when the connections between documents are also essential. For identifying sub-events on social media like Twitter, features from both word- and document-level can be useful as they supply different information of the event. We propose a hybrid Graph-of-Tweets (GoT) model which combines the word- and document-level structures for modeling Tweets. To compress large amount of raw data, we propose a graph merging method which utilizes FastText word embeddings to reduce the GoW. Furthermore, we present a novel method to construct GoT with the reduced GoW and a Mutual Information (MI) measure. Finally, we identify maximal cliques to extract popular sub-events. Our model showed promising results on condensing lexical-level information and capturing keywords of sub-events.

</p>
</details>

<details><summary><b>Deep Diffusion Processes for Active Learning of Hyperspectral Images</b>
<a href="https://arxiv.org/abs/2101.03197">arxiv:2101.03197</a>
&#x1F4C8; 2 <br>
<p>Abiy Tasissa, Duc Nguyen, James Murphy</p></summary>
<p>

**Abstract:** A method for active learning of hyperspectral images (HSI) is proposed, which combines deep learning with diffusion processes on graphs. A deep variational autoencoder extracts smoothed, denoised features from a high-dimensional HSI, which are then used to make labeling queries based on graph diffusion processes. The proposed method combines the robust representations of deep learning with the mathematical tractability of diffusion geometry, and leads to strong performance on real HSI.

</p>
</details>

<details><summary><b>Quantum Tensor Network in Machine Learning: An Application to Tiny Object Classification</b>
<a href="https://arxiv.org/abs/2101.03154">arxiv:2101.03154</a>
&#x1F4C8; 2 <br>
<p>Fanjie Kong, Xiao-yang Liu, Ricardo Henao</p></summary>
<p>

**Abstract:** Tiny object classification problem exists in many machine learning applications like medical imaging or remote sensing, where the object of interest usually occupies a small region of the whole image. It is challenging to design an efficient machine learning model with respect to tiny object of interest. Current neural network structures are unable to deal with tiny object efficiently because they are mainly developed for images featured by large scale objects. However, in quantum physics, there is a great theoretical foundation guiding us to analyze the target function for image classification regarding to specific objects size ratio. In our work, we apply Tensor Networks to solve this arising tough machine learning problem. First, we summarize the previous work that connects quantum spin model to image classification and bring the theory into the scenario of tiny object classification. Second, we propose using 2D multi-scale entanglement renormalization ansatz (MERA) to classify tiny objects in image. In the end, our experimental results indicate that tensor network models are effective for tiny object classification problem and potentially will beat state-of-the-art. Our codes will be available online https://github.com/timqqt/MERA_Image_Classification.

</p>
</details>

<details><summary><b>Twitch Gamers: a Dataset for Evaluating Proximity Preserving and Structural Role-based Node Embeddings</b>
<a href="https://arxiv.org/abs/2101.03091">arxiv:2101.03091</a>
&#x1F4C8; 2 <br>
<p>Benedek Rozemberczki, Rik Sarkar</p></summary>
<p>

**Abstract:** Proximity preserving and structural role-based node embeddings have become a prime workhorse of applied graph mining. Novel node embedding techniques are often tested on a restricted set of benchmark datasets. In this paper, we propose a new diverse social network dataset called Twitch Gamers with multiple potential target attributes. Our analysis of the social network and node classification experiments illustrate that Twitch Gamers is suitable for assessing the predictive performance of novel proximity preserving and structural role-based node embedding algorithms.

</p>
</details>

<details><summary><b>Knowledge AI: New Medical AI Solution for Medical image Diagnosis</b>
<a href="https://arxiv.org/abs/2101.03063">arxiv:2101.03063</a>
&#x1F4C8; 2 <br>
<p>Yingni Wang, Shuge Lei, Jian Dai, Kehong Yuan</p></summary>
<p>

**Abstract:** The implementation of medical AI has always been a problem. The effect of traditional perceptual AI algorithm in medical image processing needs to be improved. Here we propose a method of knowledge AI, which is a combination of perceptual AI and clinical knowledge and experience. Based on this method, the geometric information mining of medical images can represent the experience and information and evaluate the quality of medical images.

</p>
</details>

<details><summary><b>Approaching Neural Network Uncertainty Realism</b>
<a href="https://arxiv.org/abs/2101.02974">arxiv:2101.02974</a>
&#x1F4C8; 2 <br>
<p>Joachim Sicking, Alexander Kister, Matthias Fahrland, Stefan Eickeler, Fabian Hüger, Stefan Rüping, Peter Schlicht, Tim Wirtz</p></summary>
<p>

**Abstract:** Statistical models are inherently uncertain. Quantifying or at least upper-bounding their uncertainties is vital for safety-critical systems such as autonomous vehicles. While standard neural networks do not report this information, several approaches exist to integrate uncertainty estimates into them. Assessing the quality of these uncertainty estimates is not straightforward, as no direct ground truth labels are available. Instead, implicit statistical assessments are required. For regression, we propose to evaluate uncertainty realism -- a strict quality criterion -- with a Mahalanobis distance-based statistical test. An empirical evaluation reveals the need for uncertainty measures that are appropriate to upper-bound heavy-tailed empirical errors. Alongside, we transfer the variational U-Net classification architecture to standard supervised image-to-image tasks. We adopt it to the automotive domain and show that it significantly improves uncertainty realism compared to a plain encoder-decoder model.

</p>
</details>

<details><summary><b>Effect of Word Embedding Variable Parameters on Arabic Sentiment Analysis Performance</b>
<a href="https://arxiv.org/abs/2101.02906">arxiv:2101.02906</a>
&#x1F4C8; 2 <br>
<p>Anwar Alnawas, Nursal ARICI</p></summary>
<p>

**Abstract:** Social media such as Twitter, Facebook, etc. has led to a generated growing number of comments that contains users opinions. Sentiment analysis research deals with these comments to extract opinions which are positive or negative. Arabic language is a rich morphological language; thus, classical techniques of English sentiment analysis cannot be used for Arabic. Word embedding technique can be considered as one of successful methods to gaping the morphological problem of Arabic. Many works have been done for Arabic sentiment analysis based on word embedding, but there is no study focused on variable parameters. This study will discuss three parameters (Window size, Dimension of vector and Negative Sample) for Arabic sentiment analysis using DBOW and DMPV architectures. A large corpus of previous works generated to learn word representations and extract features. Four binary classifiers (Logistic Regression, Decision Tree, Support Vector Machine and Naive Bayes) are used to detect sentiment. The performance of classifiers evaluated based on; Precision, Recall and F1-score.

</p>
</details>

<details><summary><b>Deep Convolutional Neural Network based Classification of Alzheimer's Disease using MRI data</b>
<a href="https://arxiv.org/abs/2101.02876">arxiv:2101.02876</a>
&#x1F4C8; 2 <br>
<p>Ali Nawaz, Syed Muhammad Anwar, Rehan Liaqat, Javid Iqbal, Ulas Bagci, Muhammad Majid</p></summary>
<p>

**Abstract:** Alzheimer's disease (AD) is a progressive and incurable neurodegenerative disease which destroys brain cells and causes loss to patient's memory. An early detection can prevent the patient from further damage of the brain cells and hence avoid permanent memory loss. In past few years, various automatic tools and techniques have been proposed for diagnosis of AD. Several methods focus on fast, accurate and early detection of the disease to minimize the loss to patients mental health. Although machine learning and deep learning techniques have significantly improved medical imaging systems for AD by providing diagnostic performance close to human level. But the main problem faced during multi-class classification is the presence of highly correlated features in the brain structure. In this paper, we have proposed a smart and accurate way of diagnosing AD based on a two-dimensional deep convolutional neural network (2D-DCNN) using imbalanced three-dimensional MRI dataset. Experimental results on Alzheimer Disease Neuroimaging Initiative magnetic resonance imaging (MRI) dataset confirms that the proposed 2D-DCNN model is superior in terms of accuracy, efficiency, and robustness. The model classifies MRI into three categories: AD, mild cognitive impairment, and normal control: and has achieved 99.89% classification accuracy with imbalanced classes. The proposed model exhibits noticeable improvement in accuracy as compared to the state-fo-the-art methods.

</p>
</details>

<details><summary><b>ADiag: Graph Neural Network Based Diagnosis of Alzheimer's Disease</b>
<a href="https://arxiv.org/abs/2101.02870">arxiv:2101.02870</a>
&#x1F4C8; 2 <br>
<p>Vishnu Ram Sampathkumar</p></summary>
<p>

**Abstract:** Alzheimer's Disease (AD) is the most widespread neurodegenerative disease, affecting over 50 million people across the world. While its progression cannot be stopped, early and accurate diagnostic testing can drastically improve quality of life in patients. Currently, only qualitative means of testing are employed in the form of scoring performance on a battery of cognitive tests. The inherent disadvantage of this method is that the burden of an accurate diagnosis falls on the clinician's competence. Quantitative methods like MRI scan assessment are inaccurate at best,due to the elusive nature of visually observable changes in the brain. In lieu of these disadvantages to extant methods of AD diagnosis, we have developed ADiag, a novel quantitative method to diagnose AD through GraphSAGE Network and Dense Differentiable Pooling (DDP) analysis of large graphs based on thickness difference between different structural regions of the cortex. Preliminary tests of ADiag have revealed a robust accuracy of 83%, vastly outperforming other qualitative and quantitative diagnostic techniques.

</p>
</details>

<details><summary><b>Exploring Fault-Energy Trade-offs in Approximate DNN Hardware Accelerators</b>
<a href="https://arxiv.org/abs/2101.02860">arxiv:2101.02860</a>
&#x1F4C8; 2 <br>
<p>Ayesha Siddique, Kanad Basu, Khaza Anuarul Hoque</p></summary>
<p>

**Abstract:** Systolic array-based deep neural network (DNN) accelerators have recently gained prominence for their low computational cost. However, their high energy consumption poses a bottleneck to their deployment in energy-constrained devices. To address this problem, approximate computing can be employed at the cost of some tolerable accuracy loss. However, such small accuracy variations may increase the sensitivity of DNNs towards undesired subtle disturbances, such as permanent faults. The impact of permanent faults in accurate DNNs has been thoroughly investigated in the literature. Conversely, the impact of permanent faults in approximate DNN accelerators (AxDNNs) is yet under-explored. The impact of such faults may vary with the fault bit positions, activation functions and approximation errors in AxDNN layers. Such dynamacity poses a considerable challenge to exploring the trade-off between their energy efficiency and fault resilience in AxDNNs. Towards this, we present an extensive layer-wise and bit-wise fault resilience and energy analysis of different AxDNNs, using the state-of-the-art Evoapprox8b signed multipliers. In particular, we vary the stuck-at-0, stuck-at-1 fault-bit positions, and activation functions to study their impact using the most widely used MNIST and Fashion-MNIST datasets. Our quantitative analysis shows that the permanent faults exacerbate the accuracy loss in AxDNNs when compared to the accurate DNN accelerators. For instance, a permanent fault in AxDNNs can lead up to 66\% accuracy loss, whereas the same faulty bit can lead to only 9\% accuracy loss in an accurate DNN accelerator. Our results demonstrate that the fault resilience in AxDNNs is orthogonal to the energy efficiency.

</p>
</details>

<details><summary><b>End-to-end Prostate Cancer Detection in bpMRI via 3D CNNs: Effects of Attention Mechanisms, Clinical Priori and Decoupled False Positive Reduction</b>
<a href="https://arxiv.org/abs/2101.03244">arxiv:2101.03244</a>
&#x1F4C8; 1 <br>
<p>Anindo Saha, Matin Hosseinzadeh, Henkjan Huisman</p></summary>
<p>

**Abstract:** We present a multi-stage 3D computer-aided detection and diagnosis (CAD) model for automated localization of clinically significant prostate cancer (csPCa) in bi-parametric MR imaging (bpMRI). Deep attention mechanisms drive its detection network, targeting salient structures and highly discriminative feature dimensions across multiple resolutions. Its goal is to accurately identify csPCa lesions from indolent cancer and the wide range of benign pathology that can afflict the prostate gland. Simultaneously, a decoupled residual classifier is used to achieve consistent false positive reduction, without sacrificing high sensitivity or computational efficiency. In order to guide model generalization with domain-specific clinical knowledge, a probabilistic anatomical prior is used to encode the spatial prevalence and zonal distinction of csPCa. Using a large dataset of 1950 prostate bpMRI paired with radiologically-estimated annotations, we hypothesize that such CNN-based models can be trained to detect biopsy-confirmed malignancies in an independent cohort.
  For 486 institutional testing scans, the 3D CAD system achieves 83.69$\pm$5.22% and 93.19$\pm$2.96% detection sensitivity at 0.50 and 1.46 false positive(s) per patient, respectively, with 0.882$\pm$0.030 AUROC in patient-based diagnosis $-$significantly outperforming four state-of-the-art baseline architectures (U-SEResNet, UNet++, nnU-Net, Attention U-Net) from recent literature. For 296 external biopsy-confirmed testing scans, the ensembled CAD system shares moderate agreement with a consensus of expert radiologists (76.69%; $kappa$ $=$ 0.51$\pm$0.04) and independent pathologists (81.08%; $kappa$ $=$ 0.56$\pm$0.06); demonstrating strong generalization to histologically-confirmed csPCa diagnosis.

</p>
</details>

<details><summary><b>Slow manifolds in recurrent networks encode working memory efficiently and robustly</b>
<a href="https://arxiv.org/abs/2101.03163">arxiv:2101.03163</a>
&#x1F4C8; 1 <br>
<p>Elham Ghazizadeh, ShiNung Ching</p></summary>
<p>

**Abstract:** Working memory is a cognitive function involving the storage and manipulation of latent information over brief intervals of time, thus making it crucial for context-dependent computation. Here, we use a top-down modeling approach to examine network-level mechanisms of working memory, an enigmatic issue and central topic of study in neuroscience and machine intelligence. We train thousands of recurrent neural networks on a working memory task and then perform dynamical systems analysis on the ensuing optimized networks, wherein we find that four distinct dynamical mechanisms can emerge. In particular, we show the prevalence of a mechanism in which memories are encoded along slow stable manifolds in the network state space, leading to a phasic neuronal activation profile during memory periods. In contrast to mechanisms in which memories are directly encoded at stable attractors, these networks naturally forget stimuli over time. Despite this seeming functional disadvantage, they are more efficient in terms of how they leverage their attractor landscape and paradoxically, are considerably more robust to noise. Our results provide new dynamical hypotheses regarding how working memory function is encoded in both natural and artificial neural networks.

</p>
</details>

<details><summary><b>Simulating SQL Injection Vulnerability Exploitation Using Q-Learning Reinforcement Learning Agents</b>
<a href="https://arxiv.org/abs/2101.03118">arxiv:2101.03118</a>
&#x1F4C8; 1 <br>
<p>Laszlo Erdodi, Åvald Åslaugson Sommervoll, Fabio Massimo Zennaro</p></summary>
<p>

**Abstract:** In this paper, we propose a formalization of the process of exploitation of SQL injection vulnerabilities. We consider a simplification of the dynamics of SQL injection attacks by casting this problem as a security capture-the-flag challenge. We model it as a Markov decision process, and we implement it as a reinforcement learning problem. We then deploy reinforcement learning agents tasked with learning an effective policy to perform SQL injection; we design our training in such a way that the agent learns not just a specific strategy to solve an individual challenge but a more generic policy that may be applied to perform SQL injection attacks against any system instantiated randomly by our problem generator. We analyze the results in terms of the quality of the learned policy and in terms of convergence time as a function of the complexity of the challenge and the learning agent's complexity. Our work fits in the wider research on the development of intelligent agents for autonomous penetration testing and white-hat hacking, and our results aim to contribute to understanding the potential and the limits of reinforcement learning in a security environment.

</p>
</details>

<details><summary><b>A review for Tone-mapping Operators on Wide Dynamic Range Image</b>
<a href="https://arxiv.org/abs/2101.03003">arxiv:2101.03003</a>
&#x1F4C8; 1 <br>
<p>Ziyi Liu</p></summary>
<p>

**Abstract:** The dynamic range of our normal life can exceeds 120 dB, however, the smart-phone cameras and the conventional digital cameras can only capture a dynamic range of 90 dB, which sometimes leads to loss of details for the recorded image. Now, some professional hardware applications and image fusion algorithms have been devised to take wide dynamic range (WDR), but unfortunately existing devices cannot display WDR image. Tone mapping (TM) thus becomes an essential step for exhibiting WDR image on our ordinary screens, which convert the WDR image into low dynamic range (LDR) image. More and more researchers are focusing on this topic, and give their efforts to design an excellent tone mapping operator (TMO), showing detailed images as the same as the perception that human eyes could receive. Therefore, it is important for us to know the history, development, and trend of TM before proposing a practicable TMO. In this paper, we present a comprehensive study of the most well-known TMOs, which divides TMOs into traditional and machine learning-based category.

</p>
</details>

<details><summary><b>Infinite-dimensional Folded-in-time Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2101.02966">arxiv:2101.02966</a>
&#x1F4C8; 1 <br>
<p>Florian Stelzer, Serhiy Yanchuk</p></summary>
<p>

**Abstract:** The method recently introduced in arXiv:2011.10115 realizes a deep neural network with just a single nonlinear element and delayed feedback. It is applicable for the description of physically implemented neural networks. In this work, we present an infinite-dimensional generalization, which allows for a more rigorous mathematical analysis and a higher flexibility in choosing the weight functions. Precisely speaking, the weights are described by Lebesgue integrable functions instead of step functions. We also provide a functional back-propagation algorithm, which enables gradient descent training of the weights. In addition, with a slight modification, our concept realizes recurrent neural networks.

</p>
</details>

<details><summary><b>Symmetry-adapted graph neural networks for constructing molecular dynamics force fields</b>
<a href="https://arxiv.org/abs/2101.02930">arxiv:2101.02930</a>
&#x1F4C8; 1 <br>
<p>Zun Wang, Chong Wang, Sibo Zhao, Shiqiao Du, Yong Xu, Bing-Lin Gu, Wenhui Duan</p></summary>
<p>

**Abstract:** Molecular dynamics is a powerful simulation tool to explore material properties. Most of the realistic material systems are too large to be simulated with first-principles molecular dynamics. Classical molecular dynamics has lower computational cost but requires accurate force fields to achieve chemical accuracy. In this work, we develop a symmetry-adapted graph neural networks framework, named molecular dynamics graph neural networks (MDGNN), to construct force fields automatically for molecular dynamics simulations for both molecules and crystals. This architecture consistently preserves the translation, rotation and permutation invariance in the simulations. We propose a new feature engineering method including higher order contributions and show that MDGNN accurately reproduces the results of both classical and first-principles molecular dynamics. We also demonstrate that force fields constructed by the model has good transferability. Therefore, MDGNN provides an efficient and promising option for molecular dynamics simulations of large scale systems with high accuracy.

</p>
</details>

<details><summary><b>Approximate Query Processing for Group-By Queries based on Conditional Generative Models</b>
<a href="https://arxiv.org/abs/2101.02914">arxiv:2101.02914</a>
&#x1F4C8; 1 <br>
<p>Meifan Zhang, Hongzhi Wang</p></summary>
<p>

**Abstract:** The Group-By query is an important kind of query, which is common and widely used in data warehouses, data analytics, and data visualization. Approximate query processing is an effective way to increase the querying efficiency on big data. The answer to a group-by query involves multiple values, which makes it difficult to provide sufficiently accurate estimations for all the groups. Stratified sampling improves the accuracy compared with the uniform sampling, but the samples chosen for some special queries cannot work for other queries. Online sampling chooses samples for the given query at query time, but it requires a long latency. Thus, it is a challenge to achieve both accuracy and efficiency at the same time. Facing such challenge, in this work, we propose a sample generation framework based on a conditional generative model. The sample generation framework can generate any number of samples for the given query without accessing the data. The proposed framework based on the lightweight model can be combined with stratified sampling and online aggregation to improve the estimation accuracy for group-by queries. The experimental results show that our proposed methods are both efficient and accurate.

</p>
</details>

<details><summary><b>Spending Your Winning Lottery Better After Drawing It</b>
<a href="https://arxiv.org/abs/2101.03255">arxiv:2101.03255</a>
&#x1F4C8; 0 <br>
<p>Ajay Kumar Jaiswal, Haoyu Ma, Tianlong Chen, Ying Ding, Zhangyang Wang</p></summary>
<p>

**Abstract:** Lottery Ticket Hypothesis (LTH) suggests that a dense neural network contains a sparse sub-network that can match the performance of the original dense network when trained in isolation from scratch. Most works retrain the sparse sub-network with the same training protocols as its dense network, such as initialization, architecture blocks, and training recipes. However, till now it is unclear that whether these training protocols are optimal for sparse networks.
  In this paper, we demonstrate that it is unnecessary for spare retraining to strictly inherit those properties from the dense network. Instead, by plugging in purposeful "tweaks" of the sparse subnetwork architecture or its training recipe, its retraining can be significantly improved than the default, especially at high sparsity levels. Combining all our proposed "tweaks" can yield the new state-of-the-art performance of LTH, and these modifications can be easily adapted to other sparse training algorithms in general. Specifically, we have achieved a significant and consistent performance gain of1.05% - 4.93% for ResNet18 on CIFAR-100 over vanilla-LTH. Moreover, our methods are shown to generalize across datasets (CIFAR10, CIFAR100, TinyImageNet) and architectures (Vgg16, ResNet-18/ResNet-34, MobileNet). All codes will be publicly available.

</p>
</details>

<details><summary><b>Sketching Merge Trees for Scientific Data Visualization</b>
<a href="https://arxiv.org/abs/2101.03196">arxiv:2101.03196</a>
&#x1F4C8; 0 <br>
<p>Mingzhe Li, Sourabh Palande, Lin Yan, Bei Wang</p></summary>
<p>

**Abstract:** Merge trees are a type of topological descriptors that record the connectivity among the sublevel sets of scalar fields. They are among the most widely used topological tools in visualization. In this paper, we are interested in sketching a set of merge trees. That is, given a large set T of merge trees, we would like to find a much smaller basis set S such that each tree in T can be approximately reconstructed from a linear combination of merge trees in S. A set of high-dimensional vectors can be sketched via matrix sketching techniques such as principal component analysis and column subset selection. However, up until now, topological descriptors such as merge trees have not been known to be sketchable. We develop a framework for sketching a set of merge trees that combines the Gromov-Wasserstein probabilistic matching with techniques from matrix sketching. We demonstrate the applications of our framework in sketching merge trees that arise from time-varying scientific simulations. Specifically, our framework obtains a much smaller representation of a large set of merge trees for downstream analysis and visualization. It is shown to be useful in identifying good representatives and outliers with respect to a chosen basis. Finally, our work shows a promising direction of utilizing randomized linear algebra within scientific visualization.

</p>
</details>

<details><summary><b>E(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials</b>
<a href="https://arxiv.org/abs/2101.03164">arxiv:2101.03164</a>
&#x1F4C8; 0 <br>
<p>Simon Batzner, Albert Musaelian, Lixin Sun, Mario Geiger, Jonathan P. Mailoa, Mordechai Kornbluth, Nicola Molinari, Tess E. Smidt, Boris Kozinsky</p></summary>
<p>

**Abstract:** This work presents Neural Equivariant Interatomic Potentials (NequIP), an E(3)-equivariant neural network approach for learning interatomic potentials from ab-initio calculations for molecular dynamics simulations. While most contemporary symmetry-aware models use invariant convolutions and only act on scalars, NequIP employs E(3)-equivariant convolutions for interactions of geometric tensors, resulting in a more information-rich and faithful representation of atomic environments. The method achieves state-of-the-art accuracy on a challenging and diverse set of molecules and materials while exhibiting remarkable data efficiency. NequIP outperforms existing models with up to three orders of magnitude fewer training data, challenging the widely held belief that deep neural networks require massive training sets. The high data efficiency of the method allows for the construction of accurate potentials using high-order quantum chemical level of theory as reference and enables high-fidelity molecular dynamics simulations over long time scales.

</p>
</details>

<details><summary><b>Controllable reset behavior in domain wall-magnetic tunnel junction artificial neurons for task-adaptable computation</b>
<a href="https://arxiv.org/abs/2101.03095">arxiv:2101.03095</a>
&#x1F4C8; 0 <br>
<p>Samuel Liu, Christopher H. Bennett, Joseph S. Friedman, Matthew J. Marinella, David Paydarfar, Jean Anne C. Incorvia</p></summary>
<p>

**Abstract:** Neuromorphic computing with spintronic devices has been of interest due to the limitations of CMOS-driven von Neumann computing. Domain wall-magnetic tunnel junction (DW-MTJ) devices have been shown to be able to intrinsically capture biological neuron behavior. Edgy-relaxed behavior, where a frequently firing neuron experiences a lower action potential threshold, may provide additional artificial neuronal functionality when executing repeated tasks. In this study, we demonstrate that this behavior can be implemented in DW-MTJ artificial neurons via three alternative mechanisms: shape anisotropy, magnetic field, and current-driven soft reset. Using micromagnetics and analytical device modeling to classify the Optdigits handwritten digit dataset, we show that edgy-relaxed behavior improves both classification accuracy and classification rate for ordered datasets while sacrificing little to no accuracy for a randomized dataset. This work establishes methods by which artificial spintronic neurons can be flexibly adapted to datasets.

</p>
</details>

<details><summary><b>Multistage BiCross encoder for multilingual access to COVID-19 health information</b>
<a href="https://arxiv.org/abs/2101.03013">arxiv:2101.03013</a>
&#x1F4C8; 0 <br>
<p>Iknoor Singh, Carolina Scarton, Kalina Bontcheva</p></summary>
<p>

**Abstract:** The Coronavirus (COVID-19) pandemic has led to a rapidly growing 'infodemic' of health information online. This has motivated the need for accurate semantic search and retrieval of reliable COVID-19 information across millions of documents, in multiple languages. To address this challenge, this paper proposes a novel high precision and high recall neural Multistage BiCross encoder approach. It is a sequential three-stage ranking pipeline which uses the Okapi BM25 retrieval algorithm and transformer-based bi-encoder and cross-encoder to effectively rank the documents with respect to the given query. We present experimental results from our participation in the Multilingual Information Access (MLIA) shared task on COVID-19 multilingual semantic search. The independently evaluated MLIA results validate our approach and demonstrate that it outperforms other state-of-the-art approaches according to nearly all evaluation metrics in cases of both monolingual and bilingual runs.

</p>
</details>

<details><summary><b>Block-Term Tensor Decomposition Model Selection and Computation: The Bayesian Way</b>
<a href="https://arxiv.org/abs/2101.02931">arxiv:2101.02931</a>
&#x1F4C8; 0 <br>
<p>Paris V. Giampouras, Athanasios A. Rontogiannis, Eleftherios Kofidis</p></summary>
<p>

**Abstract:** The so-called block-term decomposition (BTD) tensor model, especially in its rank-$(L_r,L_r,1)$ version, has been recently receiving increasing attention due to its enhanced ability of representing systems and signals that are composed of \emph{blocks} of rank higher than one, a scenario encountered in numerous and diverse applications. Uniqueness conditions and fitting methods have thus been thoroughly studied. Nevertheless, the challenging problem of estimating the BTD model structure, namely the number of block terms, $R$, and their individual ranks, $L_r$, has only recently started to attract significant attention, mainly through regularization-based approaches which entail the need to tune the regularization parameter(s). In this work, we build on ideas of sparse Bayesian learning (SBL) and put forward a fully automated Bayesian approach. Through a suitably crafted multi-level \emph{hierarchical} probabilistic model, which gives rise to heavy-tailed prior distributions for the BTD factors, structured sparsity is \emph{jointly} imposed. Ranks are then estimated from the numbers of blocks ($R$) and columns ($L_r$) of non-negligible energy. Approximate posterior inference is implemented, within the variational inference framework. The resulting iterative algorithm completely avoids hyperparameter tuning, which is a significant defect of regularization-based methods. Alternative probabilistic models are also explored and the connections with their regularization-based counterparts are brought to light with the aid of the associated maximum a-posteriori (MAP) estimators. We report simulation results with both synthetic and real-word data, which demonstrate the merits of the proposed method in terms of both rank estimation and model fitting as compared to state-of-the-art relevant methods.

</p>
</details>


{% endraw %}
Prev: [2021.01.07]({{ '/2021/01/07/2021.01.07.html' | relative_url }})  Next: [2021.01.09]({{ '/2021/01/09/2021.01.09.html' | relative_url }})