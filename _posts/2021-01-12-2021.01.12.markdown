Prev: [2021.01.11]({{ '/2021/01/11/2021.01.11.html' | relative_url }})  Next: [2021.01.13]({{ '/2021/01/13/2021.01.13.html' | relative_url }})
{% raw %}
## Summary for 2021-01-12, created on 2021-12-24


<details><summary><b>SEED: Self-supervised Distillation For Visual Representation</b>
<a href="https://arxiv.org/abs/2101.04731">arxiv:2101.04731</a>
&#x1F4C8; 67 <br>
<p>Zhiyuan Fang, Jianfeng Wang, Lijuan Wang, Lei Zhang, Yezhou Yang, Zicheng Liu</p></summary>
<p>

**Abstract:** This paper is concerned with self-supervised learning for small models. The problem is motivated by our empirical studies that while the widely used contrastive self-supervised learning method has shown great progress on large model training, it does not work well for small models. To address this problem, we propose a new learning paradigm, named SElf-SupErvised Distillation (SEED), where we leverage a larger network (as Teacher) to transfer its representational knowledge into a smaller architecture (as Student) in a self-supervised fashion. Instead of directly learning from unlabeled data, we train a student encoder to mimic the similarity score distribution inferred by a teacher over a set of instances. We show that SEED dramatically boosts the performance of small networks on downstream tasks. Compared with self-supervised baselines, SEED improves the top-1 accuracy from 42.2% to 67.6% on EfficientNet-B0 and from 36.3% to 68.2% on MobileNet-v3-Large on the ImageNet-1k dataset.

</p>
</details>

<details><summary><b>Robustness Gym: Unifying the NLP Evaluation Landscape</b>
<a href="https://arxiv.org/abs/2101.04840">arxiv:2101.04840</a>
&#x1F4C8; 48 <br>
<p>Karan Goel, Nazneen Rajani, Jesse Vig, Samson Tan, Jason Wu, Stephan Zheng, Caiming Xiong, Mohit Bansal, Christopher Ré</p></summary>
<p>

**Abstract:** Despite impressive performance on standard benchmarks, deep neural networks are often brittle when deployed in real-world systems. Consequently, recent research has focused on testing the robustness of such models, resulting in a diverse set of evaluation methodologies ranging from adversarial attacks to rule-based data transformations. In this work, we identify challenges with evaluating NLP systems and propose a solution in the form of Robustness Gym (RG), a simple and extensible evaluation toolkit that unifies 4 standard evaluation paradigms: subpopulations, transformations, evaluation sets, and adversarial attacks. By providing a common platform for evaluation, Robustness Gym enables practitioners to compare results from all 4 evaluation paradigms with just a few clicks, and to easily develop and share novel evaluation methods using a built-in set of abstractions. To validate Robustness Gym's utility to practitioners, we conducted a real-world case study with a sentiment-modeling team, revealing performance degradations of 18%+. To verify that Robustness Gym can aid novel research analyses, we perform the first study of state-of-the-art commercial and academic named entity linking (NEL) systems, as well as a fine-grained analysis of state-of-the-art summarization models. For NEL, commercial systems struggle to link rare entities and lag their academic counterparts by 10%+, while state-of-the-art summarization models struggle on examples that require abstraction and distillation, degrading by 9%+. Robustness Gym can be found at https://robustnessgym.com/

</p>
</details>

<details><summary><b>Benchmarking Simulation-Based Inference</b>
<a href="https://arxiv.org/abs/2101.04653">arxiv:2101.04653</a>
&#x1F4C8; 38 <br>
<p>Jan-Matthis Lueckmann, Jan Boelts, David S. Greenberg, Pedro J. Gonçalves, Jakob H. Macke</p></summary>
<p>

**Abstract:** Recent advances in probabilistic modelling have led to a large number of simulation-based inference algorithms which do not require numerical evaluation of likelihoods. However, a public benchmark with appropriate performance metrics for such 'likelihood-free' algorithms has been lacking. This has made it difficult to compare algorithms and identify their strengths and weaknesses. We set out to fill this gap: We provide a benchmark with inference tasks and suitable performance metrics, with an initial selection of algorithms including recent approaches employing neural networks and classical Approximate Bayesian Computation methods. We found that the choice of performance metric is critical, that even state-of-the-art algorithms have substantial room for improvement, and that sequential estimation improves sample efficiency. Neural network-based approaches generally exhibit better performance, but there is no uniformly best algorithm. We provide practical advice and highlight the potential of the benchmark to diagnose problems and improve algorithms. The results can be explored interactively on a companion website. All code is open source, making it possible to contribute further benchmark tasks and inference algorithms.

</p>
</details>

<details><summary><b>Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis</b>
<a href="https://arxiv.org/abs/2101.04775">arxiv:2101.04775</a>
&#x1F4C8; 32 <br>
<p>Bingchen Liu, Yizhe Zhu, Kunpeng Song, Ahmed Elgammal</p></summary>
<p>

**Abstract:** Training Generative Adversarial Networks (GAN) on high-fidelity images usually requires large-scale GPU-clusters and a vast number of training images. In this paper, we study the few-shot image synthesis task for GAN with minimum computing cost. We propose a light-weight GAN structure that gains superior quality on 1024*1024 resolution. Notably, the model converges from scratch with just a few hours of training on a single RTX-2080 GPU, and has a consistent performance, even with less than 100 training samples. Two technique designs constitute our work, a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. With thirteen datasets covering a wide variety of image domains (The datasets and code are available at: https://github.com/odegeasslbc/FastGAN-pytorch), we show our model's superior performance compared to the state-of-the-art StyleGAN2, when data and computing budget are limited.

</p>
</details>

<details><summary><b>Learning Intuitive Physics with Multimodal Generative Models</b>
<a href="https://arxiv.org/abs/2101.04454">arxiv:2101.04454</a>
&#x1F4C8; 24 <br>
<p>Sahand Rezaei-Shoshtari, Francois Robert Hogan, Michael Jenkin, David Meger, Gregory Dudek</p></summary>
<p>

**Abstract:** Predicting the future interaction of objects when they come into contact with their environment is key for autonomous agents to take intelligent and anticipatory actions. This paper presents a perception framework that fuses visual and tactile feedback to make predictions about the expected motion of objects in dynamic scenes. Visual information captures object properties such as 3D shape and location, while tactile information provides critical cues about interaction forces and resulting object motion when it makes contact with the environment. Utilizing a novel See-Through-your-Skin (STS) sensor that provides high resolution multimodal sensing of contact surfaces, our system captures both the visual appearance and the tactile properties of objects. We interpret the dual stream signals from the sensor using a Multimodal Variational Autoencoder (MVAE), allowing us to capture both modalities of contacting objects and to develop a mapping from visual to tactile interaction and vice-versa. Additionally, the perceptual system can be used to infer the outcome of future physical interactions, which we validate through simulated and real-world experiments in which the resting state of an object is predicted from given initial conditions.

</p>
</details>

<details><summary><b>Expanding Explainability: Towards Social Transparency in AI systems</b>
<a href="https://arxiv.org/abs/2101.04719">arxiv:2101.04719</a>
&#x1F4C8; 19 <br>
<p>Upol Ehsan, Q. Vera Liao, Michael Muller, Mark O. Riedl, Justin D. Weisz</p></summary>
<p>

**Abstract:** As AI-powered systems increasingly mediate consequential decision-making, their explainability is critical for end-users to take informed and accountable actions. Explanations in human-human interactions are socially-situated. AI systems are often socio-organizationally embedded. However, Explainable AI (XAI) approaches have been predominantly algorithm-centered. We take a developmental step towards socially-situated XAI by introducing and exploring Social Transparency (ST), a sociotechnically informed perspective that incorporates the socio-organizational context into explaining AI-mediated decision-making. To explore ST conceptually, we conducted interviews with 29 AI users and practitioners grounded in a speculative design scenario. We suggested constitutive design elements of ST and developed a conceptual framework to unpack ST's effect and implications at the technical, decision-making, and organizational level. The framework showcases how ST can potentially calibrate trust in AI, improve decision-making, facilitate organizational collective actions, and cultivate holistic explainability. Our work contributes to the discourse of Human-Centered XAI by expanding the design space of XAI.

</p>
</details>

<details><summary><b>Whither AutoML? Understanding the Role of Automation in Machine Learning Workflows</b>
<a href="https://arxiv.org/abs/2101.04834">arxiv:2101.04834</a>
&#x1F4C8; 10 <br>
<p>Doris Xin, Eva Yiwei Wu, Doris Jung-Lin Lee, Niloufar Salehi, Aditya Parameswaran</p></summary>
<p>

**Abstract:** Efforts to make machine learning more widely accessible have led to a rapid increase in Auto-ML tools that aim to automate the process of training and deploying machine learning. To understand how Auto-ML tools are used in practice today, we performed a qualitative study with participants ranging from novice hobbyists to industry researchers who use Auto-ML tools. We present insights into the benefits and deficiencies of existing tools, as well as the respective roles of the human and automation in ML workflows. Finally, we discuss design implications for the future of Auto-ML tool development. We argue that instead of full automation being the ultimate goal of Auto-ML, designers of these tools should focus on supporting a partnership between the user and the Auto-ML tool. This means that a range of Auto-ML tools will need to be developed to support varying user goals such as simplicity, reproducibility, and reliability.

</p>
</details>

<details><summary><b>On the Calibration and Uncertainty of Neural Learning to Rank Models</b>
<a href="https://arxiv.org/abs/2101.04356">arxiv:2101.04356</a>
&#x1F4C8; 10 <br>
<p>Gustavo Penha, Claudia Hauff</p></summary>
<p>

**Abstract:** According to the Probability Ranking Principle (PRP), ranking documents in decreasing order of their probability of relevance leads to an optimal document ranking for ad-hoc retrieval. The PRP holds when two conditions are met: [C1] the models are well calibrated, and, [C2] the probabilities of relevance are reported with certainty. We know however that deep neural networks (DNNs) are often not well calibrated and have several sources of uncertainty, and thus [C1] and [C2] might not be satisfied by neural rankers. Given the success of neural Learning to Rank (L2R) approaches-and here, especially BERT-based approaches-we first analyze under which circumstances deterministic, i.e. outputs point estimates, neural rankers are calibrated. Then, motivated by our findings we use two techniques to model the uncertainty of neural rankers leading to the proposed stochastic rankers, which output a predictive distribution of relevance as opposed to point estimates. Our experimental results on the ad-hoc retrieval task of conversation response ranking reveal that (i) BERT-based rankers are not robustly calibrated and that stochastic BERT-based rankers yield better calibration; and (ii) uncertainty estimation is beneficial for both risk-aware neural ranking, i.e.taking into account the uncertainty when ranking documents, and for predicting unanswerable conversational contexts.

</p>
</details>

<details><summary><b>Practical Speech Re-use Prevention in Voice-driven Services</b>
<a href="https://arxiv.org/abs/2101.04773">arxiv:2101.04773</a>
&#x1F4C8; 9 <br>
<p>Yangyong Zhang, Maliheh Shirvanian, Sunpreet S. Arora, Jianwei Huang, Guofei Gu</p></summary>
<p>

**Abstract:** Voice-driven services (VDS) are being used in a variety of applications ranging from smart home control to payments using digital assistants. The input to such services is often captured via an open voice channel, e.g., using a microphone, in an unsupervised setting. One of the key operational security requirements in such setting is the freshness of the input speech. We present AEOLUS, a security overlay that proactively embeds a dynamic acoustic nonce at the time of user interaction, and detects the presence of the embedded nonce in the recorded speech to ensure freshness. We demonstrate that acoustic nonce can (i) be reliably embedded and retrieved, and (ii) be non-disruptive (and even imperceptible) to a VDS user. Optimal parameters (acoustic nonce's operating frequency, amplitude, and bitrate) are determined for (i) and (ii) from a practical perspective. Experimental results show that AEOLUS yields 0.5% FRR at 0% FAR for speech re-use prevention upto a distance of 4 meters in three real-world environments with different background noise levels. We also conduct a user study with 120 participants, which shows that the acoustic nonce does not degrade overall user experience for 94.16% of speech samples, on average, in these environments. AEOLUS can therefore be used in practice to prevent speech re-use and ensure the freshness of speech input.

</p>
</details>

<details><summary><b>Bootstrapping Motor Skill Learning with Motion Planning</b>
<a href="https://arxiv.org/abs/2101.04736">arxiv:2101.04736</a>
&#x1F4C8; 9 <br>
<p>Ben Abbatematteo, Eric Rosen, Stefanie Tellex, George Konidaris</p></summary>
<p>

**Abstract:** Learning a robot motor skill from scratch is impractically slow; so much so that in practice, learning must be bootstrapped using a good skill policy obtained from human demonstration. However, relying on human demonstration necessarily degrades the autonomy of robots that must learn a wide variety of skills over their operational lifetimes. We propose using kinematic motion planning as a completely autonomous, sample efficient way to bootstrap motor skill learning for object manipulation. We demonstrate the use of motion planners to bootstrap motor skills in two complex object manipulation scenarios with different policy representations: opening a drawer with a dynamic movement primitive representation, and closing a microwave door with a deep neural network policy. We also show how our method can bootstrap a motor skill for the challenging dynamic task of learning to hit a ball off a tee, where a kinematic plan based on treating the scene as static is insufficient to solve the task, but sufficient to bootstrap a more dynamic policy. In all three cases, our method is competitive with human-demonstrated initialization, and significantly outperforms starting with a random policy. This approach enables robots to to efficiently and autonomously learn motor policies for dynamic tasks without human demonstration.

</p>
</details>

<details><summary><b>Quantum Cognitively Motivated Decision Fusion for Video Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2101.04406">arxiv:2101.04406</a>
&#x1F4C8; 9 <br>
<p>Dimitris Gkoumas, Qiuchi Li, Shahram Dehdashti, Massimo Melucci, Yijun Yu, Dawei Song</p></summary>
<p>

**Abstract:** Video sentiment analysis as a decision-making process is inherently complex, involving the fusion of decisions from multiple modalities and the so-caused cognitive biases. Inspired by recent advances in quantum cognition, we show that the sentiment judgment from one modality could be incompatible with the judgment from another, i.e., the order matters and they cannot be jointly measured to produce a final decision. Thus the cognitive process exhibits "quantum-like" biases that cannot be captured by classical probability theories. Accordingly, we propose a fundamentally new, quantum cognitively motivated fusion strategy for predicting sentiment judgments. In particular, we formulate utterances as quantum superposition states of positive and negative sentiment judgments, and uni-modal classifiers as mutually incompatible observables, on a complex-valued Hilbert space with positive-operator valued measures. Experiments on two benchmarking datasets illustrate that our model significantly outperforms various existing decision level and a range of state-of-the-art content-level fusion approaches. The results also show that the concept of incompatibility allows effective handling of all combination patterns, including those extreme cases that are wrongly predicted by all uni-modal classifiers.

</p>
</details>

<details><summary><b>Probabilistic Metric Learning with Adaptive Margin for Top-K Recommendation</b>
<a href="https://arxiv.org/abs/2101.04849">arxiv:2101.04849</a>
&#x1F4C8; 7 <br>
<p>Chen Ma, Liheng Ma, Yingxue Zhang, Ruiming Tang, Xue Liu, Mark Coates</p></summary>
<p>

**Abstract:** Personalized recommender systems are playing an increasingly important role as more content and services become available and users struggle to identify what might interest them. Although matrix factorization and deep learning based methods have proved effective in user preference modeling, they violate the triangle inequality and fail to capture fine-grained preference information. To tackle this, we develop a distance-based recommendation model with several novel aspects: (i) each user and item are parameterized by Gaussian distributions to capture the learning uncertainties; (ii) an adaptive margin generation scheme is proposed to generate the margins regarding different training triplets; (iii) explicit user-user/item-item similarity modeling is incorporated in the objective function. The Wasserstein distance is employed to determine preferences because it obeys the triangle inequality and can measure the distance between probabilistic distributions. Via a comparison using five real-world datasets with state-of-the-art methods, the proposed model outperforms the best existing models by 4-22% in terms of recall@K on Top-K recommendation.

</p>
</details>

<details><summary><b>MP3net: coherent, minute-long music generation from raw audio with a simple convolutional GAN</b>
<a href="https://arxiv.org/abs/2101.04785">arxiv:2101.04785</a>
&#x1F4C8; 7 <br>
<p>Korneel van den Broek</p></summary>
<p>

**Abstract:** We present a deep convolutional GAN which leverages techniques from MP3/Vorbis audio compression to produce long, high-quality audio samples with long-range coherence. The model uses a Modified Discrete Cosine Transform (MDCT) data representation, which includes all phase information. Phase generation is hence integral part of the model. We leverage the auditory masking and psychoacoustic perception limit of the human ear to widen the true distribution and stabilize the training process. The model architecture is a deep 2D convolutional network, where each subsequent generator model block increases the resolution along the time axis and adds a higher octave along the frequency axis. The deeper layers are connected with all parts of the output and have the context of the full track. This enables generation of samples which exhibit long-range coherence. We use MP3net to create 95s stereo tracks with a 22kHz sample rate after training for 250h on a single Cloud TPUv2. An additional benefit of the CNN-based model architecture is that generation of new songs is almost instantaneous.

</p>
</details>

<details><summary><b>TrNews: Heterogeneous User-Interest Transfer Learning for News Recommendation</b>
<a href="https://arxiv.org/abs/2101.05611">arxiv:2101.05611</a>
&#x1F4C8; 6 <br>
<p>Guangneng Hu, Qiang Yang</p></summary>
<p>

**Abstract:** We investigate how to solve the cross-corpus news recommendation for unseen users in the future. This is a problem where traditional content-based recommendation techniques often fail. Luckily, in real-world recommendation services, some publisher (e.g., Daily news) may have accumulated a large corpus with lots of consumers which can be used for a newly deployed publisher (e.g., Political news). To take advantage of the existing corpus, we propose a transfer learning model (dubbed as TrNews) for news recommendation to transfer the knowledge from a source corpus to a target corpus. To tackle the heterogeneity of different user interests and of different word distributions across corpora, we design a translator-based transfer-learning strategy to learn a representation mapping between source and target corpora. The learned translator can be used to generate representations for unseen users in the future. We show through experiments on real-world datasets that TrNews is better than various baselines in terms of four metrics. We also show that our translator is effective among existing transfer strategies.

</p>
</details>

<details><summary><b>MLGO: a Machine Learning Guided Compiler Optimizations Framework</b>
<a href="https://arxiv.org/abs/2101.04808">arxiv:2101.04808</a>
&#x1F4C8; 6 <br>
<p>Mircea Trofin, Yundi Qian, Eugene Brevdo, Zinan Lin, Krzysztof Choromanski, David Li</p></summary>
<p>

**Abstract:** Leveraging machine-learning (ML) techniques for compiler optimizations has been widely studied and explored in academia. However, the adoption of ML in general-purpose, industry strength compilers has yet to happen. We propose MLGO, a framework for integrating ML techniques systematically in an industrial compiler -- LLVM. As a case study, we present the details and results of replacing the heuristics-based inlining-for-size optimization in LLVM with machine learned models. To the best of our knowledge, this work is the first full integration of ML in a complex compiler pass in a real-world setting. It is available in the main LLVM repository. We use two different ML algorithms: Policy Gradient and Evolution Strategies, to train the inlining-for-size model, and achieve up to 7\% size reduction, when compared to state of the art LLVM -Oz. The same model, trained on one corpus, generalizes well to a diversity of real-world targets, as well as to the same set of targets after months of active development. This property of the trained models is beneficial to deploy ML techniques in real-world settings.

</p>
</details>

<details><summary><b>Linear Representation Meta-Reinforcement Learning for Instant Adaptation</b>
<a href="https://arxiv.org/abs/2101.04750">arxiv:2101.04750</a>
&#x1F4C8; 6 <br>
<p>Matt Peng, Banghua Zhu, Jiantao Jiao</p></summary>
<p>

**Abstract:** This paper introduces Fast Linearized Adaptive Policy (FLAP), a new meta-reinforcement learning (meta-RL) method that is able to extrapolate well to out-of-distribution tasks without the need to reuse data from training, and adapt almost instantaneously with the need of only a few samples during testing. FLAP builds upon the idea of learning a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, we can directly use the adapter network to predict these linear weights instead of updating a meta-policy via gradient descent, such as in prior meta-RL methods like MAML, to obtain the new policy. The application of the separate feed-forward network not only speeds up the adaptation run-time significantly, but also generalizes extremely well to very different tasks that prior Meta-RL methods fail to generalize to. Experiments on standard continuous-control meta-RL benchmarks show FLAP presenting significantly stronger performance on out-of-distribution tasks with up to double the average return and up to 8X faster adaptation run-time speeds when compared to prior methods.

</p>
</details>

<details><summary><b>Latent Alignment of Procedural Concepts in Multimodal Recipes</b>
<a href="https://arxiv.org/abs/2101.04727">arxiv:2101.04727</a>
&#x1F4C8; 6 <br>
<p>Hossein Rajaby Faghihi, Roshanak Mirzaee, Sudarshan Paliwal, Parisa Kordjamshidi</p></summary>
<p>

**Abstract:** We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA. Our model is solving the textual cloze task which is a reading comprehension on a recipe containing images and instructions. We exploit the power of attention networks, cross-modal representations, and a latent alignment space between instructions and candidate answers to solve the problem. We introduce constrained max-pooling which refines the max-pooling operation on the alignment matrix to impose disjoint constraints among the outputs of the model. Our evaluation result indicates a 19\% improvement over the baselines.

</p>
</details>

<details><summary><b>Model-Based Machine Learning for Communications</b>
<a href="https://arxiv.org/abs/2101.04726">arxiv:2101.04726</a>
&#x1F4C8; 6 <br>
<p>Nir Shlezinger, Nariman Farsad, Yonina C. Eldar, Andrea J. Goldsmith</p></summary>
<p>

**Abstract:** We present an introduction to model-based machine learning for communication systems. We begin by reviewing existing strategies for combining model-based algorithms and machine learning from a high level perspective, and compare them to the conventional deep learning approach which utilizes established deep neural network (DNN) architectures trained in an end-to-end manner. Then, we focus on symbol detection, which is one of the fundamental tasks of communication receivers. We show how the different strategies of conventional deep architectures, deep unfolding, and DNN-aided hybrid algorithms, can be applied to this problem. The last two approaches constitute a middle ground between purely model-based and solely DNN-based receivers. By focusing on this specific task, we highlight the advantages and drawbacks of each strategy, and present guidelines to facilitate the design of future model-based deep learning systems for communications.

</p>
</details>

<details><summary><b>Hyperbolic Deep Neural Networks: A Survey</b>
<a href="https://arxiv.org/abs/2101.04562">arxiv:2101.04562</a>
&#x1F4C8; 6 <br>
<p>Wei Peng, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, Guoying Zhao</p></summary>
<p>

**Abstract:** Recently, there has been a rising surge of momentum for deep representation learning in hyperbolic spaces due to theirhigh capacity of modeling data like knowledge graphs or synonym hierarchies, possessing hierarchical structure. We refer to the model as hyperbolic deep neural network in this paper. Such a hyperbolic neural architecture potentially leads to drastically compact model withmuch more physical interpretability than its counterpart in Euclidean space. To stimulate future research, this paper presents acoherent and comprehensive review of the literature around the neural components in the construction of hyperbolic deep neuralnetworks, as well as the generalization of the leading deep approaches to the Hyperbolic space. It also presents current applicationsaround various machine learning tasks on several publicly available datasets, together with insightful observations and identifying openquestions and promising future directions.

</p>
</details>

<details><summary><b>Knowledge-Enhanced Top-K Recommendation in Poincaré Ball</b>
<a href="https://arxiv.org/abs/2101.04852">arxiv:2101.04852</a>
&#x1F4C8; 5 <br>
<p>Chen Ma, Liheng Ma, Yingxue Zhang, Haolun Wu, Xue Liu, Mark Coates</p></summary>
<p>

**Abstract:** Personalized recommender systems are increasingly important as more content and services become available and users struggle to identify what might interest them. Thanks to the ability for providing rich information, knowledge graphs (KGs) are being incorporated to enhance the recommendation performance and interpretability. To effectively make use of the knowledge graph, we propose a recommendation model in the hyperbolic space, which facilitates the learning of the hierarchical structure of knowledge graphs. Furthermore, a hyperbolic attention network is employed to determine the relative importances of neighboring entities of a certain item. In addition, we propose an adaptive and fine-grained regularization mechanism to adaptively regularize items and their neighboring representations. Via a comparison using three real-world datasets with state-of-the-art methods, we show that the proposed model outperforms the best existing models by 2-16% in terms of NDCG@K on Top-K recommendation.

</p>
</details>

<details><summary><b>Robust GPS-Vision Localization via Integrity-Driven Landmark Attention</b>
<a href="https://arxiv.org/abs/2101.04836">arxiv:2101.04836</a>
&#x1F4C8; 5 <br>
<p>Sriramya Bhamidipati, Grace Xingxin Gao</p></summary>
<p>

**Abstract:** For robust GPS-vision navigation in urban areas, we propose an Integrity-driven Landmark Attention (ILA) technique via stochastic reachability. Inspired by cognitive attention in humans, we perform convex optimization to select a subset of landmarks from GPS and vision measurements that maximizes integrity-driven performance. Given known measurement error bounds in non-faulty conditions, our ILA follows a unified approach to address both GPS and vision faults and is compatible with any off-the-shelf estimator. We analyze measurement deviation to estimate the stochastic reachable set of expected position for each landmark, which is parameterized via probabilistic zonotope (p-Zonotope). We apply set union to formulate a p-Zonotopic cost that represents the size of position bounds based on landmark inclusion/exclusion. We jointly minimize the p-Zonotopic cost and maximize the number of landmarks via convex relaxation. For an urban dataset, we demonstrate improved localization accuracy and robust predicted availability for a pre-defined alert limit.

</p>
</details>

<details><summary><b>Discrete Knowledge Graph Embedding based on Discrete Optimization</b>
<a href="https://arxiv.org/abs/2101.04817">arxiv:2101.04817</a>
&#x1F4C8; 5 <br>
<p>Yunqi Li, Shuyuan Xu, Bo Liu, Zuohui Fu, Shuchang Liu, Xu Chen, Yongfeng Zhang</p></summary>
<p>

**Abstract:** This paper proposes a discrete knowledge graph (KG) embedding (DKGE) method, which projects KG entities and relations into the Hamming space based on a computationally tractable discrete optimization algorithm, to solve the formidable storage and computation cost challenges in traditional continuous graph embedding methods. The convergence of DKGE can be guaranteed theoretically. Extensive experiments demonstrate that DKGE achieves superior accuracy than classical hashing functions that map the effective continuous embeddings into discrete codes. Besides, DKGE reaches comparable accuracy with much lower computational complexity and storage compared to many continuous graph embedding methods.

</p>
</details>

<details><summary><b>Transferring Experience from Simulation to the Real World for Precise Pick-And-Place Tasks in Highly Cluttered Scenes</b>
<a href="https://arxiv.org/abs/2101.04781">arxiv:2101.04781</a>
&#x1F4C8; 5 <br>
<p>Kilian Kleeberger, Markus Völk, Marius Moosmann, Erik Thiessenhusen, Florian Roth, Richard Bormann, Marco F. Huber</p></summary>
<p>

**Abstract:** In this paper, we introduce a novel learning-based approach for grasping known rigid objects in highly cluttered scenes and precisely placing them based on depth images. Our Placement Quality Network (PQ-Net) estimates the object pose and the quality for each automatically generated grasp pose for multiple objects simultaneously at 92 fps in a single forward pass of a neural network. All grasping and placement trials are executed in a physics simulation and the gained experience is transferred to the real world using domain randomization. We demonstrate that our policy successfully transfers to the real world. PQ-Net outperforms other model-free approaches in terms of grasping success rate and automatically scales to new objects of arbitrary symmetry without any human intervention.

</p>
</details>

<details><summary><b>Toward Effective Automated Content Analysis via Crowdsourcing</b>
<a href="https://arxiv.org/abs/2101.04615">arxiv:2101.04615</a>
&#x1F4C8; 5 <br>
<p>Jiele Wu, Chau-Wai Wong, Xinyan Zhao, Xianpeng Liu</p></summary>
<p>

**Abstract:** Many computer scientists use the aggregated answers of online workers to represent ground truth. Prior work has shown that aggregation methods such as majority voting are effective for measuring relatively objective features. For subjective features such as semantic connotation, online workers, known for optimizing their hourly earnings, tend to deteriorate in the quality of their responses as they work longer. In this paper, we aim to address this issue by proposing a quality-aware semantic data annotation system. We observe that with timely feedback on workers' performance quantified by quality scores, better informed online workers can maintain the quality of their labeling throughout an extended period of time. We validate the effectiveness of the proposed annotation system through i) evaluating performance based on an expert-labeled dataset, and ii) demonstrating machine learning tasks that can lead to consistent learning behavior with 70%-80% accuracy. Our results suggest that with our system, researchers can collect high-quality answers of subjective semantic features at a large scale.

</p>
</details>

<details><summary><b>Interpretable discovery of new semiconductors with machine learning</b>
<a href="https://arxiv.org/abs/2101.04383">arxiv:2101.04383</a>
&#x1F4C8; 5 <br>
<p>Hitarth Choubisa, Petar Todorović, Joao M. Pina, Darshan H. Parmar, Ziliang Li, Oleksandr Voznyy, Isaac Tamblyn, Edward Sargent</p></summary>
<p>

**Abstract:** Machine learning models of materials$^{1-5}$ accelerate discovery compared to ab initio methods: deep learning models now reproduce density functional theory (DFT)-calculated results at one hundred thousandths of the cost of DFT$^{6}$. To provide guidance in experimental materials synthesis, these need to be coupled with an accurate yet effective search algorithm and training data consistent with experimental observations. Here we report an evolutionary algorithm powered search which uses machine-learned surrogate models trained on high-throughput hybrid functional DFT data benchmarked against experimental bandgaps: Deep Adaptive Regressive Weighted Intelligent Network (DARWIN). The strategy enables efficient search over the materials space of ~10$^8$ ternaries and 10$^{11}$ quaternaries$^{7}$ for candidates with target properties. It provides interpretable design rules, such as our finding that the difference in the electronegativity between the halide and B-site cation being a strong predictor of ternary structural stability. As an example, when we seek UV emission, DARWIN predicts K$_2$CuX$_3$ (X = Cl, Br) as a promising materials family, based on its electronegativity difference. We synthesized and found these materials to be stable, direct bandgap UV emitters. The approach also allows knowledge distillation for use by humans.

</p>
</details>

<details><summary><b>Deep Cellular Recurrent Network for Efficient Analysis of Time-Series Data with Spatial Information</b>
<a href="https://arxiv.org/abs/2101.05608">arxiv:2101.05608</a>
&#x1F4C8; 4 <br>
<p>Lasitha Vidyaratne, Mahbubul Alam, Alexander Glandon, Anna Shabalina, Christopher Tennant, Khan Iftekharuddin</p></summary>
<p>

**Abstract:** Efficient processing of large-scale time series data is an intricate problem in machine learning. Conventional sensor signal processing pipelines with hand engineered feature extraction often involve huge computational cost with high dimensional data. Deep recurrent neural networks have shown promise in automated feature learning for improved time-series processing. However, generic deep recurrent models grow in scale and depth with increased complexity of the data. This is particularly challenging in presence of high dimensional data with temporal and spatial characteristics. Consequently, this work proposes a novel deep cellular recurrent neural network (DCRNN) architecture to efficiently process complex multi-dimensional time series data with spatial information. The cellular recurrent architecture in the proposed model allows for location-aware synchronous processing of time series data from spatially distributed sensor signal sources. Extensive trainable parameter sharing due to cellularity in the proposed architecture ensures efficiency in the use of recurrent processing units with high-dimensional inputs. This study also investigates the versatility of the proposed DCRNN model for classification of multi-class time series data from different application domains. Consequently, the proposed DCRNN architecture is evaluated using two time-series datasets: a multichannel scalp EEG dataset for seizure detection, and a machine fault detection dataset obtained in-house. The results suggest that the proposed architecture achieves state-of-the-art performance while utilizing substantially less trainable parameters when compared to comparable methods in the literature.

</p>
</details>

<details><summary><b>Generative Adversarial U-Net for Domain-free Medical Image Augmentation</b>
<a href="https://arxiv.org/abs/2101.04793">arxiv:2101.04793</a>
&#x1F4C8; 4 <br>
<p>Xiaocong Chen, Yun Li, Lina Yao, Ehsan Adeli, Yu Zhang</p></summary>
<p>

**Abstract:** The shortage of annotated medical images is one of the biggest challenges in the field of medical image computing. Without a sufficient number of training samples, deep learning based models are very likely to suffer from over-fitting problem. The common solution is image manipulation such as image rotation, cropping, or resizing. Those methods can help relieve the over-fitting problem as more training samples are introduced. However, they do not really introduce new images with additional information and may lead to data leakage as the test set may contain similar samples which appear in the training set. To address this challenge, we propose to generate diverse images with generative adversarial network. In this paper, we develop a novel generative method named generative adversarial U-Net , which utilizes both generative adversarial network and U-Net. Different from existing approaches, our newly designed model is domain-free and generalizable to various medical images. Extensive experiments are conducted over eight diverse datasets including computed tomography (CT) scan, pathology, X-ray, etc. The visualization and quantitative results demonstrate the efficacy and good generalization of the proposed method on generating a wide array of high-quality medical images.

</p>
</details>

<details><summary><b>Learning Efficient Representations for Keyword Spotting with Triplet Loss</b>
<a href="https://arxiv.org/abs/2101.04792">arxiv:2101.04792</a>
&#x1F4C8; 4 <br>
<p>Roman Vygon, Nikolay Mikhaylovskiy</p></summary>
<p>

**Abstract:** In the past few years, triplet loss-based metric embeddings have become a de-facto standard for several important computer vision problems, most no-tably, person reidentification. On the other hand, in the area of speech recognition the metric embeddings generated by the triplet loss are rarely used even for classification problems. We fill this gap showing that a combination of two representation learning techniques: a triplet loss-based embedding and a variant of kNN for classification instead of cross-entropy loss significantly (by 26% to 38%) improves the classification accuracy for convolutional networks on a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel phonetic similarity based triplet mining approach. We also improve the current best published SOTA for Google Speech Commands dataset V1 10+2 -class classification by about 34%, achieving 98.55% accuracy, V2 10+2-class classification by about 20%, achieving 98.37% accuracy, and V2 35-class classification by over 50%, achieving 97.0% accuracy.

</p>
</details>

<details><summary><b>Self-Training Pre-Trained Language Models for Zero- and Few-Shot Multi-Dialectal Arabic Sequence Labeling</b>
<a href="https://arxiv.org/abs/2101.04758">arxiv:2101.04758</a>
&#x1F4C8; 4 <br>
<p>Muhammad Khalifa, Muhammad Abdul-Mageed, Khaled Shaalan</p></summary>
<p>

**Abstract:** A sufficient amount of annotated data is usually required to fine-tune pre-trained language models for downstream tasks. Unfortunately, attaining labeled data can be costly, especially for multiple language varieties and dialects. We propose to self-train pre-trained language models in zero- and few-shot scenarios to improve performance on data-scarce varieties using only resources from data-rich ones. We demonstrate the utility of our approach in the context of Arabic sequence labeling by using a language model fine-tuned on Modern Standard Arabic (MSA) only to predict named entities (NE) and part-of-speech (POS) tags on several dialectal Arabic (DA) varieties. We show that self-training is indeed powerful, improving zero-shot MSA-to-DA transfer by as large as \texttildelow 10\% F$_1$ (NER) and 2\% accuracy (POS tagging). We acquire even better performance in few-shot scenarios with limited amounts of labeled data. We conduct an ablation study and show that the performance boost observed directly results from the unlabeled DA examples used for self-training. Our work opens up opportunities for developing DA models exploiting only MSA resources and it can be extended to other languages and tasks. Our code and fine-tuned models can be accessed at https://github.com/mohammadKhalifa/zero-shot-arabic-dialects.

</p>
</details>

<details><summary><b>Activation Density based Mixed-Precision Quantization for Energy Efficient Neural Networks</b>
<a href="https://arxiv.org/abs/2101.04354">arxiv:2101.04354</a>
&#x1F4C8; 4 <br>
<p>Karina Vasquez, Yeshwanth Venkatesha, Abhiroop Bhattacharjee, Abhishek Moitra, Priyadarshini Panda</p></summary>
<p>

**Abstract:** As neural networks gain widespread adoption in embedded devices, there is a need for model compression techniques to facilitate deployment in resource-constrained environments. Quantization is one of the go-to methods yielding state-of-the-art model compression. Most approaches take a fully trained model, apply different heuristics to determine the optimal bit-precision for different layers of the network, and retrain the network to regain any drop in accuracy. Based on Activation Density (AD)-the proportion of non-zero activations in a layer-we propose an in-training quantization method. Our method calculates bit-width for each layer during training yielding a mixed precision model with competitive accuracy. Since we train lower precision models during training, our approach yields the final quantized model at lower training complexity and also eliminates the need for re-training. We run experiments on benchmark datasets like CIFAR-10, CIFAR-100, TinyImagenet on VGG19/ResNet18 architectures and report the accuracy and energy estimates for the same. We achieve ~4.5x benefit in terms of estimated multiply-and-accumulate (MAC) reduction while reducing the training complexity by 50% in our experiments. To further evaluate the energy benefits of our proposed method, we develop a mixed-precision scalable Process In Memory (PIM) hardware accelerator platform. The hardware platform incorporates shift-add functionality for handling multi-bit precision neural network models. Evaluating the quantized models obtained with our proposed method on the PIM platform yields ~5x energy reduction compared to 16-bit models. Additionally, we find that integrating AD based quantization with AD based pruning (both conducted during training) yields up to ~198x and ~44x energy reductions for VGG19 and ResNet18 architectures respectively on PIM platform compared to baseline 16-bit precision, unpruned models.

</p>
</details>

<details><summary><b>A Recurrent Neural Network Approach to Roll Estimation for Needle Steering</b>
<a href="https://arxiv.org/abs/2101.04856">arxiv:2101.04856</a>
&#x1F4C8; 3 <br>
<p>Maxwell Emerson, James M. Ferguson, Tayfun Efe Ertop, Margaret Rox, Josephine Granna, Michael Lester, Fabien Maldonado, Erin A. Gillaspie, Ron Alterovitz, Robert J. Webster III., Alan Kuntz</p></summary>
<p>

**Abstract:** Steerable needles are a promising technology for delivering targeted therapies in the body in a minimally-invasive fashion, as they can curve around anatomical obstacles and hone in on anatomical targets. In order to accurately steer them, controllers must have full knowledge of the needle tip's orientation. However, current sensors either do not provide full orientation information or interfere with the needle's ability to deliver therapy. Further, torsional dynamics can vary and depend on many parameters making steerable needles difficult to accurately model, limiting the effectiveness of traditional observer methods. To overcome these limitations, we propose a model-free, learned-method that leverages LSTM neural networks to estimate the needle tip's orientation online. We validate our method by integrating it into a sliding-mode controller and steering the needle to targets in gelatin and ex vivo ovine brain tissue. We compare our method's performance against an Extended Kalman Filter, a model-based observer, achieving significantly lower targeting errors.

</p>
</details>

<details><summary><b>Personalized Federated Deep Learning for Pain Estimation From Face Images</b>
<a href="https://arxiv.org/abs/2101.04800">arxiv:2101.04800</a>
&#x1F4C8; 3 <br>
<p>Ognjen Rudovic, Nicolas Tobis, Sebastian Kaltwang, Björn Schuller, Daniel Rueckert, Jeffrey F. Cohn, Rosalind W. Picard</p></summary>
<p>

**Abstract:** Standard machine learning approaches require centralizing the users' data in one computer or a shared database, which raises data privacy and confidentiality concerns. Therefore, limiting central access is important, especially in healthcare settings, where data regulations are strict. A potential approach to tackling this is Federated Learning (FL), which enables multiple parties to collaboratively learn a shared prediction model by using parameters of locally trained models while keeping raw training data locally. In the context of AI-assisted pain-monitoring, we wish to enable confidentiality-preserving and unobtrusive pain estimation for long-term pain-monitoring and reduce the burden on the nursing staff who perform frequent routine check-ups. To this end, we propose a novel Personalized Federated Deep Learning (PFDL) approach for pain estimation from face images. PFDL performs collaborative training of a deep model, implemented using a lightweight CNN architecture, across different clients (i.e., subjects) without sharing their face images. Instead of sharing all parameters of the model, as in standard FL, PFDL retains the last layer locally (used to personalize the pain estimates). This (i) adds another layer of data confidentiality, making it difficult for an adversary to infer pain levels of the target subject, while (ii) personalizing the pain estimation to each subject through local parameter tuning. We show using a publicly available dataset of face videos of pain (UNBC-McMaster Shoulder Pain Database), that PFDL performs comparably or better than the standard centralized and FL algorithms, while further enhancing data privacy. This, has the potential to improve traditional pain monitoring by making it more secure, computationally efficient, and scalable to a large number of individuals (e.g., for in-home pain monitoring), providing timely and unobtrusive pain measurement.

</p>
</details>

<details><summary><b>Context Matters: Self-Attention for Sign Language Recognition</b>
<a href="https://arxiv.org/abs/2101.04632">arxiv:2101.04632</a>
&#x1F4C8; 3 <br>
<p>Fares Ben Slimane, Mohamed Bouguessa</p></summary>
<p>

**Abstract:** This paper proposes an attentional network for the task of Continuous Sign Language Recognition. The proposed approach exploits co-independent streams of data to model the sign language modalities. These different channels of information can share a complex temporal structure between each other. For that reason, we apply attention to synchronize and help capture entangled dependencies between the different sign language components. Even though Sign Language is multi-channel, handshapes represent the central entities in sign interpretation. Seeing handshapes in their correct context defines the meaning of a sign. Taking that into account, we utilize the attention mechanism to efficiently aggregate the hand features with their appropriate spatio-temporal context for better sign recognition. We found that by doing so the model is able to identify the essential Sign Language components that revolve around the dominant hand and the face areas. We test our model on the benchmark dataset RWTH-PHOENIX-Weather 2014, yielding competitive results.

</p>
</details>

<details><summary><b>Queue-Learning: A Reinforcement Learning Approach for Providing Quality of Service</b>
<a href="https://arxiv.org/abs/2101.04627">arxiv:2101.04627</a>
&#x1F4C8; 3 <br>
<p>Majid Raeis, Ali Tizghadam, Alberto Leon-Garcia</p></summary>
<p>

**Abstract:** End-to-end delay is a critical attribute of quality of service (QoS) in application domains such as cloud computing and computer networks. This metric is particularly important in tandem service systems, where the end-to-end service is provided through a chain of services. Service-rate control is a common mechanism for providing QoS guarantees in service systems. In this paper, we introduce a reinforcement learning-based (RL-based) service-rate controller that provides probabilistic upper-bounds on the end-to-end delay of the system, while preventing the overuse of service resources. In order to have a general framework, we use queueing theory to model the service systems. However, we adopt an RL-based approach to avoid the limitations of queueing-theoretic methods. In particular, we use Deep Deterministic Policy Gradient (DDPG) to learn the service rates (action) as a function of the queue lengths (state) in tandem service systems. In contrast to existing RL-based methods that quantify their performance by the achieved overall reward, which could be hard to interpret or even misleading, our proposed controller provides explicit probabilistic guarantees on the end-to-end delay of the system. The evaluations are presented for a tandem queueing system with non-exponential inter-arrival and service times, the results of which validate our controller's capability in meeting QoS constraints.

</p>
</details>

<details><summary><b>UFA-FUSE: A novel deep supervised and hybrid model for multi-focus image fusion</b>
<a href="https://arxiv.org/abs/2101.04506">arxiv:2101.04506</a>
&#x1F4C8; 3 <br>
<p>Yongsheng Zang, Dongming Zhou, Changcheng Wang, Rencan Nie, Yanbu Guo</p></summary>
<p>

**Abstract:** Traditional and deep learning-based fusion methods generated the intermediate decision map to obtain the fusion image through a series of post-processing procedures. However, the fusion results generated by these methods are easy to lose some source image details or results in artifacts. Inspired by the image reconstruction techniques based on deep learning, we propose a multi-focus image fusion network framework without any post-processing to solve these problems in the end-to-end and supervised learning way. To sufficiently train the fusion model, we have generated a large-scale multi-focus image dataset with ground-truth fusion images. What's more, to obtain a more informative fusion image, we further designed a novel fusion strategy based on unity fusion attention, which is composed of a channel attention module and a spatial attention module. Specifically, the proposed fusion approach mainly comprises three key components: feature extraction, feature fusion and image reconstruction. We firstly utilize seven convolutional blocks to extract the image features from source images. Then, the extracted convolutional features are fused by the proposed fusion strategy in the feature fusion layer. Finally, the fused image features are reconstructed by four convolutional blocks. Experimental results demonstrate that the proposed approach for multi-focus image fusion achieves remarkable fusion performance compared to 19 state-of-the-art fusion methods.

</p>
</details>

<details><summary><b>Automatic Extrinsic Calibration Method for LiDAR and Camera Sensor Setups</b>
<a href="https://arxiv.org/abs/2101.04431">arxiv:2101.04431</a>
&#x1F4C8; 3 <br>
<p>Jorge Beltrán, Carlos Guindel, Fernando García</p></summary>
<p>

**Abstract:** Most sensor setups for onboard autonomous perception are composed of LiDARs and vision systems, as they provide complementary information that improves the reliability of the different algorithms necessary to obtain a robust scene understanding. However, the effective use of information from different sources requires an accurate calibration between the sensors involved, which usually implies a tedious and burdensome process. We present a method to calibrate the extrinsic parameters of any pair of sensors involving LiDARs, monocular or stereo cameras, of the same or different modalities. The procedure is composed of two stages: first, reference points belonging to a custom calibration target are extracted from the data provided by the sensors to be calibrated, and second, the optimal rigid transformation is found through the registration of both point sets. The proposed approach can handle devices with very different resolutions and poses, as usually found in vehicle setups. In order to assess the performance of the proposed method, a novel evaluation suite built on top of a popular simulation framework is introduced. Experiments on the synthetic environment show that our calibration algorithm significantly outperforms existing methods, whereas real data tests corroborate the results obtained in the evaluation suite. Open-source code is available at https://github.com/beltransen/velo2cam_calibration

</p>
</details>

<details><summary><b>An Evolutionary Game Model for Understanding Fraud in Consumption Taxes</b>
<a href="https://arxiv.org/abs/2101.04424">arxiv:2101.04424</a>
&#x1F4C8; 3 <br>
<p>M. Chica, J. Hernandez, C. Manrique-de-Lara-Peñate, R. Chiong</p></summary>
<p>

**Abstract:** This paper presents a computational evolutionary game model to study and understand fraud dynamics in the consumption tax system. Players are cooperators if they correctly declare their value added tax (VAT), and are defectors otherwise. Each player's payoff is influenced by the amount evaded and the subjective probability of being inspected by tax authorities. Since transactions between companies must be declared by both the buyer and seller, a strategy adopted by one influences the other's payoff. We study the model with a well-mixed population and different scale-free networks. Model parameters were calibrated using real-world data of VAT declarations by businesses registered in the Canary Islands region of Spain. We analyzed several scenarios of audit probabilities for high and low transactions and their prevalence in the population, as well as social rewards and penalties to find the most efficient policy to increase the proportion of cooperators. Two major insights were found. First, increasing the subjective audit probability for low transactions is more efficient than increasing this probability for high transactions. Second, favoring social rewards for cooperators or alternative penalties for defectors can be effective policies, but their success depends on the distribution of the audit probability for low and high transactions.

</p>
</details>

<details><summary><b>Using uncertainty estimation to reduce false positives in liver lesion detection</b>
<a href="https://arxiv.org/abs/2101.04386">arxiv:2101.04386</a>
&#x1F4C8; 3 <br>
<p>Ishaan Bhat, Hugo J. Kuijf, Veronika Cheplygina, Josien P. W. Pluim</p></summary>
<p>

**Abstract:** Despite the successes of deep learning techniques at detecting objects in medical images, false positive detections occur which may hinder an accurate diagnosis. We propose a technique to reduce false positive detections made by a neural network using an SVM classifier trained with features derived from the uncertainty map of the neural network prediction. We demonstrate the effectiveness of this method for the detection of liver lesions on a dataset of abdominal MR images. We find that the use of a dropout rate of 0.5 produces the least number of false positives in the neural network predictions and the trained classifier filters out approximately 90% of these false positives detections in the test-set.

</p>
</details>

<details><summary><b>Automated Detection of Patellofemoral Osteoarthritis from Knee Lateral View Radiographs Using Deep Learning: Data from the Multicenter Osteoarthritis Study (MOST)</b>
<a href="https://arxiv.org/abs/2101.04350">arxiv:2101.04350</a>
&#x1F4C8; 3 <br>
<p>Neslihan Bayramoglu, Miika T. Nieminen, Simo Saarakkala</p></summary>
<p>

**Abstract:** Objective: To assess the ability of imaging-based deep learning to predict radiographic patellofemoral osteoarthritis (PFOA) from knee lateral view radiographs.
  Design: Knee lateral view radiographs were extracted from The Multicenter Osteoarthritis Study (MOST) (n = 18,436 knees). Patellar region-of-interest (ROI) was first automatically detected, and subsequently, end-to-end deep convolutional neural networks (CNNs) were trained and validated to detect the status of patellofemoral OA. Patellar ROI was detected using deep-learning-based object detection method. Manual PFOA status assessment provided in the MOST dataset was used as a classification outcome for the CNNs. Performance of prediction models was assessed using the area under the receiver operating characteristic curve (ROC AUC) and the average precision (AP) obtained from the precision-recall (PR) curve in the stratified 5-fold cross validation setting.
  Results: Of the 18,436 knees, 3,425 (19%) had PFOA. AUC and AP for the reference model including age, sex, body mass index (BMI), the total Western Ontario and McMaster Universities Arthritis Index (WOMAC) score, and tibiofemoral Kellgren-Lawrence (KL) grade to predict PFOA were 0.806 and 0.478, respectively. The CNN model that used only image data significantly improved the prediction of PFOA status (ROC AUC= 0.958, AP= 0.862).
  Conclusion: We present the first machine learning based automatic PFOA detection method. Furthermore, our deep learning based model trained on patella region from knee lateral view radiographs performs better at predicting PFOA than models based on patient characteristics and clinical assessments.

</p>
</details>

<details><summary><b>Reproducing Activation Function for Deep Learning</b>
<a href="https://arxiv.org/abs/2101.04844">arxiv:2101.04844</a>
&#x1F4C8; 2 <br>
<p>Senwei Liang, Liyao Lyu, Chunmei Wang, Haizhao Yang</p></summary>
<p>

**Abstract:** We propose reproducing activation functions (RAFs) to improve deep learning accuracy for various applications ranging from computer vision to scientific computing. The idea is to employ several basic functions and their learnable linear combination to construct neuron-wise data-driven activation functions for each neuron. Armed with RAFs, neural networks (NNs) can reproduce traditional approximation tools and, therefore, approximate target functions with a smaller number of parameters than traditional NNs. In NN training, RAFs can generate neural tangent kernels (NTKs) with a better condition number than traditional activation functions lessening the spectral bias of deep learning. As demonstrated by extensive numerical tests, the proposed RAFs can facilitate the convergence of deep learning optimization for a solution with higher accuracy than existing deep learning solvers for audio/image/video reconstruction, PDEs, and eigenvalue problems. With RAFs, the errors of audio/video reconstruction, PDEs, and eigenvalue problems are decreased by over 14%, 73%, 99%, respectively, compared with baseline, while the performance of image reconstruction increases by 58%.

</p>
</details>

<details><summary><b>Digital Elevation Model enhancement using Deep Learning</b>
<a href="https://arxiv.org/abs/2101.04812">arxiv:2101.04812</a>
&#x1F4C8; 2 <br>
<p>Casey Handmer</p></summary>
<p>

**Abstract:** We demonstrate high fidelity enhancement of planetary digital elevation models (DEMs) using optical images and deep learning with convolutional neural networks. Enhancement can be applied recursively to the limit of available optical data, representing a 90x resolution improvement in global Mars DEMs. Deep learning-based photoclinometry robustly recovers features obscured by non-ideal lighting conditions. Method can be automated at global scale. Analysis shows enhanced DEM slope errors are comparable with high resolution maps using conventional, labor intensive methods.

</p>
</details>

<details><summary><b>Embedded Computer Vision System Applied to a Four-Legged Line Follower Robot</b>
<a href="https://arxiv.org/abs/2101.04804">arxiv:2101.04804</a>
&#x1F4C8; 2 <br>
<p>Beatriz Arruda Asfora</p></summary>
<p>

**Abstract:** Robotics can be defined as the connection of perception to action. Taking this further, this project aims to drive a robot using an automated computer vision embedded system, connecting the robot's vision to its behavior. In order to implement a color recognition system on the robot, open source tools are chosen, such as Processing language, Android system, Arduino platform and Pixy camera. The constraints are clear: simplicity, replicability and financial viability. In order to integrate Robotics, Computer Vision and Image Processing, the robot is applied on a typical mobile robot's issue: line following. The problem of distinguishing the path from the background is analyzed through different approaches: the popular Otsu's Method, thresholding based on color combinations through experimentation and color tracking via hue and saturation. Decision making of where to move next is based on the line center of the path and is fully automated. Using a four-legged robot as platform and a camera as its only sensor, the robot is capable of successfully follow a line. From capturing the image to moving the robot, it's evident how integrative Robotics can be. The issue of this paper alone involves knowledge of Mechanical Engineering, Electronics, Control Systems and Programming. Everything related to this work was documented and made available on an open source online page, so it can be useful in learning and experimenting with robotics.

</p>
</details>

<details><summary><b>Explicit homography estimation improves contrastive self-supervised learning</b>
<a href="https://arxiv.org/abs/2101.04713">arxiv:2101.04713</a>
&#x1F4C8; 2 <br>
<p>David Torpey, Richard Klein</p></summary>
<p>

**Abstract:** The typical contrastive self-supervised algorithm uses a similarity measure in latent space as the supervision signal by contrasting positive and negative images directly or indirectly. Although the utility of self-supervised algorithms has improved recently, there are still bottlenecks hindering their widespread use, such as the compute needed. In this paper, we propose a module that serves as an additional objective in the self-supervised contrastive learning paradigm. We show how the inclusion of this module to regress the parameters of an affine transformation or homography, in addition to the original contrastive objective, improves both performance and learning speed. Importantly, we ensure that this module does not enforce invariance to the various components of the affine transform, as this is not always ideal. We demonstrate the effectiveness of the additional objective on two recent, popular self-supervised algorithms. We perform an extensive experimental analysis of the proposed method and show an improvement in performance for all considered datasets. Further, we find that although both the general homography and affine transformation are sufficient to improve performance and convergence, the affine transformation performs better in all cases.

</p>
</details>

<details><summary><b>Convolutional Neural Network Simplification with Progressive Retraining</b>
<a href="https://arxiv.org/abs/2101.04699">arxiv:2101.04699</a>
&#x1F4C8; 2 <br>
<p>D. Osaku, J. F. Gomes, A. X. Falcão</p></summary>
<p>

**Abstract:** Kernel pruning methods have been proposed to speed up, simplify, and improve explanation of convolutional neural network (CNN) models. However, the effectiveness of a simplified model is often below the original one. In this letter, we present new methods based on objective and subjective relevance criteria for kernel elimination in a layer-by-layer fashion. During the process, a CNN model is retrained only when the current layer is entirely simplified, by adjusting the weights from the next layer to the first one and preserving weights of subsequent layers not involved in the process. We call this strategy \emph{progressive retraining}, differently from kernel pruning methods that usually retrain the entire model after each simplification action -- e.g., the elimination of one or a few kernels. Our subjective relevance criterion exploits the ability of humans in recognizing visual patterns and improves the designer's understanding of the simplification process. The combination of suitable relevance criteria and progressive retraining shows that our methods can increase effectiveness with considerable model simplification. We also demonstrate that our methods can provide better results than two popular ones and another one from the state-of-the-art using four challenging image datasets.

</p>
</details>

<details><summary><b>Deep Gaussian Denoiser Epistemic Uncertainty and Decoupled Dual-Attention Fusion</b>
<a href="https://arxiv.org/abs/2101.04631">arxiv:2101.04631</a>
&#x1F4C8; 2 <br>
<p>Xiaoqi Ma, Xiaoyu Lin, Majed El Helou, Sabine Süsstrunk</p></summary>
<p>

**Abstract:** Following the performance breakthrough of denoising networks, improvements have come chiefly through novel architecture designs and increased depth. While novel denoising networks were designed for real images coming from different distributions, or for specific applications, comparatively small improvement was achieved on Gaussian denoising. The denoising solutions suffer from epistemic uncertainty that can limit further advancements. This uncertainty is traditionally mitigated through different ensemble approaches. However, such ensembles are prohibitively costly with deep networks, which are already large in size.
  Our work focuses on pushing the performance limits of state-of-the-art methods on Gaussian denoising. We propose a model-agnostic approach for reducing epistemic uncertainty while using only a single pretrained network. We achieve this by tapping into the epistemic uncertainty through augmented and frequency-manipulated images to obtain denoised images with varying error. We propose an ensemble method with two decoupled attention paths, over the pixel domain and over that of our different manipulations, to learn the final fusion. Our results significantly improve over the state-of-the-art baselines and across varying noise levels.

</p>
</details>

<details><summary><b>Predicting Relative Depth between Objects from Semantic Features</b>
<a href="https://arxiv.org/abs/2101.04626">arxiv:2101.04626</a>
&#x1F4C8; 2 <br>
<p>Stefan Cassar, Adrian Muscat, Dylan Seychell</p></summary>
<p>

**Abstract:** Vision and language tasks such as Visual Relation Detection and Visual Question Answering benefit from semantic features that afford proper grounding of language. The 3D depth of objects depicted in 2D images is one such feature. However it is very difficult to obtain accurate depth information without learning the appropriate features, which are scene dependent. The state of the art in this area are complex Neural Network models trained on stereo image data to predict depth per pixel. Fortunately, in some tasks, its only the relative depth between objects that is required. In this paper the extent to which semantic features can predict course relative depth is investigated. The problem is casted as a classification one and geometrical features based on object bounding boxes, object labels and scene attributes are computed and used as inputs to pattern recognition models to predict relative depth. i.e behind, in-front and neutral. The results are compared to those obtained from averaging the output of the monodepth neural network model, which represents the state-of-the art. An overall increase of 14% in relative depth accuracy over relative depth computed from the monodepth model derived results is achieved.

</p>
</details>

<details><summary><b>AI- and HPC-enabled Lead Generation for SARS-CoV-2: Models and Processes to Extract Druglike Molecules Contained in Natural Language Text</b>
<a href="https://arxiv.org/abs/2101.04617">arxiv:2101.04617</a>
&#x1F4C8; 2 <br>
<p>Zhi Hong, J. Gregory Pauloski, Logan Ward, Kyle Chard, Ben Blaiszik, Ian Foster</p></summary>
<p>

**Abstract:** Researchers worldwide are seeking to repurpose existing drugs or discover new drugs to counter the disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). A promising source of candidates for such studies is molecules that have been reported in the scientific literature to be drug-like in the context of coronavirus research. We report here on a project that leverages both human and artificial intelligence to detect references to drug-like molecules in free text. We engage non-expert humans to create a corpus of labeled text, use this labeled corpus to train a named entity recognition model, and employ the trained model to extract 10912 drug-like molecules from the COVID-19 Open Research Dataset Challenge (CORD-19) corpus of 198875 papers. Performance analyses show that our automated extraction model can achieve performance on par with that of non-expert humans.

</p>
</details>

<details><summary><b>Of Non-Linearity and Commutativity in BERT</b>
<a href="https://arxiv.org/abs/2101.04547">arxiv:2101.04547</a>
&#x1F4C8; 2 <br>
<p>Sumu Zhao, Damian Pascual, Gino Brunner, Roger Wattenhofer</p></summary>
<p>

**Abstract:** In this work we provide new insights into the transformer architecture, and in particular, its best-known variant, BERT. First, we propose a method to measure the degree of non-linearity of different elements of transformers. Next, we focus our investigation on the feed-forward networks (FFN) inside transformers, which contain 2/3 of the model parameters and have so far not received much attention. We find that FFNs are an inefficient yet important architectural element and that they cannot simply be replaced by attention blocks without a degradation in performance. Moreover, we study the interactions between layers in BERT and show that, while the layers exhibit some hierarchical structure, they extract features in a fuzzy manner. Our results suggest that BERT has an inductive bias towards layer commutativity, which we find is mainly due to the skip connections. This provides a justification for the strong performance of recurrent and weight-shared transformer models.

</p>
</details>

<details><summary><b>Data augmentation and feature selection for automatic model recommendation in computational physics</b>
<a href="https://arxiv.org/abs/2101.04530">arxiv:2101.04530</a>
&#x1F4C8; 2 <br>
<p>Thomas Daniel, Fabien Casenave, Nissrine Akkari, David Ryckelynck</p></summary>
<p>

**Abstract:** Classification algorithms have recently found applications in computational physics for the selection of numerical methods or models adapted to the environment and the state of the physical system. For such classification tasks, labeled training data come from numerical simulations and generally correspond to physical fields discretized on a mesh. Three challenging difficulties arise: the lack of training data, their high dimensionality, and the non-applicability of common data augmentation techniques to physics data. This article introduces two algorithms to address these issues, one for dimensionality reduction via feature selection, and one for data augmentation. These algorithms are combined with a wide variety of classifiers for their evaluation. When combined with a stacking ensemble made of six multilayer perceptrons and a ridge logistic regression, they enable reaching an accuracy of 90% on our classification problem for nonlinear structural mechanics.

</p>
</details>

<details><summary><b>A Unified Framework for Online Trip Destination Prediction</b>
<a href="https://arxiv.org/abs/2101.04520">arxiv:2101.04520</a>
&#x1F4C8; 2 <br>
<p>Victor Eberstein, Jonas Sjöblom, Nikolce Murgovski, Morteza Haghir Chehreghani</p></summary>
<p>

**Abstract:** Trip destination prediction is an area of increasing importance in many applications such as trip planning, autonomous driving and electric vehicles. Even though this problem could be naturally addressed in an online learning paradigm where data is arriving in a sequential fashion, the majority of research has rather considered the offline setting. In this paper, we present a unified framework for trip destination prediction in an online setting, which is suitable for both online training and online prediction. For this purpose, we develop two clustering algorithms and integrate them within two online prediction models for this problem.
  We investigate the different configurations of clustering algorithms and prediction models on a real-world dataset. By using traditional clustering metrics and accuracy, we demonstrate that both the clustering and the entire framework yield consistent results compared to the offline setting. Finally, we propose a novel regret metric for evaluating the entire online framework in comparison to its offline counterpart. This metric makes it possible to relate the source of erroneous predictions to either the clustering or the prediction model. Using this metric, we show that the proposed methods converge to a probability distribution resembling the true underlying distribution and enjoy a lower regret than all of the baselines.

</p>
</details>

<details><summary><b>PvDeConv: Point-Voxel Deconvolution for Autoencoding CAD Construction in 3D</b>
<a href="https://arxiv.org/abs/2101.04493">arxiv:2101.04493</a>
&#x1F4C8; 2 <br>
<p>Kseniya Cherenkova, Djamila Aouada, Gleb Gusev</p></summary>
<p>

**Abstract:** We propose a Point-Voxel DeConvolution (PVDeConv) module for 3D data autoencoder. To demonstrate its efficiency we learn to synthesize high-resolution point clouds of 10k points that densely describe the underlying geometry of Computer Aided Design (CAD) models. Scanning artifacts, such as protrusions, missing parts, smoothed edges and holes, inevitably appear in real 3D scans of fabricated CAD objects. Learning the original CAD model construction from a 3D scan requires a ground truth to be available together with the corresponding 3D scan of an object. To solve the gap, we introduce a new dedicated dataset, the CC3D, containing 50k+ pairs of CAD models and their corresponding 3D meshes. This dataset is used to learn a convolutional autoencoder for point clouds sampled from the pairs of 3D scans - CAD models. The challenges of this new dataset are demonstrated in comparison with other generative point cloud sampling models trained on ShapeNet. The CC3D autoencoder is efficient with respect to memory consumption and training time as compared to stateof-the-art models for 3D data generation.

</p>
</details>

<details><summary><b>Automated Synthesis of Steady-State Continuous Processes using Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2101.04422">arxiv:2101.04422</a>
&#x1F4C8; 2 <br>
<p>Quirin Göttl, Dominik G. Grimm, Jakob Burger</p></summary>
<p>

**Abstract:** Automated flowsheet synthesis is an important field in computer-aided process engineering. The present work demonstrates how reinforcement learning can be used for automated flowsheet synthesis without any heuristics of prior knowledge of conceptual design. The environment consists of a steady-state flowsheet simulator that contains all physical knowledge. An agent is trained to take discrete actions and sequentially built up flowsheets that solve a given process problem. A novel method named SynGameZero is developed to ensure good exploration schemes in the complex problem. Therein, flowsheet synthesis is modelled as a game of two competing players. The agent plays this game against itself during training and consists of an artificial neural network and a tree search for forward planning. The method is applied successfully to a reaction-distillation process in a quaternary system.

</p>
</details>

<details><summary><b>Neural Network-based Virtual Microphone Estimator</b>
<a href="https://arxiv.org/abs/2101.04315">arxiv:2101.04315</a>
&#x1F4C8; 2 <br>
<p>Tsubasa Ochiai, Marc Delcroix, Tomohiro Nakatani, Rintaro Ikeshita, Keisuke Kinoshita, Shoko Araki</p></summary>
<p>

**Abstract:** Developing microphone array technologies for a small number of microphones is important due to the constraints of many devices. One direction to address this situation consists of virtually augmenting the number of microphone signals, e.g., based on several physical model assumptions. However, such assumptions are not necessarily met in realistic conditions. In this paper, as an alternative approach, we propose a neural network-based virtual microphone estimator (NN-VME). The NN-VME estimates virtual microphone signals directly in the time domain, by utilizing the precise estimation capability of the recent time-domain neural networks. We adopt a fully supervised learning framework that uses actual observations at the locations of the virtual microphones at training time. Consequently, the NN-VME can be trained using only multi-channel observations and thus directly on real recordings, avoiding the need for unrealistic physical model-based assumptions. Experiments on the CHiME-4 corpus show that the proposed NN-VME achieves high virtual microphone estimation performance even for real recordings and that a beamformer augmented with the NN-VME improves both the speech enhancement and recognition performance.

</p>
</details>

<details><summary><b>Classification of Schizophrenia from Functional MRI Using Large-scale Extended Granger Causality</b>
<a href="https://arxiv.org/abs/2101.10471">arxiv:2101.10471</a>
&#x1F4C8; 1 <br>
<p>Axel Wismüller, M. Ali Vosoughi</p></summary>
<p>

**Abstract:** The literature manifests that schizophrenia is associated with alterations in brain network connectivity. We investigate whether large-scale Extended Granger Causality (lsXGC) can capture such alterations using resting-state fMRI data. Our method utilizes dimension reduction combined with the augmentation of source time-series in a predictive time-series model for estimating directed causal relationships among fMRI time-series. The lsXGC is a multivariate approach since it identifies the relationship of the underlying dynamic system in the presence of all other time-series. Here lsXGC serves as a biomarker for classifying schizophrenia patients from typical controls using a subset of 62 subjects from the Centers of Biomedical Research Excellence (COBRE) data repository. We use brain connections estimated by lsXGC as features for classification. After feature extraction, we perform feature selection by Kendall's tau rank correlation coefficient followed by classification using a support vector machine. As a reference method, we compare our results with cross-correlation, typically used in the literature as a standard measure of functional connectivity. We cross-validate 100 different training/test (90%/10%) data split to obtain mean accuracy and a mean Area Under the receiver operating characteristic Curve (AUC) across all tested numbers of features for lsXGC. Our results demonstrate a mean accuracy range of [0.767, 0.940] and a mean AUC range of [0.861, 0.983] for lsXGC. The result of lsXGC is significantly higher than the results obtained with the cross-correlation, namely mean accuracy of [0.721, 0.751] and mean AUC of [0.744, 0.860]. Our results suggest the applicability of lsXGC as a potential biomarker for schizophrenia.

</p>
</details>

<details><summary><b>Real or Virtual? Using Brain Activity Patterns to differentiate Attended Targets during Augmented Reality Scenarios</b>
<a href="https://arxiv.org/abs/2101.05272">arxiv:2101.05272</a>
&#x1F4C8; 1 <br>
<p>Lisa-Marie Vortmann, Leonid Schwenke, Felix Putze</p></summary>
<p>

**Abstract:** Augmented Reality is the fusion of virtual components and our real surroundings. The simultaneous visibility of generated and natural objects often requires users to direct their selective attention to a specific target that is either real or virtual. In this study, we investigated whether this target is real or virtual by using machine learning techniques to classify electroencephalographic (EEG) data collected in Augmented Reality scenarios. A shallow convolutional neural net classified 3 second data windows from 20 participants in a person-dependent manner with an average accuracy above 70\% if the testing data and training data came from different trials. Person-independent classification was possible above chance level for 6 out of 20 participants. Thus, the reliability of such a Brain-Computer Interface is high enough for it to be treated as a useful input mechanism for Augmented Reality applications.

</p>
</details>

<details><summary><b>UCNN: A Convolutional Strategy on Unstructured Mesh</b>
<a href="https://arxiv.org/abs/2101.05207">arxiv:2101.05207</a>
&#x1F4C8; 1 <br>
<p>Mengfei Xu, Shufang Song, Xuxiang Sun, Weiwei Zhang</p></summary>
<p>

**Abstract:** In machine learning for fluid mechanics, fully-connected neural network (FNN) only uses the local features for modelling, while the convolutional neural network (CNN) cannot be applied to data on structured/unstructured mesh. In order to overcome the limitations of FNN and CNN, the unstructured convolutional neural network (UCNN) is proposed, which aggregates and effectively exploits the features of neighbour nodes through the weight function. Adjoint vector modelling is taken as the task to study the performance of UCNN. The mapping function from flow-field features to adjoint vector is constructed through efficient parallel implementation on GPU. The modelling capability of UCNN is compared with that of FNN on validation set and in aerodynamic shape optimization at test case. The influence of mesh changing on the modelling capability of UCNN is further studied. The results indicate that UCNN is more accurate in modelling process.

</p>
</details>

<details><summary><b>Convolutional Neural Nets in Chemical Engineering: Foundations, Computations, and Applications</b>
<a href="https://arxiv.org/abs/2101.04869">arxiv:2101.04869</a>
&#x1F4C8; 1 <br>
<p>Shengli Jiang, Victor M. Zavala</p></summary>
<p>

**Abstract:** In this paper we review the mathematical foundations of convolutional neural nets (CNNs) with the goals of: i) highlighting connections with techniques from statistics, signal processing, linear algebra, differential equations, and optimization, ii) demystifying underlying computations, and iii) identifying new types of applications. CNNs are powerful machine learning models that highlight features from grid data to make predictions (regression and classification). The grid data object can be represented as vectors (in 1D), matrices (in 2D), or tensors (in 3D or higher dimensions) and can incorporate multiple channels (thus providing high flexibility in the input data representation). CNNs highlight features from the grid data by performing convolution operations with different types of operators. The operators highlight different types of features (e.g., patterns, gradients, geometrical features) and are learned by using optimization techniques. In other words, CNNs seek to identify optimal operators that best map the input data to the output data. A common misconception is that CNNs are only capable of processing image or video data but their application scope is much wider; specifically, datasets encountered in diverse applications can be expressed as grid data. Here, we show how to apply CNNs to new types of applications such as optimal control, flow cytometry, multivariate process monitoring, and molecular simulations.

</p>
</details>

<details><summary><b>Heterogeneous Network Embedding for Deep Semantic Relevance Match in E-commerce Search</b>
<a href="https://arxiv.org/abs/2101.04850">arxiv:2101.04850</a>
&#x1F4C8; 1 <br>
<p>Ziyang Liu, Zhaomeng Cheng, Yunjiang Jiang, Yue Shang, Wei Xiong, Sulong Xu, Bo Long, Di Jin</p></summary>
<p>

**Abstract:** Result relevance prediction is an essential task of e-commerce search engines to boost the utility of search engines and ensure smooth user experience. The last few years eyewitnessed a flurry of research on the use of Transformer-style models and deep text-match models to improve relevance. However, these two types of models ignored the inherent bipartite network structures that are ubiquitous in e-commerce search logs, making these models ineffective. We propose in this paper a novel Second-order Relevance, which is fundamentally different from the previous First-order Relevance, to improve result relevance prediction. We design, for the first time, an end-to-end First-and-Second-order Relevance prediction model for e-commerce item relevance. The model is augmented by the neighborhood structures of bipartite networks that are built using the information of user behavioral feedback, including clicks and purchases. To ensure that edges accurately encode relevance information, we introduce external knowledge generated from BERT to refine the network of user behaviors. This allows the new model to integrate information from neighboring items and queries, which are highly relevant to the focus query-item pair under consideration. Results of offline experiments showed that the new model significantly improved the prediction accuracy in terms of human relevance judgment. An ablation study showed that the First-and-Second-order model gained a 4.3% average gain over the First-order model. Results of an online A/B test revealed that the new model derived more commercial benefits compared to the base model.

</p>
</details>

<details><summary><b>A reusable pipeline for large-scale fiber segmentation on unidirectional fiber beds using fully convolutional neural networks</b>
<a href="https://arxiv.org/abs/2101.04823">arxiv:2101.04823</a>
&#x1F4C8; 1 <br>
<p>Alexandre Fioravante de Siqueira, Daniela Mayumi Ushizima, Stéfan van der Walt</p></summary>
<p>

**Abstract:** Fiber-reinforced ceramic-matrix composites are advanced materials resistant to high temperatures, with application to aerospace engineering. Their analysis depends on the detection of embedded fibers, with semi-supervised techniques usually employed to separate fibers within the fiber beds. Here we present an open computational pipeline to detect fibers in ex-situ X-ray computed tomography fiber beds. To separate the fibers in these samples, we tested four different architectures of fully convolutional neural networks. When comparing our neural network approach to a semi-supervised one, we obtained Dice and Matthews coefficients greater than $92.28 \pm 9.65\%$, reaching up to $98.42 \pm 0.03 \%$, showing that the network results are close to the human-supervised ones in these fiber beds, in some cases separating fibers that human-curated algorithms could not find. The software we generated in this project is open source, released under a permissive license, and can be freely adapted and re-used in other domains. All data and instructions on how to download and use it are also available.

</p>
</details>

<details><summary><b>Plug-and-Play Algorithms for Video Snapshot Compressive Imaging</b>
<a href="https://arxiv.org/abs/2101.04822">arxiv:2101.04822</a>
&#x1F4C8; 1 <br>
<p>Xin Yuan, Yang Liu, Jinli Suo, Frédo Durand, Qionghai Dai</p></summary>
<p>

**Abstract:** We consider the reconstruction problem of video snapshot compressive imaging (SCI), which captures high-speed videos using a low-speed 2D sensor (detector). The underlying principle of SCI is to modulate sequential high-speed frames with different masks and then these encoded frames are integrated into a snapshot on the sensor and thus the sensor can be of low-speed. On one hand, video SCI enjoys the advantages of low-bandwidth, low-power and low-cost. On the other hand, applying SCI to large-scale problems (HD or UHD videos) in our daily life is still challenging and one of the bottlenecks lies in the reconstruction algorithm. Exiting algorithms are either too slow (iterative optimization algorithms) or not flexible to the encoding process (deep learning based end-to-end networks). In this paper, we develop fast and flexible algorithms for SCI based on the plug-and-play (PnP) framework. In addition to the PnP-ADMM method, we further propose the PnP-GAP (generalized alternating projection) algorithm with a lower computational workload. We first employ the image deep denoising priors to show that PnP can recover a UHD color video with 30 frames from a snapshot measurement. Since videos have strong temporal correlation, by employing the video deep denoising priors, we achieve a significant improvement in the results. Furthermore, we extend the proposed PnP algorithms to the color SCI system using mosaic sensors, where each pixel only captures the red, green or blue channels. A joint reconstruction and demosaicing paradigm is developed for flexible and high quality reconstruction of color video SCI systems. Extensive results on both simulation and real datasets verify the superiority of our proposed algorithm.

</p>
</details>

<details><summary><b>Airfoil GAN: Encoding and Synthesizing Airfoils forAerodynamic-aware Shape Optimization</b>
<a href="https://arxiv.org/abs/2101.04757">arxiv:2101.04757</a>
&#x1F4C8; 1 <br>
<p>Yuyang Wang, Kenji Shimada, Amir Barati Farimani</p></summary>
<p>

**Abstract:** The current design of aerodynamic shapes, like airfoils, involves computationally intensive simulations to explore the possible design space. Usually, such design relies on the prior definition of design parameters and places restrictions on synthesizing novel shapes. In this work, we propose a data-driven shape encoding and generating method, which automatically learns representations from existing airfoils and uses the learned representations to generate new airfoils. The representations are then used in the optimization of synthesized airfoil shapes based on their aerodynamic performance. Our model is built upon VAEGAN, a neural network that combines Variational Autoencoder with Generative Adversarial Network and is trained by the gradient-based technique. Our model can (1) encode the existing airfoil into a latent vector and reconstruct the airfoil from that, (2) generate novel airfoils by randomly sampling the latent vectors and mapping the vectors to the airfoil coordinate domain, and (3) synthesize airfoils with desired aerodynamic properties by optimizing learned features via a genetic algorithm. Our experiments show that the learned features encode shape information thoroughly and comprehensively without predefined design parameters. By interpolating/extrapolating feature vectors or sampling from Gaussian noises, the model can automatically synthesize novel airfoil shapes, some of which possess competitive or even better aerodynamic properties comparing with training airfoils. By optimizing shape on learned features via a genetic algorithm, synthesized airfoils can evolve to have specific aerodynamic properties, which can guide designing aerodynamic products effectively and efficiently.

</p>
</details>

<details><summary><b>People, Places, and Ties: Landscape of social places and their social network structures</b>
<a href="https://arxiv.org/abs/2101.04737">arxiv:2101.04737</a>
&#x1F4C8; 1 <br>
<p>Jaehyuk Park, Bogdan State, Monica Bhole, Michael C. Bailey, Yong-Yeol Ahn</p></summary>
<p>

**Abstract:** Due to their essential role as places for socialization, "third places" - social places where people casually visit and communicate with friends and neighbors - have been studied by a wide range of fields including network science, sociology, geography, urban planning, and regional studies. However, the lack of a large-scale census on third places kept researchers from systematic investigations. Here we provide a systematic nationwide investigation of third places and their social networks, by using Facebook pages. Our analysis reveals a large degree of geographic heterogeneity in the distribution of the types of third places, which is highly correlated with baseline demographics and county characteristics. Certain types of pages like "Places of Worship" demonstrate a large degree of clustering suggesting community preference or potential complementarities to concentration. We also found that the social networks of different types of social place differ in important ways: The social networks of 'Restaurants' and 'Indoor Recreation' pages are more likely to be tight-knit communities of pre-existing friendships whereas 'Places of Worship' and 'Community Amenities' page categories are more likely to bridge new friendship ties. We believe that this study can serve as an important milestone for future studies on the systematic comparative study of social spaces and their social relationships.

</p>
</details>

<details><summary><b>Towards fast machine-learning-assisted Bayesian posterior inference of realistic microseismic events</b>
<a href="https://arxiv.org/abs/2101.04724">arxiv:2101.04724</a>
&#x1F4C8; 1 <br>
<p>Davide Piras, Alessio Spurio Mancini, Benjamin Joachimi, Michael P. Hobson</p></summary>
<p>

**Abstract:** Bayesian inference applied to microseismic activity monitoring allows for principled estimation of the coordinates of microseismic events from recorded seismograms, and their associated uncertainties. However, forward modelling of these microseismic events, necessary to perform Bayesian source inversion, can be prohibitively expensive in terms of computational resources. A viable solution is to train a surrogate model based on machine learning techniques, to emulate the forward model and thus accelerate Bayesian inference. In this paper, we improve on previous work, which considered only sources with isotropic moment tensor. We train a machine learning algorithm on the power spectrum of the recorded pressure wave and show that the trained emulator allows for the complete and fast retrieval of the event coordinates for $\textit{any}$ source mechanism. Moreover, we show that our approach is computationally inexpensive, as it can be run in less than 1 hour on a commercial laptop, while yielding accurate results using less than $10^4$ training seismograms. We additionally demonstrate how the trained emulators can be used to identify the source mechanism through the estimation of the Bayesian evidence. This work lays the foundations for the efficient localisation and characterisation of any recorded seismogram, thus helping to quantify human impact on seismic activity and mitigate seismic hazard.

</p>
</details>

<details><summary><b>Dynamic Spectrum Access using Stochastic Multi-User Bandits</b>
<a href="https://arxiv.org/abs/2101.04388">arxiv:2101.04388</a>
&#x1F4C8; 1 <br>
<p>Meghana Bande, Akshayaa Magesh, Venugopal V. Veeravalli</p></summary>
<p>

**Abstract:** A stochastic multi-user multi-armed bandit framework is used to develop algorithms for uncoordinated spectrum access. In contrast to prior work, it is assumed that rewards can be non-zero even under collisions, thus allowing for the number of users to be greater than the number of channels. The proposed algorithm consists of an estimation phase and an allocation phase. It is shown that if every user adopts the algorithm, the system wide regret is order-optimal of order $O(\log T)$ over a time-horizon of duration $T$. The regret guarantees hold for both the cases where the number of users is greater than or less than the number of channels. The algorithm is extended to the dynamic case where the number of users in the system evolves over time, and is shown to lead to sub-linear regret.

</p>
</details>

<details><summary><b>CAnet: Uplink-aided Downlink Channel Acquisition in FDD Massive MIMO using Deep Learning</b>
<a href="https://arxiv.org/abs/2101.04377">arxiv:2101.04377</a>
&#x1F4C8; 1 <br>
<p>Jiajia Guo, Chao-Kai Wen, Shi Jin</p></summary>
<p>

**Abstract:** In frequency-division duplexing systems, the downlink channel state information (CSI) acquisition scheme leads to high training and feedback overheads. In this paper, we propose an uplink-aided downlink channel acquisition framework using deep learning to reduce these overheads. Unlike most existing works that focus only on channel estimation or feedback modules, to the best of our knowledge, this is the first study that considers the entire downlink CSI acquisition process, including downlink pilot design, channel estimation, and feedback. First, we propose an adaptive pilot design module by exploiting the correlation in magnitude among bidirectional channels in the angular domain to improve channel estimation. Next, to avoid the bit allocation problem during the feedback module, we concatenate the complex channel and embed the uplink channel magnitude to the channel reconstruction at the base station. Lastly, we combine the above two modules and compare two popular downlink channel acquisition frameworks. The former framework estimates and feeds back the channel at the user equipment subsequently. The user equipment in the latter one directly feeds back the received pilot signals to the base station. Our results reveal that, with the help of uplink, directly feeding back the pilot signals can save approximately 20% of feedback bits, which provides a guideline for future research.

</p>
</details>

<details><summary><b>Data-driven peakon and periodic peakon travelling wave solutions of some nonlinear dispersive equations via deep learning</b>
<a href="https://arxiv.org/abs/2101.04371">arxiv:2101.04371</a>
&#x1F4C8; 1 <br>
<p>Li Wang, Zhenya Yan</p></summary>
<p>

**Abstract:** In the field of mathematical physics, there exist many physically interesting nonlinear dispersive equations with peakon solutions, which are solitary waves with discontinuous first-order derivative at the wave peak. In this paper, we apply the multi-layer physics-informed neural networks (PINNs) deep learning to successfully study the data-driven peakon and periodic peakon solutions of some well-known nonlinear dispersion equations with initial-boundary value conditions such as the Camassa-Holm (CH) equation, Degasperis-Procesi equation, modified CH equation with cubic nonlinearity, Novikov equation with cubic nonlinearity, mCH-Novikov equation, b-family equation with quartic nonlinearity, generalized modified CH equation with quintic nonlinearity, and etc. These results will be useful to further study the peakon solutions and corresponding experimental design of nonlinear dispersive equations.

</p>
</details>

<details><summary><b>Event-Driven Source Traffic Prediction in Machine-Type Communications Using LSTM Networks</b>
<a href="https://arxiv.org/abs/2101.04365">arxiv:2101.04365</a>
&#x1F4C8; 1 <br>
<p>Thulitha Senevirathna, Bathiya Thennakoon, Tharindu Sankalpa, Chatura Seneviratne, Samad Ali, Nandana Rajatheva</p></summary>
<p>

**Abstract:** Source traffic prediction is one of the main challenges of enabling predictive resource allocation in machine type communications (MTC). In this paper, a Long Short-Term Memory (LSTM) based deep learning approach is proposed for event-driven source traffic prediction. The source traffic prediction problem can be formulated as a sequence generation task where the main focus is predicting the transmission states of machine-type devices (MTDs) based on their past transmission data. This is done by restructuring the transmission data in a way that the LSTM network can identify the causal relationship between the devices. Knowledge of such a causal relationship can enable event-driven traffic prediction. The performance of the proposed approach is studied using data regarding events from MTDs with different ranges of entropy. Our model outperforms existing baseline solutions in saving resources and accuracy with a margin of around 9%. Reduction in Random Access (RA) requests by our model is also analyzed to demonstrate the low amount of signaling required as a result of our proposed LSTM based source traffic prediction approach.

</p>
</details>

<details><summary><b>DeepiSign: Invisible Fragile Watermark to Protect the Integrityand Authenticity of CNN</b>
<a href="https://arxiv.org/abs/2101.04319">arxiv:2101.04319</a>
&#x1F4C8; 1 <br>
<p>Alsharif Abuadbba, Hyoungshick Kim, Surya Nepal</p></summary>
<p>

**Abstract:** Convolutional Neural Networks (CNNs) deployed in real-life applications such as autonomous vehicles have shown to be vulnerable to manipulation attacks, such as poisoning attacks and fine-tuning. Hence, it is essential to ensure the integrity and authenticity of CNNs because compromised models can produce incorrect outputs and behave maliciously. In this paper, we propose a self-contained tamper-proofing method, called DeepiSign, to ensure the integrity and authenticity of CNN models against such manipulation attacks. DeepiSign applies the idea of fragile invisible watermarking to securely embed a secret and its hash value into a CNN model. To verify the integrity and authenticity of the model, we retrieve the secret from the model, compute the hash value of the secret, and compare it with the embedded hash value. To minimize the effects of the embedded secret on the CNN model, we use a wavelet-based technique to transform weights into the frequency domain and embed the secret into less significant coefficients. Our theoretical analysis shows that DeepiSign can hide up to 1KB secret in each layer with minimal loss of the model's accuracy. To evaluate the security and performance of DeepiSign, we performed experiments on four pre-trained models (ResNet18, VGG16, AlexNet, and MobileNet) using three datasets (MNIST, CIFAR-10, and Imagenet) against three types of manipulation attacks (targeted input poisoning, output poisoning, and fine-tuning). The results demonstrate that DeepiSign is verifiable without degrading the classification accuracy, and robust against representative CNN manipulation attacks.

</p>
</details>

<details><summary><b>On the Effectiveness of Small Input Noise for Defending Against Query-based Black-Box Attacks</b>
<a href="https://arxiv.org/abs/2101.04829">arxiv:2101.04829</a>
&#x1F4C8; 0 <br>
<p>Junyoung Byun, Hyojun Go, Changick Kim</p></summary>
<p>

**Abstract:** While deep neural networks show unprecedented performance in various tasks, the vulnerability to adversarial examples hinders their deployment in safety-critical systems. Many studies have shown that attacks are also possible even in a black-box setting where an adversary cannot access the target model's internal information. Most black-box attacks are based on queries, each of which obtains the target model's output for an input, and many recent studies focus on reducing the number of required queries. In this paper, we pay attention to an implicit assumption of query-based black-box adversarial attacks that the target model's output exactly corresponds to the query input. If some randomness is introduced into the model, it can break the assumption, and thus, query-based attacks may have tremendous difficulty in both gradient estimation and local search, which are the core of their attack process. From this motivation, we observe even a small additive input noise can neutralize most query-based attacks and name this simple yet effective approach Small Noise Defense (SND). We analyze how SND can defend against query-based black-box attacks and demonstrate its effectiveness against eight state-of-the-art attacks with CIFAR-10 and ImageNet datasets. Even with strong defense ability, SND almost maintains the original classification accuracy and computational speed. SND is readily applicable to pre-trained models by adding only one line of code at the inference.

</p>
</details>

<details><summary><b>Self-Adaptive Reconfigurable Arrays (SARA): Using ML to Assist Scaling GEMM Acceleration</b>
<a href="https://arxiv.org/abs/2101.04799">arxiv:2101.04799</a>
&#x1F4C8; 0 <br>
<p>Ananda Samajdar, Michael Pellauer, Tushar Krishna</p></summary>
<p>

**Abstract:** With increasing diversity in Deep Neural Network(DNN) models in terms of layer shapes and sizes, the research community has been investigating flexible/reconfigurable accelerator substrates. This line of research has opened up two challenges. The first is to determine the appropriate amount of flexibility within an accelerator array that that can trade-off the performance benefits versus the area overheads of the reconfigurability. The second is being able to determine the right configuration of the array for the current DNN model and/or layer and reconfigure the accelerator at runtime. This work introduces a new class of accelerators that we call Self Adaptive Reconfigurable Array (SARA). SARA architectures comprise of both a reconfigurable array and a hardware unit capable of determining an optimized configuration for the array at runtime. We demonstrate an instance of SARA with an accelerator we call SAGAR, which introduces a novel reconfigurable systolic array that can be configured to work as a distributed collection of smaller arrays of various sizes or as a single array with flexible aspect ratios. We also develop a novel recommendation neural network called ADAPTNET which recommends an array configuration and dataflow for the current layer parameters. ADAPTNET runs on an integrated custom hardware ADAPTNETX that runs ADAPTNET at runtime and reconfigures the array, making the entire accelerator self-sufficient. SAGAR is capable of providing the same mapping flexibility as a collection of 10244x4 arrays working as a distributed system while achieving 3.5x more power efficiency and 3.2x higher compute density Furthermore, the runtime achieved on the recommended parameters from ADAPTNET is 99.93% of the best achievable runtime.

</p>
</details>

<details><summary><b>Improving Classification Accuracy with Graph Filtering</b>
<a href="https://arxiv.org/abs/2101.04789">arxiv:2101.04789</a>
&#x1F4C8; 0 <br>
<p>Mounia Hamidouche, Carlos Lassance, Yuqing Hu, Lucas Drumetz, Bastien Pasdeloup, Vincent Gripon</p></summary>
<p>

**Abstract:** In machine learning, classifiers are typically susceptible to noise in the training data. In this work, we aim at reducing intra-class noise with the help of graph filtering to improve the classification performance. Considered graphs are obtained by connecting samples of the training set that belong to a same class depending on the similarity of their representation in a latent space. We show that the proposed graph filtering methodology has the effect of asymptotically reducing intra-class variance, while maintaining the mean. While our approach applies to all classification problems in general, it is particularly useful in few-shot settings, where intra-class noise can have a huge impact due to the small sample selection. Using standardized benchmarks in the field of vision, we empirically demonstrate the ability of the proposed method to slightly improve state-of-the-art results in both cases of few-shot and standard classification.

</p>
</details>

<details><summary><b>Survival of the strictest: Stable and unstable equilibria under regularized learning with partial information</b>
<a href="https://arxiv.org/abs/2101.04667">arxiv:2101.04667</a>
&#x1F4C8; 0 <br>
<p>Angeliki Giannou, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Panayotis Mertikopoulos</p></summary>
<p>

**Abstract:** In this paper, we examine the Nash equilibrium convergence properties of no-regret learning in general N-player games. For concreteness, we focus on the archetypal follow the regularized leader (FTRL) family of algorithms, and we consider the full spectrum of uncertainty that the players may encounter - from noisy, oracle-based feedback, to bandit, payoff-based information. In this general context, we establish a comprehensive equivalence between the stability of a Nash equilibrium and its support: a Nash equilibrium is stable and attracting with arbitrarily high probability if and only if it is strict (i.e., each equilibrium strategy has a unique best response). This equivalence extends existing continuous-time versions of the folk theorem of evolutionary game theory to a bona fide algorithmic learning setting, and it provides a clear refinement criterion for the prediction of the day-to-day behavior of no-regret learning in games

</p>
</details>

<details><summary><b>Multi-Robot Gaussian Process Estimation and Coverage: A Deterministic Sequencing Algorithm and Regret Analysis</b>
<a href="https://arxiv.org/abs/2101.04306">arxiv:2101.04306</a>
&#x1F4C8; 0 <br>
<p>Lai Wei, Andrew McDonald, Vaibhav Srivastava</p></summary>
<p>

**Abstract:** We study the problem of distributed multi-robot coverage over an unknown, nonuniform sensory field. Modeling the sensory field as a realization of a Gaussian Process and using Bayesian techniques, we devise a policy which aims to balance the tradeoff between learning the sensory function and covering the environment. We propose an adaptive coverage algorithm called Deterministic Sequencing of Learning and Coverage (DSLC) that schedules learning and coverage epochs such that its emphasis gradually shifts from exploration to exploitation while never fully ceasing to learn. Using a novel definition of coverage regret which characterizes overall coverage performance of a multi-robot team over a time horizon $T$, we analyze DSLC to provide an upper bound on expected cumulative coverage regret. Finally, we illustrate the empirical performance of the algorithm through simulations of the coverage task over an unknown distribution of wildfires.

</p>
</details>


{% endraw %}
Prev: [2021.01.11]({{ '/2021/01/11/2021.01.11.html' | relative_url }})  Next: [2021.01.13]({{ '/2021/01/13/2021.01.13.html' | relative_url }})