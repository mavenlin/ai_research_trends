Prev: [2022.03.24]({{ '/2022/03/24/2022.03.24.html' | relative_url }})  Next: [2022.03.26]({{ '/2022/03/26/2022.03.26.html' | relative_url }})
{% raw %}
## Summary for 2022-03-25, created on 2022-04-05


<details><summary><b>Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion</b>
<a href="https://arxiv.org/abs/2203.13777">arxiv:2203.13777</a>
&#x1F4C8; 91 <br>
<p>Tianpei Gu, Guangyi Chen, Junlong Li, Chunze Lin, Yongming Rao, Jie Zhou, Jiwen Lu</p></summary>
<p>

**Abstract:** Human behavior has the nature of indeterminacy, which requires the pedestrian trajectory prediction system to model the multi-modality of future motion states. Unlike existing stochastic trajectory prediction methods which usually use a latent variable to represent multi-modality, we explicitly simulate the process of human motion variation from indeterminate to determinate. In this paper, we present a new framework to formulate the trajectory prediction task as a reverse process of motion indeterminacy diffusion (MID), in which we progressively discard indeterminacy from all the walkable areas until reaching the desired trajectory. This process is learned with a parameterized Markov chain conditioned by the observed trajectories. We can adjust the length of the chain to control the degree of indeterminacy and balance the diversity and determinacy of the predictions. Specifically, we encode the history behavior information and the social interactions as a state embedding and devise a Transformer-based diffusion model to capture the temporal dependencies of trajectories. Extensive experiments on the human trajectory prediction benchmarks including the Stanford Drone and ETH/UCY datasets demonstrate the superiority of our method. Code is available at https://github.com/gutianpei/MID.

</p>
</details>

<details><summary><b>EnHDC: Ensemble Learning for Brain-Inspired Hyperdimensional Computing</b>
<a href="https://arxiv.org/abs/2203.13542">arxiv:2203.13542</a>
&#x1F4C8; 75 <br>
<p>Ruixuan Wang, Dongning Ma, Xun Jiao</p></summary>
<p>

**Abstract:** Ensemble learning is a classical learning method utilizing a group of weak learners to form a strong learner, which aims to increase the accuracy of the model. Recently, brain-inspired hyperdimensional computing (HDC) becomes an emerging computational paradigm that has achieved success in various domains such as human activity recognition, voice recognition, and bio-medical signal classification. HDC mimics the brain cognition and leverages high-dimensional vectors (e.g., 10000 dimensions) with fully distributed holographic representation and (pseudo-)randomness. This paper presents the first effort in exploring ensemble learning in the context of HDC and proposes the first ensemble HDC model referred to as EnHDC. EnHDC uses a majority voting-based mechanism to synergistically integrate the prediction outcomes of multiple base HDC classifiers. To enhance the diversity of base classifiers, we vary the encoding mechanisms, dimensions, and data width settings among base classifiers. By applying EnHDC on a wide range of applications, results show that the EnHDC can achieve on average 3.2\% accuracy improvement over a single HDC classifier. Further, we show that EnHDC with reduced dimensionality, e.g., 1000 dimensions, can achieve similar or even surpass the accuracy of baseline HDC with higher dimensionality, e.g., 10000 dimensions. This leads to a 20\% reduction of storage requirement of HDC model, which is key to enabling HDC on low-power computing platforms.

</p>
</details>

<details><summary><b>An Audit of Misinformation Filter Bubbles on YouTube: Bubble Bursting and Recent Behavior Changes</b>
<a href="https://arxiv.org/abs/2203.13769">arxiv:2203.13769</a>
&#x1F4C8; 60 <br>
<p>Matus Tomlein, Branislav Pecher, Jakub Simko, Ivan Srba, Robert Moro, Elena Stefancova, Michal Kompan, Andrea Hrckova, Juraj Podrouzek, Maria Bielikova</p></summary>
<p>

**Abstract:** The negative effects of misinformation filter bubbles in adaptive systems have been known to researchers for some time. Several studies investigated, most prominently on YouTube, how fast a user can get into a misinformation filter bubble simply by selecting wrong choices from the items offered. Yet, no studies so far have investigated what it takes to burst the bubble, i.e., revert the bubble enclosure. We present a study in which pre-programmed agents (acting as YouTube users) delve into misinformation filter bubbles by watching misinformation promoting content (for various topics). Then, by watching misinformation debunking content, the agents try to burst the bubbles and reach more balanced recommendation mixes. We recorded the search results and recommendations, which the agents encountered, and analyzed them for the presence of misinformation. Our key finding is that bursting of a filter bubble is possible, albeit it manifests differently from topic to topic. Moreover, we observe that filter bubbles do not truly appear in some situations. We also draw a direct comparison with a previous study. Sadly, we did not find much improvements in misinformation occurrences, despite recent pledges by YouTube.

</p>
</details>

<details><summary><b>Efficient-VDVAE: Less is more</b>
<a href="https://arxiv.org/abs/2203.13751">arxiv:2203.13751</a>
&#x1F4C8; 59 <br>
<p>Louay Hazami, Rayhane Mama, Ragavan Thurairatnam</p></summary>
<p>

**Abstract:** Hierarchical VAEs have emerged in recent years as a reliable option for maximum likelihood estimation. However, instability issues and demanding computational requirements have hindered research progress in the area. We present simple modifications to the Very Deep VAE to make it converge up to $2.6\times$ faster, save up to $20\times$ in memory load and improve stability during training. Despite these changes, our models achieve comparable or better negative log-likelihood performance than current state-of-the-art models on all $7$ commonly used image datasets we evaluated on. We also make an argument against using 5-bit benchmarks as a way to measure hierarchical VAE's performance due to undesirable biases caused by the 5-bit quantization. Additionally, we empirically demonstrate that roughly $3\%$ of the hierarchical VAE's latent space dimensions is sufficient to encode most of the image information, without loss of performance, opening up the doors to efficiently leverage the hierarchical VAEs' latent space in downstream tasks. We release our source code and models at https://github.com/Rayhane-mamah/Efficient-VDVAE .

</p>
</details>

<details><summary><b>Improving Contrastive Learning with Model Augmentation</b>
<a href="https://arxiv.org/abs/2203.15508">arxiv:2203.15508</a>
&#x1F4C8; 40 <br>
<p>Zhiwei Liu, Yongjun Chen, Jia Li, Man Luo, Philip S. Yu, Caiming Xiong</p></summary>
<p>

**Abstract:** The sequential recommendation aims at predicting the next items in user behaviors, which can be solved by characterizing item relationships in sequences. Due to the data sparsity and noise issues in sequences, a new self-supervised learning (SSL) paradigm is proposed to improve the performance, which employs contrastive learning between positive and negative views of sequences.
  However, existing methods all construct views by adopting augmentation from data perspectives, while we argue that 1) optimal data augmentation methods are hard to devise, 2) data augmentation methods destroy sequential correlations, and 3) data augmentation fails to incorporate comprehensive self-supervised signals.
  Therefore, we investigate the possibility of model augmentation to construct view pairs. We propose three levels of model augmentation methods: neuron masking, layer dropping, and encoder complementing.
  This work opens up a novel direction in constructing views for contrastive SSL. Experiments verify the efficacy of model augmentation for the SSL in the sequential recommendation. Code is available\footnote{\url{https://github.com/salesforce/SRMA}}.

</p>
</details>

<details><summary><b>Unsupervised Learning of Temporal Abstractions with Slot-based Transformers</b>
<a href="https://arxiv.org/abs/2203.13573">arxiv:2203.13573</a>
&#x1F4C8; 40 <br>
<p>Anand Gopalakrishnan, Kazuki Irie, JÃ¼rgen Schmidhuber, Sjoerd van Steenkiste</p></summary>
<p>

**Abstract:** The discovery of reusable sub-routines simplifies decision-making and planning in complex reinforcement learning problems. Previous approaches propose to learn such temporal abstractions in a purely unsupervised fashion through observing state-action trajectories gathered from executing a policy. However, a current limitation is that they process each trajectory in an entirely sequential manner, which prevents them from revising earlier decisions about sub-routine boundary points in light of new incoming information. In this work we propose SloTTAr, a fully parallel approach that integrates sequence processing Transformers with a Slot Attention module and adaptive computation for learning about the number of such sub-routines in an unsupervised fashion. We demonstrate how SloTTAr is capable of outperforming strong baselines in terms of boundary point discovery, even for sequences containing variable amounts of sub-routines, while being up to 7x faster to train on existing benchmarks.

</p>
</details>

<details><summary><b>Reinforcement Learning with Action-Free Pre-Training from Videos</b>
<a href="https://arxiv.org/abs/2203.13880">arxiv:2203.13880</a>
&#x1F4C8; 26 <br>
<p>Younggyo Seo, Kimin Lee, Stephen James, Pieter Abbeel</p></summary>
<p>

**Abstract:** Recent unsupervised pre-training methods have shown to be effective on language and vision domains by learning useful representations for multiple downstream tasks. In this paper, we investigate if such unsupervised pre-training methods can also be effective for vision-based reinforcement learning (RL). To this end, we introduce a framework that learns representations useful for understanding the dynamics via generative pre-training on videos. Our framework consists of two phases: we pre-train an action-free latent video prediction model, and then utilize the pre-trained representations for efficiently learning action-conditional world models on unseen environments. To incorporate additional action inputs during fine-tuning, we introduce a new architecture that stacks an action-conditional latent prediction model on top of the pre-trained action-free prediction model. Moreover, for better exploration, we propose a video-based intrinsic bonus that leverages pre-trained representations. We demonstrate that our framework significantly improves both final performances and sample-efficiency of vision-based RL in a variety of manipulation and locomotion tasks. Code is available at https://github.com/younggyoseo/apv.

</p>
</details>

<details><summary><b>BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis</b>
<a href="https://arxiv.org/abs/2203.13508">arxiv:2203.13508</a>
&#x1F4C8; 16 <br>
<p>Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu</p></summary>
<p>

**Abstract:** Diffusion probabilistic models (DPMs) and their extensions have emerged as competitive generative models yet confront challenges of efficient sampling. We propose a new bilateral denoising diffusion model (BDDM) that parameterizes both the forward and reverse processes with a schedule network and a score network, which can train with a novel bilateral modeling objective. We show that the new surrogate objective can achieve a lower bound of the log marginal likelihood tighter than a conventional surrogate. We also find that BDDM allows inheriting pre-trained score network parameters from any DPMs and consequently enables speedy and stable learning of the schedule network and optimization of a noise schedule for sampling. Our experiments demonstrate that BDDMs can generate high-fidelity audio samples with as few as three sampling steps. Moreover, compared to other state-of-the-art diffusion-based neural vocoders, BDDMs produce comparable or higher quality samples indistinguishable from human speech, notably with only seven sampling steps (143x faster than WaveGrad and 28.6x faster than DiffWave). We release our code at https://github.com/tencent-ailab/bddm.

</p>
</details>

<details><summary><b>SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks</b>
<a href="https://arxiv.org/abs/2203.13913">arxiv:2203.13913</a>
&#x1F4C8; 10 <br>
<p>Christopher Morris, Gaurav Rattan, Sandra Kiefer, Siamak Ravanbakhsh</p></summary>
<p>

**Abstract:** While (message-passing) graph neural networks have clear limitations in approximating permutation-equivariant functions over graphs or general relational data, more expressive, higher-order graph neural networks do not scale to large graphs. They either operate on $k$-order tensors or consider all $k$-node subgraphs, implying an exponential dependence on $k$ in memory requirements, and do not adapt to the sparsity of the graph. By introducing new heuristics for the graph isomorphism problem, we devise a class of universal, permutation-equivariant graph networks, which, unlike previous architectures, offer a fine-grained control between expressivity and scalability and adapt to the sparsity of the graph. These architectures lead to vastly reduced computation times compared to standard higher-order graph networks in the supervised node- and graph-level classification and regression regime while significantly improving over standard graph neural network and graph kernel architectures in terms of predictive performance.

</p>
</details>

<details><summary><b>Learning to segment fetal brain tissue from noisy annotations</b>
<a href="https://arxiv.org/abs/2203.14962">arxiv:2203.14962</a>
&#x1F4C8; 9 <br>
<p>Davood Karimi, Caitlin K. Rollins, Clemente Velasco-Annis, Abdelhakim Ouaalam, Ali Gholipour</p></summary>
<p>

**Abstract:** Automatic fetal brain tissue segmentation can enhance the quantitative assessment of brain development at this critical stage. Deep learning methods represent the state of the art in medical image segmentation and have also achieved impressive results in brain segmentation. However, effective training of a deep learning model to perform this task requires a large number of training images to represent the rapid development of the transient fetal brain structures. On the other hand, manual multi-label segmentation of a large number of 3D images is prohibitive. To address this challenge, we segmented 272 training images, covering 19-39 gestational weeks, using an automatic multi-atlas segmentation strategy based on deformable registration and probabilistic atlas fusion, and manually corrected large errors in those segmentations. Since this process generated a large training dataset with noisy segmentations, we developed a novel label smoothing procedure and a loss function to train a deep learning model with smoothed noisy segmentations. Our proposed methods properly account for the uncertainty in tissue boundaries. We evaluated our method on 23 manually-segmented test images of a separate set of fetuses. Results show that our method achieves an average Dice similarity coefficient of 0.893 and 0.916 for the transient structures of younger and older fetuses, respectively. Our method generated results that were significantly more accurate than several state-of-the-art methods including nnU-Net that achieved the closest results to our method. Our trained model can serve as a valuable tool to enhance the accuracy and reproducibility of fetal brain analysis in MRI.

</p>
</details>

<details><summary><b>Data Selection Curriculum for Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2203.13867">arxiv:2203.13867</a>
&#x1F4C8; 9 <br>
<p>Tasnim Mohiuddin, Philipp Koehn, Vishrav Chaudhary, James Cross, Shruti Bhosale, Shafiq Joty</p></summary>
<p>

**Abstract:** Neural Machine Translation (NMT) models are typically trained on heterogeneous data that are concatenated and randomly shuffled. However, not all of the training data are equally useful to the model. Curriculum training aims to present the data to the NMT models in a meaningful order. In this work, we introduce a two-stage curriculum training framework for NMT where we fine-tune a base NMT model on subsets of data, selected by both deterministic scoring using pre-trained methods and online scoring that considers prediction scores of the emerging NMT model. Through comprehensive experiments on six language pairs comprising low- and high-resource languages from WMT'21, we have shown that our curriculum strategies consistently demonstrate better quality (up to +2.2 BLEU improvement) and faster convergence (approximately 50% fewer updates).

</p>
</details>

<details><summary><b>Cluster Algebras: Network Science and Machine Learning</b>
<a href="https://arxiv.org/abs/2203.13847">arxiv:2203.13847</a>
&#x1F4C8; 9 <br>
<p>Pierre-Philippe Dechant, Yang-Hui He, Elli Heyes, Edward Hirst</p></summary>
<p>

**Abstract:** Cluster algebras have recently become an important player in mathematics and physics. In this work, we investigate them through the lens of modern data science, specifically with techniques from network science and machine-learning. Network analysis methods are applied to the exchange graphs for cluster algebras of varying mutation types. The analysis indicates that when the graphs are represented without identifying by permutation equivalence between clusters an elegant symmetry emerges in the quiver exchange graph embedding. The ratio between number of seeds and number of quivers associated to this symmetry is computed for finite Dynkin type algebras up to rank 5, and conjectured for higher ranks. Simple machine learning techniques successfully learn to differentiate cluster algebras from their seeds. The learning performance exceeds 0.9 accuracies between algebras of the same mutation type and between types, as well as relative to artificially generated data.

</p>
</details>

<details><summary><b>TimeReplayer: Unlocking the Potential of Event Cameras for Video Interpolation</b>
<a href="https://arxiv.org/abs/2203.13859">arxiv:2203.13859</a>
&#x1F4C8; 8 <br>
<p>Weihua He, Kaichao You, Zhendong Qiao, Xu Jia, Ziyang Zhang, Wenhui Wang, Huchuan Lu, Yaoyuan Wang, Jianxing Liao</p></summary>
<p>

**Abstract:** Recording fast motion in a high FPS (frame-per-second) requires expensive high-speed cameras. As an alternative, interpolating low-FPS videos from commodity cameras has attracted significant attention. If only low-FPS videos are available, motion assumptions (linear or quadratic) are necessary to infer intermediate frames, which fail to model complex motions. Event camera, a new camera with pixels producing events of brightness change at the temporal resolution of $Î¼s$ $(10^{-6}$ second $)$, is a game-changing device to enable video interpolation at the presence of arbitrarily complex motion. Since event camera is a novel sensor, its potential has not been fulfilled due to the lack of processing algorithms. The pioneering work Time Lens introduced event cameras to video interpolation by designing optical devices to collect a large amount of paired training data of high-speed frames and events, which is too costly to scale. To fully unlock the potential of event cameras, this paper proposes a novel TimeReplayer algorithm to interpolate videos captured by commodity cameras with events. It is trained in an unsupervised cycle-consistent style, canceling the necessity of high-speed training data and bringing the additional ability of video extrapolation. Its state-of-the-art results and demo videos in supplementary reveal the promising future of event-based vision.

</p>
</details>

<details><summary><b>Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities</b>
<a href="https://arxiv.org/abs/2203.13883">arxiv:2203.13883</a>
&#x1F4C8; 7 <br>
<p>Sara Abdali</p></summary>
<p>

**Abstract:** As social media platforms are evolving from text-based forums into multi-modal environments, the nature of misinformation in social media is also changing accordingly. Taking advantage of the fact that visual modalities such as images and videos are more favorable and attractive to the users, and textual contents are sometimes skimmed carelessly, misinformation spreaders have recently targeted contextual correlations between modalities e.g., text and image. Thus, many research efforts have been put into development of automatic techniques for detecting possible cross-modal discordances in web-based media. In this work, we aim to analyze, categorize and identify existing approaches in addition to challenges and shortcomings they face in order to unearth new opportunities in furthering the research in the field of multi-modal misinformation detection.

</p>
</details>

<details><summary><b>Polarization Multiplexed Diffractive Computing: All-Optical Implementation of a Group of Linear Transformations Through a Polarization-Encoded Diffractive Network</b>
<a href="https://arxiv.org/abs/2203.13482">arxiv:2203.13482</a>
&#x1F4C8; 7 <br>
<p>Jingxi Li, Yi-Chun Hung, Onur Kulce, Deniz Mengu, Aydogan Ozcan</p></summary>
<p>

**Abstract:** Research on optical computing has recently attracted significant attention due to the transformative advances in machine learning. Among different approaches, diffractive optical networks composed of spatially-engineered transmissive surfaces have been demonstrated for all-optical statistical inference and performing arbitrary linear transformations using passive, free-space optical layers. Here, we introduce a polarization multiplexed diffractive processor to all-optically perform multiple, arbitrarily-selected linear transformations through a single diffractive network trained using deep learning. In this framework, an array of pre-selected linear polarizers is positioned between trainable transmissive diffractive materials that are isotropic, and different target linear transformations (complex-valued) are uniquely assigned to different combinations of input/output polarization states. The transmission layers of this polarization multiplexed diffractive network are trained and optimized via deep learning and error-backpropagation by using thousands of examples of the input/output fields corresponding to each one of the complex-valued linear transformations assigned to different input/output polarization combinations. Our results and analysis reveal that a single diffractive network can successfully approximate and all-optically implement a group of arbitrarily-selected target transformations with a negligible error when the number of trainable diffractive features/neurons (N) approaches N_p x N_i x N_o, where N_i and N_o represent the number of pixels at the input and output fields-of-view, respectively, and N_p refers to the number of unique linear transformations assigned to different input/output polarization combinations. This polarization-multiplexed all-optical diffractive processor can find various applications in optical computing and polarization-based machine vision tasks.

</p>
</details>

<details><summary><b>Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-resolution</b>
<a href="https://arxiv.org/abs/2203.13963">arxiv:2203.13963</a>
&#x1F4C8; 6 <br>
<p>Guangyuan Li, Jun Lv, Yapeng Tian, Qi Dou, Chengyan Wang, Chenliang Xu, Jing Qin</p></summary>
<p>

**Abstract:** Magnetic resonance imaging (MRI) can present multi-contrast images of the same anatomical structures, enabling multi-contrast super-resolution (SR) techniques. Compared with SR reconstruction using a single-contrast, multi-contrast SR reconstruction is promising to yield SR images with higher quality by leveraging diverse yet complementary information embedded in different imaging modalities. However, existing methods still have two shortcomings: (1) they neglect that the multi-contrast features at different scales contain different anatomical details and hence lack effective mechanisms to match and fuse these features for better reconstruction; and (2) they are still deficient in capturing long-range dependencies, which are essential for the regions with complicated anatomical structures. We propose a novel network to comprehensively address these problems by developing a set of innovative Transformer-empowered multi-scale contextual matching and aggregation techniques; we call it McMRSR. Firstly, we tame transformers to model long-range dependencies in both reference and target images. Then, a new multi-scale contextual matching method is proposed to capture corresponding contexts from reference features at different scales. Furthermore, we introduce a multi-scale aggregation mechanism to gradually and interactively aggregate multi-scale matched features for reconstructing the target SR MR image. Extensive experiments demonstrate that our network outperforms state-of-the-art approaches and has great potential to be applied in clinical practice. Codes are available at https://github.com/XAIMI-Lab/McMRSR.

</p>
</details>

<details><summary><b>Canary Extraction in Natural Language Understanding Models</b>
<a href="https://arxiv.org/abs/2203.13920">arxiv:2203.13920</a>
&#x1F4C8; 6 <br>
<p>Rahil Parikh, Christophe Dupuy, Rahul Gupta</p></summary>
<p>

**Abstract:** Natural Language Understanding (NLU) models can be trained on sensitive information such as phone numbers, zip-codes etc. Recent literature has focused on Model Inversion Attacks (ModIvA) that can extract training data from model parameters. In this work, we present a version of such an attack by extracting canaries inserted in NLU training data. In the attack, an adversary with open-box access to the model reconstructs the canaries contained in the model's training set. We evaluate our approach by performing text completion on canaries and demonstrate that by using the prefix (non-sensitive) tokens of the canary, we can generate the full canary. As an example, our attack is able to reconstruct a four digit code in the training dataset of the NLU model with a probability of 0.5 in its best configuration. As countermeasures, we identify several defense mechanisms that, when combined, effectively eliminate the risk of ModIvA in our experiments.

</p>
</details>

<details><summary><b>Searching for Network Width with Bilaterally Coupled Network</b>
<a href="https://arxiv.org/abs/2203.13714">arxiv:2203.13714</a>
&#x1F4C8; 6 <br>
<p>Xiu Su, Shan You, Jiyang Xie, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</p></summary>
<p>

**Abstract:** Searching for a more compact network width recently serves as an effective way of channel pruning for the deployment of convolutional neural networks (CNNs) under hardware constraints. To fulfill the searching, a one-shot supernet is usually leveraged to efficiently evaluate the performance \wrt~different network widths. However, current methods mainly follow a \textit{unilaterally augmented} (UA) principle for the evaluation of each width, which induces the training unfairness of channels in supernet. In this paper, we introduce a new supernet called Bilaterally Coupled Network (BCNet) to address this issue. In BCNet, each channel is fairly trained and responsible for the same amount of network widths, thus each network width can be evaluated more accurately. Besides, we propose to reduce the redundant search space and present the BCNetV2 as the enhanced supernet to ensure rigorous training fairness over channels. Furthermore, we leverage a stochastic complementary strategy for training the BCNet, and propose a prior initial population sampling method to boost the performance of the evolutionary search. We also propose the first open-source width benchmark on macro structures named Channel-Bench-Macro for the better comparison of width search algorithms. Extensive experiments on benchmark CIFAR-10 and ImageNet datasets indicate that our method can achieve state-of-the-art or competing performance over other baseline methods. Moreover, our method turns out to further boost the performance of NAS models by refining their network widths. For example, with the same FLOPs budget, our obtained EfficientNet-B0 achieves 77.53\% Top-1 accuracy on ImageNet dataset, surpassing the performance of original setting by 0.65\%.

</p>
</details>

<details><summary><b>Speech-enhanced and Noise-aware Networks for Robust Speech Recognition</b>
<a href="https://arxiv.org/abs/2203.13696">arxiv:2203.13696</a>
&#x1F4C8; 6 <br>
<p>Hung-Shin Lee, Pin-Yuan Chen, Yu Tsao, Hsin-Min Wang</p></summary>
<p>

**Abstract:** Compensation for channel mismatch and noise interference is essential for robust automatic speech recognition. Enhanced speech has been introduced into the multi-condition training of acoustic models to improve their generalization ability. In this paper, a noise-aware training framework based on two cascaded neural structures is proposed to jointly optimize speech enhancement and speech recognition. The feature enhancement module is composed of a multi-task autoencoder, where noisy speech is decomposed into clean speech and noise. By concatenating its enhanced, noise-aware, and noisy features for each frame, the acoustic-modeling module maps each feature-augmented frame into a triphone state by optimizing the lattice-free maximum mutual information and cross entropy between the predicted and actual state sequences. On top of the factorized time delay neural network (TDNN-F) and its convolutional variant (CNN-TDNNF), both with SpecAug, the two proposed systems achieve word error rate (WER) of 3.90% and 3.55%, respectively, on the Aurora-4 task. Compared with the best existing systems that use bigram and trigram language models for decoding, the proposed CNN-TDNNF-based system achieves a relative WER reduction of 15.20% and 33.53%, respectively. In addition, the proposed CNN-TDNNF-based system also outperforms the baseline CNN-TDNNF system on the AMI task.

</p>
</details>

<details><summary><b>Chain-based Discriminative Autoencoders for Speech Recognition</b>
<a href="https://arxiv.org/abs/2203.13687">arxiv:2203.13687</a>
&#x1F4C8; 6 <br>
<p>Hung-Shin Lee, Pin-Tuan Huang, Yao-Fei Cheng, Hsin-Min Wang</p></summary>
<p>

**Abstract:** In our previous work, we proposed a discriminative autoencoder (DcAE) for speech recognition. DcAE combines two training schemes into one. First, since DcAE aims to learn encoder-decoder mappings, the squared error between the reconstructed speech and the input speech is minimized. Second, in the code layer, frame-based phonetic embeddings are obtained by minimizing the categorical cross-entropy between ground truth labels and predicted triphone-state scores. DcAE is developed based on the Kaldi toolkit by treating various TDNN models as encoders. In this paper, we further propose three new versions of DcAE. First, a new objective function that considers both categorical cross-entropy and mutual information between ground truth and predicted triphone-state sequences is used. The resulting DcAE is called a chain-based DcAE (c-DcAE). For application to robust speech recognition, we further extend c-DcAE to hierarchical and parallel structures, resulting in hc-DcAE and pc-DcAE. In these two models, both the error between the reconstructed noisy speech and the input noisy speech and the error between the enhanced speech and the reference clean speech are taken into the objective function. Experimental results on the WSJ and Aurora-4 corpora show that our DcAE models outperform baseline systems.

</p>
</details>

<details><summary><b>Analysis of OODA Loop based on Adversarial for Complex Game Environments</b>
<a href="https://arxiv.org/abs/2203.15502">arxiv:2203.15502</a>
&#x1F4C8; 5 <br>
<p>Xiangri Lu, Hongbin Ma, Zhanqing Wang</p></summary>
<p>

**Abstract:** To address the problem of imperfect confrontation strategy caused by the lack of information of game environment in the simulation of non-complete information dynamic countermeasure modeling for intelligent game, the hierarchical analysis game strategy of confrontation model based on OODA ring (Observation, Orientation, Decision, Action) theory is proposed. At the same time, taking into account the trend of unmanned future warfare, NetLogo software simulation is used to construct a dynamic derivation of the confrontation between two tanks. In the validation process, the OODA loop theory is used to describe the operation process of the complex system between red and blue sides, and the four-step cycle of observation, judgment, decision and execution is carried out according to the number of armor of both sides, and then the OODA loop system adjusts the judgment and decision time coefficients for the next confrontation cycle according to the results of the first cycle. Compared with traditional simulation methods that consider objective factors such as loss rate and support rate, the OODA-loop-based hierarchical game analysis can analyze the confrontation situation more comprehensively.

</p>
</details>

<details><summary><b>Offline Reinforcement Learning Under Value and Density-Ratio Realizability: the Power of Gaps</b>
<a href="https://arxiv.org/abs/2203.13935">arxiv:2203.13935</a>
&#x1F4C8; 5 <br>
<p>Jinglin Chen, Nan Jiang</p></summary>
<p>

**Abstract:** We consider a challenging theoretical problem in offline reinforcement learning (RL): obtaining sample-efficiency guarantees with a dataset lacking sufficient coverage, under only realizability-type assumptions for the function approximators. While the existing theory has addressed learning under realizability and under non-exploratory data separately, no work has been able to address both simultaneously (except for a concurrent work which we compare in detail). Under an additional gap assumption, we provide guarantees to a simple pessimistic algorithm based on a version space formed by marginalized importance sampling, and the guarantee only requires the data to cover the optimal policy and the function classes to realize the optimal value and density-ratio functions. While similar gap assumptions have been used in other areas of RL theory, our work is the first to identify the utility and the novel mechanism of gap assumptions in offline RL with weak function approximation.

</p>
</details>

<details><summary><b>Self-supervised machine learning model for analysis of nanowire morphologies from transmission electron microscopy images</b>
<a href="https://arxiv.org/abs/2203.13875">arxiv:2203.13875</a>
&#x1F4C8; 5 <br>
<p>Shizhao Lu, Brian Montz, Todd Emrick, Arthi Jayaraman</p></summary>
<p>

**Abstract:** In the field of soft materials, microscopy is the first and often only accessible method for structural characterization. There is a growing interest in the development of machine learning methods that can automate the analysis and interpretation of microscopy images. Typically training of machine learning models require large numbers of images with associated structural labels, however, manual labeling of images requires domain knowledge and is prone to human error and subjectivity. To overcome these limitations, we present a self-supervised transfer learning approach that uses a small number of labeled microscopy images for training and performs as effectively as methods trained on significantly larger data sets. Specifically, we train an image encoder with unlabeled images and use that encoder for transfer learning of different downstream image tasks (classification and segmentation) with a minimal number of labeled images for training.

</p>
</details>

<details><summary><b>Which Generative Adversarial Network Yields High-Quality Synthetic Medical Images: Investigation Using AMD Image Datasets</b>
<a href="https://arxiv.org/abs/2203.13856">arxiv:2203.13856</a>
&#x1F4C8; 5 <br>
<p>Guilherme C. Oliveira, Gustavo H. Rosa, Daniel C. G. Pedronette, JoÃ£o P. Papa, Himeesh Kumar, Leandro A. Passos, Dinesh Kumar</p></summary>
<p>

**Abstract:** Deep learning has been proposed for the assessment and classification of medical images. However, many medical image databases with appropriately labeled and annotated images are small and imbalanced, and thus unsuitable to train and validate such models. The option is to generate synthetic images and one successful technique has been patented which limits its use for others. We have developed a free-access, alternate method for generating synthetic high-resolution images using Generative Adversarial Networks (GAN) for data augmentation and showed their effectiveness using eye-fundus images for Age-Related Macular Degeneration (AMD) identification. Ten different GAN architectures were compared to generate synthetic eye-fundus images with and without AMD. Data from three public databases were evaluated using the FrÃ©chet Inception Distance (FID), two clinical experts and deep-learning classification. The results show that StyleGAN2 reached the lowest FID (166.17), and clinicians could not accurately differentiate between real and synthetic images. ResNet-18 architecture obtained the best performance with 85% accuracy and outperformed the two experts in detecting AMD fundus images, whose average accuracy was 77.5%. These results are similar to a recently patented method, and will provide an alternative to generating high-quality synthetic medical images. Free access has been provided to the entire method to facilitate the further development of this field.

</p>
</details>

<details><summary><b>Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap</b>
<a href="https://arxiv.org/abs/2203.13457">arxiv:2203.13457</a>
&#x1F4C8; 5 <br>
<p>Yifei Wang, Qi Zhang, Yisen Wang, Jiansheng Yang, Zhouchen Lin</p></summary>
<p>

**Abstract:** Recently, contrastive learning has risen to be a promising approach for large-scale self-supervised learning. However, theoretical understanding of how it works is still unclear. In this paper, we propose a new guarantee on the downstream performance without resorting to the conditional independence assumption that is widely adopted in previous work but hardly holds in practice. Our new theory hinges on the insight that the support of different intra-class samples will become more overlapped under aggressive data augmentations, thus simply aligning the positive samples (augmented views of the same sample) could make contrastive learning cluster intra-class samples together. Based on this augmentation overlap perspective, theoretically, we obtain asymptotically closed bounds for downstream performance under weaker assumptions, and empirically, we propose an unsupervised model selection metric ARC that aligns well with downstream accuracy. Our theory suggests an alternative understanding of contrastive learning: the role of aligning positive samples is more like a surrogate task than an ultimate goal, and the overlapped augmented views (i.e., the chaos) create a ladder for contrastive learning to gradually learn class-separated representations. The code for computing ARC is available at https://github.com/zhangq327/ARC.

</p>
</details>

<details><summary><b>A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training</b>
<a href="https://arxiv.org/abs/2203.13455">arxiv:2203.13455</a>
&#x1F4C8; 5 <br>
<p>Yifei Wang, Yisen Wang, Jiansheng Yang, Zhouchen Lin</p></summary>
<p>

**Abstract:** Adversarial Training (AT) is known as an effective approach to enhance the robustness of deep neural networks. Recently researchers notice that robust models with AT have good generative ability and can synthesize realistic images, while the reason behind it is yet under-explored. In this paper, we demystify this phenomenon by developing a unified probabilistic framework, called Contrastive Energy-based Models (CEM). On the one hand, we provide the first probabilistic characterization of AT through a unified understanding of robustness and generative ability. On the other hand, our unified framework can be extended to the unsupervised scenario, which interprets unsupervised contrastive learning as an important sampling of CEM. Based on these, we propose a principled method to develop adversarial learning and sampling methods. Experiments show that the sampling methods derived from our framework improve the sample quality in both supervised and unsupervised learning. Notably, our unsupervised adversarial sampling method achieves an Inception score of 9.61 on CIFAR-10, which is superior to previous energy-based models and comparable to state-of-the-art generative models.

</p>
</details>

<details><summary><b>Deep Multi-modal Fusion of Image and Non-image Data in Disease Diagnosis and Prognosis: A Review</b>
<a href="https://arxiv.org/abs/2203.15588">arxiv:2203.15588</a>
&#x1F4C8; 4 <br>
<p>Can Cui, Haichun Yang, Yaohong Wang, Shilin Zhao, Zuhayr Asad, Lori A. Coburn, Keith T. Wilson, Bennett A. Landman, Yuankai Huo</p></summary>
<p>

**Abstract:** The rapid development of diagnostic technologies in healthcare is leading to higher requirements for physicians to handle and integrate the heterogeneous, yet complementary data that are produced during routine practice. For instance, the personalized diagnosis and treatment planning for a single cancer patient relies on the various images (e.g., radiological, pathological, and camera images) and non-image data (e.g., clinical data and genomic data). However, such decision-making procedures can be subjective, qualitative, and have large inter-subject variabilities. With the recent advances in multi-modal deep learning technologies, an increasingly large number of efforts have been devoted to a key question: how do we extract and aggregate multi-modal information to ultimately provide more objective, quantitative computer-aided clinical decision making? This paper reviews the recent studies on dealing with such a question. Briefly, this review will include the (1) overview of current multi-modal learning workflows, (2) summarization of multi-modal fusion methods, (3) discussion of the performance, (4) applications in disease diagnosis and prognosis, and (5) challenges and future directions.

</p>
</details>

<details><summary><b>Deep Learning for Encrypted Traffic Classification and Unknown Data Detection</b>
<a href="https://arxiv.org/abs/2203.15501">arxiv:2203.15501</a>
&#x1F4C8; 4 <br>
<p>Madushi H. Pathmaperuma, Yogachandran Rahulamathavan, Safak Dogan, Ahmet M. Kondoz, Rongxing Lu</p></summary>
<p>

**Abstract:** Despite the widespread use of encryption techniques to provide confidentiality over Internet communications, mobile device users are still susceptible to privacy and security risks. In this paper, a new Deep Neural Network (DNN) based user activity detection framework is proposed to identify fine grained user activities performed on mobile applications (known as in-app activities) from a sniffed encrypted Internet traffic stream. One of the challenges is that there are countless applications, and it is practically impossible to collect and train a DNN model using all possible data from them. Therefore, in this work we exploit the probability distribution of DNN output layer to filter the data from applications that are not considered during the model training (i.e., unknown data). The proposed framework uses a time window based approach to divide the traffic flow of an activity into segments, so that in-app activities can be identified just by observing only a fraction of the activity related traffic. Our tests have shown that the DNN based framework has demonstrated an accuracy of 90% or above in identifying previously trained in-app activities and an average accuracy of 79% in identifying previously untrained in-app activity traffic as unknown data when this framework is employed.

</p>
</details>

<details><summary><b>Deep Learning and Artificial General Intelligence: Still a Long Way to Go</b>
<a href="https://arxiv.org/abs/2203.14963">arxiv:2203.14963</a>
&#x1F4C8; 4 <br>
<p>Maciej Åwiechowski</p></summary>
<p>

**Abstract:** In recent years, deep learning using neural network architecture, i.e. deep neural networks, has been on the frontier of computer science research. It has even lead to superhuman performance in some problems, e.g., in computer vision, games and biology, and as a result the term deep learning revolution was coined. The undisputed success and rapid growth of deep learning suggests that, in future, it might become an enabler for Artificial General Intelligence (AGI). In this article, we approach this statement critically showing five major reasons of why deep neural networks, as of the current state, are not ready to be the technique of choice for reaching AGI.

</p>
</details>

<details><summary><b>GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection</b>
<a href="https://arxiv.org/abs/2203.13954">arxiv:2203.13954</a>
&#x1F4C8; 4 <br>
<p>Yue Liao, Aixi Zhang, Miao Lu, Yongliang Wang, Xiaobo Li, Si Liu</p></summary>
<p>

**Abstract:** The task of Human-Object Interaction~(HOI) detection could be divided into two core problems, i.e., human-object association and interaction understanding. In this paper, we reveal and address the disadvantages of the conventional query-driven HOI detectors from the two aspects. For the association, previous two-branch methods suffer from complex and costly post-matching, while single-branch methods ignore the features distinction in different tasks. We propose Guided-Embedding Network~(GEN) to attain a two-branch pipeline without post-matching. In GEN, we design an instance decoder to detect humans and objects with two independent query sets and a position Guided Embedding~(p-GE) to mark the human and object in the same position as a pair. Besides, we design an interaction decoder to classify interactions, where the interaction queries are made of instance Guided Embeddings (i-GE) generated from the outputs of each instance decoder layer. For the interaction understanding, previous methods suffer from long-tailed distribution and zero-shot discovery. This paper proposes a Visual-Linguistic Knowledge Transfer (VLKT) training strategy to enhance interaction understanding by transferring knowledge from a visual-linguistic pre-trained model CLIP. In specific, we extract text embeddings for all labels with CLIP to initialize the classifier and adopt a mimic loss to minimize the visual feature distance between GEN and CLIP. As a result, GEN-VLKT outperforms the state of the art by large margins on multiple datasets, e.g., +5.05 mAP on HICO-Det. The source codes are available at https://github.com/YueLiao/gen-vlkt.

</p>
</details>

<details><summary><b>SolidGen: An Autoregressive Model for Direct B-rep Synthesis</b>
<a href="https://arxiv.org/abs/2203.13944">arxiv:2203.13944</a>
&#x1F4C8; 4 <br>
<p>Pradeep Kumar Jayaraman, Joseph G. Lambourne, Nishkrit Desai, Karl D. D. Willis, Aditya Sanghi, Nigel J. W. Morris</p></summary>
<p>

**Abstract:** The Boundary representation (B-rep) format is the de-facto shape representation in computer-aided design (CAD) to model watertight solid objects. Recent approaches to generating CAD models have focused on learning sketch-and-extrude modeling sequences that are executed by a solid modeling kernel in postprocess to recover a B-rep. In this paper we present a new approach that enables learning from and synthesizing B-reps without the need for supervision through CAD modeling sequence data. Our method SolidGen, is an autoregressive neural network that models the B-rep directly by predicting the vertices, edges and faces using Transformer-based and pointer neural networks. Key to achieving this is our Indexed Boundary Representation that references B-rep vertices, edges and faces in a well-defined hierarchy to capture the geometric and topological relations suitable for use with machine learning. SolidGen can be easily conditioned on contexts e.g., class labels thanks to its probabilistic modeling of the B-rep distribution. We demonstrate qualitatively, quantitatively and through perceptual evaluation by human subjects that SolidGen can produce high quality, realistic looking CAD models.

</p>
</details>

<details><summary><b>Concept Embedding Analysis: A Review</b>
<a href="https://arxiv.org/abs/2203.13909">arxiv:2203.13909</a>
&#x1F4C8; 4 <br>
<p>Gesina Schwalbe</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) have found their way into many applications with potential impact on the safety, security, and fairness of human-machine-systems. Such require basic understanding and sufficient trust by the users. This motivated the research field of explainable artificial intelligence (XAI), i.e. finding methods for opening the "black-boxes" DNNs represent. For the computer vision domain in specific, practical assessment of DNNs requires a globally valid association of human interpretable concepts with internals of the model. The research field of concept (embedding) analysis (CA) tackles this problem: CA aims to find global, assessable associations of humanly interpretable semantic concepts (e.g., eye, bearded) with internal representations of a DNN. This work establishes a general definition of CA and a taxonomy for CA methods, uniting several ideas from literature. That allows to easily position and compare CA approaches. Guided by the defined notions, the current state-of-the-art research regarding CA methods and interesting applications are reviewed. More than thirty relevant methods are discussed, compared, and categorized. Finally, for practitioners, a survey of fifteen datasets is provided that have been used for supervised concept analysis. Open challenges and research directions are pointed out at the end.

</p>
</details>

<details><summary><b>Automatic Debiased Machine Learning for Dynamic Treatment Effects</b>
<a href="https://arxiv.org/abs/2203.13887">arxiv:2203.13887</a>
&#x1F4C8; 4 <br>
<p>Rahul Singh, Vasilis Syrgkanis</p></summary>
<p>

**Abstract:** We extend the idea of automated debiased machine learning to the dynamic treatment regime. We show that the multiply robust formula for the dynamic treatment regime with discrete treatments can be re-stated in terms of a recursive Riesz representer characterization of nested mean regressions. We then apply a recursive Riesz representer estimation learning algorithm that estimates de-biasing corrections without the need to characterize how the correction terms look like, such as for instance, products of inverse probability weighting terms, as is done in prior work on doubly robust estimation in the dynamic regime. Our approach defines a sequence of loss minimization problems, whose minimizers are the mulitpliers of the de-biasing correction, hence circumventing the need for solving auxiliary propensity models and directly optimizing for the mean squared error of the target de-biasing correction.

</p>
</details>

<details><summary><b>Analyzing Generalization of Vision and Language Navigation to Unseen Outdoor Areas</b>
<a href="https://arxiv.org/abs/2203.13838">arxiv:2203.13838</a>
&#x1F4C8; 4 <br>
<p>Raphael Schumann, Stefan Riezler</p></summary>
<p>

**Abstract:** Vision and language navigation (VLN) is a challenging visually-grounded language understanding task. Given a natural language navigation instruction, a visual agent interacts with a graph-based environment equipped with panorama images and tries to follow the described route. Most prior work has been conducted in indoor scenarios where best results were obtained for navigation on routes that are similar to the training routes, with sharp drops in performance when testing on unseen environments. We focus on VLN in outdoor scenarios and find that in contrast to indoor VLN, most of the gain in outdoor VLN on unseen data is due to features like junction type embedding or heading delta that are specific to the respective environment graph, while image information plays a very minor role in generalizing VLN to unseen outdoor areas. These findings show a bias to specifics of graph representations of urban environments, demanding that VLN tasks grow in scale and diversity of geographical environments.

</p>
</details>

<details><summary><b>The TerraByte Client: providing access to terabytes of plant data</b>
<a href="https://arxiv.org/abs/2203.13691">arxiv:2203.13691</a>
&#x1F4C8; 4 <br>
<p>Michael A. Beck, Christopher P. Bidinosti, Christopher J. Henry, Manisha Ajmani</p></summary>
<p>

**Abstract:** In this paper we demonstrate the TerraByte Client, a software to download user-defined plant datasets from a data portal hosted at Compute Canada. To that end the client offers two key functionalities: (1) It allows the user to get an overview on what data is available and a quick way to visually check samples of that data. For this the client receives the results of queries to a database and displays the number of images that fulfill the search criteria. Furthermore, a sample can be downloaded within seconds to confirm that the data suits the user's needs. (2) The user can then download the specified data to their own drive. This data is prepared into chunks server-side and sent to the user's end-system, where it is automatically extracted into individual files. The first chunks of data are available for inspection after a brief waiting period of a minute or less depending on available bandwidth and type of data. The TerraByte Client has a full graphical user interface for easy usage and uses end-to-end encryption. The user interface is built on top of a low-level client. This architecture in combination of offering the client program open-source makes it possible for the user to develop their own user interface or use the client's functionality directly. An example for direct usage could be to download specific data on demand within a larger application, such as training machine learning models.

</p>
</details>

<details><summary><b>Navigable Proximity Graph-Driven Native Hybrid Queries with Structured and Unstructured Constraints</b>
<a href="https://arxiv.org/abs/2203.13601">arxiv:2203.13601</a>
&#x1F4C8; 4 <br>
<p>Mengzhao Wang, Lingwei Lv, Xiaoliang Xu, Yuxiang Wang, Qiang Yue, Jiongkang Ni</p></summary>
<p>

**Abstract:** As research interest surges, vector similarity search is applied in multiple fields, including data mining, computer vision, and information retrieval. {Given a set of objects (e.g., a set of images) and a query object, we can easily transform each object into a feature vector and apply the vector similarity search to retrieve the most similar objects. However, the original vector similarity search cannot well support \textit{hybrid queries}, where users not only input unstructured query constraint (i.e., the feature vector of query object) but also structured query constraint (i.e., the desired attributes of interest). Hybrid query processing aims at identifying these objects with similar feature vectors to query object and satisfying the given attribute constraints. Recent efforts have attempted to answer a hybrid query by performing attribute filtering and vector similarity search separately and then merging the results later, which limits efficiency and accuracy because they are not purpose-built for hybrid queries.} In this paper, we propose a native hybrid query (NHQ) framework based on proximity graph (PG), which provides the specialized \textit{composite index and joint pruning} modules for hybrid queries. We easily deploy existing various PGs on this framework to process hybrid queries efficiently. Moreover, we present two novel navigable PGs (NPGs) with optimized edge selection and routing strategies, which obtain better overall performance than existing PGs. After that, we deploy the proposed NPGs in NHQ to form two hybrid query methods, which significantly outperform the state-of-the-art competitors on all experimental datasets (10$\times$ faster under the same \textit{Recall}), including eight public and one in-house real-world datasets. Our code and datasets have been released at \url{https://github.com/AshenOn3/NHQ}.

</p>
</details>

<details><summary><b>SeCo: Separating Unknown Musical Visual Sounds with Consistency Guidance</b>
<a href="https://arxiv.org/abs/2203.13535">arxiv:2203.13535</a>
&#x1F4C8; 4 <br>
<p>Xinchi Zhou, Dongzhan Zhou, Wanli Ouyang, Hang Zhou, Ziwei Liu, Di Hu</p></summary>
<p>

**Abstract:** Recent years have witnessed the success of deep learning on the visual sound separation task. However, existing works follow similar settings where the training and testing datasets share the same musical instrument categories, which to some extent limits the versatility of this task. In this work, we focus on a more general and challenging scenario, namely the separation of unknown musical instruments, where the categories in training and testing phases have no overlap with each other. To tackle this new setting, we propose the Separation-with-Consistency (SeCo) framework, which can accomplish the separation on unknown categories by exploiting the consistency constraints. Furthermore, to capture richer characteristics of the novel melodies, we devise an online matching strategy, which can bring stable enhancements with no cost of extra parameters. Experiments demonstrate that our SeCo framework exhibits strong adaptation ability on the novel musical categories and outperforms the baseline methods by a significant margin.

</p>
</details>

<details><summary><b>Non-Probability Sampling Network for Stochastic Human Trajectory Prediction</b>
<a href="https://arxiv.org/abs/2203.13471">arxiv:2203.13471</a>
&#x1F4C8; 4 <br>
<p>Inhwan Bae, Jin-Hwi Park, Hae-Gon Jeon</p></summary>
<p>

**Abstract:** Capturing multimodal natures is essential for stochastic pedestrian trajectory prediction, to infer a finite set of future trajectories. The inferred trajectories are based on observation paths and the latent vectors of potential decisions of pedestrians in the inference step. However, stochastic approaches provide varying results for the same data and parameter settings, due to the random sampling of the latent vector. In this paper, we analyze the problem by reconstructing and comparing probabilistic distributions from prediction samples and socially-acceptable paths, respectively. Through this analysis, we observe that the inferences of all stochastic models are biased toward the random sampling, and fail to generate a set of realistic paths from finite samples. The problem cannot be resolved unless an infinite number of samples is available, which is infeasible in practice. We introduce that the Quasi-Monte Carlo (QMC) method, ensuring uniform coverage on the sampling space, as an alternative to the conventional random sampling. With the same finite number of samples, the QMC improves all the multimodal prediction results. We take an additional step ahead by incorporating a learnable sampling network into the existing networks for trajectory prediction. For this purpose, we propose the Non-Probability Sampling Network (NPSN), a very small network (~5K parameters) that generates purposive sample sequences using the past paths of pedestrians and their social interactions. Extensive experiments confirm that NPSN can significantly improve both the prediction accuracy (up to 60%) and reliability of the public pedestrian trajectory prediction benchmark. Code is publicly available at https://github.com/inhwanbae/NPSN .

</p>
</details>

<details><summary><b>From MIM-Based GAN to Anomaly Detection:Event Probability Influence on Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2203.13464">arxiv:2203.13464</a>
&#x1F4C8; 4 <br>
<p>Rui She, Pingyi Fan</p></summary>
<p>

**Abstract:** In order to introduce deep learning technologies into anomaly detection, Generative Adversarial Networks (GANs) are considered as important roles in the algorithm design and realistic applications. In terms of GANs, event probability reflected in the objective function, has an impact on the event generation which plays a crucial part in GAN-based anomaly detection. The information metric, e.g. Kullback-Leibler divergence in the original GAN, makes the objective function have different sensitivity on different event probability, which provides an opportunity to refine GAN-based anomaly detection by influencing data generation. In this paper, we introduce the exponential information metric into the GAN, referred to as MIM-based GAN, whose superior characteristics on data generation are discussed in theory. Furthermore, we propose an anomaly detection method with MIM-based GAN, as well as explain its principle for the unsupervised learning case from the viewpoint of probability event generation. Since this method is promising to detect anomalies in Internet of Things (IoT), such as environmental, medical and biochemical outliers, we make use of several datasets from the online ODDS repository to evaluate its performance and compare it with other methods.

</p>
</details>

<details><summary><b>Implementation of an Automated Learning System for Non-experts</b>
<a href="https://arxiv.org/abs/2203.15784">arxiv:2203.15784</a>
&#x1F4C8; 3 <br>
<p>Phoenix X. Huang, Zhiwei Zhao, Chao Liu, Jingyi Liu, Wenze Hu, Xiaoyu Wang</p></summary>
<p>

**Abstract:** Automated machine learning systems for non-experts could be critical for industries to adopt artificial intelligence to their own applications. This paper detailed the engineering system implementation of an automated machine learning system called YMIR, which completely relies on graphical interface to interact with users. After importing training/validation data into the system, a user without AI knowledge can label the data, train models, perform data mining and evaluation by simply clicking buttons. The paper described: 1) Open implementation of model training and inference through docker containers. 2) Implementation of task and resource management. 3) Integration of Labeling software. 4) Implementation of HCI (Human Computer Interaction) with a rebuilt collaborative development paradigm. We also provide subsequent case study on training models with the system. We hope this paper can facilitate the prosperity of our automated machine learning community from industry application perspective. The code of the system has already been released to GitHub (https://github.com/industryessentials/ymir).

</p>
</details>

<details><summary><b>A Cross-Domain Approach for Continuous Impression Recognition from Dyadic Audio-Visual-Physio Signals</b>
<a href="https://arxiv.org/abs/2203.13932">arxiv:2203.13932</a>
&#x1F4C8; 3 <br>
<p>Yuanchao Li, Catherine Lai</p></summary>
<p>

**Abstract:** The impression we make on others depends not only on what we say, but also, to a large extent, on how we say it. As a sub-branch of affective computing and social signal processing, impression recognition has proven critical in both human-human conversations and spoken dialogue systems. However, most research has studied impressions only from the signals expressed by the emitter, ignoring the response from the receiver. In this paper, we perform impression recognition using a proposed cross-domain architecture on the dyadic IMPRESSION dataset. This improved architecture makes use of cross-domain attention and regularization. The cross-domain attention consists of intra- and inter-attention mechanisms, which capture intra- and inter-domain relatedness, respectively. The cross-domain regularization includes knowledge distillation and similarity enhancement losses, which strengthen the feature connections between the emitter and receiver. The experimental evaluation verified the effectiveness of our approach. Our approach achieved a concordance correlation coefficient of 0.770 in competence dimension and 0.748 in warmth dimension.

</p>
</details>

<details><summary><b>Self-supervised Semantic Segmentation Grounded in Visual Concepts</b>
<a href="https://arxiv.org/abs/2203.13868">arxiv:2203.13868</a>
&#x1F4C8; 3 <br>
<p>Wenbin He, William Surmeier, Arvind Kumar Shekar, Liang Gou, Liu Ren</p></summary>
<p>

**Abstract:** Unsupervised semantic segmentation requires assigning a label to every pixel without any human annotations. Despite recent advances in self-supervised representation learning for individual images, unsupervised semantic segmentation with pixel-level representations is still a challenging task and remains underexplored. In this work, we propose a self-supervised pixel representation learning method for semantic segmentation by using visual concepts (i.e., groups of pixels with semantic meanings, such as parts, objects, and scenes) extracted from images. To guide self-supervised learning, we leverage three types of relationships between pixels and concepts, including the relationships between pixels and local concepts, local and global concepts, as well as the co-occurrence of concepts. We evaluate the learned pixel embeddings and visual concepts on three datasets, including PASCAL VOC 2012, COCO 2017, and DAVIS 2017. Our results show that the proposed method gains consistent and substantial improvements over recent unsupervised semantic segmentation approaches, and also demonstrate that visual concepts can reveal insights into image datasets.

</p>
</details>

<details><summary><b>Intelligent Masking: Deep Q-Learning for Context Encoding in Medical Image Analysis</b>
<a href="https://arxiv.org/abs/2203.13865">arxiv:2203.13865</a>
&#x1F4C8; 3 <br>
<p>Mojtaba Bahrami, Mahsa Ghorbani, Nassir Navab</p></summary>
<p>

**Abstract:** The need for a large amount of labeled data in the supervised setting has led recent studies to utilize self-supervised learning to pre-train deep neural networks using unlabeled data. Many self-supervised training strategies have been investigated especially for medical datasets to leverage the information available in the much fewer unlabeled data. One of the fundamental strategies in image-based self-supervision is context prediction. In this approach, a model is trained to reconstruct the contents of an arbitrary missing region of an image based on its surroundings. However, the existing methods adopt a random and blind masking approach by focusing uniformly on all regions of the images. This approach results in a lot of unnecessary network updates that cause the model to forget the rich extracted features. In this work, we develop a novel self-supervised approach that occludes targeted regions to improve the pre-training procedure. To this end, we propose a reinforcement learning-based agent which learns to intelligently mask input images through deep Q-learning. We show that training the agent against the prediction model can significantly improve the semantic features extracted for downstream classification tasks. We perform our experiments on two public datasets for diagnosing breast cancer in the ultrasound images and detecting lower-grade glioma with MR images. In our experiments, we show that our novel masking strategy advances the learned features according to the performance on the classification task in terms of accuracy, macro F1, and AUROC.

</p>
</details>

<details><summary><b>Optimal quantum kernels for small data classification</b>
<a href="https://arxiv.org/abs/2203.13848">arxiv:2203.13848</a>
&#x1F4C8; 3 <br>
<p>Elham Torabian, Roman V. Krems</p></summary>
<p>

**Abstract:** While quantum machine learning (ML) has been proposed to be one of the most promising applications of quantum computing, how to build quantum ML models that outperform classical ML remains a major open question. Here, we demonstrate an algorithm for constructing quantum kernels for support vector machines that adapts quantum gate sequences to data. The algorithm includes three essential ingredients: greedy search in the space of quantum circuits, Bayesian information criterion as circuit selection metric and Bayesian optimization of the parameters of the optimal quantum circuit identified. The performance of the resulting quantum models for classification problems with a small number of training points significantly exceeds that of optimized classical models with conventional kernels. In addition, we illustrate the possibility of mapping quantum circuits onto molecular fingerprints and show that performant quantum kernels can be isolated in the resulting chemical space. This suggests that methods developed for optimization and interpolation of molecular properties across chemical spaces can be used for building quantum circuits for quantum machine learning with enhanced performance.

</p>
</details>

<details><summary><b>A Stitch in Time Saves Nine: A Train-Time Regularizing Loss for Improved Neural Network Calibration</b>
<a href="https://arxiv.org/abs/2203.13834">arxiv:2203.13834</a>
&#x1F4C8; 3 <br>
<p>Ramya Hebbalaguppe, Jatin Prakash, Neelabh Madan, Chetan Arora</p></summary>
<p>

**Abstract:** Deep Neural Networks ( DNN s) are known to make overconfident mistakes, which makes their use problematic in safety-critical applications. State-of-the-art ( SOTA ) calibration techniques improve on the confidence of predicted labels alone and leave the confidence of non-max classes (e.g. top-2, top-5) uncalibrated. Such calibration is not suitable for label refinement using post-processing. Further, most SOTA techniques learn a few hyper-parameters post-hoc, leaving out the scope for image, or pixel specific calibration. This makes them unsuitable for calibration under domain shift, or for dense prediction tasks like semantic segmentation. In this paper, we argue for intervening at the train time itself, so as to directly produce calibrated DNN models. We propose a novel auxiliary loss function: Multi-class Difference in Confidence and Accuracy ( MDCA ), to achieve the same MDCA can be used in conjunction with other application/task-specific loss functions. We show that training with MDCA leads to better-calibrated models in terms of Expected Calibration Error ( ECE ), and Static Calibration Error ( SCE ) on image classification, and segmentation tasks. We report ECE ( SCE ) score of 0.72 (1.60) on the CIFAR 100 dataset, in comparison to 1.90 (1.71) by the SOTA. Under domain shift, a ResNet-18 model trained on PACS dataset using MDCA gives an average ECE ( SCE ) score of 19.7 (9.7) across all domains, compared to 24.2 (11.8) by the SOTA. For the segmentation task, we report a 2X reduction in calibration error on PASCAL - VOC dataset in comparison to Focal Loss. Finally, MDCA training improves calibration even on imbalanced data, and for natural language classification tasks. We have released the code here: code is available at https://github.com/mdca-loss

</p>
</details>

<details><summary><b>A Hybrid Framework for Sequential Data Prediction with End-to-End Optimization</b>
<a href="https://arxiv.org/abs/2203.13787">arxiv:2203.13787</a>
&#x1F4C8; 3 <br>
<p>Mustafa E. AydÄ±n, Suleyman S. Kozat</p></summary>
<p>

**Abstract:** We investigate nonlinear prediction in an online setting and introduce a hybrid model that effectively mitigates, via an end-to-end architecture, the need for hand-designed features and manual model selection issues of conventional nonlinear prediction/regression methods. In particular, we use recursive structures to extract features from sequential signals, while preserving the state information, i.e., the history, and boosted decision trees to produce the final output. The connection is in an end-to-end fashion and we jointly optimize the whole architecture using stochastic gradient descent, for which we also provide the backward pass update equations. In particular, we employ a recurrent neural network (LSTM) for adaptive feature extraction from sequential data and a gradient boosting machinery (soft GBDT) for effective supervised regression. Our framework is generic so that one can use other deep learning architectures for feature extraction (such as RNNs and GRUs) and machine learning algorithms for decision making as long as they are differentiable. We demonstrate the learning behavior of our algorithm on synthetic data and the significant performance improvements over the conventional methods over various real life datasets. Furthermore, we openly share the source code of the proposed method to facilitate further research.

</p>
</details>

<details><summary><b>High Dimensional Quantum Learning With Small Quantum Computers</b>
<a href="https://arxiv.org/abs/2203.13739">arxiv:2203.13739</a>
&#x1F4C8; 3 <br>
<p>Simon C. Marshall, Casper Gyurik, Vedran Dunjko</p></summary>
<p>

**Abstract:** Quantum computers hold great promise to enhance machine learning, but their current qubit counts restrict the realisation of this promise. In an attempt to placate this limitation techniques can be applied for evaluating a quantum circuit using a machine with fewer qubits than the circuit naively requires. These techniques work by evaluating many smaller circuits on the smaller machine, that are then combined in a polynomial to replicate the output of the larger machine. This scheme requires more circuit evaluations than are practical for general circuits. However, we investigate the possibility that for certain applications many of these subcircuits are superfluous, and that a much smaller sum is sufficient to estimate the full circuit. We construct a machine learning model that may be capable of approximating the outputs of the larger circuit with much fewer circuit evaluations. We successfully apply our model to the task of digit recognition, using simulated quantum computers much smaller than the data dimension. The model is also applied to the task of approximating a random 10 qubit PQC with simulated access to a 5 qubit computer, even with only relatively modest number of circuits our model provides an accurate approximation of the 10 qubit PQCs output, superior to a neural network attempt. The developed method might be useful for implementing quantum models on larger data throughout the NISQ era.

</p>
</details>

<details><summary><b>LAMBDA: Covering the Solution Set of Black-Box Inequality by Search Space Quantization</b>
<a href="https://arxiv.org/abs/2203.13708">arxiv:2203.13708</a>
&#x1F4C8; 3 <br>
<p>Lihao Liu, Tianyue Feng, Xingyu Xing, Junyi Chen</p></summary>
<p>

**Abstract:** Black-box functions are broadly used to model complex problems that provide no explicit information but the input and output. Despite existing studies of black-box function optimization, the solution set satisfying an inequality with a black-box function plays a more significant role than only one optimum in many practical situations. Covering as much as possible of the solution set through limited evaluations to the black-box objective function is defined as the Black-Box Coverage (BBC) problem in this paper. We formalized this problem in a sample-based search paradigm and constructed a coverage criterion with Confusion Matrix Analysis. Further, we propose LAMBDA (Latent-Action Monte-Carlo Beam Search with Density Adaption) to solve BBC problems. LAMBDA can focus around the solution set quickly by recursively partitioning the search space into accepted and rejected sub-spaces. Compared with La-MCTS, LAMBDA introduces density information to overcome the sampling bias of optimization and obtain more exploration. Benchmarking shows, LAMBDA achieved state-of-the-art performance among all baselines and was at most 33x faster to get 95% coverage than Random Search. Experiments also demonstrate that LAMBDA has a promising future in the verification of autonomous systems in virtual tests.

</p>
</details>

<details><summary><b>Learning to Mediate Disparities Towards Pragmatic Communication</b>
<a href="https://arxiv.org/abs/2203.13685">arxiv:2203.13685</a>
&#x1F4C8; 3 <br>
<p>Yuwei Bao, Sayan Ghosh, Joyce Chai</p></summary>
<p>

**Abstract:** Human communication is a collaborative process. Speakers, on top of conveying their own intent, adjust the content and language expressions by taking the listeners into account, including their knowledge background, personalities, and physical capabilities. Towards building AI agents with similar abilities in language communication, we propose Pragmatic Rational Speaker (PRS), a framework extending Rational Speech Act (RSA). The PRS attempts to learn the speaker-listener disparity and adjust the speech accordingly, by adding a light-weighted disparity adjustment layer into working memory on top of speaker's long-term memory system. By fixing the long-term memory, the PRS only needs to update its working memory to learn and adapt to different types of listeners. To validate our framework, we create a dataset that simulates different types of speaker-listener disparities in the context of referential games. Our empirical results demonstrate that the PRS is able to shift its output towards the language that listener are able to understand, significantly improve the collaborative task outcome.

</p>
</details>

<details><summary><b>ST-FL: Style Transfer Preprocessing in Federated Learning for COVID-19 Segmentation</b>
<a href="https://arxiv.org/abs/2203.13680">arxiv:2203.13680</a>
&#x1F4C8; 3 <br>
<p>Antonios Georgiadis, Varun Babbar, Fran Silavong, Sean Moran, Rob Otter</p></summary>
<p>

**Abstract:** Chest Computational Tomography (CT) scans present low cost, speed and objectivity for COVID-19 diagnosis and deep learning methods have shown great promise in assisting the analysis and interpretation of these images. Most hospitals or countries can train their own models using in-house data, however empirical evidence shows that those models perform poorly when tested on new unseen cases, surfacing the need for coordinated global collaboration. Due to privacy regulations, medical data sharing between hospitals and nations is extremely difficult. We propose a GAN-augmented federated learning model, dubbed ST-FL (Style Transfer Federated Learning), for COVID-19 image segmentation. Federated learning (FL) permits a centralised model to be learned in a secure manner from heterogeneous datasets located in disparate private data silos. We demonstrate that the widely varying data quality on FL client nodes leads to a sub-optimal centralised FL model for COVID-19 chest CT image segmentation. ST-FL is a novel FL framework that is robust in the face of highly variable data quality at client nodes. The robustness is achieved by a denoising CycleGAN model at each client of the federation that maps arbitrary quality images into the same target quality, counteracting the severe data variability evident in real-world FL use-cases. Each client is provided with the target style, which is the same for all clients, and trains their own denoiser. Our qualitative and quantitative results suggest that this FL model performs comparably to, and in some cases better than, a model that has centralised access to all the training data.

</p>
</details>

<details><summary><b>EmotionNAS: Two-stream Architecture Search for Speech Emotion Recognition</b>
<a href="https://arxiv.org/abs/2203.13617">arxiv:2203.13617</a>
&#x1F4C8; 3 <br>
<p>Haiyang Sun, Zheng Lian, Bin Liu, Ying Li, Licai Sun, Cong Cai, Jianhua Tao, Meng Wang, Yuan Cheng</p></summary>
<p>

**Abstract:** Speech emotion recognition (SER) is a crucial research topic in human-computer interactions. Existing works are mainly based on manually designed models. Despite their great success, these methods heavily rely on historical experience, which are time-consuming but cannot exhaust all possible structures. To address this problem, we propose a neural architecture search (NAS) based framework for SER, called "EmotionNAS". We take spectrogram and wav2vec features as the inputs, followed with NAS to optimize the network structure for these features separately. We further incorporate complementary information in these features through decision-level fusion. Experimental results on IEMOCAP demonstrate that our method succeeds over existing state-of-the-art strategies on SER.

</p>
</details>

<details><summary><b>Deformable Butterfly: A Highly Structured and Sparse Linear Transform</b>
<a href="https://arxiv.org/abs/2203.13556">arxiv:2203.13556</a>
&#x1F4C8; 3 <br>
<p>Rui Lin, Jie Ran, King Hung Chiu, Graziano Chesi, Ngai Wong</p></summary>
<p>

**Abstract:** We introduce a new kind of linear transform named Deformable Butterfly (DeBut) that generalizes the conventional butterfly matrices and can be adapted to various input-output dimensions. It inherits the fine-to-coarse-grained learnable hierarchy of traditional butterflies and when deployed to neural networks, the prominent structures and sparsity in a DeBut layer constitutes a new way for network compression. We apply DeBut as a drop-in replacement of standard fully connected and convolutional layers, and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity-accuracy tradeoff arising from the myriad deformations of a DeBut layer also opens up new rooms for analytical and practical research. The codes and Appendix are publicly available at: https://github.com/ruilin0212/DeBut.

</p>
</details>

<details><summary><b>Analysis of the Production Strategy of Mask Types in the COVID-19 Environment</b>
<a href="https://arxiv.org/abs/2203.13506">arxiv:2203.13506</a>
&#x1F4C8; 3 <br>
<p>Xiangri Lu, Zhanqing Wang, Hongbin Ma</p></summary>
<p>

**Abstract:** Since the outbreak of the COVID-19 in December 2019, medical protective equipment such as disposable medical masks and KN95 masks have become essential resources for the public. Enterprises in all sectors of society have also transformed the production of medical masks. After the outbreak, how to choose the right time to produce medical protective masks, and what type of medical masks to produce will play a positive role in preventing and controlling the epidemic in a short time. In this regard, the evolutionary game competition analysis will be conducted through the relevant data of disposable medical masks and KN95 masks to determine the appropriate nodes for the production of corresponding mask types. After the research and analysis of the production strategy of mask types, it has a positive effect on how to guide the resumption of work and production.

</p>
</details>

<details><summary><b>Current Source Localization Using Deep Prior with Depth Weighting</b>
<a href="https://arxiv.org/abs/2203.13981">arxiv:2203.13981</a>
&#x1F4C8; 2 <br>
<p>Rio Yamana, Hajime Yano, Ryoichi Takashima, Tetsuya Takiguchi, Seiji Nakagawa</p></summary>
<p>

**Abstract:** This paper proposes a novel neuronal current source localization method based on Deep Prior that represents a more complicated prior distribution of current source using convolutional networks. Deep Prior has been suggested as a means of an unsupervised learning approach that does not require learning using training data, and randomly-initialized neural networks are used to update a source location using a single observation. In our previous work, a Deep-Prior-based current source localization method in the brain has been proposed but the performance was not almost the same as those of conventional approaches, such as sLORETA. In order to improve the Deep-Prior-based approach, in this paper, a depth weight of the current source is introduced for Deep Prior, where depth weighting amounts to assigning more penalty to the superficial currents. Its effectiveness is confirmed by experiments of current source estimation on simulated MEG data.

</p>
</details>

<details><summary><b>Tuning Particle Accelerators with Safety Constraints using Bayesian Optimization</b>
<a href="https://arxiv.org/abs/2203.13968">arxiv:2203.13968</a>
&#x1F4C8; 2 <br>
<p>Johannes Kirschner, Mojmir MutnÃ½, Andreas Krause, Jaime Coello de Portugal, Nicole Hiller, Jochem Snuverink</p></summary>
<p>

**Abstract:** Tuning machine parameters of particle accelerators is a repetitive and time-consuming task, that is challenging to automate. While many off-the-shelf optimization algorithms are available, in practice their use is limited because most methods do not account for safety-critical constraints that apply to each iteration, including loss signals or step-size limitations. One notable exception is safe Bayesian optimization, which is a data-driven tuning approach for global optimization with noisy feedback. We propose and evaluate a step size-limited variant of safe Bayesian optimization on two research faculties of the Paul Scherrer Institut (PSI): a) the Swiss Free Electron Laser (SwissFEL) and b) the High-Intensity Proton Accelerator (HIPA). We report promising experimental results on both machines, tuning up to 16 parameters subject to more than 200 constraints.

</p>
</details>

<details><summary><b>Mode decomposition-based time-varying phase synchronization for fMRI Data</b>
<a href="https://arxiv.org/abs/2203.13955">arxiv:2203.13955</a>
&#x1F4C8; 2 <br>
<p>Hamed Honari, Martin A. Lindquist</p></summary>
<p>

**Abstract:** Recently there has been significant interest in measuring time-varying functional connectivity (TVC) between different brain regions using resting-state functional magnetic resonance imaging (rs-fMRI) data. One way to assess the relationship between signals from different brain regions is to measure their phase synchronization (PS) across time. However, this requires the \textit{a priori} choice of type and cut-off frequencies for the bandpass filter needed to perform the analysis. Here we explore alternative approaches based on the use of various mode decomposition (MD) techniques that circumvent this issue. These techniques allow for the data driven decomposition of signals jointly into narrow-band components at different frequencies, thus fulfilling the requirements needed to measure PS. We explore several variants of MD, including empirical mode decomposition (EMD), bivariate EMD (BEMD), noise-assisted multivariate EMD (na-MEMD), and introduce the use of multivariate variational mode decomposition (MVMD) in the context of estimating time-varying PS. We contrast the approaches using a series of simulations and application to rs-fMRI data. Our results show that MVMD outperforms other evaluated MD approaches, and further suggests that this approach can be used as a tool to reliably investigate time-varying PS in rs-fMRI data.

</p>
</details>

<details><summary><b>CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues</b>
<a href="https://arxiv.org/abs/2203.13926">arxiv:2203.13926</a>
&#x1F4C8; 2 <br>
<p>Deepanway Ghosal, Siqi Shen, Navonil Majumder, Rada Mihalcea, Soujanya Poria</p></summary>
<p>

**Abstract:** This paper addresses the problem of dialogue reasoning with contextualized commonsense inference. We curate CICERO, a dataset of dyadic conversations with five types of utterance-level reasoning-based inferences: cause, subsequent event, prerequisite, motivation, and emotional reaction. The dataset contains 53,105 of such inferences from 5,672 dialogues. We use this dataset to solve relevant generative and discriminative tasks: generation of cause and subsequent event; generation of prerequisite, motivation, and listener's emotional reaction; and selection of plausible alternatives. Our results ascertain the value of such dialogue-centric commonsense knowledge datasets. It is our hope that CICERO will open new research avenues into commonsense-based dialogue reasoning.

</p>
</details>

<details><summary><b>Spatial Processing Front-End For Distant ASR Exploiting Self-Attention Channel Combinator</b>
<a href="https://arxiv.org/abs/2203.13919">arxiv:2203.13919</a>
&#x1F4C8; 2 <br>
<p>Dushyant Sharma, Rong Gong, James Fosburgh, Stanislav Yu. Kruchinin, Patrick A. Naylor, Ljubomir Milanovic</p></summary>
<p>

**Abstract:** We present a novel multi-channel front-end based on channel shortening with theWeighted Prediction Error (WPE) method followed by a fixed MVDR beamformer used in combination with a recently proposed self-attention-based channel combination (SACC) scheme, for tackling the distant ASR problem. We show that the proposed system used as part of a ContextNet based end-to-end (E2E) ASR system outperforms leading ASR systems as demonstrated by a 21.6% reduction in relative WER on a multi-channel LibriSpeech playback dataset. We also show how dereverberation prior to beamforming is beneficial and compare the WPE method with a modified neural channel shortening approach. An analysis of the non-intrusive estimate of the signal C50 confirms that the 8 channel WPE method provides significant dereverberation of the signals (13.6 dB improvement). We also show how the weights of the SACC system allow the extraction of accurate spatial information which can be beneficial for other speech processing applications like diarization.

</p>
</details>

<details><summary><b>Theoretical Connection between Locally Linear Embedding, Factor Analysis, and Probabilistic PCA</b>
<a href="https://arxiv.org/abs/2203.13911">arxiv:2203.13911</a>
&#x1F4C8; 2 <br>
<p>Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley</p></summary>
<p>

**Abstract:** Locally Linear Embedding (LLE) is a nonlinear spectral dimensionality reduction and manifold learning method. It has two main steps which are linear reconstruction and linear embedding of points in the input space and embedding space, respectively. In this work, we look at the linear reconstruction step from a stochastic perspective where it is assumed that every data point is conditioned on its linear reconstruction weights as latent factors. The stochastic linear reconstruction of LLE is solved using expectation maximization. We show that there is a theoretical connection between three fundamental dimensionality reduction methods, i.e., LLE, factor analysis, and probabilistic Principal Component Analysis (PCA). The stochastic linear reconstruction of LLE is formulated similar to the factor analysis and probabilistic PCA. It is also explained why factor analysis and probabilistic PCA are linear and LLE is a nonlinear method. This work combines and makes a bridge between two broad approaches of dimensionality reduction, i.e., the spectral and probabilistic algorithms.

</p>
</details>

<details><summary><b>Improving robustness of jet tagging algorithms with adversarial training</b>
<a href="https://arxiv.org/abs/2203.13890">arxiv:2203.13890</a>
&#x1F4C8; 2 <br>
<p>Annika Stein, Xavier Coubez, Spandan Mondal, Andrzej Novak, Alexander Schmidt</p></summary>
<p>

**Abstract:** Deep learning is a standard tool in the field of high-energy physics, facilitating considerable sensitivity enhancements for numerous analysis strategies. In particular, in identification of physics objects, such as jet flavor tagging, complex neural network architectures play a major role. However, these methods are reliant on accurate simulations. Mismodeling can lead to non-negligible differences in performance in data that need to be measured and calibrated against. We investigate the classifier response to input data with injected mismodelings and probe the vulnerability of flavor tagging algorithms via application of adversarial attacks. Subsequently, we present an adversarial training strategy that mitigates the impact of such simulated attacks and improves the classifier robustness. We examine the relationship between performance and vulnerability and show that this method constitutes a promising approach to reduce the vulnerability to poor modeling.

</p>
</details>

<details><summary><b>Visual-based Safe Landing for UAVs in Populated Areas: Real-time Validation in Virtual Environments</b>
<a href="https://arxiv.org/abs/2203.13792">arxiv:2203.13792</a>
&#x1F4C8; 2 <br>
<p>Hector Tovanche-Picon, Javier Gonzalez-Trejo, Angel Flores-Abad, Diego Mercado-Ravell</p></summary>
<p>

**Abstract:** Safe autonomous landing for Unmanned Aerial Vehicles (UAVs) in populated areas is a crucial aspect for successful urban deployment, particularly in emergency landing situations. Nonetheless, validating autonomous landing in real scenarios is a challenging task involving a high risk of injuring people. In this work, we propose a framework for real-time safe and thorough evaluation of vision-based autonomous landing in populated scenarios, using photo-realistic virtual environments. We propose to use the Unreal graphics engine coupled with the AirSim plugin for drone's simulation, and evaluate autonomous landing strategies based on visual detection of Safe Landing Zones (SLZ) in populated scenarios. Then, we study two different criteria for selecting the "best" SLZ, and evaluate them during autonomous landing of a virtual drone in different scenarios and conditions, under different distributions of people in urban scenes, including moving people. We evaluate different metrics to quantify the performance of the landing strategies, establishing a baseline for comparison with future works in this challenging task, and analyze them through an important number of randomized iterations. The study suggests that the use of the autonomous landing algorithms considerably helps to prevent accidents involving humans, which may allow to unleash the full potential of drones in urban environments near to people.

</p>
</details>

<details><summary><b>Ensemble Spectral Prediction (ESP) Model for Metabolite Annotation</b>
<a href="https://arxiv.org/abs/2203.13783">arxiv:2203.13783</a>
&#x1F4C8; 2 <br>
<p>Xinmeng Li, Hao Zhu, Li-ping Liu, Soha Hassoun</p></summary>
<p>

**Abstract:** A key challenge in metabolomics is annotating measured spectra from a biological sample with chemical identities. Currently, only a small fraction of measurements can be assigned identities. Two complementary computational approaches have emerged to address the annotation problem: mapping candidate molecules to spectra, and mapping query spectra to molecular candidates. In essence, the candidate molecule with the spectrum that best explains the query spectrum is recommended as the target molecule. Despite candidate ranking being fundamental in both approaches, no prior works utilized rank learning tasks in determining the target molecule. We propose a novel machine learning model, Ensemble Spectral Prediction (ESP), for metabolite annotation. ESP takes advantage of prior neural network-based annotation models that utilize multilayer perceptron (MLP) networks and Graph Neural Networks (GNNs). Based on the ranking results of the MLP and GNN-based models, ESP learns a weighting for the outputs of MLP and GNN spectral predictors to generate a spectral prediction for a query molecule. Importantly, training data is stratified by molecular formula to provide candidate sets during model training. Further, baseline MLP and GNN models are enhanced by considering peak dependencies through multi-head attention mechanism and multi-tasking on spectral topic distributions. ESP improves average rank by 41% and 30% over the MLP and GNN baselines, respectively, demonstrating remarkable performance gain over state-of-the-art neural network approaches. We show that annotation performance, for ESP and other models, is a strong function of the number of molecules in the candidate set and their similarity to the target molecule.

</p>
</details>

<details><summary><b>Origins of Low-dimensional Adversarial Perturbations</b>
<a href="https://arxiv.org/abs/2203.13779">arxiv:2203.13779</a>
&#x1F4C8; 2 <br>
<p>Elvis Dohmatob, Chuan Guo, Morgane Goibert</p></summary>
<p>

**Abstract:** In this note, we initiate a rigorous study of the phenomenon of low-dimensional adversarial perturbations in classification. These are adversarial perturbations wherein, unlike the classical setting, the attacker's search is limited to a low-dimensional subspace of the feature space. The goal is to fool the classifier into flipping its decision on a nonzero fraction of inputs from a designated class, upon the addition of perturbations from a subspace chosen by the attacker and fixed once and for all. It is desirable that the dimension $k$ of the subspace be much smaller than the dimension $d$ of the feature space, while the norm of the perturbations should be negligible compared to the norm of a typical data point. In this work, we consider binary classification models under very general regularity conditions, which are verified by certain feedforward neural networks (e.g., with sufficiently smooth, or else ReLU activation function), and compute analytical lower-bounds for the fooling rate of any subspace. These bounds explicitly highlight the dependence that the fooling rate has on the margin of the model (i.e., the ratio of the output to its $L_2$-norm of its gradient at a test point), and on the alignment of the given subspace with the gradients of the model w.r.t. inputs. Our results provide a theoretical explanation for the recent success of heuristic methods for efficiently generating low-dimensional adversarial perturbations. Moreover, our theoretical results are confirmed by experiments.

</p>
</details>

<details><summary><b>L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and BERT models</b>
<a href="https://arxiv.org/abs/2203.13778">arxiv:2203.13778</a>
&#x1F4C8; 2 <br>
<p>Abhishek Velankar, Hrushikesh Patil, Amol Gore, Shubham Salunke, Raviraj Joshi</p></summary>
<p>

**Abstract:** Social media platforms are used by a large number of people prominently to express their thoughts and opinions. However, these platforms have contributed to a substantial amount of hateful and abusive content as well. Therefore, it is important to curb the spread of hate speech on these platforms. In India, Marathi is one of the most popular languages used by a wide audience. In this work, we present L3Cube-MahaHate, the first major Hate Speech Dataset in Marathi. The dataset is curated from Twitter, annotated manually. Our dataset consists of over 25000 distinct tweets labeled into four major classes i.e hate, offensive, profane, and not. We present the approaches used for collecting and annotating the data and the challenges faced during the process. Finally, we present baseline classification results using deep learning models based on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual variants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that mono-lingual models perform better than their multi-lingual counterparts. The MahaBERT model provides the best results on L3Cube-MahaHate Corpus. The data and models are available at https://github.com/l3cube-pune/MarathiNLP .

</p>
</details>

<details><summary><b>Common Failure Modes of Subcluster-based Sampling in Dirichlet Process Gaussian Mixture Models -- and a Deep-learning Solution</b>
<a href="https://arxiv.org/abs/2203.13661">arxiv:2203.13661</a>
&#x1F4C8; 2 <br>
<p>Vlad Winter, Or Dinari, Oren Freifeld</p></summary>
<p>

**Abstract:** The Dirichlet Process Gaussian Mixture Model (DPGMM) is often used to cluster data when the number of clusters is unknown. One main DPGMM inference paradigm relies on sampling. Here we consider a known state-of-art sampler (proposed by Chang and Fisher III (2013) and improved by Dinari et al. (2019)), analyze its failure modes, and show how to improve it, often drastically. Concretely, in that sampler, whenever a new cluster is formed it is augmented with two subclusters whose labels are initialized at random. Upon their evolution, the subclusters serve to propose a split of the parent cluster. We show that the random initialization is often problematic and hurts the otherwise-effective sampler. Specifically, we demonstrate that this initialization tends to lead to poor split proposals and/or too many iterations before a desired split is accepted. This slows convergence and can damage the clustering. As a remedy, we propose two drop-in-replacement options for the subcluster-initialization subroutine. The first is an intuitive heuristic while the second is based on deep learning. We show that the proposed approach yields better splits, which in turn translate to substantial improvements in performance, results, and stability.

</p>
</details>

<details><summary><b>StretchBEV: Stretching Future Instance Prediction Spatially and Temporally</b>
<a href="https://arxiv.org/abs/2203.13641">arxiv:2203.13641</a>
&#x1F4C8; 2 <br>
<p>Adil Kaan Akan, Fatma GÃ¼ney</p></summary>
<p>

**Abstract:** In self-driving, predicting future in terms of location and motion of all the agents around the vehicle is a crucial requirement for planning. Recently, a new joint formulation of perception and prediction has emerged by fusing rich sensory information perceived from multiple cameras into a compact bird's-eye view representation to perform prediction. However, the quality of future predictions degrades over time while extending to longer time horizons due to multiple plausible predictions. In this work, we address this inherent uncertainty in future predictions with a stochastic temporal model. Our model learns temporal dynamics in a latent space through stochastic residual updates at each time step. By sampling from a learned distribution at each time step, we obtain more diverse future predictions that are also more accurate compared to previous work, especially stretching both spatially further regions in the scene and temporally over longer time horizons. Despite separate processing of each time step, our model is still efficient through decoupling of the learning of dynamics and the generation of future predictions.

</p>
</details>

<details><summary><b>Lightweight Graph Convolutional Networks with Topologically Consistent Magnitude Pruning</b>
<a href="https://arxiv.org/abs/2203.13616">arxiv:2203.13616</a>
&#x1F4C8; 2 <br>
<p>Hichem Sahbi</p></summary>
<p>

**Abstract:** Graph convolution networks (GCNs) are currently mainstream in learning with irregular data. These models rely on message passing and attention mechanisms that capture context and node-to-node relationships. With multi-head attention, GCNs become highly accurate but oversized, and their deployment on cheap devices requires their pruning. However, pruning at high regimes usually leads to topologically inconsistent networks with weak generalization. In this paper, we devise a novel method for lightweight GCN design. Our proposed approach parses and selects subnetworks with the highest magnitudes while guaranteeing their topological consistency. The latter is obtained by selecting only accessible and co-accessible connections which actually contribute in the evaluation of the selected subnetworks. Experiments conducted on the challenging FPHA dataset show the substantial gain of our topologically consistent pruning method especially at very high pruning regimes.

</p>
</details>

<details><summary><b>Fast Hybrid Image Retargeting</b>
<a href="https://arxiv.org/abs/2203.13595">arxiv:2203.13595</a>
&#x1F4C8; 2 <br>
<p>Daniel Valdez-Balderas, Oleg Muraveynyk, Timothy Smith</p></summary>
<p>

**Abstract:** Image retargeting changes the aspect ratio of images while aiming to preserve content and minimise noticeable distortion. Fast and high-quality methods are particularly relevant at present, due to the large variety of image and display aspect ratios. We propose a retargeting method that quantifies and limits warping distortions with the use of content-aware cropping. The pipeline of the proposed approach consists of the following steps. First, an importance map of a source image is generated using deep semantic segmentation and saliency detection models. Then, a preliminary warping mesh is computed using axis aligned deformations, enhanced with the use of a distortion measure to ensure low warping deformations. Finally, the retargeted image is produced using a content-aware cropping algorithm. In order to evaluate our method, we perform a user study based on the RetargetMe benchmark. Experimental analyses show that our method outperforms recent approaches, while running in a fraction of their execution time.

</p>
</details>

<details><summary><b>Personalize Web Searching Strategies Classification and Comparison</b>
<a href="https://arxiv.org/abs/2203.13561">arxiv:2203.13561</a>
&#x1F4C8; 2 <br>
<p>Mariya Evtimova-Gardair, Ivan Momtchev</p></summary>
<p>

**Abstract:** Personalization is becoming very important direction in semantic web search for the users that needs to find appropriate information. In this paper, a classification of web personalization is proposed and semantic web search tools are investigated. Building user interest profile is essential for personalizing. Nowadays, semantic web tools use ontologies for personalization because of their advantages. It is important to mention that most of the semantic web search tools use agent technologies for implementation.

</p>
</details>

<details><summary><b>Neural Networks with Divisive normalization for image segmentation with application in cityscapes dataset</b>
<a href="https://arxiv.org/abs/2203.13558">arxiv:2203.13558</a>
&#x1F4C8; 2 <br>
<p>Pablo HernÃ¡ndez-CÃ¡mara, Valero Laparra, JesÃºs Malo</p></summary>
<p>

**Abstract:** One of the key problems in computer vision is adaptation: models are too rigid to follow the variability of the inputs. The canonical computation that explains adaptation in sensory neuroscience is divisive normalization, and it has appealing effects on image manifolds. In this work we show that including divisive normalization in current deep networks makes them more invariant to non-informative changes in the images. In particular, we focus on U-Net architectures for image segmentation. Experiments show that the inclusion of divisive normalization in the U-Net architecture leads to better segmentation results with respect to conventional U-Net. The gain increases steadily when dealing with images acquired in bad weather conditions. In addition to the results on the Cityscapes and Foggy Cityscapes datasets, we explain these advantages through visualization of the responses: the equalization induced by the divisive normalization leads to more invariant features to local changes in contrast and illumination.

</p>
</details>

<details><summary><b>Generalization bounds for learning under graph-dependence: A survey</b>
<a href="https://arxiv.org/abs/2203.13534">arxiv:2203.13534</a>
&#x1F4C8; 2 <br>
<p>Rui-Ray Zhang, Massih-Reza Amini</p></summary>
<p>

**Abstract:** Traditional statistical learning theory relies on the assumption that data are identically and independently generated from a given distribution (i.i.d.). The independently distributed assumption, on the other hand, fails to hold in many real applications. In this survey, we consider learning settings in which examples are dependent and their dependence relationship can be characterized by a graph. We collect various graph-dependent concentration bounds, which are then used to derive Rademacher and stability generalization bounds for learning from graph-dependent data. We illustrate this paradigm with three learning tasks and provide some research directions for future work. To the best of our knowledge, this is the first survey on this subject.

</p>
</details>

<details><summary><b>Machine-Learning Based Objective Function Selection for Community Detection</b>
<a href="https://arxiv.org/abs/2203.13495">arxiv:2203.13495</a>
&#x1F4C8; 2 <br>
<p>Asa Bornstein, Amir Rubin, Danny Hendler</p></summary>
<p>

**Abstract:** NECTAR, a Node-centric ovErlapping Community deTection AlgoRithm, presented in 2016 by Cohen et. al, chooses dynamically between two objective functions which function to optimize, based on the network on which it is invoked. This approach, as shown by Cohen et al., outperforms six state-of-the-art algorithms for overlapping community detection. In this work, we present NECTAR-ML, an extension of the NECTAR algorithm that uses a machine-learning based model for automating the selection of the objective function, trained and evaluated on a dataset of 15,755 synthetic and 7 real-world networks. Our analysis shows that in approximately 90% of the cases our model was able to successfully select the correct objective function. We conducted a competitive analysis of NECTAR and NECTAR-ML. NECTAR-ML was shown to significantly outperform NECTAR's ability to select the best objective function. We also conducted a competitive analysis of NECTAR-ML and two additional state-of-the-art multi-objective community detection algorithms. NECTAR-ML outperformed both algorithms in terms of average detection quality. Multiobjective EAs (MOEAs) are considered to be the most popular approach to solve MOP and the fact that NECTAR-ML significantly outperforms them demonstrates the effectiveness of ML-based objective function selection.

</p>
</details>

<details><summary><b>Facial Expression Recognition with Swin Transformer</b>
<a href="https://arxiv.org/abs/2203.13472">arxiv:2203.13472</a>
&#x1F4C8; 2 <br>
<p>Jun-Hwa Kim, Namho Kim, Chee Sun Won</p></summary>
<p>

**Abstract:** The task of recognizing human facial expressions plays a vital role in various human-related systems, including health care and medical fields. With the recent success of deep learning and the accessibility of a large amount of annotated data, facial expression recognition research has been mature enough to be utilized in real-world scenarios with audio-visual datasets. In this paper, we introduce Swin transformer-based facial expression approach for an in-the-wild audio-visual dataset of the Aff-Wild2 Expression dataset. Specifically, we employ a three-stream network (i.e., Visual stream, Temporal stream, and Audio stream) for the audio-visual videos to fuse the multi-modal information into facial expression recognition. Experimental results on the Aff-Wild2 dataset show the effectiveness of our proposed multi-modal approaches.

</p>
</details>

<details><summary><b>Semi-supervised and Deep learning Frameworks for Video Classification and Key-frame Identification</b>
<a href="https://arxiv.org/abs/2203.13459">arxiv:2203.13459</a>
&#x1F4C8; 2 <br>
<p>Sohini Roychowdhury</p></summary>
<p>

**Abstract:** Automating video-based data and machine learning pipelines poses several challenges including metadata generation for efficient storage and retrieval and isolation of key-frames for scene understanding tasks. In this work, we present two semi-supervised approaches that automate this process of manual frame sifting in video streams by automatically classifying scenes for content and filtering frames for fine-tuning scene understanding tasks. The first rule-based method starts from a pre-trained object detector and it assigns scene type, uncertainty and lighting categories to each frame based on probability distributions of foreground objects. Next, frames with the highest uncertainty and structural dissimilarity are isolated as key-frames. The second method relies on the simCLR model for frame encoding followed by label-spreading from 20% of frame samples to label the remaining frames for scene and lighting categories. Also, clustering the video frames in the encoded feature space further isolates key-frames at cluster boundaries. The proposed methods achieve 64-93% accuracy for automated scene categorization for outdoor image videos from public domain datasets of JAAD and KITTI. Also, less than 10% of all input frames can be filtered as key-frames that can then be sent for annotation and fine tuning of machine vision algorithms. Thus, the proposed framework can be scaled to additional video data streams for automated training of perception-driven systems with minimal training images.

</p>
</details>

<details><summary><b>A Semi-Decoupled Approach to Fast and Optimal Hardware-Software Co-Design of Neural Accelerators</b>
<a href="https://arxiv.org/abs/2203.13921">arxiv:2203.13921</a>
&#x1F4C8; 1 <br>
<p>Bingqian Lu, Zheyu Yan, Yiyu Shi, Shaolei Ren</p></summary>
<p>

**Abstract:** In view of the performance limitations of fully-decoupled designs for neural architectures and accelerators, hardware-software co-design has been emerging to fully reap the benefits of flexible design spaces and optimize neural network performance. Nonetheless, such co-design also enlarges the total search space to practically infinity and presents substantial challenges. While the prior studies have been focusing on improving the search efficiency (e.g., via reinforcement learning), they commonly rely on co-searches over the entire architecture-accelerator design space. In this paper, we propose a \emph{semi}-decoupled approach to reduce the size of the total design space by orders of magnitude, yet without losing optimality. We first perform neural architecture search to obtain a small set of optimal architectures for one accelerator candidate. Importantly, this is also the set of (close-to-)optimal architectures for other accelerator designs based on the property that neural architectures' ranking orders in terms of inference latency and energy consumption on different accelerator designs are highly similar. Then, instead of considering all the possible architectures, we optimize the accelerator design only in combination with this small set of architectures, thus significantly reducing the total search cost. We validate our approach by conducting experiments on various architecture spaces for accelerator designs with different dataflows. Our results highlight that we can obtain the optimal design by only navigating over the reduced search space. The source code of this work is at \url{https://github.com/Ren-Research/CoDesign}.

</p>
</details>

<details><summary><b>On efficient algorithms for computing near-best polynomial approximations to high-dimensional, Hilbert-valued functions from limited samples</b>
<a href="https://arxiv.org/abs/2203.13908">arxiv:2203.13908</a>
&#x1F4C8; 1 <br>
<p>Ben Adcock, Simone Brugiapaglia, Nick Dexter, Sebastian Moraga</p></summary>
<p>

**Abstract:** Sparse polynomial approximation has become indispensable for approximating smooth, high- or infinite-dimensional functions from limited samples. This is a key task in computational science and engineering, e.g., surrogate modelling in UQ where the function is the solution map of a parametric or stochastic PDE. Yet, sparse polynomial approximation lacks a complete theory. On the one hand, there is a well-developed theory of best $s$-term polynomial approximation, which asserts exponential or algebraic rates of convergence for holomorphic functions. On the other hand, there are increasingly mature methods such as (weighted) $\ell^1$-minimization for computing such approximations. While the sample complexity of these methods has been analyzed in detail, the matter of whether or not these methods achieve such rates is not well understood. Furthermore, these methods are not algorithms per se, since they involve exact minimizers of nonlinear optimization problems.
  This paper closes these gaps. Specifically, we pose and answer the following question: are there robust, efficient algorithms for computing approximations to finite- or infinite-dimensional, holomorphic and Hilbert-valued functions from limited samples that achieve best $s$-term rates? We answer this in the affirmative by introducing algorithms and theoretical guarantees that assert exponential or algebraic rates of convergence, along with robustness to sampling, algorithmic, and physical discretization errors. We tackle both scalar- and Hilbert-valued functions, this being particularly relevant to parametric and stochastic PDEs. Our work involves several significant developments of existing techniques, including a novel restarted primal-dual iteration for solving weighted $\ell^1$-minimization problems in Hilbert spaces. Our theory is supplemented by numerical experiments demonstrating the practical efficacy of these algorithms.

</p>
</details>

<details><summary><b>Using Multiple Instance Learning for Explainable Solar Flare Prediction</b>
<a href="https://arxiv.org/abs/2203.13896">arxiv:2203.13896</a>
&#x1F4C8; 1 <br>
<p>CÃ©dric Huwyler, Martin Melchior</p></summary>
<p>

**Abstract:** In this work we leverage a weakly-labeled dataset of spectral data from NASAs IRIS satellite for the prediction of solar flares using the Multiple Instance Learning (MIL) paradigm. While standard supervised learning models expect a label for every instance, MIL relaxes this and only considers bags of instances to be labeled. This is ideally suited for flare prediction with IRIS data that consists of time series of bags of UV spectra measured along the instrument slit. In particular, we consider the readout window around the Mg II h&k lines that encodes information on the dynamics of the solar chromosphere. Our MIL models are not only able to predict whether flares occur within the next $\sim$25 minutes with accuracies of around 90%, but are also able to explain which spectral profiles were particularly important for their bag-level prediction. This information can be used to highlight regions of interest in ongoing IRIS observations in real-time and to identify candidates for typical flare precursor spectral profiles. We use k-means clustering to extract groups of spectral profiles that appear relevant for flare prediction. The recovered groups show high intensity, triplet red wing emission and single-peaked h and k lines, as found by previous works. They seem to be related to small-scale explosive events that have been reported to occur tens of minutes before a flare.

</p>
</details>

<details><summary><b>JAX-FLUIDS: A fully-differentiable high-order computational fluid dynamics solver for compressible two-phase flows</b>
<a href="https://arxiv.org/abs/2203.13760">arxiv:2203.13760</a>
&#x1F4C8; 1 <br>
<p>Deniz A. Bezgin, Aaron B. Buhendwa, Nikolaus A. Adams</p></summary>
<p>

**Abstract:** Physical systems are governed by partial differential equations (PDEs). The Navier-Stokes equations describe fluid flows and are representative of nonlinear physical systems with complex spatio-temporal interactions. Fluid flows are omnipresent in nature and engineering applications, and their accurate simulation is essential for providing insights into these processes. While PDEs are typically solved with numerical methods, the recent success of machine learning (ML) has shown that ML methods can provide novel avenues of finding solutions to PDEs. ML is becoming more and more present in computational fluid dynamics (CFD). However, up to this date, there does not exist a general-purpose ML-CFD package which provides 1) powerful state-of-the-art numerical methods, 2) seamless hybridization of ML with CFD, and 3) automatic differentiation (AD) capabilities. AD in particular is essential to ML-CFD research as it provides gradient information and enables optimization of preexisting and novel CFD models. In this work, we propose JAX-FLUIDS: a comprehensive fully-differentiable CFD Python solver for compressible two-phase flows. JAX-FLUIDS allows the simulation of complex fluid dynamics with phenomena like three-dimensional turbulence, compressibility effects, and two-phase flows. Written entirely in JAX, it is straightforward to include existing ML models into the proposed framework. Furthermore, JAX-FLUIDS enables end-to-end optimization. I.e., ML models can be optimized with gradients that are backpropagated through the entire CFD algorithm, and therefore contain not only information of the underlying PDE but also of the applied numerical methods. We believe that a Python package like JAX-FLUIDS is crucial to facilitate research at the intersection of ML and CFD and may pave the way for an era of differentiable fluid dynamics.

</p>
</details>

<details><summary><b>Fast fluorescence lifetime imaging analysis via extreme learning machine</b>
<a href="https://arxiv.org/abs/2203.13754">arxiv:2203.13754</a>
&#x1F4C8; 1 <br>
<p>Zhenya Zang, Dong Xiao, Quan Wang, Zinuo Li, Wujun Xie, Yu Chen, David Day Uei Li</p></summary>
<p>

**Abstract:** We present a fast and accurate analytical method for fluorescence lifetime imaging microscopy (FLIM) using the extreme learning machine (ELM). We used extensive metrics to evaluate ELM and existing algorithms. First, we compared these algorithms using synthetic datasets. Results indicate that ELM can obtain higher fidelity, even in low-photon conditions. Afterwards, we used ELM to retrieve lifetime components from human prostate cancer cells loaded with gold nanosensors, showing that ELM also outperforms the iterative fitting and non-fitting algorithms. By comparing ELM with a computational efficient neural network, ELM achieves comparable accuracy with less training and inference time. As there is no back-propagation process for ELM during the training phase, the training speed is much higher than existing neural network approaches. The proposed strategy is promising for edge computing with online training.

</p>
</details>

<details><summary><b>Code Smells for Machine Learning Applications</b>
<a href="https://arxiv.org/abs/2203.13746">arxiv:2203.13746</a>
&#x1F4C8; 1 <br>
<p>Haiyin Zhang, LuÃ­s Cruz, Arie van Deursen</p></summary>
<p>

**Abstract:** The popularity of machine learning has wildly expanded in recent years. Machine learning techniques have been heatedly studied in academia and applied in the industry to create business value. However, there is a lack of guidelines for code quality in machine learning applications. In particular, code smells have rarely been studied in this domain. Although machine learning code is usually integrated as a small part of an overarching system, it usually plays an important role in its core functionality. Hence ensuring code quality is quintessential to avoid issues in the long run. This paper proposes and identifies a list of 22 machine learning-specific code smells collected from various sources, including papers, grey literature, GitHub commits, and Stack Overflow posts. We pinpoint each smell with a description of its context, potential issues in the long run, and proposed solutions. In addition, we link them to their respective pipeline stage and the evidence from both academic and grey literature. The code smell catalog helps data scientists and developers produce and maintain high-quality machine learning application code.

</p>
</details>

<details><summary><b>RD-Optimized Trit-Plane Coding of Deep Compressed Image Latent Tensors</b>
<a href="https://arxiv.org/abs/2203.13467">arxiv:2203.13467</a>
&#x1F4C8; 1 <br>
<p>Seungmin Jeon, Jae-Han Lee, Chang-Su Kim</p></summary>
<p>

**Abstract:** DPICT is the first learning-based image codec supporting fine granular scalability. In this paper, we describe how to implement two key components of DPICT efficiently: trit-plane slicing and RD-prioritized transmission. In DPICT, we transform an image into a latent tensor, represent the tensor in ternary digits (trits), and encode the trits in the decreasing order of significance. For entropy encoding, we should compute the probability of each trit, which demands high time complexity in both the encoder and the decoder. To reduce the complexity, we develop a parallel computing scheme for the probabilities and describe it in detail with pseudo-codes. Moreover, in this paper, we compare the trit-plane slicing in DPICT with the alternative bit-plane slicing. Experimental results show that the time complexity is reduced significantly by the parallel computing and that the trit-plane slicing provides better rate-distortion performances than the bit-plane slicing.

</p>
</details>

<details><summary><b>On the performance of preconditioned methods to solve \(L^p\)-norm phase unwrapping</b>
<a href="https://arxiv.org/abs/2203.13675">arxiv:2203.13675</a>
&#x1F4C8; 0 <br>
<p>Ricardo Legarda-Saenz, Carlos Brito-Loeza, Arturo Espinosa-Romero</p></summary>
<p>

**Abstract:** In this paper, we analyze and evaluate suitable preconditioning techniques to improve the performance of the $L^p$-norm phase unwrapping method. We consider five preconditioning techniques commonly found in the literature, and analyze their performance with different sizes of wrapped-phase maps. Keywords.- Phase unwrapping, $L^p$-norm based method, Preconditioning techniques.

</p>
</details>

<details><summary><b>$p$-Generalized Probit Regression and Scalable Maximum Likelihood Estimation via Sketching and Coresets</b>
<a href="https://arxiv.org/abs/2203.13568">arxiv:2203.13568</a>
&#x1F4C8; 0 <br>
<p>Alexander Munteanu, Simon Omlor, Christian Peters</p></summary>
<p>

**Abstract:** We study the $p$-generalized probit regression model, which is a generalized linear model for binary responses. It extends the standard probit model by replacing its link function, the standard normal cdf, by a $p$-generalized normal distribution for $p\in[1, \infty)$. The $p$-generalized normal distributions \citep{Sub23} are of special interest in statistical modeling because they fit much more flexibly to data. Their tail behavior can be controlled by choice of the parameter $p$, which influences the model's sensitivity to outliers. Special cases include the Laplace, the Gaussian, and the uniform distributions. We further show how the maximum likelihood estimator for $p$-generalized probit regression can be approximated efficiently up to a factor of $(1+\varepsilon)$ on large data by combining sketching techniques with importance subsampling to obtain a small data summary called coreset.

</p>
</details>

<details><summary><b>A Comparative Evaluation of Machine Learning Algorithms for the Prediction of R/C Buildings' Seismic Damage</b>
<a href="https://arxiv.org/abs/2203.13449">arxiv:2203.13449</a>
&#x1F4C8; 0 <br>
<p>Konstantinos Demertzis, Konstantinos Kostinakis, Konstantinos Morfidis, Lazaros Iliadis</p></summary>
<p>

**Abstract:** Seismic assessment of buildings and determination of their structural damage is at the forefront of modern scientific research. Since now, several researchers have proposed a number of procedures, in an attempt to estimate the damage response of the buildings subjected to strong ground motions, without conducting time-consuming analyses. These procedures, e.g. construction of fragility curves, usually utilize methods based on the application of statistical theory. In the last decades, the increase of the computers' power has led to the development of modern soft computing methods based on the adoption of Machine Learning algorithms. The present paper attempts an extensive comparative evaluation of the capability of various Machine Learning methods to adequately predict the seismic response of R/C buildings. The training dataset is created by means of Nonlinear Time History Analyses of 90 3D R/C buildings with three different masonry infills' distributions, which are subjected to 65 earthquakes. The seismic damage is expressed in terms of the Maximum Interstory Drift Ratio. A large-scale comparison study is utilized by the most efficient Machine Learning algorithms. The experimentation shows that the LightGBM approach produces training stability, high overall performance and a remarkable coefficient of determination to estimate the ability to predict the buildings' damage response. Due to the extremely urgent issue, civil protection mechanisms need to incorporate in their technological systems scientific methodologies and appropriate technical or modeling tools such as the proposed one, which can offer valuable assistance in making optimal decisions.

</p>
</details>


{% endraw %}
Prev: [2022.03.24]({{ '/2022/03/24/2022.03.24.html' | relative_url }})  Next: [2022.03.26]({{ '/2022/03/26/2022.03.26.html' | relative_url }})