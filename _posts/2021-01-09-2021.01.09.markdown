Prev: [2021.01.08]({{ '/2021/01/08/2021.01.08.html' | relative_url }})  Next: [2021.01.10]({{ '/2021/01/10/2021.01.10.html' | relative_url }})
{% raw %}
## Summary for 2021-01-09, created on 2021-12-24


<details><summary><b>Quantum Generative Models for Small Molecule Drug Discovery</b>
<a href="https://arxiv.org/abs/2101.03438">arxiv:2101.03438</a>
&#x1F4C8; 51 <br>
<p>Junde Li, Rasit Topaloglu, Swaroop Ghosh</p></summary>
<p>

**Abstract:** Existing drug discovery pipelines take 5-10 years and cost billions of dollars. Computational approaches aim to sample from regions of the whole molecular and solid-state compounds called chemical space which could be on the order of 1060 . Deep generative models can model the underlying probability distribution of both the physical structures and property of drugs and relate them nonlinearly. By exploiting patterns in massive datasets, these models can distill salient features that characterize the molecules. Generative Adversarial Networks (GANs) discover drug candidates by generating molecular structures that obey chemical and physical properties and show affinity towards binding with the receptor for a target disease. However, classical GANs cannot explore certain regions of the chemical space and suffer from curse-of-dimensionality. A full quantum GAN may require more than 90 qubits even to generate QM9-like small molecules. We propose a qubit-efficient quantum GAN with a hybrid generator (QGAN-HG) to learn richer representation of molecules via searching exponentially large chemical space with few qubits more efficiently than classical GAN. The QGANHG model is composed of a hybrid quantum generator that supports various number of qubits and quantum circuit layers, and, a classical discriminator. QGAN-HG with only 14.93% retained parameters can learn molecular distribution as efficiently as classical counterpart. The QGAN-HG variation with patched circuits considerably accelerates our standard QGANHG training process and avoids potential gradient vanishing issue of deep neural networks. Code is available on GitHub https://github.com/jundeli/quantum-gan.

</p>
</details>

<details><summary><b>BERT & Family Eat Word Salad: Experiments with Text Understanding</b>
<a href="https://arxiv.org/abs/2101.03453">arxiv:2101.03453</a>
&#x1F4C8; 9 <br>
<p>Ashim Gupta, Giorgi Kvernadze, Vivek Srikumar</p></summary>
<p>

**Abstract:** In this paper, we study the response of large models from the BERT family to incoherent inputs that should confuse any model that claims to understand natural language. We define simple heuristics to construct such examples. Our experiments show that state-of-the-art models consistently fail to recognize them as ill-formed, and instead produce high confidence predictions on them. As a consequence of this phenomenon, models trained on sentences with randomly permuted word order perform close to state-of-the-art models. To alleviate these issues, we show that if models are explicitly trained to recognize invalid inputs, they can be robust to such attacks without a drop in performance.

</p>
</details>

<details><summary><b>SPAGAN: Shortest Path Graph Attention Network</b>
<a href="https://arxiv.org/abs/2101.03464">arxiv:2101.03464</a>
&#x1F4C8; 7 <br>
<p>Yiding Yang, Xinchao Wang, Mingli Song, Junsong Yuan, Dacheng Tao</p></summary>
<p>

**Abstract:** Graph convolutional networks (GCN) have recently demonstrated their potential in analyzing non-grid structure data that can be represented as graphs. The core idea is to encode the local topology of a graph, via convolutions, into the feature of a center node. In this paper, we propose a novel GCN model, which we term as Shortest Path Graph Attention Network (SPAGAN). Unlike conventional GCN models that carry out node-based attentions within each layer, the proposed SPAGAN conducts path-based attention that explicitly accounts for the influence of a sequence of nodes yielding the minimum cost, or shortest path, between the center node and its higher-order neighbors. SPAGAN therefore allows for a more informative and intact exploration of the graph structure and further {a} more effective aggregation of information from distant neighbors into the center node, as compared to node-based GCN methods. We test SPAGAN on the downstream classification task on several standard datasets, and achieve performances superior to the state of the art. Code is publicly available at https://github.com/ihollywhy/SPAGAN.

</p>
</details>

<details><summary><b>LightXML: Transformer with Dynamic Negative Sampling for High-Performance Extreme Multi-label Text Classification</b>
<a href="https://arxiv.org/abs/2101.03305">arxiv:2101.03305</a>
&#x1F4C8; 6 <br>
<p>Ting Jiang, Deqing Wang, Leilei Sun, Huayi Yang, Zhengyang Zhao, Fuzhen Zhuang</p></summary>
<p>

**Abstract:** Extreme Multi-label text Classification (XMC) is a task of finding the most relevant labels from a large label set. Nowadays deep learning-based methods have shown significant success in XMC. However, the existing methods (e.g., AttentionXML and X-Transformer etc) still suffer from 1) combining several models to train and predict for one dataset, and 2) sampling negative labels statically during the process of training label ranking model, which reduces both the efficiency and accuracy of the model. To address the above problems, we proposed LightXML, which adopts end-to-end training and dynamic negative labels sampling. In LightXML, we use generative cooperative networks to recall and rank labels, in which label recalling part generates negative and positive labels, and label ranking part distinguishes positive labels from these labels. Through these networks, negative labels are sampled dynamically during label ranking part training by feeding with the same text representation. Extensive experiments show that LightXML outperforms state-of-the-art methods in five extreme multi-label datasets with much smaller model size and lower computational complexity. In particular, on the Amazon dataset with 670K labels, LightXML can reduce the model size up to 72% compared to AttentionXML.

</p>
</details>

<details><summary><b>Are We There Yet? Learning to Localize in Embodied Instruction Following</b>
<a href="https://arxiv.org/abs/2101.03431">arxiv:2101.03431</a>
&#x1F4C8; 5 <br>
<p>Shane Storks, Qiaozi Gao, Govind Thattai, Gokhan Tur</p></summary>
<p>

**Abstract:** Embodied instruction following is a challenging problem requiring an agent to infer a sequence of primitive actions to achieve a goal environment state from complex language and visual inputs. Action Learning From Realistic Environments and Directives (ALFRED) is a recently proposed benchmark for this problem consisting of step-by-step natural language instructions to achieve subgoals which compose to an ultimate high-level goal. Key challenges for this task include localizing target locations and navigating to them through visual inputs, and grounding language instructions to visual appearance of objects. To address these challenges, in this study, we augment the agent's field of view during navigation subgoals with multiple viewing angles, and train the agent to predict its relative spatial relation to the target location at each timestep. We also improve language grounding by introducing a pre-trained object detection module to the model pipeline. Empirical studies show that our approach exceeds the baseline model performance.

</p>
</details>

<details><summary><b>Task Adaptive Pretraining of Transformers for Hostility Detection</b>
<a href="https://arxiv.org/abs/2101.03382">arxiv:2101.03382</a>
&#x1F4C8; 4 <br>
<p>Tathagata Raha, Sayar Ghosh Roy, Ujwal Narayan, Zubair Abid, Vasudeva Varma</p></summary>
<p>

**Abstract:** Identifying adverse and hostile content on the web and more particularly, on social media, has become a problem of paramount interest in recent years. With their ever increasing popularity, fine-tuning of pretrained Transformer-based encoder models with a classifier head are gradually becoming the new baseline for natural language classification tasks. In our work, we explore the gains attributed to Task Adaptive Pretraining (TAPT) prior to fine-tuning of Transformer-based architectures. We specifically study two problems, namely, (a) Coarse binary classification of Hindi Tweets into Hostile or Not, and (b) Fine-grained multi-label classification of Tweets into four categories: hate, fake, offensive, and defamation. Building up on an architecture which takes emojis and segmented hashtags into consideration for classification, we are able to experimentally showcase the performance upgrades due to TAPT. Our system (with team name 'iREL IIIT') ranked first in the 'Hostile Post Detection in Hindi' shared task with an F1 score of 97.16% for coarse-grained detection and a weighted F1 score of 62.96% for fine-grained multi-label classification on the provided blind test corpora.

</p>
</details>

<details><summary><b>An Unsupervised Learning Method with Convolutional Auto-Encoder for Vessel Trajectory Similarity Computation</b>
<a href="https://arxiv.org/abs/2101.03169">arxiv:2101.03169</a>
&#x1F4C8; 4 <br>
<p>Maohan Liang, Ryan Wen Liu, Shichen Li, Zhe Xiao, Xin Liu, Feng Lu</p></summary>
<p>

**Abstract:** To achieve reliable mining results for massive vessel trajectories, one of the most important challenges is how to efficiently compute the similarities between different vessel trajectories. The computation of vessel trajectory similarity has recently attracted increasing attention in the maritime data mining research community. However, traditional shape- and warping-based methods often suffer from several drawbacks such as high computational cost and sensitivity to unwanted artifacts and non-uniform sampling rates, etc. To eliminate these drawbacks, we propose an unsupervised learning method which automatically extracts low-dimensional features through a convolutional auto-encoder (CAE). In particular, we first generate the informative trajectory images by remapping the raw vessel trajectories into two-dimensional matrices while maintaining the spatio-temporal properties. Based on the massive vessel trajectories collected, the CAE can learn the low-dimensional representations of informative trajectory images in an unsupervised manner. The trajectory similarity is finally equivalent to efficiently computing the similarities between the learned low-dimensional features, which strongly correlate with the raw vessel trajectories. Comprehensive experiments on realistic data sets have demonstrated that the proposed method largely outperforms traditional trajectory similarity computation methods in terms of efficiency and effectiveness. The high-quality trajectory clustering performance could also be guaranteed according to the CAE-based trajectory similarity computation results.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning with Function Properties in Mean Reversion Strategies</b>
<a href="https://arxiv.org/abs/2101.03418">arxiv:2101.03418</a>
&#x1F4C8; 3 <br>
<p>Sophia Gu</p></summary>
<p>

**Abstract:** Over the past decades, researchers have been pushing the limits of Deep Reinforcement Learning (DRL). Although DRL has attracted substantial interest from practitioners, many are blocked by having to search through a plethora of available methodologies that are seemingly alike, while others are still building RL agents from scratch based on classical theories. To address the aforementioned gaps in adopting the latest DRL methods, I am particularly interested in testing out if any of the recent technology developed by the leads in the field can be readily applied to a class of optimal trading problems. Unsurprisingly, many prominent breakthroughs in DRL are investigated and tested on strategic games: from AlphaGo to AlphaStar and at about the same time, OpenAI Five. Thus, in this writing, I want to show precisely how to use a DRL library that is initially built for games in a fundamental trading problem; mean reversion. And by introducing a framework that incorporates economically-motivated function properties, I also demonstrate, through the library, a highly-performant and convergent DRL solution to decision-making financial problems in general.

</p>
</details>

<details><summary><b>Context-Aware Target Apps Selection and Recommendation for Enhancing Personal Mobile Assistants</b>
<a href="https://arxiv.org/abs/2101.03394">arxiv:2101.03394</a>
&#x1F4C8; 3 <br>
<p>Mohammad Aliannejadi, Hamed Zamani, Fabio Crestani, W. Bruce Croft</p></summary>
<p>

**Abstract:** Users install many apps on their smartphones, raising issues related to information overload for users and resource management for devices. Moreover, the recent increase in the use of personal assistants has made mobile devices even more pervasive in users' lives. This paper addresses two research problems that are vital for developing effective personal mobile assistants: target apps selection and recommendation. The former is the key component of a unified mobile search system: a system that addresses the users' information needs for all the apps installed on their devices with a unified mode of access. The latter, instead, predicts the next apps that the users would want to launch. Here we focus on context-aware models to leverage the rich contextual information available to mobile devices. We design an in situ study to collect thousands of mobile queries enriched with mobile sensor data (now publicly available for research purposes). With the aid of this dataset, we study the user behavior in the context of these tasks and propose a family of context-aware neural models that take into account the sequential, temporal, and personal behavior of users. We study several state-of-the-art models and show that the proposed models significantly outperform the baselines.

</p>
</details>

<details><summary><b>Generate Natural Language Explanations for Recommendation</b>
<a href="https://arxiv.org/abs/2101.03392">arxiv:2101.03392</a>
&#x1F4C8; 3 <br>
<p>Hanxiong Chen, Xu Chen, Shaoyun Shi, Yongfeng Zhang</p></summary>
<p>

**Abstract:** Providing personalized explanations for recommendations can help users to understand the underlying insight of the recommendation results, which is helpful to the effectiveness, transparency, persuasiveness and trustworthiness of recommender systems. Current explainable recommendation models mostly generate textual explanations based on pre-defined sentence templates. However, the expressiveness power of template-based explanation sentences are limited to the pre-defined expressions, and manually defining the expressions require significant human efforts. Motivated by this problem, we propose to generate free-text natural language explanations for personalized recommendation. In particular, we propose a hierarchical sequence-to-sequence model (HSS) for personalized explanation generation. Different from conventional sentence generation in NLP research, a great challenge of explanation generation in e-commerce recommendation is that not all sentences in user reviews are of explanation purpose. To solve the problem, we further propose an auto-denoising mechanism based on topical item feature words for sentence generation. Experiments on various e-commerce product domains show that our approach can not only improve the recommendation accuracy, but also the explanation quality in terms of the offline measures and feature words coverage. This research is one of the initial steps to grant intelligent agents with the ability to explain itself based on natural language sentences.

</p>
</details>

<details><summary><b>An Unsupervised Normalization Algorithm for Noisy Text: A Case Study for Information Retrieval and Stance Detection</b>
<a href="https://arxiv.org/abs/2101.03303">arxiv:2101.03303</a>
&#x1F4C8; 3 <br>
<p>Anurag Roy, Shalmoli Ghosh, Kripabandhu Ghosh, Saptarshi Ghosh</p></summary>
<p>

**Abstract:** A large fraction of textual data available today contains various types of 'noise', such as OCR noise in digitized documents, noise due to informal writing style of users on microblogging sites, and so on. To enable tasks such as search/retrieval and classification over all the available data, we need robust algorithms for text normalization, i.e., for cleaning different kinds of noise in the text. There have been several efforts towards cleaning or normalizing noisy text; however, many of the existing text normalization methods are supervised and require language-dependent resources or large amounts of training data that is difficult to obtain. We propose an unsupervised algorithm for text normalization that does not need any training data / human intervention. The proposed algorithm is applicable to text over different languages, and can handle both machine-generated and human-generated noise. Experiments over several standard datasets show that text normalization through the proposed algorithm enables better retrieval and stance detection, as compared to that using several baseline text normalization methods. Implementation of our algorithm can be found at https://github.com/ranarag/UnsupClean.

</p>
</details>

<details><summary><b>Robust Blockchained Federated Learning with Model Validation and Proof-of-Stake Inspired Consensus</b>
<a href="https://arxiv.org/abs/2101.03300">arxiv:2101.03300</a>
&#x1F4C8; 3 <br>
<p>Hang Chen, Syed Ali Asif, Jihong Park, Chien-Chung Shen, Mehdi Bennis</p></summary>
<p>

**Abstract:** Federated learning (FL) is a promising distributed learning solution that only exchanges model parameters without revealing raw data. However, the centralized architecture of FL is vulnerable to the single point of failure. In addition, FL does not examine the legitimacy of local models, so even a small fraction of malicious devices can disrupt global training. To resolve these robustness issues of FL, in this paper, we propose a blockchain-based decentralized FL framework, termed VBFL, by exploiting two mechanisms in a blockchained architecture. First, we introduced a novel decentralized validation mechanism such that the legitimacy of local model updates is examined by individual validators. Second, we designed a dedicated proof-of-stake consensus mechanism where stake is more frequently rewarded to honest devices, which protects the legitimate local model updates by increasing their chances of dictating the blocks appended to the blockchain. Together, these solutions promote more federation within legitimate devices, enabling robust FL. Our emulation results of the MNIST classification corroborate that with 15% of malicious devices, VBFL achieves 87% accuracy, which is 7.4x higher than Vanilla FL.

</p>
</details>

<details><summary><b>Tracking Short-Term Temporal Linguistic Dynamics to Characterize Candidate Therapeutics for COVID-19 in the CORD-19 Corpus</b>
<a href="https://arxiv.org/abs/2101.11710">arxiv:2101.11710</a>
&#x1F4C8; 2 <br>
<p>James Powell, Kari Sentz</p></summary>
<p>

**Abstract:** Scientific literature tends to grow as a function of funding and interest in a given field. Mining such literature can reveal trends that may not be immediately apparent. The CORD-19 corpus represents a growing corpus of scientific literature associated with COVID-19. We examined the intersection of a set of candidate therapeutics identified in a drug-repurposing study with temporal instances of the CORD-19 corpus to determine if it was possible to find and measure changes associated with them over time. We propose that the techniques we used could form the basis of a tool to pre-screen new candidate therapeutics early in the research process.

</p>
</details>

<details><summary><b>Training Deep Architectures Without End-to-End Backpropagation: A Brief Survey</b>
<a href="https://arxiv.org/abs/2101.03419">arxiv:2101.03419</a>
&#x1F4C8; 2 <br>
<p>Shiyu Duan, Jose C. Principe</p></summary>
<p>

**Abstract:** This tutorial paper surveys training alternatives to end-to-end backpropagation (E2EBP) -- the de facto standard for training deep architectures. Modular training refers to strictly local training without both the forward and the backward pass, i.e., dividing a deep architecture into several nonoverlapping modules and training them separately without any end-to-end operation. Between the fully global E2EBP and the strictly local modular training, there are "weakly modular" hybrids performing training without the backward pass only. These alternatives can match or surpass the performance of E2EBP on challenging datasets such as ImageNet, and are gaining increased attention primarily because they offer practical advantages over E2EBP, which will be enumerated herein. In particular, they allow for greater modularity and transparency in deep learning workflows, aligning deep learning with the mainstream computer science engineering that heavily exploits modularization for scalability. Modular training has also revealed novel insights about learning and has further implications on other important research domains. Specifically, it induces natural and effective solutions to some important practical problems such as data efficiency and transferability estimation.

</p>
</details>

<details><summary><b>Active Fire Detection in Landsat-8 Imagery: a Large-Scale Dataset and a Deep-Learning Study</b>
<a href="https://arxiv.org/abs/2101.03409">arxiv:2101.03409</a>
&#x1F4C8; 2 <br>
<p>Gabriel Henrique de Almeida Pereira, Andr√© Minoro Fusioka, Bogdan Tomoyuki Nassu, Rodrigo Minetto</p></summary>
<p>

**Abstract:** Active fire detection in satellite imagery is of critical importance to the management of environmental conservation policies, supporting decision-making and law enforcement. This is a well established field, with many techniques being proposed over the years, usually based on pixel or region-level comparisons involving sensor-specific thresholds and neighborhood statistics. In this paper, we address the problem of active fire detection using deep learning techniques. In recent years, deep learning techniques have been enjoying an enormous success in many fields, but their use for active fire detection is relatively new, with open questions and demand for datasets and architectures for evaluation. This paper addresses these issues by introducing a new large-scale dataset for active fire detection, with over 150,000 image patches (more than 200 GB of data) extracted from Landsat-8 images captured around the world in August and September 2020, containing wildfires in several locations. The dataset was split in two parts, and contains 10-band spectral images with associated outputs, produced by three well known handcrafted algorithms for active fire detection in the first part, and manually annotated masks in the second part. We also present a study on how different convolutional neural network architectures can be used to approximate these handcrafted algorithms, and how models trained on automatically segmented patches can be combined to achieve better performance than the original algorithms - with the best combination having 87.2% precision and 92.4% recall on our manually annotated dataset. The proposed dataset, source codes and trained models are available on Github (https://github.com/pereira-gha/activefire), creating opportunities for further advances in the field

</p>
</details>

<details><summary><b>SARS-Cov-2 RNA Sequence Classification Based on Territory Information</b>
<a href="https://arxiv.org/abs/2101.03323">arxiv:2101.03323</a>
&#x1F4C8; 2 <br>
<p>Jingwei Liu</p></summary>
<p>

**Abstract:** CovID-19 genetics analysis is critical to determine virus type,virus variant and evaluate vaccines. In this paper, SARS-Cov-2 RNA sequence analysis relative to region or territory is investigated. A uniform framework of sequence SVM model with various genetics length from short to long and mixed-bases is developed by projecting SARS-Cov-2 RNA sequence to different dimensional space, then scoring it according to the output probability of pre-trained SVM models to explore the territory or origin information of SARS-Cov-2. Different sample size ratio of training set and test set is also discussed in the data analysis. Two SARS-Cov-2 RNA classification tasks are constructed based on GISAID database, one is for mainland, Hongkong and Taiwan of China, and the other is a 6-class classification task (Africa, Asia, Europe, North American, South American\& Central American, Ocean) of 7 continents. For 3-class classification of China, the Top-1 accuracy rate can reach 82.45\% (train 60\%, test=40\%); For 2-class classification of China, the Top-1 accuracy rate can reach 97.35\% (train 80\%, test 20\%); For 6-class classification task of world, when the ratio of training set and test set is 20\% : 80\% , the Top-1 accuracy rate can achieve 30.30\%. And, some Top-N results are also given.

</p>
</details>

<details><summary><b>FlashP: An Analytical Pipeline for Real-time Forecasting of Time-Series Relational Data</b>
<a href="https://arxiv.org/abs/2101.03298">arxiv:2101.03298</a>
&#x1F4C8; 2 <br>
<p>Shuyuan Yan, Bolin Ding, Wei Guo, Jingren Zhou, Zhewei Wei, Xiaowei Jiang, Sheng Xu</p></summary>
<p>

**Abstract:** Interactive response time is important in analytical pipelines for users to explore a sufficient number of possibilities and make informed business decisions. We consider a forecasting pipeline with large volumes of high-dimensional time series data. Real-time forecasting can be conducted in two steps. First, we specify the part of data to be focused on and the measure to be predicted by slicing, dicing, and aggregating the data. Second, a forecasting model is trained on the aggregated results to predict the trend of the specified measure. While there are a number of forecasting models available, the first step is the performance bottleneck. A natural idea is to utilize sampling to obtain approximate aggregations in real time as the input to train the forecasting model. Our scalable real-time forecasting system FlashP (Flash Prediction) is built based on this idea, with two major challenges to be resolved in this paper: first, we need to figure out how approximate aggregations affect the fitting of forecasting models, and forecasting results; and second, accordingly, what sampling algorithms we should use to obtain these approximate aggregations and how large the samples are. We introduce a new sampling scheme, called GSW sampling, and analyze error bounds for estimating aggregations using GSW samples. We introduce how to construct compact GSW samples with the existence of multiple measures to be analyzed. We conduct experiments to evaluate our solution and compare it with alternatives on real data.

</p>
</details>

<details><summary><b>Large-scale Augmented Granger Causality (lsAGC) for Connectivity Analysis in Complex Systems: From Computer Simulations to Functional MRI (fMRI)</b>
<a href="https://arxiv.org/abs/2101.09354">arxiv:2101.09354</a>
&#x1F4C8; 1 <br>
<p>Axel Wismuller, M. Ali Vosoughi</p></summary>
<p>

**Abstract:** We introduce large-scale Augmented Granger Causality (lsAGC) as a method for connectivity analysis in complex systems. The lsAGC algorithm combines dimension reduction with source time-series augmentation and uses predictive time-series modeling for estimating directed causal relationships among time-series. This method is a multivariate approach, since it is capable of identifying the influence of each time-series on any other time-series in the presence of all other time-series of the underlying dynamic system. We quantitatively evaluate the performance of lsAGC on synthetic directional time-series networks with known ground truth. As a reference method, we compare our results with cross-correlation, which is typically used as a standard measure of connectivity in the functional MRI (fMRI) literature. Using extensive simulations for a wide range of time-series lengths and two different signal-to-noise ratios of 5 and 15 dB, lsAGC consistently outperforms cross-correlation at accurately detecting network connections, using Receiver Operator Characteristic Curve (ROC) analysis, across all tested time-series lengths and noise levels. In addition, as an outlook to possible clinical application, we perform a preliminary qualitative analysis of connectivity matrices for fMRI data of Autism Spectrum Disorder (ASD) patients and typical controls, using a subset of 59 subjects of the Autism Brain Imaging Data Exchange II (ABIDE II) data repository. Our results suggest that lsAGC, by extracting sparse connectivity matrices, may be useful for network analysis in complex systems, and may be applicable to clinical fMRI analysis in future research, such as targeting disease-related classification or regression tasks on clinical data.

</p>
</details>

<details><summary><b>Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on the Arabic Content of Twitter</b>
<a href="https://arxiv.org/abs/2101.05626">arxiv:2101.05626</a>
&#x1F4C8; 1 <br>
<p>Sarah Alqurashi, Btool Hamoui, Abdulaziz Alashaikh, Ahmad Alhindi, Eisa Alanazi</p></summary>
<p>

**Abstract:** The rapid growth of social media content during the current pandemic provides useful tools for disseminating information which has also become a root for misinformation. Therefore, there is an urgent need for fact-checking and effective techniques for detecting misinformation in social media. In this work, we study the misinformation in the Arabic content of Twitter. We construct a large Arabic dataset related to COVID-19 misinformation and gold-annotate the tweets into two categories: misinformation or not. Then, we apply eight different traditional and deep machine learning models, with different features including word embeddings and word frequency. The word embedding models (\textsc{FastText} and word2vec) exploit more than two million Arabic tweets related to COVID-19. Experiments show that optimizing the area under the curve (AUC) improves the models' performance and the Extreme Gradient Boosting (XGBoost) presents the highest accuracy in detecting COVID-19 misinformation online.

</p>
</details>

<details><summary><b>Land Use Detection & Identification using Geo-tagged Tweets</b>
<a href="https://arxiv.org/abs/2101.03337">arxiv:2101.03337</a>
&#x1F4C8; 1 <br>
<p>Saeed Khan, Md Shahzamal</p></summary>
<p>

**Abstract:** Geo-tagged tweets can potentially help with sensing the interaction of people with their surrounding environment. Based on this hypothesis, this paper makes use of geotagged tweets in order to ascertain various land uses with a broader goal to help with urban/city planning. The proposed method utilises supervised learning to reveal spatial land use within cities with the help of Twitter activity signatures. Specifically, the technique involves using tweets from three cities of Australia namely Brisbane, Melbourne and Sydney. Analytical results are checked against the zoning data provided by respective city councils and a good match is observed between the predicted land use and existing land zoning by the city councils. We show that geo-tagged tweets contain features that can be useful for land use identification.

</p>
</details>

<details><summary><b>A Reconfigurable Convolution-in-Pixel CMOS Image Sensor Architecture</b>
<a href="https://arxiv.org/abs/2101.03308">arxiv:2101.03308</a>
&#x1F4C8; 0 <br>
<p>Ruibing Song, Kejie Huang, Zongsheng Wang, Haibin Shen</p></summary>
<p>

**Abstract:** The separation of the data capture and analysis in modern vision systems has led to a massive amount of data transfer between the end devices and cloud computers, resulting in long latency, slow response, and high power consumption. Efficient hardware architectures are under focused development to enable Artificial Intelligence (AI) at the resource-limited end sensing devices. One of the most promising solutions is to enable Processing-in-Pixel (PIP) scheme. However, the conventional schemes suffer from the low fill-factor issue. This paper proposes a PIP based CMOS sensor architecture, which allows convolution operation before the column readout circuit to significantly improve the image reading speed with much lower power consumption. The simulation results show that the proposed architecture could support the computing efficiency up to 11.65 TOPS/W at the 8-bit weight configuration, which is three times as high as the conventional schemes. The transistors required for each pixel are only 2.5T, significantly improving the fill-factor.

</p>
</details>


{% endraw %}
Prev: [2021.01.08]({{ '/2021/01/08/2021.01.08.html' | relative_url }})  Next: [2021.01.10]({{ '/2021/01/10/2021.01.10.html' | relative_url }})