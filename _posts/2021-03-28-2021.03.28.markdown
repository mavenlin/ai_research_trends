## Summary for 2021-03-28, created on 2021-12-23


<details><summary><b>The Autodidactic Universe</b>
<a href="https://arxiv.org/abs/2104.03902">arxiv:2104.03902</a>
&#x1F4C8; 112 <br>
<p>Stephon Alexander, William J. Cunningham, Jaron Lanier, Lee Smolin, Stefan Stanojevic, Michael W. Toomey, Dave Wecker</p></summary>
<p>

**Abstract:** We present an approach to cosmology in which the Universe learns its own physical laws. It does so by exploring a landscape of possible laws, which we express as a certain class of matrix models. We discover maps that put each of these matrix models in correspondence with both a gauge/gravity theory and a mathematical model of a learning machine, such as a deep recurrent, cyclic neural network. This establishes a correspondence between each solution of the physical theory and a run of a neural network. This correspondence is not an equivalence, partly because gauge theories emerge from $N \rightarrow \infty $ limits of the matrix models, whereas the same limits of the neural networks used here are not well-defined. We discuss in detail what it means to say that learning takes place in autodidactic systems, where there is no supervision. We propose that if the neural network model can be said to learn without supervision, the same can be said for the corresponding physical theory. We consider other protocols for autodidactic physical systems, such as optimization of graph variety, subset-replication using self-attention and look-ahead, geometrogenesis guided by reinforcement learning, structural learning using renormalization group techniques, and extensions. These protocols together provide a number of directions in which to explore the origin of physical laws based on putting machine learning architectures in correspondence with physical theories.

</p>
</details>

<details><summary><b>Whitening Sentence Representations for Better Semantics and Faster Retrieval</b>
<a href="https://arxiv.org/abs/2103.15316">arxiv:2103.15316</a>
&#x1F4C8; 43 <br>
<p>Jianlin Su, Jiarun Cao, Weijie Liu, Yangyiwen Ou</p></summary>
<p>

**Abstract:** Pre-training models such as BERT have achieved great success in many natural language processing tasks. However, how to obtain better sentence representation through these pre-training models is still worthy to exploit. Previous work has shown that the anisotropy problem is an critical bottleneck for BERT-based sentence representation which hinders the model to fully utilize the underlying semantic features. Therefore, some attempts of boosting the isotropy of sentence distribution, such as flow-based model, have been applied to sentence representations and achieved some improvement. In this paper, we find that the whitening operation in traditional machine learning can similarly enhance the isotropy of sentence representations and achieve competitive results. Furthermore, the whitening technique is also capable of reducing the dimensionality of the sentence representation. Our experimental results show that it can not only achieve promising performance but also significantly reduce the storage cost and accelerate the model retrieval speed.

</p>
</details>

<details><summary><b>Checkerboard Context Model for Efficient Learned Image Compression</b>
<a href="https://arxiv.org/abs/2103.15306">arxiv:2103.15306</a>
&#x1F4C8; 10 <br>
<p>Dailan He, Yaoyan Zheng, Baocheng Sun, Yan Wang, Hongwei Qin</p></summary>
<p>

**Abstract:** For learned image compression, the autoregressive context model is proved effective in improving the rate-distortion (RD) performance. Because it helps remove spatial redundancies among latent representations. However, the decoding process must be done in a strict scan order, which breaks the parallelization. We propose a parallelizable checkerboard context model (CCM) to solve the problem. Our two-pass checkerboard context calculation eliminates such limitations on spatial locations by re-organizing the decoding order. Speeding up the decoding process more than 40 times in our experiments, it achieves significantly improved computational efficiency with almost the same rate-distortion performance. To the best of our knowledge, this is the first exploration on parallelization-friendly spatial context model for learned image compression.

</p>
</details>

<details><summary><b>Invertible Image Signal Processing</b>
<a href="https://arxiv.org/abs/2103.15061">arxiv:2103.15061</a>
&#x1F4C8; 9 <br>
<p>Yazhou Xing, Zian Qian, Qifeng Chen</p></summary>
<p>

**Abstract:** Unprocessed RAW data is a highly valuable image format for image editing and computer vision. However, since the file size of RAW data is huge, most users can only get access to processed and compressed sRGB images. To bridge this gap, we design an Invertible Image Signal Processing (InvISP) pipeline, which not only enables rendering visually appealing sRGB images but also allows recovering nearly perfect RAW data. Due to our framework's inherent reversibility, we can reconstruct realistic RAW data instead of synthesizing RAW data from sRGB images without any memory overhead. We also integrate a differentiable JPEG compression simulator that empowers our framework to reconstruct RAW data from JPEG images. Extensive quantitative and qualitative experiments on two DSLR demonstrate that our method obtains much higher quality in both rendered sRGB images and reconstructed RAW data than alternative methods.

</p>
</details>

<details><summary><b>Improved Autoregressive Modeling with Distribution Smoothing</b>
<a href="https://arxiv.org/abs/2103.15089">arxiv:2103.15089</a>
&#x1F4C8; 8 <br>
<p>Chenlin Meng, Jiaming Song, Yang Song, Shengjia Zhao, Stefano Ermon</p></summary>
<p>

**Abstract:** While autoregressive models excel at image compression, their sample quality is often lacking. Although not realistic, generated images often have high likelihood according to the model, resembling the case of adversarial examples. Inspired by a successful adversarial defense method, we incorporate randomized smoothing into autoregressive generative modeling. We first model a smoothed version of the data distribution, and then reverse the smoothing process to recover the original data distribution. This procedure drastically improves the sample quality of existing autoregressive models on several synthetic and real-world image datasets while obtaining competitive likelihoods on synthetic datasets.

</p>
</details>

<details><summary><b>Gaussian Process Convolutional Dictionary Learning</b>
<a href="https://arxiv.org/abs/2104.00530">arxiv:2104.00530</a>
&#x1F4C8; 7 <br>
<p>Andrew H. Song, Bahareh Tolooshams, Demba Ba</p></summary>
<p>

**Abstract:** Convolutional dictionary learning (CDL), the problem of estimating shift-invariant templates from data, is typically conducted in the absence of a prior/structure on the templates. In data-scarce or low signal-to-noise ratio (SNR) regimes, learned templates overfit the data and lack smoothness, which can affect the predictive performance of downstream tasks. To address this limitation, we propose GPCDL, a convolutional dictionary learning framework that enforces priors on templates using Gaussian Processes (GPs). With the focus on smoothness, we show theoretically that imposing a GP prior is equivalent to Wiener filtering the learned templates, thereby suppressing high-frequency components and promoting smoothness. We show that the algorithm is a simple extension of the classical iteratively reweighted least squares algorithm, independent of the choice of GP kernels. This property allows one to experiment flexibly with different smoothness assumptions. Through simulation, we show that GPCDL learns smooth dictionaries with better accuracy than the unregularized alternative across a range of SNRs. Through an application to neural spiking data, we show that GPCDL learns a more accurate and visually-interpretable smooth dictionary, leading to superior predictive performance compared to non-regularized CDL, as well as parametric alternatives.

</p>
</details>

<details><summary><b>A Comparative Evaluation of Predominant Deep Learning Quantified Stock Trading Strategies</b>
<a href="https://arxiv.org/abs/2103.15304">arxiv:2103.15304</a>
&#x1F4C8; 6 <br>
<p>Haohan Zhang</p></summary>
<p>

**Abstract:** This study first reconstructs three deep learning powered stock trading models and their associated strategies that are representative of distinct approaches to the problem and established upon different aspects of the many theories evolved around deep learning. It then seeks to compare the performance of these strategies from different perspectives through trading simulations ran on three scenarios when the benchmarks are kept at historical low points for extended periods of time. The results show that in extremely adverse market climates, investment portfolios managed by deep learning powered algorithms are able to avert accumulated losses by generating return sequences that shift the constantly negative CSI 300 benchmark return upward. Among the three, the LSTM model's strategy yields the best performance when the benchmark sustains continued loss.

</p>
</details>

<details><summary><b>Best-Buddy GANs for Highly Detailed Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2103.15295">arxiv:2103.15295</a>
&#x1F4C8; 5 <br>
<p>Wenbo Li, Kun Zhou, Lu Qi, Liying Lu, Nianjuan Jiang, Jiangbo Lu, Jiaya Jia</p></summary>
<p>

**Abstract:** We consider the single image super-resolution (SISR) problem, where a high-resolution (HR) image is generated based on a low-resolution (LR) input. Recently, generative adversarial networks (GANs) become popular to hallucinate details. Most methods along this line rely on a predefined single-LR-single-HR mapping, which is not flexible enough for the SISR task. Also, GAN-generated fake details may often undermine the realism of the whole image. We address these issues by proposing best-buddy GANs (Beby-GAN) for rich-detail SISR. Relaxing the immutable one-to-one constraint, we allow the estimated patches to dynamically seek the best supervision during training, which is beneficial to producing more reasonable details. Besides, we propose a region-aware adversarial learning strategy that directs our model to focus on generating details for textured areas adaptively. Extensive experiments justify the effectiveness of our method. An ultra-high-resolution 4K dataset is also constructed to facilitate future super-resolution research.

</p>
</details>

<details><summary><b>One Network Fits All? Modular versus Monolithic Task Formulations in Neural Networks</b>
<a href="https://arxiv.org/abs/2103.15261">arxiv:2103.15261</a>
&#x1F4C8; 5 <br>
<p>Atish Agarwala, Abhimanyu Das, Brendan Juba, Rina Panigrahy, Vatsal Sharan, Xin Wang, Qiuyi Zhang</p></summary>
<p>

**Abstract:** Can deep learning solve multiple tasks simultaneously, even when they are unrelated and very different? We investigate how the representations of the underlying tasks affect the ability of a single neural network to learn them jointly. We present theoretical and empirical findings that a single neural network is capable of simultaneously learning multiple tasks from a combined data set, for a variety of methods for representing tasks -- for example, when the distinct tasks are encoded by well-separated clusters or decision trees over certain task-code attributes. More concretely, we present a novel analysis that shows that families of simple programming-like constructs for the codes encoding the tasks are learnable by two-layer neural networks with standard training. We study more generally how the complexity of learning such combined tasks grows with the complexity of the task codes; we find that combining many tasks may incur a sample complexity penalty, even though the individual tasks are easy to learn. We provide empirical support for the usefulness of the learning bounds by training networks on clusters, decision trees, and SQL-style aggregation.

</p>
</details>

<details><summary><b>Deconfounded Score Method: Scoring DAGs with Dense Unobserved Confounding</b>
<a href="https://arxiv.org/abs/2103.15106">arxiv:2103.15106</a>
&#x1F4C8; 5 <br>
<p>Alexis Bellot, Mihaela van der Schaar</p></summary>
<p>

**Abstract:** Unobserved confounding is one of the greatest challenges for causal discovery. The case in which unobserved variables have a widespread effect on many of the observed ones is particularly difficult because most pairs of variables are conditionally dependent given any other subset, rendering the causal effect unidentifiable. In this paper we show that beyond conditional independencies, under the principle of independent mechanisms, unobserved confounding in this setting leaves a statistical footprint in the observed data distribution that allows for disentangling spurious and causal effects. Using this insight, we demonstrate that a sparse linear Gaussian directed acyclic graph among observed variables may be recovered approximately and propose an adjusted score-based causal discovery algorithm that may be implemented with general purpose solvers and scales to high-dimensional problems. We find, in addition, that despite the conditions we pose to guarantee causal recovery, performance in practice is robust to large deviations in model assumptions.

</p>
</details>

<details><summary><b>Accurate Stock Price Forecasting Using Robust and Optimized Deep Learning Models</b>
<a href="https://arxiv.org/abs/2103.15096">arxiv:2103.15096</a>
&#x1F4C8; 4 <br>
<p>Jaydip Sen, Sidra Mehtab</p></summary>
<p>

**Abstract:** Designing robust frameworks for precise prediction of future prices of stocks has always been considered a very challenging research problem. The advocates of the classical efficient market hypothesis affirm that it is impossible to accurately predict the future prices in an efficiently operating market due to the stochastic nature of the stock price variables. However, numerous propositions exist in the literature with varying degrees of sophistication and complexity that illustrate how algorithms and models can be designed for making efficient, accurate, and robust predictions of stock prices. We present a gamut of ten deep learning models of regression for precise and robust prediction of the future prices of the stock of a critical company in the auto sector of India. Using a very granular stock price collected at 5 minutes intervals, we train the models based on the records from 31st Dec, 2012 to 27th Dec, 2013. The testing of the models is done using records from 30th Dec, 2013 to 9th Jan 2015. We explain the design principles of the models and analyze the results of their performance based on accuracy in forecasting and speed of execution.

</p>
</details>

<details><summary><b>Adaptive Autonomy in Human-on-the-Loop Vision-Based Robotics Systems</b>
<a href="https://arxiv.org/abs/2103.15053">arxiv:2103.15053</a>
&#x1F4C8; 4 <br>
<p>Sophia Abraham, Zachariah Carmichael, Sreya Banerjee, Rosaura VidalMata, Ankit Agrawal, Md Nafee Al Islam, Walter Scheirer, Jane Cleland-Huang</p></summary>
<p>

**Abstract:** Computer vision approaches are widely used by autonomous robotic systems to sense the world around them and to guide their decision making as they perform diverse tasks such as collision avoidance, search and rescue, and object manipulation. High accuracy is critical, particularly for Human-on-the-loop (HoTL) systems where decisions are made autonomously by the system, and humans play only a supervisory role. Failures of the vision model can lead to erroneous decisions with potentially life or death consequences. In this paper, we propose a solution based upon adaptive autonomy levels, whereby the system detects loss of reliability of these models and responds by temporarily lowering its own autonomy levels and increasing engagement of the human in the decision-making process. Our solution is applicable for vision-based tasks in which humans have time to react and provide guidance. When implemented, our approach would estimate the reliability of the vision task by considering uncertainty in its model, and by performing covariate analysis to determine when the current operating environment is ill-matched to the model's training data. We provide examples from DroneResponse, in which small Unmanned Aerial Systems are deployed for Emergency Response missions, and show how the vision model's reliability would be used in addition to confidence scores to drive and specify the behavior and adaptation of the system's autonomy. This workshop paper outlines our proposed approach and describes open challenges at the intersection of Computer Vision and Software Engineering for the safe and reliable deployment of vision models in the decision making of autonomous systems.

</p>
</details>

<details><summary><b>CyberLearning: Effectiveness Analysis of Machine Learning Security Modeling to Detect Cyber-Anomalies and Multi-Attacks</b>
<a href="https://arxiv.org/abs/2104.08080">arxiv:2104.08080</a>
&#x1F4C8; 3 <br>
<p>Iqbal H. Sarker</p></summary>
<p>

**Abstract:** Detecting cyber-anomalies and attacks are becoming a rising concern these days in the domain of cybersecurity. The knowledge of artificial intelligence, particularly, the machine learning techniques can be used to tackle these issues. However, the effectiveness of a learning-based security model may vary depending on the security features and the data characteristics. In this paper, we present "CyberLearning", a machine learning-based cybersecurity modeling with correlated-feature selection, and a comprehensive empirical analysis on the effectiveness of various machine learning based security models. In our CyberLearning modeling, we take into account a binary classification model for detecting anomalies, and multi-class classification model for various types of cyber-attacks. To build the security model, we first employ the popular ten machine learning classification techniques, such as naive Bayes, Logistic regression, Stochastic gradient descent, K-nearest neighbors, Support vector machine, Decision Tree, Random Forest, Adaptive Boosting, eXtreme Gradient Boosting, as well as Linear discriminant analysis. We then present the artificial neural network-based security model considering multiple hidden layers. The effectiveness of these learning-based security models is examined by conducting a range of experiments utilizing the two most popular security datasets, UNSW-NB15 and NSL-KDD. Overall, this paper aims to serve as a reference point for data-driven security modeling through our experimental analysis and findings in the context of cybersecurity.

</p>
</details>

<details><summary><b>Scaling sparsemax based channel selection for speech recognition with ad-hoc microphone arrays</b>
<a href="https://arxiv.org/abs/2103.15305">arxiv:2103.15305</a>
&#x1F4C8; 3 <br>
<p>Junqi Chen, Xiao-Lei Zhang</p></summary>
<p>

**Abstract:** Recently, speech recognition with ad-hoc microphone arrays has received much attention. It is known that channel selection is an important problem of ad-hoc microphone arrays, however, this topic seems far from explored in speech recognition yet, particularly with a large-scale ad-hoc microphone array. To address this problem, we propose a Scaling Sparsemax algorithm for the channel selection problem of the speech recognition with large-scale ad-hoc microphone arrays. Specifically, we first replace the conventional Softmax operator in the stream attention mechanism of a multichannel end-to-end speech recognition system with Sparsemax, which conducts channel selection by forcing the channel weights of noisy channels to zero. Because Sparsemax punishes the weights of many channels to zero harshly, we propose Scaling Sparsemax which punishes the channels mildly by setting the weights of very noisy channels to zero only. Experimental results with ad-hoc microphone arrays of over 30 channels under the conformer speech recognition architecture show that the proposed Scaling Sparsemax yields a word error rate of over 30% lower than Softmax on simulation data sets, and over 20% lower on semi-real data sets, in test scenarios with both matched and mismatched channel numbers.

</p>
</details>

<details><summary><b>IUP: An Intelligent Utility Prediction Scheme for Solid-State Fermentation in 5G IoT</b>
<a href="https://arxiv.org/abs/2103.15073">arxiv:2103.15073</a>
&#x1F4C8; 3 <br>
<p>Min Wang, Shanchen Pang, Tong Ding, Sibo Qiao, Xue Zhai, Shuo Wang, Neal N. Xiong, Zhengwen Huang</p></summary>
<p>

**Abstract:** At present, SOILD-STATE Fermentation (SSF) is mainly controlled by artificial experience, and the product quality and yield are not stable. Accurately predicting the quality and yield of SSF is of great significance for improving human food security and supply. In this paper, we propose an Intelligent Utility Prediction (IUP) scheme for SSF in 5G Industrial Internet of Things (IoT), including parameter collection and utility prediction of SSF process. This IUP scheme is based on the environmental perception and intelligent learning algorithms of the 5G Industrial IoT. We build a workflow model based on rewritable petri net to verify the correctness of the system model function and process. In addition, we design a utility prediction model for SSF based on the Generative Adversarial Networks (GAN) and Fully Connected Neural Network (FCNN). We design a GAN with constraint of mean square error (MSE-GAN) to solve the problem of few-shot learning of SSF, and then combine with the FCNN to realize the utility prediction (usually use the alcohol) of SSF. Based on the production of liquor in laboratory, the experiments show that the proposed method is more accurate than the other prediction methods in the utility prediction of SSF, and provide the basis for the numerical analysis of the proportion of preconfigured raw materials and the appropriate setting of cellar temperature.

</p>
</details>

<details><summary><b>TransICD: Transformer Based Code-wise Attention Model for Explainable ICD Coding</b>
<a href="https://arxiv.org/abs/2104.10652">arxiv:2104.10652</a>
&#x1F4C8; 2 <br>
<p>Biplob Biswas, Thai-Hoang Pham, Ping Zhang</p></summary>
<p>

**Abstract:** International Classification of Disease (ICD) coding procedure which refers to tagging medical notes with diagnosis codes has been shown to be effective and crucial to the billing system in medical sector. Currently, ICD codes are assigned to a clinical note manually which is likely to cause many errors. Moreover, training skilled coders also requires time and human resources. Therefore, automating the ICD code determination process is an important task. With the advancement of artificial intelligence theory and computational hardware, machine learning approach has emerged as a suitable solution to automate this process. In this project, we apply a transformer-based architecture to capture the interdependence among the tokens of a document and then use a code-wise attention mechanism to learn code-specific representations of the entire document. Finally, they are fed to separate dense layers for corresponding code prediction. Furthermore, to handle the imbalance in the code frequency of clinical datasets, we employ a label distribution aware margin (LDAM) loss function. The experimental results on the MIMIC-III dataset show that our proposed model outperforms other baselines by a significant margin. In particular, our best setting achieves a micro-AUC score of 0.923 compared to 0.868 of bidirectional recurrent neural networks. We also show that by using the code-wise attention mechanism, the model can provide more insights about its prediction, and thus it can support clinicians to make reliable decisions. Our code is available online (https://github.com/biplob1ly/TransICD)

</p>
</details>

<details><summary><b>Extending Multi-Sense Word Embedding to Phrases and Sentences for Unsupervised Semantic Applications</b>
<a href="https://arxiv.org/abs/2103.15330">arxiv:2103.15330</a>
&#x1F4C8; 2 <br>
<p>Haw-Shiuan Chang, Amol Agrawal, Andrew McCallum</p></summary>
<p>

**Abstract:** Most unsupervised NLP models represent each word with a single point or single region in semantic space, while the existing multi-sense word embeddings cannot represent longer word sequences like phrases or sentences. We propose a novel embedding method for a text sequence (a phrase or a sentence) where each sequence is represented by a distinct set of multi-mode codebook embeddings to capture different semantic facets of its meaning. The codebook embeddings can be viewed as the cluster centers which summarize the distribution of possibly co-occurring words in a pre-trained word embedding space. We introduce an end-to-end trainable neural model that directly predicts the set of cluster centers from the input text sequence during test time. Our experiments show that the per-sentence codebook embeddings significantly improve the performances in unsupervised sentence similarity and extractive summarization benchmarks. In phrase similarity experiments, we discover that the multi-facet embeddings provide an interpretable semantic representation but do not outperform the single-facet baseline.

</p>
</details>

<details><summary><b>Bayesian Attention Networks for Data Compression</b>
<a href="https://arxiv.org/abs/2103.15319">arxiv:2103.15319</a>
&#x1F4C8; 2 <br>
<p>Michael Tetelman</p></summary>
<p>

**Abstract:** The lossless data compression algorithm based on Bayesian Attention Networks is derived from first principles. Bayesian Attention Networks are defined by introducing an attention factor per a training sample loss as a function of two sample inputs, from training sample and prediction sample. By using a sharpened Jensen's inequality we show that the attention factor is completely defined by a correlation function of the two samples w.r.t. the model weights. Due to the attention factor the solution for a prediction sample is mostly defined by a few training samples that are correlated with the prediction sample. Finding a specific solution per prediction sample couples together the training and the prediction. To make the approach practical we introduce a latent space to map each prediction sample to a latent space and learn all possible solutions as a function of the latent space along with learning attention as a function of the latent space and a training sample. The latent space plays a role of the context representation with a prediction sample defining a context and a learned context dependent solution used for the prediction.

</p>
</details>

<details><summary><b>Elsa: Energy-based learning for semi-supervised anomaly detection</b>
<a href="https://arxiv.org/abs/2103.15296">arxiv:2103.15296</a>
&#x1F4C8; 2 <br>
<p>Sungwon Han, Hyeonho Song, Seungeon Lee, Sungwon Park, Meeyoung Cha</p></summary>
<p>

**Abstract:** Anomaly detection aims at identifying deviant instances from the normal data distribution. Many advances have been made in the field, including the innovative use of unsupervised contrastive learning. However, existing methods generally assume clean training data and are limited when the data contain unknown anomalies. This paper presents Elsa, a novel semi-supervised anomaly detection approach that unifies the concept of energy-based models with unsupervised contrastive learning. Elsa instills robustness against any data contamination by a carefully designed fine-tuning step based on the new energy function that forces the normal data to be divided into classes of prototypes. Experiments on multiple contamination scenarios show the proposed model achieves SOTA performance. Extensive analyses also verify the contribution of each component in the proposed model. Beyond the experiments, we also offer a theoretical interpretation of why contrastive learning alone cannot detect anomalies under data contamination.

</p>
</details>

<details><summary><b>Rethinking ResNets: Improved Stacking Strategies With High Order Schemes</b>
<a href="https://arxiv.org/abs/2103.15244">arxiv:2103.15244</a>
&#x1F4C8; 2 <br>
<p>Zhengbo Luo, Zitang Sun, Weilian Zhou, Zizhang Wu, Sei-ichiro Kamata</p></summary>
<p>

**Abstract:** Various deep neural network architectures (DNNs) maintain massive vital records in computer vision. While drawing attention worldwide, the design of the overall structure lacks general guidance. Based on the relationship between DNN design and numerical differential equations, we performed a fair comparison of the residual design with higher-order perspectives. We show that the widely used DNN design strategy, constantly stacking a small design (usually 2-3 layers), could be easily improved, supported by solid theoretical knowledge and with no extra parameters needed. We reorganise the residual design in higher-order ways, which is inspired by the observation that many effective networks can be interpreted as different numerical discretisations of differential equations. The design of ResNet follows a relatively simple scheme, which is Euler forward; however, the situation becomes complicated rapidly while stacking. We suppose that stacked ResNet is somehow equalled to a higher-order scheme; then, the current method of forwarding propagation might be relatively weak compared with a typical high-order method such as Runge-Kutta. We propose HO-ResNet to verify the hypothesis of widely used CV benchmarks with sufficient experiments. Stable and noticeable increases in performance are observed, and convergence and robustness are also improved. Our stacking strategy improved ResNet-30 by 2.15 per cent and ResNet-58 by 2.35 per cent on CIFAR-10, with the same settings and parameters. The proposed strategy is fundamental and theoretical and can therefore be applied to any network as a general guideline.

</p>
</details>

<details><summary><b>KNN, An Underestimated Model for Regional Rainfall Forecasting</b>
<a href="https://arxiv.org/abs/2103.15235">arxiv:2103.15235</a>
&#x1F4C8; 2 <br>
<p>Ning Yu, Timothy Haskins</p></summary>
<p>

**Abstract:** Regional rainfall forecasting is an important issue in hydrology and meteorology. This paper aims to design an integrated tool by applying various machine learning algorithms, especially the state-of-the-art deep learning algorithms including Deep Neural Network, Wide Neural Network, Deep and Wide Neural Network, Reservoir Computing, Long Short Term Memory, Support Vector Machine, K-Nearest Neighbor for forecasting regional precipitations over different catchments in Upstate New York. Through the experimental results and the comparison among machine learning models including classification and regression, we find that KNN is an outstanding model over other models to handle the uncertainty in the precipitation data. The data normalization methods such as ZScore and MinMax are also evaluated and discussed.

</p>
</details>

<details><summary><b>Entropy methods for the confidence assessment of probabilistic classification models</b>
<a href="https://arxiv.org/abs/2103.15157">arxiv:2103.15157</a>
&#x1F4C8; 2 <br>
<p>Gabriele N. Tornetta</p></summary>
<p>

**Abstract:** Many classification models produce a probability distribution as the outcome of a prediction. This information is generally compressed down to the single class with the highest associated probability. In this paper, we argue that part of the information that is discarded in this process can be in fact used to further evaluate the goodness of models, and in particular the confidence with which each prediction is made. As an application of the ideas presented in this paper, we provide a theoretical explanation of a confidence degradation phenomenon observed in the complement approach to the (Bernoulli) Naive Bayes generative model.

</p>
</details>

<details><summary><b>Face Recognition as a Method of Authentication in a Web-Based System</b>
<a href="https://arxiv.org/abs/2103.15144">arxiv:2103.15144</a>
&#x1F4C8; 2 <br>
<p>Ben Wycliff Mugalu, Rodrick Calvin Wamala, Jonathan Serugunda, Andrew Katumba</p></summary>
<p>

**Abstract:** Online information systems currently heavily rely on the username and password traditional method for protecting information and controlling access. With the advancement in biometric technology and popularity of fields like AI and Machine Learning, biometric security is becoming increasingly popular because of the usability advantage. This paper reports how machine learning based face recognition can be integrated into a web-based system as a method of authentication to reap the benefits of improved usability. This paper includes a comparison of combinations of detection and classification algorithms with FaceNet for face recognition. The results show that a combination of MTCNN for detection, Facenet for generating embeddings, and LinearSVC for classification outperforms other combinations with a 95% accuracy. The resulting classifier is integrated into the web-based system and used for authenticating users.

</p>
</details>

<details><summary><b>Scaling the weight parameters in Markov logic networks and relational logistic regression models</b>
<a href="https://arxiv.org/abs/2103.15140">arxiv:2103.15140</a>
&#x1F4C8; 2 <br>
<p>Felix Weitkämper</p></summary>
<p>

**Abstract:** We consider Markov logic networks and relational logistic regression as two fundamental representation formalisms in statistical relational artificial intelligence that use weighted formulas in their specification. However, Markov logic networks are based on undirected graphs, while relational logistic regression is based on directed acyclic graphs. We show that when scaling the weight parameters with the domain size, the asymptotic behaviour of a relational logistic regression model is transparently controlled by the parameters, and we supply an algorithm to compute asymptotic probabilities. We also show using two examples that this is not true for Markov logic networks. We also discuss using several examples, mainly from the literature, how the application context can help the user to decide when such scaling is appropriate and when using the raw unscaled parameters might be preferable. We highlight random sampling as a particularly promising area of application for scaled models and expound possible avenues for further research.

</p>
</details>

<details><summary><b>Explaining Representation by Mutual Information</b>
<a href="https://arxiv.org/abs/2103.15114">arxiv:2103.15114</a>
&#x1F4C8; 2 <br>
<p>Lifeng Gu</p></summary>
<p>

**Abstract:** Science is used to discover the law of world. Machine learning can be used to discover the law of data. In recent years, there are more and more research about interpretability in machine learning community. We hope the machine learning methods are safe, interpretable, and they can help us to find meaningful pattern in data. In this paper, we focus on interpretability of deep representation. We propose a interpretable method of representation based on mutual information, which summarizes the interpretation of representation into three types of information between input data and representation. We further proposed MI-LR module, which can be inserted into the model to estimate the amount of information to explain the model's representation. Finally, we verify the method through the visualization of the prototype network.

</p>
</details>

<details><summary><b>Acceptance of COVID-19 Vaccine and Its Determinants in Bangladesh</b>
<a href="https://arxiv.org/abs/2103.15206">arxiv:2103.15206</a>
&#x1F4C8; 1 <br>
<p>Sultan Mahmud, Md. Mohsin, Ijaz Ahmed Khan, Ashraf Uddin Mian, Miah Akib Zaman</p></summary>
<p>

**Abstract:** Background: Bangladesh govt. launched a nationwide vaccination drive against SARS-CoV-2 infection from early February 2021. The objectives of this study were to evaluate the acceptance of the COVID-19 vaccines and examine the factors associated with the acceptance in Bangladesh.
  Method: In between January 30 to February 6, 2021, we conducted a web-based anonymous cross-sectional survey among the Bangladeshi general population. The multivariate logistic regression was used to identify the factors that influence the acceptance of the COVID-19 vaccination.
  Results: 61.16% (370/605) of the respondents were willing to accept/take the COVID-19 vaccine. Among the accepted group, only 35.14% showed the willingness to take the COVID-19 vaccine immediately, while 64.86% would delay the vaccination until they are confirmed about the vaccine's efficacy and safety or COVID-19 become deadlier in Bangladesh. The regression results showed age, gender, location (urban/rural), level of education, income, perceived risk of being infected with COVID-19 in the future, perceived severity of infection, having previous vaccination experience after age 18, having higher knowledge about COVID-19 and vaccination were significantly associated with the acceptance of COVID-19 vaccines.
  Conclusion: The research reported a high prevalence of COVID-19 vaccine refusal and hesitancy in Bangladesh. To diminish the vaccine hesitancy and increase the uptake, the policymakers need to design a well-researched immunization strategy to remove the vaccination barriers. To improve vaccine acceptance among people, false rumors and misconceptions about the COVID-19 vaccines must be dispelled (especially on the internet) and people must be exposed to the actual scientific facts.

</p>
</details>

<details><summary><b>MergeComp: A Compression Scheduler for Scalable Communication-Efficient Distributed Training</b>
<a href="https://arxiv.org/abs/2103.15195">arxiv:2103.15195</a>
&#x1F4C8; 1 <br>
<p>Zhuang Wang, Xinyu Wu, T. S. Eugene Ng</p></summary>
<p>

**Abstract:** Large-scale distributed training is increasingly becoming communication bound. Many gradient compression algorithms have been proposed to reduce the communication overhead and improve scalability. However, it has been observed that in some cases gradient compression may even harm the performance of distributed training.
  In this paper, we propose MergeComp, a compression scheduler to optimize the scalability of communication-efficient distributed training. It automatically schedules the compression operations to optimize the performance of compression algorithms without the knowledge of model architectures or system parameters. We have applied MergeComp to nine popular compression algorithms. Our evaluations show that MergeComp can improve the performance of compression algorithms by up to 3.83x without losing accuracy. It can even achieve a scaling factor of distributed training up to 99% over high-speed networks.

</p>
</details>

<details><summary><b>Graph Convolutional Networks for Model-Based Learning in Nonlinear Inverse Problems</b>
<a href="https://arxiv.org/abs/2103.15138">arxiv:2103.15138</a>
&#x1F4C8; 1 <br>
<p>William Herzberg, Daniel B. Rowe, Andreas Hauptmann, Sarah J. Hamilton</p></summary>
<p>

**Abstract:** The majority of model-based learned image reconstruction methods in medical imaging have been limited to uniform domains, such as pixelated images. If the underlying model is solved on nonuniform meshes, arising from a finite element method typical for nonlinear inverse problems, interpolation and embeddings are needed. To overcome this, we present a flexible framework to extend model-based learning directly to nonuniform meshes, by interpreting the mesh as a graph and formulating our network architectures using graph convolutional neural networks. This gives rise to the proposed iterative Graph Convolutional Newton-type Method (GCNM), which includes the forward model in the solution of the inverse problem, while all updates are directly computed by the network on the problem specific mesh. We present results for Electrical Impedance Tomography, a severely ill-posed nonlinear inverse problem that is frequently solved via optimization-based methods, where the forward problem is solved by finite element methods. Results for absolute EIT imaging are compared to standard iterative methods as well as a graph residual network. We show that the GCNM has strong generalizability to different domain shapes and meshes, out of distribution data as well as experimental data, from purely simulated training data and without transfer training.

</p>
</details>

<details><summary><b>Playing Against the Board: Rolling Horizon Evolutionary Algorithms Against Pandemic</b>
<a href="https://arxiv.org/abs/2103.15090">arxiv:2103.15090</a>
&#x1F4C8; 1 <br>
<p>Konstantinos Sfikas, Antonios Liapis</p></summary>
<p>

**Abstract:** Competitive board games have provided a rich and diverse testbed for artificial intelligence. This paper contends that collaborative board games pose a different challenge to artificial intelligence as it must balance short-term risk mitigation with long-term winning strategies. Collaborative board games task all players to coordinate their different powers or pool their resources to overcome an escalating challenge posed by the board and a stochastic ruleset. This paper focuses on the exemplary collaborative board game Pandemic and presents a rolling horizon evolutionary algorithm designed specifically for this game. The complex way in which the Pandemic game state changes in a stochastic but predictable way required a number of specially designed forward models, macro-action representations for decision-making, and repair functions for the genetic operations of the evolutionary algorithm. Variants of the algorithm which explore optimistic versus pessimistic game state evaluations, different mutation rates and event horizons are compared against a baseline hierarchical policy agent. Results show that an evolutionary approach via short-horizon rollouts can better account for the future dangers that the board may introduce, and guard against them. Results highlight the types of challenges that collaborative board games pose to artificial intelligence, especially for handling multi-player collaboration interactions.

</p>
</details>

<details><summary><b>Mathematics of Digital Hyperspace</b>
<a href="https://arxiv.org/abs/2103.15203">arxiv:2103.15203</a>
&#x1F4C8; 0 <br>
<p>Jeremy Kepner, Timothy Davis, Vijay Gadepally, Hayden Jananthan, Lauren Milechin</p></summary>
<p>

**Abstract:** Social media, e-commerce, streaming video, e-mail, cloud documents, web pages, traffic flows, and network packets fill vast digital lakes, rivers, and oceans that we each navigate daily. This digital hyperspace is an amorphous flow of data supported by continuous streams that stretch standard concepts of type and dimension. The unstructured data of digital hyperspace can be elegantly represented, traversed, and transformed via the mathematics of hypergraphs, hypersparse matrices, and associative array algebra. This paper explores a novel mathematical concept, the semilink, that combines pairs of semirings to provide the essential operations for graph analytics, database operations, and machine learning. The GraphBLAS standard currently supports hypergraphs, hypersparse matrices, the mathematics required for semilinks, and seamlessly performs graph, network, and matrix operations. With the addition of key based indices (such as pointers to strings) and semilinks, GraphBLAS can become a richer associative array algebra and be a plug-in replacement for spreadsheets, database tables, and data centric operating systems, enhancing the navigation of unstructured data found in digital hyperspace.

</p>
</details>

<details><summary><b>Self-supervised Discriminative Feature Learning for Deep Multi-view Clustering</b>
<a href="https://arxiv.org/abs/2103.15069">arxiv:2103.15069</a>
&#x1F4C8; 0 <br>
<p>Jie Xu, Yazhou Ren, Huayi Tang, Zhimeng Yang, Lili Pan, Yang Yang, Xiaorong Pu</p></summary>
<p>

**Abstract:** Multi-view clustering is an important research topic due to its capability to utilize complementary information from multiple views. However, there are few methods to consider the negative impact caused by certain views with unclear clustering structures, resulting in poor multi-view clustering performance. To address this drawback, we propose self-supervised discriminative feature learning for deep multi-view clustering (SDMVC). Concretely, deep autoencoders are applied to learn embedded features for each view independently. To leverage the multi-view complementary information, we concatenate all views' embedded features to form the global features, which can overcome the negative impact of some views' unclear clustering structures. In a self-supervised manner, pseudo-labels are obtained to build a unified target distribution to perform multi-view discriminative feature learning. During this process, global discriminative information can be mined to supervise all views to learn more discriminative features, which in turn are used to update the target distribution. Besides, this unified target distribution can make SDMVC learn consistent cluster assignments, which accomplishes the clustering consistency of multiple views while preserving their features' diversity. Experiments on various types of multi-view datasets show that SDMVC achieves state-of-the-art performance.

</p>
</details>


[Next Page]({{ '/2021/03/27/2021.03.27.html' | relative_url }})
