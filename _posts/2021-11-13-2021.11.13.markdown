## Summary for 2021-11-13, created on 2021-12-17


<details><summary><b>The Three Stages of Learning Dynamics in High-Dimensional Kernel Methods</b>
<a href="https://arxiv.org/abs/2111.07167">arxiv:2111.07167</a>
&#x1F4C8; 43 <br>
<p>Nikhil Ghosh, Song Mei, Bin Yu</p></summary>
<p>

**Abstract:** To understand how deep learning works, it is crucial to understand the training dynamics of neural networks. Several interesting hypotheses about these dynamics have been made based on empirically observed phenomena, but there exists a limited theoretical understanding of when and why such phenomena occur.
  In this paper, we consider the training dynamics of gradient flow on kernel least-squares objectives, which is a limiting dynamics of SGD trained neural networks. Using precise high-dimensional asymptotics, we characterize the dynamics of the fitted model in two "worlds": in the Oracle World the model is trained on the population distribution and in the Empirical World the model is trained on a sampled dataset. We show that under mild conditions on the kernel and $L^2$ target regression function the training dynamics undergo three stages characterized by the behaviors of the models in the two worlds. Our theoretical results also mathematically formalize some interesting deep learning phenomena. Specifically, in our setting we show that SGD progressively learns more complex functions and that there is a "deep bootstrap" phenomenon: during the second stage, the test error of both worlds remain close despite the empirical training error being much smaller. Finally, we give a concrete example comparing the dynamics of two different kernels which shows that faster training is not necessary for better generalization.

</p>
</details>

<details><summary><b>GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates</b>
<a href="https://arxiv.org/abs/2112.03002">arxiv:2112.03002</a>
&#x1F4C8; 8 <br>
<p>Jiayou Zhang, Zhirui Wang, Shizhuo Zhang, Megh Manoj Bhalerao, Yucong Liu, Dawei Zhu, Sheng Wang</p></summary>
<p>

**Abstract:** Biomedical entity normalization unifies the language across biomedical experiments and studies, and further enables us to obtain a holistic view of life sciences. Current approaches mainly study the normalization of more standardized entities such as diseases and drugs, while disregarding the more ambiguous but crucial entities such as pathways, functions and cell types, hindering their real-world applications. To achieve biomedical entity normalization on these under-explored entities, we first introduce an expert-curated dataset OBO-syn encompassing 70 different types of entities and 2 million curated entity-synonym pairs. To utilize the unique graph structure in this dataset, we propose GraphPrompt, a prompt-based learning approach that creates prompt templates according to the graphs. GraphPrompt obtained 41.0% and 29.9% improvement on zero-shot and few-shot settings respectively, indicating the effectiveness of these graph-based prompt templates. We envision that our method GraphPrompt and OBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as the basis for analyzing diverse and accumulating biomedical data.

</p>
</details>

<details><summary><b>Full-attention based Neural Architecture Search using Context Auto-regression</b>
<a href="https://arxiv.org/abs/2111.07139">arxiv:2111.07139</a>
&#x1F4C8; 6 <br>
<p>Yuan Zhou, Haiyang Wang, Shuwei Huo, Boyu Wang</p></summary>
<p>

**Abstract:** Self-attention architectures have emerged as a recent advancement for improving the performance of vision tasks. Manual determination of the architecture for self-attention networks relies on the experience of experts and cannot automatically adapt to various scenarios. Meanwhile, neural architecture search (NAS) has significantly advanced the automatic design of neural architectures. Thus, it is appropriate to consider using NAS methods to discover a better self-attention architecture automatically. However, it is challenging to directly use existing NAS methods to search attention networks because of the uniform cell-based search space and the lack of long-term content dependencies. To address this issue, we propose a full-attention based NAS method. More specifically, a stage-wise search space is constructed that allows various attention operations to be adopted for different layers of a network. To extract global features, a self-supervised search algorithm is proposed that uses context auto-regression to discover the full-attention architecture. To verify the efficacy of the proposed methods, we conducted extensive experiments on various learning tasks, including image classification, fine-grained image recognition, and zero-shot image retrieval. The empirical results show strong evidence that our method is capable of discovering high-performance, full-attention architectures while guaranteeing the required search efficiency.

</p>
</details>

<details><summary><b>Curriculum Learning for Vision-and-Language Navigation</b>
<a href="https://arxiv.org/abs/2111.07228">arxiv:2111.07228</a>
&#x1F4C8; 5 <br>
<p>Jiwen Zhang, Zhongyu Wei, Jianqing Fan, Jiajie Peng</p></summary>
<p>

**Abstract:** Vision-and-Language Navigation (VLN) is a task where an agent navigates in an embodied indoor environment under human instructions. Previous works ignore the distribution of sample difficulty and we argue that this potentially degrade their agent performance. To tackle this issue, we propose a novel curriculum-based training paradigm for VLN tasks that can balance human prior knowledge and agent learning progress about training samples. We develop the principle of curriculum design and re-arrange the benchmark Room-to-Room (R2R) dataset to make it suitable for curriculum training. Experiments show that our method is model-agnostic and can significantly improve the performance, the generalizability, and the training efficiency of current state-of-the-art navigation agents without increasing model complexity.

</p>
</details>

<details><summary><b>Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views</b>
<a href="https://arxiv.org/abs/2111.07117">arxiv:2111.07117</a>
&#x1F4C8; 5 <br>
<p>Li Nanbo, Cian Eastwood, Robert B. Fisher</p></summary>
<p>

**Abstract:** Learning object-centric representations of multi-object scenes is a promising approach towards machine intelligence, facilitating high-level reasoning and control from visual sensory data. However, current approaches for unsupervised object-centric scene representation are incapable of aggregating information from multiple observations of a scene. As a result, these "single-view" methods form their representations of a 3D scene based only on a single 2D observation (view). Naturally, this leads to several inaccuracies, with these methods falling victim to single-view spatial ambiguities. To address this, we propose The Multi-View and Multi-Object Network (MulMON) -- a method for learning accurate, object-centric representations of multi-object scenes by leveraging multiple views. In order to sidestep the main technical difficulty of the multi-object-multi-view scenario -- maintaining object correspondences across views -- MulMON iteratively updates the latent object representations for a scene over multiple views. To ensure that these iterative updates do indeed aggregate spatial information to form a complete 3D scene understanding, MulMON is asked to predict the appearance of the scene from novel viewpoints during training. Through experiments, we show that MulMON better-resolves spatial ambiguities than single-view methods -- learning more accurate and disentangled object representations -- and also achieves new functionality in predicting object segmentations for novel viewpoints.

</p>
</details>

<details><summary><b>Local Multi-Head Channel Self-Attention for Facial Expression Recognition</b>
<a href="https://arxiv.org/abs/2111.07224">arxiv:2111.07224</a>
&#x1F4C8; 4 <br>
<p>Roberto Pecoraro, Valerio Basile, Viviana Bono, Sara Gallo</p></summary>
<p>

**Abstract:** Since the Transformer architecture was introduced in 2017 there has been many attempts to bring the self-attention paradigm in the field of computer vision. In this paper we propose a novel self-attention module that can be easily integrated in virtually every convolutional neural network and that is specifically designed for computer vision, the LHC: Local (multi) Head Channel (self-attention). LHC is based on two main ideas: first, we think that in computer vision the best way to leverage the self-attention paradigm is the channel-wise application instead of the more explored spatial attention and that convolution will not be replaced by attention modules like recurrent networks were in NLP; second, a local approach has the potential to better overcome the limitations of convolution than global attention. With LHC-Net we managed to achieve a new state of the art in the famous FER2013 dataset with a significantly lower complexity and impact on the "host" architecture in terms of computational cost when compared with the previous SOTA.

</p>
</details>

<details><summary><b>Towards One Shot Search Space Poisoning in Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2111.07138">arxiv:2111.07138</a>
&#x1F4C8; 4 <br>
<p>Nayan Saxena, Robert Wu, Rohan Jain</p></summary>
<p>

**Abstract:** We evaluate the robustness of a Neural Architecture Search (NAS) algorithm known as Efficient NAS (ENAS) against data agnostic poisoning attacks on the original search space with carefully designed ineffective operations. We empirically demonstrate how our one shot search space poisoning approach exploits design flaws in the ENAS controller to degrade predictive performance on classification tasks. With just two poisoning operations injected into the search space, we inflate prediction error rates for child networks upto 90% on the CIFAR-10 dataset.

</p>
</details>

<details><summary><b>Memotion Analysis through the Lens of Joint Embedding</b>
<a href="https://arxiv.org/abs/2111.07074">arxiv:2111.07074</a>
&#x1F4C8; 4 <br>
<p>Nethra Gunti, Sathyanarayanan Ramamoorthy, Parth Patwa, Amitava Das</p></summary>
<p>

**Abstract:** Joint embedding (JE) is a way to encode multi-modal data into a vector space where text remains as the grounding key and other modalities like image are to be anchored with such keys. Meme is typically an image with embedded text onto it. Although, memes are commonly used for fun, they could also be used to spread hate and fake information. That along with its growing ubiquity over several social platforms has caused automatic analysis of memes to become a widespread topic of research. In this paper, we report our initial experiments on Memotion Analysis problem through joint embeddings. Results are marginally yielding SOTA.

</p>
</details>

<details><summary><b>Visual design intuition: Predicting dynamic properties of beams from raw cross-section images</b>
<a href="https://arxiv.org/abs/2111.09701">arxiv:2111.09701</a>
&#x1F4C8; 3 <br>
<p>Philippe M. Wyder, Hod Lipson</p></summary>
<p>

**Abstract:** In this work we aim to mimic the human ability to acquire the intuition to estimate the performance of a design from visual inspection and experience alone. We study the ability of convolutional neural networks to predict static and dynamic properties of cantilever beams directly from their raw cross-section images. Using pixels as the only input, the resulting models learn to predict beam properties such as volume maximum deflection and eigenfrequencies with 4.54% and 1.43% Mean Average Percentage Error (MAPE) respectively, compared to the Finite Element Analysis (FEA) approach. Training these models doesn't require prior knowledge of theory or relevant geometric properties, but rather relies solely on simulated or empirical data, thereby making predictions based on "experience" as opposed to theoretical knowledge. Since this approach is over 1000 times faster than FEA, it can be adopted to create surrogate models that could speed up the preliminary optimization studies where numerous consecutive evaluations of similar geometries are required. We suggest that this modeling approach would aid in addressing challenging optimization problems involving complex structures and physical phenomena for which theoretical models are unavailable.

</p>
</details>

<details><summary><b>Session-aware Item-combination Recommendation with Transformer Network</b>
<a href="https://arxiv.org/abs/2111.07154">arxiv:2111.07154</a>
&#x1F4C8; 3 <br>
<p>Tzu-Heng Lin, Chen Gao</p></summary>
<p>

**Abstract:** In this paper, we detailedly describe our solution for the IEEE BigData Cup 2021: RL-based RecSys (Track 1: Item Combination Prediction). We first conduct an exploratory data analysis on the dataset and then utilize the findings to design our framework. Specifically, we use a two-headed transformer-based network to predict user feedback and unlocked sessions, along with the proposed session-aware reweighted loss, multi-tasking with click behavior prediction, and randomness-in-session augmentation. In the final private leaderboard on Kaggle, our method ranked 2nd with a categorization accuracy of 0.39224.

</p>
</details>

<details><summary><b>New Performance Measures for Object Tracking under Complex Environments</b>
<a href="https://arxiv.org/abs/2111.07145">arxiv:2111.07145</a>
&#x1F4C8; 3 <br>
<p>Ajoy Mondal</p></summary>
<p>

**Abstract:** Various performance measures based on the ground truth and without ground truth exist to evaluate the quality of a developed tracking algorithm. The existing popular measures - average center location error (ACLE) and average tracking accuracy (ATA) based on ground truth, may sometimes create confusion to quantify the quality of a developed algorithm for tracking an object under some complex environments (e.g., scaled or oriented or both scaled and oriented object). In this article, we propose three new auxiliary performance measures based on ground truth information to evaluate the quality of a developed tracking algorithm under such complex environments. Moreover, one performance measure is developed by combining both two existing measures ACLE and ATA and three new proposed measures for better quantifying the developed tracking algorithm under such complex conditions. Some examples and experimental results conclude that the proposed measure is better than existing measures to quantify one developed algorithm for tracking objects under such complex environments.

</p>
</details>

<details><summary><b>On the Statistical Benefits of Curriculum Learning</b>
<a href="https://arxiv.org/abs/2111.07126">arxiv:2111.07126</a>
&#x1F4C8; 3 <br>
<p>Ziping Xu, Ambuj Tewari</p></summary>
<p>

**Abstract:** Curriculum learning (CL) is a commonly used machine learning training strategy. However, we still lack a clear theoretical understanding of CL's benefits. In this paper, we study the benefits of CL in the multitask linear regression problem under both structured and unstructured settings. For both settings, we derive the minimax rates for CL with the oracle that provides the optimal curriculum and without the oracle, where the agent has to adaptively learn a good curriculum. Our results reveal that adaptive learning can be fundamentally harder than the oracle learning in the unstructured setting, but it merely introduces a small extra term in the structured setting. To connect theory with practice, we provide justification for a popular empirical method that selects tasks with highest local prediction gain by comparing its guarantees with the minimax rates mentioned above.

</p>
</details>

<details><summary><b>A strong baseline for image and video quality assessment</b>
<a href="https://arxiv.org/abs/2111.07104">arxiv:2111.07104</a>
&#x1F4C8; 3 <br>
<p>Shaoguo Wen, Junle Wang</p></summary>
<p>

**Abstract:** In this work, we present a simple yet effective unified model for perceptual quality assessment of image and video. In contrast to existing models which usually consist of complex network architecture, or rely on the concatenation of multiple branches of features, our model achieves a comparable performance by applying only one global feature derived from a backbone network (i.e. resnet18 in the presented work). Combined with some training tricks, the proposed model surpasses the current baselines of SOTA models on public and private datasets. Based on the architecture proposed, we release the models well trained for three common real-world scenarios: UGC videos in the wild, PGC videos with compression, Game videos with compression. These three pre-trained models can be directly applied for quality assessment, or be further fine-tuned for more customized usages. All the code, SDK, and the pre-trained weights of the proposed models are publicly available at https://github.com/Tencent/CenseoQoE.

</p>
</details>

<details><summary><b>A Practical Tutorial on Explainable AI Techniques</b>
<a href="https://arxiv.org/abs/2111.14260">arxiv:2111.14260</a>
&#x1F4C8; 2 <br>
<p>Adrien Bennetot, Ivan Donadello, Ayoub El Qadi, Mauro Dragoni, Thomas Frossard, Benedikt Wagner, Anna Saranti, Silvia Tulli, Maria Trocan, Raja Chatila, Andreas Holzinger, Artur d'Avila Garcez, Natalia Díaz-Rodríguez</p></summary>
<p>

**Abstract:** Last years have been characterized by an upsurge of opaque automatic decision support systems, such as Deep Neural Networks (DNNs). Although they have great generalization and prediction skills, their functioning does not allow obtaining detailed explanations of their behaviour. As opaque machine learning models are increasingly being employed to make important predictions in critical environments, the danger is to create and use decisions that are not justifiable or legitimate. Therefore, there is a general agreement on the importance of endowing machine learning models with explainability. The reason is that EXplainable Artificial Intelligence (XAI) techniques can serve to verify and certify model outputs and enhance them with desirable notions such as trustworthiness, accountability, transparency and fairness. This tutorial is meant to be the go-to handbook for any audience with a computer science background aiming at getting intuitive insights of machine learning models, accompanied with straight, fast, and intuitive explanations out of the box. We believe that these methods provide a valuable contribution for applying XAI techniques in their particular day-to-day models, datasets and use-cases. Figure \ref{fig:Flowchart} acts as a flowchart/map for the reader and should help him to find the ideal method to use according to his type of data. The reader will find a description of the proposed method as well as an example of use and a Python notebook that he can easily modify as he pleases in order to apply it to his own case of application.

</p>
</details>

<details><summary><b>SDnDTI: Self-supervised deep learning-based denoising for diffusion tensor MRI</b>
<a href="https://arxiv.org/abs/2111.07220">arxiv:2111.07220</a>
&#x1F4C8; 2 <br>
<p>Qiyuan Tian, Ziyu Li, Qiuyun Fan, Jonathan R. Polimeni, Berkin Bilgic, David H. Salat, Susie Y. Huang</p></summary>
<p>

**Abstract:** The noise in diffusion-weighted images (DWIs) decreases the accuracy and precision of diffusion tensor magnetic resonance imaging (DTI) derived microstructural parameters and leads to prolonged acquisition time for achieving improved signal-to-noise ratio (SNR). Deep learning-based image denoising using convolutional neural networks (CNNs) has superior performance but often requires additional high-SNR data for supervising the training of CNNs, which reduces the practical feasibility. We develop a self-supervised deep learning-based method entitled "SDnDTI" for denoising DTI data, which does not require additional high-SNR data for training. Specifically, SDnDTI divides multi-directional DTI data into many subsets, each consisting of six DWI volumes along optimally chosen diffusion-encoding directions that are robust to noise for the tensor fitting, and then synthesizes DWI volumes along all acquired directions from the diffusion tensors fitted using each subset of the data as the input data of CNNs. On the other hand, SDnDTI synthesizes DWI volumes along acquired diffusion-encoding directions with higher SNR from the diffusion tensors fitted using all acquired data as the training target. SDnDTI removes noise from each subset of synthesized DWI volumes using a deep 3-dimensional CNN to match the quality of the cleaner target DWI volumes and achieves even higher SNR by averaging all subsets of denoised data. The denoising efficacy of SDnDTI is demonstrated on two datasets provided by the Human Connectome Project (HCP) and the Lifespan HCP in Aging. The SDnDTI results preserve image sharpness and textural details and substantially improve upon those from the raw data. The results of SDnDTI are comparable to those from supervised learning-based denoising and outperform those from state-of-the-art conventional denoising algorithms including BM4D, AONLM and MPPCA.

</p>
</details>

<details><summary><b>Keyphrase Extraction Using Neighborhood Knowledge Based on Word Embeddings</b>
<a href="https://arxiv.org/abs/2111.07198">arxiv:2111.07198</a>
&#x1F4C8; 2 <br>
<p>Yuchen Liang, Mohammed J. Zaki</p></summary>
<p>

**Abstract:** Keyphrase extraction is the task of finding several interesting phrases in a text document, which provide a list of the main topics within the document. Most existing graph-based models use co-occurrence links as cohesion indicators to model the relationship of syntactic elements. However, a word may have different forms of expression within the document, and may have several synonyms as well. Simply using co-occurrence information cannot capture this information. In this paper, we enhance the graph-based ranking model by leveraging word embeddings as background knowledge to add semantic information to the inter-word graph. Our approach is evaluated on established benchmark datasets and empirical results show that the word embedding neighborhood information improves the model performance.

</p>
</details>

<details><summary><b>Explainable Semantic Space by Grounding Language to Vision with Cross-Modal Contrastive Learning</b>
<a href="https://arxiv.org/abs/2111.07180">arxiv:2111.07180</a>
&#x1F4C8; 2 <br>
<p>Yizhen Zhang, Minkyu Choi, Kuan Han, Zhongming Liu</p></summary>
<p>

**Abstract:** In natural language processing, most models try to learn semantic representations merely from texts. The learned representations encode the distributional semantics but fail to connect to any knowledge about the physical world. In contrast, humans learn language by grounding concepts in perception and action and the brain encodes grounded semantics for cognition. Inspired by this notion and recent work in vision-language learning, we design a two-stream model for grounding language learning in vision. The model includes a VGG-based visual stream and a Bert-based language stream. The two streams merge into a joint representational space. Through cross-modal contrastive learning, the model first learns to align visual and language representations with the MS COCO dataset. The model further learns to retrieve visual objects with language queries through a cross-modal attention module and to infer the visual relations between the retrieved objects through a bilinear operator with the Visual Genome dataset. After training, the language stream of this model is a stand-alone language model capable of embedding concepts in a visually grounded semantic space. This semantic space manifests principal dimensions explainable with human intuition and neurobiological knowledge. Word embeddings in this semantic space are predictive of human-defined norms of semantic features and are segregated into perceptually distinctive clusters. Furthermore, the visually grounded language model also enables compositional language understanding based on visual knowledge and multimodal image search with queries based on images, texts, or their combinations.

</p>
</details>

<details><summary><b>Robust Deep Reinforcement Learning for Extractive Legal Summarization</b>
<a href="https://arxiv.org/abs/2111.07158">arxiv:2111.07158</a>
&#x1F4C8; 2 <br>
<p>Duy-Hung Nguyen, Bao-Sinh Nguyen, Nguyen Viet Dung Nghiem, Dung Tien Le, Mim Amina Khatun, Minh-Tien Nguyen, Hung Le</p></summary>
<p>

**Abstract:** Automatic summarization of legal texts is an important and still a challenging task since legal documents are often long and complicated with unusual structures and styles. Recent advances of deep models trained end-to-end with differentiable losses can well-summarize natural text, yet when applied to legal domain, they show limited results. In this paper, we propose to use reinforcement learning to train current deep summarization models to improve their performance on the legal domain. To this end, we adopt proximal policy optimization methods and introduce novel reward functions that encourage the generation of candidate summaries satisfying both lexical and semantic criteria. We apply our method to training different summarization backbones and observe a consistent and significant performance gain across 3 public legal datasets.

</p>
</details>

<details><summary><b>Developing a Novel Approach for Periapical Dental Radiographs Segmentation</b>
<a href="https://arxiv.org/abs/2111.07156">arxiv:2111.07156</a>
&#x1F4C8; 2 <br>
<p>Elaheh Hatami Majoumerd, Farshad Tajeripour</p></summary>
<p>

**Abstract:** Image processing techniques has been widely used in dental researches such as human identification and forensic dentistry, teeth numbering, dental carries detection and periodontal disease analysis. One of the most challenging parts in dental imaging is teeth segmentation and how to separate them from each other. In this paper, an automated method for teeth segmentation of Periapical dental x-ray images which contain at least one root-canalled tooth is proposed. The result of this approach can be used as an initial step in bone lesion detection. The proposed algorithm is made of two stages. The first stage is pre-processing. The second and main part of this algorithm calculated rotation degree and uses the integral projection method for tooth isolation. Experimental results show that this algorithm is robust and achieves high accuracy.

</p>
</details>

<details><summary><b>Visual Understanding of Complex Table Structures from Document Images</b>
<a href="https://arxiv.org/abs/2111.07129">arxiv:2111.07129</a>
&#x1F4C8; 2 <br>
<p>Sachin Raja, Ajoy Mondal, C V Jawahar</p></summary>
<p>

**Abstract:** Table structure recognition is necessary for a comprehensive understanding of documents. Tables in unstructured business documents are tough to parse due to the high diversity of layouts, varying alignments of contents, and the presence of empty cells. The problem is particularly difficult because of challenges in identifying individual cells using visual or linguistic contexts or both. Accurate detection of table cells (including empty cells) simplifies structure extraction and hence, it becomes the prime focus of our work. We propose a novel object-detection-based deep model that captures the inherent alignments of cells within tables and is fine-tuned for fast optimization. Despite accurate detection of cells, recognizing structures for dense tables may still be challenging because of difficulties in capturing long-range row/column dependencies in presence of multi-row/column spanning cells. Therefore, we also aim to improve structure recognition by deducing a novel rectilinear graph-based formulation. From a semantics perspective, we highlight the significance of empty cells in a table. To take these cells into account, we suggest an enhancement to a popular evaluation criterion. Finally, we introduce a modestly sized evaluation dataset with an annotation style inspired by human cognition to encourage new approaches to the problem. Our framework improves the previous state-of-the-art performance by a 2.7% average F1-score on benchmark datasets.

</p>
</details>

<details><summary><b>Nyström Regularization for Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2111.07109">arxiv:2111.07109</a>
&#x1F4C8; 2 <br>
<p>Zirui Sun, Mingwei Dai, Yao Wang, Shao-Bo Lin</p></summary>
<p>

**Abstract:** This paper focuses on learning rate analysis of Nyström regularization with sequential sub-sampling for $τ$-mixing time series. Using a recently developed Banach-valued Bernstein inequality for $τ$-mixing sequences and an integral operator approach based on second-order decomposition, we succeed in deriving almost optimal learning rates of Nyström regularization with sequential sub-sampling for $τ$-mixing time series. A series of numerical experiments are carried out to verify our theoretical results, showing the excellent learning performance of Nyström regularization with sequential sub-sampling in learning massive time series data. All these results extend the applicable range of Nyström regularization from i.i.d. samples to non-i.i.d. sequences.

</p>
</details>

<details><summary><b>Deep Neural Networks for Automatic Grain-matrix Segmentation in Plane and Cross-polarized Sandstone Photomicrographs</b>
<a href="https://arxiv.org/abs/2111.07102">arxiv:2111.07102</a>
&#x1F4C8; 2 <br>
<p>Rajdeep Das, Ajoy Mondal, Tapan Chakraborty, Kuntal Ghosh</p></summary>
<p>

**Abstract:** Grain segmentation of sandstone that is partitioning the grain from its surrounding matrix/cement in the thin section is the primary step for computer-aided mineral identification and sandstone classification. The microscopic images of sandstone contain many mineral grains and their surrounding matrix/cement. The distinction between adjacent grains and the matrix is often ambiguous, making grain segmentation difficult. Various solutions exist in literature to handle these problems; however, they are not robust against sandstone petrography's varied pattern. In this paper, we formulate grain segmentation as a pixel-wise two-class (i.e., grain and background) semantic segmentation task. We develop a deep learning-based end-to-end trainable framework named Deep Semantic Grain Segmentation network (DSGSN), a data-driven method, and provide a generic solution. As per the authors' knowledge, this is the first work where the deep neural network is explored to solve the grain segmentation problem. Extensive experiments on microscopic images highlight that our method obtains better segmentation accuracy than various segmentation architectures with more parameters.

</p>
</details>

<details><summary><b>Speech Emotion Recognition Using Deep Sparse Auto-Encoder Extreme Learning Machine with a New Weighting Scheme and Spectro-Temporal Features Along with Classical Feature Selection and A New Quantum-Inspired Dimension Reduction Method</b>
<a href="https://arxiv.org/abs/2111.07094">arxiv:2111.07094</a>
&#x1F4C8; 2 <br>
<p>Fatemeh Daneshfar, Seyed Jahanshah Kabudian</p></summary>
<p>

**Abstract:** Affective computing is very important in the relationship between man and machine. In this paper, a system for speech emotion recognition (SER) based on speech signal is proposed, which uses new techniques in different stages of processing. The system consists of three stages: feature extraction, feature selection, and finally feature classification. In the first stage, a complex set of long-term statistics features is extracted from both the speech signal and the glottal-waveform signal using a combination of new and diverse features such as prosodic, spectral, and spectro-temporal features. One of the challenges of the SER systems is to distinguish correlated emotions. These features are good discriminators for speech emotions and increase the SER's ability to recognize similar and different emotions. This feature vector with a large number of dimensions naturally has redundancy. In the second stage, using classical feature selection techniques as well as a new quantum-inspired technique to reduce the feature vector dimensionality, the number of feature vector dimensions is reduced. In the third stage, the optimized feature vector is classified by a weighted deep sparse extreme learning machine (ELM) classifier. The classifier performs classification in three steps: sparse random feature learning, orthogonal random projection using the singular value decomposition (SVD) technique, and discriminative classification in the last step using the generalized Tikhonov regularization technique. Also, many existing emotional datasets suffer from the problem of data imbalanced distribution, which in turn increases the classification error and decreases system performance. In this paper, a new weighting method has also been proposed to deal with class imbalance, which is more efficient than existing weighting methods. The proposed method is evaluated on three standard emotional databases.

</p>
</details>

<details><summary><b>Learning Data Teaching Strategies Via Knowledge Tracing</b>
<a href="https://arxiv.org/abs/2111.07083">arxiv:2111.07083</a>
&#x1F4C8; 2 <br>
<p>Ghodai Abdelrahman, Qing Wang</p></summary>
<p>

**Abstract:** Teaching plays a fundamental role in human learning. Typically, a human teaching strategy would involve assessing a student's knowledge progress for tailoring the teaching materials in a way that enhances the learning progress. A human teacher would achieve this by tracing a student's knowledge over important learning concepts in a task. Albeit, such teaching strategy is not well exploited yet in machine learning as current machine teaching methods tend to directly assess the progress on individual training samples without paying attention to the underlying learning concepts in a learning task. In this paper, we propose a novel method, called Knowledge Augmented Data Teaching (KADT), which can optimize a data teaching strategy for a student model by tracing its knowledge progress over multiple learning concepts in a learning task. Specifically, the KADT method incorporates a knowledge tracing model to dynamically capture the knowledge progress of a student model in terms of latent learning concepts. Then we develop an attention pooling mechanism to distill knowledge representations of a student model with respect to class labels, which enables to develop a data teaching strategy on critical training samples. We have evaluated the performance of the KADT method on four different machine learning tasks including knowledge tracing, sentiment analysis, movie recommendation, and image classification. The results comparing to the state-of-the-art methods empirically validate that KADT consistently outperforms others on all tasks.

</p>
</details>

<details><summary><b>Networking of Internet of UAVs: Challenges and Intelligent Approaches</b>
<a href="https://arxiv.org/abs/2111.07078">arxiv:2111.07078</a>
&#x1F4C8; 2 <br>
<p>Peng Yang, Xianbin Cao, Tony Q. S. Quek, Dapeng Oliver Wu</p></summary>
<p>

**Abstract:** Internet of unmanned aerial vehicle (I-UAV) networks promise to accomplish sensing and transmission tasks quickly, robustly, and cost-efficiently via effective cooperation among UAVs. To achieve the promising benefits, the crucial I-UAV networking issue should be tackled. This article argues that I-UAV networking can be classified into three categories, quality-of-service (QoS) driven networking, quality-of-experience (QoE) driven networking, and situation aware networking. Each category of networking poses emerging challenges which have severe effects on the safe and efficient accomplishment of I-UAV missions. This article elaborately analyzes these challenges and expounds on the corresponding intelligent approaches to tackle the I-UAV networking issue. Besides, considering the uplifting effect of extending the scalability of I-UAV networks through cooperating with high altitude platforms (HAPs), this article gives an overview of the integrated HAP and I-UAV networks and presents the corresponding networking challenges and intelligent approaches.

</p>
</details>

<details><summary><b>Multiset Signal Processing and Electronics</b>
<a href="https://arxiv.org/abs/2111.08514">arxiv:2111.08514</a>
&#x1F4C8; 1 <br>
<p>Luciano da F. Costa</p></summary>
<p>

**Abstract:** Multisets are an intuitive extension of the traditional concept of sets that allow repetition of elements, with the number of times each element appears being understood as the respective multiplicity. Recent generalizations of multisets to real-valued functions, accounting for possibly negative values, have paved the way to a number of interesting implications and applications, including respective implementations as electronic systems. The basic multiset operations include the set complementation (sign change), intersection (minimum between two values), union (maximum between two values), difference and sum (identical to the algebraic counterparts). When applied to functions or signals, the sign and conjoint sign functions are also required. Given that signals are functions, it becomes possible to effectively translate the multiset and multifunction operations to analog electronics, which is the objective of the present work. It is proposed that effective multiset operations capable of high performance self and cross-correlation can be obtained with relative simplicity in either discrete or integrated circuits. The problem of switching noise is also briefly discussed. The present results have great potential for applications and related developments in analog and digital electronics, as well as for pattern recognition, signal processing, and deep learning.

</p>
</details>

<details><summary><b>An Energy Consumption Model for Electrical Vehicle Networks via Extended Federated-learning</b>
<a href="https://arxiv.org/abs/2111.08472">arxiv:2111.08472</a>
&#x1F4C8; 1 <br>
<p>Shiliang Zhang</p></summary>
<p>

**Abstract:** Electrical vehicle (EV) raises to promote an eco-sustainable society. Nevertheless, the ``range anxiety'' of EV hinders its wider acceptance among customers. This paper proposes a novel solution to range anxiety based on a federated-learning model, which is capable of estimating battery consumption and providing energy-efficient route planning for vehicle networks. Specifically, the new approach extends the federated-learning structure with two components: anomaly detection and sharing policy. The first component identifies preventing factors in model learning, while the second component offers guidelines for information sharing amongst vehicle networks when the sharing is necessary to preserve learning efficiency. The two components collaborate to enhance learning robustness against data heterogeneities in networks. Numerical experiments are conducted, and the results show that compared with considered solutions, the proposed approach could provide higher accuracy of battery-consumption estimation for vehicles under heterogeneous data distributions, without increasing the time complexity or transmitting raw data among vehicle networks.

</p>
</details>

<details><summary><b>FACOS: Finding API Relevant Contents on Stack Overflow with Semantic and Syntactic Analysis</b>
<a href="https://arxiv.org/abs/2111.07238">arxiv:2111.07238</a>
&#x1F4C8; 1 <br>
<p>Kien Luong, Mohammad Hadi, Ferdian Thung, Fatemeh Fard, David Lo</p></summary>
<p>

**Abstract:** Collecting API examples, usages, and mentions relevant to a specific API method over discussions on venues such as Stack Overflow is not a trivial problem. It requires efforts to correctly recognize whether the discussion refers to the API method that developers/tools are searching for. The content of the thread, which consists of both text paragraphs describing the involvement of the API method in the discussion and the code snippets containing the API invocation, may refer to the given API method. Leveraging this observation, we develop FACOS, a context-specific algorithm to capture the semantic and syntactic information of the paragraphs and code snippets in a discussion. FACOS combines a syntactic word-based score with a score from a predictive model fine-tuned from CodeBERT. FACOS beats the state-of-the-art approach by 13.9% in terms of F1-score.

</p>
</details>

<details><summary><b>Reliably-stabilizing piecewise-affine neural network controllers</b>
<a href="https://arxiv.org/abs/2111.07183">arxiv:2111.07183</a>
&#x1F4C8; 1 <br>
<p>Filippo Fabiani, Paul J. Goulart</p></summary>
<p>

**Abstract:** A common problem affecting neural network (NN) approximations of model predictive control (MPC) policies is the lack of analytical tools to assess the stability of the closed-loop system under the action of the NN-based controller. We present a general procedure to quantify the performance of such a controller, or to design minimum complexity NNs with rectified linear units (ReLUs) that preserve the desirable properties of a given MPC scheme. By quantifying the approximation error between NN-based and MPC-based state-to-input mappings, we first establish suitable conditions involving two key quantities, the worst-case error and the Lipschitz constant, guaranteeing the stability of the closed-loop system. We then develop an offline, mixed-integer optimization-based method to compute those quantities exactly. Together these techniques provide conditions sufficient to certify the stability and performance of a ReLU-based approximation of an MPC control law.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning with Shallow Controllers: An Experimental Application to PID Tuning</b>
<a href="https://arxiv.org/abs/2111.07171">arxiv:2111.07171</a>
&#x1F4C8; 1 <br>
<p>Nathan P. Lawrence, Michael G. Forbes, Philip D. Loewen, Daniel G. McClement, Johan U. Backstrom, R. Bhushan Gopaluni</p></summary>
<p>

**Abstract:** Deep reinforcement learning (RL) is an optimization-driven framework for producing control strategies for general dynamical systems without explicit reliance on process models. Good results have been reported in simulation. Here we demonstrate the challenges in implementing a state of the art deep RL algorithm on a real physical system. Aspects include the interplay between software and existing hardware; experiment design and sample efficiency; training subject to input constraints; and interpretability of the algorithm and control law. At the core of our approach is the use of a PID controller as the trainable RL policy. In addition to its simplicity, this approach has several appealing features: No additional hardware needs to be added to the control system, since a PID controller can easily be implemented through a standard programmable logic controller; the control law can easily be initialized in a "safe'' region of the parameter space; and the final product -- a well-tuned PID controller -- has a form that practitioners can reason about and deploy with confidence.

</p>
</details>

<details><summary><b>SocialBERT -- Transformers for Online SocialNetwork Language Modelling</b>
<a href="https://arxiv.org/abs/2111.07148">arxiv:2111.07148</a>
&#x1F4C8; 1 <br>
<p>Ilia Karpov, Nick Kartashev</p></summary>
<p>

**Abstract:** The ubiquity of the contemporary language understanding tasks gives relevance to the development of generalized, yet highly efficient models that utilize all knowledge, provided by the data source. In this work, we present SocialBERT - the first model that uses knowledge about the author's position in the network during text analysis. We investigate possible models for learning social network information and successfully inject it into the baseline BERT model. The evaluation shows that embedding this information maintains a good generalization, with an increase in the quality of the probabilistic model for the given author up to 7.5%. The proposed model has been trained on the majority of groups for the chosen social network, and still able to work with previously unknown groups. The obtained model, as well as the code of our experiments, is available for download and use in applied tasks.

</p>
</details>

<details><summary><b>The Pseudo Projection Operator: Applications of Deep Learning to Projection Based Filtering in Non-Trivial Frequency Regimes</b>
<a href="https://arxiv.org/abs/2111.07140">arxiv:2111.07140</a>
&#x1F4C8; 1 <br>
<p>Matthew L. Weiss, Nathan C. Frey, Siddharth Samsi, Randy C. Paffenroth, Vijay Gadepally</p></summary>
<p>

**Abstract:** Traditional frequency based projection filters, or projection operators (PO), separate signal and noise through a series of transformations which remove frequencies where noise is present. However, this technique relies on a priori knowledge of what frequencies contain signal and noise and that these frequencies do not overlap, which is difficult to achieve in practice. To address these issues, we introduce a PO-neural network hybrid model, the Pseudo Projection Operator (PPO), which leverages a neural network to perform frequency selection. We compare the filtering capabilities of a PPO, PO, and denoising autoencoder (DAE) on the University of Rochester Multi-Modal Music Performance Dataset with a variety of added noise types. In the majority of experiments, the PPO outperforms both the PO and DAE. Based upon these results, we suggest future application of the PPO to filtering problems in the physical and biological sciences.

</p>
</details>

<details><summary><b>PAMMELA: Policy Administration Methodology using Machine Learning</b>
<a href="https://arxiv.org/abs/2111.07060">arxiv:2111.07060</a>
&#x1F4C8; 1 <br>
<p>Varun Gumma, Barsha Mitra, Soumyadeep Dey, Pratik Shashikantbhai Patel, Sourabh Suman, Saptarshi Das</p></summary>
<p>

**Abstract:** In recent years, Attribute-Based Access Control (ABAC) has become quite popular and effective for enforcing access control in dynamic and collaborative environments. Implementation of ABAC requires the creation of a set of attribute-based rules which cumulatively form a policy. Designing an ABAC policy ab initio demands a substantial amount of effort from the system administrator. Moreover, organizational changes may necessitate the inclusion of new rules in an already deployed policy. In such a case, re-mining the entire ABAC policy will require a considerable amount of time and administrative effort. Instead, it is better to incrementally augment the policy. Keeping these aspects of reducing administrative overhead in mind, in this paper, we propose PAMMELA, a Policy Administration Methodology using Machine Learning to help system administrators in creating new ABAC policies as well as augmenting existing ones. PAMMELA can generate a new policy for an organization by learning the rules of a policy currently enforced in a similar organization. For policy augmentation, PAMMELA can infer new rules based on the knowledge gathered from the existing rules. Experimental results show that our proposed approach provides a reasonably good performance in terms of the various machine learning evaluation metrics as well as execution time.

</p>
</details>


[Next Page]({{ '/2021/11/12/2021.11.12.html' | relative_url }})
