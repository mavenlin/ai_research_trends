Prev: [2022.04.21]({{ '/2022/04/21/2022.04.21.html' | relative_url }})  Next: [2022.04.23]({{ '/2022/04/23/2022.04.23.html' | relative_url }})
{% raw %}
## Summary for 2022-04-22, created on 2022-04-26


<details><summary><b>A Vocabulary-Free Multilingual Neural Tokenizer for End-to-End Task Learning</b>
<a href="https://arxiv.org/abs/2204.10815">arxiv:2204.10815</a>
&#x1F4C8; 7 <br>
<p>Md Mofijul Islam, Gustavo Aguilar, Pragaash Ponnusamy, Clint Solomon Mathialagan, Chengyuan Ma, Chenlei Guo</p></summary>
<p>

**Abstract:** Subword tokenization is a commonly used input pre-processing step in most recent NLP models. However, it limits the models' ability to leverage end-to-end task learning. Its frequency-based vocabulary creation compromises tokenization in low-resource languages, leading models to produce suboptimal representations. Additionally, the dependency on a fixed vocabulary limits the subword models' adaptability across languages and domains. In this work, we propose a vocabulary-free neural tokenizer by distilling segmentation information from heuristic-based subword tokenization. We pre-train our character-based tokenizer by processing unique words from multilingual corpus, thereby extensively increasing word diversity across languages. Unlike the predefined and fixed vocabularies in subword methods, our tokenizer allows end-to-end task learning, resulting in optimal task-specific tokenization. The experimental results show that replacing the subword tokenizer with our neural tokenizer consistently improves performance on multilingual (NLI) and code-switching (sentiment analysis) tasks, with larger gains in low-resource languages. Additionally, our neural tokenizer exhibits a robust performance on downstream tasks when adversarial noise is present (typos and misspelling), further increasing the initial improvements over statistical subword tokenizers.

</p>
</details>

<details><summary><b>Exploiting Session Information in BERT-based Session-aware Sequential Recommendation</b>
<a href="https://arxiv.org/abs/2204.10851">arxiv:2204.10851</a>
&#x1F4C8; 6 <br>
<p>Jinseok Seol, Youngrok Ko, Sang-goo Lee</p></summary>
<p>

**Abstract:** In recommendation systems, utilizing the user interaction history as sequential information has resulted in great performance improvement. However, in many online services, user interactions are commonly grouped by sessions that presumably share preferences, which requires a different approach from ordinary sequence representation techniques. To this end, sequence representation models with a hierarchical structure or various viewpoints have been developed but with a rather complex network structure. In this paper, we propose three methods to improve recommendation performance by exploiting session information while minimizing additional parameters in a BERT-based sequential recommendation model: using session tokens, adding session segment embeddings, and a time-aware self-attention. We demonstrate the feasibility of the proposed methods through experiments on widely used recommendation datasets.

</p>
</details>

<details><summary><b>E2E Segmenter: Joint Segmenting and Decoding for Long-Form ASR</b>
<a href="https://arxiv.org/abs/2204.10749">arxiv:2204.10749</a>
&#x1F4C8; 6 <br>
<p>W. Ronny Huang, Shuo-yiin Chang, David Rybach, Rohit Prabhavalkar, Tara N. Sainath, Cyril Allauzen, Cal Peyser, Zhiyun Lu</p></summary>
<p>

**Abstract:** Improving the performance of end-to-end ASR models on long utterances ranging from minutes to hours in length is an ongoing challenge in speech recognition. A common solution is to segment the audio in advance using a separate voice activity detector (VAD) that decides segment boundary locations based purely on acoustic speech/non-speech information. VAD segmenters, however, may be sub-optimal for real-world speech where, e.g., a complete sentence that should be taken as a whole may contain hesitations in the middle ("set an alarm for... 5 o'clock").
  We propose to replace the VAD with an end-to-end ASR model capable of predicting segment boundaries in a streaming fashion, allowing the segmentation decision to be conditioned not only on better acoustic features but also on semantic features from the decoded text with negligible extra computation. In experiments on real world long-form audio (YouTube) with lengths of up to 30 minutes, we demonstrate 8.5% relative WER improvement and 250 ms reduction in median end-of-segment latency compared to the VAD segmenter baseline on a state-of-the-art Conformer RNN-T model.

</p>
</details>

<details><summary><b>Learning to Scaffold: Optimizing Model Explanations for Teaching</b>
<a href="https://arxiv.org/abs/2204.10810">arxiv:2204.10810</a>
&#x1F4C8; 5 <br>
<p>Patrick Fernandes, Marcos Treviso, Danish Pruthi, André F. T. Martins, Graham Neubig</p></summary>
<p>

**Abstract:** Modern machine learning models are opaque, and as a result there is a burgeoning academic subfield on methods that explain these models' behavior. However, what is the precise goal of providing such explanations, and how can we demonstrate that explanations achieve this goal? Some research argues that explanations should help teach a student (either human or machine) to simulate the model being explained, and that the quality of explanations can be measured by the simulation accuracy of students on unexplained examples. In this work, leveraging meta-learning techniques, we extend this idea to improve the quality of the explanations themselves, specifically by optimizing explanations such that student models more effectively learn to simulate the original model. We train models on three natural language processing and computer vision tasks, and find that students trained with explanations extracted with our framework are able to simulate the teacher significantly more effectively than ones produced with previous methods. Through human annotations and a user study, we further find that these learned explanations more closely align with how humans would explain the required decisions in these tasks. Our code is available at https://github.com/coderpat/learning-scaffold

</p>
</details>

<details><summary><b>Spacing Loss for Discovering Novel Categories</b>
<a href="https://arxiv.org/abs/2204.10595">arxiv:2204.10595</a>
&#x1F4C8; 5 <br>
<p>K J Joseph, Sujoy Paul, Gaurav Aggarwal, Soma Biswas, Piyush Rai, Kai Han, Vineeth N Balasubramanian</p></summary>
<p>

**Abstract:** Novel Class Discovery (NCD) is a learning paradigm, where a machine learning model is tasked to semantically group instances from unlabeled data, by utilizing labeled instances from a disjoint set of classes. In this work, we first characterize existing NCD approaches into single-stage and two-stage methods based on whether they require access to labeled and unlabeled data together while discovering new classes. Next, we devise a simple yet powerful loss function that enforces separability in the latent space using cues from multi-dimensional scaling, which we refer to as Spacing Loss. Our proposed formulation can either operate as a standalone method or can be plugged into existing methods to enhance them. We validate the efficacy of Spacing Loss with thorough experimental evaluation across multiple settings on CIFAR-10 and CIFAR-100 datasets.

</p>
</details>

<details><summary><b>Learning Functional Distributional Semantics with Visual Data</b>
<a href="https://arxiv.org/abs/2204.10624">arxiv:2204.10624</a>
&#x1F4C8; 4 <br>
<p>Yinhong Liu, Guy Emerson</p></summary>
<p>

**Abstract:** Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.

</p>
</details>

<details><summary><b>Modelling graph dynamics in fraud detection with "Attention"</b>
<a href="https://arxiv.org/abs/2204.10614">arxiv:2204.10614</a>
&#x1F4C8; 4 <br>
<p>Susie Xi Rao, Clémence Lanfranchi, Shuai Zhang, Zhichao Han, Zitao Zhang, Wei Min, Mo Cheng, Yinan Shan, Yang Zhao, Ce Zhang</p></summary>
<p>

**Abstract:** At online retail platforms, detecting fraudulent accounts and transactions is crucial to improve customer experience, minimize loss, and avoid unauthorized transactions. Despite the variety of different models for deep learning on graphs, few approaches have been proposed for dealing with graphs that are both heterogeneous and dynamic. In this paper, we propose DyHGN (Dynamic Heterogeneous Graph Neural Network) and its variants to capture both temporal and heterogeneous information. We first construct dynamic heterogeneous graphs from registration and transaction data from eBay. Then, we build models with diachronic entity embedding and heterogeneous graph transformer. We also use model explainability techniques to understand the behaviors of DyHGN-* models. Our findings reveal that modelling graph dynamics with heterogeneous inputs need to be conducted with "attention" depending on the data structure, distribution, and computation cost.

</p>
</details>

<details><summary><b>Depth Pruning with Auxiliary Networks for TinyML</b>
<a href="https://arxiv.org/abs/2204.10546">arxiv:2204.10546</a>
&#x1F4C8; 4 <br>
<p>Josen Daniel De Leon, Rowel Atienza</p></summary>
<p>

**Abstract:** Pruning is a neural network optimization technique that sacrifices accuracy in exchange for lower computational requirements. Pruning has been useful when working with extremely constrained environments in tinyML. Unfortunately, special hardware requirements and limited study on its effectiveness on already compact models prevent its wider adoption. Depth pruning is a form of pruning that requires no specialized hardware but suffers from a large accuracy falloff. To improve this, we propose a modification that utilizes a highly efficient auxiliary network as an effective interpreter of intermediate feature maps. Our results show a parameter reduction of 93% on the MLPerfTiny Visual Wakewords (VWW) task and 28% on the Keyword Spotting (KWS) task with accuracy cost of 0.65% and 1.06% respectively. When evaluated on a Cortex-M0 microcontroller, our proposed method reduces the VWW model size by 4.7x and latency by 1.6x while counter intuitively gaining 1% accuracy. KWS model size on Cortex-M0 was also reduced by 1.2x and latency by 1.2x at the cost of 2.21% accuracy.

</p>
</details>

<details><summary><b>Memory Bounds for Continual Learning</b>
<a href="https://arxiv.org/abs/2204.10830">arxiv:2204.10830</a>
&#x1F4C8; 3 <br>
<p>Xi Chen, Christos Papadimitriou, Binghui Peng</p></summary>
<p>

**Abstract:** Continual learning, or lifelong learning, is a formidable current challenge to machine learning. It requires the learner to solve a sequence of $k$ different learning tasks, one after the other, while retaining its aptitude for earlier tasks; the continual learner should scale better than the obvious solution of developing and maintaining a separate learner for each of the $k$ tasks. We embark on a complexity-theoretic study of continual learning in the PAC framework. We make novel uses of communication complexity to establish that any continual learner, even an improper one, needs memory that grows linearly with $k$, strongly suggesting that the problem is intractable. When logarithmically many passes over the learning tasks are allowed, we provide an algorithm based on multiplicative weights update whose memory requirement scales well; we also establish that improper learning is necessary for such performance. We conjecture that these results may lead to new promising approaches to continual learning.

</p>
</details>

<details><summary><b>The Boltzmann Policy Distribution: Accounting for Systematic Suboptimality in Human Models</b>
<a href="https://arxiv.org/abs/2204.10759">arxiv:2204.10759</a>
&#x1F4C8; 3 <br>
<p>Cassidy Laidlaw, Anca Dragan</p></summary>
<p>

**Abstract:** Models of human behavior for prediction and collaboration tend to fall into two categories: ones that learn from large amounts of data via imitation learning, and ones that assume human behavior to be noisily-optimal for some reward function. The former are very useful, but only when it is possible to gather a lot of human data in the target environment and distribution. The advantage of the latter type, which includes Boltzmann rationality, is the ability to make accurate predictions in new environments without extensive data when humans are actually close to optimal. However, these models fail when humans exhibit systematic suboptimality, i.e. when their deviations from optimal behavior are not independent, but instead consistent over time. Our key insight is that systematic suboptimality can be modeled by predicting policies, which couple action choices over time, instead of trajectories. We introduce the Boltzmann policy distribution (BPD), which serves as a prior over human policies and adapts via Bayesian inference to capture systematic deviations by observing human actions during a single episode. The BPD is difficult to compute and represent because policies lie in a high-dimensional continuous space, but we leverage tools from generative and sequence models to enable efficient sampling and inference. We show that the BPD enables prediction of human behavior and human-AI collaboration equally as well as imitation learning-based human models while using far less data.

</p>
</details>

<details><summary><b>Unknown Face Presentation Attack Detection via Localised Learning of Multiple Kernels</b>
<a href="https://arxiv.org/abs/2204.10675">arxiv:2204.10675</a>
&#x1F4C8; 3 <br>
<p>Shervin Rahimzadeh Arashloo</p></summary>
<p>

**Abstract:** The paper studies face spoofing, a.k.a. presentation attack detection (PAD) in the demanding scenarios of unknown types of attack. While earlier studies have revealed the benefits of ensemble methods, and in particular, a multiple kernel learning approach to the problem, one limitation of such techniques is that they typically treat the entire observation space similarly and ignore any variability and local structure inherent to the data. This work studies this aspect of the face presentation attack detection problem in relation to multiple kernel learning in a one-class setting to benefit from intrinsic local structure in bona fide face samples. More concretely, inspired by the success of the one-class Fisher null formalism, we formulate a convex localised multiple kernel learning algorithm by imposing a joint matrix-norm constraint on the collection of local kernel weights and infer locally adaptive weights for zero-shot one-class unseen attack detection.
  We present a theoretical study of the proposed localised MKL algorithm using Rademacher complexities to characterise its generalisation capability and demonstrate the advantages of the proposed technique over some other options. An assessment of the proposed approach on general object image datasets illustrates its efficacy for abnormality and novelty detection while the results of the experiments on face PAD datasets verifies its potential in detecting unknown/unseen face presentation attacks.

</p>
</details>

<details><summary><b>MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering</b>
<a href="https://arxiv.org/abs/2204.10629">arxiv:2204.10629</a>
&#x1F4C8; 3 <br>
<p>Viktoriia Chekalina, Anton Razzhigaev, Albert Sayapin, Alexander Panchenko</p></summary>
<p>

**Abstract:** Knowledge Graphs (KGs) are symbolically structured storages of facts. The KG embedding contains concise data used in NLP tasks requiring implicit information about the real world. Furthermore, the size of KGs that may be useful in actual NLP assignments is enormous, and creating embedding over it has memory cost issues. We represent KG as a 3rd-order binary tensor and move beyond the standard CP decomposition by using a data-specific generalized version of it. The generalization of the standard CP-ALS algorithm allows obtaining optimization gradients without a backpropagation mechanism. It reduces the memory needed in training while providing computational benefits. We propose a MEKER, a memory-efficient KG embedding model, which yields SOTA-comparable performance on link prediction tasks and KG-based Question Answering.

</p>
</details>

<details><summary><b>Balancing Expert Utilization in Mixture-of-Experts Layers Embedded in CNNs</b>
<a href="https://arxiv.org/abs/2204.10598">arxiv:2204.10598</a>
&#x1F4C8; 3 <br>
<p>Svetlana Pavlitskaya, Christian Hubschneider, Lukas Struppek, J. Marius Zöllner</p></summary>
<p>

**Abstract:** This work addresses the problem of unbalanced expert utilization in sparsely-gated Mixture of Expert (MoE) layers, embedded directly into convolutional neural networks. To enable a stable training process, we present both soft and hard constraint-based approaches. With hard constraints, the weights of certain experts are allowed to become zero, while soft constraints balance the contribution of experts with an additional auxiliary loss. As a result, soft constraints handle expert utilization better and support the expert specialization process, hard constraints mostly maintain generalized experts and increase the model performance for many applications. Our findings demonstrate that even with a single dataset and end-to-end training, experts can implicitly focus on individual sub-domains of the input space. Experts in the proposed models with MoE embeddings implicitly focus on distinct domains, even without suitable predefined datasets. As an example, experts trained for CIFAR-100 image classification specialize in recognizing different domains such as sea animals or flowers without previous data clustering. Experiments with RetinaNet and the COCO dataset further indicate that object detection experts can also specialize in detecting objects of distinct sizes.

</p>
</details>

<details><summary><b>SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues</b>
<a href="https://arxiv.org/abs/2204.10591">arxiv:2204.10591</a>
&#x1F4C8; 3 <br>
<p>Ssu Chiu, Maolin Li, Yen-Ting Lin, Yun-Nung Chen</p></summary>
<p>

**Abstract:** Dialogue systems are usually categorized into two types, open-domain and task-oriented. The first one focuses on chatting with users and making them engage in the conversations, where selecting a proper topic to fit the dialogue context is essential for a successful dialogue. The other one focuses on a specific task instead of casual talks, e.g., finding a movie on Friday night, or playing a song. These two directions have been studied separately due to their different purposes. However, how smoothly transitioning from social chatting to task-oriented dialogues is important for triggering business opportunities, and there is no public data focusing on such scenarios. Hence, this paper focuses on investigating the conversations starting from open-domain social chatting and then gradually transitioning to task-oriented purposes, and releases a large-scale dataset with detailed annotations for encouraging this research direction. To achieve this goal, this paper proposes a framework to automatically generate many dialogues without human involvement, in which any powerful open-domain dialogue generation model can be easily leveraged. The human evaluation shows that our generated dialogue data has a natural flow at a reasonable quality, showing that our released data has a great potential of guiding future research directions and commercial activities. Furthermore, the released models allow researchers to automatically generate unlimited dialogues in the target scenarios, which can greatly benefit semi-supervised and unsupervised approaches.

</p>
</details>

<details><summary><b>Alleviating Representational Shift for Continual Fine-tuning</b>
<a href="https://arxiv.org/abs/2204.10535">arxiv:2204.10535</a>
&#x1F4C8; 3 <br>
<p>Shibo Jie, Zhi-Hong Deng, Ziheng Li</p></summary>
<p>

**Abstract:** We study a practical setting of continual learning: fine-tuning on a pre-trained model continually. Previous work has found that, when training on new tasks, the features (penultimate layer representations) of previous data will change, called representational shift. Besides the shift of features, we reveal that the intermediate layers' representational shift (IRS) also matters since it disrupts batch normalization, which is another crucial cause of catastrophic forgetting. Motivated by this, we propose ConFiT, a fine-tuning method incorporating two components, cross-convolution batch normalization (Xconv BN) and hierarchical fine-tuning. Xconv BN maintains pre-convolution running means instead of post-convolution, and recovers post-convolution ones before testing, which corrects the inaccurate estimates of means under IRS. Hierarchical fine-tuning leverages a multi-stage strategy to fine-tune the pre-trained network, preventing massive changes in Conv layers and thus alleviating IRS. Experimental results on four datasets show that our method remarkably outperforms several state-of-the-art methods with lower storage overhead.

</p>
</details>

<details><summary><b>"Public(s)-in-the-Loop": Facilitating Deliberation of Algorithmic Decisions in Contentious Public Policy Domains</b>
<a href="https://arxiv.org/abs/2204.10814">arxiv:2204.10814</a>
&#x1F4C8; 2 <br>
<p>Hong Shen, Ángel Alexander Cabrera, Adam Perer, Jason Hong</p></summary>
<p>

**Abstract:** This position paper offers a framework to think about how to better involve human influence in algorithmic decision-making of contentious public policy issues. Drawing from insights in communication literature, we introduce a "public(s)-in-the-loop" approach and enumerates three features that are central to this approach: publics as plural political entities, collective decision-making through deliberation, and the construction of publics. It explores how these features might advance our understanding of stakeholder participation in AI design in contentious public policy domains such as recidivism prediction. Finally, it sketches out part of a research agenda for the HCI community to support this work.

</p>
</details>

<details><summary><b>On Feature Learning in Neural Networks with Global Convergence Guarantees</b>
<a href="https://arxiv.org/abs/2204.10782">arxiv:2204.10782</a>
&#x1F4C8; 2 <br>
<p>Zhengdao Chen, Eric Vanden-Eijnden, Joan Bruna</p></summary>
<p>

**Abstract:** We study the optimization of wide neural networks (NNs) via gradient flow (GF) in setups that allow feature learning while admitting non-asymptotic global convergence guarantees. First, for wide shallow NNs under the mean-field scaling and with a general class of activation functions, we prove that when the input dimension is no less than the size of the training set, the training loss converges to zero at a linear rate under GF. Building upon this analysis, we study a model of wide multi-layer NNs whose second-to-last layer is trained via GF, for which we also prove a linear-rate convergence of the training loss to zero, but regardless of the input dimension. We also show empirically that, unlike in the Neural Tangent Kernel (NTK) regime, our multi-layer model exhibits feature learning and can achieve better generalization performance than its NTK counterpart.

</p>
</details>

<details><summary><b>Tweets2Stance: Users stance detection exploiting Zero-Shot Learning Algorithms on Tweets</b>
<a href="https://arxiv.org/abs/2204.10710">arxiv:2204.10710</a>
&#x1F4C8; 2 <br>
<p>Margherita Gambini, Tiziano Fagni, Caterina Senette, Maurizio Tesconi</p></summary>
<p>

**Abstract:** In the last years there has been a growing attention towards predicting the political orientation of active social media users, being this of great help to study political forecasts, opinion dynamics modeling and users polarization. Existing approaches, mainly targeting Twitter users, rely on content-based analysis or are based on a mixture of content, network and communication analysis. The recent research perspective exploits the fact that a user's political affinity mainly depends on his/her positions on major political and social issues, thus shifting the focus on detecting the stance of users through user-generated content shared on social networks. The work herein described focuses on a completely unsupervised stance detection framework that predicts the user's stance about specific social-political statements by exploiting content-based analysis of its Twitter timeline. The ground-truth user's stance may come from Voting Advice Applications, online tools that help citizens to identify their political leanings by comparing their political preferences with party political stances. Starting from the knowledge of the agreement level of six parties on 20 different statements, the objective of the study is to predict the stance of a Party p in regard to each statement s exploiting what the Twitter Party account wrote on Twitter. To this end we propose Tweets2Stance (T2S), a novel and totally unsupervised stance detector framework which relies on the zero-shot learning technique to quickly and accurately operate on non-labeled data. Interestingly, T2S can be applied to any social media user for any context of interest, not limited to the political one. Results obtained from multiple experiments show that, although the general maximum F1 value is 0.4, T2S can correctly predict the stance with a general minimum MAE of 1.13, which is a great achievement considering the task complexity.

</p>
</details>

<details><summary><b>Paramixer: Parameterizing Mixing Links in Sparse Factors Works Better than Dot-Product Self-Attention</b>
<a href="https://arxiv.org/abs/2204.10670">arxiv:2204.10670</a>
&#x1F4C8; 2 <br>
<p>Tong Yu, Ruslan Khalitov, Lei Cheng, Zhirong Yang</p></summary>
<p>

**Abstract:** Self-Attention is a widely used building block in neural modeling to mix long-range data elements. Most self-attention neural networks employ pairwise dot-products to specify the attention coefficients. However, these methods require $O(N^2)$ computing cost for sequence length $N$. Even though some approximation methods have been introduced to relieve the quadratic cost, the performance of the dot-product approach is still bottlenecked by the low-rank constraint in the attention matrix factorization. In this paper, we propose a novel scalable and effective mixing building block called Paramixer. Our method factorizes the interaction matrix into several sparse matrices, where we parameterize the non-zero entries by MLPs with the data elements as input. The overall computing cost of the new building block is as low as $O(N \log N)$. Moreover, all factorizing matrices in Paramixer are full-rank, so it does not suffer from the low-rank bottleneck. We have tested the new method on both synthetic and various real-world long sequential data sets and compared it with several state-of-the-art attention networks. The experimental results show that Paramixer has better performance in most learning tasks.

</p>
</details>

<details><summary><b>Federated Learning via Inexact ADMM</b>
<a href="https://arxiv.org/abs/2204.10607">arxiv:2204.10607</a>
&#x1F4C8; 2 <br>
<p>Shenglong Zhou, Geoffrey Ye Li</p></summary>
<p>

**Abstract:** One of the crucial issues in federated learning is how to develop efficient optimization algorithms. Most of the current ones require full devices participation and/or impose strong assumptions for convergence. Different from the widely-used gradient descent-based algorithms, this paper develops an inexact alternating direction method of multipliers (ADMM), which is both computation and communication-efficient, capable of combating the stragglers' effect, and convergent under mild conditions.

</p>
</details>

<details><summary><b>Emergent Communication for Understanding Human Language Evolution: What's Missing?</b>
<a href="https://arxiv.org/abs/2204.10590">arxiv:2204.10590</a>
&#x1F4C8; 2 <br>
<p>Lukas Galke, Yoav Ram, Limor Raviv</p></summary>
<p>

**Abstract:** Emergent communication protocols among humans and artificial neural network agents do not yet share the same properties and show some critical mismatches in results. We describe three important phenomena with respect to the emergence and benefits of compositionality: ease-of-learning, generalization, and group size effects (i.e., larger groups create more systematic languages). The latter two are not fully replicated with neural agents, which hinders the use of neural emergent communication for language evolution research. We argue that one possible reason for these mismatches is that key cognitive and communicative constraints of humans are not yet integrated. Specifically, in humans, memory constraints and the alternation between the roles of speaker and listener underlie the emergence of linguistic structure, yet these constraints are typically absent in neural simulations. We suggest that introducing such communicative and cognitive constraints would promote more linguistically plausible behaviors with neural agents.

</p>
</details>

<details><summary><b>FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection</b>
<a href="https://arxiv.org/abs/2204.10581">arxiv:2204.10581</a>
&#x1F4C8; 2 <br>
<p>Tuan Truong, Matthias Lenga, Antoine Serrurier, Sadegh Mohammadi</p></summary>
<p>

**Abstract:** Audio-based classification techniques on body sounds have long been studied to support diagnostic decisions, particularly in pulmonary diseases. In response to the urgency of the COVID-19 pandemic, a growing number of models are developed to identify COVID-19 patients based on acoustic input. Most models focus on cough because the dry cough is the best-known symptom of COVID-19. However, other body sounds, such as breath and speech, have also been revealed to correlate with COVID-19 as well. In this work, rather than relying on a specific body sound, we propose Fused Audio Instance and Representation for COVID-19 Detection (FAIR4Cov). It relies on constructing a joint feature vector obtained from a plurality of body sounds in waveform and spectrogram representation. The core component of FAIR4Cov is a self-attention fusion unit that is trained to establish the relation of multiple body sounds and audio representations and integrate it into a compact feature vector. We set up our experiments on different combinations of body sounds using only waveform, spectrogram, and a joint representation of waveform and spectrogram. Our findings show that the use of self-attention to combine extracted features from cough, breath, and speech sounds leads to the best performance with an Area Under the Receiver Operating Characteristic Curve (AUC) score of 0.8658, a sensitivity of 0.8057, and a specificity of 0.7958. This AUC is 0.0227 higher than the one of the models trained on spectrograms only and 0.0847 higher than the one of the models trained on waveforms only. The results demonstrate that the combination of spectrogram with waveform representation helps to enrich the extracted features and outperforms the models with single representation.

</p>
</details>

<details><summary><b>A piece-wise constant approximation for non-conjugate Gaussian Process models</b>
<a href="https://arxiv.org/abs/2204.10575">arxiv:2204.10575</a>
&#x1F4C8; 2 <br>
<p>Sarem Seitz</p></summary>
<p>

**Abstract:** Gaussian Processes (GPs) are a versatile and popular method in Bayesian Machine Learning. A common modification are Sparse Variational Gaussian Processes (SVGPs) which are well suited to deal with large datasets. While GPs allow to elegantly deal with Gaussian-distributed target variables in closed form, their applicability can be extended to non-Gaussian data as well. These extensions are usually impossible to treat in closed form and hence require approximate solutions. This paper proposes to approximate the inverse-link function, which is necessary when working with non-Gaussian likelihoods, by a piece-wise constant function. It will be shown that this yields a closed form solution for the corresponding SVGP lower bound. In addition, it is demonstrated how the piece-wise constant function itself can be optimized, resulting in an inverse-link function that can be learnt from the data at hand.

</p>
</details>

<details><summary><b>Development of an algorithm for medical image segmentation of bone tissue in interaction with metallic implants</b>
<a href="https://arxiv.org/abs/2204.10560">arxiv:2204.10560</a>
&#x1F4C8; 2 <br>
<p>Fernando García-Torres, Carmen Mínguez-Porter, Julia Tomás-Chenoll, Sofía Iranzo-Egea, Juan-Manuel Belda-Lois</p></summary>
<p>

**Abstract:** This preliminary study focuses on the development of a medical image segmentation algorithm based on artificial intelligence for calculating bone growth in contact with metallic implants. %as a result of the problem of estimating the growth of new bone tissue due to artifacts. %the presence of various types of distortions and errors, known as artifacts.
  Two databases consisting of computerized microtomography images have been used throughout this work: 100 images for training and 196 images for testing. Both bone and implant tissue were manually segmented in the training data set. The type of network constructed follows the U-Net architecture, a convolutional neural network explicitly used for medical image segmentation.
  In terms of network accuracy, the model reached around 98\%. Once the prediction was obtained from the new data set (test set), the total number of pixels belonging to bone tissue was calculated. This volume is around 15\% of the volume estimated by conventional techniques, which are usually overestimated. This method has shown its good performance and results, although it has a wide margin for improvement, modifying various parameters of the networks or using larger databases to improve training.

</p>
</details>

<details><summary><b>Rethinking Offensive Text Detection as a Multi-Hop Reasoning Problem</b>
<a href="https://arxiv.org/abs/2204.10521">arxiv:2204.10521</a>
&#x1F4C8; 2 <br>
<p>Qiang Zhang, Jason Naradowsky, Yusuke Miyao</p></summary>
<p>

**Abstract:** We introduce the task of implicit offensive text detection in dialogues, where a statement may have either an offensive or non-offensive interpretation, depending on the listener and context. We argue that reasoning is crucial for understanding this broader class of offensive utterances and release SLIGHT, a dataset to support research on this task. Experiments using the data show that state-of-the-art methods of offense detection perform poorly when asked to detect implicitly offensive statements, achieving only ${\sim} 11\%$ accuracy.
  In contrast to existing offensive text detection datasets, SLIGHT features human-annotated chains of reasoning which describe the mental process by which an offensive interpretation can be reached from each ambiguous statement. We explore the potential for a multi-hop reasoning approach by utilizing existing entailment models to score the probability of these chains and show that even naive reasoning models can yield improved performance in most situations. Furthermore, analysis of the chains provides insight into the human interpretation process and emphasizes the importance of incorporating additional commonsense knowledge.

</p>
</details>

<details><summary><b>MIPR:Automatic Annotation of Medical Images with Pixel Rearrangement</b>
<a href="https://arxiv.org/abs/2204.10513">arxiv:2204.10513</a>
&#x1F4C8; 2 <br>
<p>Pingping Dai, Haiming Zhu, Shuang Ge, Ruihan Zhang, Xiang Qian, Xi Li, Kehong Yuan</p></summary>
<p>

**Abstract:** Most of the state-of-the-art semantic segmentation reported in recent years is based on fully supervised deep learning in the medical domain. How?ever, the high-quality annotated datasets require intense labor and domain knowledge, consuming enormous time and cost. Previous works that adopt semi?supervised and unsupervised learning are proposed to address the lack of anno?tated data through assisted training with unlabeled data and achieve good perfor?mance. Still, these methods can not directly get the image annotation as doctors do. In this paper, inspired by self-training of semi-supervised learning, we pro?pose a novel approach to solve the lack of annotated data from another angle, called medical image pixel rearrangement (short in MIPR). The MIPR combines image-editing and pseudo-label technology to obtain labeled data. As the number of iterations increases, the edited image is similar to the original image, and the labeled result is similar to the doctor annotation. Therefore, the MIPR is to get labeled pairs of data directly from amounts of unlabled data with pixel rearrange?ment, which is implemented with a designed conditional Generative Adversarial Networks and a segmentation network. Experiments on the ISIC18 show that the effect of the data annotated by our method for segmentation task is is equal to or even better than that of doctors annotations

</p>
</details>

<details><summary><b>MOLE: Digging Tunnels Through Multimodal Multi-Objective Landscapes</b>
<a href="https://arxiv.org/abs/2204.10848">arxiv:2204.10848</a>
&#x1F4C8; 1 <br>
<p>Lennart Schäpermeier, Christian Grimme, Pascal Kerschke</p></summary>
<p>

**Abstract:** Recent advances in the visualization of continuous multimodal multi-objective optimization (MMMOO) landscapes brought a new perspective to their search dynamics. Locally efficient (LE) sets, often considered as traps for local search, are rarely isolated in the decision space. Rather, intersections by superposing attraction basins lead to further solution sets that at least partially contain better solutions. The Multi-Objective Gradient Sliding Algorithm (MOGSA) is an algorithmic concept developed to exploit these superpositions. While it has promising performance on many MMMOO problems with linear LE sets, closer analysis of MOGSA revealed that it does not sufficiently generalize to a wider set of test problems. Based on a detailed analysis of shortcomings of MOGSA, we propose a new algorithm, the Multi-Objective Landscape Explorer (MOLE). It is able to efficiently model and exploit LE sets in MMMOO problems. An implementation of MOLE is presented for the bi-objective case, and the practicality of the approach is shown in a benchmarking experiment on the Bi-Objective BBOB testbed.

</p>
</details>

<details><summary><b>Detecting early signs of depression in the conversational domain: The role of transfer learning in low-resource scenarios</b>
<a href="https://arxiv.org/abs/2204.10841">arxiv:2204.10841</a>
&#x1F4C8; 1 <br>
<p>Petr Lorenc, Ana-Sabina Uban, Paolo Rosso, Jan Šedivý</p></summary>
<p>

**Abstract:** The high prevalence of depression in society has given rise to the need for new digital tools to assist in its early detection. To this end, existing research has mainly focused on detecting depression in the domain of social media, where there is a sufficient amount of data. However, with the rise of conversational agents like Siri or Alexa, the conversational domain is becoming more critical. Unfortunately, there is a lack of data in the conversational domain. We perform a study focusing on domain adaptation from social media to the conversational domain. Our approach mainly exploits the linguistic information preserved in the vector representation of text. We describe transfer learning techniques to classify users who suffer from early signs of depression with high recall. We achieve state-of-the-art results on a commonly used conversational dataset, and we highlight how the method can easily be used in conversational agents. We publicly release all source code.

</p>
</details>

<details><summary><b>Embracing AWKWARD! Real-time Adjustment of Reactive Planning Using Social Norms</b>
<a href="https://arxiv.org/abs/2204.10740">arxiv:2204.10740</a>
&#x1F4C8; 1 <br>
<p>Leila Methnani, Andreas Antoniades, Andreas Theodorou</p></summary>
<p>

**Abstract:** This paper presents the AWKWARD agent architecture for the development of agents in Multi-Agent Systems. AWKWARD agents can have their plans re-configured in real time to align with social role requirements under changing environmental and social circumstances. The proposed hybrid architecture makes use of Behaviour Oriented Design (BOD) to develop agents with reactive planning and of the well-established OperA framework to provide organisational, social, and interaction definitions in order to validate and adjust agents' behaviours. Together, OperA and BOD can achieve real-time adjustment of agent plans for evolving social roles, while providing the additional benefit of transparency into the interactions that drive this behavioural change in individual agents. We present this architecture to motivate the bridging between traditional symbolic- and behaviour-based AI communities, where such combined solutions can help MAS researchers in their pursuit of building stronger, more robust intelligent agent teams. We use DOTA2 -- a game where success is heavily dependent on social interactions -- as a medium to demonstrate a sample implementation of our proposed hybrid architecture

</p>
</details>

<details><summary><b>Revealing interactions between HVDC cross-area flows and frequency stability with explainable AI</b>
<a href="https://arxiv.org/abs/2204.10727">arxiv:2204.10727</a>
&#x1F4C8; 1 <br>
<p>Sebastian Pütz, Benjamin Schäfer, Dirk Witthaut, Johannes Kruse</p></summary>
<p>

**Abstract:** The energy transition introduces more volatile energy sources into the power grids. In this context, power transfer between different synchronous areas through High Voltage Direct Current (HVDC) links becomes increasingly important. Such links can balance volatile generation by enabling long-distance transport or by leveraging their fast control behavior. Here, we investigate the interaction of power imbalances - represented through the power grid frequency - and power flows on HVDC links between synchronous areas in Europe. We use explainable machine learning to identify key dependencies and disentangle the interaction of critical features. Our results show that market-based HVDC flows introduce deterministic frequency deviations, which however can be mitigated through strict ramping limits. Moreover, varying HVDC operation modes strongly affect the interaction with the grid. In particular, we show that load-frequency control via HVDC links can both have control-like or disturbance-like impacts on frequency stability.

</p>
</details>

<details><summary><b>3D pride without 2D prejudice: Bias-controlled multi-level generative models for structure-based ligand design</b>
<a href="https://arxiv.org/abs/2204.10663">arxiv:2204.10663</a>
&#x1F4C8; 1 <br>
<p>Lucian Chan, Rajendra Kumar, Marcel Verdonk, Carl Poelking</p></summary>
<p>

**Abstract:** Generative models for structure-based molecular design hold significant promise for drug discovery, with the potential to speed up the hit-to-lead development cycle, while improving the quality of drug candidates and reducing costs. Data sparsity and bias are, however, two main roadblocks to the development of 3D-aware models. Here we propose a first-in-kind training protocol based on multi-level contrastive learning for improved bias control and data efficiency. The framework leverages the large data resources available for 2D generative modelling with datasets of ligand-protein complexes. The result are hierarchical generative models that are topologically unbiased, explainable and customizable. We show how, by deconvolving the generative posterior into chemical, topological and structural context factors, we not only avoid common pitfalls in the design and evaluation of generative models, but furthermore gain detailed insight into the generative process itself. This improved transparency significantly aids method development, besides allowing fine-grained control over novelty vs familiarity.

</p>
</details>

<details><summary><b>Non-Uniformly Terminating Chase: Size and Complexity</b>
<a href="https://arxiv.org/abs/2204.10584">arxiv:2204.10584</a>
&#x1F4C8; 1 <br>
<p>Marco Calautti, Georg Gottlob, Andreas Pieris</p></summary>
<p>

**Abstract:** The chase procedure, originally introduced for checking implication of database constraints, and later on used for computing data exchange solutions, has recently become a central algorithmic tool in rule-based ontological reasoning. In this context, a key problem is non-uniform chase termination: does the chase of a database w.r.t. a rule-based ontology terminate? And if this is the case, what is the size of the result of the chase? We focus on guarded tuple-generating dependencies (TGDs), which form a robust rule-based ontology language, and study the above central questions for the semi-oblivious version of the chase. One of our main findings is that non-uniform semi-oblivious chase termination for guarded TGDs is feasible in polynomial time w.r.t. the database, and the size of the result of the chase (whenever is finite) is linear w.r.t. the database. Towards our results concerning non-uniform chase termination, we show that basic techniques such as simplification and linearization, originally introduced in the context of ontological query answering, can be safely applied to the chase termination problem.

</p>
</details>

<details><summary><b>Sparse and Dense Approaches for the Full-rank Retrieval of Responses for Dialogues</b>
<a href="https://arxiv.org/abs/2204.10558">arxiv:2204.10558</a>
&#x1F4C8; 1 <br>
<p>Gustavo Penha, Claudia Hauff</p></summary>
<p>

**Abstract:** Ranking responses for a given dialogue context is a popular benchmark in which the setup is to re-rank the ground-truth response over a limited set of $n$ responses, where $n$ is typically 10. The predominance of this setup in conversation response ranking has lead to a great deal of attention to building neural re-rankers, while the first-stage retrieval step has been overlooked. Since the correct answer is always available in the candidate list of $n$ responses, this artificial evaluation setup assumes that there is a first-stage retrieval step which is always able to rank the correct response in its top-$n$ list. In this paper we focus on the more realistic task of full-rank retrieval of responses, where $n$ can be up to millions of responses. We investigate both dialogue context and response expansion techniques for sparse retrieval, as well as zero-shot and fine-tuned dense retrieval approaches. Our findings based on three different information-seeking dialogue datasets reveal that a learned response expansion technique is a solid baseline for sparse retrieval. We find the best performing method overall to be dense retrieval with intermediate training, i.e. a step after the language model pre-training where sentence representations are learned, followed by fine-tuning on the target conversational data. We also investigate the intriguing phenomena that harder negatives sampling techniques lead to worse results for the fine-tuned dense retrieval models. The code and datasets are available at https://github.com/Guzpenha/transformer_rankers/tree/full_rank_retrieval_dialogues.

</p>
</details>

<details><summary><b>Exploring Hidden Semantics in Neural Networks with Symbolic Regression</b>
<a href="https://arxiv.org/abs/2204.10529">arxiv:2204.10529</a>
&#x1F4C8; 1 <br>
<p>Yuanzhen Luo, Qiang Lu, Xilei Hu, Jake Luo, Zhiguang Wang</p></summary>
<p>

**Abstract:** Many recent studies focus on developing mechanisms to explain the black-box behaviors of neural networks (NNs). However, little work has been done to extract the potential hidden semantics (mathematical representation) of a neural network. A succinct and explicit mathematical representation of a NN model could improve the understanding and interpretation of its behaviors. To address this need, we propose a novel symbolic regression method for neural works (called SRNet) to discover the mathematical expressions of a NN. SRNet creates a Cartesian genetic programming (NNCGP) to represent the hidden semantics of a single layer in a NN. It then leverages a multi-chromosome NNCGP to represent hidden semantics of all layers of the NN. The method uses a (1+$λ$) evolutionary strategy (called MNNCGP-ES) to extract the final mathematical expressions of all layers in the NN. Experiments on 12 symbolic regression benchmarks and 5 classification benchmarks show that SRNet not only can reveal the complex relationships between each layer of a NN but also can extract the mathematical representation of the whole NN. Compared with LIME and MAPLE, SRNet has higher interpolation accuracy and trends to approximate the real model on the practical dataset.

</p>
</details>

<details><summary><b>Taygete at SemEval-2022 Task 4: RoBERTa based models for detecting Patronising and Condescending Language</b>
<a href="https://arxiv.org/abs/2204.10519">arxiv:2204.10519</a>
&#x1F4C8; 1 <br>
<p>Jayant Chhillar</p></summary>
<p>

**Abstract:** This work describes the development of different models to detect patronising and condescending language within extracts of news articles as part of the SemEval 2022 competition (Task-4). This work explores different models based on the pre-trained RoBERTa language model coupled with LSTM and CNN layers. The best models achieved 15$^{th}$ rank with an F1-score of 0.5924 for subtask-A and 12$^{th}$ in subtask-B with a macro-F1 score of 0.3763.

</p>
</details>

<details><summary><b>Learning for Spatial Branching: An Algorithm Selection Approach</b>
<a href="https://arxiv.org/abs/2204.10834">arxiv:2204.10834</a>
&#x1F4C8; 0 <br>
<p>Bissan Ghaddar, Ignacio Gómez-Casares, Julio González-Díaz, Brais González-Rodríguez, Beatriz Pateiro-López, Sofía Rodríguez-Ballesteros</p></summary>
<p>

**Abstract:** The use of machine learning techniques to improve the performance of branch-and-bound optimization algorithms is a very active area in the context of mixed integer linear problems, but little has been done for non-linear optimization. To bridge this gap, we develop a learning framework for spatial branching and show its efficacy in the context of the Reformulation-Linearization Technique for polynomial optimization problems. The proposed learning is performed offline, based on instance-specific features and with no computational overhead when solving new instances. Novel graph-based features are introduced, which turn out to play an important role for the learning. Experiments on different benchmark instances from the literature show that the learning-based branching rule significantly outperforms the standard rules.

</p>
</details>

<details><summary><b>A Unifying Framework for Combining Complementary Strengths of Humans and ML toward Better Predictive Decision-Making</b>
<a href="https://arxiv.org/abs/2204.10806">arxiv:2204.10806</a>
&#x1F4C8; 0 <br>
<p>Charvi Rastogi, Liu Leqi, Kenneth Holstein, Hoda Heidari</p></summary>
<p>

**Abstract:** Hybrid human-ML systems are increasingly in charge of consequential decisions in a wide range of domains. A growing body of work has advanced our understanding of these systems by providing empirical and theoretical analyses. However, existing empirical results are mixed, and theoretical proposals are often incompatible with each other. Our goal in this work is to bring much-needed organization to this field by offering a unifying framework for understanding conditions under which combining complementary strengths of human and ML leads to higher quality decisions than those produced by them individually -- a state to which we refer to as human-ML complementarity. We focus specifically on the context of human-ML predictive decision-making systems and investigate optimal ways of combining human and ML-based predictive decisions, accounting for the underlying causes of variation in their judgments. Within this scope, we present two crucial contributions. First, drawing upon prior literature in human psychology, machine learning, and human-computer interaction, we introduce a taxonomy characterizing a wide variety of criteria across which human and machine decision-making differ. Building on our taxonomy, our second contribution presents a unifying optimization-based framework for formalizing how human and ML predictive decisions should be aggregated optimally. We show that our proposed framework encompasses several existing models of human-ML complementarity as special cases. Last but not least, the exploratory analysis of our framework offers a critical piece of insight for future work in this area: the mechanism by which we combine human-ML judgments should be informed by the underlying causes of their diverging decisions.

</p>
</details>

<details><summary><b>Constructing dynamic residential energy lifestyles using Latent Dirichlet Allocation</b>
<a href="https://arxiv.org/abs/2204.10770">arxiv:2204.10770</a>
&#x1F4C8; 0 <br>
<p>Xiao Chen, Chad Zanocco, June Flora, Ram Rajagopal</p></summary>
<p>

**Abstract:** The rapid expansion of Advanced Meter Infrastructure (AMI) has dramatically altered the energy information landscape. However, our ability to use this information to generate actionable insights about residential electricity demand remains limited. In this research, we propose and test a new framework for understanding residential electricity demand by using a dynamic energy lifestyles approach that is iterative and highly extensible. To obtain energy lifestyles, we develop a novel approach that applies Latent Dirichlet Allocation (LDA), a method commonly used for inferring the latent topical structure of text data, to extract a series of latent household energy attributes. By doing so, we provide a new perspective on household electricity consumption where each household is characterized by a mixture of energy attributes that form the building blocks for identifying a sparse collection of energy lifestyles. We examine this approach by running experiments on one year of hourly smart meter data from 60,000 households and we extract six energy attributes that describe general daily use patterns. We then use clustering techniques to derive six distinct energy lifestyle profiles from energy attribute proportions. Our lifestyle approach is also flexible to varying time interval lengths, and we test our lifestyle approach seasonally (Autumn, Winter, Spring, and Summer) to track energy lifestyle dynamics within and across households and find that around 73% of households manifest multiple lifestyles across a year. These energy lifestyles are then compared to different energy use characteristics, and we discuss their practical applications for demand response program design and lifestyle change analysis.

</p>
</details>

<details><summary><b>EmbedTrack -- Simultaneous Cell Segmentation and Tracking Through Learning Offsets and Clustering Bandwidths</b>
<a href="https://arxiv.org/abs/2204.10713">arxiv:2204.10713</a>
&#x1F4C8; 0 <br>
<p>Katharina Löffler, Ralf Mikut</p></summary>
<p>

**Abstract:** A systematic analysis of the cell behavior requires automated approaches for cell segmentation and tracking. While deep learning has been successfully applied for the task of cell segmentation, there are few approaches for simultaneous cell segmentation and tracking using deep learning. Here, we present EmbedTrack, a single convolutional neural network for simultaneous cell segmentation and tracking which predicts easy to interpret embeddings. As embeddings, offsets of cell pixels to their cell center and bandwidths are learned. We benchmark our approach on nine 2D data sets from the Cell Tracking Challenge, where our approach performs on seven out of nine data sets within the top 3 contestants including three top 1 performances. The source code is publicly available at https://git.scc.kit.edu/kit-loe-ge/embedtrack.

</p>
</details>

<details><summary><b>Fourier Imager Network (FIN): A deep neural network for hologram reconstruction with superior external generalization</b>
<a href="https://arxiv.org/abs/2204.10533">arxiv:2204.10533</a>
&#x1F4C8; 0 <br>
<p>Hanlong Chen, Luzhe Huang, Tairan Liu, Aydogan Ozcan</p></summary>
<p>

**Abstract:** Deep learning-based image reconstruction methods have achieved remarkable success in phase recovery and holographic imaging. However, the generalization of their image reconstruction performance to new types of samples never seen by the network remains a challenge. Here we introduce a deep learning framework, termed Fourier Imager Network (FIN), that can perform end-to-end phase recovery and image reconstruction from raw holograms of new types of samples, exhibiting unprecedented success in external generalization. FIN architecture is based on spatial Fourier transform modules that process the spatial frequencies of its inputs using learnable filters and a global receptive field. Compared with existing convolutional deep neural networks used for hologram reconstruction, FIN exhibits superior generalization to new types of samples, while also being much faster in its image inference speed, completing the hologram reconstruction task in ~0.04 s per 1 mm^2 of the sample area. We experimentally validated the performance of FIN by training it using human lung tissue samples and blindly testing it on human prostate, salivary gland tissue and Pap smear samples, proving its superior external generalization and image reconstruction speed. Beyond holographic microscopy and quantitative phase imaging, FIN and the underlying neural network architecture might open up various new opportunities to design broadly generalizable deep learning models in computational imaging and machine vision fields.

</p>
</details>


{% endraw %}
Prev: [2022.04.21]({{ '/2022/04/21/2022.04.21.html' | relative_url }})  Next: [2022.04.23]({{ '/2022/04/23/2022.04.23.html' | relative_url }})