Prev: [2022.09.07]({{ '/2022/09/07/2022.09.07.html' | relative_url }})  Next: [2022.09.09]({{ '/2022/09/09/2022.09.09.html' | relative_url }})
{% raw %}
## Summary for 2022-09-08, created on 2022-09-18


<details><summary><b>FAT Forensics: A Python Toolbox for Implementing and Deploying Fairness, Accountability and Transparency Algorithms in Predictive Systems</b>
<a href="https://arxiv.org/abs/2209.03805">arxiv:2209.03805</a>
&#x1F4C8; 100 <br>
<p>Kacper Sokol, Alexander Hepburn, Rafael Poyiadzi, Matthew Clifford, Raul Santos-Rodriguez, Peter Flach</p></summary>
<p>

**Abstract:** Predictive systems, in particular machine learning algorithms, can take important, and sometimes legally binding, decisions about our everyday life. In most cases, however, these systems and decisions are neither regulated nor certified. Given the potential harm that these algorithms can cause, their qualities such as fairness, accountability and transparency (FAT) are of paramount importance. To ensure high-quality, fair, transparent and reliable predictive systems, we developed an open source Python package called FAT Forensics. It can inspect important fairness, accountability and transparency aspects of predictive algorithms to automatically and objectively report them back to engineers and users of such systems. Our toolbox can evaluate all elements of a predictive pipeline: data (and their features), models and predictions. Published under the BSD 3-Clause open source licence, FAT Forensics is opened up for personal and commercial usage.

</p>
</details>

<details><summary><b>Text-Free Learning of a Natural Language Interface for Pretrained Face Generators</b>
<a href="https://arxiv.org/abs/2209.03953">arxiv:2209.03953</a>
&#x1F4C8; 76 <br>
<p>Xiaodan Du, Raymond A. Yeh, Nicholas Kolkin, Eli Shechtman, Greg Shakhnarovich</p></summary>
<p>

**Abstract:** We propose Fast text2StyleGAN, a natural language interface that adapts pre-trained GANs for text-guided human face synthesis. Leveraging the recent advances in Contrastive Language-Image Pre-training (CLIP), no text data is required during training. Fast text2StyleGAN is formulated as a conditional variational autoencoder (CVAE) that provides extra control and diversity to the generated images at test time. Our model does not require re-training or fine-tuning of the GANs or CLIP when encountering new text prompts. In contrast to prior work, we do not rely on optimization at test time, making our method orders of magnitude faster than prior work. Empirically, on FFHQ dataset, our method offers faster and more accurate generation of images from natural language descriptions with varying levels of detail compared to prior work.

</p>
</details>

<details><summary><b>Data Feedback Loops: Model-driven Amplification of Dataset Biases</b>
<a href="https://arxiv.org/abs/2209.03942">arxiv:2209.03942</a>
&#x1F4C8; 34 <br>
<p>Rohan Taori, Tatsunori B. Hashimoto</p></summary>
<p>

**Abstract:** Datasets scraped from the internet have been critical to the successes of large-scale machine learning. Yet, this very success puts the utility of future internet-derived datasets at potential risk, as model outputs begin to replace human annotations as a source of supervision.
  In this work, we first formalize a system where interactions with one model are recorded as history and scraped as training data in the future. We then analyze its stability over time by tracking changes to a test-time bias statistic (e.g. gender bias of model predictions). We find that the degree of bias amplification is closely linked to whether the model's outputs behave like samples from the training distribution, a behavior which we characterize and define as consistent calibration. Experiments in three conditional prediction scenarios - image classification, visual role-labeling, and language generation - demonstrate that models that exhibit a sampling-like behavior are more calibrated and thus more stable. Based on this insight, we propose an intervention to help calibrate and stabilize unstable feedback systems.
  Code is available at https://github.com/rtaori/data_feedback.

</p>
</details>

<details><summary><b>Clifford Neural Layers for PDE Modeling</b>
<a href="https://arxiv.org/abs/2209.04934">arxiv:2209.04934</a>
&#x1F4C8; 23 <br>
<p>Johannes Brandstetter, Rianne van den Berg, Max Welling, Jayesh K. Gupta</p></summary>
<p>

**Abstract:** Partial differential equations (PDEs) see widespread use in sciences and engineering to describe simulation of physical processes as scalar and vector fields interacting and coevolving over time. Due to the computationally expensive nature of their standard solution methods, neural PDE surrogates have become an active research topic to accelerate these simulations. However, current methods do not explicitly take into account the relationship between different fields and their internal components, which are often correlated. Viewing the time evolution of such correlated fields through the lens of multivector fields allows us to overcome these limitations. Multivector fields consist of scalar, vector, as well as higher-order components, such as bivectors and trivectors. Their algebraic properties, such as multiplication, addition and other arithmetic operations can be described by Clifford algebras. To our knowledge, this paper presents the first usage of such multivector representations together with Clifford convolutions and Clifford Fourier transforms in the context of deep learning. The resulting Clifford neural layers are universally applicable and will find direct use in the areas of fluid dynamics, weather forecasting, and the modeling of physical systems in general. We empirically evaluate the benefit of Clifford neural layers by replacing convolution and Fourier operations in common neural PDE surrogates by their Clifford counterparts on two-dimensional Navier-Stokes and weather modeling tasks, as well as three-dimensional Maxwell equations. Clifford neural layers consistently improve generalization capabilities of the tested neural PDE surrogates.

</p>
</details>

<details><summary><b>PixTrack: Precise 6DoF Object Pose Tracking using NeRF Templates and Feature-metric Alignment</b>
<a href="https://arxiv.org/abs/2209.03910">arxiv:2209.03910</a>
&#x1F4C8; 16 <br>
<p>Prajwal Chidananda, Saurabh Nair, Douglas Lee, Adrian Kaehler</p></summary>
<p>

**Abstract:** We present PixTrack, a vision based object pose tracking framework using novel view synthesis and deep feature-metric alignment. Our evaluations demonstrate that our method produces highly accurate, robust, and jitter-free 6DoF pose estimates of objects in RGB images without the need of any data annotation or trajectory smoothing. Our method is also computationally efficient making it easy to have multi-object tracking with no alteration to our method and just using CPU multiprocessing.

</p>
</details>

<details><summary><b>W-Transformers : A Wavelet-based Transformer Framework for Univariate Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2209.03945">arxiv:2209.03945</a>
&#x1F4C8; 10 <br>
<p>Lena Sasal, Tanujit Chakraborty, Abdenour Hadid</p></summary>
<p>

**Abstract:** Deep learning utilizing transformers has recently achieved a lot of success in many vital areas such as natural language processing, computer vision, anomaly detection, and recommendation systems, among many others. Among several merits of transformers, the ability to capture long-range temporal dependencies and interactions is desirable for time series forecasting, leading to its progress in various time series applications. In this paper, we build a transformer model for non-stationary time series. The problem is challenging yet crucially important. We present a novel framework for univariate time series representation learning based on the wavelet-based transformer encoder architecture and call it W-Transformer. The proposed W-Transformers utilize a maximal overlap discrete wavelet transformation (MODWT) to the time series data and build local transformers on the decomposed datasets to vividly capture the nonstationarity and long-range nonlinear dependencies in the time series. Evaluating our framework on several publicly available benchmark time series datasets from various domains and with diverse characteristics, we demonstrate that it performs, on average, significantly better than the baseline forecasters for short-term and long-term forecasting, even for datasets that consist of only a few hundred training samples.

</p>
</details>

<details><summary><b>What and How of Machine Learning Transparency: Building Bespoke Explainability Tools with Interoperable Algorithmic Components</b>
<a href="https://arxiv.org/abs/2209.03813">arxiv:2209.03813</a>
&#x1F4C8; 10 <br>
<p>Kacper Sokol, Alexander Hepburn, Raul Santos-Rodriguez, Peter Flach</p></summary>
<p>

**Abstract:** Explainability techniques for data-driven predictive models based on artificial intelligence and machine learning algorithms allow us to better understand the operation of such systems and help to hold them accountable. New transparency approaches are developed at breakneck speed, enabling us to peek inside these black boxes and interpret their decisions. Many of these techniques are introduced as monolithic tools, giving the impression of one-size-fits-all and end-to-end algorithms with limited customisability. Nevertheless, such approaches are often composed of multiple interchangeable modules that need to be tuned to the problem at hand to produce meaningful explanations. This paper introduces a collection of hands-on training materials -- slides, video recordings and Jupyter Notebooks -- that provide guidance through the process of building and evaluating bespoke modular surrogate explainers for tabular data. These resources cover the three core building blocks of this technique: interpretable representation composition, data sampling and explanation generation.

</p>
</details>

<details><summary><b>IDIAPers @ Causal News Corpus 2022: Efficient Causal Relation Identification Through a Prompt-based Few-shot Approach</b>
<a href="https://arxiv.org/abs/2209.03895">arxiv:2209.03895</a>
&#x1F4C8; 9 <br>
<p>Sergio Burdisso, Juan Zuluaga-Gomez, Esau Villatoro-Tello, Martin Fajcik, Muskaan Singh, Pavel Smrz, Petr Motlicek</p></summary>
<p>

**Abstract:** In this paper, we describe our participation in the subtask 1 of CASE-2022, Event Causality Identification with Casual News Corpus. We address the Causal Relation Identification (CRI) task by exploiting a set of simple yet complementary techniques for fine-tuning language models (LMs) on a small number of annotated examples (i.e., a few-shot configuration). We follow a prompt-based prediction approach for fine-tuning LMs in which the CRI task is treated as a masked language modeling problem (MLM). This approach allows LMs natively pre-trained on MLM problems to directly generate textual responses to CRI-specific prompts. We compare the performance of this method against ensemble techniques trained on the entire dataset. Our best-performing submission was trained only with 256 instances per class, a small portion of the entire dataset, and yet was able to obtain the second-best precision (0.82), third-best accuracy (0.82), and an F1-score (0.85) very close to what was reported by the winner team (0.86).

</p>
</details>

<details><summary><b>IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model</b>
<a href="https://arxiv.org/abs/2209.03891">arxiv:2209.03891</a>
&#x1F4C8; 9 <br>
<p>Martin Fajcik, Muskaan Singh, Juan Zuluaga-Gomez, Esaú Villatoro-Tello, Sergio Burdisso, Petr Motlicek, Pavel Smrz</p></summary>
<p>

**Abstract:** In this paper, we describe our shared task submissions for Subtask 2 in CASE-2022, Event Causality Identification with Casual News Corpus. The challenge focused on the automatic detection of all cause-effect-signal spans present in the sentence from news-media. We detect cause-effect-signal spans in a sentence using T5 -- a pre-trained autoregressive language model. We iteratively identify all cause-effect-signal span triplets, always conditioning the prediction of the next triplet on the previously predicted ones. To predict the triplet itself, we consider different causal relationships such as cause$\rightarrow$effect$\rightarrow$signal. Each triplet component is generated via a language model conditioned on the sentence, the previous parts of the current triplet, and previously predicted triplets. Despite training on an extremely small dataset of 160 samples, our approach achieved competitive performance, being placed second in the competition. Furthermore, we show that assuming either cause$\rightarrow$effect or effect$\rightarrow$cause order achieves similar results. Our code and model predictions will be released online.

</p>
</details>

<details><summary><b>Histogram Layers for Synthetic Aperture Sonar Imagery</b>
<a href="https://arxiv.org/abs/2209.03878">arxiv:2209.03878</a>
&#x1F4C8; 9 <br>
<p>Joshua Peeples, Alina Zare, Jeffrey Dale, James Keller</p></summary>
<p>

**Abstract:** Synthetic aperture sonar (SAS) imagery is crucial for several applications, including target recognition and environmental segmentation. Deep learning models have led to much success in SAS analysis; however, the features extracted by these approaches may not be suitable for capturing certain textural information. To address this problem, we present a novel application of histogram layers on SAS imagery. The addition of histogram layer(s) within the deep learning models improved performance by incorporating statistical texture information on both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Tuning arrays with rays: Physics-informed tuning of quantum dot charge states</b>
<a href="https://arxiv.org/abs/2209.03837">arxiv:2209.03837</a>
&#x1F4C8; 9 <br>
<p>Joshua Ziegler, Florian Luthi, Mick Ramsey, Felix Borjans, Guoji Zheng, Justyna P. Zwolak</p></summary>
<p>

**Abstract:** Quantum computers based on gate-defined quantum dots (QDs) are expected to scale. However, as the number of qubits increases, the burden of manually calibrating these systems becomes unreasonable and autonomous tuning must be used. There have been a range of recent demonstrations of automated tuning of various QD parameters such as coarse gate ranges, global state topology (e.g. single QD, double QD), charge, and tunnel coupling with a variety of methods. Here, we demonstrate an intuitive, reliable, and data-efficient set of tools for automated global state and charge tuning in a framework deemed physics-informed tuning (PIT). The first module of PIT is an action-based algorithm that combines a machine learning (ML) classifier with physics knowledge to navigate to a target global state. The second module uses a series of one-dimensional measurements to tune to a target charge state by first emptying the QDs of charge, followed by calibrating capacitive couplings, and navigating to the target charge state. The success rate for the action-based tuning consistently surpasses $95~\%$ on both simulated and experimental data suitable for off-line testing. The success rate for charge setting is comparable when testing with simulated data, at $95.5(5.4)~\%$, and only slightly worse for off-line experimental tests, with an average of $89.7(17.4)~\%$ (median $97.5~\%$). It's noteworthy that the high performance is demonstrated both on data from samples fabricated in an academic cleanroom as well as on an industrial 300 mm process line, further underlining the device-agnosticity of PIT. Together, these tests on a range of simulated and experimental devices demonstrate the effectiveness and robustness of PIT.

</p>
</details>

<details><summary><b>Lightweight Long-Range Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2209.03793">arxiv:2209.03793</a>
&#x1F4C8; 9 <br>
<p>Bowen Li, Thomas Lukasiewicz</p></summary>
<p>

**Abstract:** In this paper, we introduce novel lightweight generative adversarial networks, which can effectively capture long-range dependencies in the image generation process, and produce high-quality results with a much simpler architecture. To achieve this, we first introduce a long-range module, allowing the network to dynamically adjust the number of focused sampling pixels and to also augment sampling locations. Thus, it can break the limitation of the fixed geometric structure of the convolution operator, and capture long-range dependencies in both spatial and channel-wise directions. Also, the proposed long-range module can highlight negative relations between pixels, working as a regularization to stabilize training. Furthermore, we propose a new generation strategy through which we introduce metadata into the image generation process to provide basic information about target images, which can stabilize and speed up the training process. Our novel long-range module only introduces few additional parameters and is easily inserted into existing models to capture long-range dependencies. Extensive experiments demonstrate the competitive performance of our method with a lightweight architecture.

</p>
</details>

<details><summary><b>Aerial View Goal Localization with Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.03694">arxiv:2209.03694</a>
&#x1F4C8; 9 <br>
<p>Aleksis Pirinen, Anton Samuelsson, John Backsund, Kalle Åström</p></summary>
<p>

**Abstract:** With an increased amount and availability of unmanned aerial vehicles (UAVs) and other remote sensing devices (e.g. satellites), we have recently seen a vast increase in computer vision methods for aerial view data. One application of such technologies is within search-and-rescue (SAR), where the task is to localize and assist one or several people who are missing, for example after a natural disaster. In many cases the rough location may be known and a UAV can be deployed to explore a given, confined area to precisely localize the missing people. Due to time and battery constraints it is often critical that localization is performed as efficiently as possible. In this work, we approach this type of problem by abstracting it as an aerial view goal localization task in a framework that emulates a SAR-like setup without requiring access to actual UAVs. In this framework, an agent operates on top of an aerial image (proxy for a search area) and is tasked with localizing a goal that is described in terms of visual cues. To further mimic the situation on an actual UAV, the agent is not able to observe the search area in its entirety, not even at low resolution, and thus it has to operate solely based on partial glimpses when navigating towards the goal. To tackle this task, we propose AiRLoc, a reinforcement learning (RL)-based model that decouples exploration (searching for distant goals) and exploitation (localizing nearby goals). Extensive evaluations show that AiRLoc outperforms heuristic search methods as well as alternative learnable approaches. We also conduct a proof-of-concept study which indicates that the learnable methods outperform humans on average. Code has been made publicly available: https://github.com/aleksispi/airloc.

</p>
</details>

<details><summary><b>Joint Alignment of Multi-Task Feature and Label Spaces for Emotion Cause Pair Extraction</b>
<a href="https://arxiv.org/abs/2209.04112">arxiv:2209.04112</a>
&#x1F4C8; 8 <br>
<p>Shunjie Chen, Xiaochuan Shi, Jingye Li, Shengqiong Wu, Hao Fei, Fei Li, Donghong Ji</p></summary>
<p>

**Abstract:** Emotion cause pair extraction (ECPE), as one of the derived subtasks of emotion cause analysis (ECA), shares rich inter-related features with emotion extraction (EE) and cause extraction (CE). Therefore EE and CE are frequently utilized as auxiliary tasks for better feature learning, modeled via multi-task learning (MTL) framework by prior works to achieve state-of-the-art (SoTA) ECPE results. However, existing MTL-based methods either fail to simultaneously model the specific features and the interactive feature in between, or suffer from the inconsistency of label prediction. In this work, we consider addressing the above challenges for improving ECPE by performing two alignment mechanisms with a novel A^2Net model. We first propose a feature-task alignment to explicitly model the specific emotion-&cause-specific features and the shared interactive feature. Besides, an inter-task alignment is implemented, in which the label distance between the ECPE and the combinations of EE&CE are learned to be narrowed for better label consistency. Evaluations of benchmarks show that our methods outperform current best-performing systems on all ECA subtasks. Further analysis proves the importance of our proposed alignment mechanisms for the task.

</p>
</details>

<details><summary><b>MATT: A Multiple-instance Attention Mechanism for Long-tail Music Genre Classification</b>
<a href="https://arxiv.org/abs/2209.04109">arxiv:2209.04109</a>
&#x1F4C8; 8 <br>
<p>Xiaokai Liu, Menghua Zhang</p></summary>
<p>

**Abstract:** Imbalanced music genre classification is a crucial task in the Music Information Retrieval (MIR) field for identifying the long-tail, data-poor genre based on the related music audio segments, which is very prevalent in real-world scenarios. Most of the existing models are designed for class-balanced music datasets, resulting in poor performance in accuracy and generalization when identifying the music genres at the tail of the distribution. Inspired by the success of introducing Multi-instance Learning (MIL) in various classification tasks, we propose a novel mechanism named Multi-instance Attention (MATT) to boost the performance for identifying tail classes. Specifically, we first construct the bag-level datasets by generating the album-artist pair bags. Second, we leverage neural networks to encode the music audio segments. Finally, under the guidance of a multi-instance attention mechanism, the neural network-based models could select the most informative genre to match the given music segment. Comprehensive experimental results on a large-scale music genre benchmark dataset with long-tail distribution demonstrate MATT significantly outperforms other state-of-the-art baselines.

</p>
</details>

<details><summary><b>Online Low Rank Matrix Completion</b>
<a href="https://arxiv.org/abs/2209.03997">arxiv:2209.03997</a>
&#x1F4C8; 8 <br>
<p>Prateek Jain, Soumyabrata Pal</p></summary>
<p>

**Abstract:** We study the problem of \textit{online} low-rank matrix completion with $\mathsf{M}$ users, $\mathsf{N}$ items and $\mathsf{T}$ rounds. In each round, we recommend one item per user. For each recommendation, we obtain a (noisy) reward sampled from a low-rank user-item reward matrix. The goal is to design an online method with sub-linear regret (in $\mathsf{T}$). While the problem can be mapped to the standard multi-armed bandit problem where each item is an \textit{independent} arm, it leads to poor regret as the correlation between arms and users is not exploited. In contrast, exploiting the low-rank structure of reward matrix is challenging due to non-convexity of low-rank manifold. We overcome this challenge using an explore-then-commit (ETC) approach that ensures a regret of $O(\mathsf{polylog} (\mathsf{M}+\mathsf{N}) \mathsf{T}^{2/3})$. That is, roughly only $\mathsf{polylog} (\mathsf{M}+\mathsf{N})$ item recommendations are required per user to get non-trivial solution. We further improve our result for the rank-$1$ setting. Here, we propose a novel algorithm OCTAL (Online Collaborative filTering using iterAtive user cLustering) that ensures nearly optimal regret bound of $O(\mathsf{polylog} (\mathsf{M}+\mathsf{N}) \mathsf{T}^{1/2})$. Our algorithm uses a novel technique of clustering users and eliminating items jointly and iteratively, which allows us to obtain nearly minimax optimal rate in $\mathsf{T}$.

</p>
</details>

<details><summary><b>Simpler is better: Multilevel Abstraction with Graph Convolutional Recurrent Neural Network Cells for Traffic Prediction</b>
<a href="https://arxiv.org/abs/2209.03858">arxiv:2209.03858</a>
&#x1F4C8; 8 <br>
<p>Naghmeh Shafiee Roudbari, Zachary Patterson, Ursula Eicker, Charalambos Poullis</p></summary>
<p>

**Abstract:** In recent years, graph neural networks (GNNs) combined with variants of recurrent neural networks (RNNs) have reached state-of-the-art performance in spatiotemporal forecasting tasks. This is particularly the case for traffic forecasting, where GNN models use the graph structure of road networks to account for spatial correlation between links and nodes. Recent solutions are either based on complex graph operations or avoiding predefined graphs. This paper proposes a new sequence-to-sequence architecture to extract the spatiotemporal correlation at multiple levels of abstraction using GNN-RNN cells with sparse architecture to decrease training time compared to more complex designs. Encoding the same input sequence through multiple encoders, with an incremental increase in encoder layers, enables the network to learn general and detailed information through multilevel abstraction. We further present a new benchmark dataset of street-level segment traffic data from Montreal, Canada. Unlike highways, urban road segments are cyclic and characterized by complicated spatial dependencies. Experimental results on the METR-LA benchmark highway and our MSLTD street-level segment datasets demonstrate that our model improves performance by more than 7% for one-hour prediction compared to the baseline methods while reducing computing resource requirements by more than half compared to other competing methods.

</p>
</details>

<details><summary><b>Applying Transformer-based Text Summarization for Keyphrase Generation</b>
<a href="https://arxiv.org/abs/2209.03791">arxiv:2209.03791</a>
&#x1F4C8; 8 <br>
<p>Anna Glazkova, Dmitry Morozov</p></summary>
<p>

**Abstract:** Keyphrases are crucial for searching and systematizing scholarly documents. Most current methods for keyphrase extraction are aimed at the extraction of the most significant words in the text. But in practice, the list of keyphrases often includes words that do not appear in the text explicitly. In this case, the list of keyphrases represents an abstractive summary of the source text. In this paper, we experiment with popular transformer-based models for abstractive text summarization using four benchmark datasets for keyphrase extraction. We compare the results obtained with the results of common unsupervised and supervised methods for keyphrase extraction. Our evaluation shows that summarization models are quite effective in generating keyphrases in the terms of the full-match F1-score and BERTScore. However, they produce a lot of words that are absent in the author's list of keyphrases, which makes summarization models ineffective in terms of ROUGE-1. We also investigate several ordering strategies to concatenate target keyphrases. The results showed that the choice of strategy affects the performance of keyphrase generation.

</p>
</details>

<details><summary><b>DIY-IPS: Towards an Off-the-Shelf Accurate Indoor Positioning System</b>
<a href="https://arxiv.org/abs/2209.03613">arxiv:2209.03613</a>
&#x1F4C8; 8 <br>
<p>Riccardo Menon, Abdallah Lakhdari, Amani Abusafia, Qijun He, Athman Bouguettaya</p></summary>
<p>

**Abstract:** We present DIY-IPS - Do It Yourself - Indoor Positioning System, an open-source real-time indoor positioning mobile application. DIY-IPS detects users' indoor position by employing dual-band RSSI fingerprinting of available WiFi access points. The app can be used, without additional infrastructural costs, to detect users' indoor positions in real time. We published our app as an open source to save other researchers time recreating it. The app enables researchers/users to (1) collect indoor positioning datasets with a ground truth label, (2) customize the app for higher accuracy or other research purposes (3) test the accuracy of modified methods by live testing with ground truth. We ran preliminary experiments to demonstrate the effectiveness of the app.

</p>
</details>

<details><summary><b>Improving the Environmental Perception of Autonomous Vehicles using Deep Learning-based Audio Classification</b>
<a href="https://arxiv.org/abs/2209.04075">arxiv:2209.04075</a>
&#x1F4C8; 7 <br>
<p>Finley Walden, Sagar Dasgupta, Mizanur Rahman, Mhafuzul Islam</p></summary>
<p>

**Abstract:** Sense of hearing is crucial for autonomous vehicles (AVs) to better perceive its surrounding environment. Although visual sensors of an AV, such as camera, lidar, and radar, help to see its surrounding environment, an AV cannot see beyond those sensors line of sight. On the other hand, an AV s sense of hearing cannot be obstructed by line of sight. For example, an AV can identify an emergency vehicle s siren through audio classification even though the emergency vehicle is not within the line of sight of the AV. Thus, auditory perception is complementary to the camera, lidar, and radar-based perception systems. This paper presents a deep learning-based robust audio classification framework aiming to achieve improved environmental perception for AVs. The presented framework leverages a deep Convolution Neural Network (CNN) to classify different audio classes. UrbanSound8k, an urban environment dataset, is used to train and test the developed framework. Seven audio classes i.e., air conditioner, car horn, children playing, dog bark, engine idling, gunshot, and siren, are identified from the UrbanSound8k dataset because of their relevancy related to AVs. Our framework can classify different audio classes with 97.82% accuracy. Moreover, the audio classification accuracies with all ten classes are presented, which proves that our framework performed better in the case of AV-related sounds compared to the existing audio classification frameworks.

</p>
</details>

<details><summary><b>A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans</b>
<a href="https://arxiv.org/abs/2209.03918">arxiv:2209.03918</a>
&#x1F4C8; 7 <br>
<p>ZeYu Liu, Yi Wang, Jing Wen, Yong Zhang, Hao Yin, Chao Guo, ZhongYu Wang</p></summary>
<p>

**Abstract:** This is the technical report of the 9th place in the final result of PARSE2022 Challenge. We solve the segmentation problem of the pulmonary artery by using a two-stage method based on a 3D CNN network. The coarse model is used to locate the ROI, and the fine model is used to refine the segmentation result. In addition, in order to improve the segmentation performance, we adopt multi-view and multi-window level method, at the same time we employ a fine-tune strategy to mitigate the impact of inconsistent labeling.

</p>
</details>

<details><summary><b>Ethical and Social Considerations in Automatic Expert Identification and People Recommendation in Organizational Knowledge Management Systems</b>
<a href="https://arxiv.org/abs/2209.03819">arxiv:2209.03819</a>
&#x1F4C8; 6 <br>
<p>Ida Larsen-Ledet, Bhaskar Mitra, Siân Lindley</p></summary>
<p>

**Abstract:** Organizational knowledge bases are moving from passive archives to active entities in the flow of people's work. We are seeing machine learning used to enable systems that both collect and surface information as people are working, making it possible to bring out connections between people and content that were previously much less visible in order to automatically identify and highlight experts on a given topic. When these knowledge bases begin to actively bring attention to people and the content they work on, especially as that work is still ongoing, we run into important challenges at the intersection of work and the social. While such systems have the potential to make certain parts of people's work more productive or enjoyable, they may also introduce new workloads, for instance by putting people in the role of experts for others to reach out to. And these knowledge bases can also have profound social consequences by changing what parts of work are visible and, therefore, acknowledged. We pose a number of open questions that warrant attention and engagement across industry and academia. Addressing these questions is an essential step in ensuring that the future of work becomes a good future for those doing the work. With this position paper, we wish to enter into the cross-disciplinary discussion we believe is required to tackle the challenge of developing recommender systems that respect social values.

</p>
</details>

<details><summary><b>Towards explainable evaluation of language models on the semantic similarity of visual concepts</b>
<a href="https://arxiv.org/abs/2209.03723">arxiv:2209.03723</a>
&#x1F4C8; 6 <br>
<p>Maria Lymperaiou, George Manoliadis, Orfeas Menis Mastromichalakis, Edmund G. Dervakos, Giorgos Stamou</p></summary>
<p>

**Abstract:** Recent breakthroughs in NLP research, such as the advent of Transformer models have indisputably contributed to major advancements in several tasks. However, few works research robustness and explainability issues of their evaluation strategies. In this work, we examine the behavior of high-performing pre-trained language models, focusing on the task of semantic similarity for visual vocabularies. First, we address the need for explainable evaluation metrics, necessary for understanding the conceptual quality of retrieved instances. Our proposed metrics provide valuable insights in local and global level, showcasing the inabilities of widely used approaches. Secondly, adversarial interventions on salient query semantics expose vulnerabilities of opaque metrics and highlight patterns in learned linguistic representations.

</p>
</details>

<details><summary><b>Generalized One-shot Domain Adaption of Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2209.03665">arxiv:2209.03665</a>
&#x1F4C8; 6 <br>
<p>Zicheng Zhang, Yinglu Liu, Congying Han, Tiande Guo, Ting Yao, Tao Mei</p></summary>
<p>

**Abstract:** The adaption of Generative Adversarial Network (GAN) aims to transfer a pre-trained GAN to a given domain with limited training data. In this paper, we focus on the one-shot case, which is more challenging and rarely explored in previous works. We consider that the adaptation from source domain to target domain can be decoupled into two parts: the transfer of global style like texture and color, and the emergence of new entities that do not belong to the source domain. While previous works mainly focus on the style transfer, we propose a novel and concise framework\footnote{\url{https://github.com/thevoidname/Generalized-One-shot-GAN-Adaption}} to address the \textit{generalized one-shot adaption} task for both style and entity transfer, in which a reference image and its binary entity mask are provided. Our core objective is to constrain the gap between the internal distributions of the reference and syntheses by sliced Wasserstein distance. To better achieve it, style fixation is used at first to roughly obtain the exemplary style, and an auxiliary network is introduced to the original generator to disentangle entity and style transfer. Besides, to realize cross-domain correspondence, we propose the variational Laplacian regularization to constrain the smoothness of the adapted generator. Both quantitative and qualitative experiments demonstrate the effectiveness of our method in various scenarios.

</p>
</details>

<details><summary><b>Application of image-to-image translation in improving pedestrian detection</b>
<a href="https://arxiv.org/abs/2209.03625">arxiv:2209.03625</a>
&#x1F4C8; 6 <br>
<p>Devarsh Patel, Sarthak Patel, Megh Patel</p></summary>
<p>

**Abstract:** The lack of effective target regions makes it difficult to perform several visual functions in low intensity light, including pedestrian recognition, and image-to-image translation. In this situation, with the accumulation of high-quality information by the combined use of infrared and visible images it is possible to detect pedestrians even in low light. In this study we are going to use advanced deep learning models like pix2pixGAN and YOLOv7 on LLVIP dataset, containing visible-infrared image pairs for low light vision. This dataset contains 33672 images and most of the images were captured in dark scenes, tightly synchronized with time and location.

</p>
</details>

<details><summary><b>Robust and Lossless Fingerprinting of Deep Neural Networks via Pooled Membership Inference</b>
<a href="https://arxiv.org/abs/2209.04113">arxiv:2209.04113</a>
&#x1F4C8; 5 <br>
<p>Hanzhou Wu</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) have already achieved great success in a lot of application areas and brought profound changes to our society. However, it also raises new security problems, among which how to protect the intellectual property (IP) of DNNs against infringement is one of the most important yet very challenging topics. To deal with this problem, recent studies focus on the IP protection of DNNs by applying digital watermarking, which embeds source information and/or authentication data into DNN models by tuning network parameters directly or indirectly. However, tuning network parameters inevitably distorts the DNN and therefore surely impairs the performance of the DNN model on its original task regardless of the degree of the performance degradation. It has motivated the authors in this paper to propose a novel technique called \emph{pooled membership inference (PMI)} so as to protect the IP of the DNN models. The proposed PMI neither alters the network parameters of the given DNN model nor fine-tunes the DNN model with a sequence of carefully crafted trigger samples. Instead, it leaves the original DNN model unchanged, but can determine the ownership of the DNN model by inferring which mini-dataset among multiple mini-datasets was once used to train the target DNN model, which differs from previous arts and has remarkable potential in practice. Experiments also have demonstrated the superiority and applicability of this work.

</p>
</details>

<details><summary><b>Transformer-based classification of premise in tweets related to COVID-19</b>
<a href="https://arxiv.org/abs/2209.03851">arxiv:2209.03851</a>
&#x1F4C8; 5 <br>
<p>Vadim Porvatov, Natalia Semenova</p></summary>
<p>

**Abstract:** Automation of social network data assessment is one of the classic challenges of natural language processing. During the COVID-19 pandemic, mining people's stances from public messages have become crucial regarding understanding attitudes towards health orders. In this paper, the authors propose the predictive model based on transformer architecture to classify the presence of premise in Twitter texts. This work is completed as part of the Social Media Mining for Health (SMM4H) Workshop 2022. We explored modern transformer-based classifiers in order to construct the pipeline efficiently capturing tweets semantics. Our experiments on a Twitter dataset showed that RoBERTa is superior to the other transformer models in the case of the premise prediction task. The model achieved competitive performance with respect to ROC AUC value 0.807, and 0.7648 for the F1 score.

</p>
</details>

<details><summary><b>Improved Robust Algorithms for Learning with Discriminative Feature Feedback</b>
<a href="https://arxiv.org/abs/2209.03753">arxiv:2209.03753</a>
&#x1F4C8; 5 <br>
<p>Sivan Sabato</p></summary>
<p>

**Abstract:** Discriminative Feature Feedback is a setting proposed by Dastupta et al. (2018), which provides a protocol for interactive learning based on feature explanations that are provided by a human teacher. The features distinguish between the labels of pairs of possibly similar instances. That work has shown that learning in this model can have considerable statistical and computational advantages over learning in standard label-based interactive learning models.
  In this work, we provide new robust interactive learning algorithms for the Discriminative Feature Feedback model, with mistake bounds that are significantly lower than those of previous robust algorithms for this setting. In the adversarial setting, we reduce the dependence on the number of protocol exceptions from quadratic to linear. In addition, we provide an algorithm for a slightly more restricted model, which obtains an even smaller mistake bound for large models with many exceptions.
  In the stochastic setting, we provide the first algorithm that converges to the exception rate with a polynomial sample complexity. Our algorithm and analysis for the stochastic setting involve a new construction that we call Feature Influence, which may be of wider applicability.

</p>
</details>

<details><summary><b>Learning-based and unrolled motion-compensated reconstruction for cardiac MR CINE imaging</b>
<a href="https://arxiv.org/abs/2209.03671">arxiv:2209.03671</a>
&#x1F4C8; 5 <br>
<p>Jiazhen Pan, Daniel Rueckert, Thomas Küstner, Kerstin Hammernik</p></summary>
<p>

**Abstract:** Motion-compensated MR reconstruction (MCMR) is a powerful concept with considerable potential, consisting of two coupled sub-problems: Motion estimation, assuming a known image, and image reconstruction, assuming known motion. In this work, we propose a learning-based self-supervised framework for MCMR, to efficiently deal with non-rigid motion corruption in cardiac MR imaging. Contrary to conventional MCMR methods in which the motion is estimated prior to reconstruction and remains unchanged during the iterative optimization process, we introduce a dynamic motion estimation process and embed it into the unrolled optimization. We establish a cardiac motion estimation network that leverages temporal information via a group-wise registration approach, and carry out a joint optimization between the motion estimation and reconstruction. Experiments on 40 acquired 2D cardiac MR CINE datasets demonstrate that the proposed unrolled MCMR framework can reconstruct high quality MR images at high acceleration rates where other state-of-the-art methods fail. We also show that the joint optimization mechanism is mutually beneficial for both sub-tasks, i.e., motion estimation and image reconstruction, especially when the MR image is highly undersampled.

</p>
</details>

<details><summary><b>Who Pays? Personalization, Bossiness and the Cost of Fairness</b>
<a href="https://arxiv.org/abs/2209.04043">arxiv:2209.04043</a>
&#x1F4C8; 4 <br>
<p>Paresha Farastu, Nicholas Mattei, Robin Burke</p></summary>
<p>

**Abstract:** Fairness-aware recommender systems that have a provider-side fairness concern seek to ensure that protected group(s) of providers have a fair opportunity to promote their items or products. There is a ``cost of fairness'' borne by the consumer side of the interaction when such a solution is implemented. This consumer-side cost raises its own questions of fairness, particularly when personalization is used to control the impact of the fairness constraint. In adopting a personalized approach to the fairness objective, researchers may be opening their systems up to strategic behavior on the part of users. This type of incentive has been studied in the computational social choice literature under the terminology of ``bossiness''. The concern is that a bossy user may be able to shift the cost of fairness to others, improving their own outcomes and worsening those for others. This position paper introduces the concept of bossiness, shows its application in fairness-aware recommendation and discusses strategies for reducing this strategic incentive.

</p>
</details>

<details><summary><b>Uncovering the Connection Between Differential Privacy and Certified Robustness of Federated Learning against Poisoning Attacks</b>
<a href="https://arxiv.org/abs/2209.04030">arxiv:2209.04030</a>
&#x1F4C8; 4 <br>
<p>Chulin Xie, Yunhui Long, Pin-Yu Chen, Bo Li</p></summary>
<p>

**Abstract:** Federated learning (FL) provides an efficient paradigm to jointly train a global model leveraging data from distributed users. As the local training data come from different users who may not be trustworthy, several studies have shown that FL is vulnerable to poisoning attacks. Meanwhile, to protect the privacy of local users, FL is always trained in a differentially private way (DPFL). Thus, in this paper, we ask: Can we leverage the innate privacy property of DPFL to provide certified robustness against poisoning attacks? Can we further improve the privacy of FL to improve such certification? We first investigate both user-level and instance-level privacy of FL and propose novel mechanisms to achieve improved instance-level privacy. We then provide two robustness certification criteria: certified prediction and certified attack cost for DPFL on both levels. Theoretically, we prove the certified robustness of DPFL under a bounded number of adversarial users or instances. Empirically, we conduct extensive experiments to verify our theories under a range of attacks on different datasets. We show that DPFL with a tighter privacy guarantee always provides stronger robustness certification in terms of certified attack cost, but the optimal certified prediction is achieved under a proper balance between privacy protection and utility loss.

</p>
</details>

<details><summary><b>Mean Field Games on Weighted and Directed Graphs via Colored Digraphons</b>
<a href="https://arxiv.org/abs/2209.03887">arxiv:2209.03887</a>
&#x1F4C8; 4 <br>
<p>Christian Fabian, Kai Cui, Heinz Koeppl</p></summary>
<p>

**Abstract:** The field of multi-agent reinforcement learning (MARL) has made considerable progress towards controlling challenging multi-agent systems by employing various learning methods. Numerous of these approaches focus on empirical and algorithmic aspects of the MARL problems and lack a rigorous theoretical foundation. Graphon mean field games (GMFGs) on the other hand provide a scalable and mathematically well-founded approach to learning problems that involve a large number of connected agents. In standard GMFGs, the connections between agents are undirected, unweighted and invariant over time. Our paper introduces colored digraphon mean field games (CDMFGs) which allow for weighted and directed links between agents that are also adaptive over time. Thus, CDMFGs are able to model more complex connections than standard GMFGs. Besides a rigorous theoretical analysis including both existence and convergence guarantees, we provide a learning scheme and illustrate our findings with an epidemics model and a model of the systemic risk in financial markets.

</p>
</details>

<details><summary><b>Learning Sparse Graphon Mean Field Games</b>
<a href="https://arxiv.org/abs/2209.03880">arxiv:2209.03880</a>
&#x1F4C8; 4 <br>
<p>Christian Fabian, Kai Cui, Heinz Koeppl</p></summary>
<p>

**Abstract:** Although the field of multi-agent reinforcement learning (MARL) has made considerable progress in the last years, solving systems with a large number of agents remains a hard challenge. Graphon mean field games (GMFGs) enable the scalable analysis of MARL problems that are otherwise intractable. By the mathematical structure of graphons, this approach is limited to dense graphs which are insufficient to describe many real-world networks such as power law graphs. Our paper introduces a novel formulation of GMFGs, called LPGMFGs, which leverages the graph theoretical concept of $L^p$ graphons and provides a machine learning tool to efficiently and accurately approximate solutions for sparse network problems. This especially includes power law networks which are empirically observed in various application areas and cannot be captured by standard graphons. We derive theoretical existence and convergence guarantees and give empirical examples that demonstrate the accuracy of our learning approach for systems with many agents. Furthermore, we rigorously extend the Online Mirror Descent (OMD) learning algorithm to our setup to accelerate learning speed, allow for agent interaction through the mean field in the transition kernel, and empirically show its capabilities. In general, we provide a scalable, mathematically well-founded machine learning approach to a large class of otherwise intractable problems of great relevance in numerous research fields.

</p>
</details>

<details><summary><b>Losing momentum in continuous-time stochastic optimisation</b>
<a href="https://arxiv.org/abs/2209.03705">arxiv:2209.03705</a>
&#x1F4C8; 4 <br>
<p>Kexin Jin, Jonas Latz, Chenguang Liu, Alessandro Scagliotti</p></summary>
<p>

**Abstract:** The training of deep neural networks and other modern machine learning models usually consists in solving non-convex optimisation problems that are high-dimensional and subject to large-scale data. Here, momentum-based stochastic optimisation algorithms have become especially popular in recent years. The stochasticity arises from data subsampling which reduces computational cost. Moreover, both, momentum and stochasticity are supposed to help the algorithm to overcome local minimisers and, hopefully, converge globally. Theoretically, this combination of stochasticity and momentum is badly understood.
  In this work, we propose and analyse a continuous-time model for stochastic gradient descent with momentum. This model is a piecewise-deterministic Markov process that represents the particle movement by an underdamped dynamical system and the data subsampling through a stochastic switching of the dynamical system. In our analysis, we investigate longtime limits, the subsampling-to-no-subsampling limit, and the momentum-to-no-momentum limit. We are particularly interested in the case of reducing the momentum over time: intuitively, the momentum helps to overcome local minimisers in the initial phase of the algorithm, but prohibits fast convergence to a global minimiser later. Under convexity assumptions, we show convergence of our dynamical system to the global minimiser when reducing momentum over time and let the subsampling rate go to infinity.
  We then propose a stable, symplectic discretisation scheme to construct an algorithm from our continuous-time dynamical system. In numerical experiments, we study our discretisation scheme in convex and non-convex test problems. Additionally, we train a convolutional neural network to solve the CIFAR-10 image classification problem. Here, our algorithm reaches competitive results compared to stochastic gradient descent with momentum.

</p>
</details>

<details><summary><b>IMAP: Individual huMAn mobility Patterns visualizing platform</b>
<a href="https://arxiv.org/abs/2209.03615">arxiv:2209.03615</a>
&#x1F4C8; 4 <br>
<p>Yisheng Alison Zheng, Amani Abusafia, Abdallah Lakhdari, Shing Tai Tony Lui, Athman Bouguettaya</p></summary>
<p>

**Abstract:** Understanding human mobility is essential for the development of smart cities and social behavior research. Human mobility models may be used in numerous applications, including pandemic control, urban planning, and traffic management. The existing models' accuracy in predicting users' mobility patterns is less than 25%. The low accuracy may be justified by the flexible nature of the human movement. Indeed, humans are not rigid in their daily movement. In addition, the rigid mobility models may result in missing the hidden regularities in users' records. Thus, we propose a novel perspective to study and analyze human mobility patterns and capture their flexibility. Typically, the mobility patterns are represented by a sequence of locations. We propose to define the mobility patterns by abstracting these locations into a set of places. Labeling these locations will allow us to detect close-to-reality hidden patterns. We present IMAP, an Individual huMAn mobility Patterns visualizing platform. Our platform enables users to visualize a graph of the places they visited based on their history records. In addition, our platform displays the most frequent mobility patterns computed using a modified PrefixSpan approach.

</p>
</details>

<details><summary><b>SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by Self-supervised Learning</b>
<a href="https://arxiv.org/abs/2209.03563">arxiv:2209.03563</a>
&#x1F4C8; 4 <br>
<p>Peizhuo Lv, Pan Li, Shenchen Zhu, Shengzhi Zhang, Kai Chen, Ruigang Liang, Chang Yue, Fan Xiang, Yuling Cai, Hualong Ma, Yingjun Zhang, Guozhu Meng</p></summary>
<p>

**Abstract:** Recent years have witnessed significant success in Self-Supervised Learning (SSL), which facilitates various downstream tasks. However, attackers may steal such SSL models and commercialize them for profit, making it crucial to protect their Intellectual Property (IP). Most existing IP protection solutions are designed for supervised learning models and cannot be used directly since they require that the models' downstream tasks and target labels be known and available during watermark embedding, which is not always possible in the domain of SSL. To address such a problem especially when downstream tasks are diverse and unknown during watermark embedding, we propose a novel black-box watermarking solution, named SSL-WM, for protecting the ownership of SSL models. SSL-WM maps watermarked inputs by the watermarked encoders into an invariant representation space, which causes any downstream classifiers to produce expected behavior, thus allowing the detection of embedded watermarks. We evaluate SSL-WM on numerous tasks, such as Computer Vision (CV) and Natural Language Processing (NLP), using different SSL models, including contrastive-based and generative-based. Experimental results demonstrate that SSL-WM can effectively verify the ownership of stolen SSL models in various downstream tasks. Furthermore, SSL-WM is robust against model fine-tuning and pruning attacks. Lastly, SSL-WM can also evade detection from evaluated watermark detection approaches, demonstrating its promising application in protecting the IP of SSL models.

</p>
</details>

<details><summary><b>Gaussian Process Koopman Mode Decomposition</b>
<a href="https://arxiv.org/abs/2209.04111">arxiv:2209.04111</a>
&#x1F4C8; 3 <br>
<p>Takahiro Kawashima, Hideitsu Hino</p></summary>
<p>

**Abstract:** In this paper, we propose a nonlinear probabilistic generative model of Koopman mode decomposition based on an unsupervised Gaussian process. Existing data-driven methods for Koopman mode decomposition have focused on estimating the quantities specified by Koopman mode decomposition, namely, eigenvalues, eigenfunctions, and modes. Our model enables the simultaneous estimation of these quantities and latent variables governed by an unknown dynamical system. Furthermore, we introduce an efficient strategy to estimate the parameters of our model by low-rank approximations of covariance matrices. Applying the proposed model to both synthetic data and a real-world epidemiological dataset, we show that various analyses are available using the estimated parameters.

</p>
</details>

<details><summary><b>Stochastic Compositional Optimization with Compositional Constraints</b>
<a href="https://arxiv.org/abs/2209.04086">arxiv:2209.04086</a>
&#x1F4C8; 3 <br>
<p>Shuoguang Yang, Zhe Zhang, Ethan X. Fang</p></summary>
<p>

**Abstract:** Stochastic compositional optimization (SCO) has attracted considerable attention because of its broad applicability to important real-world problems. However, existing works on SCO assume that the projection within a solution update is simple, which fails to hold for problem instances where the constraints are in the form of expectations, such as empirical conditional value-at-risk constraints. We study a novel model that incorporates single-level expected value and two-level compositional constraints into the current SCO framework. Our model can be applied widely to data-driven optimization and risk management, including risk-averse optimization and high-moment portfolio selection, and can handle multiple constraints. We further propose a class of primal-dual algorithms that generates sequences converging to the optimal solution at the rate of $\cO(\frac{1}{\sqrt{N}})$under both single-level expected value and two-level compositional constraints, where $N$ is the iteration counter, establishing the benchmarks in expected value constrained SCO.

</p>
</details>

<details><summary><b>RASR: Risk-Averse Soft-Robust MDPs with EVaR and Entropic Risk</b>
<a href="https://arxiv.org/abs/2209.04067">arxiv:2209.04067</a>
&#x1F4C8; 3 <br>
<p>Jia Lin Hau, Marek Petrik, Mohammad Ghavamzadeh, Reazul Russel</p></summary>
<p>

**Abstract:** Prior work on safe Reinforcement Learning (RL) has studied risk-aversion to randomness in dynamics (aleatory) and to model uncertainty (epistemic) in isolation. We propose and analyze a new framework to jointly model the risk associated with epistemic and aleatory uncertainties in finite-horizon and discounted infinite-horizon MDPs. We call this framework that combines Risk-Averse and Soft-Robust methods RASR. We show that when the risk-aversion is defined using either EVaR or the entropic risk, the optimal policy in RASR can be computed efficiently using a new dynamic program formulation with a time-dependent risk level. As a result, the optimal risk-averse policies are deterministic but time-dependent, even in the infinite-horizon discounted setting. We also show that particular RASR objectives reduce to risk-averse RL with mean posterior transition probabilities. Our empirical results show that our new algorithms consistently mitigate uncertainty as measured by EVaR and other standard risk measures.

</p>
</details>

<details><summary><b>Studying Drowsiness Detection Performance while Driving through Scalable Machine Learning Models using Electroencephalography</b>
<a href="https://arxiv.org/abs/2209.04048">arxiv:2209.04048</a>
&#x1F4C8; 3 <br>
<p>José Manuel Hidalgo Rogel, Enrique Tomás Martínez Beltrán, Mario Quiles Pérez, Sergio López Bernal, Gregorio Martínez Pérez, Alberto Huertas Celdrán</p></summary>
<p>

**Abstract:** Drowsiness is a major concern for drivers and one of the leading causes of traffic accidents. Advances in Cognitive Neuroscience and Computer Science have enabled the detection of drivers' drowsiness by using Brain-Computer Interfaces (BCIs) and Machine Learning (ML). Nevertheless, several challenges remain open and should be faced. First, a comprehensive enough evaluation of drowsiness detection performance using a heterogeneous set of ML algorithms is missing in the literature. Last, it is needed to study the detection performance of scalable ML models suitable for groups of subjects and compare it with the individual models proposed in the literature. To improve these limitations, this work presents an intelligent framework that employs BCIs and features based on electroencephalography (EEG) for detecting drowsiness in driving scenarios. The SEED-VIG dataset is used to feed different ML regressors and three-class classifiers and then evaluate, analyze, and compare the best-performing models for individual subjects and groups of them. More in detail, regarding individual models, Random Forest (RF) obtained a 78% f1-score, improving the 58% obtained by models used in the literature such as Support Vector Machine (SVM). Concerning scalable models, RF reached a 79% f1-score, demonstrating the effectiveness of these approaches. The lessons learned can be summarized as follows: i) not only SVM but also other models not sufficiently explored in the literature are relevant for drowsiness detection, and ii) scalable approaches suitable for groups of subjects are effective to detect drowsiness, even when new subjects that are not included in the models training are evaluated.

</p>
</details>

<details><summary><b>Sequential Information Design: Learning to Persuade in the Dark</b>
<a href="https://arxiv.org/abs/2209.03927">arxiv:2209.03927</a>
&#x1F4C8; 3 <br>
<p>Martino Bernasconi, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti, Francesco Trovo</p></summary>
<p>

**Abstract:** We study a repeated information design problem faced by an informed sender who tries to influence the behavior of a self-interested receiver. We consider settings where the receiver faces a sequential decision making (SDM) problem. At each round, the sender observes the realizations of random events in the SDM problem. This begets the challenge of how to incrementally disclose such information to the receiver to persuade them to follow (desirable) action recommendations. We study the case in which the sender does not know random events probabilities, and, thus, they have to gradually learn them while persuading the receiver. We start by providing a non-trivial polytopal approximation of the set of sender's persuasive information structures. This is crucial to design efficient learning algorithms. Next, we prove a negative result: no learning algorithm can be persuasive. Thus, we relax persuasiveness requirements by focusing on algorithms that guarantee that the receiver's regret in following recommendations grows sub-linearly. In the full-feedback setting -- where the sender observes all random events realizations -- , we provide an algorithm with $\tilde{O}(\sqrt{T})$ regret for both the sender and the receiver. Instead, in the bandit-feedback setting -- where the sender only observes the realizations of random events actually occurring in the SDM problem -- , we design an algorithm that, given an $α\in [1/2, 1]$ as input, ensures $\tilde{O}({T^α})$ and $\tilde{O}( T^{\max \{ α, 1-\fracα{2} \} })$ regrets, for the sender and the receiver respectively. This result is complemented by a lower bound showing that such a regrets trade-off is essentially tight.

</p>
</details>

<details><summary><b>Training Scale-Invariant Neural Networks on the Sphere Can Happen in Three Regimes</b>
<a href="https://arxiv.org/abs/2209.03695">arxiv:2209.03695</a>
&#x1F4C8; 3 <br>
<p>Maxim Kodryan, Ekaterina Lobacheva, Maksim Nakhodnov, Dmitry Vetrov</p></summary>
<p>

**Abstract:** A fundamental property of deep learning normalization techniques, such as batch normalization, is making the pre-normalization parameters scale invariant. The intrinsic domain of such parameters is the unit sphere, and therefore their gradient optimization dynamics can be represented via spherical optimization with varying effective learning rate (ELR), which was studied previously. In this work, we investigate the properties of training scale-invariant neural networks directly on the sphere using a fixed ELR. We discover three regimes of such training depending on the ELR value: convergence, chaotic equilibrium, and divergence. We study these regimes in detail both on a theoretical examination of a toy example and on a thorough empirical analysis of real scale-invariant deep learning models. Each regime has unique features and reflects specific properties of the intrinsic loss landscape, some of which have strong parallels with previous research on both regular and scale-invariant neural networks training. Finally, we demonstrate how the discovered regimes are reflected in conventional training of normalized networks and how they can be leveraged to achieve better optima.

</p>
</details>

<details><summary><b>Tag-Aware Document Representation for Research Paper Recommendation</b>
<a href="https://arxiv.org/abs/2209.03660">arxiv:2209.03660</a>
&#x1F4C8; 3 <br>
<p>Hebatallah A. Mohamed, Giuseppe Sansonetti, Alessandro Micarelli</p></summary>
<p>

**Abstract:** Finding online research papers relevant to one's interests is very challenging due to the increasing number of publications. Therefore, personalized research paper recommendation has become a significant and timely research topic. Collaborative filtering is a successful recommendation approach, which exploits the ratings given to items by users as a source of information for learning to make accurate recommendations. However, the ratings are often very sparse as in the research paper domain, due to the huge number of publications growing every year. Therefore, more attention has been drawn to hybrid methods that consider both ratings and content information. Nevertheless, most of the hybrid recommendation approaches that are based on text embedding have utilized bag-of-words techniques, which ignore word order and semantic meaning. In this paper, we propose a hybrid approach that leverages deep semantic representation of research papers based on social tags assigned by users. The experimental evaluation is performed on CiteULike, a real and publicly available dataset. The obtained findings show that the proposed model is effective in recommending research papers even when the rating data is very sparse.

</p>
</details>

<details><summary><b>Deep learning in a bilateral brain with hemispheric specialization</b>
<a href="https://arxiv.org/abs/2209.06862">arxiv:2209.06862</a>
&#x1F4C8; 2 <br>
<p>Chandramouli Rajagopalan, David Rawlinson, Elkhonon Goldberg, Gideon Kowadlo</p></summary>
<p>

**Abstract:** The brains of all bilaterally symmetric animals on Earth are are divided into left and right hemispheres. The anatomy and functionality of the hemispheres have a large degree of overlap, but they specialize to possess different attributes. The left hemisphere is believed to specialize in specificity and routine, the right in generalities and novelty. In this study, we propose an artificial neural network that imitates that bilateral architecture using two convolutional neural networks with different training objectives and test it on an image classification task. The bilateral architecture outperforms architectures of similar representational capacity that don't exploit differential specialization. It demonstrates the efficacy of bilateralism and constitutes a new principle that could be incorporated into other computational neuroscientific models and used as an inductive bias when designing new ML systems. An analysis of the model can help us to understand the human brain.

</p>
</details>

<details><summary><b>Majority Vote for Distributed Differentially Private Sign Selection</b>
<a href="https://arxiv.org/abs/2209.04419">arxiv:2209.04419</a>
&#x1F4C8; 2 <br>
<p>Weidong Liu, Jiyuan Tu, Xiaojun Mao, Xi Chen</p></summary>
<p>

**Abstract:** Privacy-preserving data analysis has become prevailing in recent years. In this paper, we propose a distributed group differentially private majority vote mechanism for the sign selection problem in a distributed setup. To achieve this, we apply the iterative peeling to the stability function and use the exponential mechanism to recover the signs. As applications, we study the private sign selection for mean estimation and linear regression problems in distributed systems. Our method recovers the support and signs with the optimal signal-to-noise ratio as in the non-private scenario, which is better than contemporary works of private variable selections. Moreover, the sign selection consistency is justified with theoretical guarantees. Simulation studies are conducted to demonstrate the effectiveness of our proposed method.

</p>
</details>

<details><summary><b>Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept Statistics</b>
<a href="https://arxiv.org/abs/2209.04049">arxiv:2209.04049</a>
&#x1F4C8; 2 <br>
<p>Masataro Asai</p></summary>
<p>

**Abstract:** The symbolic AI community is increasingly trying to embrace machine learning in neuro-symbolic architectures, yet is still struggling due to cultural barriers. To break the barrier, this rather opinionated personal memo attempts to explain and rectify the conventions in Statistics, Machine Learning, and Deep Learning from the viewpoint of outsiders. It provides a step-by-step protocol for designing a machine learning system that satisfies a minimum theoretical guarantee necessary for being taken seriously by the symbolic AI community, i.e., it discusses "in what condition we can stop worrying and accept statistical machine learning." Some highlights:
  Most textbooks are written for those who plan to specialize in Stat/ML/DL and are supposed to accept jargons. This memo is for experienced symbolic researchers that hear a lot of buzz but are still uncertain and skeptical.
  Information on Stat/ML/DL is currently too scattered or too noisy to invest in. This memo prioritizes compactness and pays special attention to concepts that resonate well with symbolic paradigms. I hope this memo offers time savings.
  It prioritizes general mathematical modeling and does not discuss any specific function approximator, such as neural networks (NNs), SVMs, decision trees, etc.
  It is open to corrections. Consider this memo as something similar to a blog post taking the form of a paper on Arxiv.

</p>
</details>

<details><summary><b>Functional dimension of feedforward ReLU neural networks</b>
<a href="https://arxiv.org/abs/2209.04036">arxiv:2209.04036</a>
&#x1F4C8; 2 <br>
<p>J. Elisenda Grigsby, Kathryn Lindsey, Robert Meyerhoff, Chenxi Wu</p></summary>
<p>

**Abstract:** It is well-known that the parameterized family of functions representable by fully-connected feedforward neural networks with ReLU activation function is precisely the class of piecewise linear functions with finitely many pieces. It is less well-known that for every fixed architecture of ReLU neural network, the parameter space admits positive-dimensional spaces of symmetries, and hence the local functional dimension near any given parameter is lower than the parametric dimension. In this work we carefully define the notion of functional dimension, show that it is inhomogeneous across the parameter space of ReLU neural network functions, and continue an investigation - initiated in [14] and [5] - into when the functional dimension achieves its theoretical maximum. We also study the quotient space and fibers of the realization map from parameter space to function space, supplying examples of fibers that are disconnected, fibers upon which functional dimension is non-constant, and fibers upon which the symmetry group acts non-transitively.

</p>
</details>

<details><summary><b>Analyzing the Effect of Sampling in GNNs on Individual Fairness</b>
<a href="https://arxiv.org/abs/2209.03904">arxiv:2209.03904</a>
&#x1F4C8; 2 <br>
<p>Rebecca Salganik, Fernando Diaz, Golnoosh Farnadi</p></summary>
<p>

**Abstract:** Graph neural network (GNN) based methods have saturated the field of recommender systems. The gains of these systems have been significant, showing the advantages of interpreting data through a network structure. However, despite the noticeable benefits of using graph structures in recommendation tasks, this representational form has also bred new challenges which exacerbate the complexity of mitigating algorithmic bias. When GNNs are integrated into downstream tasks, such as recommendation, bias mitigation can become even more difficult. Furthermore, the intractability of applying existing methods of fairness promotion to large, real world datasets places even more serious constraints on mitigation attempts. Our work sets out to fill in this gap by taking an existing method for promoting individual fairness on graphs and extending it to support mini-batch, or sub-sample based, training of a GNN, thus laying the groundwork for applying this method to a downstream recommendation task. We evaluate two popular GNN methods: Graph Convolutional Network (GCN), which trains on the entire graph, and GraphSAGE, which uses probabilistic random walks to create subgraphs for mini-batch training, and assess the effects of sub-sampling on individual fairness. We implement an individual fairness notion called \textit{REDRESS}, proposed by Dong et al., which uses rank optimization to learn individual fair node, or item, embeddings. We empirically show on two real world datasets that GraphSAGE is able to achieve, not just, comparable accuracy, but also, improved fairness as compared with the GCN model. These finding have consequential ramifications to individual fairness promotion, GNNs, and in downstream form, recommender systems, showing that mini-batch training facilitate individual fairness promotion by allowing for local nuance to guide the process of fairness promotion in representation learning.

</p>
</details>

<details><summary><b>Dyadic Interaction Assessment from Free-living Audio for Depression Severity Assessment</b>
<a href="https://arxiv.org/abs/2209.03901">arxiv:2209.03901</a>
&#x1F4C8; 2 <br>
<p>Bishal Lamichhane, Nidal Moukaddam, Ankit B. Patel, Ashutosh Sabharwal</p></summary>
<p>

**Abstract:** Psychomotor retardation in depression has been associated with speech timing changes from dyadic clinical interviews. In this work, we investigate speech timing features from free-living dyadic interactions. Apart from the possibility of continuous monitoring to complement clinical visits, a study in free-living conditions would also allow inferring sociability features such as dyadic interaction frequency implicated in depression. We adapted a speaker count estimator as a dyadic interaction detector with a specificity of 89.5% and a sensitivity of 86.1% in the DIHARD dataset. Using the detector, we obtained speech timing features from the detected dyadic interactions in multi-day audio recordings of 32 participants comprised of 13 healthy individuals, 11 individuals with depression, and 8 individuals with psychotic disorders. The dyadic interaction frequency increased with depression severity in participants with no or mild depression, indicating a potential diagnostic marker of depression onset. However, the dyadic interaction frequency decreased with increasing depression severity for participants with moderate or severe depression. In terms of speech timing features, the response time had a significant positive correlation with depression severity. Our work shows the potential of dyadic interaction analysis from audio recordings of free-living to obtain markers of depression severity.

</p>
</details>

<details><summary><b>A Survey on Large-Population Systems and Scalable Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.03859">arxiv:2209.03859</a>
&#x1F4C8; 2 <br>
<p>Kai Cui, Anam Tahir, Gizem Ekinci, Ahmed Elshamanhory, Yannick Eich, Mengguang Li, Heinz Koeppl</p></summary>
<p>

**Abstract:** The analysis and control of large-population systems is of great interest to diverse areas of research and engineering, ranging from epidemiology over robotic swarms to economics and finance. An increasingly popular and effective approach to realizing sequential decision-making in multi-agent systems is through multi-agent reinforcement learning, as it allows for an automatic and model-free analysis of highly complex systems. However, the key issue of scalability complicates the design of control and reinforcement learning algorithms particularly in systems with large populations of agents. While reinforcement learning has found resounding empirical success in many scenarios with few agents, problems with many agents quickly become intractable and necessitate special consideration. In this survey, we will shed light on current approaches to tractably understanding and analyzing large-population systems, both through multi-agent reinforcement learning and through adjacent areas of research such as mean-field games, collective intelligence, or complex network theory. These classically independent subject areas offer a variety of approaches to understanding or modeling large-population systems, which may be of great use for the formulation of tractable MARL algorithms in the future. Finally, we survey potential areas of application for large-scale control and identify fruitful future applications of learning algorithms in practical systems. We hope that our survey could provide insight and future directions to junior and senior researchers in theoretical and applied sciences alike.

</p>
</details>

<details><summary><b>Double Q-Learning for Citizen Relocation During Natural Hazards</b>
<a href="https://arxiv.org/abs/2209.03800">arxiv:2209.03800</a>
&#x1F4C8; 2 <br>
<p>Alysson Ribeiro da Silva</p></summary>
<p>

**Abstract:** Natural disasters can cause substantial negative socio-economic impacts around the world, due to mortality, relocation, rates, and reconstruction decisions. Robotics has been successfully applied to identify and rescue victims during the occurrence of a natural hazard. However, little effort has been taken to deploy solutions where an autonomous robot can save the life of a citizen by itself relocating it, without the need to wait for a rescue team composed of humans. Reinforcement learning approaches can be used to deploy such a solution, however, one of the most famous algorithms to deploy it, the Q-learning, suffers from biased results generated when performing its learning routines. In this research a solution for citizen relocation based on Partially Observable Markov Decision Processes is adopted, where the capability of the Double Q-learning in relocating citizens during a natural hazard is evaluated under a proposed hazard simulation engine based on a grid world. The performance of the solution was measured as a success rate of a citizen relocation procedure, where the results show that the technique portrays a performance above 100% for easy scenarios and near 50% for hard ones.

</p>
</details>

<details><summary><b>Developing a multi-variate prediction model for the detection of COVID-19 from Crowd-sourced Respiratory Voice Data</b>
<a href="https://arxiv.org/abs/2209.03727">arxiv:2209.03727</a>
&#x1F4C8; 2 <br>
<p>Wafaa Aljbawi, Sami O. Simmons, Visara Urovi</p></summary>
<p>

**Abstract:** COVID-19 has affected more than 223 countries worldwide. There is a pressing need for non invasive, low costs and highly scalable solutions to detect COVID-19, especially in low-resource countries where PCR testing is not ubiquitously available. Our aim is to develop a deep learning model identifying COVID-19 using voice data recordings spontaneously provided by the general population (voice recordings and a short questionnaire) via their personal devices. The novelty of this work is in the development of a deep learning model for the identification of COVID-19 patients from voice recordings. Methods: We used the Cambridge University dataset consisting of 893 audio samples, crowd-sourced from 4352 participants that used a COVID-19 Sounds app. Voice features were extracted using a Mel-spectrogram analysis. Based on the voice data, we developed deep learning classification models to detect positive COVID-19 cases. These models included Long-Short Term Memory (LSTM) and Convolutional Neural Network (CNN). We compared their predictive power to baseline classification models, namely Logistic Regression and Support Vector Machine. Results: LSTM based on a Mel-frequency cepstral coefficients (MFCC) features achieved the highest accuracy (89%,) with a sensitivity and specificity of respectively 89% and 89%, The results achieved with the proposed model suggest a significant improvement in the prediction accuracy of COVID-19 diagnosis compared to the results obtained in the state of the art. Conclusion: Deep learning can detect subtle changes in the voice of COVID-19 patients with promising results. As an addition to the current testing techniques this model may aid health professionals in fast diagnosis and tracing of COVID-19 cases using simple voice analysis

</p>
</details>

<details><summary><b>What Did I Just Hear? Detecting Pornographic Sounds in Adult Videos Using Neural Networks</b>
<a href="https://arxiv.org/abs/2209.03711">arxiv:2209.03711</a>
&#x1F4C8; 2 <br>
<p>Holy Lovenia, Dessi Puji Lestari, Rita Frieske</p></summary>
<p>

**Abstract:** Audio-based pornographic detection enables efficient adult content filtering without sacrificing performance by exploiting distinct spectral characteristics. To improve it, we explore pornographic sound modeling based on different neural architectures and acoustic features. We find that CNN trained on log mel spectrogram achieves the best performance on Pornography-800 dataset. Our experiment results also show that log mel spectrogram allows better representations for the models to recognize pornographic sounds. Finally, to classify whole audio waveforms rather than segments, we employ voting segment-to-audio technique that yields the best audio-level detection results.

</p>
</details>

<details><summary><b>Kernel-Segregated Transpose Convolution Operation</b>
<a href="https://arxiv.org/abs/2209.03704">arxiv:2209.03704</a>
&#x1F4C8; 2 <br>
<p>Vijay Srinivas Tida, Sai Venkatesh Chilukoti, Xiali Hei, Sonya Hsu</p></summary>
<p>

**Abstract:** Transpose convolution has shown prominence in many deep learning applications. However, transpose convolution layers are computationally intensive due to the increased feature map size due to adding zeros after each element in each row and column. Thus, convolution operation on the expanded input feature map leads to poor utilization of hardware resources. The main reason for unnecessary multiplication operations is zeros at predefined positions in the input feature map. We propose an algorithmic-level optimization technique for the effective transpose convolution implementation to solve these problems. Based on kernel activations, we segregated the original kernel into four sub-kernels. This scheme could reduce memory requirements and unnecessary multiplications. Our proposed method was $3.09 (3.02) \times$ faster computation using the Titan X GPU (Intel Dual Core CPU) with a flower dataset from the Kaggle website. Furthermore, the proposed optimization method can be generalized to existing devices without additional hardware requirements. A simple deep learning model containing one transpose convolution layer was used to evaluate the optimization method. It showed $2.2 \times$ faster training using the MNIST dataset with an Intel Dual-core CPU than the conventional implementation.

</p>
</details>

<details><summary><b>Incremental Correction in Dynamic Systems Modelled with Neural Networks for Constraint Satisfaction</b>
<a href="https://arxiv.org/abs/2209.03698">arxiv:2209.03698</a>
&#x1F4C8; 2 <br>
<p>Namhoon Cho, Hyo-Sang Shin, Antonios Tsourdos, Davide Amato</p></summary>
<p>

**Abstract:** This study presents incremental correction methods for refining neural network parameters or control functions entering into a continuous-time dynamic system to achieve improved solution accuracy in satisfying the interim point constraints placed on the performance output variables. The proposed approach is to linearise the dynamics around the baseline values of its arguments, and then to solve for the corrective input required to transfer the perturbed trajectory to precisely known or desired values at specific time points, i.e., the interim points. Depending on the type of decision variables to adjust, parameter correction and control function correction methods are developed. These incremental correction methods can be utilised as a means to compensate for the prediction errors of pre-trained neural networks in real-time applications where high accuracy of the prediction of dynamical systems at prescribed time points is imperative. In this regard, the online update approach can be useful for enhancing overall targeting accuracy of finite-horizon control subject to point constraints using a neural policy. Numerical example demonstrates the effectiveness of the proposed approach in an application to a powered descent problem at Mars.

</p>
</details>

<details><summary><b>Known by the company we keep: `Triadic influence' as a proxy for compatibility in social relationships</b>
<a href="https://arxiv.org/abs/2209.03683">arxiv:2209.03683</a>
&#x1F4C8; 2 <br>
<p>Miguel Ruíz-García, Juan Ozaita, María Pereda, Antonio Alfonso, Pablo Brañas-Garza, Jose A. Cuesta, Ángel Sánchez</p></summary>
<p>

**Abstract:** Networks of social interactions are the substrate upon which civilizations are built. Often, we create new bonds with people that we like or feel that our relationships are damaged through the intervention of third parties. Despite their importance and the huge impact that these processes have in our lives, quantitative scientific understanding of them is still in its infancy, mainly due to the difficulty of collecting large datasets of social networks including individual attributes. In this work, we present a thorough study of real social networks of 13 schools, with more than 3,000 students and 60,000 declared positive and negative relations, including tests for personal traits of all the students. We introduce a metric -- the `triadic influence' -- that measures the influence of nearest-neighbors in the relationships of their contacts. We use neural networks to predict the relationships and to extract the probability that two students are friends or enemies depending on their personal attributes or the triadic influence. We alternatively use a high-dimensional embedding of the network structure to also predict the relationships. Remarkably, the triadic influence (a simple one-dimensional metric) achieves the highest accuracy at predicting the relationship between two students. We postulate that the probabilities extracted from the neural networks -- functions of the triadic influence and the personalities of the students -- control the evolution of real social networks, opening a new avenue for the quantitative study of these systems.

</p>
</details>

<details><summary><b>Reconstruction of Three-dimensional Scroll Wave Chaos in Opaque and Transparent Excitable Media using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2209.06860">arxiv:2209.06860</a>
&#x1F4C8; 1 <br>
<p>Jan Lebert, Meenakshi Mittal, Jan Christoph</p></summary>
<p>

**Abstract:** Scroll wave chaos is thought to underlie life-threatening ventricular fibrillation. However, currently there is no direct way to measure action potential wave patterns transmurally throughout the thick ventricular heart muscle. Consequently, direct observation of three-dimensional electrical scroll wave chaos remains elusive. Here, we study whether it is possible to reconstruct simulated three-dimensional scroll wave chaos inside a bulk-shaped excitable medium from two-dimensional observations of the wave dynamics on the bulk's surface using deep learning. We trained encoding-decoding convolutional neural networks to predict three-dimensional scroll wave chaos inside opaque and transparent as well as isotropic and anisotropic excitable media from two-dimensional projections or observations of the wave dynamics on the surface. We tested whether observations from one or two opposing surfaces would be sufficient, whether incorporating measurements of the surface deformation improves the reconstruction, and tested the feasibility of predicting the bulk's thickness. We demonstrate that it is possible to fully reconstruct three-dimensional scroll wave chaos in transparent excitable media with anisotropy and to obtain partial reconstructions in opaque excitable media when analyzing two opposing layers of the bulk. We found that anisotropy provides crucial information for neural networks to decode depth, which facilitates the reconstructions. In the future, deep neural networks could be used to visualize transmural action potential wave patterns during ventricular fibrillation from epi- or endocardial recordings.

</p>
</details>

<details><summary><b>Algorithms with More Granular Differential Privacy Guarantees</b>
<a href="https://arxiv.org/abs/2209.04053">arxiv:2209.04053</a>
&#x1F4C8; 1 <br>
<p>Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Thomas Steinke</p></summary>
<p>

**Abstract:** Differential privacy is often applied with a privacy parameter that is larger than the theory suggests is ideal; various informal justifications for tolerating large privacy parameters have been proposed. In this work, we consider partial differential privacy (DP), which allows quantifying the privacy guarantee on a per-attribute basis. In this framework, we study several basic data analysis and learning tasks, and design algorithms whose per-attribute privacy parameter is smaller that the best possible privacy parameter for the entire record of a person (i.e., all the attributes).

</p>
</details>

<details><summary><b>SE(3)-DiffusionFields: Learning cost functions for joint grasp and motion optimization through diffusion</b>
<a href="https://arxiv.org/abs/2209.03855">arxiv:2209.03855</a>
&#x1F4C8; 1 <br>
<p>Julen Urain, Niklas Funk, Georgia Chalvatzaki, Jan Peters</p></summary>
<p>

**Abstract:** Multi-objective high-dimensional motion optimization problems are ubiquitous in robotics and highly benefit from informative gradients. To this end, we require all cost functions to be differentiable. We propose learning task-space, data-driven cost functions as diffusion models. Diffusion models represent expressive multimodal distributions and exhibit proper gradients over the entire space. We exploit these properties for motion optimization by integrating the learned cost functions with other potentially learned or hand-tuned costs in a single objective function and optimize all of them jointly by gradient descent. We showcase the benefits of joint optimization in a set of complex grasp and motion planning problems and compare against hierarchical approaches that decouple grasp selection from motion optimization.

</p>
</details>

<details><summary><b>Hardware Accelerator and Neural Network Co-Optimization for Ultra-Low-Power Audio Processing Devices</b>
<a href="https://arxiv.org/abs/2209.03807">arxiv:2209.03807</a>
&#x1F4C8; 1 <br>
<p>Christoph Gerum, Adrian Frischknecht, Tobias Hald, Paul Palomero Bernardo, Konstantin Lübeck, Olver Bringmann</p></summary>
<p>

**Abstract:** The increasing spread of artificial neural networks does not stop at ultralow-power edge devices. However, these very often have high computational demand and require specialized hardware accelerators to ensure the design meets power and performance constraints. The manual optimization of neural networks along with the corresponding hardware accelerators can be very challenging. This paper presents HANNAH (Hardware Accelerator and Neural Network seArcH), a framework for automated and combined hardware/software co-design of deep neural networks and hardware accelerators for resource and power-constrained edge devices. The optimization approach uses an evolution-based search algorithm, a neural network template technique, and analytical KPI models for the configurable UltraTrail hardware accelerator template to find an optimized neural network and accelerator configuration. We demonstrate that HANNAH can find suitable neural networks with minimized power consumption and high accuracy for different audio classification tasks such as single-class wake word detection, multi-class keyword detection, and voice activity detection, which are superior to the related work.

</p>
</details>

<details><summary><b>Impact of dataset size and long-term ECoG-based BCI usage on deep learning decoders performance</b>
<a href="https://arxiv.org/abs/2209.03789">arxiv:2209.03789</a>
&#x1F4C8; 1 <br>
<p>Maciej Śliwowski, Matthieu Martin, Antoine Souloumiac, Pierre Blanchart, Tetiana Aksenova</p></summary>
<p>

**Abstract:** In brain-computer interfaces (BCI) research, recording data is time-consuming and expensive, which limits access to big datasets. This may influence the BCI system performance as machine learning methods depend strongly on the training dataset size. Important questions arise: taking into account neuronal signal characteristics (e.g., non-stationarity), can we achieve higher decoding performance with more data to train decoders? What is the perspective for further improvement with time in the case of long-term BCI studies? In this study, we investigated the impact of long-term recordings on motor imagery decoding from two main perspectives: model requirements regarding dataset size and potential for patient adaptation. We evaluated the multilinear model and two deep learning (DL) models on a long-term BCI and Tetraplegia NCT02550522 clinical trial dataset containing 43 sessions of ECoG recordings performed with a tetraplegic patient. In the experiment, a participant executed 3D virtual hand translation using motor imagery patterns. We designed multiple computational experiments in which training datasets were increased or translated to investigate the relationship between models' performance and different factors influencing recordings. Our analysis showed that adding more data to the training dataset may not instantly increase performance for datasets already containing 40 minutes of the signal. DL decoders showed similar requirements regarding the dataset size compared to the multilinear model while demonstrating higher decoding performance. Moreover, high decoding performance was obtained with relatively small datasets recorded later in the experiment, suggesting motor imagery patterns improvement and patient adaptation. Finally, we proposed UMAP embeddings and local intrinsic dimensionality as a way to visualize the data and potentially evaluate data quality.

</p>
</details>

<details><summary><b>Knowledge-Driven Program Synthesis via Adaptive Replacement Mutation and Auto-constructed Subprogram Archives</b>
<a href="https://arxiv.org/abs/2209.03736">arxiv:2209.03736</a>
&#x1F4C8; 1 <br>
<p>Yifan He, Claus Aranha, Tetsuya Sakurai</p></summary>
<p>

**Abstract:** We introduce Knowledge-Driven Program Synthesis (KDPS) as a variant of the program synthesis task that requires the agent to solve a sequence of program synthesis problems. In KDPS, the agent should use knowledge from the earlier problems to solve the later ones. We propose a novel method based on PushGP to solve the KDPS problem, which takes subprograms as knowledge. The proposed method extracts subprograms from the solution of previously solved problems by the Even Partitioning (EP) method and uses these subprograms to solve the upcoming programming task using Adaptive Replacement Mutation (ARM). We call this method PushGP+EP+ARM. With PushGP+EP+ARM, no human effort is required in the knowledge extraction and utilization processes. We compare the proposed method with PushGP, as well as a method using subprograms manually extracted by a human. Our PushGP+EP+ARM achieves better train error, success count, and faster convergence than PushGP. Additionally, we demonstrate the superiority of PushGP+EP+ARM when consecutively solving a sequence of six program synthesis problems.

</p>
</details>

<details><summary><b>T$^2$LR-Net: An Unrolling Reconstruction Network Learning Transformed Tensor Low-Rank prior for Dynamic MR Imaging</b>
<a href="https://arxiv.org/abs/2209.03832">arxiv:2209.03832</a>
&#x1F4C8; 0 <br>
<p>Yinghao Zhang, Yue Hu</p></summary>
<p>

**Abstract:** While the methods exploiting the tensor low-rank prior are booming in high-dimensional data processing and have obtained satisfying performance, their applications in dynamic magnetic resonance (MR) image reconstruction are limited. In this paper, we concentrate on the tensor singular value decomposition (t-SVD), which is based on the Fast Fourier Transform (FFT) and only provides the definite and limited tensor low-rank prior in the FFT domain, heavily reliant upon how closely the data and the FFT domain match up. By generalizing the FFT into an arbitrary unitary transformation of the transformed t-SVD and proposing the transformed tensor nuclear norm (TTNN), we introduce a flexible model based on TTNN with the ability to exploit the tensor low-rank prior of a transformed domain in a larger transformation space and elaborately design an iterative optimization algorithm based on the alternating direction method of multipliers (ADMM), which is further unrolled into a model-based deep unrolling reconstruction network to learn the transformed tensor low-rank prior (T$^2$LR-Net). The convolutional neural network (CNN) is incorporated within the T$^2$LR-Net to learn the best-matched transform from the dynamic MR image dataset. The unrolling reconstruction network also provides a new perspective on the low-rank prior utilization by exploiting the low-rank prior in the CNN-extracted feature domain. Experimental results on two cardiac cine MR datasets demonstrate that the proposed framework can provide improved recovery results compared with the state-of-the-art optimization-based and unrolling network-based methods.

</p>
</details>

<details><summary><b>Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints</b>
<a href="https://arxiv.org/abs/2209.03668">arxiv:2209.03668</a>
&#x1F4C8; 0 <br>
<p>Xinyi Hu, Jasper C. H. Lee, Jimmy H. M. Lee</p></summary>
<p>

**Abstract:** Predict+Optimize is a recently proposed framework which combines machine learning and constrained optimization, tackling optimization problems that contain parameters that are unknown at solving time. The goal is to predict the unknown parameters and use the estimates to solve for an estimated optimal solution to the optimization problem. However, all prior works have focused on the case where unknown parameters appear only in the optimization objective and not the constraints, for the simple reason that if the constraints were not known exactly, the estimated optimal solution might not even be feasible under the true parameters. The contributions of this paper are two-fold. First, we propose a novel and practically relevant framework for the Predict+Optimize setting, but with unknown parameters in both the objective and the constraints. We introduce the notion of a correction function, and an additional penalty term in the loss function, modelling practical scenarios where an estimated optimal solution can be modified into a feasible solution after the true parameters are revealed, but at an additional cost. Second, we propose a corresponding algorithmic approach for our framework, which handles all packing and covering linear programs. Our approach is inspired by the prior work of Mandi and Guns, though with crucial modifications and re-derivations for our very different setting. Experimentation demonstrates the superior empirical performance of our method over classical approaches.

</p>
</details>


{% endraw %}
Prev: [2022.09.07]({{ '/2022/09/07/2022.09.07.html' | relative_url }})  Next: [2022.09.09]({{ '/2022/09/09/2022.09.09.html' | relative_url }})