## Summary for 2021-07-20, created on 2021-12-19


<details><summary><b>WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset</b>
<a href="https://arxiv.org/abs/2107.09556">arxiv:2107.09556</a>
&#x1F4C8; 94 <br>
<p>Luyu Wang, Yujia Li, Ozlem Aslan, Oriol Vinyals</p></summary>
<p>

**Abstract:** We present a new dataset of Wikipedia articles each paired with a knowledge graph, to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new dataset WikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and transformer model results on our dataset for 3 tasks: graph -> text generation, graph -> text retrieval and text -> graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement.

</p>
</details>

<details><summary><b>Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2107.09645">arxiv:2107.09645</a>
&#x1F4C8; 33 <br>
<p>Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto</p></summary>
<p>

**Abstract:** We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for visual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic approach that uses data augmentation to learn directly from pixels. We introduce several improvements that yield state-of-the-art results on the DeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid locomotion tasks directly from pixel observations, previously unattained by model-free RL. DrQ-v2 is conceptually simple, easy to implement, and provides significantly better computational footprint compared to prior work, with the majority of tasks taking just 8 hours to train on a single GPU. Finally, we publicly release DrQ-v2's implementation to provide RL practitioners with a strong and computationally efficient baseline.

</p>
</details>

<details><summary><b>Statistical Estimation from Dependent Data</b>
<a href="https://arxiv.org/abs/2107.09773">arxiv:2107.09773</a>
&#x1F4C8; 25 <br>
<p>Yuval Dagan, Constantinos Daskalakis, Nishanth Dikkala, Surbhi Goel, Anthimos Vardis Kandiros</p></summary>
<p>

**Abstract:** We consider a general statistical estimation problem wherein binary labels across different observations are not independent conditioned on their feature vectors, but dependent, capturing settings where e.g. these observations are collected on a spatial domain, a temporal domain, or a social network, which induce dependencies. We model these dependencies in the language of Markov Random Fields and, importantly, allow these dependencies to be substantial, i.e do not assume that the Markov Random Field capturing these dependencies is in high temperature. As our main contribution we provide algorithms and statistically efficient estimation rates for this model, giving several instantiations of our bounds in logistic regression, sparse logistic regression, and neural network settings with dependent data. Our estimation guarantees follow from novel results for estimating the parameters (i.e. external fields and interaction strengths) of Ising models from a {\em single} sample. {We evaluate our estimation approach on real networked data, showing that it outperforms standard regression approaches that ignore dependencies, across three text classification datasets: Cora, Citeseer and Pubmed.}

</p>
</details>

<details><summary><b>QVHighlights: Detecting Moments and Highlights in Videos via Natural Language Queries</b>
<a href="https://arxiv.org/abs/2107.09609">arxiv:2107.09609</a>
&#x1F4C8; 19 <br>
<p>Jie Lei, Tamara L. Berg, Mohit Bansal</p></summary>
<p>

**Abstract:** Detecting customized moments and highlights from videos given natural language (NL) user queries is an important but under-studied topic. One of the challenges in pursuing this direction is the lack of annotated data. To address this issue, we present the Query-based Video Highlights (QVHIGHLIGHTS) dataset. It consists of over 10,000 YouTube videos, covering a wide range of topics, from everyday activities and travel in lifestyle vlog videos to social and political activities in news videos. Each video in the dataset is annotated with: (1) a human-written free-form NL query, (2) relevant moments in the video w.r.t. the query, and (3) five-point scale saliency scores for all query-relevant clips. This comprehensive annotation enables us to develop and evaluate systems that detect relevant moments as well as salient highlights for diverse, flexible user queries. We also present a strong baseline for this task, Moment-DETR, a transformer encoder-decoder model that views moment retrieval as a direct set prediction problem, taking extracted video and query representations as inputs and predicting moment coordinates and saliency scores end-to-end. While our model does not utilize any human prior, we show that it performs competitively when compared to well-engineered architectures. With weakly supervised pretraining using ASR captions, MomentDETR substantially outperforms previous methods. Lastly, we present several ablations and visualizations of Moment-DETR. Data and code is publicly available at https://github.com/jayleicn/moment_detr

</p>
</details>

<details><summary><b>Characterizing Generalization under Out-Of-Distribution Shifts in Deep Metric Learning</b>
<a href="https://arxiv.org/abs/2107.09562">arxiv:2107.09562</a>
&#x1F4C8; 19 <br>
<p>Timo Milbich, Karsten Roth, Samarth Sinha, Ludwig Schmidt, Marzyeh Ghassemi, Bj√∂rn Ommer</p></summary>
<p>

**Abstract:** Deep Metric Learning (DML) aims to find representations suitable for zero-shot transfer to a priori unknown test distributions. However, common evaluation protocols only test a single, fixed data split in which train and test classes are assigned randomly. More realistic evaluations should consider a broad spectrum of distribution shifts with potentially varying degree and difficulty. In this work, we systematically construct train-test splits of increasing difficulty and present the ooDML benchmark to characterize generalization under out-of-distribution shifts in DML. ooDML is designed to probe the generalization performance on much more challenging, diverse train-to-test distribution shifts. Based on our new benchmark, we conduct a thorough empirical analysis of state-of-the-art DML methods. We find that while generalization tends to consistently degrade with difficulty, some methods are better at retaining performance as the distribution shift increases. Finally, we propose few-shot DML as an efficient way to consistently improve generalization in response to unknown test shifts presented in ooDML. Code available here: https://github.com/CompVis/Characterizing_Generalization_in_DML.

</p>
</details>

<details><summary><b>ReSSL: Relational Self-Supervised Learning with Weak Augmentation</b>
<a href="https://arxiv.org/abs/2107.09282">arxiv:2107.09282</a>
&#x1F4C8; 14 <br>
<p>Mingkai Zheng, Shan You, Fei Wang, Chen Qian, Changshui Zhang, Xiaogang Wang, Chang Xu</p></summary>
<p>

**Abstract:** Self-supervised Learning (SSL) including the mainstream contrastive learning has achieved great success in learning visual representations without data annotations. However, most of methods mainly focus on the instance level information (\ie, the different augmented images of the same instance should have the same feature or cluster into the same class), but there is a lack of attention on the relationships between different instances. In this paper, we introduced a novel SSL paradigm, which we term as relational self-supervised learning (ReSSL) framework that learns representations by modeling the relationship between different instances. Specifically, our proposed method employs sharpened distribution of pairwise similarities among different instances as \textit{relation} metric, which is thus utilized to match the feature embeddings of different augmentations. Moreover, to boost the performance, we argue that weak augmentations matter to represent a more reliable relation, and leverage momentum strategy for practical efficiency. Experimental results show that our proposed ReSSL significantly outperforms the previous state-of-the-art algorithms in terms of both performance and training efficiency. Code is available at \url{https://github.com/KyleZheng1997/ReSSL}.

</p>
</details>

<details><summary><b>Audio Captioning Transformer</b>
<a href="https://arxiv.org/abs/2107.09817">arxiv:2107.09817</a>
&#x1F4C8; 13 <br>
<p>Xinhao Mei, Xubo Liu, Qiushi Huang, Mark D. Plumbley, Wenwu Wang</p></summary>
<p>

**Abstract:** Audio captioning aims to automatically generate a natural language description of an audio clip. Most captioning models follow an encoder-decoder architecture, where the decoder predicts words based on the audio features extracted by the encoder. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) are often used as the audio encoder. However, CNNs can be limited in modelling temporal relationships among the time frames in an audio signal, while RNNs can be limited in modelling the long-range dependencies among the time frames. In this paper, we propose an Audio Captioning Transformer (ACT), which is a full Transformer network based on an encoder-decoder architecture and is totally convolution-free. The proposed method has a better ability to model the global information within an audio signal as well as capture temporal relationships between audio events. We evaluate our model on AudioCaps, which is the largest audio captioning dataset publicly available. Our model shows competitive performance compared to other state-of-the-art approaches.

</p>
</details>

<details><summary><b>Large-scale graph representation learning with very deep GNNs and self-supervision</b>
<a href="https://arxiv.org/abs/2107.09422">arxiv:2107.09422</a>
&#x1F4C8; 12 <br>
<p>Ravichandra Addanki, Peter W. Battaglia, David Budden, Andreea Deac, Jonathan Godwin, Thomas Keck, Wai Lok Sibon Li, Alvaro Sanchez-Gonzalez, Jacklynn Stott, Shantanu Thakoor, Petar Veliƒçkoviƒá</p></summary>
<p>

**Abstract:** Effectively and efficiently deploying graph neural networks (GNNs) at scale remains one of the most challenging aspects of graph representation learning. Many powerful solutions have only ever been validated on comparatively small datasets, often with counter-intuitive outcomes -- a barrier which has been broken by the Open Graph Benchmark Large-Scale Challenge (OGB-LSC). We entered the OGB-LSC with two large-scale GNNs: a deep transductive node classifier powered by bootstrapping, and a very deep (up to 50-layer) inductive graph regressor regularised by denoising objectives. Our models achieved an award-level (top-3) performance on both the MAG240M and PCQM4M benchmarks. In doing so, we demonstrate evidence of scalable self-supervised graph representation learning, and utility of very deep GNNs -- both very important open issues. Our code is publicly available at: https://github.com/deepmind/deepmind-research/tree/master/ogb_lsc.

</p>
</details>

<details><summary><b>Critic Guided Segmentation of Rewarding Objects in First-Person Views</b>
<a href="https://arxiv.org/abs/2107.09540">arxiv:2107.09540</a>
&#x1F4C8; 10 <br>
<p>Andrew Melnik, Augustin Harter, Christian Limberg, Krishan Rana, Niko Suenderhauf, Helge Ritter</p></summary>
<p>

**Abstract:** This work discusses a learning approach to mask rewarding objects in images using sparse reward signals from an imitation learning dataset. For that, we train an Hourglass network using only feedback from a critic model. The Hourglass network learns to produce a mask to decrease the critic's score of a high score image and increase the critic's score of a low score image by swapping the masked areas between these two images. We trained the model on an imitation learning dataset from the NeurIPS 2020 MineRL Competition Track, where our model learned to mask rewarding objects in a complex interactive 3D environment with a sparse reward signal. This approach was part of the 1st place winning solution in this competition. Video demonstration and code: https://rebrand.ly/critic-guided-segmentation

</p>
</details>

<details><summary><b>3D-StyleGAN: A Style-Based Generative Adversarial Network for Generative Modeling of Three-Dimensional Medical Images</b>
<a href="https://arxiv.org/abs/2107.09700">arxiv:2107.09700</a>
&#x1F4C8; 9 <br>
<p>Sungmin Hong, Razvan Marinescu, Adrian V. Dalca, Anna K. Bonkhoff, Martin Bretzner, Natalia S. Rost, Polina Golland</p></summary>
<p>

**Abstract:** Image synthesis via Generative Adversarial Networks (GANs) of three-dimensional (3D) medical images has great potential that can be extended to many medical applications, such as, image enhancement and disease progression modeling. However, current GAN technologies for 3D medical image synthesis need to be significantly improved to be readily adapted to real-world medical problems. In this paper, we extend the state-of-the-art StyleGAN2 model, which natively works with two-dimensional images, to enable 3D image synthesis. In addition to the image synthesis, we investigate the controllability and interpretability of the 3D-StyleGAN via style vectors inherited form the original StyleGAN2 that are highly suitable for medical applications: (i) the latent space projection and reconstruction of unseen real images, and (ii) style mixing. We demonstrate the 3D-StyleGAN's performance and feasibility with ~12,000 three-dimensional full brain MR T1 images, although it can be applied to any 3D volumetric images. Furthermore, we explore different configurations of hyperparameters to investigate potential improvement of the image synthesis with larger networks. The codes and pre-trained networks are available online: https://github.com/sh4174/3DStyleGAN.

</p>
</details>

<details><summary><b>Bayesian Controller Fusion: Leveraging Control Priors in Deep Reinforcement Learning for Robotics</b>
<a href="https://arxiv.org/abs/2107.09822">arxiv:2107.09822</a>
&#x1F4C8; 8 <br>
<p>Krishan Rana, Vibhavari Dasagi, Jesse Haviland, Ben Talbot, Michael Milford, Niko S√ºnderhauf</p></summary>
<p>

**Abstract:** We present Bayesian Controller Fusion (BCF): a hybrid control strategy that combines the strengths of traditional hand-crafted controllers and model-free deep reinforcement learning (RL). BCF thrives in the robotics domain, where reliable but suboptimal control priors exist for many tasks, but RL from scratch remains unsafe and data-inefficient. By fusing uncertainty-aware distributional outputs from each system, BCF arbitrates control between them, exploiting their respective strengths. We study BCF on two real-world robotics tasks involving navigation in a vast and long-horizon environment, and a complex reaching task that involves manipulability maximisation. For both these domains, there exist simple handcrafted controllers that can solve the task at hand in a risk-averse manner but do not necessarily exhibit the optimal solution given limitations in analytical modelling, controller miscalibration and task variation. As exploration is naturally guided by the prior in the early stages of training, BCF accelerates learning, while substantially improving beyond the performance of the control prior, as the policy gains more experience. More importantly, given the risk-aversity of the control prior, BCF ensures safe exploration and deployment, where the control prior naturally dominates the action distribution in states unknown to the policy. We additionally show BCF's applicability to the zero-shot sim-to-real setting and its ability to deal with out-of-distribution states in the real-world. BCF is a promising approach for combining the complementary strengths of deep RL and traditional robotic control, surpassing what either can achieve independently. The code and supplementary video material are made publicly available at https://krishanrana.github.io/bcf.

</p>
</details>

<details><summary><b>Built-in Elastic Transformations for Improved Robustness</b>
<a href="https://arxiv.org/abs/2107.09391">arxiv:2107.09391</a>
&#x1F4C8; 8 <br>
<p>Sadaf Gulshad, Ivan Sosnovik, Arnold Smeulders</p></summary>
<p>

**Abstract:** We focus on building robustness in the convolutions of neural visual classifiers, especially against natural perturbations like elastic deformations, occlusions and Gaussian noise. Existing CNNs show outstanding performance on clean images, but fail to tackle naturally occurring perturbations. In this paper, we start from elastic perturbations, which approximate (local) view-point changes of the object. We present elastically-augmented convolutions (EAConv) by parameterizing filters as a combination of fixed elastically-perturbed bases functions and trainable weights for the purpose of integrating unseen viewpoints in the CNN. We show on CIFAR-10 and STL-10 datasets that the general robustness of our method on unseen occlusion, zoom, rotation, image cut and Gaussian perturbations improves, while significantly improving the performance on clean images without any data augmentation.

</p>
</details>

<details><summary><b>A Bayesian Approach to Invariant Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2107.09301">arxiv:2107.09301</a>
&#x1F4C8; 8 <br>
<p>Nikolaos Mourdoukoutas, Marco Federici, Georges Pantalos, Mark van der Wilk, Vincent Fortuin</p></summary>
<p>

**Abstract:** We propose a novel Bayesian neural network architecture that can learn invariances from data alone by inferring a posterior distribution over different weight-sharing schemes. We show that our model outperforms other non-invariant architectures, when trained on datasets that contain specific invariances. The same holds true when no data augmentation is performed.

</p>
</details>

<details><summary><b>Neural Abstructions: Abstractions that Support Construction for Grounded Language Learning</b>
<a href="https://arxiv.org/abs/2107.09285">arxiv:2107.09285</a>
&#x1F4C8; 8 <br>
<p>Kaylee Burns, Christopher D. Manning, Li Fei-Fei</p></summary>
<p>

**Abstract:** Although virtual agents are increasingly situated in environments where natural language is the most effective mode of interaction with humans, these exchanges are rarely used as an opportunity for learning. Leveraging language interactions effectively requires addressing limitations in the two most common approaches to language grounding: semantic parsers built on top of fixed object categories are precise but inflexible and end-to-end models are maximally expressive, but fickle and opaque. Our goal is to develop a system that balances the strengths of each approach so that users can teach agents new instructions that generalize broadly from a single example. We introduce the idea of neural abstructions: a set of constraints on the inference procedure of a label-conditioned generative model that can affect the meaning of the label in context. Starting from a core programming language that operates over abstructions, users can define increasingly complex mappings from natural language to actions. We show that with this method a user population is able to build a semantic parser for an open-ended house modification task in Minecraft. The semantic parser that results is both flexible and expressive: the percentage of utterances sourced from redefinitions increases steadily over the course of 191 total exchanges, achieving a final value of 28%.

</p>
</details>

<details><summary><b>Different kinds of cognitive plausibility: why are transformers better than RNNs at predicting N400 amplitude?</b>
<a href="https://arxiv.org/abs/2107.09648">arxiv:2107.09648</a>
&#x1F4C8; 7 <br>
<p>James A. Michaelov, Megan D. Bardolph, Seana Coulson, Benjamin K. Bergen</p></summary>
<p>

**Abstract:** Despite being designed for performance rather than cognitive plausibility, transformer language models have been found to be better at predicting metrics used to assess human language comprehension than language models with other architectures, such as recurrent neural networks. Based on how well they predict the N400, a neural signal associated with processing difficulty, we propose and provide evidence for one possible explanation - their predictions are affected by the preceding context in a way analogous to the effect of semantic facilitation in humans.

</p>
</details>

<details><summary><b>A Review of Generative Adversarial Networks in Cancer Imaging: New Applications, New Solutions</b>
<a href="https://arxiv.org/abs/2107.09543">arxiv:2107.09543</a>
&#x1F4C8; 7 <br>
<p>Richard Osuala, Kaisar Kushibar, Lidia Garrucho, Akis Linardos, Zuzanna Szafranowska, Stefan Klein, Ben Glocker, Oliver Diaz, Karim Lekadir</p></summary>
<p>

**Abstract:** Despite technological and medical advances, the detection, interpretation, and treatment of cancer based on imaging data continue to pose significant challenges. These include high inter-observer variability, difficulty of small-sized lesion detection, nodule interpretation and malignancy determination, inter- and intra-tumour heterogeneity, class imbalance, segmentation inaccuracies, and treatment effect uncertainty. The recent advancements in Generative Adversarial Networks (GANs) in computer vision as well as in medical imaging may provide a basis for enhanced capabilities in cancer detection and analysis. In this review, we assess the potential of GANs to address a number of key challenges of cancer imaging, including data scarcity and imbalance, domain and dataset shifts, data access and privacy, data annotation and quantification, as well as cancer detection, tumour profiling and treatment planning. We provide a critical appraisal of the existing literature of GANs applied to cancer imagery, together with suggestions on future research directions to address these challenges. We analyse and discuss 163 papers that apply adversarial training techniques in the context of cancer imaging and elaborate their methodologies, advantages and limitations. With this work, we strive to bridge the gap between the needs of the clinical cancer imaging community and the current and prospective research on GANs in the artificial intelligence community.

</p>
</details>

<details><summary><b>Open Problem: Is There an Online Learning Algorithm That Learns Whenever Online Learning Is Possible?</b>
<a href="https://arxiv.org/abs/2107.09542">arxiv:2107.09542</a>
&#x1F4C8; 7 <br>
<p>Steve Hanneke</p></summary>
<p>

**Abstract:** This open problem asks whether there exists an online learning algorithm for binary classification that guarantees, for all target concepts, to make a sublinear number of mistakes, under only the assumption that the (possibly random) sequence of points X allows that such a learning algorithm can exist for that sequence. As a secondary problem, it also asks whether a specific concise condition completely determines whether a given (possibly random) sequence of points X admits the existence of online learning algorithms guaranteeing a sublinear number of mistakes for all target concepts.

</p>
</details>

<details><summary><b>Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models</b>
<a href="https://arxiv.org/abs/2107.09428">arxiv:2107.09428</a>
&#x1F4C8; 7 <br>
<p>Tianzi Wang, Yuya Fujita, Xuankai Chang, Shinji Watanabe</p></summary>
<p>

**Abstract:** Non-autoregressive (NAR) modeling has gained more and more attention in speech processing. With recent state-of-the-art attention-based automatic speech recognition (ASR) structure, NAR can realize promising real-time factor (RTF) improvement with only small degradation of accuracy compared to the autoregressive (AR) models. However, the recognition inference needs to wait for the completion of a full speech utterance, which limits their applications on low latency scenarios. To address this issue, we propose a novel end-to-end streaming NAR speech recognition system by combining blockwise-attention and connectionist temporal classification with mask-predict (Mask-CTC) NAR. During inference, the input audio is separated into small blocks and then processed in a blockwise streaming way. To address the insertion and deletion error at the edge of the output of each block, we apply an overlapping decoding strategy with a dynamic mapping trick that can produce more coherent sentences. Experimental results show that the proposed method improves online ASR recognition in low latency conditions compared to vanilla Mask-CTC. Moreover, it can achieve a much faster inference speed compared to the AR attention-based models. All of our codes will be publicly available at https://github.com/espnet/espnet.

</p>
</details>

<details><summary><b>An Empirical Analysis of Measure-Valued Derivatives for Policy Gradients</b>
<a href="https://arxiv.org/abs/2107.09359">arxiv:2107.09359</a>
&#x1F4C8; 7 <br>
<p>Jo√£o Carvalho, Davide Tateo, Fabio Muratore, Jan Peters</p></summary>
<p>

**Abstract:** Reinforcement learning methods for robotics are increasingly successful due to the constant development of better policy gradient techniques. A precise (low variance) and accurate (low bias) gradient estimator is crucial to face increasingly complex tasks. Traditional policy gradient algorithms use the likelihood-ratio trick, which is known to produce unbiased but high variance estimates. More modern approaches exploit the reparametrization trick, which gives lower variance gradient estimates but requires differentiable value function approximators. In this work, we study a different type of stochastic gradient estimator: the Measure-Valued Derivative. This estimator is unbiased, has low variance, and can be used with differentiable and non-differentiable function approximators. We empirically evaluate this estimator in the actor-critic policy gradient setting and show that it can reach comparable performance with methods based on the likelihood-ratio or reparametrization tricks, both in low and high-dimensional action spaces.

</p>
</details>

<details><summary><b>Approximation Theory of Convolutional Architectures for Time Series Modelling</b>
<a href="https://arxiv.org/abs/2107.09355">arxiv:2107.09355</a>
&#x1F4C8; 7 <br>
<p>Haotian Jiang, Zhong Li, Qianxiao Li</p></summary>
<p>

**Abstract:** We study the approximation properties of convolutional architectures applied to time series modelling, which can be formulated mathematically as a functional approximation problem. In the recurrent setting, recent results reveal an intricate connection between approximation efficiency and memory structures in the data generation process. In this paper, we derive parallel results for convolutional architectures, with WaveNet being a prime example. Our results reveal that in this new setting, approximation efficiency is not only characterised by memory, but also additional fine structures in the target relationship. This leads to a novel definition of spectrum-based regularity that measures the complexity of temporal relationships under the convolutional approximation scheme. These analyses provide a foundation to understand the differences between architectural choices for time series modelling and can give theoretically grounded guidance for practical applications.

</p>
</details>

<details><summary><b>SynthSeg: Domain Randomisation for Segmentation of Brain MRI Scans of any Contrast and Resolution</b>
<a href="https://arxiv.org/abs/2107.09559">arxiv:2107.09559</a>
&#x1F4C8; 6 <br>
<p>Benjamin Billot, Douglas N. Greve, Oula Puonti, Axel Thielscher, Koen Van Leemput, Bruce Fischl, Adrian V. Dalca, Juan Eugenio Iglesias</p></summary>
<p>

**Abstract:** Despite advances in data augmentation and transfer learning, convolutional neural networks (CNNs) have difficulties generalising to unseen target domains. When applied to segmentation of brain MRI scans, CNNs are highly sensitive to changes in resolution and contrast: even within the same MR modality, decreases in performance can be observed across datasets. We introduce SynthSeg, the first segmentation CNN agnostic to brain MRI scans of any contrast and resolution. SynthSeg is trained with synthetic data sampled from a generative model inspired by Bayesian segmentation. Crucially, we adopt a \textit{domain randomisation} strategy where we fully randomise the generation parameters to maximise the variability of the training data. Consequently, SynthSeg can segment preprocessed and unpreprocessed real scans of any target domain, without retraining or fine-tuning. Because SynthSeg only requires segmentations to be trained (no images), it can learn from label maps obtained automatically from existing datasets of different populations (e.g., with atrophy and lesions), thus achieving robustness to a wide range of morphological variability. We demonstrate SynthSeg on 5,500 scans of 6 modalities and 10 resolutions, where it exhibits unparalleled generalisation compared to supervised CNNs, test time adaptation, and Bayesian segmentation. The code and trained model are available at https://github.com/BBillot/SynthSeg.

</p>
</details>

<details><summary><b>FoleyGAN: Visually Guided Generative Adversarial Network-Based Synchronous Sound Generation in Silent Videos</b>
<a href="https://arxiv.org/abs/2107.09262">arxiv:2107.09262</a>
&#x1F4C8; 5 <br>
<p>Sanchita Ghose, John J. Prevost</p></summary>
<p>

**Abstract:** Deep learning based visual to sound generation systems essentially need to be developed particularly considering the synchronicity aspects of visual and audio features with time. In this research we introduce a novel task of guiding a class conditioned generative adversarial network with the temporal visual information of a video input for visual to sound generation task adapting the synchronicity traits between audio-visual modalities. Our proposed FoleyGAN model is capable of conditioning action sequences of visual events leading towards generating visually aligned realistic sound tracks. We expand our previously proposed Automatic Foley dataset to train with FoleyGAN and evaluate our synthesized sound through human survey that shows noteworthy (on average 81\%) audio-visual synchronicity performance. Our approach also outperforms in statistical experiments compared with other baseline models and audio-visual datasets.

</p>
</details>

<details><summary><b>Neural Variational Learning for Grounded Language Acquisition</b>
<a href="https://arxiv.org/abs/2107.14593">arxiv:2107.14593</a>
&#x1F4C8; 4 <br>
<p>Nisha Pillai, Cynthia Matuszek, Francis Ferraro</p></summary>
<p>

**Abstract:** We propose a learning system in which language is grounded in visual percepts without specific pre-defined categories of terms. We present a unified generative method to acquire a shared semantic/visual embedding that enables the learning of language about a wide range of real-world objects. We evaluate the efficacy of this learning by predicting the semantics of objects and comparing the performance with neural and non-neural inputs. We show that this generative approach exhibits promising results in language grounding without pre-specifying visual categories under low resource settings. Our experiments demonstrate that this approach is generalizable to multilingual, highly varied datasets.

</p>
</details>

<details><summary><b>Structure-aware Interactive Graph Neural Networks for the Prediction of Protein-Ligand Binding Affinity</b>
<a href="https://arxiv.org/abs/2107.10670">arxiv:2107.10670</a>
&#x1F4C8; 4 <br>
<p>Shuangli Li, Jingbo Zhou, Tong Xu, Liang Huang, Fan Wang, Haoyi Xiong, Weili Huang, Dejing Dou, Hui Xiong</p></summary>
<p>

**Abstract:** Drug discovery often relies on the successful prediction of protein-ligand binding affinity. Recent advances have shown great promise in applying graph neural networks (GNNs) for better affinity prediction by learning the representations of protein-ligand complexes. However, existing solutions usually treat protein-ligand complexes as topological graph data, thus the biomolecular structural information is not fully utilized. The essential long-range interactions among atoms are also neglected in GNN models. To this end, we propose a structure-aware interactive graph neural network (SIGN) which consists of two components: polar-inspired graph attention layers (PGAL) and pairwise interactive pooling (PiPool). Specifically, PGAL iteratively performs the node-edge aggregation process to update embeddings of nodes and edges while preserving the distance and angle information among atoms. Then, PiPool is adopted to gather interactive edges with a subsequent reconstruction loss to reflect the global interactions. Exhaustive experimental study on two benchmarks verifies the superiority of SIGN.

</p>
</details>

<details><summary><b>Manifold learning-based polynomial chaos expansions for high-dimensional surrogate models</b>
<a href="https://arxiv.org/abs/2107.09814">arxiv:2107.09814</a>
&#x1F4C8; 4 <br>
<p>Katiana Kontolati, Dimitrios Loukrezis, Ketson R. M. dos Santos, Dimitrios G. Giovanis, Michael D. Shields</p></summary>
<p>

**Abstract:** In this work we introduce a manifold learning-based method for uncertainty quantification (UQ) in systems describing complex spatiotemporal processes. Our first objective is to identify the embedding of a set of high-dimensional data representing quantities of interest of the computational or analytical model. For this purpose, we employ Grassmannian diffusion maps, a two-step nonlinear dimension reduction technique which allows us to reduce the dimensionality of the data and identify meaningful geometric descriptions in a parsimonious and inexpensive manner. Polynomial chaos expansion is then used to construct a mapping between the stochastic input parameters and the diffusion coordinates of the reduced space. An adaptive clustering technique is proposed to identify an optimal number of clusters of points in the latent space. The similarity of points allows us to construct a number of geometric harmonic emulators which are finally utilized as a set of inexpensive pre-trained models to perform an inverse map of realizations of latent features to the ambient space and thus perform accurate out-of-sample predictions. Thus, the proposed method acts as an encoder-decoder system which is able to automatically handle very high-dimensional data while simultaneously operating successfully in the small-data regime. The method is demonstrated on two benchmark problems and on a system of advection-diffusion-reaction equations which model a first-order chemical reaction between two species. In all test cases, the proposed method is able to achieve highly accurate approximations which ultimately lead to the significant acceleration of UQ tasks.

</p>
</details>

<details><summary><b>What Do You Get When You Cross Beam Search with Nucleus Sampling?</b>
<a href="https://arxiv.org/abs/2107.09729">arxiv:2107.09729</a>
&#x1F4C8; 4 <br>
<p>Uri Shaham, Omer Levy</p></summary>
<p>

**Abstract:** We combine beam search with the probabilistic pruning technique of nucleus sampling to create two deterministic nucleus search algorithms for natural language generation. The first algorithm, p-exact search, locally prunes the next-token distribution and performs an exact search over the remaining space. The second algorithm, dynamic beam search, shrinks and expands the beam size according to the entropy of the candidate's probability distribution. Despite the probabilistic intuition behind nucleus search, experiments on machine translation and summarization benchmarks show that both algorithms reach the same performance levels as standard beam search.

</p>
</details>

<details><summary><b>CogME: A Novel Evaluation Metric for Video Understanding Intelligence</b>
<a href="https://arxiv.org/abs/2107.09847">arxiv:2107.09847</a>
&#x1F4C8; 3 <br>
<p>Minjung Shin, Jeonghoon Kim, Seongho Choi, Yu-Jung Heo, Donghyun Kim, Minsu Lee, Byoung-Tak Zhang, Jeh-Kwang Ryu</p></summary>
<p>

**Abstract:** Developing video understanding intelligence is quite challenging because it requires holistic integration of images, scripts, and sounds based on natural language processing, temporal dependency, and reasoning. Recently, substantial attempts have been made on several video datasets with associated question answering (QA) on a large scale. However, existing evaluation metrics for video question answering (VideoQA) do not provide meaningful analysis. To make progress, we argue that a well-made framework, established on the way humans understand, is required to explain and evaluate the performance of understanding in detail. Then we propose a top-down evaluation system for VideoQA, based on the cognitive process of humans and story elements: Cognitive Modules for Evaluation (CogME). CogME is composed of three cognitive modules: targets, contents, and thinking. The interaction among the modules in the understanding procedure can be expressed in one sentence as follows: "I understand the CONTENT of the TARGET through a way of THINKING." Each module has sub-components derived from the story elements. We can specify the required aspects of understanding by annotating the sub-components to individual questions. CogME thus provides a framework for an elaborated specification of VideoQA datasets. To examine the suitability of a VideoQA dataset for validating video understanding intelligence, we evaluated the baseline model of the DramaQA dataset by applying CogME. The evaluation reveals that story elements are unevenly reflected in the existing dataset, and the model based on the dataset may cause biased predictions. Although this study has only been able to grasp a narrow range of stories, we expect that it offers the first step in considering the cognitive process of humans on the video understanding intelligence of humans and AI.

</p>
</details>

<details><summary><b>Private Alternating Least Squares: Practical Private Matrix Completion with Tighter Rates</b>
<a href="https://arxiv.org/abs/2107.09802">arxiv:2107.09802</a>
&#x1F4C8; 3 <br>
<p>Steve Chien, Prateek Jain, Walid Krichene, Steffen Rendle, Shuang Song, Abhradeep Thakurta, Li Zhang</p></summary>
<p>

**Abstract:** We study the problem of differentially private (DP) matrix completion under user-level privacy. We design a joint differentially private variant of the popular Alternating-Least-Squares (ALS) method that achieves: i) (nearly) optimal sample complexity for matrix completion (in terms of number of items, users), and ii) the best known privacy/utility trade-off both theoretically, as well as on benchmark data sets. In particular, we provide the first global convergence analysis of ALS with noise introduced to ensure DP, and show that, in comparison to the best known alternative (the Private Frank-Wolfe algorithm by Jain et al. (2018)), our error bounds scale significantly better with respect to the number of items and users, which is critical in practical problems. Extensive validation on standard benchmarks demonstrate that the algorithm, in combination with carefully designed sampling procedures, is significantly more accurate than existing techniques, thus promising to be the first practical DP embedding model.

</p>
</details>

<details><summary><b>DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2107.09600">arxiv:2107.09600</a>
&#x1F4C8; 3 <br>
<p>Li Gao, Jing Zhang, Lefei Zhang, Dacheng Tao</p></summary>
<p>

**Abstract:** Unsupervised domain adaptation (UDA) for semantic segmentation aims to adapt a segmentation model trained on the labeled source domain to the unlabeled target domain. Existing methods try to learn domain invariant features while suffering from large domain gaps that make it difficult to correctly align discrepant features, especially in the initial training phase. To address this issue, we propose a novel Dual Soft-Paste (DSP) method in this paper. Specifically, DSP selects some classes from a source domain image using a long-tail class first sampling strategy and softly pastes the corresponding image patch on both the source and target training images with a fusion weight. Technically, we adopt the mean teacher framework for domain adaptation, where the pasted source and target images go through the student network while the original target image goes through the teacher network. Output-level alignment is carried out by aligning the probability maps of the target fused image from both networks using a weighted cross-entropy loss. In addition, feature-level alignment is carried out by aligning the feature maps of the source and target images from student network using a weighted maximum mean discrepancy loss. DSP facilitates the model learning domain-invariant features from the intermediate domains, leading to faster convergence and better performance. Experiments on two challenging benchmarks demonstrate the superiority of DSP over state-of-the-art methods. Code is available at \url{https://github.com/GaoLii/DSP}.

</p>
</details>

<details><summary><b>Learning Altruistic Behaviours in Reinforcement Learning without External Rewards</b>
<a href="https://arxiv.org/abs/2107.09598">arxiv:2107.09598</a>
&#x1F4C8; 3 <br>
<p>Tim Franzmeyer, Mateusz Malinowski, Jo√£o F. Henriques</p></summary>
<p>

**Abstract:** Can artificial agents learn to assist others in achieving their goals without knowing what those goals are? Generic reinforcement learning agents could be trained to behave altruistically towards others by rewarding them for altruistic behaviour, i.e., rewarding them for benefiting other agents in a given situation. Such an approach assumes that other agents' goals are known so that the altruistic agent can cooperate in achieving those goals. However, explicit knowledge of other agents' goals is often difficult to acquire. In the case of human agents, their goals and preferences may be difficult to express fully, may be ambiguous or even contradictory. Thus, it is beneficial to develop agents that do not depend on external supervision and can learn altruistic behaviour in a task-agnostic manner. We propose to act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals. Some concrete examples include opening a door for others or safeguarding them to pursue their objectives without interference. We formalize this concept and propose an altruistic agent that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. We evaluate our approach on three different multi-agent environments where another agent's success depends on the altruistic agent's behaviour. Finally, we show that our unsupervised agents can perform comparably to agents explicitly trained to work cooperatively, in some cases even outperforming them.

</p>
</details>

<details><summary><b>Canonical Polyadic Decomposition and Deep Learning for Machine Fault Detection</b>
<a href="https://arxiv.org/abs/2107.09519">arxiv:2107.09519</a>
&#x1F4C8; 3 <br>
<p>Frusque Gaetan, Michau Gabriel, Fink Olga</p></summary>
<p>

**Abstract:** Acoustic monitoring for machine fault detection is a recent and expanding research path that has already provided promising results for industries. However, it is impossible to collect enough data to learn all types of faults from a machine. Thus, new algorithms, trained using data from healthy conditions only, were developed to perform unsupervised anomaly detection. A key issue in the development of these algorithms is the noise in the signals, as it impacts the anomaly detection performance. In this work, we propose a powerful data-driven and quasi non-parametric denoising strategy for spectral data based on a tensor decomposition: the Non-negative Canonical Polyadic (CP) decomposition. This method is particularly adapted for machine emitting stationary sound. We demonstrate in a case study, the Malfunctioning Industrial Machine Investigation and Inspection (MIMII) baseline, how the use of our denoising strategy leads to a sensible improvement of the unsupervised anomaly detection. Such approaches are capable to make sound-based monitoring of industrial processes more reliable.

</p>
</details>

<details><summary><b>Algorithm Selection on a Meta Level</b>
<a href="https://arxiv.org/abs/2107.09414">arxiv:2107.09414</a>
&#x1F4C8; 3 <br>
<p>Alexander Tornede, Lukas Gehring, Tanja Tornede, Marcel Wever, Eyke H√ºllermeier</p></summary>
<p>

**Abstract:** The problem of selecting an algorithm that appears most suitable for a specific instance of an algorithmic problem class, such as the Boolean satisfiability problem, is called instance-specific algorithm selection. Over the past decade, the problem has received considerable attention, resulting in a number of different methods for algorithm selection. Although most of these methods are based on machine learning, surprisingly little work has been done on meta learning, that is, on taking advantage of the complementarity of existing algorithm selection methods in order to combine them into a single superior algorithm selector. In this paper, we introduce the problem of meta algorithm selection, which essentially asks for the best way to combine a given set of algorithm selectors. We present a general methodological framework for meta algorithm selection as well as several concrete learning methods as instantiations of this framework, essentially combining ideas of meta learning and ensemble learning. In an extensive experimental evaluation, we demonstrate that ensembles of algorithm selectors can significantly outperform single algorithm selectors and have the potential to form the new state of the art in algorithm selection.

</p>
</details>

<details><summary><b>Establishing process-structure linkages using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2107.09402">arxiv:2107.09402</a>
&#x1F4C8; 3 <br>
<p>Mohammad Safiuddin, CH Likith Reddy, Ganesh Vasantada, CHJNS Harsha, Srinu Gangolu</p></summary>
<p>

**Abstract:** The microstructure of material strongly influences its mechanical properties and the microstructure itself is influenced by the processing conditions. Thus, establishing a Process-Structure-Property relationship is a crucial task in material design and is of interest in many engineering applications. We develop a GAN (Generative Adversarial Network) to synthesize microstructures based on given processing conditions. This approach is devoid of feature engineering, needs little domain awareness, and can be applied to a wide variety of material systems. Results show that our GAN model can produce high-fidelity multi-phase microstructures which have a good correlation with the given processing conditions.

</p>
</details>

<details><summary><b>Interactive Storytelling for Children: A Case-study of Design and Development Considerations for Ethical Conversational AI</b>
<a href="https://arxiv.org/abs/2107.13076">arxiv:2107.13076</a>
&#x1F4C8; 2 <br>
<p>ennifer Chubba, Sondess Missaouib, Shauna Concannonc, Liam Maloneyb, James Alfred Walker</p></summary>
<p>

**Abstract:** Conversational Artificial Intelligence (CAI) systems and Intelligent Personal Assistants (IPA), such as Alexa, Cortana, Google Home and Siri are becoming ubiquitous in our lives, including those of children, the implications of which is receiving increased attention, specifically with respect to the effects of these systems on children's cognitive, social and linguistic development. Recent advances address the implications of CAI with respect to privacy, safety, security, and access. However, there is a need to connect and embed the ethical and technical aspects in the design. Using a case-study of a research and development project focused on the use of CAI in storytelling for children, this paper reflects on the social context within a specific case of technology development, as substantiated and supported by argumentation from within the literature. It describes the decision making process behind the recommendations made on this case for their adoption in the creative industries. Further research that engages with developers and stakeholders in the ethics of storytelling through CAI is highlighted as a matter of urgency.

</p>
</details>

<details><summary><b>Filament Plots for Data Visualization</b>
<a href="https://arxiv.org/abs/2107.10869">arxiv:2107.10869</a>
&#x1F4C8; 2 <br>
<p>Nate Strawn</p></summary>
<p>

**Abstract:** The efficiency of modern computer graphics allows us to explore collections of space curves simultaneously with "drag-to-rotate" interfaces. This inspires us to replace "scatterplots of points" with "scatterplots of curves" to simultaneously visualize relationships across an entire dataset. Since spaces of curves are infinite dimensional, scatterplots of curves avoid the "lossy" nature of scatterplots of points. In particular, if two points are close in a scatterplot of points derived from high-dimensional data, it does not generally follow that the two associated data points are close in the data space. Standard Andrews plots provide scatterplots of curves that perfectly preserve Euclidean distances, but simultaneous visualization of these graphs over an entire dataset produces visual clutter because graphs of functions generally overlap in 2D. We mitigate this visual clutter issue by constructing computationally inexpensive 3D extensions of Andrews plots. First, we construct optimally smooth 3D Andrews plots by considering linear isometries from Euclidean data spaces to spaces of planar parametric curves. We rigorously parametrize the linear isometries that produce (on average) optimally smooth curves over a given dataset. This parameterization of optimal isometries reveals many degrees of freedom, and (using recent results on generalized Gauss sums) we identify a particular member of this set which admits an asymptotic "tour" property that avoids certain local degeneracies as well. Finally, we construct unit-length 3D curves (filaments) by numerically solving Frenet-Serret systems given data from these 3D Andrews plots. We conclude with examples of filament plots for several standard datasets, illustrating how filament plots avoid visual clutter. Code and examples available at https://github.com/n8epi/filaments/ and https://n8epi.github.io/filaments/

</p>
</details>

<details><summary><b>EMG Pattern Recognition via Bayesian Inference with Scale Mixture-Based Stochastic Generative Models</b>
<a href="https://arxiv.org/abs/2107.09853">arxiv:2107.09853</a>
&#x1F4C8; 2 <br>
<p>Akira Furui, Takuya Igaue, Toshio Tsuji</p></summary>
<p>

**Abstract:** Electromyogram (EMG) has been utilized to interface signals for prosthetic hands and information devices owing to its ability to reflect human motion intentions. Although various EMG classification methods have been introduced into EMG-based control systems, they do not fully consider the stochastic characteristics of EMG signals. This paper proposes an EMG pattern classification method incorporating a scale mixture-based generative model. A scale mixture model is a stochastic EMG model in which the EMG variance is considered as a random variable, enabling the representation of uncertainty in the variance. This model is extended in this study and utilized for EMG pattern classification. The proposed method is trained by variational Bayesian learning, thereby allowing the automatic determination of the model complexity. Furthermore, to optimize the hyperparameters of the proposed method with a partial discriminative approach, a mutual information-based determination method is introduced. Simulation and EMG analysis experiments demonstrated the relationship between the hyperparameters and classification accuracy of the proposed method as well as the validity of the proposed method. The comparison using public EMG datasets revealed that the proposed method outperformed the various conventional classifiers. These results indicated the validity of the proposed method and its applicability to EMG-based control systems. In EMG pattern recognition, a classifier based on a generative model that reflects the stochastic characteristics of EMG signals can outperform the conventional general-purpose classifier.

</p>
</details>

<details><summary><b>A Factor Graph-based approach to vehicle sideslip angle estimation</b>
<a href="https://arxiv.org/abs/2107.09815">arxiv:2107.09815</a>
&#x1F4C8; 2 <br>
<p>Antonio Leanza, Giulio Reina, Jose-Luis Blanco-Claraco</p></summary>
<p>

**Abstract:** Sideslip angle is an important variable for understanding and monitoring vehicle dynamics but it lacks an inexpensive method for direct measurement. Therefore, it is typically estimated from inertial and other proprioceptive sensors onboard using filtering methods from the family of the Kalman Filter. As a novel alternative, this work proposes modelling the problem directly as a graphical model (factor graph), which can then be optimized using a variety of methods, such as whole dataset batch optimization for offline processing or fixed-lag smoother for on-line operation. Experimental results on real vehicle datasets validate the proposal with a good agreement between estimated and actual sideslip angle, showing similar performance than the state-of-the-art with a great potential for future extensions due to the flexible mathematical framework.

</p>
</details>

<details><summary><b>High-dimensional Multivariate Time Series Forecasting in IoT Applications using Embedding Non-stationary Fuzzy Time Series</b>
<a href="https://arxiv.org/abs/2107.09785">arxiv:2107.09785</a>
&#x1F4C8; 2 <br>
<p>Hugo Vinicius Bitencourt, Frederico Gadelha Guimar√£es</p></summary>
<p>

**Abstract:** In Internet of things (IoT), data is continuously recorded from different data sources and devices can suffer faults in their embedded electronics, thus leading to a high-dimensional data sets and concept drift events. Therefore, methods that are capable of high-dimensional non-stationary time series are of great value in IoT applications. Fuzzy Time Series (FTS) models stand out as data-driven non-parametric models of easy implementation and high accuracy. Unfortunately, FTS encounters difficulties when dealing with data sets of many variables and scenarios with concept drift. We present a new approach to handle high-dimensional non-stationary time series, by projecting the original high-dimensional data into a low dimensional embedding space and using FTS approach. Combining these techniques enables a better representation of the complex content of non-stationary multivariate time series and accurate forecasts. Our model is able to explain 98% of the variance and reach 11.52% of RMSE, 2.68% of MAE and 2.91% of MAPE.

</p>
</details>

<details><summary><b>Uncertainty Estimation and Out-of-Distribution Detection for Counterfactual Explanations: Pitfalls and Solutions</b>
<a href="https://arxiv.org/abs/2107.09734">arxiv:2107.09734</a>
&#x1F4C8; 2 <br>
<p>Eoin Delaney, Derek Greene, Mark T. Keane</p></summary>
<p>

**Abstract:** Whilst an abundance of techniques have recently been proposed to generate counterfactual explanations for the predictions of opaque black-box systems, markedly less attention has been paid to exploring the uncertainty of these generated explanations. This becomes a critical issue in high-stakes scenarios, where uncertain and misleading explanations could have dire consequences (e.g., medical diagnosis and treatment planning). Moreover, it is often difficult to determine if the generated explanations are well grounded in the training data and sensitive to distributional shifts. This paper proposes several practical solutions that can be leveraged to solve these problems by establishing novel connections with other research works in explainability (e.g., trust scores) and uncertainty estimation (e.g., Monte Carlo Dropout). Two experiments demonstrate the utility of our proposed solutions.

</p>
</details>

<details><summary><b>Human Perception of Audio Deepfakes</b>
<a href="https://arxiv.org/abs/2107.09667">arxiv:2107.09667</a>
&#x1F4C8; 2 <br>
<p>Nicolas M. M√ºller, Karla Markert, Konstantin B√∂ttinger</p></summary>
<p>

**Abstract:** The recent emergence of deepfakes, computerized realistic multimedia fakes, brought the detection of manipulated and generated content to the forefront. While many machine learning models for deepfakes detection have been proposed, the human detection capabilities have remained far less explored. This is of special importance as human perception differs from machine perception and deepfakes are generally designed to fool the human. So far, this issue has only been addressed in the area of images and video.
  To compare the ability of humans and machines in detecting audio deepfakes, we conducted an online gamified experiment in which we asked users to discern bonda-fide audio samples from spoofed audio, generated with a variety of algorithms. 200 users competed for 8976 game rounds with an artificial intelligence (AI) algorithm trained for audio deepfake detection. With the collected data we found that the machine generally outperforms the humans in detecting audio deepfakes, but that the converse holds for a certain attack type, for which humans are still more accurate. Furthermore, we found that younger participants are on average better at detecting audio deepfakes than older participants, while IT-professionals hold no advantage over laymen. We conclude that it is important to combine human and machine knowledge in order to improve audio deepfake detection.

</p>
</details>

<details><summary><b>Positively Weighted Kernel Quadrature via Subsampling</b>
<a href="https://arxiv.org/abs/2107.09597">arxiv:2107.09597</a>
&#x1F4C8; 2 <br>
<p>Satoshi Hayakawa, Harald Oberhauser, Terry Lyons</p></summary>
<p>

**Abstract:** We study kernel quadrature rules with positive weights for probability measures on general domains. Our theoretical analysis combines the spectral properties of the kernel with random sampling of points. This results in effective algorithms to construct kernel quadrature rules with positive weights and small worst-case error. Besides the additional benefits resulting from positive weights, our numerical experiments indicate that this can achieve fast convergence rates that compete with the optimal bounds in well-known examples.

</p>
</details>

<details><summary><b>Significant Wave Height Prediction based on Wavelet Graph Neural Network</b>
<a href="https://arxiv.org/abs/2107.09483">arxiv:2107.09483</a>
&#x1F4C8; 2 <br>
<p>Delong Chen, Fan Liu, Zheqi Zhang, Xiaomin Lu, Zewen Li</p></summary>
<p>

**Abstract:** Computational intelligence-based ocean characteristics forecasting applications, such as Significant Wave Height (SWH) prediction, are crucial for avoiding social and economic loss in coastal cities. Compared to the traditional empirical-based or numerical-based forecasting models, "soft computing" approaches, including machine learning and deep learning models, have shown numerous success in recent years. In this paper, we focus on enabling the deep learning model to learn both short-term and long-term spatial-temporal dependencies for SWH prediction. A Wavelet Graph Neural Network (WGNN) approach is proposed to integrate the advantages of wavelet transform and graph neural network. Several parallel graph neural networks are separately trained on wavelet decomposed data, and the reconstruction of each model's prediction forms the final SWH prediction. Experimental results show that the proposed WGNN approach outperforms other models, including the numerical models, the machine learning models, and several deep learning models.

</p>
</details>

<details><summary><b>Edge of chaos as a guiding principle for modern neural network training</b>
<a href="https://arxiv.org/abs/2107.09437">arxiv:2107.09437</a>
&#x1F4C8; 2 <br>
<p>Lin Zhang, Ling Feng, Kan Chen, Choy Heng Lai</p></summary>
<p>

**Abstract:** The success of deep neural networks in real-world problems has prompted many attempts to explain their training dynamics and generalization performance, but more guiding principles for the training of neural networks are still needed. Motivated by the edge of chaos principle behind the optimal performance of neural networks, we study the role of various hyperparameters in modern neural network training algorithms in terms of the order-chaos phase diagram. In particular, we study a fully analytical feedforward neural network trained on the widely adopted Fashion-MNIST dataset, and study the dynamics associated with the hyperparameters in back-propagation during the training process. We find that for the basic algorithm of stochastic gradient descent with momentum, in the range around the commonly used hyperparameter values, clear scaling relations are present with respect to the training time during the ordered phase in the phase diagram, and the model's optimal generalization power at the edge of chaos is similar across different training parameter combinations. In the chaotic phase, the same scaling no longer exists. The scaling allows us to choose the training parameters to achieve faster training without sacrificing performance. In addition, we find that the commonly used model regularization method - weight decay - effectively pushes the model towards the ordered phase to achieve better performance. Leveraging on this fact and the scaling relations in the other hyperparameters, we derived a principled guideline for hyperparameter determination, such that the model can achieve optimal performance by saturating it at the edge of chaos. Demonstrated on this simple neural network model and training algorithm, our work improves the understanding of neural network training dynamics, and can potentially be extended to guiding principles of more complex model architectures and algorithms.

</p>
</details>

<details><summary><b>DeepSMILE: Self-supervised heterogeneity-aware multiple instance learning for DNA damage response defect classification directly from H&E whole-slide images</b>
<a href="https://arxiv.org/abs/2107.09405">arxiv:2107.09405</a>
&#x1F4C8; 2 <br>
<p>Yoni Schirris, Efstratios Gavves, Iris Nederlof, Hugo Mark Horlings, Jonas Teuwen</p></summary>
<p>

**Abstract:** We propose a Deep learning-based weak label learning method for analysing whole slide images (WSIs) of Hematoxylin and Eosin (H&E) stained tumorcells not requiring pixel-level or tile-level annotations using Self-supervised pre-training and heterogeneity-aware deep Multiple Instance LEarning (DeepSMILE). We apply DeepSMILE to the task of Homologous recombination deficiency (HRD) and microsatellite instability (MSI) prediction. We utilize contrastive self-supervised learning to pre-train a feature extractor on histopathology tiles of cancer tissue. Additionally, we use variability-aware deep multiple instance learning to learn the tile feature aggregation function while modeling tumor heterogeneity. Compared to state-of-the-art genomic label classification methods, DeepSMILE improves classification performance for HRD from $70.43\pm4.10\%$ to $83.79\pm1.25\%$ AUC and MSI from $78.56\pm6.24\%$ to $90.32\pm3.58\%$ AUC in a multi-center breast and colorectal cancer dataset, respectively. These improvements suggest we can improve genomic label classification performance without collecting larger datasets. In the future, this may reduce the need for expensive genome sequencing techniques, provide personalized therapy recommendations based on widely available WSIs of cancer tissue, and improve patient care with quicker treatment decisions - also in medical centers without access to genome sequencing resources.

</p>
</details>

<details><summary><b>SVSNet: An End-to-end Speaker Voice Similarity Assessment Model</b>
<a href="https://arxiv.org/abs/2107.09392">arxiv:2107.09392</a>
&#x1F4C8; 2 <br>
<p>Cheng-Hung Hu, Yu-Huai Peng, Junichi Yamagishi, Yu Tsao, Hsin-Min Wang</p></summary>
<p>

**Abstract:** Neural evaluation metrics derived for numerous speech generation tasks have recently attracted great attention. In this paper, we propose SVSNet, the first end-to-end neural network model to assess the speaker voice similarity between natural speech and synthesized speech. Unlike most neural evaluation metrics that use hand-crafted features, SVSNet directly takes the raw waveform as input to more completely utilize speech information for prediction. SVSNet consists of encoder, co-attention, distance calculation, and prediction modules and is trained in an end-to-end manner. The experimental results on the Voice Conversion Challenge 2018 and 2020 (VCC2018 and VCC2020) datasets show that SVSNet notably outperforms well-known baseline systems in the assessment of speaker similarity at the utterance and system levels.

</p>
</details>

<details><summary><b>An induction proof of the backpropagation algorithm in matrix notation</b>
<a href="https://arxiv.org/abs/2107.09384">arxiv:2107.09384</a>
&#x1F4C8; 2 <br>
<p>Dirk Ostwald, Franziska Us√©e</p></summary>
<p>

**Abstract:** Backpropagation (BP) is a core component of the contemporary deep learning incarnation of neural networks. Briefly, BP is an algorithm that exploits the computational architecture of neural networks to efficiently evaluate the gradient of a cost function during neural network parameter optimization. The validity of BP rests on the application of a multivariate chain rule to the computational architecture of neural networks and their associated objective functions. Introductions to deep learning theory commonly present the computational architecture of neural networks in matrix form, but eschew a parallel formulation and justification of BP in the framework of matrix differential calculus. This entails several drawbacks for the theory and didactics of deep learning. In this work, we overcome these limitations by providing a full induction proof of the BP algorithm in matrix notation. Specifically, we situate the BP algorithm in the framework of matrix differential calculus, encompass affine-linear potential functions, prove the validity of the BP algorithm in inductive form, and exemplify the implementation of the matrix form BP algorithm in computer code.

</p>
</details>

<details><summary><b>Protecting Semantic Segmentation Models by Using Block-wise Image Encryption with Secret Key from Unauthorized Access</b>
<a href="https://arxiv.org/abs/2107.09362">arxiv:2107.09362</a>
&#x1F4C8; 2 <br>
<p>Hiroki Ito, MaungMaung AprilPyone, Hitoshi Kiya</p></summary>
<p>

**Abstract:** Since production-level trained deep neural networks (DNNs) are of a great business value, protecting such DNN models against copyright infringement and unauthorized access is in a rising demand. However, conventional model protection methods focused only the image classification task, and these protection methods were never applied to semantic segmentation although it has an increasing number of applications. In this paper, we propose to protect semantic segmentation models from unauthorized access by utilizing block-wise transformation with a secret key for the first time. Protected models are trained by using transformed images. Experiment results show that the proposed protection method allows rightful users with the correct key to access the model to full capacity and deteriorate the performance for unauthorized users. However, protected models slightly drop the segmentation performance compared to non-protected models.

</p>
</details>

<details><summary><b>Kernel Selection for Stein Variational Gradient Descent</b>
<a href="https://arxiv.org/abs/2107.09338">arxiv:2107.09338</a>
&#x1F4C8; 2 <br>
<p>Qingzhong Ai, Shiyu Liu, Zenglin Xu</p></summary>
<p>

**Abstract:** Stein variational gradient descent (SVGD) and its variants have shown promising successes in approximate inference for complex distributions. However, their empirical performance depends crucially on the choice of optimal kernel. Unfortunately, RBF kernel with median heuristics is a common choice in previous approaches which has been proved sub-optimal. Inspired by the paradigm of multiple kernel learning, our solution to this issue is using a combination of multiple kernels to approximate the optimal kernel instead of a single one which may limit the performance and flexibility. To do so, we extend Kernelized Stein Discrepancy (KSD) to its multiple kernel view called Multiple Kernelized Stein Discrepancy (MKSD). Further, we leverage MKSD to construct a general algorithm based on SVGD, which be called Multiple Kernel SVGD (MK-SVGD). Besides, we automatically assign a weight to each kernel without any other parameters. The proposed method not only gets rid of optimal kernel dependence but also maintains computational effectiveness. Experiments on various tasks and models show the effectiveness of our method.

</p>
</details>

<details><summary><b>Improving Sentence-Level Relation Extraction through Curriculum Learning</b>
<a href="https://arxiv.org/abs/2107.09332">arxiv:2107.09332</a>
&#x1F4C8; 2 <br>
<p>Seongsik Park, Harksoo Kim</p></summary>
<p>

**Abstract:** Sentence-level relation extraction mainly aims to classify the relation between two entities in a sentence. The sentence-level relation extraction corpus often contains data that are difficult for the model to infer or noise data. In this paper, we propose a curriculum learning-based relation extraction model that splits data by difficulty and utilizes them for learning. In the experiments with the representative sentence-level relation extraction datasets, TACRED and Re-TACRED, the proposed method obtained an F1-score of 75.0% and 91.4% respectively, which are the state-of-the-art performance.

</p>
</details>

<details><summary><b>A Real-time Speaker Diarization System Based on Spatial Spectrum</b>
<a href="https://arxiv.org/abs/2107.09321">arxiv:2107.09321</a>
&#x1F4C8; 2 <br>
<p>Siqi Zheng, Weilong Huang, Xianliang Wang, Hongbin Suo, Jinwei Feng, Zhijie Yan</p></summary>
<p>

**Abstract:** In this paper we describe a speaker diarization system that enables localization and identification of all speakers present in a conversation or meeting. We propose a novel systematic approach to tackle several long-standing challenges in speaker diarization tasks: (1) to segment and separate overlapping speech from two speakers; (2) to estimate the number of speakers when participants may enter or leave the conversation at any time; (3) to provide accurate speaker identification on short text-independent utterances; (4) to track down speakers movement during the conversation; (5) to detect speaker change incidence real-time. First, a differential directional microphone array-based approach is exploited to capture the target speakers' voice in far-field adverse environment. Second, an online speaker-location joint clustering approach is proposed to keep track of speaker location. Third, an instant speaker number detector is developed to trigger the mechanism that separates overlapped speech. The results suggest that our system effectively incorporates spatial information and achieves significant gains.

</p>
</details>

<details><summary><b>Follow Your Path: a Progressive Method for Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2107.09305">arxiv:2107.09305</a>
&#x1F4C8; 2 <br>
<p>Wenxian Shi, Yuxuan Song, Hao Zhou, Bohan Li, Lei Li</p></summary>
<p>

**Abstract:** Deep neural networks often have a huge number of parameters, which posts challenges in deployment in application scenarios with limited memory and computation capacity. Knowledge distillation is one approach to derive compact models from bigger ones. However, it has been observed that a converged heavy teacher model is strongly constrained for learning a compact student network and could make the optimization subject to poor local optima. In this paper, we propose ProKT, a new model-agnostic method by projecting the supervision signals of a teacher model into the student's parameter space. Such projection is implemented by decomposing the training objective into local intermediate targets with an approximate mirror descent technique. The proposed method could be less sensitive with the quirks during optimization which could result in a better local optimum. Experiments on both image and text datasets show that our proposed ProKT consistently achieves superior performance compared to other existing knowledge distillation methods.

</p>
</details>

<details><summary><b>ECG Heartbeat Classification Using Multimodal Fusion</b>
<a href="https://arxiv.org/abs/2107.09869">arxiv:2107.09869</a>
&#x1F4C8; 1 <br>
<p>Zeeshan Ahmad, Anika Tabassum, Ling Guan, Naimul Khan</p></summary>
<p>

**Abstract:** Electrocardiogram (ECG) is an authoritative source to diagnose and counter critical cardiovascular syndromes such as arrhythmia and myocardial infarction (MI). Current machine learning techniques either depend on manually extracted features or large and complex deep learning networks which merely utilize the 1D ECG signal directly. Since intelligent multimodal fusion can perform at the stateof-the-art level with an efficient deep network, therefore, in this paper, we propose two computationally efficient multimodal fusion frameworks for ECG heart beat classification called Multimodal Image Fusion (MIF) and Multimodal Feature Fusion (MFF). At the input of these frameworks, we convert the raw ECG data into three different images using Gramian Angular Field (GAF), Recurrence Plot (RP) and Markov Transition Field (MTF). In MIF, we first perform image fusion by combining three imaging modalities to create a single image modality which serves as input to the Convolutional Neural Network (CNN). In MFF, we extracted features from penultimate layer of CNNs and fused them to get unique and interdependent information necessary for better performance of classifier. These informational features are finally used to train a Support Vector Machine (SVM) classifier for ECG heart-beat classification. We demonstrate the superiority of the proposed fusion models by performing experiments on PhysioNets MIT-BIH dataset for five distinct conditions of arrhythmias which are consistent with the AAMI EC57 protocols and on PTB diagnostics dataset for Myocardial Infarction (MI) classification. We achieved classification accuracy of 99.7% and 99.2% on arrhythmia and MI classification, respectively.

</p>
</details>

<details><summary><b>Modality-aware Mutual Learning for Multi-modal Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2107.09842">arxiv:2107.09842</a>
&#x1F4C8; 1 <br>
<p>Yao Zhang, Jiawei Yang, Jiang Tian, Zhongchao Shi, Cheng Zhong, Yang Zhang, Zhiqiang He</p></summary>
<p>

**Abstract:** Liver cancer is one of the most common cancers worldwide. Due to inconspicuous texture changes of liver tumor, contrast-enhanced computed tomography (CT) imaging is effective for the diagnosis of liver cancer. In this paper, we focus on improving automated liver tumor segmentation by integrating multi-modal CT images. To this end, we propose a novel mutual learning (ML) strategy for effective and robust multi-modal liver tumor segmentation. Different from existing multi-modal methods that fuse information from different modalities by a single model, with ML, an ensemble of modality-specific models learn collaboratively and teach each other to distill both the characteristics and the commonality between high-level representations of different modalities. The proposed ML not only enables the superiority for multi-modal learning but can also handle missing modalities by transferring knowledge from existing modalities to missing ones. Additionally, we present a modality-aware (MA) module, where the modality-specific models are interconnected and calibrated with attention weights for adaptive information exchange. The proposed modality-aware mutual learning (MAML) method achieves promising results for liver tumor segmentation on a large-scale clinical dataset. Moreover, we show the efficacy and robustness of MAML for handling missing modalities on both the liver tumor and public brain tumor (BRATS 2018) datasets. Our code is available at https://github.com/YaoZhang93/MAML.

</p>
</details>

<details><summary><b>Using Undervolting as an On-Device Defense Against Adversarial Machine Learning Attacks</b>
<a href="https://arxiv.org/abs/2107.09804">arxiv:2107.09804</a>
&#x1F4C8; 1 <br>
<p>Saikat Majumdar, Mohammad Hossein Samavatian, Kristin Barber, Radu Teodorescu</p></summary>
<p>

**Abstract:** Deep neural network (DNN) classifiers are powerful tools that drive a broad spectrum of important applications, from image recognition to autonomous vehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks that affect virtually all state-of-the-art models. These attacks make small imperceptible modifications to inputs that are sufficient to induce the DNNs to produce the wrong classification.
  In this paper we propose a novel, lightweight adversarial correction and/or detection mechanism for image classifiers that relies on undervolting (running a chip at a voltage that is slightly below its safe margin). We propose using controlled undervolting of the chip running the inference process in order to introduce a limited number of compute errors. We show that these errors disrupt the adversarial input in a way that can be used either to correct the classification or detect the input as adversarial. We evaluate the proposed solution in an FPGA design and through software simulation. We evaluate 10 attacks and show average detection rates of 77% and 90% on two popular DNNs.

</p>
</details>

<details><summary><b>Quantum Measurement Classification with Qudits</b>
<a href="https://arxiv.org/abs/2107.09781">arxiv:2107.09781</a>
&#x1F4C8; 1 <br>
<p>Diego H. Useche, Andres Giraldo-Carvajal, Hernan M. Zuluaga-Bucheli, Jose A. Jaramillo-Villegas, Fabio A. Gonz√°lez</p></summary>
<p>

**Abstract:** This paper presents a hybrid classical-quantum program for density estimation and supervised classification. The program is implemented as a quantum circuit in a high-dimensional quantum computer simulator. We show that the proposed quantum protocols allow to estimate probability density functions and to make predictions in a supervised learning manner. This model can be generalized to find expected values of density matrices in high-dimensional quantum computers. Experiments on various data sets are presented. Results show that the proposed method is a viable strategy to implement supervised classification and density estimation in a high-dimensional quantum computer.

</p>
</details>

<details><summary><b>An Efficient Multi-objective Evolutionary Approach for Solving the Operation of Multi-Reservoir System Scheduling in Hydro-Power Plants</b>
<a href="https://arxiv.org/abs/2107.09718">arxiv:2107.09718</a>
&#x1F4C8; 1 <br>
<p>C. G. Marcelino, G. M. C. Leite, C. A. D. M Delgado, L. B. de Oliveira, E. F. Wanner, S. Jim√©nez-Fern√°ndez, S. Salcedo-Sanz</p></summary>
<p>

**Abstract:** This paper tackles the short-term hydro-power unit commitment problem in a multi-reservoir system - a cascade-based operation scenario. For this, we propose a new mathematical modelling in which the goal is to maximize the total energy production of the hydro-power plant in a sub-daily operation, and, simultaneously, to maximize the total water content (volume) of reservoirs. For solving the problem, we discuss the Multi-objective Evolutionary Swarm Hybridization (MESH) algorithm, a recently proposed multi-objective swarm intelligence-based optimization method which has obtained very competitive results when compared to existing evolutionary algorithms in specific applications. The MESH approach has been applied to find the optimal water discharge and the power produced at the maximum reservoir volume for all possible combinations of turbines in a hydro-power plant. The performance of MESH has been compared with that of well-known evolutionary approaches such as NSGA-II, NSGA-III, SPEA2, and MOEA/D in a realistic problem considering data from a hydro-power energy system with two cascaded hydro-power plants in Brazil. Results indicate that MESH showed a superior performance than alternative multi-objective approaches in terms of efficiency and accuracy, providing a profit of \$412,500 per month in a projection analysis carried out.

</p>
</details>

<details><summary><b>On Estimating Rank-One Spiked Tensors in the Presence of Heavy Tailed Errors</b>
<a href="https://arxiv.org/abs/2107.09660">arxiv:2107.09660</a>
&#x1F4C8; 1 <br>
<p>Arnab Auddy, Ming Yuan</p></summary>
<p>

**Abstract:** In this paper, we study the estimation of a rank-one spiked tensor in the presence of heavy tailed noise. Our results highlight some of the fundamental similarities and differences in the tradeoff between statistical and computational efficiencies under heavy tailed and Gaussian noise. In particular, we show that, for $p$ th order tensors, the tradeoff manifests in an identical fashion as the Gaussian case when the noise has finite $4(p-1)$ th moment. The difference in signal strength requirements, with or without computational constraints, for us to estimate the singular vectors at the optimal rate, interestingly, narrows for noise with heavier tails and vanishes when the noise only has finite fourth moment. Moreover, if the noise has less than fourth moment, tensor SVD, perhaps the most natural approach, is suboptimal even though it is computationally intractable. Our analysis exploits a close connection between estimating the rank-one spikes and the spectral norm of a random tensor with iid entries. In particular, we show that the order of the spectral norm of a random tensor can be precisely characterized by the moment of its entries, generalizing classical results for random matrices. In addition to the theoretical guarantees, we propose estimation procedures for the heavy tailed regime, which are easy to implement and efficient to run. Numerical experiments are presented to demonstrate their practical merits.

</p>
</details>

<details><summary><b>Rethinking the Tradeoff in Integrated Sensing and Communication: Recognition Accuracy versus Communication Rate</b>
<a href="https://arxiv.org/abs/2107.09621">arxiv:2107.09621</a>
&#x1F4C8; 1 <br>
<p>Guoliang Li, Shuai Wang, Jie Li, Rui Wang, Fan Liu, Meihong Zhang, Xiaohui Peng, Tony Xiao Han</p></summary>
<p>

**Abstract:** Integrated sensing and communication (ISAC) is a promising technology to improve the band-utilization efficiency via spectrum sharing or hardware sharing between radar and communication systems. Since a common radio resource budget is shared by both functionalities, there exists a tradeoff between the sensing and communication performance. However, this tradeoff curve is currently unknown in ISAC systems with human motion recognition tasks based on deep learning. To fill this gap, this paper formulates and solves a multi-objective optimization problem which simultaneously maximizes the recognition accuracy and the communication data rate. The key ingredient of this new formulation is a nonlinear recognition accuracy model with respect to the wireless resources, where the model is derived from power function regression of the system performance of the deep spectrogram network. To avoid cost-expensive data collection procedures, a primitive-based autoregressive hybrid (PBAH) channel model is developed, which facilitates efficient training and testing dataset generation for human motion recognition in a virtual environment. Extensive results demonstrate that the proposed wireless recognition accuracy and PBAH channel models match the actual experimental data very well. Moreover, it is found that the accuracy-rate region consists of a communication saturation zone, a sensing saturation zone, and a communication-sensing adversarial zone, of which the third zone achieves the desirable balanced performance for ISAC systems.

</p>
</details>

<details><summary><b>Hybrid neural network reduced order modelling for turbulent flows with geometric parameters</b>
<a href="https://arxiv.org/abs/2107.09591">arxiv:2107.09591</a>
&#x1F4C8; 1 <br>
<p>Matteo Zancanaro, Markus Mrosek, Giovanni Stabile, Carsten Othmer, Gianluigi Rozza</p></summary>
<p>

**Abstract:** Geometrically parametrized Partial Differential Equations are nowadays widely used in many different fields as, for example, shape optimization processes or patient specific surgery studies. The focus of this work is on some advances for this topic, capable of increasing the accuracy with respect to previous approaches while relying on a high cost-benefit ratio performance. The main scope of this paper is the introduction of a new technique mixing up a classical Galerkin-projection approach together with a data-driven method to obtain a versatile and accurate algorithm for the resolution of geometrically parametrized incompressible turbulent Navier-Stokes problems. The effectiveness of this procedure is demonstrated on two different test cases: a classical academic back step problem and a shape deformation Ahmed body application. The results show into details the properties of the architecture we developed while exposing possible future perspectives for this work.

</p>
</details>

<details><summary><b>How Does Cell-Free Massive MIMO Support Multiple Federated Learning Groups?</b>
<a href="https://arxiv.org/abs/2107.09577">arxiv:2107.09577</a>
&#x1F4C8; 1 <br>
<p>Tung T. Vu, Hien Quoc Ngo, Thomas L. Marzetta, Michail Matthaiou</p></summary>
<p>

**Abstract:** Federated learning (FL) has been considered as a promising learning framework for future machine learning systems due to its privacy preservation and communication efficiency. In beyond-5G/6G systems, it is likely to have multiple FL groups with different learning purposes. This scenario leads to a question: How does a wireless network support multiple FL groups? As an answer, we first propose to use a cell-free massive multiple-input multiple-output (MIMO) network to guarantee the stable operation of multiple FL processes by letting the iterations of these FL processes be executed together within a large-scale coherence time. We then develop a novel scheme that asynchronously executes the iterations of FL processes under multicasting downlink and conventional uplink transmission protocols. Finally, we propose a simple/low-complexity resource allocation algorithm which optimally chooses the power and computation resources to minimize the execution time of each iteration of each FL process.

</p>
</details>

<details><summary><b>Accelerating Edge Intelligence via Integrated Sensing and Communication</b>
<a href="https://arxiv.org/abs/2107.09574">arxiv:2107.09574</a>
&#x1F4C8; 1 <br>
<p>Tong Zhang, Shuai Wang, Guoliang Li, Fan Liu, Guangxu Zhu, Rui Wang</p></summary>
<p>

**Abstract:** Realizing edge intelligence consists of sensing, communication, training, and inference stages. Conventionally, the sensing and communication stages are executed sequentially, which results in excessive amount of dataset generation and uploading time. This paper proposes to accelerate edge intelligence via integrated sensing and communication (ISAC). As such, the sensing and communication stages are merged so as to make the best use of the wireless signals for the dual purpose of dataset generation and uploading. However, ISAC also introduces additional interference between sensing and communication functionalities. To address this challenge, this paper proposes a classification error minimization formulation to design the ISAC beamforming and time allocation. The globally optimal solution is derived via the rank-1 guaranteed semidefinite relaxation, and performance analysis is performed to quantify the ISAC gain over that of conventional edge intelligence. Simulation results are provided to verify the effectiveness of the proposed ISAC-assisted edge intelligence system. Interestingly, we find that ISAC is always beneficial, when the duration of generating a sample is more than the duration of uploading a sample. Otherwise, the ISAC gain can vanish or even be negative. Nevertheless, we still derive a sufficient condition, under which a positive ISAC gain is feasible.

</p>
</details>

<details><summary><b>Into Summarization Techniques for IoT Data Discovery Routing</b>
<a href="https://arxiv.org/abs/2107.09558">arxiv:2107.09558</a>
&#x1F4C8; 1 <br>
<p>Hieu Tran, Son Nguyen, I-Ling Yen, Farokh Bastani</p></summary>
<p>

**Abstract:** In this paper, we consider the IoT data discovery problem in very large and growing scale networks. Specifically, we investigate in depth the routing table summarization techniques to support effective and space-efficient IoT data discovery routing. Novel summarization algorithms, including alphabetical based, hash based, and meaning based summarization and their corresponding coding schemes are proposed. The issue of potentially misleading routing due to summarization is also investigated. Subsequently, we analyze the strategy of when to summarize in order to balance the tradeoff between the routing table compression rate and the chance of causing misleading routing. For experimental study, we have collected 100K IoT data streams from various IoT databases as the input dataset. Experimental results show that our summarization solution can reduce the routing table size by 20 to 30 folds with 2-5% increase in latency when compared with similar peer-to-peer discovery routing algorithms without summarization. Also, our approach outperforms DHT based approaches by 2 to 6 folds in terms of latency and traffic.

</p>
</details>

<details><summary><b>Relay-Assisted Cooperative Federated Learning</b>
<a href="https://arxiv.org/abs/2107.09518">arxiv:2107.09518</a>
&#x1F4C8; 1 <br>
<p>Zehong Lin, Hang Liu, Ying-Jun Angela Zhang</p></summary>
<p>

**Abstract:** Federated learning (FL) has recently emerged as a promising technology to enable artificial intelligence (AI) at the network edge, where distributed mobile devices collaboratively train a shared AI model under the coordination of an edge server. To significantly improve the communication efficiency of FL, over-the-air computation allows a large number of mobile devices to concurrently upload their local models by exploiting the superposition property of wireless multi-access channels. Due to wireless channel fading, the model aggregation error at the edge server is dominated by the weakest channel among all devices, causing severe straggler issues. In this paper, we propose a relay-assisted cooperative FL scheme to effectively address the straggler issue. In particular, we deploy multiple half-duplex relays to cooperatively assist the devices in uploading the local model updates to the edge server. The nature of the over-the-air computation poses system objectives and constraints that are distinct from those in traditional relay communication systems. Moreover, the strong coupling between the design variables renders the optimization of such a system challenging. To tackle the issue, we propose an alternating-optimization-based algorithm to optimize the transceiver and relay operation with low complexity. Then, we analyze the model aggregation error in a single-relay case and show that our relay-assisted scheme achieves a smaller error than the one without relays provided that the relay transmit power and the relay channel gains are sufficiently large. The analysis provides critical insights on relay deployment in the implementation of cooperative FL. Extensive numerical results show that our design achieves faster convergence compared with state-of-the-art schemes.

</p>
</details>

<details><summary><b>Automated Segmentation and Volume Measurement of Intracranial Carotid Artery Calcification on Non-Contrast CT</b>
<a href="https://arxiv.org/abs/2107.09442">arxiv:2107.09442</a>
&#x1F4C8; 1 <br>
<p>Gerda Bortsova, Daniel Bos, Florian Dubost, Meike W. Vernooij, M. Kamran Ikram, Gijs van Tulder, Marleen de Bruijne</p></summary>
<p>

**Abstract:** Purpose: To evaluate a fully-automated deep-learning-based method for assessment of intracranial carotid artery calcification (ICAC). Methods: Two observers manually delineated ICAC in non-contrast CT scans of 2,319 participants (mean age 69 (SD 7) years; 1154 women) of the Rotterdam Study, prospectively collected between 2003 and 2006. These data were used to retrospectively develop and validate a deep-learning-based method for automated ICAC delineation and volume measurement. To evaluate the method, we compared manual and automatic assessment (computed using ten-fold cross-validation) with respect to 1) the agreement with an independent observer's assessment (available in a random subset of 47 scans); 2) the accuracy in delineating ICAC as judged via blinded visual comparison by an expert; 3) the association with first stroke incidence from the scan date until 2012. All method performance metrics were computed using 10-fold cross-validation. Results: The automated delineation of ICAC reached sensitivity of 83.8% and positive predictive value (PPV) of 88%. The intraclass correlation between automatic and manual ICAC volume measures was 0.98 (95% CI: 0.97, 0.98; computed in the entire dataset). Measured between the assessments of independent observers, sensitivity was 73.9%, PPV was 89.5%, and intraclass correlation was 0.91 (95% CI: 0.84, 0.95; computed in the 47-scan subset). In the blinded visual comparisons, automatic delineations were more accurate than manual ones (p-value = 0.01). The association of ICAC volume with incident stroke was similarly strong for both automated (hazard ratio, 1.38 (95% CI: 1.12, 1.75) and manually measured volumes (hazard ratio, 1.48 (95% CI: 1.20, 1.87)). Conclusions: The developed model was capable of automated segmentation and volume quantification of ICAC with accuracy comparable to human experts.

</p>
</details>

<details><summary><b>CREW: Computation Reuse and Efficient Weight Storage for Hardware-accelerated MLPs and RNNs</b>
<a href="https://arxiv.org/abs/2107.09408">arxiv:2107.09408</a>
&#x1F4C8; 1 <br>
<p>Marc Riera, Jose-Maria Arnau, Antonio Gonzalez</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) have achieved tremendous success for cognitive applications. The core operation in a DNN is the dot product between quantized inputs and weights. Prior works exploit the weight/input repetition that arises due to quantization to avoid redundant computations in Convolutional Neural Networks (CNNs). However, in this paper we show that their effectiveness is severely limited when applied to Fully-Connected (FC) layers, which are commonly used in state-of-the-art DNNs, as it is the case of modern Recurrent Neural Networks (RNNs) and Transformer models.
  To improve energy-efficiency of FC computation we present CREW, a hardware accelerator that implements Computation Reuse and an Efficient Weight Storage mechanism to exploit the large number of repeated weights in FC layers. CREW first performs the multiplications of the unique weights by their respective inputs and stores the results in an on-chip buffer. The storage requirements are modest due to the small number of unique weights and the relatively small size of the input compared to convolutional layers. Next, CREW computes each output by fetching and adding its required products. To this end, each weight is replaced offline by an index in the buffer of unique products. Indices are typically smaller than the quantized weights, since the number of unique weights for each input tends to be much lower than the range of quantized weights, which reduces storage and memory bandwidth requirements.
  Overall, CREW greatly reduces the number of multiplications and provides significant savings in model memory footprint and memory bandwidth usage. We evaluate CREW on a diverse set of modern DNNs. On average, CREW provides 2.61x speedup and 2.42x energy savings over a TPU-like accelerator. Compared to UCNN, a state-of-art computation reuse technique, CREW achieves 2.10x speedup and 2.08x energy savings on average.

</p>
</details>

<details><summary><b>Image-Hashing-Based Anomaly Detection for Privacy-Preserving Online Proctoring</b>
<a href="https://arxiv.org/abs/2107.09373">arxiv:2107.09373</a>
&#x1F4C8; 1 <br>
<p>Waheeb Yaqub, Manoranjan Mohanty, Basem Suleiman</p></summary>
<p>

**Abstract:** Online proctoring has become a necessity in online teaching. Video-based crowd-sourced online proctoring solutions are being used, where an exam-taking student's video is monitored by third parties, leading to privacy concerns. In this paper, we propose a privacy-preserving online proctoring system. The proposed image-hashing-based system can detect the student's excessive face and body movement (i.e., anomalies) that is resulted when the student tries to cheat in the exam. The detection can be done even if the student's face is blurred or masked in video frames. Experiment with an in-house dataset shows the usability of the proposed system.

</p>
</details>

<details><summary><b>Positive/Negative Approximate Multipliers for DNN Accelerators</b>
<a href="https://arxiv.org/abs/2107.09366">arxiv:2107.09366</a>
&#x1F4C8; 1 <br>
<p>Ourania Spantidi, Georgios Zervakis, Iraklis Anagnostopoulos, Hussam Amrouch, J√∂rg Henkel</p></summary>
<p>

**Abstract:** Recent Deep Neural Networks (DNNs) managed to deliver superhuman accuracy levels on many AI tasks. Several applications rely more and more on DNNs to deliver sophisticated services and DNN accelerators are becoming integral components of modern systems-on-chips. DNNs perform millions of arithmetic operations per inference and DNN accelerators integrate thousands of multiply-accumulate units leading to increased energy requirements. Approximate computing principles are employed to significantly lower the energy consumption of DNN accelerators at the cost of some accuracy loss. Nevertheless, recent research demonstrated that complex DNNs are increasingly sensitive to approximation. Hence, the obtained energy savings are often limited when targeting tight accuracy constraints. In this work, we present a dynamically configurable approximate multiplier that supports three operation modes, i.e., exact, positive error, and negative error. In addition, we propose a filter-oriented approximation method to map the weights to the appropriate modes of the approximate multiplier. Our mapping algorithm balances the positive with the negative errors due to the approximate multiplications, aiming at maximizing the energy reduction while minimizing the overall convolution error. We evaluate our approach on multiple DNNs and datasets against state-of-the-art approaches, where our method achieves 18.33% energy gains on average across 7 NNs on 4 different datasets for a maximum accuracy drop of only 1%.

</p>
</details>

<details><summary><b>Similarity metrics for Different Market Scenarios in Abides</b>
<a href="https://arxiv.org/abs/2107.09352">arxiv:2107.09352</a>
&#x1F4C8; 1 <br>
<p>Diego Pino, Javier Garc√≠a, Fernando Fern√°ndez, Svitlana S Vyetrenko</p></summary>
<p>

**Abstract:** Markov Decision Processes (MDPs) are an effective way to formally describe many Machine Learning problems. In fact, recently MDPs have also emerged as a powerful framework to model financial trading tasks. For example, financial MDPs can model different market scenarios. However, the learning of a (near-)optimal policy for each of these financial MDPs can be a very time-consuming process, especially when nothing is known about the policy to begin with. An alternative approach is to find a similar financial MDP for which we have already learned its policy, and then reuse such policy in the learning of a new policy for a new financial MDP. Such a knowledge transfer between market scenarios raises several issues. On the one hand, how to measure the similarity between financial MDPs. On the other hand, how to use this similarity measurement to effectively transfer the knowledge between financial MDPs. This paper addresses both of these issues. Regarding the first one, this paper analyzes the use of three similarity metrics based on conceptual, structural and performance aspects of the financial MDPs. Regarding the second one, this paper uses Probabilistic Policy Reuse to balance the exploitation/exploration in the learning of a new financial MDP according to the similarity of the previous financial MDPs whose knowledge is reused.

</p>
</details>

<details><summary><b>LENS: Layer Distribution Enabled Neural Architecture Search in Edge-Cloud Hierarchies</b>
<a href="https://arxiv.org/abs/2107.09309">arxiv:2107.09309</a>
&#x1F4C8; 1 <br>
<p>Mohanad Odema, Nafiul Rashid, Berken Utku Demirel, Mohammad Abdullah Al Faruque</p></summary>
<p>

**Abstract:** Edge-Cloud hierarchical systems employing intelligence through Deep Neural Networks (DNNs) endure the dilemma of workload distribution within them. Previous solutions proposed to distribute workloads at runtime according to the state of the surroundings, like the wireless conditions. However, such conditions are usually overlooked at design time. This paper addresses this issue for DNN architectural design by presenting a novel methodology, LENS, which administers multi-objective Neural Architecture Search (NAS) for two-tiered systems, where the performance objectives are refashioned to consider the wireless communication parameters. From our experimental search space, we demonstrate that LENS improves upon the traditional solution's Pareto set by 76.47% and 75% with respect to the energy and latency metrics, respectively.

</p>
</details>

<details><summary><b>Improved Reinforcement Learning in Cooperative Multi-agent Environments Using Knowledge Transfer</b>
<a href="https://arxiv.org/abs/2107.09807">arxiv:2107.09807</a>
&#x1F4C8; 0 <br>
<p>Mahnoosh Mahdavimoghaddam, Amin Nikanjam, Monireh Abdoos</p></summary>
<p>

**Abstract:** Nowadays, cooperative multi-agent systems are used to learn how to achieve goals in large-scale dynamic environments. However, learning in these environments is challenging: from the effect of search space size on learning time to inefficient cooperation among agents. Moreover, reinforcement learning algorithms may suffer from a long time of convergence in such environments. In this paper, a communication framework is introduced. In the proposed communication framework, agents learn to cooperate effectively and also by introduction of a new state calculation method the size of state space will decline considerably. Furthermore, a knowledge-transferring algorithm is presented to share the gained experiences among the different agents, and develop an effective knowledge-fusing mechanism to fuse the knowledge learnt utilizing the agents' own experiences with the knowledge received from other team members. Finally, the simulation results are provided to indicate the efficacy of the proposed method in the complex learning task. We have evaluated our approach on the shepherding problem and the results show that the learning process accelerates by making use of the knowledge transferring mechanism and the size of state space has declined by generating similar states based on state abstraction concept.

</p>
</details>


[Next Page](2021/2021-07/2021-07-19.md)
