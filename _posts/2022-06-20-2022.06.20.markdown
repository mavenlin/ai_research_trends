Prev: [2022.06.19]({{ '/2022/06/19/2022.06.19.html' | relative_url }})  Next: [2022.06.21]({{ '/2022/06/21/2022.06.21.html' | relative_url }})
{% raw %}
## Summary for 2022-06-20, created on 2022-06-24


<details><summary><b>The Role of Machine Learning in Cybersecurity</b>
<a href="https://arxiv.org/abs/2206.09707">arxiv:2206.09707</a>
&#x1F4C8; 133 <br>
<p>Giovanni Apruzzese, Pavel Laskov, Edgardo Montes de Oca, Wissam Mallouli, Luis Burdalo Rapa, Athanasios Vasileios Grammatopoulos, Fabio Di Franco</p></summary>
<p>

**Abstract:** Machine Learning (ML) represents a pivotal technology for current and future information systems, and many domains already leverage the capabilities of ML. However, deployment of ML in cybersecurity is still at an early stage, revealing a significant discrepancy between research and practice. Such discrepancy has its root cause in the current state-of-the-art, which does not allow to identify the role of ML in cybersecurity. The full potential of ML will never be unleashed unless its pros and cons are understood by a broad audience.
  This paper is the first attempt to provide a holistic understanding of the role of ML in the entire cybersecurity domain -- to any potential reader with an interest in this topic. We highlight the advantages of ML with respect to human-driven detection methods, as well as the additional tasks that can be addressed by ML in cybersecurity. Moreover, we elucidate various intrinsic problems affecting real ML deployments in cybersecurity. Finally, we present how various stakeholders can contribute to future developments of ML in cybersecurity, which is essential for further progress in this field. Our contributions are complemented with two real case studies describing industrial applications of ML as defense against cyber-threats.

</p>
</details>

<details><summary><b>Square One Bias in NLP: Towards a Multi-Dimensional Exploration of the Research Manifold</b>
<a href="https://arxiv.org/abs/2206.09755">arxiv:2206.09755</a>
&#x1F4C8; 20 <br>
<p>Sebastian Ruder, Ivan Vulić, Anders Søgaard</p></summary>
<p>

**Abstract:** The prototypical NLP experiment trains a standard architecture on labeled English data and optimizes for accuracy, without accounting for other dimensions such as fairness, interpretability, or computational efficiency. We show through a manual classification of recent NLP research papers that this is indeed the case and refer to it as the square one experimental setup. We observe that NLP research often goes beyond the square one setup, e.g, focusing not only on accuracy, but also on fairness or interpretability, but typically only along a single dimension. Most work targeting multilinguality, for example, considers only accuracy; most work on fairness or interpretability considers only English; and so on. We show this through manual classification of recent NLP research papers and ACL Test-of-Time award recipients. Such one-dimensionality of most research means we are only exploring a fraction of the NLP research search space. We provide historical and recent examples of how the square one bias has led researchers to draw false conclusions or make unwise choices, point to promising yet unexplored directions on the research manifold, and make practical recommendations to enable more multi-dimensional research. We open-source the results of our annotations to enable further analysis at https://github.com/google-research/url-nlp

</p>
</details>

<details><summary><b>Global Context Vision Transformers</b>
<a href="https://arxiv.org/abs/2206.09959">arxiv:2206.09959</a>
&#x1F4C8; 10 <br>
<p>Ali Hatamizadeh, Hongxu Yin, Jan Kautz, Pavlo Molchanov</p></summary>
<p>

**Abstract:** We propose global context vision transformer (GC ViT), a novel architecture that enhances parameter and compute utilization. Our method leverages global context self-attention modules, joint with local self-attention, to effectively yet efficiently model both long and short-range spatial interactions, without the need for expensive operations such as computing attention masks or shifting local windows. In addition, we address the issue of lack of the inductive bias in ViTs via proposing to use a modified fused inverted residual blocks in our architecture. Our proposed GC ViT achieves state-of-the-art results across image classification, object detection and semantic segmentation tasks. On ImageNet-1K dataset for classification, the base, small and tiny variants of GC ViT with $28$M, $51$M and $90$M parameters achieve $\textbf{83.2\%}$, $\textbf{83.9\%}$ and $\textbf{84.4\%}$ Top-1 accuracy, respectively, surpassing comparably-sized prior art such as CNN-based ConvNeXt and ViT-based Swin Transformer by a large margin. Pre-trained GC ViT backbones in downstream tasks of object detection, instance segmentation, and semantic segmentation using MS COCO and ADE20K datasets outperform prior work consistently, sometimes by large margins. Code available at https://github.com/NVlabs/GCViT.

</p>
</details>

<details><summary><b>Great Expectations: Unsupervised Inference of Suspense, Surprise and Salience in Storytelling</b>
<a href="https://arxiv.org/abs/2206.09708">arxiv:2206.09708</a>
&#x1F4C8; 6 <br>
<p>David Wilmot</p></summary>
<p>

**Abstract:** Stories interest us not because they are a sequence of mundane and predictable events but because they have drama and tension. Crucial to creating dramatic and exciting stories are surprise and suspense. The thesis trains a series of deep learning models via only reading stories, a self-supervised (or unsupervised) system. Narrative theory methods (rules and procedures) are applied to the knowledge built into deep learning models to directly infer salience, surprise, and salience in stories. Extensions add memory and external knowledge from story plots and from Wikipedia to infer salience on novels such as Great Expectations and plays such as Macbeth. Other work adapts the models as a planning system for generating original stories.
  The thesis finds that applying the narrative theory to deep learning models can align with the typical reader. In follow-up work, the insights could help improve computer models for tasks such as automatic story writing and assistance for writing, summarising or editing stories. Moreover, the approach of applying narrative theory to the inherent qualities built in a system that learns itself (self-supervised) from reading from books, watching videos, and listening to audio is much cheaper and more adaptable to other domains and tasks. Progress is swift in improving self-supervised systems. As such, the thesis's relevance is that applying domain expertise with these systems may be a more productive approach for applying machine learning in many areas of interest.

</p>
</details>

<details><summary><b>DNA: Proximal Policy Optimization with a Dual Network Architecture</b>
<a href="https://arxiv.org/abs/2206.10027">arxiv:2206.10027</a>
&#x1F4C8; 5 <br>
<p>Mathew Aitchison, Penny Sweetser</p></summary>
<p>

**Abstract:** This paper explores the problem of simultaneously learning a value function and policy in deep actor-critic reinforcement learning models. We find that the common practice of learning these functions jointly is sub-optimal, due to an order-of-magnitude difference in noise levels between these two tasks. Instead, we show that learning these tasks independently, but with a constrained distillation phase, significantly improves performance. Furthermore, we find that the policy gradient noise levels can be decreased by using a lower \textit{variance} return estimate. Whereas, the value learning noise level decreases with a lower \textit{bias} estimate. Together these insights inform an extension to Proximal Policy Optimization we call \textit{Dual Network Architecture} (DNA), which significantly outperforms its predecessor. DNA also exceeds the performance of the popular Rainbow DQN algorithm on four of the five environments tested, even under more difficult stochastic control settings.

</p>
</details>

<details><summary><b>WOLONet: Wave Outlooker for Efficient and High Fidelity Speech Synthesis</b>
<a href="https://arxiv.org/abs/2206.09920">arxiv:2206.09920</a>
&#x1F4C8; 5 <br>
<p>Yi Wang, Yi Si</p></summary>
<p>

**Abstract:** Recently, GAN-based neural vocoders such as Parallel WaveGAN, MelGAN, HiFiGAN, and UnivNet have become popular due to their lightweight and parallel structure, resulting in a real-time synthesized waveform with high fidelity, even on a CPU. HiFiGAN and UnivNet are two SOTA vocoders. Despite their high quality, there is still room for improvement. In this paper, motivated by the structure of Vision Outlooker from computer vision, we adopt a similar idea and propose an effective and lightweight neural vocoder called WOLONet. In this network, we develop a novel lightweight block that uses a location-variable, channel-independent, and depthwise dynamic convolutional kernel with sinusoidally activated dynamic kernel weights. To demonstrate the effectiveness and generalizability of our method, we perform an ablation study to verify our novel design and make a subjective and objective comparison with typical GAN-based vocoders. The results show that our WOLONet achieves the best generation quality while requiring fewer parameters than the two neural SOTA vocoders, HiFiGAN and UnivNet.

</p>
</details>

<details><summary><b>Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities</b>
<a href="https://arxiv.org/abs/2206.09880">arxiv:2206.09880</a>
&#x1F4C8; 5 <br>
<p>Julian Bitterwolf, Alexander Meinke, Maximilian Augustin, Matthias Hein</p></summary>
<p>

**Abstract:** It is an important problem in trustworthy machine learning to recognize out-of-distribution (OOD) inputs which are inputs unrelated to the in-distribution task. Many out-of-distribution detection methods have been suggested in recent years. The goal of this paper is to recognize common objectives as well as to identify the implicit scoring functions of different OOD detection methods. We focus on the sub-class of methods that use surrogate OOD data during training in order to learn an OOD detection score that generalizes to new unseen out-distributions at test time. We show that binary discrimination between in- and (different) out-distributions is equivalent to several distinct formulations of the OOD detection problem. When trained in a shared fashion with a standard classifier, this binary discriminator reaches an OOD detection performance similar to that of Outlier Exposure. Moreover, we show that the confidence loss which is used by Outlier Exposure has an implicit scoring function which differs in a non-trivial fashion from the theoretically optimal scoring function in the case where training and test out-distribution are the same, which again is similar to the one used when training an Energy-Based OOD detector or when adding a background class. In practice, when trained in exactly the same way, all these methods perform similarly.

</p>
</details>

<details><summary><b>EAGER: Asking and Answering Questions for Automatic Reward Shaping in Language-guided RL</b>
<a href="https://arxiv.org/abs/2206.09674">arxiv:2206.09674</a>
&#x1F4C8; 5 <br>
<p>Thomas Carta, Sylvain Lamprier, Pierre-Yves Oudeyer, Olivier Sigaud</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) in long horizon and sparse reward tasks is notoriously difficult and requires a lot of training steps. A standard solution to speed up the process is to leverage additional reward signals, shaping it to better guide the learning process. In the context of language-conditioned RL, the abstraction and generalisation properties of the language input provide opportunities for more efficient ways of shaping the reward. In this paper, we leverage this idea and propose an automated reward shaping method where the agent extracts auxiliary objectives from the general language goal. These auxiliary objectives use a question generation (QG) and question answering (QA) system: they consist of questions leading the agent to try to reconstruct partial information about the global goal using its own trajectory. When it succeeds, it receives an intrinsic reward proportional to its confidence in its answer. This incentivizes the agent to generate trajectories which unambiguously explain various aspects of the general language goal. Our experimental study shows that this approach, which does not require engineer intervention to design the auxiliary objectives, improves sample efficiency by effectively directing exploration.

</p>
</details>

<details><summary><b>Performance Prediction in Major League Baseball by Long Short-Term Memory Networks</b>
<a href="https://arxiv.org/abs/2206.09654">arxiv:2206.09654</a>
&#x1F4C8; 5 <br>
<p>Hsuan-Cheng Sun, Tse-Yu Lin, Yen-Lung Tsai</p></summary>
<p>

**Abstract:** Player performance prediction is a serious problem in every sport since it brings valuable future information for managers to make important decisions. In baseball industries, there already existed variable prediction systems and many types of researches that attempt to provide accurate predictions and help domain users. However, it is a lack of studies about the predicting method or systems based on deep learning. Deep learning models had proven to be the greatest solutions in different fields nowadays, so we believe they could be tried and applied to the prediction problem in baseball. Hence, the predicting abilities of deep learning models are set to be our research problem in this paper. As a beginning, we select numbers of home runs as the target because it is one of the most critical indexes to understand the power and the talent of baseball hitters. Moreover, we use the sequential model Long Short-Term Memory as our main method to solve the home run prediction problem in Major League Baseball. We compare models' ability with several machine learning models and a widely used baseball projection system, sZymborski Projection System. Our results show that Long Short-Term Memory has better performance than others and has the ability to make more exact predictions. We conclude that Long Short-Term Memory is a feasible way for performance prediction problems in baseball and could bring valuable information to fit users' needs.

</p>
</details>

<details><summary><b>Generating Diverse Indoor Furniture Arrangements</b>
<a href="https://arxiv.org/abs/2206.10608">arxiv:2206.10608</a>
&#x1F4C8; 4 <br>
<p>Ya-Chuan Hsu, Matthew C. Fontaine, Sam Earle, Maria Edwards, Julian Togelius, Stefanos Nikolaidis</p></summary>
<p>

**Abstract:** We present a method for generating arrangements of indoor furniture from human-designed furniture layout data. Our method creates arrangements that target specified diversity, such as the total price of all furniture in the room and the number of pieces placed. To generate realistic furniture arrangement, we train a generative adversarial network (GAN) on human-designed layouts. To target specific diversity in the arrangements, we optimize the latent space of the GAN via a quality diversity algorithm to generate a diverse arrangement collection. Experiments show our approach discovers a set of arrangements that are similar to human-designed layouts but varies in price and number of furniture pieces.

</p>
</details>

<details><summary><b>Identifiability of deep generative models under mixture priors without auxiliary information</b>
<a href="https://arxiv.org/abs/2206.10044">arxiv:2206.10044</a>
&#x1F4C8; 4 <br>
<p>Bohdan Kivva, Goutham Rajendran, Pradeep Ravikumar, Bryon Aragam</p></summary>
<p>

**Abstract:** We prove identifiability of a broad class of deep latent variable models that (a) have universal approximation capabilities and (b) are the decoders of variational autoencoders that are commonly used in practice. Unlike existing work, our analysis does not require weak supervision, auxiliary information, or conditioning in the latent space. Recently, there has been a surge of works studying identifiability of such models. In these works, the main assumption is that along with the data, an auxiliary variable $u$ (also known as side information) is observed as well. At the same time, several works have empirically observed that this doesn't seem to be necessary in practice. In this work, we explain this behavior by showing that for a broad class of generative (i.e. unsupervised) models with universal approximation capabilities, the side information $u$ is not necessary: We prove identifiability of the entire generative model where we do not observe $u$ and only observe the data $x$. The models we consider are tightly connected with autoencoder architectures used in practice that leverage mixture priors in the latent space and ReLU/leaky-ReLU activations in the encoder. Our main result is an identifiability hierarchy that significantly generalizes previous work and exposes how different assumptions lead to different "strengths" of identifiability. For example, our weakest result establishes (unsupervised) identifiability up to an affine transformation, which already improves existing work. It's well known that these models have universal approximation capabilities and moreover, they have been extensively used in practice to learn representations of data.

</p>
</details>

<details><summary><b>Intention-Aware Navigation in Crowds with Extended-Space POMDP Planning</b>
<a href="https://arxiv.org/abs/2206.10028">arxiv:2206.10028</a>
&#x1F4C8; 4 <br>
<p>Himanshu Gupta, Bradley Hayes, Zachary Sunberg</p></summary>
<p>

**Abstract:** This paper presents a hybrid online Partially Observable Markov Decision Process (POMDP) planning system that addresses the problem of autonomous navigation in the presence of multi-modal uncertainty introduced by other agents in the environment. As a particular example, we consider the problem of autonomous navigation in dense crowds of pedestrians and among obstacles. Popular approaches to this problem first generate a path using a complete planner (e.g., Hybrid A*) with ad-hoc assumptions about uncertainty, then use online tree-based POMDP solvers to reason about uncertainty with control over a limited aspect of the problem (i.e. speed along the path). We present a more capable and responsive real-time approach enabling the POMDP planner to control more degrees of freedom (e.g., both speed AND heading) to achieve more flexible and efficient solutions. This modification greatly extends the region of the state space that the POMDP planner must reason over, significantly increasing the importance of finding effective roll-out policies within the limited computational budget that real time control affords. Our key insight is to use multi-query motion planning techniques (e.g., Probabilistic Roadmaps or Fast Marching Method) as priors for rapidly generating efficient roll-out policies for every state that the POMDP planning tree might reach during its limited horizon search. Our proposed approach generates trajectories that are safe and significantly more efficient than the previous approach, even in densely crowded dynamic environments with long planning horizons.

</p>
</details>

<details><summary><b>Deep Partial Least Squares for Empirical Asset Pricing</b>
<a href="https://arxiv.org/abs/2206.10014">arxiv:2206.10014</a>
&#x1F4C8; 4 <br>
<p>Matthew F. Dixon, Nicholas G. Polson, Kemen Goicoechea</p></summary>
<p>

**Abstract:** We use deep partial least squares (DPLS) to estimate an asset pricing model for individual stock returns that exploits conditioning information in a flexible and dynamic way while attributing excess returns to a small set of statistical risk factors. The novel contribution is to resolve the non-linear factor structure, thus advancing the current paradigm of deep learning in empirical asset pricing which uses linear stochastic discount factors under an assumption of Gaussian asset returns and factors. This non-linear factor structure is extracted by using projected least squares to jointly project firm characteristics and asset returns on to a subspace of latent factors and using deep learning to learn the non-linear map from the factor loadings to the asset returns. The result of capturing this non-linear risk factor structure is to characterize anomalies in asset returns by both linear risk factor exposure and interaction effects. Thus the well known ability of deep learning to capture outliers, shed lights on the role of convexity and higher order terms in the latent factor structure on the factor risk premia. On the empirical side, we implement our DPLS factor models and exhibit superior performance to LASSO and plain vanilla deep learning models. Furthermore, our network training times are significantly reduced due to the more parsimonious architecture of DPLS. Specifically, using 3290 assets in the Russell 1000 index over a period of December 1989 to January 2018, we assess our DPLS factor model and generate information ratios that are approximately 1.2x greater than deep learning. DPLS explains variation and pricing errors and identifies the most prominent latent factors and firm characteristics.

</p>
</details>

<details><summary><b>When Does Re-initialization Work?</b>
<a href="https://arxiv.org/abs/2206.10011">arxiv:2206.10011</a>
&#x1F4C8; 4 <br>
<p>Sheheryar Zaidi, Tudor Berariu, Hyunjik Kim, Jörg Bornschein, Claudia Clopath, Yee Whye Teh, Razvan Pascanu</p></summary>
<p>

**Abstract:** Re-initializing a neural network during training has been observed to improve generalization in recent works. Yet it is neither widely adopted in deep learning practice nor is it often used in state-of-the-art training protocols. This raises the question of when re-initialization works, and whether it should be used together with regularization techniques such as data augmentation, weight decay and learning rate schedules. In this work, we conduct an extensive empirical comparison of standard training with a selection of re-initialization methods to answer this question, training over 15,000 models on a variety of image classification benchmarks. We first establish that such methods are consistently beneficial for generalization in the absence of any other regularization. However, when deployed alongside other carefully tuned regularization techniques, re-initialization methods offer little to no added benefit for generalization, although optimal generalization performance becomes less sensitive to the choice of learning rate and weight decay hyperparameters. To investigate the impact of re-initialization methods on noisy data, we also consider learning under label noise. Surprisingly, in this case, re-initialization significantly improves upon standard training, even in the presence of other carefully tuned regularization techniques.

</p>
</details>

<details><summary><b>Model Optimization in Imbalanced Regression</b>
<a href="https://arxiv.org/abs/2206.09991">arxiv:2206.09991</a>
&#x1F4C8; 4 <br>
<p>Aníbal Silva, Rita P. Ribeiro, Nuno Moniz</p></summary>
<p>

**Abstract:** Imbalanced domain learning aims to produce accurate models in predicting instances that, though underrepresented, are of utmost importance for the domain. Research in this field has been mainly focused on classification tasks. Comparatively, the number of studies carried out in the context of regression tasks is negligible. One of the main reasons for this is the lack of loss functions capable of focusing on minimizing the errors of extreme (rare) values. Recently, an evaluation metric was introduced: Squared Error Relevance Area (SERA). This metric posits a bigger emphasis on the errors committed at extreme values while also accounting for the performance in the overall target variable domain, thus preventing severe bias. However, its effectiveness as an optimization metric is unknown. In this paper, our goal is to study the impacts of using SERA as an optimization criterion in imbalanced regression tasks. Using gradient boosting algorithms as proof of concept, we perform an experimental study with 36 data sets of different domains and sizes. Results show that models that used SERA as an objective function are practically better than the models produced by their respective standard boosting algorithms at the prediction of extreme values. This confirms that SERA can be embedded as a loss function into optimization-based learning algorithms for imbalanced regression scenarios.

</p>
</details>

<details><summary><b>Quantum machine learning channel discrimination</b>
<a href="https://arxiv.org/abs/2206.09933">arxiv:2206.09933</a>
&#x1F4C8; 4 <br>
<p>Andrey Kardashin, Anna vlasova, Anastasia Pervishko, Dmitry Yudin, Jacob Biamonte</p></summary>
<p>

**Abstract:** In the problem of quantum channel discrimination, one distinguishes between a given number of quantum channels, which is done by sending an input state through a channel and measuring the output state. This work studies applications of variational quantum circuits and machine learning techniques for discriminating such channels. In particular, we explore (i) the practical implementation of embedding this task into the framework of variational quantum computing, (ii) training a quantum classifier based on variational quantum circuits, and (iii) applying the quantum kernel estimation technique. For testing these three channel discrimination approaches, we considered a pair of entanglement-breaking channels and the depolarizing channel with two different depolarization factors. For the approach (i), we address solving the quantum channel discrimination problem using widely discussed parallel and sequential strategies. We show the advantage of the latter in terms of better convergence with less quantum resources. Quantum channel discrimination with a variational quantum classifier (ii) allows one to operate even with random and mixed input states and simple variational circuits. The kernel-based classification approach (iii) is also found effective as it allows one to discriminate depolarizing channels associated not with just fixed values of the depolarization factor, but with ranges of it. Additionally, we discovered that a simple modification of one of the commonly used kernels significantly increases the efficiency of this approach. Finally, our numerical findings reveal that the performance of variational methods of channel discrimination depends on the trace of the product of the output states. These findings demonstrate that quantum machine learning can be used to discriminate channels, such as those representing physical noise processes.

</p>
</details>

<details><summary><b>A Langevin-like Sampler for Discrete Distributions</b>
<a href="https://arxiv.org/abs/2206.09914">arxiv:2206.09914</a>
&#x1F4C8; 4 <br>
<p>Ruqi Zhang, Xingchao Liu, Qiang Liu</p></summary>
<p>

**Abstract:** We propose discrete Langevin proposal (DLP), a simple and scalable gradient-based proposal for sampling complex high-dimensional discrete distributions. In contrast to Gibbs sampling-based methods, DLP is able to update all coordinates in parallel in a single step and the magnitude of changes is controlled by a stepsize. This allows a cheap and efficient exploration in the space of high-dimensional and strongly correlated variables. We prove the efficiency of DLP by showing that the asymptotic bias of its stationary distribution is zero for log-quadratic distributions, and is small for distributions that are close to being log-quadratic. With DLP, we develop several variants of sampling algorithms, including unadjusted, Metropolis-adjusted, stochastic and preconditioned versions. DLP outperforms many popular alternatives on a wide variety of tasks, including Ising models, restricted Boltzmann machines, deep energy-based models, binary neural networks and language generation.

</p>
</details>

<details><summary><b>Nocturne: a scalable driving benchmark for bringing multi-agent learning one step closer to the real world</b>
<a href="https://arxiv.org/abs/2206.09889">arxiv:2206.09889</a>
&#x1F4C8; 4 <br>
<p>Eugene Vinitsky, Nathan Lichtlé, Xiaomeng Yang, Brandon Amos, Jakob Foerster</p></summary>
<p>

**Abstract:** We introduce \textit{Nocturne}, a new 2D driving simulator for investigating multi-agent coordination under partial observability. The focus of Nocturne is to enable research into inference and theory of mind in real-world multi-agent settings without the computational overhead of computer vision and feature extraction from images. Agents in this simulator only observe an obstructed view of the scene, mimicking human visual sensing constraints. Unlike existing benchmarks that are bottlenecked by rendering human-like observations directly using a camera input, Nocturne uses efficient intersection methods to compute a vectorized set of visible features in a C++ back-end, allowing the simulator to run at $2000+$ steps-per-second. Using open-source trajectory and map data, we construct a simulator to load and replay arbitrary trajectories and scenes from real-world driving data. Using this environment, we benchmark reinforcement-learning and imitation-learning agents and demonstrate that the agents are quite far from human-level coordination ability and deviate significantly from the expert trajectories.

</p>
</details>

<details><summary><b>SMT-DTA: Improving Drug-Target Affinity Prediction with Semi-supervised Multi-task Training</b>
<a href="https://arxiv.org/abs/2206.09818">arxiv:2206.09818</a>
&#x1F4C8; 4 <br>
<p>Qizhi Pei, Lijun Wu, Jinhua Zhu, Yingce Xia, Shufang Xie, Tao Qin, Haiguang Liu, Tie-Yan Liu</p></summary>
<p>

**Abstract:** Drug-Target Affinity (DTA) prediction is an essential task for drug discovery and pharmaceutical research. Accurate predictions of DTA can greatly benefit the design of new drug. As wet experiments are costly and time consuming, the supervised data for DTA prediction is extremely limited. This seriously hinders the application of deep learning based methods, which require a large scale of supervised data. To address this challenge and improve the DTA prediction accuracy, we propose a framework with several simple yet effective strategies in this work: (1) a multi-task training strategy, which takes the DTA prediction and the masked language modeling (MLM) task on the paired drug-target dataset; (2) a semi-supervised training method to empower the drug and target representation learning by leveraging large-scale unpaired molecules and proteins in training, which differs from previous pre-training and fine-tuning methods that only utilize molecules or proteins in pre-training; and (3) a cross-attention module to enhance the interaction between drug and target representation. Extensive experiments are conducted on three real-world benchmark datasets: BindingDB, DAVIS and KIBA. The results show that our framework significantly outperforms existing methods and achieves state-of-the-art performances, e.g., $0.712$ RMSE on BindingDB IC$_{50}$ measurement with more than $5\%$ improvement than previous best work. In addition, case studies on specific drug-target binding activities, drug feature visualizations, and real-world applications demonstrate the great potential of our work. The code and data are released at https://github.com/QizhiPei/SMT-DTA

</p>
</details>

<details><summary><b>Sampling Efficient Deep Reinforcement Learning through Preference-Guided Stochastic Exploration</b>
<a href="https://arxiv.org/abs/2206.09627">arxiv:2206.09627</a>
&#x1F4C8; 4 <br>
<p>Wenhui Huang, Cong Zhang, Jingda Wu, Xiangkun He, Jie Zhang, Chen Lv</p></summary>
<p>

**Abstract:** Massive practical works addressed by Deep Q-network (DQN) algorithm have indicated that stochastic policy, despite its simplicity, is the most frequently used exploration approach. However, most existing stochastic exploration approaches either explore new actions heuristically regardless of Q-values or inevitably introduce bias into the learning process to couple the sampling with Q-values. In this paper, we propose a novel preference-guided $ε$-greedy exploration algorithm that can efficiently learn the action distribution in line with the landscape of Q-values for DQN without introducing additional bias. Specifically, we design a dual architecture consisting of two branches, one of which is a copy of DQN, namely the Q-branch. The other branch, which we call the preference branch, learns the action preference that the DQN implicit follows. We theoretically prove that the policy improvement theorem holds for the preference-guided $ε$-greedy policy and experimentally show that the inferred action preference distribution aligns with the landscape of corresponding Q-values. Consequently, preference-guided $ε$-greedy exploration motivates the DQN agent to take diverse actions, i.e., actions with larger Q-values can be sampled more frequently whereas actions with smaller Q-values still have a chance to be explored, thus encouraging the exploration. We assess the proposed method with four well-known DQN variants in nine different environments. Extensive results confirm the superiority of our proposed method in terms of performance and convergence speed.
  Index Terms- Preference-guided exploration, stochastic policy, data efficiency, deep reinforcement learning, deep Q-learning.

</p>
</details>

<details><summary><b>Business Document Information Extraction: Towards Practical Benchmarks</b>
<a href="https://arxiv.org/abs/2206.11229">arxiv:2206.11229</a>
&#x1F4C8; 3 <br>
<p>Matyáš Skalický, Štěpán Šimsa, Michal Uřičář, Milan Šulc</p></summary>
<p>

**Abstract:** Information extraction from semi-structured documents is crucial for frictionless business-to-business (B2B) communication. While machine learning problems related to Document Information Extraction (IE) have been studied for decades, many common problem definitions and benchmarks do not reflect domain-specific aspects and practical needs for automating B2B document communication. We review the landscape of Document IE problems, datasets and benchmarks. We highlight the practical aspects missing in the common definitions and define the Key Information Localization and Extraction (KILE) and Line Item Recognition (LIR) problems. There is a lack of relevant datasets and benchmarks for Document IE on semi-structured business documents as their content is typically legally protected or sensitive. We discuss potential sources of available documents including synthetic data.

</p>
</details>

<details><summary><b>Model-Based Imitation Learning Using Entropy Regularization of Model and Policy</b>
<a href="https://arxiv.org/abs/2206.10101">arxiv:2206.10101</a>
&#x1F4C8; 3 <br>
<p>Eiji Uchibe</p></summary>
<p>

**Abstract:** Approaches based on generative adversarial networks for imitation learning are promising because they are sample efficient in terms of expert demonstrations. However, training a generator requires many interactions with the actual environment because model-free reinforcement learning is adopted to update a policy. To improve the sample efficiency using model-based reinforcement learning, we propose model-based Entropy-Regularized Imitation Learning (MB-ERIL) under the entropy-regularized Markov decision process to reduce the number of interactions with the actual environment. MB-ERIL uses two discriminators. A policy discriminator distinguishes the actions generated by a robot from expert ones, and a model discriminator distinguishes the counterfactual state transitions generated by the model from the actual ones. We derive the structured discriminators so that the learning of the policy and the model is efficient. Computer simulations and real robot experiments show that MB-ERIL achieves a competitive performance and significantly improves the sample efficiency compared to baseline methods.

</p>
</details>

<details><summary><b>Transformers Improve Breast Cancer Diagnosis from Unregistered Multi-View Mammograms</b>
<a href="https://arxiv.org/abs/2206.10096">arxiv:2206.10096</a>
&#x1F4C8; 3 <br>
<p>Xuxin Chen, Ke Zhang, Neman Abdoli, Patrik W. Gilley, Ximin Wang, Hong Liu, Bin Zheng, Yuchen Qiu</p></summary>
<p>

**Abstract:** Deep convolutional neural networks (CNNs) have been widely used in various medical imaging tasks. However, due to the intrinsic locality of convolution operation, CNNs generally cannot model long-range dependencies well, which are important for accurately identifying or mapping corresponding breast lesion features computed from unregistered multiple mammograms. This motivates us to leverage the architecture of Multi-view Vision Transformers to capture long-range relationships of multiple mammograms from the same patient in one examination. For this purpose, we employ local Transformer blocks to separately learn patch relationships within four mammograms acquired from two-view (CC/MLO) of two-side (right/left) breasts. The outputs from different views and sides are concatenated and fed into global Transformer blocks, to jointly learn patch relationships between four images representing two different views of the left and right breasts. To evaluate the proposed model, we retrospectively assembled a dataset involving 949 sets of mammograms, which include 470 malignant cases and 479 normal or benign cases. We trained and evaluated the model using a five-fold cross-validation method. Without any arduous preprocessing steps (e.g., optimal window cropping, chest wall or pectoral muscle removal, two-view image registration, etc.), our four-image (two-view-two-side) Transformer-based model achieves case classification performance with an area under ROC curve (AUC = 0.818), which significantly outperforms AUC = 0.784 achieved by the state-of-the-art multi-view CNNs (p = 0.009). It also outperforms two one-view-two-side models that achieve AUC of 0.724 (CC view) and 0.769 (MLO view), respectively. The study demonstrates the potential of using Transformers to develop high-performing computer-aided diagnosis schemes that combine four mammograms.

</p>
</details>

<details><summary><b>One-stage Action Detection Transformer</b>
<a href="https://arxiv.org/abs/2206.10080">arxiv:2206.10080</a>
&#x1F4C8; 3 <br>
<p>Lijun Li, Li'an Zhuo, Bang Zhang</p></summary>
<p>

**Abstract:** In this work, we introduce our solution to the EPIC-KITCHENS-100 2022 Action Detection challenge. One-stage Action Detection Transformer (OADT) is proposed to model the temporal connection of video segments. With the help of OADT, both the category and time boundary can be recognized simultaneously. After ensembling multiple OADT models trained from different features, our model can reach 21.28\% action mAP and ranks the 1st on the test-set of the Action detection challenge.

</p>
</details>

<details><summary><b>Decentralized Distributed Learning with Privacy-Preserving Data Synthesis</b>
<a href="https://arxiv.org/abs/2206.10048">arxiv:2206.10048</a>
&#x1F4C8; 3 <br>
<p>Matteo Pennisi, Federica Proietto Salanitri, Giovanni Bellitto, Bruno Casella, Marco Aldinucci, Simone Palazzo, Concetto Spampinato</p></summary>
<p>

**Abstract:** In the medical field, multi-center collaborations are often sought to yield more generalizable findings by leveraging the heterogeneity of patient and clinical data. However, recent privacy regulations hinder the possibility to share data, and consequently, to come up with machine learning-based solutions that support diagnosis and prognosis. Federated learning (FL) aims at sidestepping this limitation by bringing AI-based solutions to data owners and only sharing local AI models, or parts thereof, that need then to be aggregated. However, most of the existing federated learning solutions are still at their infancy and show several shortcomings, from the lack of a reliable and effective aggregation scheme able to retain the knowledge learned locally to weak privacy preservation as real data may be reconstructed from model updates. Furthermore, the majority of these approaches, especially those dealing with medical data, relies on a centralized distributed learning strategy that poses robustness, scalability and trust issues. In this paper we present a decentralized distributed method that, exploiting concepts from experience replay and generative adversarial research, effectively integrates features from local nodes, providing models able to generalize across multiple datasets while maintaining privacy. The proposed approach is tested on two tasks - tuberculosis and melanoma classification - using multiple datasets in order to simulate realistic non-i.i.d. data scenarios. Results show that our approach achieves performance comparable to both standard (non-federated) learning and federated methods in their centralized (thus, more favourable) formulation.

</p>
</details>

<details><summary><b>Deep Learning Models on CPUs: A Methodology for Efficient Training</b>
<a href="https://arxiv.org/abs/2206.10034">arxiv:2206.10034</a>
&#x1F4C8; 3 <br>
<p>Quchen Fu, Ramesh Chukka, Keith Achorn, Thomas Atta-fosu, Deepak R. Canchi, Zhongwei Teng, Jules White, Douglas C. Schmidt</p></summary>
<p>

**Abstract:** GPUs have been favored for training deep learning models due to their highly parallelized architecture. As a result, most studies on training optimization focus on GPUs. There is often a trade-off, however, between cost and efficiency when deciding on how to choose the proper hardware for training. In particular, CPU servers can be beneficial if training on CPUs was more efficient, as they incur fewer hardware update costs and better utilizing existing infrastructure. This paper makes several contributions to research on training deep learning models using CPUs. First, it presents a method for optimizing the training of deep learning models on Intel CPUs and a toolkit called ProfileDNN, which we developed to improve performance profiling. Second, we describe a generic training optimization method that guides our workflow and explores several case studies where we identified performance issues and then optimized the Intel Extension for PyTorch, resulting in an overall 2x training performance increase for the RetinaNet-ResNext50 model. Third, we show how to leverage the visualization capabilities of ProfileDNN, which enabled us to pinpoint bottlenecks and create a custom focal loss kernel that was two times faster than the official reference PyTorch implementation.

</p>
</details>

<details><summary><b>Limitations of the NTK for Understanding Generalization in Deep Learning</b>
<a href="https://arxiv.org/abs/2206.10012">arxiv:2206.10012</a>
&#x1F4C8; 3 <br>
<p>Nikhil Vyas, Yamini Bansal, Preetum Nakkiran</p></summary>
<p>

**Abstract:** The ``Neural Tangent Kernel'' (NTK) (Jacot et al 2018), and its empirical variants have been proposed as a proxy to capture certain behaviors of real neural networks. In this work, we study NTKs through the lens of scaling laws, and demonstrate that they fall short of explaining important aspects of neural network generalization. In particular, we demonstrate realistic settings where finite-width neural networks have significantly better data scaling exponents as compared to their corresponding empirical and infinite NTKs at initialization. This reveals a more fundamental difference between the real networks and NTKs, beyond just a few percentage points of test accuracy. Further, we show that even if the empirical NTK is allowed to be pre-trained on a constant number of samples, the kernel scaling does not catch up to the neural network scaling. Finally, we show that the empirical NTK continues to evolve throughout most of the training, in contrast with prior work which suggests that it stabilizes after a few epochs of training. Altogether, our work establishes concrete limitations of the NTK approach in understanding generalization of real networks on natural datasets.

</p>
</details>

<details><summary><b>Thompson Sampling Efficiently Learns to Control Diffusion Processes</b>
<a href="https://arxiv.org/abs/2206.09977">arxiv:2206.09977</a>
&#x1F4C8; 3 <br>
<p>Mohamad Kazem Shirani Faradonbeh, Mohamad Sadegh Shirani Faradonbeh, Mohsen Bayati</p></summary>
<p>

**Abstract:** Diffusion processes that evolve according to linear stochastic differential equations are an important family of continuous-time dynamic decision-making models. Optimal policies are well-studied for them, under full certainty about the drift matrices. However, little is known about data-driven control of diffusion processes with uncertain drift matrices as conventional discrete-time analysis techniques are not applicable. In addition, while the task can be viewed as a reinforcement learning problem involving exploration and exploitation trade-off, ensuring system stability is a fundamental component of designing optimal policies. We establish that the popular Thompson sampling algorithm learns optimal actions fast, incurring only a square-root of time regret, and also stabilizes the system in a short time period. To the best of our knowledge, this is the first such result for Thompson sampling in a diffusion process control problem. We validate our theoretical results through empirical simulations with real parameter matrices from two settings of airplane and blood glucose control. Moreover, we observe that Thompson sampling significantly improves (worst-case) regret, compared to the state-of-the-art algorithms, suggesting Thompson sampling explores in a more guarded fashion. Our theoretical analysis involves characterization of a certain optimality manifold that ties the local geometry of the drift parameters to the optimal control of the diffusion process. We expect this technique to be of broader interest.

</p>
</details>

<details><summary><b>Only Tails Matter: Average-Case Universality and Robustness in the Convex Regime</b>
<a href="https://arxiv.org/abs/2206.09901">arxiv:2206.09901</a>
&#x1F4C8; 3 <br>
<p>Leonardo Cunha, Gauthier Gidel, Fabian Pedregosa, Damien Scieur, Courtney Paquette</p></summary>
<p>

**Abstract:** The recently developed average-case analysis of optimization methods allows a more fine-grained and representative convergence analysis than usual worst-case results. In exchange, this analysis requires a more precise hypothesis over the data generating process, namely assuming knowledge of the expected spectral distribution (ESD) of the random matrix associated with the problem. This work shows that the concentration of eigenvalues near the edges of the ESD determines a problem's asymptotic average complexity. This a priori information on this concentration is a more grounded assumption than complete knowledge of the ESD. This approximate concentration is effectively a middle ground between the coarseness of the worst-case scenario convergence and the restrictive previous average-case analysis. We also introduce the Generalized Chebyshev method, asymptotically optimal under a hypothesis on this concentration and globally optimal when the ESD follows a Beta distribution. We compare its performance to classical optimization algorithms, such as gradient descent or Nesterov's scheme, and we show that, in the average-case context, Nesterov's method is universally nearly optimal asymptotically.

</p>
</details>

<details><summary><b>Variational Quantum and Quantum-Inspired Clustering</b>
<a href="https://arxiv.org/abs/2206.09893">arxiv:2206.09893</a>
&#x1F4C8; 3 <br>
<p>Pablo Bermejo, Roman Orus</p></summary>
<p>

**Abstract:** Here we present a quantum algorithm for clustering data based on a variational quantum circuit. The algorithm allows to classify data into many clusters, and can easily be implemented in few-qubit Noisy Intermediate-Scale Quantum (NISQ) devices. The idea of the algorithm relies on reducing the clustering problem to an optimization, and then solving it via a Variational Quantum Eigensolver (VQE) combined with non-orthogonal qubit states. In practice, the method uses maximally-orthogonal states of the target Hilbert space instead of the usual computational basis, allowing for a large number of clusters to be considered even with few qubits. We benchmark the algorithm with numerical simulations using real datasets, showing excellent performance even with one single qubit. Moreover, a tensor network simulation of the algorithm implements, by construction, a quantum-inspired clustering algorithm that can run on current classical hardware.

</p>
</details>

<details><summary><b>Latent Variable Modelling Using Variational Autoencoders: A survey</b>
<a href="https://arxiv.org/abs/2206.09891">arxiv:2206.09891</a>
&#x1F4C8; 3 <br>
<p>Vasanth Kalingeri</p></summary>
<p>

**Abstract:** A probability distribution allows practitioners to uncover hidden structure in the data and build models to solve supervised learning problems using limited data. The focus of this report is on Variational autoencoders, a method to learn the probability distribution of large complex datasets. The report provides a theoretical understanding of variational autoencoders and consolidates the current research in the field.
  The report is divided into multiple chapters, the first chapter introduces the problem, describes variational autoencoders and identifies key research directions in the field. Chapters 2, 3, 4 and 5 dive into the details of each of the key research areas. Chapter 6 concludes the report and suggests directions for future work.
  A reader who has a basic idea of machine learning but wants to learn about general themes in machine learning research can benefit from the report. The report explains central ideas on learning probability distributions, what people did to make this tractable and goes into details around how deep learning is currently applied. The report also serves a gentle introduction for someone looking to contribute to this sub-field.

</p>
</details>

<details><summary><b>Additive Gaussian Processes Revisited</b>
<a href="https://arxiv.org/abs/2206.09861">arxiv:2206.09861</a>
&#x1F4C8; 3 <br>
<p>Xiaoyu Lu, Alexis Boukouvalas, James Hensman</p></summary>
<p>

**Abstract:** Gaussian Process (GP) models are a class of flexible non-parametric models that have rich representational power. By using a Gaussian process with additive structure, complex responses can be modelled whilst retaining interpretability. Previous work showed that additive Gaussian process models require high-dimensional interaction terms. We propose the orthogonal additive kernel (OAK), which imposes an orthogonality constraint on the additive functions, enabling an identifiable, low-dimensional representation of the functional relationship. We connect the OAK kernel to functional ANOVA decomposition, and show improved convergence rates for sparse computation methods. With only a small number of additive low-dimensional terms, we demonstrate the OAK model achieves similar or better predictive performance compared to black-box models, while retaining interpretability.

</p>
</details>

<details><summary><b>A Distributional Approach for Soft Clustering Comparison and Evaluation</b>
<a href="https://arxiv.org/abs/2206.09827">arxiv:2206.09827</a>
&#x1F4C8; 3 <br>
<p>Andrea Campagner, Davide Ciucci, Thierry Denœux</p></summary>
<p>

**Abstract:** The development of external evaluation criteria for soft clustering (SC) has received limited attention: existing methods do not provide a general approach to extend comparison measures to SC, and are unable to account for the uncertainty represented in the results of SC algorithms. In this article, we propose a general method to address these limitations, grounding on a novel interpretation of SC as distributions over hard clusterings, which we call \emph{distributional measures}. We provide an in-depth study of complexity- and metric-theoretic properties of the proposed approach, and we describe approximation techniques that can make the calculations tractable. Finally, we illustrate our approach through a simple but illustrative experiment.

</p>
</details>

<details><summary><b>Guided Safe Shooting: model based reinforcement learning with safety constraints</b>
<a href="https://arxiv.org/abs/2206.09743">arxiv:2206.09743</a>
&#x1F4C8; 3 <br>
<p>Giuseppe Paolo, Jonas Gonzalez-Billandon, Albert Thomas, Balázs Kégl</p></summary>
<p>

**Abstract:** In the last decade, reinforcement learning successfully solved complex control tasks and decision-making problems, like the Go board game. Yet, there are few success stories when it comes to deploying those algorithms to real-world scenarios. One of the reasons is the lack of guarantees when dealing with and avoiding unsafe states, a fundamental requirement in critical control engineering systems. In this paper, we introduce Guided Safe Shooting (GuSS), a model-based RL approach that can learn to control systems with minimal violations of the safety constraints. The model is learned on the data collected during the operation of the system in an iterated batch fashion, and is then used to plan for the best action to perform at each time step. We propose three different safe planners, one based on a simple random shooting strategy and two based on MAP-Elites, a more advanced divergent-search algorithm. Experiments show that these planners help the learning agent avoid unsafe situations while maximally exploring the state space, a necessary aspect when learning an accurate model of the system. Furthermore, compared to model-free approaches, learning a model allows GuSS reducing the number of interactions with the real-system while still reaching high rewards, a fundamental requirement when handling engineering systems.

</p>
</details>

<details><summary><b>GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2206.09677">arxiv:2206.09677</a>
&#x1F4C8; 3 <br>
<p>Kenza Amara, Rex Ying, Zitao Zhang, Zhihao Han, Yinan Shan, Ulrik Brandes, Sebastian Schemm, Ce Zhang</p></summary>
<p>

**Abstract:** As one of the most popular machine learning models today, graph neural networks (GNNs) have attracted intense interest recently, and so does their explainability. Users are increasingly interested in a better understanding of GNN models and their outcomes. Unfortunately, today's evaluation frameworks for GNN explainability often rely on synthetic datasets, leading to conclusions of limited scope due to a lack of complexity in the problem instances. As GNN models are deployed to more mission-critical applications, we are in dire need for a common evaluation protocol of explainability methods of GNNs. In this paper, we propose, to our best knowledge, the first systematic evaluation framework for GNN explainability, considering explainability on three different "user needs:" explanation focus, mask nature, and mask transformation. We propose a unique metric that combines the fidelity measures and classify explanations based on their quality of being sufficient or necessary. We scope ourselves to node classification tasks and compare the most representative techniques in the field of input-level explainability for GNNs. For the widely used synthetic benchmarks, surprisingly shallow techniques such as personalized PageRank have the best performance for a minimum computation time. But when the graph structure is more complex and nodes have meaningful features, gradient-based methods, in particular Saliency, are the best according to our evaluation criteria. However, none dominates the others on all evaluation dimensions and there is always a trade-off. We further apply our evaluation protocol in a case study on eBay graphs to reflect the production environment.

</p>
</details>

<details><summary><b>What Can be Seen is What You Get: Structure Aware Point Cloud Augmentation</b>
<a href="https://arxiv.org/abs/2206.09664">arxiv:2206.09664</a>
&#x1F4C8; 3 <br>
<p>Frederik Hasecke, Martin Alsfasser, Anton Kummert</p></summary>
<p>

**Abstract:** To train a well performing neural network for semantic segmentation, it is crucial to have a large dataset with available ground truth for the network to generalize on unseen data. In this paper we present novel point cloud augmentation methods to artificially diversify a dataset. Our sensor-centric methods keep the data structure consistent with the lidar sensor capabilities. Due to these new methods, we are able to enrich low-value data with high-value instances, as well as create entirely new scenes. We validate our methods on multiple neural networks with the public SemanticKITTI dataset and demonstrate that all networks improve compared to their respective baseline. In addition, we show that our methods enable the use of very small datasets, saving annotation time, training time and the associated costs.

</p>
</details>

<details><summary><b>FedSSO: A Federated Server-Side Second-Order Optimization Algorithm</b>
<a href="https://arxiv.org/abs/2206.09576">arxiv:2206.09576</a>
&#x1F4C8; 3 <br>
<p>Xin Ma, Renyi Bao, Jinpeng Jiang, Yang Liu, Arthur Jiang, Jun Yan, Xin Liu, Zhisong Pan</p></summary>
<p>

**Abstract:** In this work, we propose FedSSO, a server-side second-order optimization method for federated learning (FL). In contrast to previous works in this direction, we employ a server-side approximation for the Quasi-Newton method without requiring any training data from the clients. In this way, we not only shift the computation burden from clients to server, but also eliminate the additional communication for second-order updates between clients and server entirely. We provide theoretical guarantee for convergence of our novel method, and empirically demonstrate our fast convergence and communication savings in both convex and non-convex settings.

</p>
</details>

<details><summary><b>C-SENN: Contrastive Self-Explaining Neural Network</b>
<a href="https://arxiv.org/abs/2206.09575">arxiv:2206.09575</a>
&#x1F4C8; 3 <br>
<p>Yoshihide Sawada, Keigo Nakamura</p></summary>
<p>

**Abstract:** In this study, we use a self-explaining neural network (SENN), which learns unsupervised concepts, to acquire concepts that are easy for people to understand automatically. In concept learning, the hidden layer retains verbalizable features relevant to the output, which is crucial when adapting to real-world environments where explanations are required. However, it is known that the interpretability of concepts output by SENN is reduced in general settings, such as autonomous driving scenarios. Thus, this study combines contrastive learning with concept learning to improve the readability of concepts and the accuracy of tasks. We call this model Contrastive Self-Explaining Neural Network (C-SENN).

</p>
</details>

<details><summary><b>S2RL: Do We Really Need to Perceive All States in Deep Multi-Agent Reinforcement Learning?</b>
<a href="https://arxiv.org/abs/2206.11054">arxiv:2206.11054</a>
&#x1F4C8; 2 <br>
<p>Shuang Luo, Yinchuan Li, Jiahui Li, Kun Kuang, Furui Liu, Yunfeng Shao, Chao Wu</p></summary>
<p>

**Abstract:** Collaborative multi-agent reinforcement learning (MARL) has been widely used in many practical applications, where each agent makes a decision based on its own observation. Most mainstream methods treat each local observation as an entirety when modeling the decentralized local utility functions. However, they ignore the fact that local observation information can be further divided into several entities, and only part of the entities is helpful to model inference. Moreover, the importance of different entities may change over time. To improve the performance of decentralized policies, the attention mechanism is used to capture features of local information. Nevertheless, existing attention models rely on dense fully connected graphs and cannot better perceive important states. To this end, we propose a sparse state based MARL (S2RL) framework, which utilizes a sparse attention mechanism to discard irrelevant information in local observations. The local utility functions are estimated through the self-attention and sparse attention mechanisms separately, then are combined into a standard joint value function and auxiliary joint value function in the central critic. We design the S2RL framework as a plug-and-play module, making it general enough to be applied to various methods. Extensive experiments on StarCraft II show that S2RL can significantly improve the performance of many state-of-the-art methods.

</p>
</details>

<details><summary><b>COVYT: Introducing the Coronavirus YouTube and TikTok speech dataset featuring the same speakers with and without infection</b>
<a href="https://arxiv.org/abs/2206.11045">arxiv:2206.11045</a>
&#x1F4C8; 2 <br>
<p>Andreas Triantafyllopoulos, Anastasia Semertzidou, Meishu Song, Florian B. Pokorny, Björn W. Schuller</p></summary>
<p>

**Abstract:** More than two years after its outbreak, the COVID-19 pandemic continues to plague medical systems around the world, putting a strain on scarce resources, and claiming human lives. From the very beginning, various AI-based COVID-19 detection and monitoring tools have been pursued in an attempt to stem the tide of infections through timely diagnosis. In particular, computer audition has been suggested as a non-invasive, cost-efficient, and eco-friendly alternative for detecting COVID-19 infections through vocal sounds. However, like all AI methods, also computer audition is heavily dependent on the quantity and quality of available data, and large-scale COVID-19 sound datasets are difficult to acquire -- amongst other reasons -- due to the sensitive nature of such data. To that end, we introduce the COVYT dataset -- a novel COVID-19 dataset collected from public sources containing more than 8 hours of speech from 65 speakers. As compared to other existing COVID-19 sound datasets, the unique feature of the COVYT dataset is that it comprises both COVID-19 positive and negative samples from all 65 speakers. We analyse the acoustic manifestation of COVID-19 on the basis of these perfectly speaker characteristic balanced `in-the-wild' data using interpretable audio descriptors, and investigate several classification scenarios that shed light into proper partitioning strategies for a fair speech-based COVID-19 detection.

</p>
</details>

<details><summary><b>On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games</b>
<a href="https://arxiv.org/abs/2206.10614">arxiv:2206.10614</a>
&#x1F4C8; 2 <br>
<p>Robert Loftin, Frans A. Oliehoek</p></summary>
<p>

**Abstract:** Learning to cooperate with other agents is challenging when those agents also possess the ability to adapt to our own behavior. Practical and theoretical approaches to learning in cooperative settings typically assume that other agents' behaviors are stationary, or else make very specific assumptions about other agents' learning processes. The goal of this work is to understand whether we can reliably learn to cooperate with other agents without such restrictive assumptions, which are unlikely to hold in real-world applications. Our main contribution is a set of impossibility results, which show that no learning algorithm can reliably learn to cooperate with all possible adaptive partners in a repeated matrix game, even if that partner is guaranteed to cooperate with some stationary strategy. Motivated by these results, we then discuss potential alternative assumptions which capture the idea that an adaptive partner will only adapt rationally to our behavior.

</p>
</details>

<details><summary><b>The Right Tool for the Job: Open-Source Auditing Tools in Machine Learning</b>
<a href="https://arxiv.org/abs/2206.10613">arxiv:2206.10613</a>
&#x1F4C8; 2 <br>
<p>Cherie M Poland</p></summary>
<p>

**Abstract:** In recent years, discussions about fairness in machine learning, AI ethics and algorithm audits have increased. Many entities have developed framework guidance to establish a baseline rubric for fairness and accountability. However, in spite of increased discussions and multiple frameworks, algorithm and data auditing still remain difficult to execute in practice. Many open-source auditing tools are available, but users aren't always aware of the tools, what they are useful for, or how to access them. Model auditing and evaluation are not frequently emphasized skills in machine learning. There are also legal reasons for the proactive adoption of these tools that extend beyond the desire for greater fairness in machine learning. There are positive social issues of public perception and goodwill that matter in our highly connected global society. Greater awareness of these tools and the reasons for actively utilizing them may be helpful to the entire continuum of programmers, data scientists, engineers, researchers, users and consumers of AI and machine learning products. It is important for everyone to better understand the input and output differentials, how they are occurring, and what can be done to promote FATE (fairness, accountability, transparency, and ethics) in machine- and deep learning. The ability to freely access open-source auditing tools removes barriers to fairness assessment at the most basic levels of machine learning. This paper aims to reinforce the urgent need to actually use these tools and provides motivations for doing so. The exemplary tools highlighted herein are open-source with software or code-base repositories available that can be used immediately by anyone worldwide.

</p>
</details>

<details><summary><b>Stop ordering machine learning algorithms by their explainability! A user-centered investigation of performance and explainability</b>
<a href="https://arxiv.org/abs/2206.10610">arxiv:2206.10610</a>
&#x1F4C8; 2 <br>
<p>Lukas-Valentin Herm, Kai Heinrich, Jonas Wanner, Christian Janiesch</p></summary>
<p>

**Abstract:** Machine learning algorithms enable advanced decision making in contemporary intelligent systems. Research indicates that there is a tradeoff between their model performance and explainability. Machine learning models with higher performance are often based on more complex algorithms and therefore lack explainability and vice versa. However, there is little to no empirical evidence of this tradeoff from an end user perspective. We aim to provide empirical evidence by conducting two user experiments. Using two distinct datasets, we first measure the tradeoff for five common classes of machine learning algorithms. Second, we address the problem of end user perceptions of explainable artificial intelligence augmentations aimed at increasing the understanding of the decision logic of high-performing complex models. Our results diverge from the widespread assumption of a tradeoff curve and indicate that the tradeoff between model performance and explainability is much less gradual in the end user's perception. This is a stark contrast to assumed inherent model interpretability. Further, we found the tradeoff to be situational for example due to data complexity. Results of our second experiment show that while explainable artificial intelligence augmentations can be used to increase explainability, the type of explanation plays an essential role in end user perception.

</p>
</details>

<details><summary><b>Autoencoder-based Attribute Noise Handling Method for Medical Data</b>
<a href="https://arxiv.org/abs/2206.10609">arxiv:2206.10609</a>
&#x1F4C8; 2 <br>
<p>Thomas Ranvier, Haytham Elgazel, Emmanuel Coquery, Khalid Benabdeslem</p></summary>
<p>

**Abstract:** Medical datasets are particularly subject to attribute noise, that is, missing and erroneous values. Attribute noise is known to be largely detrimental to learning performances. To maximize future learning performances it is primordial to deal with attribute noise before any inference. We propose a simple autoencoder-based preprocessing method that can correct mixed-type tabular data corrupted by attribute noise. No other method currently exists to handle attribute noise in tabular data. We experimentally demonstrate that our method outperforms both state-of-the-art imputation methods and noise correction methods on several real-world medical datasets.

</p>
</details>

<details><summary><b>MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer</b>
<a href="https://arxiv.org/abs/2206.10607">arxiv:2206.10607</a>
&#x1F4C8; 2 <br>
<p>Jeewon Jeon, Woojun Kim, Whiyoung Jung, Youngchul Sung</p></summary>
<p>

**Abstract:** In this paper, we consider cooperative multi-agent reinforcement learning (MARL) with sparse reward. To tackle this problem, we propose a novel method named MASER: MARL with subgoals generated from experience replay buffer. Under the widely-used assumption of centralized training with decentralized execution and consistent Q-value decomposition for MARL, MASER automatically generates proper subgoals for multiple agents from the experience replay buffer by considering both individual Q-value and total Q-value. Then, MASER designs individual intrinsic reward for each agent based on actionable representation relevant to Q-learning so that the agents reach their subgoals while maximizing the joint action value. Numerical results show that MASER significantly outperforms StarCraft II micromanagement benchmark compared to other state-of-the-art MARL algorithms.

</p>
</details>

<details><summary><b>Automatic Controllable Product Copywriting for E-Commerce</b>
<a href="https://arxiv.org/abs/2206.10103">arxiv:2206.10103</a>
&#x1F4C8; 2 <br>
<p>Xiaojie Guo, Qingkai Zeng, Meng Jiang, Yun Xiao, Bo Long, Lingfei Wu</p></summary>
<p>

**Abstract:** Automatic product description generation for e-commerce has witnessed significant advancement in the past decade. Product copywriting aims to attract users' interest and improve user experience by highlighting product characteristics with textual descriptions. As the services provided by e-commerce platforms become diverse, it is necessary to adapt the patterns of automatically-generated descriptions dynamically. In this paper, we report our experience in deploying an E-commerce Prefix-based Controllable Copywriting Generation (EPCCG) system into the JD.com e-commerce product recommendation platform. The development of the system contains two main components: 1) copywriting aspect extraction; 2) weakly supervised aspect labeling; 3) text generation with a prefix-based language model; 4) copywriting quality control. We conduct experiments to validate the effectiveness of the proposed EPCCG. In addition, we introduce the deployed architecture which cooperates with the EPCCG into the real-time JD.com e-commerce recommendation platform and the significant payoff since deployment.

</p>
</details>

<details><summary><b>Reconstruct from Top View: A 3D Lane Detection Approach based on Geometry Structure Prior</b>
<a href="https://arxiv.org/abs/2206.10098">arxiv:2206.10098</a>
&#x1F4C8; 2 <br>
<p>Chenguang Li, Jia Shi, Ya Wang, Guangliang Cheng</p></summary>
<p>

**Abstract:** In this paper, we propose an advanced approach in targeting the problem of monocular 3D lane detection by leveraging geometry structure underneath the process of 2D to 3D lane reconstruction. Inspired by previous methods, we first analyze the geometry heuristic between the 3D lane and its 2D representation on the ground and propose to impose explicit supervision based on the structure prior, which makes it achievable to build inter-lane and intra-lane relationships to facilitate the reconstruction of 3D lanes from local to global. Second, to reduce the structure loss in 2D lane representation, we directly extract top view lane information from front view images, which tremendously eases the confusion of distant lane features in previous methods. Furthermore, we propose a novel task-specific data augmentation method by synthesizing new training data for both segmentation and reconstruction tasks in our pipeline, to counter the imbalanced data distribution of camera pose and ground slope to improve generalization on unseen data. Our work marks the first attempt to employ the geometry prior information into DNN-based 3D lane detection and makes it achievable for detecting lanes in an extra-long distance, doubling the original detection range. The proposed method can be smoothly adopted by other frameworks without extra costs. Experimental results show that our work outperforms state-of-the-art approaches by 3.8% F-Score on Apollo 3D synthetic dataset at real-time speed of 82 FPS without introducing extra parameters.

</p>
</details>

<details><summary><b>Renormalized Sparse Neural Network Pruning</b>
<a href="https://arxiv.org/abs/2206.10088">arxiv:2206.10088</a>
&#x1F4C8; 2 <br>
<p>Michael G. Rawson</p></summary>
<p>

**Abstract:** Large neural networks are heavily over-parameterized. This is done because it improves training to optimality. However once the network is trained, this means many parameters can be zeroed, or pruned, leaving an equivalent sparse neural network. We propose renormalizing sparse neural networks in order to improve accuracy. We prove that our method's error converges to 0 as network parameters cluster or concentrate. We prove that without renormalizing, the error does not converge to zero in general. We experiment with our method on real world datasets MNIST, Fashion MNIST, and CIFAR-10 and confirm a large improvement in accuracy with renormalization versus standard pruning.

</p>
</details>

<details><summary><b>The Manifold Scattering Transform for High-Dimensional Point Cloud Data</b>
<a href="https://arxiv.org/abs/2206.10078">arxiv:2206.10078</a>
&#x1F4C8; 2 <br>
<p>Joyce Chew, Holly R. Steach, Siddharth Viswanath, Hau-Tieng Wu, Matthew Hirn, Deanna Needell, Smita Krishnaswamy, Michael Perlmutter</p></summary>
<p>

**Abstract:** The manifold scattering transform is a deep feature extractor for data defined on a Riemannian manifold. It is one of the first examples of extending convolutional neural network-like operators to general manifolds. The initial work on this model focused primarily on its theoretical stability and invariance properties but did not provide methods for its numerical implementation except in the case of two-dimensional surfaces with predefined meshes. In this work, we present practical schemes, based on the theory of diffusion maps, for implementing the manifold scattering transform to datasets arising in naturalistic systems, such as single cell genetics, where the data is a high-dimensional point cloud modeled as lying on a low-dimensional manifold. We show that our methods are effective for signal classification and manifold classification tasks.

</p>
</details>

<details><summary><b>Early Recall, Late Precision: Multi-Robot Semantic Object Mapping under Operational Constraints in Perceptually-Degraded Environments</b>
<a href="https://arxiv.org/abs/2206.10062">arxiv:2206.10062</a>
&#x1F4C8; 2 <br>
<p>Xianmei Lei, Taeyeon Kim, Nicolas Marchal, Daniel Pastor, Barry Ridge, Frederik Schöller, Edward Terry, Fernando Chavez, Thomas Touma, Kyohei Otsu, Ali Agha</p></summary>
<p>

**Abstract:** Semantic object mapping in uncertain, perceptually degraded environments during long-range multi-robot autonomous exploration tasks such as search-and-rescue is important and challenging. During such missions, high recall is desirable to avoid missing true target objects and high precision is also critical to avoid wasting valuable operational time on false positives. Given recent advancements in visual perception algorithms, the former is largely solvable autonomously, but the latter is difficult to address without the supervision of a human operator. However, operational constraints such as mission time, computational requirements, mesh network bandwidth and so on, can make the operator's task infeasible unless properly managed. We propose the Early Recall, Late Precision (EaRLaP) semantic object mapping pipeline to solve this problem. EaRLaP was used by Team CoSTAR in DARPA Subterranean Challenge, where it successfully detected all the artifacts encountered by the team of robots. We will discuss these results and performance of the EaRLaP on various datasets.

</p>
</details>

<details><summary><b>Noise Estimation in Gaussian Process Regression</b>
<a href="https://arxiv.org/abs/2206.09976">arxiv:2206.09976</a>
&#x1F4C8; 2 <br>
<p>Siavash Ameli, Shawn C. Shadden</p></summary>
<p>

**Abstract:** We develop a computational procedure to estimate the covariance hyperparameters for semiparametric Gaussian process regression models with additive noise. Namely, the presented method can be used to efficiently estimate the variance of the correlated error, and the variance of the noise based on maximizing a marginal likelihood function. Our method involves suitably reducing the dimensionality of the hyperparameter space to simplify the estimation procedure to a univariate root-finding problem. Moreover, we derive bounds and asymptotes of the marginal likelihood function and its derivatives, which are useful to narrowing the initial range of the hyperparameter search. Using numerical examples, we demonstrate the computational advantages and robustness of the presented approach compared to traditional parameter optimization.

</p>
</details>

<details><summary><b>Seizure Detection and Prediction by Parallel Memristive Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2206.09951">arxiv:2206.09951</a>
&#x1F4C8; 2 <br>
<p>Chenqi Li, Corey Lammie, Xuening Dong, Amirali Amirsoleimani, Mostafa Rahimi Azghadi, Roman Genov</p></summary>
<p>

**Abstract:** During the past two decades, epileptic seizure detection and prediction algorithms have evolved rapidly. However, despite significant performance improvements, their hardware implementation using conventional technologies, such as Complementary Metal-Oxide-Semiconductor (CMOS), in power and area-constrained settings remains a challenging task; especially when many recording channels are used. In this paper, we propose a novel low-latency parallel Convolutional Neural Network (CNN) architecture that has between 2-2,800x fewer network parameters compared to SOTA CNN architectures and achieves 5-fold cross validation accuracy of 99.84% for epileptic seizure detection, and 99.01% and 97.54% for epileptic seizure prediction, when evaluated using the University of Bonn Electroencephalogram (EEG), CHB-MIT and SWEC-ETHZ seizure datasets, respectively. We subsequently implement our network onto analog crossbar arrays comprising Resistive Random-Access Memory (RRAM) devices, and provide a comprehensive benchmark by simulating, laying out, and determining hardware requirements of the CNN component of our system. To the best of our knowledge, we are the first to parallelize the execution of convolution layer kernels on separate analog crossbars to enable 2 orders of magnitude reduction in latency compared to SOTA hybrid Memristive-CMOS DL accelerators. Furthermore, we investigate the effects of non-idealities on our system and investigate Quantization Aware Training (QAT) to mitigate the performance degradation due to low ADC/DAC resolution. Finally, we propose a stuck weight offsetting methodology to mitigate performance degradation due to stuck RON/ROFF memristor weights, recovering up to 32% accuracy, without requiring retraining. The CNN component of our platform is estimated to consume approximately 2.791W of power while occupying an area of 31.255mm$^2$ in a 22nm FDSOI CMOS process.

</p>
</details>

<details><summary><b>Inference-Based Quantum Sensing</b>
<a href="https://arxiv.org/abs/2206.09919">arxiv:2206.09919</a>
&#x1F4C8; 2 <br>
<p>C. Huerta Alderete, Max Hunter Gordon, Frederic Sauvage, Akira Sone, Andrew T. Sornborger, Patrick J. Coles, M. Cerezo</p></summary>
<p>

**Abstract:** In a standard Quantum Sensing (QS) task one aims at estimating an unknown parameter $θ$, encoded into an $n$-qubit probe state, via measurements of the system. The success of this task hinges on the ability to correlate changes in the parameter to changes in the system response $\mathcal{R}(θ)$ (i.e., changes in the measurement outcomes). For simple cases the form of $\mathcal{R}(θ)$ is known, but the same cannot be said for realistic scenarios, as no general closed-form expression exists. In this work we present an inference-based scheme for QS. We show that, for a general class of unitary families of encoding, $\mathcal{R}(θ)$ can be fully characterized by only measuring the system response at $2n+1$ parameters. In turn, this allows us to infer the value of an unknown parameter given the measured response, as well as to determine the sensitivity of the sensing scheme, which characterizes its overall performance. We show that inference error is, with high probability, smaller than $δ$, if one measures the system response with a number of shots that scales only as $Ω(\log^3(n)/δ^2)$. Furthermore, the framework presented can be broadly applied as it remains valid for arbitrary probe states and measurement schemes, and, even holds in the presence of quantum noise. We also discuss how to extend our results beyond unitary families. Finally, to showcase our method we implement it for a QS task on real quantum hardware, and in numerical simulations.

</p>
</details>

<details><summary><b>Low-Precision Stochastic Gradient Langevin Dynamics</b>
<a href="https://arxiv.org/abs/2206.09909">arxiv:2206.09909</a>
&#x1F4C8; 2 <br>
<p>Ruqi Zhang, Andrew Gordon Wilson, Christopher De Sa</p></summary>
<p>

**Abstract:** While low-precision optimization has been widely used to accelerate deep learning, low-precision sampling remains largely unexplored. As a consequence, sampling is simply infeasible in many large-scale scenarios, despite providing remarkable benefits to generalization and uncertainty estimation for neural networks. In this paper, we provide the first study of low-precision Stochastic Gradient Langevin Dynamics (SGLD), showing that its costs can be significantly reduced without sacrificing performance, due to its intrinsic ability to handle system noise. We prove that the convergence of low-precision SGLD with full-precision gradient accumulators is less affected by the quantization error than its SGD counterpart in the strongly convex setting. To further enable low-precision gradient accumulators, we develop a new quantization function for SGLD that preserves the variance in each update step. We demonstrate that low-precision SGLD achieves comparable performance to full-precision SGLD with only 8 bits on a variety of deep learning tasks.

</p>
</details>

<details><summary><b>A Neural Network Based Method with Transfer Learning for Genetic Data Analysis</b>
<a href="https://arxiv.org/abs/2206.09872">arxiv:2206.09872</a>
&#x1F4C8; 2 <br>
<p>Jinghang Lin, Shan Zhang, Qing Lu</p></summary>
<p>

**Abstract:** Transfer learning has emerged as a powerful technique in many application problems, such as computer vision and natural language processing. However, this technique is largely ignored in application to genetic data analysis. In this paper, we combine transfer learning technique with a neural network based method(expectile neural networks). With transfer learning, instead of starting the learning process from scratch, we start from one task that have been learned when solving a different task. We leverage previous learnings and avoid starting from scratch to improve the model performance by passing information gained in different but related task. To demonstrate the performance, we run two real data sets. By using transfer learning algorithm, the performance of expectile neural networks is improved compared to expectile neural network without using transfer learning technique.

</p>
</details>

<details><summary><b>Label noise (stochastic) gradient descent implicitly solves the Lasso for quadratic parametrisation</b>
<a href="https://arxiv.org/abs/2206.09841">arxiv:2206.09841</a>
&#x1F4C8; 2 <br>
<p>Loucas Pillaud-Vivien, Julien Reygner, Nicolas Flammarion</p></summary>
<p>

**Abstract:** Understanding the implicit bias of training algorithms is of crucial importance in order to explain the success of overparametrised neural networks. In this paper, we study the role of the label noise in the training dynamics of a quadratically parametrised model through its continuous time version. We explicitly characterise the solution chosen by the stochastic flow and prove that it implicitly solves a Lasso program. To fully complete our analysis, we provide nonasymptotic convergence guarantees for the dynamics as well as conditions for support recovery. We also give experimental results which support our theoretical claims. Our findings highlight the fact that structured noise can induce better generalisation and help explain the greater performances of stochastic dynamics as observed in practice.

</p>
</details>

<details><summary><b>Exceedance Probability Forecasting via Regression for Significant Wave Height Forecasting</b>
<a href="https://arxiv.org/abs/2206.09821">arxiv:2206.09821</a>
&#x1F4C8; 2 <br>
<p>Vitor Cerqueira, Luis Torgo</p></summary>
<p>

**Abstract:** Significant wave height forecasting is a key problem in ocean data analytics. Predicting the significant wave height is crucial for estimating the energy production from waves. Moreover, the timely prediction of large waves is important to ensure the safety of maritime operations, e.g. passage of vessels. We frame the task of predicting extreme values of significant wave height as an exceedance probability forecasting problem. Accordingly, we aim at estimating the probability that the significant wave height will exceed a predefined threshold. This task is usually solved using a probabilistic binary classification model. Instead, we propose a novel approach based on a forecasting model. The method leverages the forecasts for the upcoming observations to estimate the exceedance probability according to the cumulative distribution function. We carried out experiments using data from a buoy placed in the coast of Halifax, Canada. The results suggest that the proposed methodology is better than state-of-the-art approaches for exceedance probability forecasting.

</p>
</details>

<details><summary><b>Actively learning to learn causal relationships</b>
<a href="https://arxiv.org/abs/2206.09777">arxiv:2206.09777</a>
&#x1F4C8; 2 <br>
<p>Chentian Jiang, Christopher G. Lucas</p></summary>
<p>

**Abstract:** How do people actively learn to learn? That is, how and when do people choose actions that facilitate long-term learning and choosing future actions that are more informative? We explore these questions in the domain of active causal learning. We propose a hierarchical Bayesian model that goes beyond past models by predicting that people pursue information not only about the causal relationship at hand but also about causal overhypotheses$\unicode{x2014}$abstract beliefs about causal relationships that span multiple situations and constrain how we learn the specifics in each situation. In two active "blicket detector" experiments with 14 between-subjects manipulations, our model was supported by both qualitative trends in participant behavior and an individual-differences-based model comparison. Our results suggest when there are abstract similarities across active causal learning problems, people readily learn and transfer overhypotheses about these similarities. Moreover, people exploit these overhypotheses to facilitate long-term active learning.

</p>
</details>

<details><summary><b>Quantitative CT texture-based method to predict diagnosis and prognosis of fibrosing interstitial lung disease patterns</b>
<a href="https://arxiv.org/abs/2206.09766">arxiv:2206.09766</a>
&#x1F4C8; 2 <br>
<p>Babak Haghighi, Warren B. Gefter, Lauren Pantalone, Despina Kontos, Eduardo Mortani Barbosa Jr</p></summary>
<p>

**Abstract:** Purpose: To utilize high-resolution quantitative CT (QCT) imaging features for prediction of diagnosis and prognosis in fibrosing interstitial lung diseases (ILD). Approach: 40 ILD patients (20 usual interstitial pneumonia (UIP), 20 non-UIP pattern ILD) were classified by expert consensus of 2 radiologists and followed for 7 years. Clinical variables were recorded. Following segmentation of the lung field, a total of 26 texture features were extracted using a lattice-based approach (TM model). The TM model was compared with previously histogram-based model (HM) for their abilities to classify UIP vs non-UIP. For prognostic assessment, survival analysis was performed comparing the expert diagnostic labels versus TM metrics. Results: In the classification analysis, the TM model outperformed the HM method with AUC of 0.70. While survival curves of UIP vs non-UIP expert labels in Cox regression analysis were not statistically different, TM QCT features allowed statistically significant partition of the cohort. Conclusions: TM model outperformed HM model in distinguishing UIP from non-UIP patterns. Most importantly, TM allows for partitioning of the cohort into distinct survival groups, whereas expert UIP vs non-UIP labeling does not. QCT TM models may improve diagnosis of ILD and offer more accurate prognostication, better guiding patient management.

</p>
</details>

<details><summary><b>A Machine Learning Data Fusion Model for Soil Moisture Retrieval</b>
<a href="https://arxiv.org/abs/2206.09649">arxiv:2206.09649</a>
&#x1F4C8; 2 <br>
<p>Vishal Batchu, Grey Nearing, Varun Gulshan</p></summary>
<p>

**Abstract:** We develop a deep learning based convolutional-regression model that estimates the volumetric soil moisture content in the top ~5 cm of soil. Input predictors include Sentinel-1 (active radar), Sentinel-2 (optical imagery), and SMAP (passive radar) as well as geophysical variables from SoilGrids and modelled soil moisture fields from GLDAS. The model was trained and evaluated on data from ~1300 in-situ sensors globally over the period 2015 - 2021 and obtained an average per-sensor correlation of 0.727 and ubRMSE of 0.054, and can be used to produce a soil moisture map at a nominal 320m resolution. These results are benchmarked against 13 other soil moisture works at different locations, and an ablation study was used to identify important predictors.

</p>
</details>

<details><summary><b>Beyond IID: data-driven decision-making in heterogeneous environments</b>
<a href="https://arxiv.org/abs/2206.09642">arxiv:2206.09642</a>
&#x1F4C8; 2 <br>
<p>Omar Besbes, Will Ma, Omar Mouchtaki</p></summary>
<p>

**Abstract:** In this work, we study data-driven decision-making and depart from the classical identically and independently distributed (i.i.d.) assumption. We present a new framework in which historical samples are generated from unknown and different distributions, which we dub heterogeneous environments. These distributions are assumed to lie in a heterogeneity ball with known radius and centered around the (also) unknown future (out-of-sample) distribution on which the performance of a decision will be evaluated. We quantify the asymptotic worst-case regret that is achievable by central data-driven policies such as Sample Average Approximation, but also by rate-optimal ones, as a function of the radius of the heterogeneity ball. Our work shows that the type of achievable performance varies considerably across different combinations of problem classes and notions of heterogeneity. We demonstrate the versatility of our framework by comparing achievable guarantees for the heterogeneous version of widely studied data-driven problems such as pricing, ski-rental, and newsvendor. En route, we establish a new connection between data-driven decision-making and distributionally robust optimization.

</p>
</details>

<details><summary><b>Diversified Adversarial Attacks based on Conjugate Gradient Method</b>
<a href="https://arxiv.org/abs/2206.09628">arxiv:2206.09628</a>
&#x1F4C8; 2 <br>
<p>Keiichiro Yamamura, Haruki Sato, Nariaki Tateiwa, Nozomi Hata, Toru Mitsutake, Issa Oe, Hiroki Ishikura, Katsuki Fujisawa</p></summary>
<p>

**Abstract:** Deep learning models are vulnerable to adversarial examples, and adversarial attacks used to generate such examples have attracted considerable research interest. Although existing methods based on the steepest descent have achieved high attack success rates, ill-conditioned problems occasionally reduce their performance. To address this limitation, we utilize the conjugate gradient (CG) method, which is effective for this type of problem, and propose a novel attack algorithm inspired by the CG method, named the Auto Conjugate Gradient (ACG) attack. The results of large-scale evaluation experiments conducted on the latest robust models show that, for most models, ACG was able to find more adversarial examples with fewer iterations than the existing SOTA algorithm Auto-PGD (APGD). We investigated the difference in search performance between ACG and APGD in terms of diversification and intensification, and define a measure called Diversity Index (DI) to quantify the degree of diversity. From the analysis of the diversity using this index, we show that the more diverse search of the proposed method remarkably improves its attack success rate.

</p>
</details>

<details><summary><b>Distortion-Aware Network Pruning and Feature Reuse for Real-time Video Segmentation</b>
<a href="https://arxiv.org/abs/2206.09604">arxiv:2206.09604</a>
&#x1F4C8; 2 <br>
<p>Hyunsu Rhee, Dongchan Min, Sunil Hwang, Bruno Andreis, Sung Ju Hwang</p></summary>
<p>

**Abstract:** Real-time video segmentation is a crucial task for many real-world applications such as autonomous driving and robot control. Since state-of-the-art semantic segmentation models are often too heavy for real-time applications despite their impressive performance, researchers have proposed lightweight architectures with speed-accuracy trade-offs, achieving real-time speed at the expense of reduced accuracy. In this paper, we propose a novel framework to speed up any architecture with skip-connections for real-time vision tasks by exploiting the temporal locality in videos. Specifically, at the arrival of each frame, we transform the features from the previous frame to reuse them at specific spatial bins. We then perform partial computation of the backbone network on the regions of the current frame that captures temporal differences between the current and previous frame. This is done by dynamically dropping out residual blocks using a gating mechanism which decides which blocks to drop based on inter-frame distortion. We validate our Spatial-Temporal Mask Generator (STMG) on video semantic segmentation benchmarks with multiple backbone networks, and show that our method largely speeds up inference with minimal loss of accuracy.

</p>
</details>

<details><summary><b>Constrained Reinforcement Learning for Robotics via Scenario-Based Programming</b>
<a href="https://arxiv.org/abs/2206.09603">arxiv:2206.09603</a>
&#x1F4C8; 2 <br>
<p>Davide Corsi, Raz Yerushalmi, Guy Amir, Alessandro Farinelli, David Harel, Guy Katz</p></summary>
<p>

**Abstract:** Deep reinforcement learning (DRL) has achieved groundbreaking successes in a wide variety of robotic applications. A natural consequence is the adoption of this paradigm for safety-critical tasks, where human safety and expensive hardware can be involved. In this context, it is crucial to optimize the performance of DRL-based agents while providing guarantees about their behavior. This paper presents a novel technique for incorporating domain-expert knowledge into a constrained DRL training loop. Our technique exploits the scenario-based programming paradigm, which is designed to allow specifying such knowledge in a simple and intuitive way. We validated our method on the popular robotic mapless navigation problem, in simulation, and on the actual platform. Our experiments demonstrate that using our approach to leverage expert knowledge dramatically improves the safety and the performance of the agent.

</p>
</details>

<details><summary><b>From Multi-agent to Multi-robot: A Scalable Training and Evaluation Platform for Multi-robot Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2206.09590">arxiv:2206.09590</a>
&#x1F4C8; 2 <br>
<p>Zhiuxan Liang, Jiannong Cao, Shan Jiang, Divya Saxena, Jinlin Chen, Huafeng Xu</p></summary>
<p>

**Abstract:** Multi-agent reinforcement learning (MARL) has been gaining extensive attention from academia and industries in the past few decades. One of the fundamental problems in MARL is how to evaluate different approaches comprehensively. Most existing MARL methods are evaluated in either video games or simplistic simulated scenarios. It remains unknown how these methods perform in real-world scenarios, especially multi-robot systems. This paper introduces a scalable emulation platform for multi-robot reinforcement learning (MRRL) called SMART to meet this need. Precisely, SMART consists of two components: 1) a simulation environment that provides a variety of complex interaction scenarios for training and 2) a real-world multi-robot system for realistic performance evaluation. Besides, SMART offers agent-environment APIs that are plug-and-play for algorithm implementation. To illustrate the practicality of our platform, we conduct a case study on the cooperative driving lane change scenario. Building off the case study, we summarize several unique challenges of MRRL, which are rarely considered previously. Finally, we open-source the simulation environments, associated benchmark tasks, and state-of-the-art baselines to encourage and empower MRRL research.

</p>
</details>

<details><summary><b>5th Place Solution for YouTube-VOS Challenge 2022: Video Object Segmentation</b>
<a href="https://arxiv.org/abs/2206.09585">arxiv:2206.09585</a>
&#x1F4C8; 2 <br>
<p>Wangwang Yang, Jinming Su, Yiting Duan, Tingyi Guo, Junfeng Luo</p></summary>
<p>

**Abstract:** Video object segmentation (VOS) has made significant progress with the rise of deep learning. However, there still exist some thorny problems, for example, similar objects are easily confused and tiny objects are difficult to be found. To solve these problems and further improve the performance of VOS, we propose a simple yet effective solution for this task. In the solution, we first analyze the distribution of the Youtube-VOS dataset and supplement the dataset by introducing public static and video segmentation datasets. Then, we improve three network architectures with different characteristics and train several networks to learn the different characteristics of objects in videos. After that, we use a simple way to integrate all results to ensure that different models complement each other. Finally, subtle post-processing is carried out to ensure accurate video object segmentation with precise boundaries. Extensive experiments on Youtube-VOS dataset show that the proposed solution achieves the state-of-the-art performance with an 86.1% overall score on the YouTube-VOS 2022 test set, which is 5th place on the video object segmentation track of the Youtube-VOS Challenge 2022.

</p>
</details>

<details><summary><b>Automatic Autism Spectrum Disorder Detection Using Artificial Intelligence Methods with MRI Neuroimaging: A Review</b>
<a href="https://arxiv.org/abs/2206.11233">arxiv:2206.11233</a>
&#x1F4C8; 1 <br>
<p>Parisa Moridian, Navid Ghassemi, Mahboobeh Jafari, Salam Salloum-Asfar, Delaram Sadeghi, Marjane Khodatars, Afshin Shoeibi, Abbas Khosravi, Sai Ho Ling, Abdulhamit Subasi, Sara A Abdulla, Roohallah Alizadehsani, Juan M. Gorriz, U. Rajendra Acharya</p></summary>
<p>

**Abstract:** Autism spectrum disorder (ASD) is a brain condition characterized by diverse signs and symptoms that appear in early childhood. ASD is also associated with communication deficits and repetitive behavior in affected individuals. Various ASD detection methods have been developed, including neuroimaging modalities and psychological tests. Among these methods, magnetic resonance imaging (MRI) imaging modalities are of paramount importance to physicians. Clinicians rely on MRI modalities to diagnose ASD accurately. The MRI modalities are non-invasive methods that include functional (fMRI) and structural (sMRI) neuroimaging methods. However, the process of diagnosing ASD with fMRI and sMRI for specialists is often laborious and time-consuming; therefore, several computer-aided design systems (CADS) based on artificial intelligence (AI) have been developed to assist the specialist physicians. Conventional machine learning (ML) and deep learning (DL) are the most popular schemes of AI used for diagnosing ASD. This study aims to review the automated detection of ASD using AI. We review several CADS that have been developed using ML techniques for the automated diagnosis of ASD using MRI modalities. There has been very limited work on the use of DL techniques to develop automated diagnostic models for ASD. A summary of the studies developed using DL is provided in the appendix. Then, the challenges encountered during the automated diagnosis of ASD using MRI and AI techniques are described in detail. Additionally, a graphical comparison of studies using ML and DL to diagnose ASD automatically is discussed. We conclude by suggesting future approaches to detecting ASDs using AI techniques and MRI neuroimaging.

</p>
</details>

<details><summary><b>A Novel Three-Dimensional Navigation Method for the Visually Impaired</b>
<a href="https://arxiv.org/abs/2206.11136">arxiv:2206.11136</a>
&#x1F4C8; 1 <br>
<p>Stanley Shen</p></summary>
<p>

**Abstract:** According to the World Health Organization, visual impairment is estimated to affect approximately 2.2 billion people worldwide. The visually impaired must currently rely on navigational aids to replace their sense of sight, like a white cane or GPS (Global Positioning System) based navigation, both of which fail to work well indoors. The white cane cannot be used to determine a user's position within a room, while GPS can often lose connection indoors and does not provide orientation information, making both approaches unsuitable for indoor use. Therefore, this research seeks to develop a 3D-imaging solution that enables contactless navigation through a complex indoor environment. The device can pinpoint a user's position and orientation with 31% less error compared to previous approaches while requiring only 53.1% of the memory, and processing 125% faster. The device can also detect obstacles with 60.2% more accuracy than the previous state-of-the-art models while requiring only 41% of the memory and processing 260% faster. When testing with human participants, the device allows for a 94.5% reduction in collisions with obstacles in the environment and allows for a 48.3% increase in walking speed, showing that my device enables safer and more rapid navigation for the visually impaired. All in all, this research demonstrates a 3D-based navigation system for the visually impaired. The approach can be used by a wide variety of mobile low-power devices, like cell phones, ensuring this research remains accessible to all.

</p>
</details>

<details><summary><b>An Ontological Approach to Analysing Social Service Provisioning</b>
<a href="https://arxiv.org/abs/2206.11061">arxiv:2206.11061</a>
&#x1F4C8; 1 <br>
<p>Mark S. Fox, Bart Gajderowicz, Daniela Rosu, Alina Turner, Lester Lyu</p></summary>
<p>

**Abstract:** This paper introduces ontological concepts required to evaluate and manage the coverage of social services in a Smart City context. Here, we focus on the perspective of key stakeholders, namely social purpose organizations and the clients they serve. The Compass ontology presented here extends the Common Impact Data Standard by introducing new concepts related to key dimensions: the who (Stakeholder), the what (Need, Need Satisfier, Outcome), the how (Service, Event), and the contributions (tracking resources). The paper first introduces key stakeholders, services, outcomes, events, needs and need satisfiers, along with their definitions. Second, a subset of competency questions are presented to illustrate the types of questions key stakeholders have posed. Third, the extension's ability to answer questions is evaluated by presenting SPARQL queries executed on a Compass-based knowledge graph and analysing their results.

</p>
</details>

<details><summary><b>Penalty Weights in QUBO Formulations: Permutation Problems</b>
<a href="https://arxiv.org/abs/2206.11040">arxiv:2206.11040</a>
&#x1F4C8; 1 <br>
<p>Mayowa Ayodele</p></summary>
<p>

**Abstract:** Optimisation algorithms designed to work on quantum computers or other specialised hardware have been of research interest in recent years. Many of these solver can only optimise problems that are in binary and quadratic form. Quadratic Unconstrained Binary Optimisation (QUBO) is therefore a common formulation used by these solvers.
  There are many combinatorial optimisation problems that are naturally represented as permutations e.g., travelling salesman problem. Encoding permutation problems using binary variables however presents some challenges. Many QUBO solvers are single flip solvers, it is therefore possible to generate solutions that cannot be decoded to a valid permutation. To create bias towards generating feasible solutions, we use penalty weights. The process of setting static penalty weights for various types of problems is not trivial. This is because values that are too small will lead to infeasible solutions being returned by the solver while values that are too large may lead to slower convergence. In this study, we explore some methods of setting penalty weights within the context of QUBO formulations. We propose new static methods of calculating penalty weights which lead to more promising results than existing methods.

</p>
</details>

<details><summary><b>Metareview-informed Explainable Cytokine Storm Detection during CAR-T cell Therapy</b>
<a href="https://arxiv.org/abs/2206.10612">arxiv:2206.10612</a>
&#x1F4C8; 1 <br>
<p>Alex Bogatu, Magdalena Wysocka, Oskar Wysocki, Holly Butterworth, Donal Landers, Elaine Kilgour, Andre Freitas</p></summary>
<p>

**Abstract:** Cytokine release syndrome (CRS), also known as cytokine storm, is one of the most consequential adverse effects of chimeric antigen receptor therapies that have shown promising results in cancer treatment. When emerging, CRS could be identified by the analysis of specific cytokine and chemokine profiles that tend to exhibit similarities across patients. In this paper, we exploit these similarities using machine learning algorithms and set out to pioneer a meta--review informed method for the identification of CRS based on specific cytokine peak concentrations and evidence from previous clinical studies. We argue that such methods could support clinicians in analyzing suspect cytokine profiles by matching them against CRS knowledge from past clinical studies, with the ultimate aim of swift CRS diagnosis. During evaluation with real--world CRS clinical data, we emphasize the potential of our proposed method of producing interpretable results, in addition to being effective in identifying the onset of cytokine storm.

</p>
</details>

<details><summary><b>Finding Optimal Policy for Queueing Models: New Parameterization</b>
<a href="https://arxiv.org/abs/2206.10073">arxiv:2206.10073</a>
&#x1F4C8; 1 <br>
<p>Trang H. Tran, Lam M. Nguyen, Katya Scheinberg</p></summary>
<p>

**Abstract:** Queueing systems appear in many important real-life applications including communication networks, transportation and manufacturing systems. Reinforcement learning (RL) framework is a suitable model for the queueing control problem where the underlying dynamics are usually unknown and the agent receives little information from the environment to navigate. In this work, we investigate the optimization aspects of the queueing model as a RL environment and provide insight to learn the optimal policy efficiently. We propose a new parameterization of the policy by using the intrinsic properties of queueing network systems. Experiments show good performance of our methods with various load conditions from light to heavy traffic.

</p>
</details>

<details><summary><b>Hyperparameter Importance of Quantum Neural Networks Across Small Datasets</b>
<a href="https://arxiv.org/abs/2206.09992">arxiv:2206.09992</a>
&#x1F4C8; 1 <br>
<p>Charles Moussa, Jan N. van Rijn, Thomas Bäck, Vedran Dunjko</p></summary>
<p>

**Abstract:** As restricted quantum computers are slowly becoming a reality, the search for meaningful first applications intensifies. In this domain, one of the more investigated approaches is the use of a special type of quantum circuit - a so-called quantum neural network -- to serve as a basis for a machine learning model. Roughly speaking, as the name suggests, a quantum neural network can play a similar role to a neural network. However, specifically for applications in machine learning contexts, very little is known about suitable circuit architectures, or model hyperparameters one should use to achieve good learning performance. In this work, we apply the functional ANOVA framework to quantum neural networks to analyze which of the hyperparameters were most influential for their predictive performance. We analyze one of the most typically used quantum neural network architectures. We then apply this to $7$ open-source datasets from the OpenML-CC18 classification benchmark whose number of features is small enough to fit on quantum hardware with less than $20$ qubits. Three main levels of importance were detected from the ranking of hyperparameters obtained with functional ANOVA. Our experiment both confirmed expected patterns and revealed new insights. For instance, setting well the learning rate is deemed the most critical hyperparameter in terms of marginal contribution on all datasets, whereas the particular choice of entangling gates used is considered the least important except on one dataset. This work introduces new methodologies to study quantum machine learning models and provides new insights toward quantum model selection.

</p>
</details>

<details><summary><b>Regression of high dimensional angular momentum states of light</b>
<a href="https://arxiv.org/abs/2206.09873">arxiv:2206.09873</a>
&#x1F4C8; 1 <br>
<p>Danilo Zia, Riccardo Checchinato, Alessia Suprano, Taira Giordani, Emanuele Polino, Luca Innocenti, Alessandro Ferraro, Mauro Paternostro, Nicolò Spagnolo, Fabio Sciarrino</p></summary>
<p>

**Abstract:** The Orbital Angular Momentum (OAM) of light is an infinite-dimensional degree of freedom of light with several applications in both classical and quantum optics. However, to fully take advantage of the potential of OAM states, reliable detection platforms to characterize generated states in experimental conditions are needed. Here, we present an approach to reconstruct input OAM states from measurements of the spatial intensity distributions they produce. To obviate issues arising from intrinsic symmetry of Laguerre-Gauss modes, we employ a pair of intensity profiles per state projecting it only on two distinct bases, showing how this allows to uniquely recover input states from the collected data. Our approach is based on a combined application of dimensionality reduction via principal component analysis, and linear regression, and thus has a low computational cost during both training and testing stages. We showcase our approach in a real photonic setup, generating up-to-four-dimensional OAM states through a quantum walk dynamics. The high performances and versatility of the demonstrated approach make it an ideal tool to characterize high dimensional states in quantum information protocols.

</p>
</details>

<details><summary><b>Understanding Robust Learning through the Lens of Representation Similarities</b>
<a href="https://arxiv.org/abs/2206.09868">arxiv:2206.09868</a>
&#x1F4C8; 1 <br>
<p>Christian Cianfarani, Arjun Nitin Bhagoji, Vikash Sehwag, Ben Zhao, Prateek Mittal</p></summary>
<p>

**Abstract:** Representation learning, i.e. the generation of representations useful for downstream applications, is a task of fundamental importance that underlies much of the success of deep neural networks (DNNs). Recently, robustness to adversarial examples has emerged as a desirable property for DNNs, spurring the development of robust training methods that account for adversarial examples. In this paper, we aim to understand how the properties of representations learned by robust training differ from those obtained from standard, non-robust training. This is critical to diagnosing numerous salient pitfalls in robust networks, such as, degradation of performance on benign inputs, poor generalization of robustness, and increase in over-fitting. We utilize a powerful set of tools known as representation similarity metrics, across three vision datasets, to obtain layer-wise comparisons between robust and non-robust DNNs with different architectures, training procedures and adversarial constraints. Our experiments highlight hitherto unseen properties of robust representations that we posit underlie the behavioral differences of robust networks. We discover a lack of specialization in robust networks' representations along with a disappearance of `block structure'. We also find overfitting during robust training largely impacts deeper layers. These, along with other findings, suggest ways forward for the design and training of better robust networks.

</p>
</details>

<details><summary><b>Contextual Squeeze-and-Excitation for Efficient Few-Shot Image Classification</b>
<a href="https://arxiv.org/abs/2206.09843">arxiv:2206.09843</a>
&#x1F4C8; 1 <br>
<p>Massimiliano Patacchiola, John Bronskill, Aliaksandra Shysheya, Katja Hofmann, Sebastian Nowozin, Richard E. Turner</p></summary>
<p>

**Abstract:** Recent years have seen a growth in user-centric applications that require effective knowledge transfer across tasks in the low-data regime. An example is personalization, where a pretrained system is adapted by learning on small amounts of labeled data belonging to a specific user. This setting requires high accuracy under low computational complexity, therefore the Pareto frontier of accuracy vs.~adaptation cost plays a crucial role. In this paper we push this Pareto frontier in the few-shot image classification setting with two key contributions: (i) a new adaptive block called Contextual Squeeze-and-Excitation (CaSE) that adjusts a pretrained neural network on a new task to significantly improve performance with a single forward pass of the user data (context), and (ii) a hybrid training protocol based on Coordinate-Descent called UpperCaSE that exploits meta-trained CaSE blocks and fine-tuning routines for efficient adaptation. UpperCaSE achieves a new state-of-the-art accuracy relative to meta-learners on the 26 datasets of VTAB+MD and on a challenging real-world personalization benchmark (ORBIT), narrowing the gap with leading fine-tuning methods with the benefit of orders of magnitude lower adaptation cost.

</p>
</details>

<details><summary><b>Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2206.09811">arxiv:2206.09811</a>
&#x1F4C8; 1 <br>
<p>Han Xiao, Ziwei Wang, Zheng Zhu, Jie Zhou, Jiwen Lu</p></summary>
<p>

**Abstract:** In this paper, we propose a Shapley value based method to evaluate operation contribution (Shapley-NAS) for neural architecture search. Differentiable architecture search (DARTS) acquires the optimal architectures by optimizing the architecture parameters with gradient descent, which significantly reduces the search cost. However, the magnitude of architecture parameters updated by gradient descent fails to reveal the actual operation importance to the task performance and therefore harms the effectiveness of obtained architectures. By contrast, we propose to evaluate the direct influence of operations on validation accuracy. To deal with the complex relationships between supernet components, we leverage Shapley value to quantify their marginal contributions by considering all possible combinations. Specifically, we iteratively optimize the supernet weights and update the architecture parameters by evaluating operation contributions via Shapley value, so that the optimal architectures are derived by selecting the operations that contribute significantly to the tasks. Since the exact computation of Shapley value is NP-hard, the Monte-Carlo sampling based algorithm with early truncation is employed for efficient approximation, and the momentum update mechanism is adopted to alleviate fluctuation of the sampling process. Extensive experiments on various datasets and various search spaces show that our Shapley-NAS outperforms the state-of-the-art methods by a considerable margin with light search cost. The code is available at https://github.com/Euphoria16/Shapley-NAS.git

</p>
</details>

<details><summary><b>Towards Perspective-Based Specification of Machine Learning-Enabled Systems</b>
<a href="https://arxiv.org/abs/2206.09760">arxiv:2206.09760</a>
&#x1F4C8; 1 <br>
<p>Hugo Villamizar, Marcos Kalinowski, Helio Lopes</p></summary>
<p>

**Abstract:** Machine learning (ML) teams often work on a project just to realize the performance of the model is not good enough. Indeed, the success of ML-enabled systems involves aligning data with business problems, translating them into ML tasks, experimenting with algorithms, evaluating models, capturing data from users, among others. Literature has shown that ML-enabled systems are rarely built based on precise specifications for such concerns, leading ML teams to become misaligned due to incorrect assumptions, which may affect the quality of such systems and overall project success. In order to help addressing this issue, this paper describes our work towards a perspective-based approach for specifying ML-enabled systems. The approach involves analyzing a set of 45 ML concerns grouped into five perspectives: objectives, user experience, infrastructure, model, and data. The main contribution of this paper is to provide two new artifacts that can be used to help specifying ML-enabled systems: (i) the perspective-based ML task and concern diagram and (ii) the perspective-based ML specification template.

</p>
</details>

<details><summary><b>Time Gated Convolutional Neural Networks for Crop Classification</b>
<a href="https://arxiv.org/abs/2206.09756">arxiv:2206.09756</a>
&#x1F4C8; 1 <br>
<p>Longlong Weng, Yashu Kang, Kezhao Jiang, Chunlei Chen</p></summary>
<p>

**Abstract:** This paper presented a state-of-the-art framework, Time Gated Convolutional Neural Network (TGCNN) that takes advantage of temporal information and gating mechanisms for the crop classification problem. Besides, several vegetation indices were constructed to expand dimensions of input data to take advantage of spectral information. Both spatial (channel-wise) and temporal (step-wise) correlation are considered in TGCNN. Specifically, our preliminary analysis indicates that step-wise information is of greater importance in this data set. Lastly, the gating mechanism helps capture high-order relationship. Our TGCNN solution achieves $0.973$ F1 score, $0.977$ AUC ROC and $0.948$ IoU, respectively. In addition, it outperforms three other benchmarks in different local tasks (Kenya, Brazil and Togo). Overall, our experiments demonstrate that TGCNN is advantageous in this earth observation time series classification task.

</p>
</details>

<details><summary><b>Developing a Free and Open-source Automated Building Exterior Crack Inspection Software for Construction and Facility Managers</b>
<a href="https://arxiv.org/abs/2206.09742">arxiv:2206.09742</a>
&#x1F4C8; 1 <br>
<p>Pi Ko, Samuel A. Prieto, Borja Garcia de Soto</p></summary>
<p>

**Abstract:** Inspection of cracks is an important process for properly monitoring and maintaining a building. However, manual crack inspection is time-consuming, inconsistent, and dangerous (e.g., in tall buildings). Due to the development of open-source AI technologies, the increase in available Unmanned Aerial Vehicles (UAVs) and the availability of smartphone cameras, it has become possible to automate the building crack inspection process. This study presents the development of an easy-to-use, free and open-source Automated Building Exterior Crack Inspection Software (ABECIS) for construction and facility managers, using state-of-the-art segmentation algorithms to identify concrete cracks and generate a quantitative and qualitative report. ABECIS was tested using images collected from a UAV and smartphone cameras in real-world conditions and a controlled laboratory environment. From the raw output of the algorithm, the median Intersection over Unions for the test experiments is (1) 0.686 for indoor crack detection experiment in a controlled lab environment using a commercial drone, (2) 0.186 for indoor crack detection at a construction site using a smartphone and (3) 0.958 for outdoor crack detection on university campus using a commercial drone. These IoU results can be improved significantly to over 0.8 when a human operator selectively removes the false positives. In general, ABECIS performs best for outdoor drone images, and combining the algorithm predictions with human verification/intervention offers very accurate crack detection results. The software is available publicly and can be downloaded for out-of-the-box use at: https://github.com/SMART-NYUAD/ABECIS

</p>
</details>

<details><summary><b>Analyzing Büchi Automata with Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2206.09619">arxiv:2206.09619</a>
&#x1F4C8; 1 <br>
<p>Christophe Stammet, Prisca Dotti, Ulrich Ultes-Nitsche, Andreas Fischer</p></summary>
<p>

**Abstract:** Büchi Automata on infinite words present many interesting problems and are used frequently in program verification and model checking. A lot of these problems on Büchi automata are computationally hard, raising the question if a learning-based data-driven analysis might be more efficient than using traditional algorithms. Since Büchi automata can be represented by graphs, graph neural networks are a natural choice for such a learning-based analysis. In this paper, we demonstrate how graph neural networks can be used to reliably predict basic properties of Büchi automata when trained on automatically generated random automata datasets.

</p>
</details>

<details><summary><b>Revisiting lp-constrained Softmax Loss: A Comprehensive Study</b>
<a href="https://arxiv.org/abs/2206.09616">arxiv:2206.09616</a>
&#x1F4C8; 1 <br>
<p>Chintan Trivedi, Konstantinos Makantasis, Antonios Liapis, Georgios N. Yannakakis</p></summary>
<p>

**Abstract:** Normalization is a vital process for any machine learning task as it controls the properties of data and affects model performance at large. The impact of particular forms of normalization, however, has so far been investigated in limited domain-specific classification tasks and not in a general fashion. Motivated by the lack of such a comprehensive study, in this paper we investigate the performance of lp-constrained softmax loss classifiers across different norm orders, magnitudes, and data dimensions in both proof-of-concept classification problems and real-world popular image classification tasks. Experimental results suggest collectively that lp-constrained softmax loss classifiers not only can achieve more accurate classification results but, at the same time, appear to be less prone to overfitting. The core findings hold across the three popular deep learning architectures tested and eight datasets examined, and suggest that lp normalization is a recommended data representation practice for image classification in terms of performance and convergence, and against overfitting.

</p>
</details>

<details><summary><b>Deep Random Vortex Method for Simulation and Inference of Navier-Stokes Equations</b>
<a href="https://arxiv.org/abs/2206.09571">arxiv:2206.09571</a>
&#x1F4C8; 1 <br>
<p>Rui Zhang, Peiyan Hu, Qi Meng, Yue Wang, Rongchan Zhu, Bingguang Chen, Zhi-Ming Ma, Tie-Yan Liu</p></summary>
<p>

**Abstract:** Navier-Stokes equations are significant partial differential equations that describe the motion of fluids such as liquids and air. Due to the importance of Navier-Stokes equations, the development on efficient numerical schemes is important for both science and engineer. Recently, with the development of AI techniques, several approaches have been designed to integrate deep neural networks in simulating and inferring the fluid dynamics governed by incompressible Navier-Stokes equations, which can accelerate the simulation or inferring process in a mesh-free and differentiable way. In this paper, we point out that the capability of existing deep Navier-Stokes informed methods is limited to handle non-smooth or fractional equations, which are two critical situations in reality. To this end, we propose the \emph{Deep Random Vortex Method} (DRVM), which combines the neural network with a random vortex dynamics system equivalent to the Navier-Stokes equation. Specifically, the random vortex dynamics motivates a Monte Carlo based loss function for training the neural network, which avoids the calculation of derivatives through auto-differentiation. Therefore, DRVM not only can efficiently solve Navier-Stokes equations involving rough path, non-differentiable initial conditions and fractional operators, but also inherits the mesh-free and differentiable benefits of the deep-learning-based solver. We conduct experiments on the Cauchy problem, parametric solver learning, and the inverse problem of both 2-d and 3-d incompressible Navier-Stokes equations. The proposed method achieves accurate results for simulation and inference of Navier-Stokes equations. Especially for the cases that include singular initial conditions, DRVM significantly outperforms existing PINN method.

</p>
</details>

<details><summary><b>Neural Activation Patterns (NAPs): Visual Explainability of Learned Concepts</b>
<a href="https://arxiv.org/abs/2206.10611">arxiv:2206.10611</a>
&#x1F4C8; 0 <br>
<p>Alex Bäuerle, Daniel Jönsson, Timo Ropinski</p></summary>
<p>

**Abstract:** A key to deciphering the inner workings of neural networks is understanding what a model has learned. Promising methods for discovering learned features are based on analyzing activation values, whereby current techniques focus on analyzing high activation values to reveal interesting features on a neuron level. However, analyzing high activation values limits layer-level concept discovery. We present a method that instead takes into account the entire activation distribution. By extracting similar activation profiles within the high-dimensional activation space of a neural network layer, we find groups of inputs that are treated similarly. These input groups represent neural activation patterns (NAPs) and can be used to visualize and interpret learned layer concepts. We release a framework with which NAPs can be extracted from pre-trained models and provide a visual introspection tool that can be used to analyze NAPs. We tested our method with a variety of networks and show how it complements existing methods for analyzing neural network activation values.

</p>
</details>

<details><summary><b>DeePKS+ABACUS as a Bridge between Expensive Quantum Mechanical Models and Machine Learning Potentials</b>
<a href="https://arxiv.org/abs/2206.10093">arxiv:2206.10093</a>
&#x1F4C8; 0 <br>
<p>Wenfei Li, Qi Ou, Yixiao Chen, Yu Cao, Renxi Liu, Chunyi Zhang, Daye Zheng, Chun Cai, Xifan Wu, Han Wang, Mohan Chen, Linfeng Zhang</p></summary>
<p>

**Abstract:** Recently, the development of machine learning (ML) potentials has made it possible to perform large-scale and long-time molecular simulations with the accuracy of quantum mechanical (QM) models. However, for high-level QM methods, such as density functional theory (DFT) at the meta-GGA level and/or with exact exchange, quantum Monte Carlo, etc., generating a sufficient amount of data for training a ML potential has remained computationally challenging due to their high cost. In this work, we demonstrate that this issue can be largely alleviated with Deep Kohn-Sham (DeePKS), a ML-based DFT model. DeePKS employs a computationally efficient neural network-based functional model to construct a correction term added upon a cheap DFT model. Upon training, DeePKS offers closely-matched energies and forces compared with high-level QM method, but the number of training data required is orders of magnitude less than that required for training a reliable ML potential. As such, DeePKS can serve as a bridge between expensive QM models and ML potentials: one can generate a decent amount of high-accuracy QM data to train a DeePKS model, and then use the DeePKS model to label a much larger amount of configurations to train a ML potential. This scheme for periodic systems is implemented in a DFT package ABACUS, which is open-source and ready for use in various applications.

</p>
</details>

<details><summary><b>Short Video Uprising: How #BlackLivesMatter Content on TikTok Challenges the Protest Paradigm</b>
<a href="https://arxiv.org/abs/2206.09946">arxiv:2206.09946</a>
&#x1F4C8; 0 <br>
<p>Yanru Jiang, Xin Jin, Qinhao Deng</p></summary>
<p>

**Abstract:** This study uses TikTok (N = 8,173) to examine how short-form video platforms challenge the protest paradigm in the recent Black Lives Matter movement. A computer-mediated visual analysis, computer vision, is employed to identify the presence of four visual frames of protest (riot, confrontation, spectacle, and debate) in multimedia content. Results of descriptive statistics and the t-test indicate that the three delegitimizing frames - riot, confrontation, and spectacle - are rarely found on TikTok, whereas the debate frame, that empowers marginalized communities, dominates the public sphere. However, although the three delegitimizing frames receive lower social media visibility, as measured by views, likes, shares, followers, and durations, legitimizing elements, such as the debate frame, minority identities, and unofficial sources, are not generally favored by TikTok audiences. This study concludes that while short-form video platforms could potentially challenge the protest paradigm on the content creators' side, the audiences' preference as measured by social media visibility might still be moderately associated with the protest paradigm.

</p>
</details>

<details><summary><b>WiFi-based Spatiotemporal Human Action Perception</b>
<a href="https://arxiv.org/abs/2206.09867">arxiv:2206.09867</a>
&#x1F4C8; 0 <br>
<p>Yanling Hao, Zhiyuan Shi, Yuanwei Liu</p></summary>
<p>

**Abstract:** WiFi-based sensing for human activity recognition (HAR) has recently become a hot topic as it brings great benefits when compared with video-based HAR, such as eliminating the demands of line-of-sight (LOS) and preserving privacy. Making the WiFi signals to 'see' the action, however, is quite coarse and thus still in its infancy. An end-to-end spatiotemporal WiFi signal neural network (STWNN) is proposed to enable WiFi-only sensing in both line-of-sight and non-line-of-sight scenarios. Especially, the 3D convolution module is able to explore the spatiotemporal continuity of WiFi signals, and the feature self-attention module can explicitly maintain dominant features. In addition, a novel 3D representation for WiFi signals is designed to preserve multi-scale spatiotemporal information. Furthermore, a small wireless-vision dataset (WVAR) is synchronously collected to extend the potential of STWNN to 'see' through occlusions. Quantitative and qualitative results on WVAR and the other three public benchmark datasets demonstrate the effectiveness of our approach on both accuracy and shift consistency.

</p>
</details>

<details><summary><b>A Note on the Convergence of Mirrored Stein Variational Gradient Descent under $(L_0,L_1)-$Smoothness Condition</b>
<a href="https://arxiv.org/abs/2206.09709">arxiv:2206.09709</a>
&#x1F4C8; 0 <br>
<p>Lukang Sun, Peter Richtárik</p></summary>
<p>

**Abstract:** In this note, we establish a descent lemma for the population limit Mirrored Stein Variational Gradient Method~(MSVGD). This descent lemma does not rely on the path information of MSVGD but rather on a simple assumption for the mirrored distribution $\nablaΨ_{\#}π\propto\exp(-V)$. Our analysis demonstrates that MSVGD can be applied to a broader class of constrained sampling problems with non-smooth $V$. We also investigate the complexity of the population limit MSVGD in terms of dimension $d$.

</p>
</details>

<details><summary><b>FoR$^2$M: Recognition and Repair of Foldings in Mesh Surfaces. Application to 3D Object Degradation</b>
<a href="https://arxiv.org/abs/2206.09699">arxiv:2206.09699</a>
&#x1F4C8; 0 <br>
<p>K. Sfikas, P. Perakis, T. Theoharis</p></summary>
<p>

**Abstract:** Triangular meshes are the most popular representations of 3D objects, but many mesh surfaces contain topological singularities that represent a challenge for displaying or further processing them properly. One such singularity is the self-intersections that may be present in mesh surfaces that have been created by a scanning procedure or by a deformation transformation, such as off-setting.
  Mesh foldings comprise a special case of mesh surface self-intersections, where the faces of the 3D model intersect and become reversed, with respect to the unfolded part of the mesh surface. A novel method for the recognition and repair of mesh surface foldings is presented, which exploits the structural characteristics of the foldings in order to efficiently detect the folded regions. Following detection, the foldings are removed and any gaps so created are filled based on the geometry of the 3D model. The proposed method is directly applicable to simple mesh surface representations while it does not perform any embedding of the 3D mesh (i.e. voxelization, projection). Target of the proposed method is to facilitate mesh degradation procedures in a fashion that retains the original structure, given the operator, in the most efficient manner.

</p>
</details>

<details><summary><b>SJ-HD^2R: Selective Joint High Dynamic Range and Denoising Imaging for Dynamic Scenes</b>
<a href="https://arxiv.org/abs/2206.09611">arxiv:2206.09611</a>
&#x1F4C8; 0 <br>
<p>Wei Li, Shuai Xiao, Tianhong Dai, Shanxin Yuan, Tao Wang, Cheng Li, Fenglong Song</p></summary>
<p>

**Abstract:** Ghosting artifacts, motion blur, and low fidelity in highlight are the main challenges in High Dynamic Range (HDR) imaging from multiple Low Dynamic Range (LDR) images. These issues come from using the medium-exposed image as the reference frame in previous methods. To deal with them, we propose to use the under-exposed image as the reference to avoid these issues. However, the heavy noise in dark regions of the under-exposed image becomes a new problem. Therefore, we propose a joint HDR and denoising pipeline, containing two sub-networks: (i) a pre-denoising network (PreDNNet) to adaptively denoise input LDRs by exploiting exposure priors; (ii) a pyramid cascading fusion network (PCFNet), introducing an attention mechanism and cascading structure in a multi-scale manner. To further leverage these two paradigms, we propose a selective and joint HDR and denoising (SJ-HD$^2$R) imaging framework, utilizing scenario-specific priors to conduct the path selection with an accuracy of more than 93.3$\%$. We create the first joint HDR and denoising benchmark dataset, which contains a variety of challenging HDR and denoising scenes and supports the switching of the reference image. Extensive experiment results show that our method achieves superior performance to previous methods.

</p>
</details>

<details><summary><b>Guardian Angel: A Novel Walking Aid for the Visually Impaired</b>
<a href="https://arxiv.org/abs/2206.09570">arxiv:2206.09570</a>
&#x1F4C8; 0 <br>
<p>Ko-Wei Tai, HuaYen Lee, Hsin-Huei Chen, Jeng-Sheng Yeh, Ming Ouhyoung</p></summary>
<p>

**Abstract:** This work introduces Guardian Angel, an Android App that assists visually impaired people to avoid danger in complex traffic environment. The system, consisting of object detection by pretrained YOLO model, distance estimation and moving direction estimation, provides information about surrounding vehicles and alarms users of potential danger without expensive special purpose device. With an experiment of 8 subjects, we corroborate that in terms of satisfaction score in pedestrian-crossing experiment with the assistance of our App using a smartphone is better than when without under 99% confidence level. The time needed to cross a road is shorter on average with the assistance of our system, however, not reaching significant difference by our experiment. The App has been released in Google Play Store, open to the public for free.

</p>
</details>


{% endraw %}
Prev: [2022.06.19]({{ '/2022/06/19/2022.06.19.html' | relative_url }})  Next: [2022.06.21]({{ '/2022/06/21/2022.06.21.html' | relative_url }})