Prev: [2022.04.09]({{ '/2022/04/09/2022.04.09.html' | relative_url }})  Next: [2022.04.11]({{ '/2022/04/11/2022.04.11.html' | relative_url }})
{% raw %}
## Summary for 2022-04-10, created on 2022-04-14


<details><summary><b>DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</b>
<a href="https://arxiv.org/abs/2204.04799">arxiv:2204.04799</a>
&#x1F4C8; 7 <br>
<p>Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, Tomas Pfister</p></summary>
<p>

**Abstract:** Continual learning aims to enable a single model to learn a sequence of tasks without catastrophic forgetting. Top-performing methods usually require a rehearsal buffer to store past pristine examples for experience replay, which, however, limits their practical value due to privacy and memory constraints. In this work, we present a simple yet effective framework, DualPrompt, which learns a tiny set of parameters, called prompts, to properly instruct a pre-trained model to learn tasks arriving sequentially without buffering past examples. DualPrompt presents a novel approach to attach complementary prompts to the pre-trained backbone, and then formulates the objective as learning task-invariant and task-specific "instructions". With extensive experimental validation, DualPrompt consistently sets state-of-the-art performance under the challenging class-incremental setting. In particular, DualPrompt outperforms recent advanced continual learning methods with relatively large buffer sizes. We also introduce a more challenging benchmark, Split ImageNet-R, to help generalize rehearsal-free continual learning research. Source code is available at https://github.com/google-research/l2p.

</p>
</details>

<details><summary><b>FedCorr: Multi-Stage Federated Learning for Label Noise Correction</b>
<a href="https://arxiv.org/abs/2204.04677">arxiv:2204.04677</a>
&#x1F4C8; 5 <br>
<p>Jingyi Xu, Zihan Chen, Tony Q. S. Quek, Kai Fong Ernest Chong</p></summary>
<p>

**Abstract:** Federated learning (FL) is a privacy-preserving distributed learning paradigm that enables clients to jointly train a global model. In real-world FL implementations, client data could have label noise, and different clients could have vastly different label noise levels. Although there exist methods in centralized learning for tackling label noise, such methods do not perform well on heterogeneous label noise in FL settings, due to the typically smaller sizes of client datasets and data privacy requirements in FL. In this paper, we propose $\texttt{FedCorr}$, a general multi-stage framework to tackle heterogeneous label noise in FL, without making any assumptions on the noise models of local clients, while still maintaining client data privacy. In particular, (1) $\texttt{FedCorr}$ dynamically identifies noisy clients by exploiting the dimensionalities of the model prediction subspaces independently measured on all clients, and then identifies incorrect labels on noisy clients based on per-sample losses. To deal with data heterogeneity and to increase training stability, we propose an adaptive local proximal regularization term that is based on estimated local noise levels. (2) We further finetune the global model on identified clean clients and correct the noisy labels for the remaining noisy clients after finetuning. (3) Finally, we apply the usual training on all clients to make full use of all local data. Experiments conducted on CIFAR-10/100 with federated synthetic label noise, and on a real-world noisy dataset, Clothing1M, demonstrate that $\texttt{FedCorr}$ is robust to label noise and substantially outperforms the state-of-the-art methods at multiple noise levels.

</p>
</details>

<details><summary><b>Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention</b>
<a href="https://arxiv.org/abs/2204.04601">arxiv:2204.04601</a>
&#x1F4C8; 5 <br>
<p>Yu Yang, Seungbae Kim, Jungseock Joo</p></summary>
<p>

**Abstract:** Interpretability is an important property for visual models as it helps researchers and users understand the internal mechanism of a complex model. However, generating semantic explanations about the learned representation is challenging without direct supervision to produce such explanations. We propose a general framework, Latent Visual Semantic Explainer (LaViSE), to teach any existing convolutional neural network to generate text descriptions about its own latent representations at the filter level. Our method constructs a mapping between the visual and semantic spaces using generic image datasets, using images and category names. It then transfers the mapping to the target domain which does not have semantic labels. The proposed framework employs a modular structure and enables to analyze any trained network whether or not its original training data is available. We show that our method can generate novel descriptions for learned filters beyond the set of categories defined in the training dataset and perform an extensive evaluation on multiple datasets. We also demonstrate a novel application of our method for unsupervised dataset bias analysis which allows us to automatically discover hidden biases in datasets or compare different subsets without using additional labels. The dataset and code are made public to facilitate further research.

</p>
</details>

<details><summary><b>Fusion of Self-supervised Learned Models for MOS Prediction</b>
<a href="https://arxiv.org/abs/2204.04855">arxiv:2204.04855</a>
&#x1F4C8; 4 <br>
<p>Zhengdong Yang, Wangjin Zhou, Chenhui Chu, Sheng Li, Raj Dabre, Raphael Rubino, Yi Zhao</p></summary>
<p>

**Abstract:** We participated in the mean opinion score (MOS) prediction challenge, 2022. This challenge aims to predict MOS scores of synthetic speech on two tracks, the main track and a more challenging sub-track: out-of-domain (OOD). To improve the accuracy of the predicted scores, we have explored several model fusion-related strategies and proposed a fused framework in which seven pretrained self-supervised learned (SSL) models have been engaged. These pretrained SSL models are derived from three ASR frameworks, including Wav2Vec, Hubert, and WavLM. For the OOD track, we followed the 7 SSL models selected on the main track and adopted a semi-supervised learning method to exploit the unlabeled data. According to the official analysis results, our system has achieved 1st rank in 6 out of 16 metrics and is one of the top 3 systems for 13 out of 16 metrics. Specifically, we have achieved the highest LCC, SRCC, and KTAU scores at the system level on main track, as well as the best performance on the LCC, SRCC, and KTAU evaluation metrics at the utterance level on OOD track. Compared with the basic SSL models, the prediction accuracy of the fused system has been largely improved, especially on OOD sub-track.

</p>
</details>

<details><summary><b>Explanation Graph Generation via Pre-trained Language Models: An Empirical Study with Contrastive Learning</b>
<a href="https://arxiv.org/abs/2204.04813">arxiv:2204.04813</a>
&#x1F4C8; 4 <br>
<p>Swarnadeep Saha, Prateek Yadav, Mohit Bansal</p></summary>
<p>

**Abstract:** Pre-trained sequence-to-sequence language models have led to widespread success in many natural language generation tasks. However, there has been relatively less work on analyzing their ability to generate structured outputs such as graphs. Unlike natural language, graphs have distinct structural and semantic properties in the context of a downstream NLP task, e.g., generating a graph that is connected and acyclic can be attributed to its structural constraints, while the semantics of a graph can refer to how meaningfully an edge represents the relation between two node concepts. In this work, we study pre-trained language models that generate explanation graphs in an end-to-end manner and analyze their ability to learn the structural constraints and semantics of such graphs. We first show that with limited supervision, pre-trained language models often generate graphs that either violate these constraints or are semantically incoherent. Since curating large amount of human-annotated graphs is expensive and tedious, we propose simple yet effective ways of graph perturbations via node and edge edit operations that lead to structurally and semantically positive and negative graphs. Next, we leverage these graphs in different contrastive learning models with Max-Margin and InfoNCE losses. Our methods lead to significant improvements in both structural and semantic accuracy of explanation graphs and also generalize to other similar graph generation tasks. Lastly, we show that human errors are the best negatives for contrastive learning and also that automatically generating more such human-like negative graphs can lead to further improvements. Our code and models are publicly available at https://github.com/swarnaHub/ExplagraphGen

</p>
</details>

<details><summary><b>SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition</b>
<a href="https://arxiv.org/abs/2204.04796">arxiv:2204.04796</a>
&#x1F4C8; 4 <br>
<p>Victor Escorcia, Ricardo Guerrero, Xiatian Zhu, Brais Martinez</p></summary>
<p>

**Abstract:** Learning an egocentric action recognition model from video data is challenging due to distractors (e.g., irrelevant objects) in the background. Further integrating object information into an action model is hence beneficial. Existing methods often leverage a generic object detector to identify and represent the objects in the scene. However, several important issues remain. Object class annotations of good quality for the target domain (dataset) are still required for learning good object representation. Besides, previous methods deeply couple the existing action models and need to retrain them jointly with object representation, leading to costly and inflexible integration. To overcome both limitations, we introduce Self-Supervised Learning Over Sets (SOS), an approach to pre-train a generic Objects In Contact (OIC) representation model from video object regions detected by an off-the-shelf hand-object contact detector. Instead of augmenting object regions individually as in conventional self-supervised learning, we view the action process as a means of natural data transformations with unique spatio-temporal continuity and exploit the inherent relationships among per-video object sets. Extensive experiments on two datasets, EPIC-KITCHENS-100 and EGTEA, show that our OIC significantly boosts the performance of multiple state-of-the-art video classification models.

</p>
</details>

<details><summary><b>MedDistant19: A Challenging Benchmark for Distantly Supervised Biomedical Relation Extraction</b>
<a href="https://arxiv.org/abs/2204.04779">arxiv:2204.04779</a>
&#x1F4C8; 4 <br>
<p>Saadullah Amin, Pasquale Minervini, David Chang, Günter Neumann, Pontus Stenetorp</p></summary>
<p>

**Abstract:** Relation Extraction in the biomedical domain is challenging due to the lack of labeled data and high annotation costs, needing domain experts. Distant supervision is commonly used as a way to tackle the scarcity of annotated data by automatically pairing knowledge graph relationships with raw texts. Distantly Supervised Biomedical Relation Extraction (Bio-DSRE) models can seemingly produce very accurate results in several benchmarks. However, given the challenging nature of the task, we set out to investigate the validity of such impressive results. We probed the datasets used by Amin et al. (2020) and Hogan et al. (2021) and found a significant overlap between training and evaluation relationships that, once resolved, reduced the accuracy of the models by up to 71%. Furthermore, we noticed several inconsistencies with the data construction process, such as creating negative samples and improper handling of redundant relationships. We mitigate these issues and present MedDistant19, a new benchmark dataset obtained by aligning the MEDLINE abstracts with the widely used SNOMED Clinical Terms (SNOMED CT) knowledge base. We experimented with several state-of-the-art models achieving an AUC of 55.4% and 49.8% at sentence- and bag-level, showing that there is still plenty of room for improvement.

</p>
</details>

<details><summary><b>Word Embeddings Are Capable of Capturing Rhythmic Similarity of Words</b>
<a href="https://arxiv.org/abs/2204.04833">arxiv:2204.04833</a>
&#x1F4C8; 3 <br>
<p>Hosein Rezaei</p></summary>
<p>

**Abstract:** Word embedding systems such as Word2Vec and GloVe are well-known in deep learning approaches to NLP. This is largely due to their ability to capture semantic relationships between words. In this work we investigated their usefulness in capturing rhythmic similarity of words instead. The results show that vectors these embeddings assign to rhyming words are more similar to each other, compared to the other words. It is also revealed that GloVe performs relatively better than Word2Vec in this regard. We also proposed a first of its kind metric for quantifying rhythmic similarity of a pair of words.

</p>
</details>

<details><summary><b>OutfitTransformer: Learning Outfit Representations for Fashion Recommendation</b>
<a href="https://arxiv.org/abs/2204.04812">arxiv:2204.04812</a>
&#x1F4C8; 3 <br>
<p>Rohan Sarkar, Navaneeth Bodla, Mariya Vasileva, Yen-Liang Lin, Anurag Beniwal, Alan Lu, Gerard Medioni</p></summary>
<p>

**Abstract:** Learning an effective outfit-level representation is critical for predicting the compatibility of items in an outfit, and retrieving complementary items for a partial outfit. We present a framework, OutfitTransformer, that uses the proposed task-specific tokens and leverages the self-attention mechanism to learn effective outfit-level representations encoding the compatibility relationships between all items in the entire outfit for addressing both compatibility prediction and complementary item retrieval tasks. For compatibility prediction, we design an outfit token to capture a global outfit representation and train the framework using a classification loss. For complementary item retrieval, we design a target item token that additionally takes the target item specification (in the form of a category or text description) into consideration. We train our framework using a proposed set-wise outfit ranking loss to generate a target item embedding given an outfit, and a target item specification as inputs. The generated target item embedding is then used to retrieve compatible items that match the rest of the outfit. Additionally, we adopt a pre-training approach and a curriculum learning strategy to improve retrieval performance. Since our framework learns at an outfit-level, it allows us to learn a single embedding capturing higher-order relations among multiple items in the outfit more effectively than pairwise methods. Experiments demonstrate that our approach outperforms state-of-the-art methods on compatibility prediction, fill-in-the-blank, and complementary item retrieval tasks. We further validate the quality of our retrieval results with a user study.

</p>
</details>

<details><summary><b>On the pragmatism of using binary classifiers over data intensive neural network classifiers for detection of COVID-19 from voice</b>
<a href="https://arxiv.org/abs/2204.04802">arxiv:2204.04802</a>
&#x1F4C8; 3 <br>
<p>Ankit Shah, Hira Dhamyal, Yang Gao, Rita Singh, Bhiksha Raj</p></summary>
<p>

**Abstract:** Lately, there has been a global effort by multiple research groups to detect COVID-19 from voice. Different researchers use different kinds of information from the voice signal to achieve this. Various types of phonated sounds and the sound of cough and breath have all been used with varying degrees of success in automated voice-based COVID-19 detection apps. In this paper, we show that detecting COVID-19 from voice does not require custom-made non-standard features or complicated neural network classifiers rather it can be successfully done with just standard features and simple binary classifiers. In fact, we show that the latter is not only more accurate and interpretable and also more computationally efficient in that they can be run locally on small devices. We demonstrate this from a human-curated dataset collected and calibrated in clinical settings. On this dataset which comprises over 1000 speakers, a simple binary classifier is able to achieve 94% detection accuracy.

</p>
</details>

<details><summary><b>DILEMMA: Self-Supervised Shape and Texture Learning with Transformers</b>
<a href="https://arxiv.org/abs/2204.04788">arxiv:2204.04788</a>
&#x1F4C8; 3 <br>
<p>Sepehr Sameni, Simon Jenni, Paolo Favaro</p></summary>
<p>

**Abstract:** There is a growing belief that deep neural networks with a shape bias may exhibit better generalization capabilities than models with a texture bias, because shape is a more reliable indicator of the object category. However, we show experimentally that existing measures of shape bias are not stable predictors of generalization and argue that shape discrimination should not come at the expense of texture discrimination. Thus, we propose a pseudo-task to explicitly boost both shape and texture discriminability in models trained via self-supervised learning. For this purpose, we train a ViT to detect which input token has been combined with an incorrect positional embedding. To retain texture discrimination, the ViT is also trained as in MoCo with a student-teacher architecture and a contrastive loss over an extra learnable class token. We call our method DILEMMA, which stands for Detection of Incorrect Location EMbeddings with MAsked inputs. We evaluate our method through fine-tuning on several datasets and show that it outperforms MoCoV3 and DINO. Moreover, we show that when downstream tasks are strongly reliant on shape (such as in the YOGA-82 pose dataset), our pre-trained features yield a significant gain over prior work. Code will be released upon publication.

</p>
</details>

<details><summary><b>Rethinking Exponential Averaging of the Fisher</b>
<a href="https://arxiv.org/abs/2204.04718">arxiv:2204.04718</a>
&#x1F4C8; 3 <br>
<p>Constantin Octavian Puiu</p></summary>
<p>

**Abstract:** In optimization for Machine learning (ML), it is typical that curvature-matrix (CM) estimates rely on an exponential average (EA) of local estimates (giving EA-CM algorithms). This approach has little principled justification, but is very often used in practice. In this paper, we draw a connection between EA-CM algorithms and what we call a "Wake of Quadratic regularized models". The outlined connection allows us to understand what EA-CM algorithms are doing from an optimization perspective. Generalizing from the established connection, we propose a new family of algorithms, "KL-Divergence Wake-Regularized Models" (KLD-WRM). We give three different practical instantiations of KLD-WRM, and show numerical results where we outperform K-FAC.

</p>
</details>

<details><summary><b>TOV: The Original Vision Model for Optical Remote Sensing Image Understanding via Self-supervised Learning</b>
<a href="https://arxiv.org/abs/2204.04716">arxiv:2204.04716</a>
&#x1F4C8; 3 <br>
<p>Chao Tao, Ji Qia, Guo Zhang, Qing Zhu, Weipeng Lu, Haifeng Li</p></summary>
<p>

**Abstract:** Do we on the right way for remote sensing image understanding (RSIU) by training models via supervised data-dependent and task-dependent way, instead of human vision in a label-free and task-independent way? We argue that a more desirable RSIU model should be trained with intrinsic structure from data rather that extrinsic human labels to realize generalizability across a wide range of RSIU tasks. According to this hypothesis, we proposed \textbf{T}he \textbf{O}riginal \textbf{V}ision model (TOV) in remote sensing filed. Trained by massive unlabeled optical data along a human-like self-supervised learning (SSL) path that is from general knowledge to specialized knowledge, TOV model can be easily adapted to various RSIU tasks, including scene classification, object detection, and semantic segmentation, and outperforms dominant ImageNet supervised pretrained method as well as two recently proposed SSL pretrained methods on majority of 12 publicly available benchmarks. Moreover, we analyze the influences of two key factors on the performance of building TOV model for RSIU, including the influence of using different data sampling methods and the selection of learning paths during self-supervised optimization. We believe that a general model which is trained by a label-free and task-independent way may be the next paradigm for RSIU and hope the insights distilled from this study can help to foster the development of an original vision model for RSIU.

</p>
</details>

<details><summary><b>Linear Complexity Randomized Self-attention Mechanism</b>
<a href="https://arxiv.org/abs/2204.04667">arxiv:2204.04667</a>
&#x1F4C8; 3 <br>
<p>Lin Zheng, Chong Wang, Lingpeng Kong</p></summary>
<p>

**Abstract:** Recently, random feature attentions (RFAs) are proposed to approximate the softmax attention in linear time and space complexity by linearizing the exponential kernel. In this paper, we first propose a novel perspective to understand the bias in such approximation by recasting RFAs as self-normalized importance samplers. This perspective further sheds light on an \emph{unbiased} estimator for the whole softmax attention, called randomized attention (RA). RA constructs positive random features via query-specific distributions and enjoys greatly improved approximation fidelity, albeit exhibiting quadratic complexity. By combining the expressiveness in RA and the efficiency in RFA, we develop a novel linear complexity self-attention mechanism called linear randomized attention (LARA). Extensive experiments across various domains demonstrate that RA and LARA significantly improve the performance of RFAs by a substantial margin.

</p>
</details>

<details><summary><b>Self-Supervised Audio-and-Text Pre-training with Extremely Low-Resource Parallel Data</b>
<a href="https://arxiv.org/abs/2204.04645">arxiv:2204.04645</a>
&#x1F4C8; 3 <br>
<p>Yu Kang, Tianqiao Liu, Hang Li, Yang Hao, Wenbiao Ding</p></summary>
<p>

**Abstract:** Multimodal pre-training for audio-and-text has recently been proved to be effective and has significantly improved the performance of many downstream speech understanding tasks. However, these state-of-the-art pre-training audio-text models work well only when provided with large amount of parallel audio-and-text data, which brings challenges on many languages that are rich in unimodal corpora but scarce of parallel cross-modal corpus. In this paper, we investigate whether it is possible to pre-train an audio-text multimodal model with extremely low-resource parallel data and extra non-parallel unimodal data. Our pre-training framework consists of the following components: (1) Intra-modal Denoising Auto-Encoding (IDAE), which is able to reconstruct input text (audio) representations from a noisy version of itself. (2) Cross-modal Denoising Auto-Encoding (CDAE), which is pre-trained to reconstruct the input text (audio), given both a noisy version of the input text (audio) and the corresponding translated noisy audio features (text embeddings). (3) Iterative Denoising Process (IDP), which iteratively translates raw audio (text) and the corresponding text embeddings (audio features) translated from previous iteration into the new less-noisy text embeddings (audio features). We adapt a dual cross-modal Transformer as our backbone model which consists of two unimodal encoders for IDAE and two cross-modal encoders for CDAE and IDP. Our method achieves comparable performance on multiple downstream speech understanding tasks compared with the model pre-trained on fully parallel data, demonstrating the great potential of the proposed method. Our code is available at: \url{https://github.com/KarlYuKang/Low-Resource-Multimodal-Pre-training}.

</p>
</details>

<details><summary><b>"That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2204.04636">arxiv:2204.04636</a>
&#x1F4C8; 3 <br>
<p>Edoardo Mosca, Shreyash Agarwal, Javier Rando-Ramirez, Georg Groh</p></summary>
<p>

**Abstract:** Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks.

</p>
</details>

<details><summary><b>Decay No More: A Persistent Twitter Dataset for Learning Social Meaning</b>
<a href="https://arxiv.org/abs/2204.04611">arxiv:2204.04611</a>
&#x1F4C8; 3 <br>
<p>Chiyu Zhang, Muhammad Abdul-Mageed, El Moatez Billah Nagoudi</p></summary>
<p>

**Abstract:** With the proliferation of social media, many studies resort to social media to construct datasets for developing social meaning understanding systems. For the popular case of Twitter, most researchers distribute tweet IDs without the actual text contents due to the data distribution policy of the platform. One issue is that the posts become increasingly inaccessible over time, which leads to unfair comparisons and a temporal bias in social media research. To alleviate this challenge of data decay, we leverage a paraphrase model to propose a new persistent English Twitter dataset for social meaning (PTSM). PTSM consists of $17$ social meaning datasets in $10$ categories of tasks. We experiment with two SOTA pre-trained language models and show that our PTSM can substitute the actual tweets with paraphrases with marginal performance loss.

</p>
</details>

<details><summary><b>Towards efficient representation identification in supervised learning</b>
<a href="https://arxiv.org/abs/2204.04606">arxiv:2204.04606</a>
&#x1F4C8; 3 <br>
<p>Kartik Ahuja, Divyat Mahajan, Vasilis Syrgkanis, Ioannis Mitliagkas</p></summary>
<p>

**Abstract:** Humans have a remarkable ability to disentangle complex sensory inputs (e.g., image, text) into simple factors of variation (e.g., shape, color) without much supervision. This ability has inspired many works that attempt to solve the following question: how do we invert the data generation process to extract those factors with minimal or no supervision? Several works in the literature on non-linear independent component analysis have established this negative result; without some knowledge of the data generation process or appropriate inductive biases, it is impossible to perform this inversion. In recent years, a lot of progress has been made on disentanglement under structural assumptions, e.g., when we have access to auxiliary information that makes the factors of variation conditionally independent. However, existing work requires a lot of auxiliary information, e.g., in supervised classification, it prescribes that the number of label classes should be at least equal to the total dimension of all factors of variation. In this work, we depart from these assumptions and ask: a) How can we get disentanglement when the auxiliary information does not provide conditional independence over the factors of variation? b) Can we reduce the amount of auxiliary information required for disentanglement? For a class of models where auxiliary information does not ensure conditional independence, we show theoretically and experimentally that disentanglement (to a large extent) is possible even when the auxiliary information dimension is much less than the dimension of the true latent representation.

</p>
</details>

<details><summary><b>SUMD: Super U-shaped Matrix Decomposition Convolutional neural network for Image denoising</b>
<a href="https://arxiv.org/abs/2204.04861">arxiv:2204.04861</a>
&#x1F4C8; 2 <br>
<p>QiFan Li</p></summary>
<p>

**Abstract:** In this paper, we propose a novel and efficient CNN-based framework that leverages local and global context information for image denoising. Due to the limitations of convolution itself, the CNN-based method is generally unable to construct an effective and structured global feature representation, usually called the long-distance dependencies in the Transformer-based method. To tackle this problem, we introduce the matrix decomposition module(MD) in the network to establish the global context feature, comparable to the Transformer based method performance. Inspired by the design of multi-stage progressive restoration of U-shaped architecture, we further integrate the MD module into the multi-branches to acquire the relative global feature representation of the patch range at the current stage. Then, the stage input gradually rises to the overall scope and continuously improves the final feature. Experimental results on various image denoising datasets: SIDD, DND, and synthetic Gaussian noise datasets show that our model(SUMD) can produce comparable visual quality and accuracy results with Transformer-based methods.

</p>
</details>

<details><summary><b>A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and Challenges</b>
<a href="https://arxiv.org/abs/2204.04859">arxiv:2204.04859</a>
&#x1F4C8; 2 <br>
<p>Junyun Cui, Xiaoyu Shen, Feiping Nie, Zheng Wang, Jinglong Wang, Yulong Chen</p></summary>
<p>

**Abstract:** Legal judgment prediction (LJP) applies Natural Language Processing (NLP) techniques to predict judgment results based on fact descriptions automatically. Recently, large-scale public datasets and advances in NLP research have led to increasing interest in LJP. Despite a clear gap between machine and human performance, impressive results have been achieved in various benchmark datasets. In this paper, to address the current lack of comprehensive survey of existing LJP tasks, datasets, models and evaluations, (1) we analyze 31 LJP datasets in 6 languages, present their construction process and define a classification method of LJP with 3 different attributes; (2) we summarize 14 evaluation metrics under four categories for different outputs of LJP tasks; (3) we review 12 legal-domain pretrained models in 3 languages and highlight 3 major research directions for LJP; (4) we show the state-of-art results for 8 representative datasets from different court cases and discuss the open challenges. This paper can provide up-to-date and comprehensive reviews to help readers understand the status of LJP. We hope to facilitate both NLP researchers and legal professionals for further joint efforts in this problem.

</p>
</details>

<details><summary><b>Towards Homogeneous Modality Learning and Multi-Granularity Information Exploration for Visible-Infrared Person Re-Identification</b>
<a href="https://arxiv.org/abs/2204.04842">arxiv:2204.04842</a>
&#x1F4C8; 2 <br>
<p>Haojie Liu, Daoxun Xia, Wei Jiang, Chao Xu</p></summary>
<p>

**Abstract:** Visible-infrared person re-identification (VI-ReID) is a challenging and essential task, which aims to retrieve a set of person images over visible and infrared camera views. In order to mitigate the impact of large modality discrepancy existing in heterogeneous images, previous methods attempt to apply generative adversarial network (GAN) to generate the modality-consisitent data. However, due to severe color variations between the visible domain and infrared domain, the generated fake cross-modality samples often fail to possess good qualities to fill the modality gap between synthesized scenarios and target real ones, which leads to sub-optimal feature representations. In this work, we address cross-modality matching problem with Aligned Grayscale Modality (AGM), an unified dark-line spectrum that reformulates visible-infrared dual-mode learning as a gray-gray single-mode learning problem. Specifically, we generate the grasycale modality from the homogeneous visible images. Then, we train a style tranfer model to transfer infrared images into homogeneous grayscale images. In this way, the modality discrepancy is significantly reduced in the image space. In order to reduce the remaining appearance discrepancy, we further introduce a multi-granularity feature extraction network to conduct feature-level alignment. Rather than relying on the global information, we propose to exploit local (head-shoulder) features to assist person Re-ID, which complements each other to form a stronger feature descriptor. Comprehensive experiments implemented on the mainstream evaluation datasets include SYSU-MM01 and RegDB indicate that our method can significantly boost cross-modality retrieval performance against the state of the art methods.

</p>
</details>

<details><summary><b>Dependable Intrusion Detection System for IoT: A Deep Transfer Learning-based Approach</b>
<a href="https://arxiv.org/abs/2204.04837">arxiv:2204.04837</a>
&#x1F4C8; 2 <br>
<p>Sk. Tanzir Mehedi, Adnan Anwar, Ziaur Rahman, Kawsar Ahmed, Rafiqul Islam</p></summary>
<p>

**Abstract:** Security concerns for IoT applications have been alarming because of their widespread use in different enterprise systems. The potential threats to these applications are constantly emerging and changing, and therefore, sophisticated and dependable defense solutions are necessary against such threats. With the rapid development of IoT networks and evolving threat types, the traditional machine learning-based IDS must update to cope with the security requirements of the current sustainable IoT environment. In recent years, deep learning, and deep transfer learning have progressed and experienced great success in different fields and have emerged as a potential solution for dependable network intrusion detection. However, new and emerging challenges have arisen related to the accuracy, efficiency, scalability, and dependability of the traditional IDS in a heterogeneous IoT setup. This manuscript proposes a deep transfer learning-based dependable IDS model that outperforms several existing approaches. The unique contributions include effective attribute selection, which is best suited to identify normal and attack scenarios for a small amount of labeled data, designing a dependable deep transfer learning-based ResNet model, and evaluating considering real-world data. To this end, a comprehensive experimental performance evaluation has been conducted. Extensive analysis and performance evaluation show that the proposed model is robust, more efficient, and has demonstrated better performance, ensuring dependability.

</p>
</details>

<details><summary><b>RMFGP: Rotated Multi-fidelity Gaussian process with Dimension Reduction for High-dimensional Uncertainty Quantification</b>
<a href="https://arxiv.org/abs/2204.04819">arxiv:2204.04819</a>
&#x1F4C8; 2 <br>
<p>Jiahao Zhang, Shiqi Zhang, Guang Lin</p></summary>
<p>

**Abstract:** Multi-fidelity modelling arises in many situations in computational science and engineering world. It enables accurate inference even when only a small set of accurate data is available. Those data often come from a high-fidelity model, which is computationally expensive. By combining the realizations of the high-fidelity model with one or more low-fidelity models, the multi-fidelity method can make accurate predictions of quantities of interest. This paper proposes a new dimension reduction framework based on rotated multi-fidelity Gaussian process regression and a Bayesian active learning scheme when the available precise observations are insufficient. By drawing samples from the trained rotated multi-fidelity model, the so-called supervised dimension reduction problems can be solved following the idea of the sliced average variance estimation (SAVE) method combined with a Gaussian process regression dimension reduction technique. This general framework we develop can effectively solve high-dimensional problems while the data are insufficient for applying traditional dimension reduction methods. Moreover, a more accurate surrogate Gaussian process model of the original problem can be obtained based on our trained model. The effectiveness of the proposed rotated multi-fidelity Gaussian process(RMFGP) model is demonstrated in four numerical examples. The results show that our method has better performance in all cases and uncertainty propagation analysis is performed for last two cases involving stochastic partial differential equations.

</p>
</details>

<details><summary><b>Temporal Knowledge Graph Reasoning with Low-rank and Model-agnostic Representations</b>
<a href="https://arxiv.org/abs/2204.04783">arxiv:2204.04783</a>
&#x1F4C8; 2 <br>
<p>Ioannis Dikeoulias, Saadullah Amin, Günter Neumann</p></summary>
<p>

**Abstract:** Temporal knowledge graph completion (TKGC) has become a popular approach for reasoning over the event and temporal knowledge graphs, targeting the completion of knowledge with accurate but missing information. In this context, tensor decomposition has successfully modeled interactions between entities and relations. Their effectiveness in static knowledge graph completion motivates us to introduce Time-LowFER, a family of parameter-efficient and time-aware extensions of the low-rank tensor factorization model LowFER. Noting several limitations in current approaches to represent time, we propose a cycle-aware time-encoding scheme for time features, which is model-agnostic and offers a more generalized representation of time. We implement our methods in a unified temporal knowledge graph embedding framework, focusing on time-sensitive data processing. The experiments show that our proposed methods perform on par or better than the state-of-the-art semantic matching models on two benchmarks.

</p>
</details>

<details><summary><b>Few-Shot Cross-lingual Transfer for Coarse-grained De-identification of Code-Mixed Clinical Texts</b>
<a href="https://arxiv.org/abs/2204.04775">arxiv:2204.04775</a>
&#x1F4C8; 2 <br>
<p>Saadullah Amin, Noon Pokaratsiri Goldstein, Morgan Kelly Wixted, Alejandro García-Rudolph, Catalina Martínez-Costa, Günter Neumann</p></summary>
<p>

**Abstract:** Despite the advances in digital healthcare systems offering curated structured knowledge, much of the critical information still lies in large volumes of unlabeled and unstructured clinical texts. These texts, which often contain protected health information (PHI), are exposed to information extraction tools for downstream applications, risking patient identification. Existing works in de-identification rely on using large-scale annotated corpora in English, which often are not suitable in real-world multilingual settings. Pre-trained language models (LM) have shown great potential for cross-lingual transfer in low-resource settings. In this work, we empirically show the few-shot cross-lingual transfer property of LMs for named entity recognition (NER) and apply it to solve a low-resource and real-world challenge of code-mixed (Spanish-Catalan) clinical notes de-identification in the stroke domain. We annotate a gold evaluation dataset to assess few-shot setting performance where we only use a few hundred labeled examples for training. Our model improves the zero-shot F1-score from 73.7% to 91.2% on the gold evaluation set when adapting Multilingual BERT (mBERT) (Devlin et al., 2019) from the MEDDOCAN (Marimon et al., 2019) corpus with our few-shot cross-lingual target corpus. When generalized to an out-of-sample test set, the best model achieves a human-evaluation F1-score of 97.2%.

</p>
</details>

<details><summary><b>Worst-case Performance of Greedy Policies in Bandits with Imperfect Context Observations</b>
<a href="https://arxiv.org/abs/2204.04773">arxiv:2204.04773</a>
&#x1F4C8; 2 <br>
<p>Hongju Park, Mohamad Kazem Shirani Faradonbeh</p></summary>
<p>

**Abstract:** Contextual bandits are canonical models for sequential decision-making under uncertainty in environments with time-varying components. In this setting, the expected reward of each bandit arm consists of the inner product of an unknown parameter and the context vector of that arm, perturbed with a random error. The classical setting heavily relies on fully observed contexts, while study of the richer model of imperfectly observed contextual bandits is immature. This work considers Greedy reinforcement learning policies that take actions as if the current estimates of the parameter and of the unobserved contexts coincide with the corresponding true values. We establish that the non-asymptotic worst-case regret grows logarithmically with the time horizon and the failure probability, while it scales linearly with the number of arms. Numerical analysis showcasing the above efficiency of Greedy policies is also provided.

</p>
</details>

<details><summary><b>Information-theoretic Online Memory Selection for Continual Learning</b>
<a href="https://arxiv.org/abs/2204.04763">arxiv:2204.04763</a>
&#x1F4C8; 2 <br>
<p>Shengyang Sun, Daniele Calandriello, Huiyi Hu, Ang Li, Michalis Titsias</p></summary>
<p>

**Abstract:** A challenging problem in task-free continual learning is the online selection of a representative replay memory from data streams. In this work, we investigate the online memory selection problem from an information-theoretic perspective. To gather the most information, we propose the \textit{surprise} and the \textit{learnability} criteria to pick informative points and to avoid outliers. We present a Bayesian model to compute the criteria efficiently by exploiting rank-one matrix structures. We demonstrate that these criteria encourage selecting informative points in a greedy algorithm for online memory selection. Furthermore, by identifying the importance of \textit{the timing to update the memory}, we introduce a stochastic information-theoretic reservoir sampler (InfoRS), which conducts sampling among selective points with high information. Compared to reservoir sampling, InfoRS demonstrates improved robustness against data imbalance. Finally, empirical performances over continual learning benchmarks manifest its efficiency and efficacy.

</p>
</details>

<details><summary><b>A Comparative Analysis of Decision-Level Fusion for Multimodal Driver Behaviour Understanding</b>
<a href="https://arxiv.org/abs/2204.04734">arxiv:2204.04734</a>
&#x1F4C8; 2 <br>
<p>Alina Roitberg, Kunyu Peng, Zdravko Marinov, Constantin Seibold, David Schneider, Rainer Stiefelhagen</p></summary>
<p>

**Abstract:** Visual recognition inside the vehicle cabin leads to safer driving and more intuitive human-vehicle interaction but such systems face substantial obstacles as they need to capture different granularities of driver behaviour while dealing with highly limited body visibility and changing illumination. Multimodal recognition mitigates a number of such issues: prediction outcomes of different sensors complement each other due to different modality-specific strengths and weaknesses. While several late fusion methods have been considered in previously published frameworks, they constantly feature different architecture backbones and building blocks making it very hard to isolate the role of the chosen late fusion strategy itself. This paper presents an empirical evaluation of different paradigms for decision-level late fusion in video-based driver observation. We compare seven different mechanisms for joining the results of single-modal classifiers which have been both popular, (e.g. score averaging) and not yet considered (e.g. rank-level fusion) in the context of driver observation evaluating them based on different criteria and benchmark settings. This is the first systematic study of strategies for fusing outcomes of multimodal predictors inside the vehicles, conducted with the goal to provide guidance for fusion scheme selection.

</p>
</details>

<details><summary><b>Data Augmentation for Biomedical Factoid Question Answering</b>
<a href="https://arxiv.org/abs/2204.04711">arxiv:2204.04711</a>
&#x1F4C8; 2 <br>
<p>Dimitris Pappas, Prodromos Malakasiotis, Ion Androutsopoulos</p></summary>
<p>

**Abstract:** We study the effect of seven data augmentation (da) methods in factoid question answering, focusing on the biomedical domain, where obtaining training instances is particularly difficult. We experiment with data from the BioASQ challenge, which we augment with training instances obtained from an artificial biomedical machine reading comprehension dataset, or via back-translation, information retrieval, word substitution based on word2vec embeddings, or masked language modeling, question generation, or extending the given passage with additional context. We show that da can lead to very significant performance gains, even when using large pre-trained Transformers, contributing to a broader discussion of if/when da benefits large pre-trained models. One of the simplest da methods, word2vec-based word substitution, performed best and is recommended. We release our artificial training instances and code.

</p>
</details>

<details><summary><b>SplitNets: Designing Neural Architectures for Efficient Distributed Computing on Head-Mounted Systems</b>
<a href="https://arxiv.org/abs/2204.04705">arxiv:2204.04705</a>
&#x1F4C8; 2 <br>
<p>Xin Dong, Barbara De Salvo, Meng Li, Chiao Liu, Zhongnan Qu, H. T. Kung, Ziyun Li</p></summary>
<p>

**Abstract:** We design deep neural networks (DNNs) and corresponding networks' splittings to distribute DNNs' workload to camera sensors and a centralized aggregator on head mounted devices to meet system performance targets in inference accuracy and latency under the given hardware resource constraints. To achieve an optimal balance among computation, communication, and performance, a split-aware neural architecture search framework, SplitNets, is introduced to conduct model designing, splitting, and communication reduction simultaneously. We further extend the framework to multi-view systems for learning to fuse inputs from multiple camera sensors with optimal performance and systemic efficiency. We validate SplitNets for single-view system on ImageNet as well as multi-view system on 3D classification, and show that the SplitNets framework achieves state-of-the-art (SOTA) performance and system latency compared with existing approaches.

</p>
</details>

<details><summary><b>An Efficient Pattern Mining Convolution Neural Network (CNN) algorithm with Grey Wolf Optimization (GWO)</b>
<a href="https://arxiv.org/abs/2204.04704">arxiv:2204.04704</a>
&#x1F4C8; 2 <br>
<p>Aatif Jamshed, Bhawna Mallick, Rajendra Kumar Bharti</p></summary>
<p>

**Abstract:** Automation of feature analysis in the dynamic image frame dataset deals with complexity of intensity mapping with normal and abnormal class. The threshold-based data clustering and feature analysis requires iterative model to learn the component of image frame in multi-pattern for different image frame data type. This paper proposed a novel model of feature analysis method with the CNN based on Convoluted Pattern of Wavelet Transform (CPWT) feature vectors that are optimized by Grey Wolf Optimization (GWO) algorithm. Initially, the image frame gets normalized by applying median filter to the image frame that reduce the noise and apply smoothening on it. From that, the edge information represents the boundary region of bright spot in the image frame. Neural network-based image frame classification performs repeated learning of the feature with minimum training of dataset to cluster the image frame pixels. Features of the filtered image frame was analyzed in different pattern of feature extraction model based on the convoluted model of wavelet transformation method. These features represent the different class of image frame in spatial and textural pattern of it. Convolutional Neural Network (CNN) classifier supports to analyze the features and classify the action label for the image frame dataset. This process enhances the classification with minimum number of training dataset. The performance of this proposed method can be validated by comparing with traditional state-of-art methods.

</p>
</details>

<details><summary><b>Coreset of Hyperspectral Images on Small Quantum Computer</b>
<a href="https://arxiv.org/abs/2204.04691">arxiv:2204.04691</a>
&#x1F4C8; 2 <br>
<p>Soronzonbold Otgonbaatar, Mihai Datcu, Begüm Demir</p></summary>
<p>

**Abstract:** Machine Learning (ML) techniques are employed to analyze and process big Remote Sensing (RS) data, and one well-known ML technique is a Support Vector Machine (SVM). An SVM is a quadratic programming (QP) problem, and a D-Wave quantum annealer (D-Wave QA) promises to solve this QP problem more efficiently than a conventional computer. However, the D-Wave QA cannot solve directly the SVM due to its very few input qubits. Hence, we use a coreset ("core of a dataset") of given EO data for training an SVM on this small D-Wave QA. The coreset is a small, representative weighted subset of an original dataset, and any training models generate competitive classes by using the coreset in contrast to by using its original dataset. We measured the closeness between an original dataset and its coreset by employing a Kullback-Leibler (KL) divergence measure. Moreover, we trained the SVM on the coreset data by using both a D-Wave QA and a conventional method. We conclude that the coreset characterizes the original dataset with very small KL divergence measure. In addition, we present our KL divergence results for demonstrating the closeness between our original data and its coreset. As practical RS data, we use Hyperspectral Image (HSI) of Indian Pine, USA.

</p>
</details>

<details><summary><b>Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architecture Search</b>
<a href="https://arxiv.org/abs/2204.04681">arxiv:2204.04681</a>
&#x1F4C8; 2 <br>
<p>Chao Li, Jia Ning, Han Hu, Kun He</p></summary>
<p>

**Abstract:** Differentiable architecture search (DARTS) has attracted much attention due to its simplicity and significant improvement in efficiency. However, the excessive accumulation of the skip connection makes it suffer from long-term weak stability and low robustness. Many works attempt to restrict the accumulation of skip connections by indicators or manual design, however, these methods are susceptible to thresholds and human priors. In this work, we suggest a more subtle and direct approach that removes skip connections from the operation space. Then, by introducing an adaptive channel allocation strategy, we redesign the DARTS framework to automatically refill the skip connections in the evaluation stage, resolving the performance degradation caused by the absence of skip connections. Our method, dubbed Adaptive-Channel-Allocation-DARTS (ACA-DRATS), could eliminate the inconsistency in operation strength and significantly expand the architecture diversity. We continue to explore smaller search space under our framework, and offer a direct search on the entire ImageNet dataset. Experiments show that ACA-DRATS improves the search stability and significantly speeds up DARTS by more than ten times while yielding higher accuracy.

</p>
</details>

<details><summary><b>Is my Driver Observation Model Overconfident? Input-guided Calibration Networks for Reliable and Interpretable Confidence Estimates</b>
<a href="https://arxiv.org/abs/2204.04674">arxiv:2204.04674</a>
&#x1F4C8; 2 <br>
<p>Alina Roitberg, Kunyu Peng, David Schneider, Kailun Yang, Marios Koulakis, Manuel Martinez, Rainer Stiefelhagen</p></summary>
<p>

**Abstract:** Driver observation models are rarely deployed under perfect conditions. In practice, illumination, camera placement and type differ from the ones present during training and unforeseen behaviours may occur at any time. While observing the human behind the steering wheel leads to more intuitive human-vehicle-interaction and safer driving, it requires recognition algorithms which do not only predict the correct driver state, but also determine their prediction quality through realistic and interpretable confidence measures. Reliable uncertainty estimates are crucial for building trust and are a serious obstacle for deploying activity recognition networks in real driving systems. In this work, we for the first time examine how well the confidence values of modern driver observation models indeed match the probability of the correct outcome and show that raw neural network-based approaches tend to significantly overestimate their prediction quality. To correct this misalignment between the confidence values and the actual uncertainty, we consider two strategies. First, we enhance two activity recognition models often used for driver observation with temperature scaling-an off-the-shelf method for confidence calibration in image classification. Then, we introduce Calibrated Action Recognition with Input Guidance (CARING)-a novel approach leveraging an additional neural network to learn scaling the confidences depending on the video representation. Extensive experiments on the Drive&Act dataset demonstrate that both strategies drastically improve the quality of model confidences, while our CARING model out-performs both, the original architectures and their temperature scaling enhancement, leading to best uncertainty estimates.

</p>
</details>

<details><summary><b>Effective Out-of-Distribution Detection in Classifier Based on PEDCC-Loss</b>
<a href="https://arxiv.org/abs/2204.04665">arxiv:2204.04665</a>
&#x1F4C8; 2 <br>
<p>Qiuyu Zhu, Guohui Zheng, Yingying Yan</p></summary>
<p>

**Abstract:** Deep neural networks suffer from the overconfidence issue in the open world, meaning that classifiers could yield confident, incorrect predictions for out-of-distribution (OOD) samples. Thus, it is an urgent and challenging task to detect these samples drawn far away from training distribution based on the security considerations of artificial intelligence. Many current methods based on neural networks mainly rely on complex processing strategies, such as temperature scaling and input preprocessing, to obtain satisfactory results. In this paper, we propose an effective algorithm for detecting out-of-distribution examples utilizing PEDCC-Loss. We mathematically analyze the nature of the confidence score output by the PEDCC (Predefined Evenly-Distribution Class Centroids) classifier, and then construct a more effective scoring function to distinguish in-distribution (ID) and out-of-distribution. In this method, there is no need to preprocess the input samples and the computational burden of the algorithm is reduced. Experiments demonstrate that our method can achieve better OOD detection performance.

</p>
</details>

<details><summary><b>FOSTER: Feature Boosting and Compression for Class-Incremental Learning</b>
<a href="https://arxiv.org/abs/2204.04662">arxiv:2204.04662</a>
&#x1F4C8; 2 <br>
<p>Fu-Yun Wang, Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan</p></summary>
<p>

**Abstract:** The ability to learn new concepts continually is necessary in this ever-changing world. However, deep neural networks suffer from catastrophic forgetting when learning new categories. Many works have been proposed to alleviate this phenomenon, whereas most of them either fall into the stability-plasticity dilemma or take too much computation or storage overhead. Inspired by the gradient boosting algorithm to gradually fit the residuals between the target and the current approximation function, we propose a novel two-stage learning paradigm FOSTER, empowering the model to learn new categories adaptively. Specifically, we first dynamically expand new modules to fit the residuals of the target and the original model. Next, we remove redundant parameters and feature dimensions through an effective distillation strategy to maintain the single backbone model. We validate our method FOSTER on CIFAR-100, ImageNet-100/1000 under different settings. Experimental results show that our method achieves state-of-the-art performance.

</p>
</details>

<details><summary><b>Gaussian Processes for Missing Value Imputation</b>
<a href="https://arxiv.org/abs/2204.04648">arxiv:2204.04648</a>
&#x1F4C8; 2 <br>
<p>Bahram Jafrasteh, Daniel Hernández-Lobato, Simón Pedro Lubián-López, Isabel Benavente-Fernández</p></summary>
<p>

**Abstract:** Missing values are common in many real-life datasets. However, most of the current machine learning methods can not handle missing values. This means that they should be imputed beforehand. Gaussian Processes (GPs) are non-parametric models with accurate uncertainty estimates that combined with sparse approximations and stochastic variational inference scale to large data sets. Sparse GPs can be used to compute a predictive distribution for missing data. Here, we present a hierarchical composition of sparse GPs that is used to predict missing values at each dimension using all the variables from the other dimensions. We call the approach missing GP (MGP). MGP can be trained simultaneously to impute all observed missing values. Specifically, it outputs a predictive distribution for each missing value that is then used in the imputation of other missing values. We evaluate MGP in one private clinical data set and four UCI datasets with a different percentage of missing values. We compare the performance of MGP with other state-of-the-art methods for imputing missing values, including variants based on sparse GPs and deep GPs. The results obtained show a significantly better performance of MGP.

</p>
</details>

<details><summary><b>Confidence Estimation Transformer for Long-term Renewable Energy Forecasting in Reinforcement Learning-based Power Grid Dispatching</b>
<a href="https://arxiv.org/abs/2204.04612">arxiv:2204.04612</a>
&#x1F4C8; 2 <br>
<p>Xinhang Li, Zihao Li, Nan Yang, Zheng Yuan, Qinwen Wang, Yiying Yang, Yupeng Huang, Xuri Song, Lei Li, Lin Zhang</p></summary>
<p>

**Abstract:** The expansion of renewable energy could help realizing the goals of peaking carbon dioxide emissions and carbon neutralization. Some existing grid dispatching methods integrating short-term renewable energy prediction and reinforcement learning (RL) have been proved to alleviate the adverse impact of energy fluctuations risk. However, these methods omit the long-term output prediction, which leads to stability and security problems on the optimal power flow. This paper proposes a confidence estimation Transformer for long-term renewable energy forecasting in reinforcement learning-based power grid dispatching (Conformer-RLpatching). Conformer-RLpatching predicts long-term active output of each renewable energy generator with an enhanced Transformer to boost the performance of hybrid energy grid dispatching. Furthermore, a confidence estimation method is proposed to reduce the prediction error of renewable energy. Meanwhile, a dispatching necessity evaluation mechanism is put forward to decide whether the active output of a generator needs to be adjusted. Experiments carried out on the SG-126 power grid simulator show that Conformer-RLpatching achieves great improvement over the second best algorithm DDPG in security score by 25.8% and achieves a better total reward compared with the golden medal team in the power grid dispatching competition sponsored by State Grid Corporation of China under the same simulation environment. Codes are outsourced in https://github.com/buptlxh/Conformer-RLpatching.

</p>
</details>

<details><summary><b>Self-Supervised Video Representation Learning with Motion-Contrastive Perception</b>
<a href="https://arxiv.org/abs/2204.04607">arxiv:2204.04607</a>
&#x1F4C8; 2 <br>
<p>Jinyu Liu, Ying Cheng, Yuejie Zhang, Rui-Wei Zhao, Rui Feng</p></summary>
<p>

**Abstract:** Visual-only self-supervised learning has achieved significant improvement in video representation learning. Existing related methods encourage models to learn video representations by utilizing contrastive learning or designing specific pretext tasks. However, some models are likely to focus on the background, which is unimportant for learning video representations. To alleviate this problem, we propose a new view called long-range residual frame to obtain more motion-specific information. Based on this, we propose the Motion-Contrastive Perception Network (MCPNet), which consists of two branches, namely, Motion Information Perception (MIP) and Contrastive Instance Perception (CIP), to learn generic video representations by focusing on the changing areas in videos. Specifically, the MIP branch aims to learn fine-grained motion features, and the CIP branch performs contrastive learning to learn overall semantics information for each instance. Experiments on two benchmark datasets UCF-101 and HMDB-51 show that our method outperforms current state-of-the-art visual-only self-supervised approaches.

</p>
</details>

<details><summary><b>BABD: A Bitcoin Address Behavior Dataset for Address Behavior Pattern Analysis</b>
<a href="https://arxiv.org/abs/2204.05746">arxiv:2204.05746</a>
&#x1F4C8; 1 <br>
<p>Yuexin Xiang, Wei Ren, Hang Gao, Ding Bao, Yuchen Lei, Tiantian Li, Qingqing Yang, Wenmao Liu, Tianqing Zhu, Kim-Kwang Raymond Choo</p></summary>
<p>

**Abstract:** Cryptocurrencies are no longer just the preferred option for cybercriminal activities on darknets, due to the increasing adoption in mainstream applications. This is partly due to the transparency associated with the underpinning ledgers, where any individual can access the record of a transaction record on the public ledger. In this paper, we build a dataset comprising Bitcoin transactions between 12 July 2019 and 26 May 2021. This dataset (hereafter referred to as BABD-13) contains 13 types of Bitcoin addresses, 5 categories of indicators with 148 features, and 544,462 labeled data. We then use our proposed dataset on common machine learning models, namely: k-nearest neighbors algorithm, decision tree, random forest, multilayer perceptron, and XGBoost. The results show that the accuracy rates of these machine learning models on our proposed dataset are between 93.24% and 96.71%. We also analyze the proposed features and their relationships from the experiments, and propose a k-hop subgraph generation algorithm to extract a k-hop subgraph from the entire Bitcoin transaction graph constructed by the directed heterogeneous multigraph starting from a specific Bitcoin address node (e.g., a known transaction associated with a criminal investigation).

</p>
</details>

<details><summary><b>Autonomous Mobile Clinics: Empowering Affordable Anywhere Anytime Healthcare Access</b>
<a href="https://arxiv.org/abs/2204.04841">arxiv:2204.04841</a>
&#x1F4C8; 1 <br>
<p>Shaoshan Liu, Yuzhang Huang, Leiyu Shi</p></summary>
<p>

**Abstract:** We are facing a global healthcare crisis today as the healthcare cost is ever climbing, but with the aging population, government fiscal revenue is ever dropping. To create a more efficient and effective healthcare system, three technical challenges immediately present themselves: healthcare access, healthcare equity, and healthcare efficiency. An autonomous mobile clinic solves the healthcare access problem by bringing healthcare services to the patient by the order of the patient's fingertips. Nevertheless, to enable a universal autonomous mobile clinic network, a three-stage technical roadmap needs to be achieved: In stage one, we focus on solving the inequity challenge in the existing healthcare system by combining autonomous mobility and telemedicine. In stage two, we develop an AI doctor for primary care, which we foster from infancy to adulthood with clean healthcare data. With the AI doctor, we can solve the inefficiency problem. In stage three, after we have proven that the autonomous mobile clinic network can truly solve the target clinical use cases, we shall open up the platform for all medical verticals, thus enabling universal healthcare through this whole new system.

</p>
</details>

<details><summary><b>Effective Mutation Rate Adaptation through Group Elite Selection</b>
<a href="https://arxiv.org/abs/2204.04817">arxiv:2204.04817</a>
&#x1F4C8; 1 <br>
<p>Akarsh Kumar, Bo Liu, Risto Miikkulainen, Peter Stone</p></summary>
<p>

**Abstract:** Evolutionary algorithms are sensitive to the mutation rate (MR); no single value of this parameter works well across domains. Self-adaptive MR approaches have been proposed but they tend to be brittle: Sometimes they decay the MR to zero, thus halting evolution. To make self-adaptive MR robust, this paper introduces the Group Elite Selection of Mutation Rates (GESMR) algorithm. GESMR co-evolves a population of solutions and a population of MRs, such that each MR is assigned to a group of solutions. The resulting best mutational change in the group, instead of average mutational change, is used for MR selection during evolution, thus avoiding the vanishing MR problem. With the same number of function evaluations and with almost no overhead, GESMR converges faster and to better solutions than previous approaches on a wide range of continuous test optimization problems. GESMR also scales well to high-dimensional neuroevolution for supervised image-classification tasks and for reinforcement learning control tasks. Remarkably, GESMR produces MRs that are optimal in the long-term, as demonstrated through a comprehensive look-ahead grid search. Thus, GESMR and its theoretical and empirical analysis demonstrate how self-adaptation can be harnessed to improve performance in several applications of evolutionary computation.

</p>
</details>

<details><summary><b>Driving black-box quantum thermal machines with optimal power/efficiency trade-offs using reinforcement learning</b>
<a href="https://arxiv.org/abs/2204.04785">arxiv:2204.04785</a>
&#x1F4C8; 1 <br>
<p>Paolo Andrea Erdman, Frank Noé</p></summary>
<p>

**Abstract:** The optimal control of non-equilibrium open quantum systems is a challenging task but has a key role in improving existing quantum information processing technologies. We introduce a general model-free framework based on Reinforcement Learning to identify out-of-equilibrium thermodynamic cycles that are Pareto optimal trade-offs between power and efficiency for quantum heat engines and refrigerators. The method does not require any knowledge of the quantum thermal machine, nor of the system model, nor of the quantum state. Instead, it only observes the heat fluxes, so it is both applicable to simulations and experimental devices. We test our method identifying Pareto-optimal trade-offs between power and efficiency in two systems: an experimentally realistic refrigerator based on a superconducting qubit, where we identify non-intuitive control sequences that reduce quantum friction and outperform previous cycles proposed in literature; and a heat engine based on a quantum harmonic oscillator, where we find cycles with an elaborate structure that outperform the optimized Otto cycle.

</p>
</details>

<details><summary><b>Analysis of Power-Oriented Fault Injection Attacks on Spiking Neural Networks</b>
<a href="https://arxiv.org/abs/2204.04768">arxiv:2204.04768</a>
&#x1F4C8; 1 <br>
<p>Karthikeyan Nagarajan, Junde Li, Sina Sayyah Ensan, Mohammad Nasim Imtiaz Khan, Sachhidh Kannan, Swaroop Ghosh</p></summary>
<p>

**Abstract:** Spiking Neural Networks (SNN) are quickly gaining traction as a viable alternative to Deep Neural Networks (DNN). In comparison to DNNs, SNNs are more computationally powerful and provide superior energy efficiency. SNNs, while exciting at first appearance, contain security-sensitive assets (e.g., neuron threshold voltage) and vulnerabilities (e.g., sensitivity of classification accuracy to neuron threshold voltage change) that adversaries can exploit. We investigate global fault injection attacks by employing external power supplies and laser-induced local power glitches to corrupt crucial training parameters such as spike amplitude and neuron's membrane threshold potential on SNNs developed using common analog neurons. We also evaluate the impact of power-based attacks on individual SNN layers for 0% (i.e., no attack) to 100% (i.e., whole layer under attack). We investigate the impact of the attacks on digit classification tasks and find that in the worst-case scenario, classification accuracy is reduced by 85.65%. We also propose defenses e.g., a robust current driver design that is immune to power-oriented attacks, improved circuit sizing of neuron components to reduce/recover the adversarial accuracy degradation at the cost of negligible area and 25% power overhead. We also present a dummy neuron-based voltage fault injection detection system with 1% power and area overhead.

</p>
</details>

<details><summary><b>Configuration and Collection Factors for Side-Channel Disassembly</b>
<a href="https://arxiv.org/abs/2204.04766">arxiv:2204.04766</a>
&#x1F4C8; 1 <br>
<p>Random Gwinn, Mark Matties, Aviel D. Rubin</p></summary>
<p>

**Abstract:** Myriad uses, methodologies, and channels have been explored for side-channel analysis. However, specific implementation considerations are often unpublished. This paper explores select test configuration and collection parameters, such as input voltage, shunt resistance, sample rate, and microcontroller clock frequency, along with their impact on side-channel analysis performance. The analysis use case considered is instruction disassembly and classification using the microcontroller power side-channel. An ATmega328P microcontroller and a subset of the AVR instruction set are used in the experiments as the Device Under Test (DUT). A time-series convolutional neural network (CNN) is used to evaluate classification performance at clock-cycle fidelity. We conclude that configuration and collection parameters have a meaningful impact on performance, especially where the instruction-trace's signal to noise ratio (SNR) is impacted. Additionally, data collection and analysis well above the Nyquist rate is required for side-channel disassembly. We also found that 7V input voltage with 1 kiloohm shunt and a sample rate of 250-500 MSa/s provided optimal performance in our application, with diminishing returns or in some cases degradation at higher levels.

</p>
</details>

<details><summary><b>Rockafellian Relaxation in Optimization under Uncertainty: Asymptotically Exact Formulations</b>
<a href="https://arxiv.org/abs/2204.04762">arxiv:2204.04762</a>
&#x1F4C8; 1 <br>
<p>Louis L. Chen, Johannes O. Royset</p></summary>
<p>

**Abstract:** In practice, optimization models are often prone to unavoidable inaccuracies due to lack of data and dubious assumptions. Traditionally, this placed special emphasis on risk-based and robust formulations, and their focus on "conservative" decisions. We develop, in contrast, an "optimistic" framework based on Rockafellian relaxations in which optimization is conducted not only over the original decision space but also jointly with a choice of model perturbation. The framework enables us to address challenging problems with ambiguous probability distributions from the areas of two-stage stochastic optimization without relatively complete recourse, probability functions lacking continuity properties, expectation constraints, and outlier analysis. We are also able to circumvent the fundamental difficulty in stochastic optimization that convergence of distributions fails to guarantee convergence of expectations. The framework centers on the novel concepts of exact and asymptotically exact Rockafellians, with interpretations of "negative" regularization emerging in certain settings. We illustrate the role of Phi-divergence, examine rates of convergence under changing distributions, and explore extensions to first-order optimality conditions. The main development is free of assumptions about convexity, smoothness, and even continuity of objective functions.

</p>
</details>

<details><summary><b>Regret Analysis of Online Gradient Descent-based Iterative Learning Control with Model Mismatch</b>
<a href="https://arxiv.org/abs/2204.04722">arxiv:2204.04722</a>
&#x1F4C8; 1 <br>
<p>Efe C. Balta, Andrea Iannelli, Roy S. Smith, John Lygeros</p></summary>
<p>

**Abstract:** In Iterative Learning Control (ILC), a sequence of feedforward control actions is generated at each iteration on the basis of partial model knowledge and past measurements with the goal of steering the system toward a desired reference trajectory. This is framed here as an online learning task, where the decision-maker takes sequential decisions by solving a sequence of optimization problems having only partial knowledge of the cost functions. Having established this connection, the performance of an online gradient-descent based scheme using inexact gradient information is analyzed in the setting of dynamic and static regret, standard measures in online learning. Fundamental limitations of the scheme and its integration with adaptation mechanisms are further investigated, followed by numerical simulations on a benchmark ILC problem.

</p>
</details>

<details><summary><b>Spectral Unmixing of Hyperspectral Images Based on Block Sparse Structure</b>
<a href="https://arxiv.org/abs/2204.04638">arxiv:2204.04638</a>
&#x1F4C8; 1 <br>
<p>Seyed Hossein Mosavi Azarang, Roozbeh Rajabi, Hadi Zayyani, Amin Zehtabian</p></summary>
<p>

**Abstract:** Spectral unmixing (SU) of hyperspectral images (HSIs) is one of the important areas in remote sensing (RS) that needs to be carefully addressed in different RS applications. Despite the high spectral resolution of the hyperspectral data, the relatively low spatial resolution of the sensors may lead to mixture of different pure materials within the image pixels. In this case, the spectrum of a given pixel recorded by the sensor can be a combination of multiple spectra each belonging to a unique material in that pixel. Spectral unmixing is then used as a technique to extract the spectral characteristics of the different materials within the mixed pixels and to recover the spectrum of each pure spectral signature, called endmember. Block-sparsity exists in hyperspectral images as a result of spectral similarity between neighboring pixels. In block-sparse signals, the nonzero samples occur in clusters and the pattern of the clusters is often supposed to be unavailable as prior information. This paper presents an innovative spectral unmixing approach for HSIs based on block-sparse structure and sparse Bayesian learning (SBL) strategy. To evaluate the performance of the proposed SU algorithm, it is tested on both synthetic and real hyperspectral data and the quantitative results are compared to those of other state-of-the-art methods in terms of abundance angel distance (AAD) and mean square error (MSE). The achieved results show the superiority of the proposed algorithm over the other competing methods by a significant margin.

</p>
</details>

<details><summary><b>Improved Approximations for Euclidean $k$-means and $k$-median, via Nested Quasi-Independent Sets</b>
<a href="https://arxiv.org/abs/2204.04828">arxiv:2204.04828</a>
&#x1F4C8; 0 <br>
<p>Vincent Cohen-Addad, Hossein Esfandiari, Vahab Mirrokni, Shyam Narayanan</p></summary>
<p>

**Abstract:** Motivated by data analysis and machine learning applications, we consider the popular high-dimensional Euclidean $k$-median and $k$-means problems. We propose a new primal-dual algorithm, inspired by the classic algorithm of Jain and Vazirani and the recent algorithm of Ahmadian, Norouzi-Fard, Svensson, and Ward. Our algorithm achieves an approximation ratio of $2.406$ and $5.912$ for Euclidean $k$-median and $k$-means, respectively, improving upon the 2.633 approximation ratio of Ahmadian et al. and the 6.1291 approximation ratio of Grandoni, Ostrovsky, Rabani, Schulman, and Venkat.
  Our techniques involve a much stronger exploitation of the Euclidean metric than previous work on Euclidean clustering. In addition, we introduce a new method of removing excess centers using a variant of independent sets over graphs that we dub a "nested quasi-independent set". In turn, this technique may be of interest for other optimization problems in Euclidean and $\ell_p$ metric spaces.

</p>
</details>


{% endraw %}
Prev: [2022.04.09]({{ '/2022/04/09/2022.04.09.html' | relative_url }})  Next: [2022.04.11]({{ '/2022/04/11/2022.04.11.html' | relative_url }})