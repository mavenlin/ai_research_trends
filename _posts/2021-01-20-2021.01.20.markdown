Prev: [2021.01.19]({{ '/2021/01/19/2021.01.19.html' | relative_url }})  Next: [2021.01.21]({{ '/2021/01/21/2021.01.21.html' | relative_url }})
{% raw %}
## Summary for 2021-01-20, created on 2021-12-24


<details><summary><b>UPDeT: Universal Multi-agent Reinforcement Learning via Policy Decoupling with Transformers</b>
<a href="https://arxiv.org/abs/2101.08001">arxiv:2101.08001</a>
&#x1F4C8; 21 <br>
<p>Siyi Hu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang</p></summary>
<p>

**Abstract:** Recent advances in multi-agent reinforcement learning have been largely limited in training one model from scratch for every new task. The limitation is due to the restricted model architecture related to fixed input and output dimensions. This hinders the experience accumulation and transfer of the learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs 6 multi-agent games). In this paper, we make the first attempt to explore a universal multi-agent reinforcement learning pipeline, designing one single architecture to fit tasks with the requirement of different observation and action configurations. Unlike previous RNN-based models, we utilize a transformer-based model to generate a flexible policy by decoupling the policy distribution from the intertwined input observation with an importance weight measured by the merits of the self-attention mechanism. Compared to a standard transformer block, the proposed model, named as Universal Policy Decoupling Transformer (UPDeT), further relaxes the action restriction and makes the multi-agent task's decision process more explainable. UPDeT is general enough to be plugged into any multi-agent reinforcement learning pipeline and equip them with strong generalization abilities that enables the handling of multiple tasks at a time. Extensive experiments on large-scale SMAC multi-agent competitive games demonstrate that the proposed UPDeT-based multi-agent reinforcement learning achieves significant results relative to state-of-the-art approaches, demonstrating advantageous transfer capability in terms of both performance and training speed (10 times faster).

</p>
</details>

<details><summary><b>Analysis of Information Flow Through U-Nets</b>
<a href="https://arxiv.org/abs/2101.08427">arxiv:2101.08427</a>
&#x1F4C8; 17 <br>
<p>Suemin Lee, Ivan V. Bajić</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) have become ubiquitous in medical image processing and analysis. Among them, U-Nets are very popular in various image segmentation tasks. Yet, little is known about how information flows through these networks and whether they are indeed properly designed for the tasks they are being proposed for. In this paper, we employ information-theoretic tools in order to gain insight into information flow through U-Nets. In particular, we show how mutual information between input/output and an intermediate layer can be a useful tool to understand information flow through various portions of a U-Net, assess its architectural efficiency, and even propose more efficient designs.

</p>
</details>

<details><summary><b>Influence Estimation for Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2101.08367">arxiv:2101.08367</a>
&#x1F4C8; 12 <br>
<p>Naoyuki Terashita, Hiroki Ohashi, Yuichi Nonaka, Takashi Kanemaru</p></summary>
<p>

**Abstract:** Identifying harmful instances, whose absence in a training dataset improves model performance, is important for building better machine learning models. Although previous studies have succeeded in estimating harmful instances under supervised settings, they cannot be trivially extended to generative adversarial networks (GANs). This is because previous approaches require that (1) the absence of a training instance directly affects the loss value and that (2) the change in the loss directly measures the harmfulness of the instance for the performance of a model. In GAN training, however, neither of the requirements is satisfied. This is because, (1) the generator's loss is not directly affected by the training instances as they are not part of the generator's training steps, and (2) the values of GAN's losses normally do not capture the generative performance of a model. To this end, (1) we propose an influence estimation method that uses the Jacobian of the gradient of the generator's loss with respect to the discriminator's parameters (and vice versa) to trace how the absence of an instance in the discriminator's training affects the generator's parameters, and (2) we propose a novel evaluation scheme, in which we assess harmfulness of each training instance on the basis of how GAN evaluation metric (e.g., inception score) is expect to change due to the removal of the instance. We experimentally verified that our influence estimation method correctly inferred the changes in GAN evaluation metrics. Further, we demonstrated that the removal of the identified harmful instances effectively improved the model's generative performance with respect to various GAN evaluation metrics.

</p>
</details>

<details><summary><b>Generative Zero-shot Network Quantization</b>
<a href="https://arxiv.org/abs/2101.08430">arxiv:2101.08430</a>
&#x1F4C8; 9 <br>
<p>Xiangyu He, Qinghao Hu, Peisong Wang, Jian Cheng</p></summary>
<p>

**Abstract:** Convolutional neural networks are able to learn realistic image priors from numerous training samples in low-level image generation and restoration. We show that, for high-level image recognition tasks, we can further reconstruct "realistic" images of each category by leveraging intrinsic Batch Normalization (BN) statistics without any training data. Inspired by the popular VAE/GAN methods, we regard the zero-shot optimization process of synthetic images as generative modeling to match the distribution of BN statistics. The generated images serve as a calibration set for the following zero-shot network quantizations. Our method meets the needs for quantizing models based on sensitive information, \textit{e.g.,} due to privacy concerns, no data is available. Extensive experiments on benchmark datasets show that, with the help of generated data, our approach consistently outperforms existing data-free quantization methods.

</p>
</details>

<details><summary><b>SUGAR: Subgraph Neural Network with Reinforcement Pooling and Self-Supervised Mutual Information Mechanism</b>
<a href="https://arxiv.org/abs/2101.08170">arxiv:2101.08170</a>
&#x1F4C8; 9 <br>
<p>Qingyun Sun, Jianxin Li, Hao Peng, Jia Wu, Yuanxing Ning, Phillip S. Yu, Lifang He</p></summary>
<p>

**Abstract:** Graph representation learning has attracted increasing research attention. However, most existing studies fuse all structural features and node attributes to provide an overarching view of graphs, neglecting finer substructures' semantics, and suffering from interpretation enigmas. This paper presents a novel hierarchical subgraph-level selection and embedding based graph neural network for graph classification, namely SUGAR, to learn more discriminative subgraph representations and respond in an explanatory way. SUGAR reconstructs a sketched graph by extracting striking subgraphs as the representative part of the original graph to reveal subgraph-level patterns. To adaptively select striking subgraphs without prior knowledge, we develop a reinforcement pooling mechanism, which improves the generalization ability of the model. To differentiate subgraph representations among graphs, we present a self-supervised mutual information mechanism to encourage subgraph embedding to be mindful of the global graph structural properties by maximizing their mutual information. Extensive experiments on six typical bioinformatics datasets demonstrate a significant and consistent improvement in model quality with competitive performance and interpretability.

</p>
</details>

<details><summary><b>Zero-Cost Proxies for Lightweight NAS</b>
<a href="https://arxiv.org/abs/2101.08134">arxiv:2101.08134</a>
&#x1F4C8; 9 <br>
<p>Mohamed S. Abdelfattah, Abhinav Mehrotra, Łukasz Dudziak, Nicholas D. Lane</p></summary>
<p>

**Abstract:** Neural Architecture Search (NAS) is quickly becoming the standard methodology to design neural network models. However, NAS is typically compute-intensive because multiple models need to be evaluated before choosing the best one. To reduce the computational power and time needed, a proxy task is often used for evaluating each model instead of full training. In this paper, we evaluate conventional reduced-training proxies and quantify how well they preserve ranking between multiple models during search when compared with the rankings produced by final trained accuracy. We propose a series of zero-cost proxies, based on recent pruning literature, that use just a single minibatch of training data to compute a model's score. Our zero-cost proxies use 3 orders of magnitude less computation but can match and even outperform conventional proxies. For example, Spearman's rank correlation coefficient between final validation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82, compared to 0.61 for EcoNAS (a recently proposed reduced-training proxy). Finally, we use these zero-cost proxies to enhance existing NAS search algorithms such as random search, reinforcement learning, evolutionary search and predictor-based search. For all search methodologies and across three different NAS datasets, we are able to significantly improve sample efficiency, and thereby decrease computation, by using our zero-cost proxies. For example on NAS-Bench-101, we achieved the same accuracy 4$\times$ quicker than the best previous result. Our code is made public at: https://github.com/mohsaied/zero-cost-nas.

</p>
</details>

<details><summary><b>Aesthetics, Personalization and Recommendation: A survey on Deep Learning in Fashion</b>
<a href="https://arxiv.org/abs/2101.08301">arxiv:2101.08301</a>
&#x1F4C8; 8 <br>
<p>Wei Gong, Laila Khalid</p></summary>
<p>

**Abstract:** Machine learning is completely changing the trends in the fashion industry. From big to small every brand is using machine learning techniques in order to improve their revenue, increase customers and stay ahead of the trend. People are into fashion and they want to know what looks best and how they can improve their style and elevate their personality. Using Deep learning technology and infusing it with Computer Vision techniques one can do so by utilizing Brain-inspired Deep Networks, and engaging into Neuroaesthetics, working with GANs and Training them, playing around with Unstructured Data,and infusing the transformer architecture are just some highlights which can be touched with the Fashion domain. Its all about designing a system that can tell us information regarding the fashion aspect that can come in handy with the ever growing demand. Personalization is a big factor that impacts the spending choices of customers.The survey also shows remarkable approaches that encroach the subject of achieving that by divulging deep into how visual data can be interpreted and leveraged into different models and approaches. Aesthetics play a vital role in clothing recommendation as users' decision depends largely on whether the clothing is in line with their aesthetics, however the conventional image features cannot portray this directly. For that the survey also highlights remarkable models like tensor factorization model, conditional random field model among others to cater the need to acknowledge aesthetics as an important factor in Apparel recommendation.These AI inspired deep models can pinpoint exactly which certain style resonates best with their customers and they can have an understanding of how the new designs will set in with the community. With AI and machine learning your businesses can stay ahead of the fashion trends.

</p>
</details>

<details><summary><b>Adversarial Attacks for Tabular Data: Application to Fraud Detection and Imbalanced Data</b>
<a href="https://arxiv.org/abs/2101.08030">arxiv:2101.08030</a>
&#x1F4C8; 8 <br>
<p>Francesco Cartella, Orlando Anunciacao, Yuki Funabiki, Daisuke Yamaguchi, Toru Akishita, Olivier Elshocht</p></summary>
<p>

**Abstract:** Guaranteeing the security of transactional systems is a crucial priority of all institutions that process transactions, in order to protect their businesses against cyberattacks and fraudulent attempts. Adversarial attacks are novel techniques that, other than being proven to be effective to fool image classification models, can also be applied to tabular data. Adversarial attacks aim at producing adversarial examples, in other words, slightly modified inputs that induce the Artificial Intelligence (AI) system to return incorrect outputs that are advantageous for the attacker. In this paper we illustrate a novel approach to modify and adapt state-of-the-art algorithms to imbalanced tabular data, in the context of fraud detection. Experimental results show that the proposed modifications lead to a perfect attack success rate, obtaining adversarial examples that are also less perceptible when analyzed by humans. Moreover, when applied to a real-world production system, the proposed techniques shows the possibility of posing a serious threat to the robustness of advanced AI-based fraud detection procedures.

</p>
</details>

<details><summary><b>Dive into Decision Trees and Forests: A Theoretical Demonstration</b>
<a href="https://arxiv.org/abs/2101.08656">arxiv:2101.08656</a>
&#x1F4C8; 7 <br>
<p>Jinxiong Zhang</p></summary>
<p>

**Abstract:** Based on decision trees, many fields have arguably made tremendous progress in recent years. In simple words, decision trees use the strategy of "divide-and-conquer" to divide the complex problem on the dependency between input features and labels into smaller ones. While decision trees have a long history, recent advances have greatly improved their performance in computational advertising, recommender system, information retrieval, etc. We introduce common tree-based models (e.g., Bayesian CART, Bayesian regression splines) and training techniques (e.g., mixed integer programming, alternating optimization, gradient descent). Along the way, we highlight probabilistic characteristics of tree-based models and explain their practical and theoretical benefits. Except machine learning and data mining, we try to show theoretical advances on tree-based models from other fields such as statistics and operation research. We list the reproducible resource at the end of each method.

</p>
</details>

<details><summary><b>Enhancing Generative Models via Quantum Correlations</b>
<a href="https://arxiv.org/abs/2101.08354">arxiv:2101.08354</a>
&#x1F4C8; 7 <br>
<p>Xun Gao, Eric R. Anschuetz, Sheng-Tao Wang, J. Ignacio Cirac, Mikhail D. Lukin</p></summary>
<p>

**Abstract:** Generative modeling using samples drawn from the probability distribution constitutes a powerful approach for unsupervised machine learning. Quantum mechanical systems can produce probability distributions that exhibit quantum correlations which are difficult to capture using classical models. We show theoretically that such quantum correlations provide a powerful resource for generative modeling. In particular, we provide an unconditional proof of separation in expressive power between a class of widely-used generative models, known as Bayesian networks, and its minimal quantum extension. We show that this expressivity advantage is associated with quantum nonlocality and quantum contextuality. Furthermore, we numerically test this separation on standard machine learning data sets and show that it holds for practical problems. The possibility of quantum advantage demonstrated in this work not only sheds light on the design of useful quantum machine learning protocols but also provides inspiration to draw on ideas from quantum foundations to improve purely classical algorithms.

</p>
</details>

<details><summary><b>Text Line Segmentation for Challenging Handwritten Document Images Using Fully Convolutional Network</b>
<a href="https://arxiv.org/abs/2101.08299">arxiv:2101.08299</a>
&#x1F4C8; 7 <br>
<p>Berat Barakat, Ahmad Droby, Majeed Kassis, Jihad El-Sana</p></summary>
<p>

**Abstract:** This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.

</p>
</details>

<details><summary><b>Open-Domain Conversational Search Assistant with Transformers</b>
<a href="https://arxiv.org/abs/2101.08197">arxiv:2101.08197</a>
&#x1F4C8; 7 <br>
<p>Rafael Ferreira, Mariana Leite, David Semedo, Joao Magalhaes</p></summary>
<p>

**Abstract:** Open-domain conversational search assistants aim at answering user questions about open topics in a conversational manner. In this paper we show how the Transformer architecture achieves state-of-the-art results in key IR tasks, leveraging the creation of conversational assistants that engage in open-domain conversational search with single, yet informative, answers. In particular, we propose an open-domain abstractive conversational search agent pipeline to address two major challenges: first, conversation context-aware search and second, abstractive search-answers generation. To address the first challenge, the conversation context is modeled with a query rewriting method that unfolds the context of the conversation up to a specific moment to search for the correct answers. These answers are then passed to a Transformer-based re-ranker to further improve retrieval performance. The second challenge, is tackled with recent Abstractive Transformer architectures to generate a digest of the top most relevant passages. Experiments show that Transformers deliver a solid performance across all tasks in conversational search, outperforming the best TREC CAsT 2019 baseline.

</p>
</details>

<details><summary><b>Classifying Scientific Publications with BERT -- Is Self-Attention a Feature Selection Method?</b>
<a href="https://arxiv.org/abs/2101.08114">arxiv:2101.08114</a>
&#x1F4C8; 7 <br>
<p>Andres Garcia-Silva, Jose Manuel Gomez-Perez</p></summary>
<p>

**Abstract:** We investigate the self-attention mechanism of BERT in a fine-tuning scenario for the classification of scientific articles over a taxonomy of research disciplines. We observe how self-attention focuses on words that are highly related to the domain of the article. Particularly, a small subset of vocabulary words tends to receive most of the attention. We compare and evaluate the subset of the most attended words with feature selection methods normally used for text classification in order to characterize self-attention as a possible feature selection approach. Using ConceptNet as ground truth, we also find that attended words are more related to the research fields of the articles. However, conventional feature selection methods are still a better option to learn classifiers from scratch. This result suggests that, while self-attention identifies domain-relevant terms, the discriminatory information in BERT is encoded in the contextualized outputs and the classification layer. It also raises the question whether injecting feature selection methods in the self-attention mechanism could further optimize single sequence classification using transformers.

</p>
</details>

<details><summary><b>SplitSR: An End-to-End Approach to Super-Resolution on Mobile Devices</b>
<a href="https://arxiv.org/abs/2101.07996">arxiv:2101.07996</a>
&#x1F4C8; 7 <br>
<p>Xin Liu, Yuang Li, Josh Fromm, Yuntao Wang, Ziheng Jiang, Alex Mariakakis, Shwetak Patel</p></summary>
<p>

**Abstract:** Super-resolution (SR) is a coveted image processing technique for mobile apps ranging from the basic camera apps to mobile health. Existing SR algorithms rely on deep learning models with significant memory requirements, so they have yet to be deployed on mobile devices and instead operate in the cloud to achieve feasible inference time. This shortcoming prevents existing SR methods from being used in applications that require near real-time latency. In this work, we demonstrate state-of-the-art latency and accuracy for on-device super-resolution using a novel hybrid architecture called SplitSR and a novel lightweight residual block called SplitSRBlock. The SplitSRBlock supports channel-splitting, allowing the residual blocks to retain spatial information while reducing the computation in the channel dimension. SplitSR has a hybrid design consisting of standard convolutional blocks and lightweight residual blocks, allowing people to tune SplitSR for their computational budget. We evaluate our system on a low-end ARM CPU, demonstrating both higher accuracy and up to 5 times faster inference than previous approaches. We then deploy our model onto a smartphone in an app called ZoomSR to demonstrate the first-ever instance of on-device, deep learning-based SR. We conducted a user study with 15 participants to have them assess the perceived quality of images that were post-processed by SplitSR. Relative to bilinear interpolation -- the existing standard for on-device SR -- participants showed a statistically significant preference when looking at both images (Z=-9.270, p<0.01) and text (Z=-6.486, p<0.01).

</p>
</details>

<details><summary><b>Robust W-GAN-Based Estimation Under Wasserstein Contamination</b>
<a href="https://arxiv.org/abs/2101.07969">arxiv:2101.07969</a>
&#x1F4C8; 7 <br>
<p>Zheng Liu, Po-Ling Loh</p></summary>
<p>

**Abstract:** Robust estimation is an important problem in statistics which aims at providing a reasonable estimator when the data-generating distribution lies within an appropriately defined ball around an uncontaminated distribution. Although minimax rates of estimation have been established in recent years, many existing robust estimators with provably optimal convergence rates are also computationally intractable. In this paper, we study several estimation problems under a Wasserstein contamination model and present computationally tractable estimators motivated by generative adversarial networks (GANs). Specifically, we analyze properties of Wasserstein GAN-based estimators for location estimation, covariance matrix estimation, and linear regression and show that our proposed estimators are minimax optimal in many scenarios. Finally, we present numerical results which demonstrate the effectiveness of our estimators.

</p>
</details>

<details><summary><b>DynaComm: Accelerating Distributed CNN Training between Edges and Clouds through Dynamic Communication Scheduling</b>
<a href="https://arxiv.org/abs/2101.07968">arxiv:2101.07968</a>
&#x1F4C8; 7 <br>
<p>Shangming Cai, Dongsheng Wang, Haixia Wang, Yongqiang Lyu, Guangquan Xu, Xi Zheng, Athanasios V. Vasilakos</p></summary>
<p>

**Abstract:** To reduce uploading bandwidth and address privacy concerns, deep learning at the network edge has been an emerging topic. Typically, edge devices collaboratively train a shared model using real-time generated data through the Parameter Server framework. Although all the edge devices can share the computing workloads, the distributed training processes over edge networks are still time-consuming due to the parameters and gradients transmission procedures between parameter servers and edge devices. Focusing on accelerating distributed Convolutional Neural Networks (CNNs) training at the network edge, we present DynaComm, a novel scheduler that dynamically decomposes each transmission procedure into several segments to achieve optimal layer-wise communications and computations overlapping during run-time. Through experiments, we verify that DynaComm manages to achieve optimal layer-wise scheduling for all cases compared to competing strategies while the model accuracy remains untouched.

</p>
</details>

<details><summary><b>TDA-Net: Fusion of Persistent Homology and Deep Learning Features for COVID-19 Detection in Chest X-Ray Images</b>
<a href="https://arxiv.org/abs/2101.08398">arxiv:2101.08398</a>
&#x1F4C8; 6 <br>
<p>Mustafa Hajij, Ghada Zamzmi, Fawwaz Batayneh</p></summary>
<p>

**Abstract:** Topological Data Analysis (TDA) has emerged recently as a robust tool to extract and compare the structure of datasets. TDA identifies features in data such as connected components and holes and assigns a quantitative measure to these features. Several studies reported that topological features extracted by TDA tools provide unique information about the data, discover new insights, and determine which feature is more related to the outcome. On the other hand, the overwhelming success of deep neural networks in learning patterns and relationships has been proven on a vast array of data applications, images in particular. To capture the characteristics of both powerful tools, we propose \textit{TDA-Net}, a novel ensemble network that fuses topological and deep features for the purpose of enhancing model generalizability and accuracy. We apply the proposed \textit{TDA-Net} to a critical application, which is the automated detection of COVID-19 from CXR images. The experimental results showed that the proposed network achieved excellent performance and suggests the applicability of our method in practice.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning with Spatio-temporal Traffic Forecasting for Data-Driven Base Station Sleep Control</b>
<a href="https://arxiv.org/abs/2101.08391">arxiv:2101.08391</a>
&#x1F4C8; 6 <br>
<p>Qiong Wu, Xu Chen, Zhi Zhou, Liang Chen, Junshan Zhang</p></summary>
<p>

**Abstract:** To meet the ever increasing mobile traffic demand in 5G era, base stations (BSs) have been densely deployed in radio access networks (RANs) to increase the network coverage and capacity. However, as the high density of BSs is designed to accommodate peak traffic, it would consume an unnecessarily large amount of energy if BSs are on during off-peak time. To save the energy consumption of cellular networks, an effective way is to deactivate some idle base stations that do not serve any traffic demand. In this paper, we develop a traffic-aware dynamic BS sleep control framework, named DeepBSC, which presents a novel data-driven learning approach to determine the BS active/sleep modes while meeting lower energy consumption and satisfactory Quality of Service (QoS) requirements. Specifically, the traffic demands are predicted by the proposed GS-STN model, which leverages the geographical and semantic spatial-temporal correlations of mobile traffic. With accurate mobile traffic forecasting, the BS sleep control problem is cast as a Markov Decision Process that is solved by Actor-Critic reinforcement learning methods. To reduce the variance of cost estimation in the dynamic environment, we propose a benchmark transformation method that provides robust performance indicator for policy update. To expedite the training process, we adopt a Deep Deterministic Policy Gradient (DDPG) approach, together with an explorer network, which can strengthen the exploration further. Extensive experiments with a real-world dataset corroborate that our proposed framework significantly outperforms the existing methods.

</p>
</details>

<details><summary><b>Do we need to go Deep? Knowledge Tracing with Big Data</b>
<a href="https://arxiv.org/abs/2101.08349">arxiv:2101.08349</a>
&#x1F4C8; 6 <br>
<p>Varun Mandalapu, Jiaqi Gong, Lujie Chen</p></summary>
<p>

**Abstract:** Interactive Educational Systems (IES) enabled researchers to trace student knowledge in different skills and provide recommendations for a better learning path. To estimate the student knowledge and further predict their future performance, the interest in utilizing the student interaction data captured by IES to develop learner performance models is increasing rapidly. Moreover, with the advances in computing systems, the amount of data captured by these IES systems is also increasing that enables deep learning models to compete with traditional logistic models and Markov processes. However, it is still not empirically evident if these deep models outperform traditional models on the current scale of datasets with millions of student interactions. In this work, we adopt EdNet, the largest student interaction dataset publicly available in the education domain, to understand how accurately both deep and traditional models predict future student performances. Our work observes that logistic regression models with carefully engineered features outperformed deep models from extensive experimentation. We follow this analysis with interpretation studies based on Locally Interpretable Model-agnostic Explanation (LIME) to understand the impact of various features on best performing model pre-dictions.

</p>
</details>

<details><summary><b>Evaluating uncertainties in electrochemical impedance spectra of solid oxide fuel cells</b>
<a href="https://arxiv.org/abs/2101.08049">arxiv:2101.08049</a>
&#x1F4C8; 6 <br>
<p>Luka Žnidarič, Gjorgji Nusev, Bertrand Morel, Julie Mougin, Đani Juričić, Pavle Boškoski</p></summary>
<p>

**Abstract:** Electrochemical impedance spectroscopy (EIS) is a widely used tool for characterization of fuel cells and other electrochemical conversion systems. When applied to the on-line monitoring in the context of in-field applications, the disturbances, drifts and sensor noise may cause severe distortions in the evaluated spectra, especially in the low-frequency part. Failure to ignore the random effects can result in misinterpreted spectra and, consequently, in misleading diagnostic reasoning. This fact has not been often addressed in the research so far. In this paper, we propose an approach to the quantification of the spectral uncertainty, which relies on evaluating the uncertainty of the equivalent circuit model (ECM). We apply the computationally efficient variational Bayes (VB) method and compare the quality of the results with those obtained with the Markov chain Monte Carlo (MCMC) algorithm. Namely, MCMC algorithm returns accurate distributions of the estimated model parameters, while VB approach provides the approximate distributions. By using simulated and real data we show that approximate results provided by VB approach, although slightly over-optimistic, are still close to the more realistic MCMC estimates. A great advantage of the VB method for online monitoring is low computational load, which is several orders of magnitude lower compared to MCMC. The performance of VB algorithm is demonstrated on a case of ECM parameters estimation in a 6 cell solid oxide fuel cell (SOFC) stack. The complete numerical implementation for recreating the results can be found at https://repo.ijs.si/lznidaric/variational-bayes-supplementary-material.

</p>
</details>

<details><summary><b>Bridge the Vision Gap from Field to Command: A Deep Learning Network Enhancing Illumination and Details</b>
<a href="https://arxiv.org/abs/2101.08039">arxiv:2101.08039</a>
&#x1F4C8; 6 <br>
<p>Zhuqing Jiang, Chang Liu, Ya'nan Wang, Kai Li, Aidong Men, Haiying Wang, Haiyong Luo</p></summary>
<p>

**Abstract:** With the goal of tuning up the brightness, low-light image enhancement enjoys numerous applications, such as surveillance, remote sensing and computational photography. Images captured under low-light conditions often suffer from poor visibility and blur. Solely brightening the dark regions will inevitably amplify the blur, thus may lead to detail loss. In this paper, we propose a simple yet effective two-stream framework named NEID to tune up the brightness and enhance the details simultaneously without introducing many computational costs. Precisely, the proposed method consists of three parts: Light Enhancement (LE), Detail Refinement (DR) and Feature Fusing (FF) module, which can aggregate composite features oriented to multiple tasks based on channel attention mechanism. Extensive experiments conducted on several benchmark datasets demonstrate the efficacy of our method and its superiority over state-of-the-art methods.

</p>
</details>

<details><summary><b>Android Controlled Mobile Robot Design with IP Camera</b>
<a href="https://arxiv.org/abs/2102.01511">arxiv:2102.01511</a>
&#x1F4C8; 5 <br>
<p>Emre Demir, Ahmet Gokcen, Yakup Kutlu</p></summary>
<p>

**Abstract:** In this study Arduino card based mobile robot design was realized. This robot can serve as a security robot, an auxiliary robot or a control robot. The designed robot has two operation modes. The first operating mode is autonomous mode. In this mode, the robot detects the surroundings with the help of ultrasonic sensors placed around it, and keeps track of the places it passes by using the encoder. It is able to navigate without hitting any place and passing from where it passes, and it transmits the patient's pulse and temperature condition to the user by other systems installed on it. Also the IP camera sends the scene on the screen. The emergency button to be placed next to the patient sends information to the user in emergency situations. If the abnormality is detected in the temperature and pulse again, the user gives a message. When the pre-recorded drug use times come, the system can alert the patient. The second mode is manual mode. In this mode, the user can move the desired direction of the robot with the Android operating system. In addition, all data received in autonomous mode can be sent to the user. Thus, the user can control the mobile robot with the camera image even if it is not in the vicinity of the robot.

</p>
</details>

<details><summary><b>Blocked and Hierarchical Disentangled Representation From Information Theory Perspective</b>
<a href="https://arxiv.org/abs/2101.08408">arxiv:2101.08408</a>
&#x1F4C8; 5 <br>
<p>Ziwen Liu, Mingqiang Li, Congying Han</p></summary>
<p>

**Abstract:** We propose a novel and theoretical model, blocked and hierarchical variational autoencoder (BHiVAE), to get better-disentangled representation. It is well known that information theory has an excellent explanatory meaning for the network, so we start to solve the disentanglement problem from the perspective of information theory. BHiVAE mainly comes from the information bottleneck theory and information maximization principle. Our main idea is that (1) Neurons block not only one neuron node is used to represent attribute, which can contain enough information; (2) Create a hierarchical structure with different attributes on different layers, so that we can segment the information within each layer to ensure that the final representation is disentangled. Furthermore, we present supervised and unsupervised BHiVAE, respectively, where the difference is mainly reflected in the separation of information between different blocks. In supervised BHiVAE, we utilize the label information as the standard to separate blocks. In unsupervised BHiVAE, without extra information, we use the Total Correlation (TC) measure to achieve independence, and we design a new prior distribution of the latent space to guide the representation learning. It also exhibits excellent disentanglement results in experiments and superior classification accuracy in representation learning.

</p>
</details>

<details><summary><b>Chest X-ray lung and heart segmentation based on minimal training sets</b>
<a href="https://arxiv.org/abs/2101.08309">arxiv:2101.08309</a>
&#x1F4C8; 5 <br>
<p>Balázs Maga</p></summary>
<p>

**Abstract:** As the COVID-19 pandemic aggravated the excessive workload of doctors globally, the demand for computer aided methods in medical imaging analysis increased even further. Such tools can result in more robust diagnostic pipelines which are less prone to human errors. In our paper, we present a deep neural network to which we refer to as Attention BCDU-Net, and apply it to the task of lung and heart segmentation from chest X-ray (CXR) images, a basic but ardous step in the diagnostic pipeline, for instance for the detection of cardiomegaly. We show that the fine-tuned model exceeds previous state-of-the-art results, reaching $98.1\pm 0.1\%$ Dice score and $95.2\pm 0.1\%$ IoU score on the dataset of Japanese Society of Radiological Technology (JSRT). Besides that, we demonstrate the relative simplicity of the task by attaining surprisingly strong results with training sets of size 10 and 20: in terms of Dice score, $97.0\pm 0.8\%$ and $97.3\pm 0.5$, respectively, while in terms of IoU score, $92.2\pm 1.2\%$ and $93.3\pm 0.4\%$, respectively. To achieve these scores, we capitalize on the mixup augmentation technique, which yields a remarkable gain above $4\%$ IoU score in the size 10 setup.

</p>
</details>

<details><summary><b>Variational Autoencoders with a Structural Similarity Loss in Time of Flight MRAs</b>
<a href="https://arxiv.org/abs/2101.08052">arxiv:2101.08052</a>
&#x1F4C8; 5 <br>
<p>Kimberley M. Timmins, Irene C. van der Schaaf, Ynte M. Ruigrok, Birgitta K. Velthuis, Hugo J. Kuijf</p></summary>
<p>

**Abstract:** Time-of-Flight Magnetic Resonance Angiographs (TOF-MRAs) enable visualization and analysis of cerebral arteries. This analysis may indicate normal variation of the configuration of the cerebrovascular system or vessel abnormalities, such as aneurysms. A model would be useful to represent normal cerebrovascular structure and variabilities in a healthy population and to differentiate from abnormalities. Current anomaly detection using autoencoding convolutional neural networks usually use a voxelwise mean-error for optimization. We propose optimizing a variational-autoencoder (VAE) with structural similarity loss (SSIM) for TOF-MRA reconstruction. A patch-trained 2D fully-convolutional VAE was optimized for TOF-MRA reconstruction by comparing vessel segmentations of original and reconstructed MRAs. The method was trained and tested on two datasets: the IXI dataset, and a subset from the ADAM challenge. Both trained networks were tested on a dataset including subjects with aneurysms. We compared VAE optimization with L2-loss and SSIM-loss. Performance was evaluated between original and reconstructed MRAs using mean square error, mean-SSIM, peak-signal-to-noise-ratio and dice similarity index (DSI) of segmented vessels. The L2-optimized VAE outperforms SSIM, with improved reconstruction metrics and DSIs for both datasets. Optimization using SSIM performed best for visual image quality, but with discrepancy in quantitative reconstruction and vascular segmentation. The larger, more diverse IXI dataset had overall better performance. Reconstruction metrics, including SSIM, were lower for MRAs including aneurysms. A SSIM-optimized VAE improved the visual perceptive image quality of TOF-MRA reconstructions. A L2-optimized VAE performed best for TOF-MRA reconstruction, where the vascular segmentation is important. SSIM is a potential metric for anomaly detection of MRAs.

</p>
</details>

<details><summary><b>Learning based signal detection for MIMO systems with unknown noise statistics</b>
<a href="https://arxiv.org/abs/2101.08435">arxiv:2101.08435</a>
&#x1F4C8; 4 <br>
<p>Ke He, Le He, Lisheng Fan, Yansha Deng, George K. Karagiannidis, Arumugam Nallanathan</p></summary>
<p>

**Abstract:** This paper aims to devise a generalized maximum likelihood (ML) estimator to robustly detect signals with unknown noise statistics in multiple-input multiple-output (MIMO) systems. In practice, there is little or even no statistical knowledge on the system noise, which in many cases is non-Gaussian, impulsive and not analyzable. Existing detection methods have mainly focused on specific noise models, which are not robust enough with unknown noise statistics. To tackle this issue, we propose a novel ML detection framework to effectively recover the desired signal. Our framework is a fully probabilistic one that can efficiently approximate the unknown noise distribution through a normalizing flow. Importantly, this framework is driven by an unsupervised learning approach, where only the noise samples are required. To reduce the computational complexity, we further present a low-complexity version of the framework, by utilizing an initial estimation to reduce the search space. Simulation results show that our framework outperforms other existing algorithms in terms of bit error rate (BER) in non-analytical noise environments, while it can reach the ML performance bound in analytical noise environments. The code of this paper is available at https://github.com/skypitcher/manfe.

</p>
</details>

<details><summary><b>Introduction to Normalizing Flows for Lattice Field Theory</b>
<a href="https://arxiv.org/abs/2101.08176">arxiv:2101.08176</a>
&#x1F4C8; 4 <br>
<p>Michael S. Albergo, Denis Boyda, Daniel C. Hackett, Gurtej Kanwar, Kyle Cranmer, Sébastien Racanière, Danilo Jimenez Rezende, Phiala E. Shanahan</p></summary>
<p>

**Abstract:** This notebook tutorial demonstrates a method for sampling Boltzmann distributions of lattice field theories using a class of machine learning models known as normalizing flows. The ideas and approaches proposed in arXiv:1904.12072, arXiv:2002.02428, and arXiv:2003.06413 are reviewed and a concrete implementation of the framework is presented. We apply this framework to a lattice scalar field theory and to U(1) gauge theory, explicitly encoding gauge symmetries in the flow-based approach to the latter. This presentation is intended to be interactive and working with the attached Jupyter notebook is recommended.

</p>
</details>

<details><summary><b>Raspberry Pi Based Intelligent Robot that Recognizes and Places Puzzle Objects</b>
<a href="https://arxiv.org/abs/2101.12584">arxiv:2101.12584</a>
&#x1F4C8; 3 <br>
<p>Yakup Kutlu, Zülfü Alanoglu, Ahmet Gökçen, Mustafa Yeniad</p></summary>
<p>

**Abstract:** In this study; in order to diagnose congestive heart failure (CHF) patients, non-linear secondorder difference plot (SODP) obtained from raw 256 Hz sampled frequency and windowed record with different time of ECG records are used. All of the data rows are labelled with their belongings to classify much more realistically. SODPs are divided into different radius of quadrant regions and numbers of the points fall in the quadrants are computed in order to extract feature vectors. Fisher's linear discriminant, Naive Bayes, and artificial neural network are used as classifier. The results are considered in two step validation methods as general kfold cross-validation and patient based cross-validation. As a result, it is shown that using neural network classifier with features obtained from SODP, the constructed system could distinguish normal and CHF patients with 100% accuracy rate.

</p>
</details>

<details><summary><b>A New Knowledge Gradient-based Method for Constrained Bayesian Optimization</b>
<a href="https://arxiv.org/abs/2101.08743">arxiv:2101.08743</a>
&#x1F4C8; 3 <br>
<p>Wenjie Chen, Shengcai Liu, Ke Tang</p></summary>
<p>

**Abstract:** Black-box problems are common in real life like structural design, drug experiments, and machine learning. When optimizing black-box systems, decision-makers always consider multiple performances and give the final decision by comprehensive evaluations. Motivated by such practical needs, we focus on constrained black-box problems where the objective and constraints lack known special structure, and evaluations are expensive and even with noise. We develop a novel constrained Bayesian optimization approach based on the knowledge gradient method ($c-\rm{KG}$). A new acquisition function is proposed to determine the next batch of samples considering optimality and feasibility. An unbiased estimator of the gradient of the new acquisition function is derived to implement the $c-\rm{KG}$ approach.

</p>
</details>

<details><summary><b>From Local Pseudorandom Generators to Hardness of Learning</b>
<a href="https://arxiv.org/abs/2101.08303">arxiv:2101.08303</a>
&#x1F4C8; 3 <br>
<p>Amit Daniely, Gal Vardi</p></summary>
<p>

**Abstract:** We prove hardness-of-learning results under a well-studied assumption on the existence of local pseudorandom generators. As we show, this assumption allows us to surpass the current state of the art, and prove hardness of various basic problems, with no hardness results to date.
  Our results include: hardness of learning shallow ReLU neural networks under the Gaussian distribution and other distributions; hardness of learning intersections of $ω(1)$ halfspaces, DNF formulas with $ω(1)$ terms, and ReLU networks with $ω(1)$ hidden neurons; hardness of weakly learning deterministic finite automata under the uniform distribution; hardness of weakly learning depth-$3$ Boolean circuits under the uniform distribution, as well as distribution-specific hardness results for learning DNF formulas and intersections of halfspaces. We also establish lower bounds on the complexity of learning intersections of a constant number of halfspaces, and ReLU networks with a constant number of hidden neurons. Moreover, our results imply the hardness of virtually all improper PAC-learning problems (both distribution-free and distribution-specific) that were previously shown hard under other assumptions.

</p>
</details>

<details><summary><b>A Similarity Measure of Gaussian Process Predictive Distributions</b>
<a href="https://arxiv.org/abs/2101.08061">arxiv:2101.08061</a>
&#x1F4C8; 3 <br>
<p>Lucia Asencio-Martín, Eduardo C. Garrido-Merchán</p></summary>
<p>

**Abstract:** Some scenarios require the computation of a predictive distribution of a new value evaluated on an objective function conditioned on previous observations. We are interested on using a model that makes valid assumptions on the objective function whose values we are trying to predict. Some of these assumptions may be smoothness or stationarity. Gaussian process (GPs) are probabilistic models that can be interpreted as flexible distributions over functions. They encode the assumptions through covariance functions, making hypotheses about new data through a predictive distribution by being fitted to old observations. We can face the case where several GPs are used to model different objective functions. GPs are non-parametric models whose complexity is cubic on the number of observations. A measure that represents how similar is one GP predictive distribution with respect to another would be useful to stop using one GP when they are modelling functions of the same input space. We are really inferring that two objective functions are correlated, so one GP is enough to model both of them by performing a transformation of the prediction of the other function in case of inverse correlation. We show empirical evidence in a set of synthetic and benchmark experiments that GPs predictive distributions can be compared and that one of them is enough to predict two correlated functions in the same input space. This similarity metric could be extremely useful used to discard objectives in Bayesian many-objective optimization.

</p>
</details>

<details><summary><b>Improved Signed Distance Function for 2D Real-time SLAM and Accurate Localization</b>
<a href="https://arxiv.org/abs/2101.08018">arxiv:2101.08018</a>
&#x1F4C8; 3 <br>
<p>Xingyin Fu, Zheng Fang, Xizhen Xiao, Yijia He, Xiao Liu</p></summary>
<p>

**Abstract:** Accurate mapping and localization are very important for many industrial robotics applications. In this paper, we propose an improved Signed Distance Function (SDF) for both 2D SLAM and pure localization to improve the accuracy of mapping and localization. To achieve this goal, firstly we improved the back-end mapping to build a more accurate SDF map by extending the update range and building free space, etc. Secondly, to get more accurate pose estimation for the front-end, we proposed a new iterative registration method to align the current scan to the SDF submap by removing random outliers of laser scanners. Thirdly, we merged all the SDF submaps to produce an integrated SDF map for highly accurate pure localization. Experimental results show that based on the merged SDF map, a localization accuracy of a few millimeters (5mm) can be achieved globally within the map. We believe that this method is important for mobile robots working in scenarios where high localization accuracy matters.

</p>
</details>

<details><summary><b>Deep Epidemiological Modeling by Black-box Knowledge Distillation: An Accurate Deep Learning Model for COVID-19</b>
<a href="https://arxiv.org/abs/2101.10280">arxiv:2101.10280</a>
&#x1F4C8; 2 <br>
<p>Dongdong Wang, Shunpu Zhang, Liqiang Wang</p></summary>
<p>

**Abstract:** An accurate and efficient forecasting system is imperative to the prevention of emerging infectious diseases such as COVID-19 in public health. This system requires accurate transient modeling, lower computation cost, and fewer observation data. To tackle these three challenges, we propose a novel deep learning approach using black-box knowledge distillation for both accurate and efficient transmission dynamics prediction in a practical manner. First, we leverage mixture models to develop an accurate, comprehensive, yet impractical simulation system. Next, we use simulated observation sequences to query the simulation system to retrieve simulated projection sequences as knowledge. Then, with the obtained query data, sequence mixup is proposed to improve query efficiency, increase knowledge diversity, and boost distillation model accuracy. Finally, we train a student deep neural network with the retrieved and mixed observation-projection sequences for practical use. The case study on COVID-19 justifies that our approach accurately projects infections with much lower computation cost when observation data are limited.

</p>
</details>

<details><summary><b>Improved Sensitivity of Base Layer on the Performance of Rigid Pavement</b>
<a href="https://arxiv.org/abs/2101.09167">arxiv:2101.09167</a>
&#x1F4C8; 2 <br>
<p>Sajib Saha, Fan Gu, Xue Luo, Robert L. Lytton</p></summary>
<p>

**Abstract:** The performance of rigid pavement is greatly affected by the properties of base/subbase as well as subgrade layer. However, the performance predicted by the AASHTOWare Pavement ME design shows low sensitivity to the properties of base and subgrade layers. To improve the sensitivity and better reflect the influence of unbound layers a new set of improved models i.e., resilient modulus (MR) and modulus of subgrade reaction (k-value) are adopted in this study. An Artificial Neural Network (ANN) model is developed to predict the modified k-value based on finite element (FE) analysis. The training and validation datasets in the ANN model consist of 27000 simulation cases with different combinations of pavement layer thickness, layer modulus and slab-base interface bond ratio. To examine the sensitivity of modified MR and k-values on pavement response, eight pavement sections data are collected from the Long-Term Pavement performance (LTPP) database and modeled by using the FE software ISLAB2000. The computational results indicate that the modified MR values have higher sensitivity to water content in base layer on critical stress and deflection response of rigid pavements compared to the results using the Pavement ME design model. It is also observed that the k-values using ANN model has the capability of predicting critical pavement response at any partially bonded conditions whereas the Pavement ME design model can only calculate at two extreme bonding conditions (i.e., fully bonding and no bonding).

</p>
</details>

<details><summary><b>Motif Identification using CNN-based Pairwise Subsequence Alignment Score Prediction</b>
<a href="https://arxiv.org/abs/2101.08385">arxiv:2101.08385</a>
&#x1F4C8; 2 <br>
<p>Ethan Jacob Moyer, Anup Das</p></summary>
<p>

**Abstract:** A common problem in bioinformatics is related to identifying gene regulatory regions marked by relatively high frequencies of motifs, or deoxyribonucleic acid sequences that often code for transcription and enhancer proteins. Predicting alignment scores between subsequence k-mers and a given motif enables the identification of candidate regulatory regions in a gene, which correspond to the transcription of these proteins. We propose a one-dimensional (1-D) Convolution Neural Network trained on k-mer formatted sequences interspaced with the given motif pattern to predict pairwise alignment scores between the consensus motif and subsequence k-mers. Our model consists of fifteen layers with three rounds of a one-dimensional convolution layer, a batch normalization layer, a dense layer, and a 1-D maximum pooling layer. We train the model using mean squared error loss on four different data sets each with a different motif pattern randomly inserted in DNA sequences: the first three data sets have zero, one, and two mutations applied on each inserted motif, and the fourth data set represents the inserted motif as a position-specific probability matrix. We use a novel proposed metric in order to evaluate the model's performance, $S_α$, which is based on the Jaccard Index. We use 10-fold cross validation to evaluate out model. Using $S_α$, we measure the accuracy of the model by identifying the 15 highest-scoring 15-mer indices of the predicted scores that agree with that of the actual scores within a selected $α$ region. For the best performing data set, our results indicate on average 99.3% of the top 15 motifs were identified correctly within a one base pair stride ($α= 1$) in the out of sample data. To the best of our knowledge, this is a novel approach that illustrates how data formatted in an intelligent way can be extrapolated using machine learning.

</p>
</details>

<details><summary><b>The Diagnosis of Asthma using Hilbert-Huang Transform and Deep Learning on Lung Sounds</b>
<a href="https://arxiv.org/abs/2101.08288">arxiv:2101.08288</a>
&#x1F4C8; 2 <br>
<p>Gökhan Altan, Yakup Kutlu, Adnan Özhan Pekmezci, Serkan Nural</p></summary>
<p>

**Abstract:** Lung auscultation is the most effective and indispensable method for diagnosing various respiratory disorders by using the sounds from the airways during inspirium and exhalation using a stethoscope. In this study, the statistical features are calculated from intrinsic mode functions that are extracted by applying the HilbertHuang Transform to the lung sounds from 12 different auscultation regions on the chest and back. The classification of the lung sounds from asthma and healthy subjects is performed using Deep Belief Networks (DBN). The DBN classifier model with two hidden layers has been tested using 5-fold cross validation method. The proposed DBN separated lung sounds from asthmatic and healthy subjects with high classification performance rates of 84.61%, 85.83%, and 77.11% for overall accuracy, sensitivity, and selectivity, respectively using frequencytime analysis.

</p>
</details>

<details><summary><b>Can stable and accurate neural networks be computed? -- On the barriers of deep learning and Smale's 18th problem</b>
<a href="https://arxiv.org/abs/2101.08286">arxiv:2101.08286</a>
&#x1F4C8; 2 <br>
<p>Matthew J. Colbrook, Vegard Antun, Anders C. Hansen</p></summary>
<p>

**Abstract:** Deep learning (DL) has had unprecedented success and is now entering scientific computing with full force. However, current DL methods typically suffer from instability, even when universal approximation properties guarantee the existence of stable neural networks (NNs). We address this paradox by demonstrating basic well-conditioned problems in scientific computing where one can prove the existence of NNs with great approximation qualities, however, there does not exist any algorithm, even randomised, that can train (or compute) such a NN. For any positive integers $K > 2$ and $L$, there are cases where simultaneously: (a) no randomised training algorithm can compute a NN correct to $K$ digits with probability greater than $1/2$, (b) there exists a deterministic training algorithm that computes a NN with $K-1$ correct digits, but any such (even randomised) algorithm needs arbitrarily many training data, (c) there exists a deterministic training algorithm that computes a NN with $K-2$ correct digits using no more than $L$ training samples. These results imply a classification theory describing conditions under which (stable) NNs with a given accuracy can be computed by an algorithm. We begin this theory by establishing sufficient conditions for the existence of algorithms that compute stable NNs in inverse problems. We introduce Fast Iterative REstarted NETworks (FIRENETs), which we both prove and numerically verify are stable. Moreover, we prove that only $\mathcal{O}(|\log(ε)|)$ layers are needed for an $ε$-accurate solution to the inverse problem.

</p>
</details>

<details><summary><b>Data-to-text Generation by Splicing Together Nearest Neighbors</b>
<a href="https://arxiv.org/abs/2101.08248">arxiv:2101.08248</a>
&#x1F4C8; 2 <br>
<p>Sam Wiseman, Arturs Backurs, Karl Stratos</p></summary>
<p>

**Abstract:** We propose to tackle data-to-text generation tasks by directly splicing together retrieved segments of text from "neighbor" source-target pairs. Unlike recent work that conditions on retrieved neighbors but generates text token-by-token, left-to-right, we learn a policy that directly manipulates segments of neighbor text, by inserting or replacing them in partially constructed generations. Standard techniques for training such a policy require an oracle derivation for each generation, and we prove that finding the shortest such derivation can be reduced to parsing under a particular weighted context-free grammar. We find that policies learned in this way perform on par with strong baselines in terms of automatic and human evaluation, but allow for more interpretable and controllable generation.

</p>
</details>

<details><summary><b>Component Tree Loss Function: Definition and Optimization</b>
<a href="https://arxiv.org/abs/2101.08063">arxiv:2101.08063</a>
&#x1F4C8; 2 <br>
<p>Benjamin Perret, Jean Cousty</p></summary>
<p>

**Abstract:** In this article, we propose a method to design loss functions based on component trees which can be optimized by gradient descent algorithms and which are therefore usable in conjunction with recent machine learning approaches such as neural networks. We show how the altitudes associated to the nodes of such hierarchical image representations can be differentiated with respect to the image pixel values. This feature is used to design a generic loss function that can select or discard image maxima based on various attributes such as extinction values. The possibilities of the proposed method are demonstrated on simulated and real image filtering.

</p>
</details>

<details><summary><b>On the Non-Monotonicity of a Non-Differentially Mismeasured Binary Confounder</b>
<a href="https://arxiv.org/abs/2101.08007">arxiv:2101.08007</a>
&#x1F4C8; 2 <br>
<p>Jose M. Peña</p></summary>
<p>

**Abstract:** Suppose that we are interested in the average causal effect of a binary treatment on an outcome when this relationship is confounded by a binary confounder. Suppose that the confounder is unobserved but a non-differential binary proxy of it is observed. We identify conditions under which adjusting for the proxy comes closer to the incomputable true average causal effect than not adjusting at all. Unlike other works, we do not assume that the average causal effect of the confounder on the outcome is in the same direction among treated and untreated.

</p>
</details>

<details><summary><b>Visible light communication-based monitoring for indoor environments using unsupervised learning</b>
<a href="https://arxiv.org/abs/2101.10838">arxiv:2101.10838</a>
&#x1F4C8; 1 <br>
<p>Mehmet C. Ilter, Alexis A. Dowhuszko, Jyri Hämäläinen, Risto Wichman</p></summary>
<p>

**Abstract:** Visible Light Communication~(VLC) systems provide not only illumination and data communication, but also indoor monitoring services if the effect that different events create on the received optical signal is properly tracked. For this purpose, the Channel State Information that a VLC receiver computes to equalize the subcarriers of the OFDM signal can be also reused to train an Unsupervised Learning classifier. This way, different clusters can be created on the collected CSI data, which could be then mapped into relevant events to-be-monitored in the indoor environments, such as the presence of a new object in a given position or the change of the position of a given object. When compared to supervised learning algorithms, the proposed approach does not need to add tags in the training data, simplifying notably the implementation of the machine learning classifier. The practical validation the monitoring approach was done with the aid of a software-defined VLC link based on OFDM, in which a copy of the intensity modulated signal coming from a Phosphor-converted LED was captured by a pair of Photodetectors~(PDs). The performance evaluation of the experimental VLC-based monitoring demo achieved a positioning accuracy in the few-centimeter-range, without the necessity of deploying a large number of sensors and/or adding a VLC-enabled sensor on the object to-be-tracked.

</p>
</details>

<details><summary><b>A Robust Blockchain Readiness Index Model</b>
<a href="https://arxiv.org/abs/2101.09162">arxiv:2101.09162</a>
&#x1F4C8; 1 <br>
<p>Elias Iosif, Klitos Christodoulou, Andreas Vlachos</p></summary>
<p>

**Abstract:** As the blockchain ecosystem gets more mature many businesses, investors, and entrepreneurs are seeking opportunities on working with blockchain systems and cryptocurrencies. A critical challenge for these actors is to identify the most suitable environment to start or evolve their businesses. In general, the question is to identify which countries are offering the most suitable conditions to host their blockchain-based activities and implement their innovative projects. The Blockchain Readiness Index (BRI) provides a numerical metric (referred to as the blockchain readiness score) in measuring the maturity/readiness levels of a country in adopting blockchain and cryptocurrencies. In doing so, BRI leverages on techniques from information retrieval to algorithmically derive an index ranking for a set of countries. The index considers a range of indicators organized under five pillars: Government Regulation, Research, Technology, Industry, and User Engagement. In this paper, we further extent BRI with the capability of deriving the index - at the country level - even in the presence of missing information for the indicators. In doing so, we are proposing two weighting schemes namely, linear and sigmoid weighting for refining the initial estimates for the indicator values. A classification framework was employed to evaluate the effectiveness of the developed techniques which yielded to a significant classification accuracy.

</p>
</details>

<details><summary><b>Finite Model Theory of the Triguarded Fragment and Related Logics</b>
<a href="https://arxiv.org/abs/2101.08377">arxiv:2101.08377</a>
&#x1F4C8; 1 <br>
<p>Emanuel Kieroński, Sebastian Rudolph</p></summary>
<p>

**Abstract:** The Triguarded Fragment (TGF) is among the most expressive decidable fragments of first-order logic, subsuming both its two-variable and guarded fragments without equality. We show that the TGF has the finite model property (providing a tight doubly exponential bound on the model size) and hence finite satisfiability coincides with satisfiability known to be N2ExpTime-complete. Using similar constructions, we also establish 2ExpTime-completeness for finite satisfiability of the constant-free (tri)guarded fragment with transitive guards.

</p>
</details>

<details><summary><b>Learning Ultrasound Rendering from Cross-Sectional Model Slices for Simulated Training</b>
<a href="https://arxiv.org/abs/2101.08339">arxiv:2101.08339</a>
&#x1F4C8; 1 <br>
<p>Lin Zhang, Tiziano Portenier, Orcun Goksel</p></summary>
<p>

**Abstract:** Purpose. Given the high level of expertise required for navigation and interpretation of ultrasound images, computational simulations can facilitate the training of such skills in virtual reality. With ray-tracing based simulations, realistic ultrasound images can be generated. However, due to computational constraints for interactivity, image quality typically needs to be compromised.
  Methods. We propose herein to bypass any rendering and simulation process at interactive time, by conducting such simulations during a non-time-critical offline stage and then learning image translation from cross-sectional model slices to such simulated frames. We use a generative adversarial framework with a dedicated generator architecture and input feeding scheme, which both substantially improve image quality without increase in network parameters. Integral attenuation maps derived from cross-sectional model slices, texture-friendly strided convolutions, providing stochastic noise and input maps to intermediate layers in order to preserve locality are all shown herein to greatly facilitate such translation task.
  Results. Given several quality metrics, the proposed method with only tissue maps as input is shown to provide comparable or superior results to a state-of-the-art that uses additional images of low-quality ultrasound renderings. An extensive ablation study shows the need and benefits from the individual contributions utilized in this work, based on qualitative examples and quantitative ultrasound similarity metrics. To that end, a local histogram statistics based error metric is proposed and demonstrated for visualization of local dissimilarities between ultrasound images.

</p>
</details>

<details><summary><b>RADAR: Run-time Adversarial Weight Attack Detection and Accuracy Recovery</b>
<a href="https://arxiv.org/abs/2101.08254">arxiv:2101.08254</a>
&#x1F4C8; 1 <br>
<p>Jingtao Li, Adnan Siraj Rakin, Zhezhi He, Deliang Fan, Chaitali Chakrabarti</p></summary>
<p>

**Abstract:** Adversarial attacks on Neural Network weights, such as the progressive bit-flip attack (PBFA), can cause a catastrophic degradation in accuracy by flipping a very small number of bits. Furthermore, PBFA can be conducted at run time on the weights stored in DRAM main memory. In this work, we propose RADAR, a Run-time adversarial weight Attack Detection and Accuracy Recovery scheme to protect DNN weights against PBFA. We organize weights that are interspersed in a layer into groups and employ a checksum-based algorithm on weights to derive a 2-bit signature for each group. At run time, the 2-bit signature is computed and compared with the securely stored golden signature to detect the bit-flip attacks in a group. After successful detection, we zero out all the weights in a group to mitigate the accuracy drop caused by malicious bit-flips. The proposed scheme is embedded in the inference computation stage. For the ResNet-18 ImageNet model, our method can detect 9.6 bit-flips out of 10 on average. For this model, the proposed accuracy recovery scheme can restore the accuracy from below 1% caused by 10 bit flips to above 69%. The proposed method has extremely low time and storage overhead. System-level simulation on gem5 shows that RADAR only adds <1% to the inference time, making this scheme highly suitable for run-time attack detection and mitigation.

</p>
</details>

<details><summary><b>Trimming the Fat from OFDM: Pilot- and CP-less Communication with End-to-end Learning</b>
<a href="https://arxiv.org/abs/2101.08213">arxiv:2101.08213</a>
&#x1F4C8; 1 <br>
<p>Fayçal Ait Aoudia, Jakob Hoydis</p></summary>
<p>

**Abstract:** Orthogonal frequency division multiplexing (OFDM) is one of the dominant waveforms in wireless communication systems due to its efficient implementation. However, it suffers from a loss of spectral efficiency as it requires a cyclic prefix (CP) to mitigate inter-symbol interference (ISI) and pilots to estimate the channel. We propose in this work to address these drawbacks by learning a neural network (NN)-based receiver jointly with a constellation geometry and bit labeling at the transmitter, that allows CP-less and pilotless communication on top of OFDM without a significant loss in bit error rate (BER). Our approach enables at least 18% throughput gains compared to a pilot and CP-based baseline, and at least 4% gains compared to a system that uses a neural receiver with pilots but no CP.

</p>
</details>

<details><summary><b>Fast deep learning correspondence for neuron tracking and identification in C.elegans using synthetic training</b>
<a href="https://arxiv.org/abs/2101.08211">arxiv:2101.08211</a>
&#x1F4C8; 1 <br>
<p>Xinwei Yu, Matthew S. Creamer, Francesco Randi, Anuj K. Sharma, Scott W. Linderman, Andrew M. Leifer</p></summary>
<p>

**Abstract:** We present an automated method to track and identify neurons in C. elegans, called "fast Deep Learning Correspondence" or fDLC, based on the transformer network architecture. The model is trained once on empirically derived synthetic data and then predicts neural correspondence across held-out real animals via transfer learning. The same pre-trained model both tracks neurons across time and identifies corresponding neurons across individuals. Performance is evaluated against hand-annotated datasets, including NeuroPAL [1]. Using only position information, the method achieves 80.0% accuracy at tracking neurons within an individual and 65.8% accuracy at identifying neurons across individuals. Accuracy is even higher on a published dataset [2]. Accuracy reaches 76.5% when using color information from NeuroPAL. Unlike previous methods, fDLC does not require straightening or transforming the animal into a canonical coordinate system. The method is fast and predicts correspondence in 10 ms making it suitable for future real-time applications.

</p>
</details>

<details><summary><b>secureTF: A Secure TensorFlow Framework</b>
<a href="https://arxiv.org/abs/2101.08204">arxiv:2101.08204</a>
&#x1F4C8; 1 <br>
<p>Do Le Quoc, Franz Gregor, Sergei Arnautov, Roland Kunkel, Pramod Bhatotia, Christof Fetzer</p></summary>
<p>

**Abstract:** Data-driven intelligent applications in modern online services have become ubiquitous. These applications are usually hosted in the untrusted cloud computing infrastructure. This poses significant security risks since these applications rely on applying machine learning algorithms on large datasets which may contain private and sensitive information.
  To tackle this challenge, we designed secureTF, a distributed secure machine learning framework based on Tensorflow for the untrusted cloud infrastructure. secureTF is a generic platform to support unmodified TensorFlow applications, while providing end-to-end security for the input data, ML model, and application code. secureTF is built from ground-up based on the security properties provided by Trusted Execution Environments (TEEs). However, it extends the trust of a volatile memory region (or secure enclave) provided by the single node TEE to secure a distributed infrastructure required for supporting unmodified stateful machine learning applications running in the cloud.
  The paper reports on our experiences about the system design choices and the system deployment in production use-cases. We conclude with the lessons learned based on the limitations of our commercially available platform, and discuss open research problems for the future work.

</p>
</details>

<details><summary><b>Synthesizing Context-free Grammars from Recurrent Neural Networks (Extended Version)</b>
<a href="https://arxiv.org/abs/2101.08200">arxiv:2101.08200</a>
&#x1F4C8; 1 <br>
<p>Daniel M. Yellin, Gail Weiss</p></summary>
<p>

**Abstract:** We present an algorithm for extracting a subclass of the context free grammars (CFGs) from a trained recurrent neural network (RNN). We develop a new framework, pattern rule sets (PRSs), which describe sequences of deterministic finite automata (DFAs) that approximate a non-regular language. We present an algorithm for recovering the PRS behind a sequence of such automata, and apply it to the sequences of automata extracted from trained RNNs using the L* algorithm. We then show how the PRS may converted into a CFG, enabling a familiar and useful presentation of the learned language.
  Extracting the learned language of an RNN is important to facilitate understanding of the RNN and to verify its correctness. Furthermore, the extracted CFG can augment the RNN in classifying correct sentences, as the RNN's predictive accuracy decreases when the recursion depth and distance between matching delimiters of its input sequences increases.

</p>
</details>

<details><summary><b>Neural-based Modeling for Performance Tuning of Spark Data Analytics</b>
<a href="https://arxiv.org/abs/2101.08167">arxiv:2101.08167</a>
&#x1F4C8; 1 <br>
<p>Khaled Zaouk, Fei Song, Chenghao Lyu, Yanlei Diao</p></summary>
<p>

**Abstract:** Cloud data analytics has become an integral part of enterprise business operations for data-driven insight discovery. Performance modeling of cloud data analytics is crucial for performance tuning and other critical operations in the cloud. Traditional modeling techniques fail to adapt to the high degree of diversity in workloads and system behaviors in this domain. In this paper, we bring recent Deep Learning techniques to bear on the process of automated performance modeling of cloud data analytics, with a focus on Spark data analytics as representative workloads. At the core of our work is the notion of learning workload embeddings (with a set of desired properties) to represent fundamental computational characteristics of different jobs, which enable performance prediction when used together with job configurations that control resource allocation and other system knobs. Our work provides an in-depth study of different modeling choices that suit our requirements. Results of extensive experiments reveal the strengths and limitations of different modeling methods, as well as superior performance of our best performing method over a state-of-the-art modeling tool for cloud analytics.

</p>
</details>

<details><summary><b>Extensive Studies of the Neutron Star Equation of State from the Deep Learning Inference with the Observational Data Augmentation</b>
<a href="https://arxiv.org/abs/2101.08156">arxiv:2101.08156</a>
&#x1F4C8; 1 <br>
<p>Yuki Fujimoto, Kenji Fukushima, Koichi Murase</p></summary>
<p>

**Abstract:** We discuss deep learning inference for the neutron star equation of state (EoS) using the real observational data of the mass and the radius. We make a quantitative comparison between the conventional polynomial regression and the neural network approach for the EoS parametrization. For our deep learning method to incorporate uncertainties in observation, we augment the training data with noise fluctuations corresponding to observational uncertainties. Deduced EoSs can accommodate a weak first-order phase transition, and we make a histogram for likely first-order regions. We also find that our observational data augmentation has a byproduct to tame the overfitting behavior. To check the performance improved by the data augmentation, we set up a toy model as the simplest inference problem to recover a double-peaked function and monitor the validation loss. We conclude that the data augmentation could be a useful technique to evade the overfitting without tuning the neural network architecture such as inserting the dropout.

</p>
</details>

<details><summary><b>Automatic Differentiation via Effects and Handlers: An Implementation in Frank</b>
<a href="https://arxiv.org/abs/2101.08095">arxiv:2101.08095</a>
&#x1F4C8; 1 <br>
<p>Jesse Sigal</p></summary>
<p>

**Abstract:** Automatic differentiation (AD) is an important family of algorithms which enables derivative based optimization. We show that AD can be simply implemented with effects and handlers by doing so in the Frank language. By considering how our implementation behaves in Frank's operational semantics, we show how our code performs the dynamic creation of programs during evaluation.

</p>
</details>

<details><summary><b>Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs Using Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2101.08074">arxiv:2101.08074</a>
&#x1F4C8; 1 <br>
<p>Chao Yan, Xiaojia Xiang, Chang Wang, Zhen Lan</p></summary>
<p>

**Abstract:** Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is still a challenge due to kinematic complexity and environmental uncertainty. In this paper, we deal with the decentralized flocking and collision avoidance problem through deep reinforcement learning (DRL). Specifically, we formulate a decentralized DRL-based decision making framework from the perspective of every follower, where a collision avoidance mechanism is integrated into the flocking controller. Then, we propose a novel reinforcement learning algorithm PS-CACER for training a shared control policy for all the followers. Besides, we design a plug-n-play embedding module based on convolutional neural networks and the attention mechanism. As a result, the variable-length system state can be encoded into a fixed-length embedding vector, which makes the learned DRL policy independent with the number and the order of followers. Finally, numerical simulation results demonstrate the effectiveness of the proposed method, and the learned policies can be directly transferred to semi-physical simulation without any parameter finetuning.

</p>
</details>

<details><summary><b>NEMR: Network Embedding on Metric of Relation</b>
<a href="https://arxiv.org/abs/2101.08020">arxiv:2101.08020</a>
&#x1F4C8; 1 <br>
<p>Luodi Xie, Hong Shen, Jiaxin Ren</p></summary>
<p>

**Abstract:** Network embedding maps the nodes of a given network into a low-dimensional space such that the semantic similarities among the nodes can be effectively inferred. Most existing approaches use inner-product of node embedding to measure the similarity between nodes leading to the fact that they lack the capacity to capture complex relationships among nodes. Besides, they take the path in the network just as structural auxiliary information when inferring node embeddings, while paths in the network are formed with rich user informations which are semantically relevant and cannot be ignored. In this paper, We propose a novel method called Network Embedding on the Metric of Relation, abbreviated as NEMR, which can learn the embeddings of nodes in a relational metric space efficiently. First, our NEMR models the relationships among nodes in a metric space with deep learning methods including variational inference that maps the relationship of nodes to a gaussian distribution so as to capture the uncertainties. Secondly, our NEMR considers not only the equivalence of multiple-paths but also the natural order of a single-path when inferring embeddings of nodes, which makes NEMR can capture the multiple relationships among nodes since multiple paths contain rich user information, e.g., age, hobby and profession. Experimental results on several public datasets show that the NEMR outperforms the state-of-the-art methods on relevant inference tasks including link prediction and node classification.

</p>
</details>

<details><summary><b>Cell image segmentation by Feature Random Enhancement Module</b>
<a href="https://arxiv.org/abs/2101.07983">arxiv:2101.07983</a>
&#x1F4C8; 1 <br>
<p>Takamasa Ando, Kazuhiro Hotta</p></summary>
<p>

**Abstract:** It is important to extract good features using an encoder to realize semantic segmentation with high accuracy. Although loss function is optimized in training deep neural network, far layers from the layers for computing loss function are difficult to train. Skip connection is effective for this problem but there are still far layers from the loss function. In this paper, we propose the Feature Random Enhancement Module which enhances the features randomly in only training. By emphasizing the features at far layers from loss function, we can train those layers well and the accuracy was improved. In experiments, we evaluated the proposed module on two kinds of cell image datasets, and our module improved the segmentation accuracy without increasing computational cost in test phase.

</p>
</details>

<details><summary><b>MoDL-QSM: Model-based Deep Learning for Quantitative Susceptibility Mapping</b>
<a href="https://arxiv.org/abs/2101.08413">arxiv:2101.08413</a>
&#x1F4C8; 0 <br>
<p>Ruimin Feng, Jiayi Zhao, He Wang, Baofeng Yang, Jie Feng, Yuting Shi, Ming Zhang, Chunlei Liu, Yuyao Zhang, Jie Zhuang, Hongjiang Wei</p></summary>
<p>

**Abstract:** Quantitative susceptibility mapping (QSM) has demonstrated great potential in quantifying tissue susceptibility in various brain diseases. However, the intrinsic ill-posed inverse problem relating the tissue phase to the underlying susceptibility distribution affects the accuracy for quantifying tissue susceptibility. Recently, deep learning has shown promising results to improve accuracy by reducing the streaking artifacts. However, there exists a mismatch between the observed phase and the theoretical forward phase estimated by the susceptibility label. In this study, we proposed a model-based deep learning architecture that followed the STI (susceptibility tensor imaging) physical model, referred to as MoDL-QSM. Specifically, MoDL-QSM accounts for the relationship between STI-derived phase contrast induced by the susceptibility tensor terms (ki13,ki23,ki33) and the acquired single-orientation phase. The convolution neural networks are embedded into the physical model to learn a regularization term containing prior information. ki33 and phase induced by ki13 and ki23 terms were used as the labels for network training. Quantitative evaluation metrics (RSME, SSIM, and HFEN) were compared with recently developed deep learning QSM methods. The results showed that MoDL-QSM achieved superior performance, demonstrating its potential for future applications.

</p>
</details>

<details><summary><b>A Survey on Ensemble Learning under the Era of Deep Learning</b>
<a href="https://arxiv.org/abs/2101.08387">arxiv:2101.08387</a>
&#x1F4C8; 0 <br>
<p>Yongquan Yang, Haijun Lv, Ning Chen</p></summary>
<p>

**Abstract:** Due to the dominant position of deep learning (mostly deep neural networks) in various artificial intelligence applications, recently, ensemble learning based on deep neural networks (ensemble deep learning) has shown significant performances in improving the generalization of learning system. However, since modern deep neural networks usually have millions to billions of parameters, the time and space overheads for training multiple base deep learners and testing with the ensemble deep learner are far greater than that of traditional ensemble learning. Though several algorithms of fast ensemble deep learning have been proposed to promote the deployment of ensemble deep learning in some applications, further advances still need to be made for many applications in specific fields, where the developing time and computing resources are usually restricted or the data to be processed is of large dimensionality. An urgent problem needs to be solved is how to take the significant advantages of ensemble deep learning while reduce the required time and space overheads so that many more applications in specific fields can benefit from it. For the alleviation of this problem, it is essential to know about how ensemble learning has developed under the era of deep learning. Thus, in this article, we present discussions focusing on data analyses of published works, methodologies, recent advances and unattainability of traditional ensemble learning and ensemble deep learning. We hope this article will be helpful to realize the technical challenges faced by future developments of ensemble learning under the era of deep learning.

</p>
</details>


{% endraw %}
Prev: [2021.01.19]({{ '/2021/01/19/2021.01.19.html' | relative_url }})  Next: [2021.01.21]({{ '/2021/01/21/2021.01.21.html' | relative_url }})