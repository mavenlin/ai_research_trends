Prev: [2022.09.11]({{ '/2022/09/11/2022.09.11.html' | relative_url }})  Next: [2022.09.13]({{ '/2022/09/13/2022.09.13.html' | relative_url }})
{% raw %}
## Summary for 2022-09-12, created on 2022-09-19


<details><summary><b>Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation</b>
<a href="https://arxiv.org/abs/2209.05451">arxiv:2209.05451</a>
&#x1F4C8; 339 <br>
<p>Mohit Shridhar, Lucas Manuelli, Dieter Fox</p></summary>
<p>

**Abstract:** Transformers have revolutionized vision and natural language processing with their ability to scale with large datasets. But in robotic manipulation, data is both limited and expensive. Can we still benefit from Transformers with the right problem formulation? We investigate this question with PerAct, a language-conditioned behavior-cloning agent for multi-task 6-DoF manipulation. PerAct encodes language goals and RGB-D voxel observations with a Perceiver Transformer, and outputs discretized actions by "detecting the next best voxel action". Unlike frameworks that operate on 2D images, the voxelized observation and action space provides a strong structural prior for efficiently learning 6-DoF policies. With this formulation, we train a single multi-task Transformer for 18 RLBench tasks (with 249 variations) and 7 real-world tasks (with 18 variations) from just a few demonstrations per task. Our results show that PerAct significantly outperforms unstructured image-to-action agents and 3D ConvNet baselines for a wide range of tabletop tasks.

</p>
</details>

<details><summary><b>GenLoco: Generalized Locomotion Controllers for Quadrupedal Robots</b>
<a href="https://arxiv.org/abs/2209.05309">arxiv:2209.05309</a>
&#x1F4C8; 117 <br>
<p>Gilbert Feng, Hongbo Zhang, Zhongyu Li, Xue Bin Peng, Bhuvan Basireddy, Linzhu Yue, Zhitao Song, Lizhi Yang, Yunhui Liu, Koushil Sreenath, Sergey Levine</p></summary>
<p>

**Abstract:** Recent years have seen a surge in commercially-available and affordable quadrupedal robots, with many of these platforms being actively used in research and industry. As the availability of legged robots grows, so does the need for controllers that enable these robots to perform useful skills. However, most learning-based frameworks for controller development focus on training robot-specific controllers, a process that needs to be repeated for every new robot. In this work, we introduce a framework for training generalized locomotion (GenLoco) controllers for quadrupedal robots. Our framework synthesizes general-purpose locomotion controllers that can be deployed on a large variety of quadrupedal robots with similar morphologies. We present a simple but effective morphology randomization method that procedurally generates a diverse set of simulated robots for training. We show that by training a controller on this large set of simulated robots, our models acquire more general control strategies that can be directly transferred to novel simulated and real-world robots with diverse morphologies, which were not observed during training.

</p>
</details>

<details><summary><b>Statistical Learning Theory for Control: A Finite Sample Perspective</b>
<a href="https://arxiv.org/abs/2209.05423">arxiv:2209.05423</a>
&#x1F4C8; 93 <br>
<p>Anastasios Tsiamis, Ingvar Ziemann, Nikolai Matni, George J. Pappas</p></summary>
<p>

**Abstract:** This tutorial survey provides an overview of recent non-asymptotic advances in statistical learning theory as relevant to control and system identification. While there has been substantial progress across all areas of control, the theory is most well-developed when it comes to linear system identification and learning for the linear quadratic regulator, which are the focus of this manuscript. From a theoretical perspective, much of the labor underlying these advances has been in adapting tools from modern high-dimensional statistics and learning theory. While highly relevant to control theorists interested in integrating tools from machine learning, the foundational material has not always been easily accessible. To remedy this, we provide a self-contained presentation of the relevant material, outlining all the key ideas and the technical machinery that underpin recent results. We also present a number of open problems and future directions.

</p>
</details>

<details><summary><b>Soft Diffusion: Score Matching for General Corruptions</b>
<a href="https://arxiv.org/abs/2209.05442">arxiv:2209.05442</a>
&#x1F4C8; 52 <br>
<p>Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alexandros G. Dimakis, Peyman Milanfar</p></summary>
<p>

**Abstract:** We define a broader family of corruption processes that generalizes previously known diffusion models. To reverse these general diffusions, we propose a new objective called Soft Score Matching that provably learns the score function for any linear corruption process and yields state of the art results for CelebA. Soft Score Matching incorporates the degradation process in the network and trains the model to predict a clean image that after corruption matches the diffused observation. We show that our objective learns the gradient of the likelihood under suitable regularity conditions for the family of corruption processes. We further develop a principled way to select the corruption levels for general diffusion processes and a novel sampling method that we call Momentum Sampler. We evaluate our framework with the corruption being Gaussian Blur and low magnitude additive noise. Our method achieves state-of-the-art FID score $1.85$ on CelebA-64, outperforming all previous linear diffusion models. We also show significant computational benefits compared to vanilla denoising diffusion.

</p>
</details>

<details><summary><b>Blurring Diffusion Models</b>
<a href="https://arxiv.org/abs/2209.05557">arxiv:2209.05557</a>
&#x1F4C8; 49 <br>
<p>Emiel Hoogeboom, Tim Salimans</p></summary>
<p>

**Abstract:** Recently, Rissanen et al., (2022) have presented a new type of diffusion process for generative modeling based on heat dissipation, or blurring, as an alternative to isotropic Gaussian diffusion. Here, we show that blurring can equivalently be defined through a Gaussian diffusion process with non-isotropic noise. In making this connection, we bridge the gap between inverse heat dissipation and denoising diffusion, and we shed light on the inductive bias that results from this modeling choice. Finally, we propose a generalized class of diffusion models that offers the best of both standard Gaussian denoising diffusion and inverse heat dissipation, which we call Blurring Diffusion Models.

</p>
</details>

<details><summary><b>On the Factory Floor: ML Engineering for Industrial-Scale Ads Recommendation Models</b>
<a href="https://arxiv.org/abs/2209.05310">arxiv:2209.05310</a>
&#x1F4C8; 42 <br>
<p>Rohan Anil, Sandra Gadanho, Da Huang, Nijith Jacob, Zhuoshu Li, Dong Lin, Todd Phillips, Cristina Pop, Kevin Regan, Gil I. Shamir, Rakesh Shivanna, Qiqi Yan</p></summary>
<p>

**Abstract:** For industrial-scale advertising systems, prediction of ad click-through rate (CTR) is a central problem. Ad clicks constitute a significant class of user engagements and are often used as the primary signal for the usefulness of ads to users. Additionally, in cost-per-click advertising systems where advertisers are charged per click, click rate expectations feed directly into value estimation. Accordingly, CTR model development is a significant investment for most Internet advertising companies. Engineering for such problems requires many machine learning (ML) techniques suited to online learning that go well beyond traditional accuracy improvements, especially concerning efficiency, reproducibility, calibration, credit attribution. We present a case study of practical techniques deployed in Google's search ads CTR model. This paper provides an industry case study highlighting important areas of current ML research and illustrating how impactful new ML methods are evaluated and made useful in a large-scale industrial setting.

</p>
</details>

<details><summary><b>The Mori-Zwanzig formulation of deep learning</b>
<a href="https://arxiv.org/abs/2209.05544">arxiv:2209.05544</a>
&#x1F4C8; 41 <br>
<p>Daniele Venturi, Xiantao Li</p></summary>
<p>

**Abstract:** We develop a new formulation of deep learning based on the Mori-Zwanzig (MZ) formalism of irreversible statistical mechanics. The new formulation is built upon the well-known duality between deep neural networks and discrete stochastic dynamical systems, and it allows us to directly propagate quantities of interest (conditional expectations and probability density functions) forward and backward through the network by means of exact linear operator equations. Such new equations can be used as a starting point to develop new effective parameterizations of deep neural networks, and provide a new framework to study deep-learning via operator theoretic methods. The proposed MZ formulation of deep learning naturally introduces a new concept, i.e., the memory of the neural network, which plays a fundamental role in low-dimensional modeling and parameterization. By using the theory of contraction mappings, we develop sufficient conditions for the memory of the neural network to decay with the number of layers. This allows us to rigorously transform deep networks into shallow ones, e.g., by reducing the number of neurons per layer (using projection operators), or by reducing the total number of layers (using the decaying property of the memory operator).

</p>
</details>

<details><summary><b>Bias Challenges in Counterfactual Data Augmentation</b>
<a href="https://arxiv.org/abs/2209.05104">arxiv:2209.05104</a>
&#x1F4C8; 40 <br>
<p>S Chandra Mouli, Yangze Zhou, Bruno Ribeiro</p></summary>
<p>

**Abstract:** Deep learning models tend not to be out-of-distribution robust primarily due to their reliance on spurious features to solve the task. Counterfactual data augmentations provide a general way of (approximately) achieving representations that are counterfactual-invariant to spurious features, a requirement for out-of-distribution (OOD) robustness. In this work, we show that counterfactual data augmentations may not achieve the desired counterfactual-invariance if the augmentation is performed by a context-guessing machine, an abstract machine that guesses the most-likely context of a given input. We theoretically analyze the invariance imposed by such counterfactual data augmentations and describe an exemplar NLP task where counterfactual data augmentation by a context-guessing machine does not lead to robust OOD classifiers.

</p>
</details>

<details><summary><b>Holistic Segmentation</b>
<a href="https://arxiv.org/abs/2209.05407">arxiv:2209.05407</a>
&#x1F4C8; 20 <br>
<p>Stefano Gasperini, Frithjof Winkelmann, Alvaro Marcos-Ramiro, Micheal Schmidt, Nassir Navab, Benjamin Busam, Federico Tombari</p></summary>
<p>

**Abstract:** As panoptic segmentation provides a prediction for every pixel in input, non-standard and unseen objects systematically lead to wrong outputs. However, in safety-critical settings, robustness against out-of-distribution samples and corner cases is crucial to avoid dangerous behaviors, such as ignoring an animal or a lost cargo on the road. Since driving datasets cannot contain enough data points to properly sample the long tail of the underlying distribution, a method must deal with unknown and unseen scenarios to be deployed safely. Previous methods targeted part of this issue, by re-identifying already seen unlabeled objects. In this work, we broaden the scope proposing holistic segmentation: a task to identify and separate unseen unknown objects into instances, without learning from unknowns, while performing panoptic segmentation of known classes. We tackle this new problem with U3HS, which first finds unknowns as highly uncertain regions, then clusters the corresponding instance-aware embeddings into individual objects. By doing so, for the first time in panoptic segmentation with unknown objects, our U3HS is not trained with unknown data, thus leaving the settings unconstrained with respect to the type of objects and allowing for a holistic scene understanding. Extensive experiments and comparisons on two public datasets, namely Cityscapes and Lost&Found as a transfer, demonstrate the effectiveness of U3HS in the challenging task of holistic segmentation, with competitive closed-set panoptic segmentation performance.

</p>
</details>

<details><summary><b>Adaptive 3D Localization of 2D Freehand Ultrasound Brain Images</b>
<a href="https://arxiv.org/abs/2209.05477">arxiv:2209.05477</a>
&#x1F4C8; 19 <br>
<p>Pak-Hei Yeung, Moska Aliasi, Monique Haak, The INTERGROWTH-21st Consortium, Weidi Xie, Ana I. L. Namburete</p></summary>
<p>

**Abstract:** Two-dimensional (2D) freehand ultrasound is the mainstay in prenatal care and fetal growth monitoring. The task of matching corresponding cross-sectional planes in the 3D anatomy for a given 2D ultrasound brain scan is essential in freehand scanning, but challenging. We propose AdLocUI, a framework that Adaptively Localizes 2D Ultrasound Images in the 3D anatomical atlas without using any external tracking sensor.. We first train a convolutional neural network with 2D slices sampled from co-aligned 3D ultrasound volumes to predict their locations in the 3D anatomical atlas. Next, we fine-tune it with 2D freehand ultrasound images using a novel unsupervised cycle consistency, which utilizes the fact that the overall displacement of a sequence of images in the 3D anatomical atlas is equal to the displacement from the first image to the last in that sequence. We demonstrate that AdLocUI can adapt to three different ultrasound datasets, acquired with different machines and protocols, and achieves significantly better localization accuracy than the baselines. AdLocUI can be used for sensorless 2D freehand ultrasound guidance by the bedside. The source code is available at https://github.com/pakheiyeung/AdLocUI.

</p>
</details>

<details><summary><b>Defense against Privacy Leakage in Federated Learning</b>
<a href="https://arxiv.org/abs/2209.05724">arxiv:2209.05724</a>
&#x1F4C8; 13 <br>
<p>Jing Wu, Munawar Hayat, Mingyi Zhou, Mehrtash Harandi</p></summary>
<p>

**Abstract:** Federated Learning (FL) provides a promising distributed learning paradigm, since it seeks to protect users privacy by not sharing their private training data. Recent research has demonstrated, however, that FL is susceptible to model inversion attacks, which can reconstruct users' private data by eavesdropping on shared gradients. Existing defense solutions cannot survive stronger attacks and exhibit a poor trade-off between privacy and performance. In this paper, we present a straightforward yet effective defense strategy based on obfuscating the gradients of sensitive data with concealing data. Specifically, we alter a few samples within a mini batch to mimic the sensitive data at the gradient levels. Using a gradient projection technique, our method seeks to obscure sensitive data without sacrificing FL performance. Our extensive evaluations demonstrate that, compared to other defenses, our technique offers the highest level of protection while preserving FL performance. Our source code is located in the repository.

</p>
</details>

<details><summary><b>Towards Multi-Lingual Visual Question Answering</b>
<a href="https://arxiv.org/abs/2209.05401">arxiv:2209.05401</a>
&#x1F4C8; 11 <br>
<p>Soravit Changpinyo, Linting Xue, Idan Szpektor, Ashish V. Thapliyal, Julien Amelot, Xi Chen, Radu Soricut</p></summary>
<p>

**Abstract:** Visual Question Answering (VQA) has been primarily studied through the lens of the English language. Yet, tackling VQA in other languages in the same manner would require considerable amount of resources. In this paper, we propose scalable solutions to multi-lingual visual question answering (mVQA), on both data and modeling fronts. We first propose a translation-based framework to mVQA data generation that requires much less human annotation efforts than the conventional approach of directly collection questions and answers. Then, we apply our framework to the multi-lingual captions in the Crossmodal-3600 dataset and develop an efficient annotation protocol to create MAVERICS-XM3600 (MaXM), a test-only VQA benchmark in 7 diverse languages. Finally, we propose an approach to unified, extensible, open-ended, and end-to-end mVQA modeling and demonstrate strong performance in 13 languages.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for Cryptocurrency Trading: Practical Approach to Address Backtest Overfitting</b>
<a href="https://arxiv.org/abs/2209.05559">arxiv:2209.05559</a>
&#x1F4C8; 10 <br>
<p>Berend Jelmer Dirk Gort, Xiao-Yang Liu, Xinghang Sun, Jiechao Gao, Shuaiyu Chen, Christina Dan Wang</p></summary>
<p>

**Abstract:** Designing profitable and reliable trading strategies is challenging in the highly volatile cryptocurrency market. Existing works applied deep reinforcement learning methods and optimistically reported increased profits in backtesting, which may suffer from the false positive issue due to overfitting. In this paper, we propose a practical approach to address backtest overfitting for cryptocurrency trading using deep reinforcement learning. First, we formulate the detection of backtest overfitting as a hypothesis test. Then, we train the DRL agents, estimate the probability of overfitting, and reject the overfitted agents, increasing the chance of good trading performance. Finally, on 10 cryptocurrencies over a testing period from 05/01/2022 to 06/27/2022 (during which the crypto market crashed two times), we show that the less overfitted deep reinforcement learning agents have a higher Sharpe ratio than that of more over-fitted agents, an equal weight strategy, and the S&P DBM Index (market benchmark), offering confidence in possible deployment to a real market.

</p>
</details>

<details><summary><b>If Influence Functions are the Answer, Then What is the Question?</b>
<a href="https://arxiv.org/abs/2209.05364">arxiv:2209.05364</a>
&#x1F4C8; 10 <br>
<p>Juhan Bae, Nathan Ng, Alston Lo, Marzyeh Ghassemi, Roger Grosse</p></summary>
<p>

**Abstract:** Influence functions efficiently estimate the effect of removing a single training data point on a model's learned parameters. While influence estimates align well with leave-one-out retraining for linear models, recent works have shown this alignment is often poor in neural networks. In this work, we investigate the specific factors that cause this discrepancy by decomposing it into five separate terms. We study the contributions of each term on a variety of architectures and datasets and how they vary with factors such as network width and training time. While practical influence function estimates may be a poor match to leave-one-out retraining for nonlinear networks, we show they are often a good approximation to a different object we term the proximal Bregman response function (PBRF). Since the PBRF can still be used to answer many of the questions motivating influence functions, such as identifying influential or mislabeled examples, our results suggest that current algorithms for influence function estimation give more informative results than previous error analyses would suggest.

</p>
</details>

<details><summary><b>Delving into the Devils of Bird's-eye-view Perception: A Review, Evaluation and Recipe</b>
<a href="https://arxiv.org/abs/2209.05324">arxiv:2209.05324</a>
&#x1F4C8; 10 <br>
<p>Hongyang Li, Chonghao Sima, Jifeng Dai, Wenhai Wang, Lewei Lu, Huijie Wang, Enze Xie, Zhiqi Li, Hanming Deng, Hao Tian, Xizhou Zhu, Li Chen, Yulu Gao, Xiangwei Geng, Jia Zeng, Yang Li, Jiazhi Yang, Xiaosong Jia, Bohan Yu, Yu Qiao, Dahua Lin, Si Liu, Junchi Yan, Jianping Shi, Ping Luo</p></summary>
<p>

**Abstract:** Learning powerful representations in bird's-eye-view (BEV) for perception tasks is trending and drawing extensive attention both from industry and academia. Conventional approaches for most autonomous driving algorithms perform detection, segmentation, tracking, etc., in a front or perspective view. As sensor configurations get more complex, integrating multi-source information from different sensors and representing features in a unified view come of vital importance. BEV perception inherits several advantages, as representing surrounding scenes in BEV is intuitive and fusion-friendly; and representing objects in BEV is most desirable for subsequent modules as in planning and/or control. The core problems for BEV perception lie in (a) how to reconstruct the lost 3D information via view transformation from perspective view to BEV; (b) how to acquire ground truth annotations in BEV grid; (c) how to formulate the pipeline to incorporate features from different sources and views; and (d) how to adapt and generalize algorithms as sensor configurations vary across different scenarios. In this survey, we review the most recent work on BEV perception and provide an in-depth analysis of different solutions. Moreover, several systematic designs of BEV approach from the industry are depicted as well. Furthermore, we introduce a full suite of practical guidebook to improve the performance of BEV perception tasks, including camera, LiDAR and fusion inputs. At last, we point out the future research directions in this area. We hope this report would shed some light on the community and encourage more research effort on BEV perception. We keep an active repository to collect the most recent work and provide a toolbox for bag of tricks at https://github.com/OpenPerceptionX/BEVPerception-Survey-Recipe.

</p>
</details>

<details><summary><b>Leveraging Large Language Models for Robot 3D Scene Understanding</b>
<a href="https://arxiv.org/abs/2209.05629">arxiv:2209.05629</a>
&#x1F4C8; 9 <br>
<p>William Chen, Siyi Hu, Rajat Talak, Luca Carlone</p></summary>
<p>

**Abstract:** Semantic 3D scene understanding is a problem of critical importance in robotics. While significant advances have been made in spatial perception, robots are still far from having the common-sense knowledge about household objects and locations of an average human. We thus investigate the use of large language models to impart common sense for scene understanding. Specifically, we introduce three paradigms for leveraging language for classifying rooms in indoor environments based on their contained objects: (i) a zero-shot approach, (ii) a feed-forward classifier approach, and (iii) a contrastive classifier approach. These methods operate on 3D scene graphs produced by modern spatial perception systems. We then analyze each approach, demonstrating notable zero-shot generalization and transfer capabilities stemming from their use of language. Finally, we show these approaches also apply to inferring building labels from contained rooms and demonstrate our zero-shot approach on a real environment. All code can be found at https://github.com/MIT-SPARK/llm_scene_understanding.

</p>
</details>

<details><summary><b>Graph Neural Modeling of Network Flows</b>
<a href="https://arxiv.org/abs/2209.05208">arxiv:2209.05208</a>
&#x1F4C8; 9 <br>
<p>Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi</p></summary>
<p>

**Abstract:** Network flow problems, which involve distributing traffic over a network such that the underlying infrastructure is used effectively, are ubiquitous in transportation and logistics. Due to the appeal of data-driven optimization, these problems have increasingly been approached using graph learning methods. Among them, the Multi-Commodity Network Flow (MCNF) problem is of particular interest given its generality, since it concerns the distribution of multiple flows (also called demands) of different sizes between several sources and sinks. The widely-used objective that we focus on is the maximum utilization of any link in the network, given traffic demands and a routing strategy.
  In this paper, we propose a novel approach based on Graph Neural Networks (GNNs) for the MCNF problem which uses distinctly parametrized message functions along each link, akin to a relational model where all edge types are unique. We show that our proposed method yields substantial gains over existing graph learning methods that constrain the routing unnecessarily. We extensively evaluate the proposed approach by means of an Internet routing case study using 17 Service Provider topologies and two flow routing schemes. We find that, in many networks, an MLP is competitive with a generic GNN that does not use our mechanism. Furthermore, we shed some light on the relationship between graph structure and the difficulty of data-driven routing of flows, an aspect that has not been considered in the existing work in the area.

</p>
</details>

<details><summary><b>Data Augmentation by Selecting Mixed Classes Considering Distance Between Classes</b>
<a href="https://arxiv.org/abs/2209.05122">arxiv:2209.05122</a>
&#x1F4C8; 9 <br>
<p>Shungo Fujii, Yasunori Ishii, Kazuki Kozuka, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi</p></summary>
<p>

**Abstract:** Data augmentation is an essential technique for improving recognition accuracy in object recognition using deep learning. Methods that generate mixed data from multiple data sets, such as mixup, can acquire new diversity that is not included in the training data, and thus contribute significantly to accuracy improvement. However, since the data selected for mixing are randomly sampled throughout the training process, there are cases where appropriate classes or data are not selected. In this study, we propose a data augmentation method that calculates the distance between classes based on class probabilities and can select data from suitable classes to be mixed in the training process. Mixture data is dynamically adjusted according to the training trend of each class to facilitate training. The proposed method is applied in combination with conventional methods for generating mixed data. Evaluation experiments show that the proposed method improves recognition performance on general and long-tailed image recognition datasets.

</p>
</details>

<details><summary><b>TruVR: Trustworthy Cybersickness Detection using Explainable Machine Learning</b>
<a href="https://arxiv.org/abs/2209.05257">arxiv:2209.05257</a>
&#x1F4C8; 8 <br>
<p>Ripan Kumar Kundu, Rifatul Islam, Prasad Calyam, Khaza Anuarul Hoque</p></summary>
<p>

**Abstract:** Cybersickness can be characterized by nausea, vertigo, headache, eye strain, and other discomforts when using virtual reality (VR) systems. The previously reported machine learning (ML) and deep learning (DL) algorithms for detecting (classification) and predicting (regression) VR cybersickness use black-box models; thus, they lack explainability. Moreover, VR sensors generate a massive amount of data, resulting in complex and large models. Therefore, having inherent explainability in cybersickness detection models can significantly improve the model's trustworthiness and provide insight into why and how the ML/DL model arrived at a specific decision. To address this issue, we present three explainable machine learning (xML) models to detect and predict cybersickness: 1) explainable boosting machine (EBM), 2) decision tree (DT), and 3) logistic regression (LR). We evaluate xML-based models with publicly available physiological and gameplay datasets for cybersickness. The results show that the EBM can detect cybersickness with an accuracy of 99.75% and 94.10% for the physiological and gameplay datasets, respectively. On the other hand, while predicting the cybersickness, EBM resulted in a Root Mean Square Error (RMSE) of 0.071 for the physiological dataset and 0.27 for the gameplay dataset. Furthermore, the EBM-based global explanation reveals exposure length, rotation, and acceleration as key features causing cybersickness in the gameplay dataset. In contrast, galvanic skin responses and heart rate are most significant in the physiological dataset. Our results also suggest that EBM-based local explanation can identify cybersickness-causing factors for individual samples. We believe the proposed xML-based cybersickness detection method can help future researchers understand, analyze, and design simpler cybersickness detection and reduction models.

</p>
</details>

<details><summary><b>Statistical Estimation of Confounded Linear MDPs: An Instrumental Variable Approach</b>
<a href="https://arxiv.org/abs/2209.05186">arxiv:2209.05186</a>
&#x1F4C8; 8 <br>
<p>Miao Lu, Wenhao Yang, Liangyu Zhang, Zhihua Zhang</p></summary>
<p>

**Abstract:** In an Markov decision process (MDP), unobservable confounders may exist and have impacts on the data generating process, so that the classic off-policy evaluation (OPE) estimators may fail to identify the true value function of the target policy. In this paper, we study the statistical properties of OPE in confounded MDPs with observable instrumental variables. Specifically, we propose a two-stage estimator based on the instrumental variables and establish its statistical properties in the confounded MDPs with a linear structure. For non-asymptotic analysis, we prove a $\mathcal{O}(n^{-1/2})$-error bound where $n$ is the number of samples. For asymptotic analysis, we prove that the two-stage estimator is asymptotically normal with a typical rate of $n^{1/2}$. To the best of our knowledge, we are the first to show such statistical results of the two-stage estimator for confounded linear MDPs via instrumental variables.

</p>
</details>

<details><summary><b>Bounding The Rademacher Complexity of Fourier Neural Operator</b>
<a href="https://arxiv.org/abs/2209.05150">arxiv:2209.05150</a>
&#x1F4C8; 8 <br>
<p>Taeyoung Kim, Myungjoo Kang</p></summary>
<p>

**Abstract:** A Fourier neural operator (FNO) is one of the physics-inspired machine learning methods. In particular, it is a neural operator. In recent times, several types of neural operators have been developed, e.g., deep operator networks, GNO, and MWTO. Compared with other models, the FNO is computationally efficient and can learn nonlinear operators between function spaces independent of a certain finite basis. In this study, we investigated the bounding of the Rademacher complexity of the FNO based on specific group norms. Using capacity based on these norms, we bound the generalization error of the FNO model. In addition, we investigated the correlation between the empirical generalization error and the proposed capacity of FNO. Based on this investigation, we gained insight into the impact of the model architecture on the generalization error and estimated the amount of information about FNO models stored in various types of capacities.

</p>
</details>

<details><summary><b>HandMime: Sign Language Fingerspelling Acquisition via Imitation Learning</b>
<a href="https://arxiv.org/abs/2209.05135">arxiv:2209.05135</a>
&#x1F4C8; 8 <br>
<p>Federico Tavella, Aphrodite Galata, Angelo Cangelosi</p></summary>
<p>

**Abstract:** Learning fine-grained movements is among the most challenging topics in robotics. This holds true especially for robotic hands. Robotic sign language acquisition or, more specifically, fingerspelling sign language acquisition in robots can be considered a specific instance of such challenge. In this paper, we propose an approach for learning dexterous motor imitation from videos examples, without the use of any additional information. We build an URDF model of a robotic hand with a single actuator for each joint. By leveraging pre-trained deep vision models, we extract the 3D pose of the hand from RGB videos. Then, using state-of-the-art reinforcement learning algorithms for motion imitation (namely, proximal policy optimisation), we train a policy to reproduce the movement extracted from the demonstrations. We identify the best set of hyperparameters to perform imitation based on a reference motion. Additionally, we demonstrate the ability of our approach to generalise over 6 different fingerspelled letters.

</p>
</details>

<details><summary><b>Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization</b>
<a href="https://arxiv.org/abs/2209.05045">arxiv:2209.05045</a>
&#x1F4C8; 8 <br>
<p>Tianyi Lin, Zeyu Zheng, Michael I. Jordan</p></summary>
<p>

**Abstract:** Nonsmooth nonconvex optimization problems broadly emerge in machine learning and business decision making, whereas two core challenges impede the development of efficient solution methods with finite-time convergence guarantee: the lack of computationally tractable optimality criterion and the lack of computationally powerful oracles. The contributions of this paper are two-fold. First, we establish the relationship between the celebrated Goldstein subdifferential~\citep{Goldstein-1977-Optimization} and uniform smoothing, thereby providing the basis and intuition for the design of gradient-free methods that guarantee the finite-time convergence to a set of Goldstein stationary points. Second, we propose the gradient-free method (GFM) and stochastic GFM for solving a class of nonsmooth nonconvex optimization problems and prove that both of them can return a $(δ,ε)$-Goldstein stationary point of a Lipschitz function $f$ at an expected convergence rate at $O(d^{3/2}δ^{-1}ε^{-4})$ where $d$ is the problem dimension. Two-phase versions of GFM and SGFM are also proposed and proven to achieve improved large-deviation results. Finally, we demonstrate the effectiveness of 2-SGFM on training ReLU neural networks with the \textsc{Minst} dataset.

</p>
</details>

<details><summary><b>Self-supervised Wide Baseline Visual Servoing via 3D Equivariance</b>
<a href="https://arxiv.org/abs/2209.05432">arxiv:2209.05432</a>
&#x1F4C8; 7 <br>
<p>Jinwook Huh, Jungseok Hong, Suveer Garg, Hyun Soo Park, Volkan Isler</p></summary>
<p>

**Abstract:** One of the challenging input settings for visual servoing is when the initial and goal camera views are far apart. Such settings are difficult because the wide baseline can cause drastic changes in object appearance and cause occlusions. This paper presents a novel self-supervised visual servoing method for wide baseline images which does not require 3D ground truth supervision. Existing approaches that regress absolute camera pose with respect to an object require 3D ground truth data of the object in the forms of 3D bounding boxes or meshes. We learn a coherent visual representation by leveraging a geometric property called 3D equivariance-the representation is transformed in a predictable way as a function of 3D transformation. To ensure that the feature-space is faithful to the underlying geodesic space, a geodesic preserving constraint is applied in conjunction with the equivariance. We design a Siamese network that can effectively enforce these two geometric properties without requiring 3D supervision. With the learned model, the relative transformation can be inferred simply by following the gradient in the learned space and used as feedback for closed-loop visual servoing. Our method is evaluated on objects from the YCB dataset, showing meaningful outperformance on a visual servoing task, or object alignment task with respect to state-of-the-art approaches that use 3D supervision. Ours yields more than 35% average distance error reduction and more than 90% success rate with 3cm error tolerance.

</p>
</details>

<details><summary><b>Action-based Early Autism Diagnosis Using Contrastive Feature Learning</b>
<a href="https://arxiv.org/abs/2209.05379">arxiv:2209.05379</a>
&#x1F4C8; 7 <br>
<p>Asha Rani, Pankaj Yadav, Yashaswi Verma</p></summary>
<p>

**Abstract:** Autism, also known as Autism Spectrum Disorder (or ASD), is a neurological disorder. Its main symptoms include difficulty in (verbal and/or non-verbal) communication, and rigid/repetitive behavior. These symptoms are often indistinguishable from a normal (control) individual, due to which this disorder remains undiagnosed in early childhood leading to delayed treatment. Since the learning curve is steep during the initial age, an early diagnosis of autism could allow to take adequate interventions at the right time, which might positively affect the growth of an autistic child. Further, the traditional methods of autism diagnosis require multiple visits to a specialized psychiatrist, however this process can be time-consuming. In this paper, we present a learning based approach to automate autism diagnosis using simple and small action video clips of subjects. This task is particularly challenging because the amount of annotated data available is small, and the variations among samples from the two categories (ASD and control) are generally indistinguishable. This is also evident from poor performance of a binary classifier learned using the cross-entropy loss on top of a baseline encoder. To address this, we adopt contrastive feature learning in both self supervised and supervised learning frameworks, and show that these can lead to a significant increase in the prediction accuracy of a binary classifier on this task. We further validate this by conducting thorough experimental analyses under different set-ups on two publicly available datasets.

</p>
</details>

<details><summary><b>Identification of Cognitive Workload during Surgical Tasks with Multimodal Deep Learning</b>
<a href="https://arxiv.org/abs/2209.06208">arxiv:2209.06208</a>
&#x1F4C8; 6 <br>
<p>Kaizhe Jin, Adrian Rubio-Solis, Ravik Nain, Tochukwu Onyeogulu, Amirul Islam, Salman Khan, Tochukwu Onyeogulu, Amirul Islam, Salman Khan, Izzeddin Teeti, Fabio Cuzzolin, George Mylonas</p></summary>
<p>

**Abstract:** In operating Rooms (ORs), activities are usually different from other typical working environments. In particular, surgeons are frequently exposed to multiple psycho-organizational constraints that may cause negative repercussions on their health and performance. This is commonly attributed to an increase in the associated Cognitive Workload (CWL) that results from dealing with unexpected and repetitive tasks, as well as large amounts of information and potentially risky cognitive overload. In this paper, a cascade of two machine learning approaches is suggested for the multimodal recognition of CWL in a number of four different surgical tasks. First, a model based on the concept of transfer learning is used to identify if a surgeon is experiencing any CWL. Secondly, a Convolutional Neural Network (CNN) uses this information to identify different types of CWL associated to each surgical task. The suggested multimodal approach consider adjacent signals from electroencephalogram (EEG), functional near-infrared spectroscopy (fNIRS) and pupil eye diameter. The concatenation of signals allows complex correlations in terms of time (temporal) and channel location (spatial). Data collection is performed by a Multi-sensing AI Environment for Surgical Task $\&$ Role Optimisation platform (MAESTRO) developed at HARMS Lab. To compare the performance of the proposed methodology, a number of state-of-art machine learning techniques have been implemented. The tests show that the proposed model has a precision of 93%.

</p>
</details>

<details><summary><b>Online Continual Learning via the Meta-learning Update with Multi-scale Knowledge Distillation and Data Augmentation</b>
<a href="https://arxiv.org/abs/2209.06107">arxiv:2209.06107</a>
&#x1F4C8; 6 <br>
<p>Ya-nan Han, Jian-wei Liu</p></summary>
<p>

**Abstract:** Continual learning aims to rapidly and continually learn the current task from a sequence of tasks.
  Compared to other kinds of methods, the methods based on experience replay have shown great advantages to overcome catastrophic forgetting. One common limitation of this method is the data imbalance between the previous and current tasks, which would further aggravate forgetting. Moreover, how to effectively address the stability-plasticity dilemma in this setting is also an urgent problem to be solved. In this paper, we overcome these challenges by proposing a novel framework called Meta-learning update via Multi-scale Knowledge Distillation and Data Augmentation (MMKDDA). Specifically, we apply multiscale knowledge distillation to grasp the evolution of long-range and short-range spatial relationships at different feature levels to alleviate the problem of data imbalance. Besides, our method mixes the samples from the episodic memory and current task in the online continual training procedure, thus alleviating the side influence due to the change of probability distribution. Moreover, we optimize our model via the meta-learning update resorting to the number of tasks seen previously, which is helpful to keep a better balance between stability and plasticity. Finally, our experimental evaluation on four benchmark datasets shows the effectiveness of the proposed MMKDDA framework against other popular baselines, and ablation studies are also conducted to further analyze the role of each component in our framework.

</p>
</details>

<details><summary><b>Deep Convolutional Pooling Transformer for Deepfake Detection</b>
<a href="https://arxiv.org/abs/2209.05299">arxiv:2209.05299</a>
&#x1F4C8; 6 <br>
<p>Tianyi Wang, Harry Cheng, Kam Pui Chow, Liqiang Nie</p></summary>
<p>

**Abstract:** Recently, Deepfake has drawn considerable public attention due to security and privacy concerns in social media digital forensics. As the wildly spreading Deepfake videos on the Internet become more realistic, traditional detection techniques have failed in distinguishing between the real and fake. Most existing deep learning methods mainly focus on local features and relations within the face image using convolutional neural networks as a backbone. However, local features and relations are insufficient for model training to learn enough general information for Deepfake detection. Therefore, the existing Deepfake detection methods have reached a bottleneck to further improving the detection performance. To address this issue, we propose a deep convolutional Transformer to incorporate the decisive image features both locally and globally. Specifically, we apply convolutional pooling and re-attention to enrich the extracted features and enhance the efficacy. Moreover, we employ the barely discussed image keyframes in model training for performance improvement and visualize the feature quantity gap between the key and normal image frames caused by video compression. We finally illustrate the transferability with extensive experiments on several Deepfake benchmark datasets. The proposed solution consistently outperforms several state-of-the-art baselines on both within- and cross-dataset experiments.

</p>
</details>

<details><summary><b>TrackletMapper: Ground Surface Segmentation and Mapping from Traffic Participant Trajectories</b>
<a href="https://arxiv.org/abs/2209.05247">arxiv:2209.05247</a>
&#x1F4C8; 6 <br>
<p>Jannik Zürn, Sebastian Weber, Wolfram Burgard</p></summary>
<p>

**Abstract:** Robustly classifying ground infrastructure such as roads and street crossings is an essential task for mobile robots operating alongside pedestrians. While many semantic segmentation datasets are available for autonomous vehicles, models trained on such datasets exhibit a large domain gap when deployed on robots operating in pedestrian spaces. Manually annotating images recorded from pedestrian viewpoints is both expensive and time-consuming. To overcome this challenge, we propose TrackletMapper, a framework for annotating ground surface types such as sidewalks, roads, and street crossings from object tracklets without requiring human-annotated data. To this end, we project the robot ego-trajectory and the paths of other traffic participants into the ego-view camera images, creating sparse semantic annotations for multiple types of ground surfaces from which a ground segmentation model can be trained. We further show that the model can be self-distilled for additional performance benefits by aggregating a ground surface map and projecting it into the camera images, creating a denser set of training annotations compared to the sparse tracklet annotations. We qualitatively and quantitatively attest our findings on a novel large-scale dataset for mobile robots operating in pedestrian areas. Code and dataset will be made available at http://trackletmapper.cs.uni-freiburg.de.

</p>
</details>

<details><summary><b>Prototypical few-shot segmentation for cross-institution male pelvic structures with spatial registration</b>
<a href="https://arxiv.org/abs/2209.05160">arxiv:2209.05160</a>
&#x1F4C8; 6 <br>
<p>Yiwen Li, Yunguan Fu, Iani Gayo, Qianye Yang, Zhe Min, Shaheer Saeed, Wen Yan, Yipei Wang, J. Alison Noble, Mark Emberton, Matthew J. Clarkson, Henkjan Huisman, Dean Barratt, Victor Adrian Prisacariu, Yipeng Hu</p></summary>
<p>

**Abstract:** The prowess that makes few-shot learning desirable in medical image analysis is the efficient use of the support image data, which are labelled to classify or segment new classes, a task that otherwise requires substantially more training images and expert annotations. This work describes a fully 3D prototypical few-shot segmentation algorithm, such that the trained networks can be effectively adapted to clinically interesting structures that are absent in training, using only a few labelled images from a different institute. First, to compensate for the widely recognised spatial variability between institutions in episodic adaptation of novel classes, a novel spatial registration mechanism is integrated into prototypical learning, consisting of a segmentation head and an spatial alignment module. Second, to assist the training with observed imperfect alignment, support mask conditioning module is proposed to further utilise the annotation available from the support images. Extensive experiments are presented in an application of segmenting eight anatomical structures important for interventional planning, using a data set of 589 pelvic T2-weighted MR images, acquired at seven institutes. The results demonstrate the efficacy in each of the 3D formulation, the spatial registration, and the support mask conditioning, all of which made positive contributions independently or collectively. Compared with the previously proposed 2D alternatives, the few-shot segmentation performance was improved with statistical significance, regardless whether the support data come from the same or different institutes.

</p>
</details>

<details><summary><b>Reproducibility in machine learning for medical imaging</b>
<a href="https://arxiv.org/abs/2209.05097">arxiv:2209.05097</a>
&#x1F4C8; 6 <br>
<p>Olivier Colliot, Elina Thibeau-Sutre, Ninon Burgos</p></summary>
<p>

**Abstract:** Reproducibility is a cornerstone of science, as the replication of findings is the process through which they become knowledge. It is widely considered that many fields of science are undergoing a reproducibility crisis. This has led to the publications of various guidelines in order to improve research reproducibility.
  This didactic chapter intends at being an introduction to reproducibility for researchers in the field of machine learning for medical imaging. We first distinguish between different types of reproducibility. For each of them, we aim at defining it, at describing the requirements to achieve it and at discussing its utility. The chapter ends with a discussion on the benefits of reproducibility and with a plea for a non-dogmatic approach to this concept and its implementation in research practice.

</p>
</details>

<details><summary><b>Finite Sample Guarantees for Distributed Online Parameter Estimation with Communication Costs</b>
<a href="https://arxiv.org/abs/2209.06678">arxiv:2209.06678</a>
&#x1F4C8; 5 <br>
<p>Lei Xin, George Chiu, Shreyas Sundaram</p></summary>
<p>

**Abstract:** We study the problem of estimating an unknown parameter in a distributed and online manner. Existing work on distributed online learning typically either focuses on asymptotic analysis, or provides bounds on regret. However, these results may not directly translate into bounds on the error of the learned model after a finite number of time-steps. In this paper, we propose a distributed online estimation algorithm which enables each agent in a network to improve its estimation accuracy by communicating with neighbors. We provide non-asymptotic bounds on the estimation error, leveraging the statistical properties of the underlying model. Our analysis demonstrates a trade-off between estimation error and communication costs. Further, our analysis allows us to determine a time at which the communication can be stopped (due to the costs associated with communications), while meeting a desired estimation accuracy. We also provide a numerical example to validate our results.

</p>
</details>

<details><summary><b>Model interpretation using improved local regression with variable importance</b>
<a href="https://arxiv.org/abs/2209.05371">arxiv:2209.05371</a>
&#x1F4C8; 5 <br>
<p>Gilson Y. Shimizu, Rafael Izbicki, Andre C. P. L. F. de Carvalho</p></summary>
<p>

**Abstract:** A fundamental question on the use of ML models concerns the explanation of their predictions for increasing transparency in decision-making. Although several interpretability methods have emerged, some gaps regarding the reliability of their explanations have been identified. For instance, most methods are unstable (meaning that they give very different explanations with small changes in the data), and do not cope well with irrelevant features (that is, features not related to the label). This article introduces two new interpretability methods, namely VarImp and SupClus, that overcome these issues by using local regressions fits with a weighted distance that takes into account variable importance. Whereas VarImp generates explanations for each instance and can be applied to datasets with more complex relationships, SupClus interprets clusters of instances with similar explanations and can be applied to simpler datasets where clusters can be found. We compare our methods with state-of-the art approaches and show that it yields better explanations according to several metrics, particularly in high-dimensional problems with irrelevant features, as well as when the relationship between features and target is non-linear.

</p>
</details>

<details><summary><b>Analysis and Comparison of Classification Metrics</b>
<a href="https://arxiv.org/abs/2209.05355">arxiv:2209.05355</a>
&#x1F4C8; 5 <br>
<p>Luciana Ferrer</p></summary>
<p>

**Abstract:** A number of different performance metrics are commonly used in the machine learning literature for classification systems that output categorical decisions. Some of the most common ones are accuracy, total error (one minus accuracy), balanced accuracy, balanced total error (one minus balanced accuracy), F-score, and Matthews correlation coefficient (MCC). In this document, we review the definition of these metrics and compare them with the expected cost (EC), a metric introduced in every statistical learning course but rarely used in the machine learning literature. We show that the empirical estimate of the EC is a generalized version of both the total error and balanced total error. Further, we show its relation with F-score and MCC and argue that EC is superior to them, being more general, simpler, intuitive and well motivated. We highlight some issues with the F-score and the MCC that make them suboptimal metrics. While not explained in the current version of this manuscript, where we focus exclusively on metrics that are computed over hard decisions, the EC has the additional advantage of being a great tool to measure calibration of a system's scores and allows users to make optimal decisions given a set of posteriors for each class. We leave that discussion for a future version of this manuscript.

</p>
</details>

<details><summary><b>MetaNetwork: A Task-agnostic Network Parameters Generation Framework for Improving Device Model Generalization</b>
<a href="https://arxiv.org/abs/2209.05227">arxiv:2209.05227</a>
&#x1F4C8; 5 <br>
<p>Zheqi Lv, Feng Wang, Kun Kuang, Yongwei Wang, Zhengyu Chen, Tao Shen, Hongxia Yang, Fei Wu</p></summary>
<p>

**Abstract:** Deploying machine learning models on mobile devices has gained increasing attention. To tackle the model generalization problem with the limitations of hardware resources on the device, the device model needs to be lightweight by techniques such as model compression from the cloud model. However, the major obstacle to improve the device model generalization is the distribution shift between the data of cloud and device models, since the data distribution on device model often changes over time (e.g., users might have different preferences in recommendation system). Although real-time fine-tuning and distillation method take this situation into account, these methods require on-device training, which are practically infeasible due to the low computational power and a lack of real-time labeled samples on the device.
  In this paper, we propose a novel task-agnostic framework, named MetaNetwork, for generating adaptive device model parameters from cloud without on-device training. Specifically, our MetaNetwork is deployed on cloud and consists of MetaGenerator and MetaStabilizer modules. The MetaGenerator is designed to learn a mapping function from samples to model parameters, and it can generate and deliver the adaptive parameters to the device based on samples uploaded from the device to the cloud. The MetaStabilizer aims to reduce the oscillation of the MetaGenerator, accelerate the convergence and improve the model performance during both training and inference. We evaluate our method on two tasks with three datasets. Extensive experiments show that MetaNetwork can achieve competitive performances in different modalities.

</p>
</details>

<details><summary><b>A Note on the Efficient Evaluation of PAC-Bayes Bounds</b>
<a href="https://arxiv.org/abs/2209.05188">arxiv:2209.05188</a>
&#x1F4C8; 5 <br>
<p>Felix Biggs</p></summary>
<p>

**Abstract:** When utilising PAC-Bayes theory for risk certification, it is usually necessary to estimate and bound the Gibbs risk of the PAC-Bayes posterior. Many works in the literature employ a method for this which requires a large number of passes of the dataset, incurring high computational cost. This manuscript presents a very general alternative which makes computational savings on the order of the dataset size.

</p>
</details>

<details><summary><b>On topological data analysis for structural dynamics: an introduction to persistent homology</b>
<a href="https://arxiv.org/abs/2209.05134">arxiv:2209.05134</a>
&#x1F4C8; 5 <br>
<p>Tristan Gowdridge, Nikolaos Dervilis, Keith Worden</p></summary>
<p>

**Abstract:** Topological methods can provide a way of proposing new metrics and methods of scrutinising data, that otherwise may be overlooked. In this work, a method of quantifying the shape of data, via a topic called topological data analysis will be introduced. The main tool within topological data analysis (TDA) is persistent homology. Persistent homology is a method of quantifying the shape of data over a range of length scales. The required background and a method of computing persistent homology is briefly discussed in this work. Ideas from topological data analysis are then used for nonlinear dynamics to analyse some common attractors, by calculating their embedding dimension, and then to assess their general topologies. A method will also be proposed, that uses topological data analysis to determine the optimal delay for a time-delay embedding. TDA will also be applied to a Z24 Bridge case study in structural health monitoring, where it will be used to scrutinise different data partitions, classified by the conditions at which the data were collected. A metric, from topological data analysis, is used to compare data between the partitions. The results presented demonstrate that the presence of damage alters the manifold shape more significantly than the effects present from temperature.

</p>
</details>

<details><summary><b>SELTO: Sample-Efficient Learned Topology Optimization</b>
<a href="https://arxiv.org/abs/2209.05098">arxiv:2209.05098</a>
&#x1F4C8; 5 <br>
<p>Sören Dittmer, David Erzmann, Henrik Harms, Peter Maass</p></summary>
<p>

**Abstract:** We present a sample-efficient deep learning strategy for topology optimization. Our end-to-end approach is supervised and includes physics-based preprocessing and equivariant networks. We analyze how different components of our deep learning pipeline influence the number of required training samples via a large-scale comparison. The results demonstrate that including physical concepts not only drastically improves the sample efficiency but also the predictions' physical correctness. Finally, we publish two topology optimization datasets containing problems and corresponding ground truth solutions. We are confident that these datasets will improve comparability and future progress in the field.

</p>
</details>

<details><summary><b>Predicting the Next Action by Modeling the Abstract Goal</b>
<a href="https://arxiv.org/abs/2209.05044">arxiv:2209.05044</a>
&#x1F4C8; 5 <br>
<p>Debaditya Roy, Basura Fernando</p></summary>
<p>

**Abstract:** The problem of anticipating human actions is an inherently uncertain one. However, we can reduce this uncertainty if we have a sense of the goal that the actor is trying to achieve. Here, we present an action anticipation model that leverages goal information for the purpose of reducing the uncertainty in future predictions. Since we do not possess goal information or the observed actions during inference, we resort to visual representation to encapsulate information about both actions and goals. Through this, we derive a novel concept called abstract goal which is conditioned on observed sequences of visual features for action anticipation. We design the abstract goal as a distribution whose parameters are estimated using a variational recurrent network. We sample multiple candidates for the next action and introduce a goal consistency measure to determine the best candidate that follows from the abstract goal. Our method obtains impressive results on the very challenging Epic-Kitchens55 (EK55), EK100, and EGTEA Gaze+ datasets. We obtain absolute improvements of +13.69, +11.24, and +5.19 for Top-1 verb, Top-1 noun, and Top-1 action anticipation accuracy respectively over prior state-of-the-art methods for seen kitchens (S1) of EK55. Similarly, we also obtain significant improvements in the unseen kitchens (S2) set for Top-1 verb (+10.75), noun (+5.84) and action (+2.87) anticipation. Similar trend is observed for EGTEA Gaze+ dataset, where absolute improvement of +9.9, +13.1 and +6.8 is obtained for noun, verb, and action anticipation. It is through the submission of this paper that our method is currently the new state-of-the-art for action anticipation in EK55 and EGTEA Gaze+ https://competitions.codalab.org/competitions/20071#results Code available at https://github.com/debadityaroy/Abstract_Goal

</p>
</details>

<details><summary><b>VL-Taboo: An Analysis of Attribute-based Zero-shot Capabilities of Vision-Language Models</b>
<a href="https://arxiv.org/abs/2209.06103">arxiv:2209.06103</a>
&#x1F4C8; 4 <br>
<p>Felix Vogel, Nina Shvetsova, Leonid Karlinsky, Hilde Kuehne</p></summary>
<p>

**Abstract:** Vision-language models trained on large, randomly collected data had significant impact in many areas since they appeared. But as they show great performance in various fields, such as image-text-retrieval, their inner workings are still not fully understood. The current work analyses the true zero-shot capabilities of those models. We start from the analysis of the training corpus assessing to what extent (and which of) the test classes are really zero-shot and how this correlates with individual classes performance. We follow up with the analysis of the attribute-based zero-shot learning capabilities of these models, evaluating how well this classical zero-shot notion emerges from large-scale webly supervision. We leverage the recently released LAION400M data corpus as well as the publicly available pretrained models of CLIP, OpenCLIP, and FLAVA, evaluating the attribute-based zero-shot capabilities on CUB and AWA2 benchmarks. Our analysis shows that: (i) most of the classes in popular zero-shot benchmarks are observed (a lot) during pre-training; (ii) zero-shot performance mainly comes out of models' capability of recognizing class labels, whenever they are present in the text, and a significantly lower performing capability of attribute-based zeroshot learning is only observed when class labels are not used; (iii) the number of the attributes used can have a significant effect on performance, and can easily cause a significant performance decrease.

</p>
</details>

<details><summary><b>Driving Safety Prediction and Safe Route Mapping Using In-vehicle and Roadside Data</b>
<a href="https://arxiv.org/abs/2209.05604">arxiv:2209.05604</a>
&#x1F4C8; 4 <br>
<p>Yufei Huang, Mohsen Jafari, Peter Jin</p></summary>
<p>

**Abstract:** Risk assessment of roadways is commonly practiced based on historical crash data. Information on driver behaviors and real-time traffic situations is sometimes missing. In this paper, the Safe Route Mapping (SRM) model, a methodology for developing dynamic risk heat maps of roadways, is extended to consider driver behaviors when making predictions. An Android App is designed to gather drivers' information and upload it to a server. On the server, facial recognition extracts drivers' data, such as facial landmarks, gaze directions, and emotions. The driver's drowsiness and distraction are detected, and driving performance is evaluated. Meanwhile, dynamic traffic information is captured by a roadside camera and uploaded to the same server. A longitudinal-scanline-based arterial traffic video analytics is applied to recognize vehicles from the video to build speed and trajectory profiles. Based on these data, a LightGBM model is introduced to predict conflict indices for drivers in the next one or two seconds. Then, multiple data sources, including historical crash counts and predicted traffic conflict indicators, are combined using a Fuzzy logic model to calculate risk scores for road segments. The proposed SRM model is illustrated using data collected from an actual traffic intersection and a driving simulation platform. The prediction results show that the model is accurate, and the added driver behavior features will improve the model's performance. Finally, risk heat maps are generated for visualization purposes. The authorities can use the dynamic heat map to designate safe corridors and dispatch law enforcement and drivers for early warning and trip planning.

</p>
</details>

<details><summary><b>Towards More Efficient Data Valuation in Healthcare Federated Learning using Ensembling</b>
<a href="https://arxiv.org/abs/2209.05424">arxiv:2209.05424</a>
&#x1F4C8; 4 <br>
<p>Sourav Kumar, A. Lakshminarayanan, Ken Chang, Feri Guretno, Ivan Ho Mien, Jayashree Kalpathy-Cramer, Pavitra Krishnaswamy, Praveer Singh</p></summary>
<p>

**Abstract:** Federated Learning (FL) wherein multiple institutions collaboratively train a machine learning model without sharing data is becoming popular. Participating institutions might not contribute equally, some contribute more data, some better quality data or some more diverse data. To fairly rank the contribution of different institutions, Shapley value (SV) has emerged as the method of choice. Exact SV computation is impossibly expensive, especially when there are hundreds of contributors. Existing SV computation techniques use approximations. However, in healthcare where the number of contributing institutions are likely not of a colossal scale, computing exact SVs is still exorbitantly expensive, but not impossible. For such settings, we propose an efficient SV computation technique called SaFE (Shapley Value for Federated Learning using Ensembling). We empirically show that SaFE computes values that are close to exact SVs, and that it performs better than current SV approximations. This is particularly relevant in medical imaging setting where widespread heterogeneity across institutions is rampant and fast accurate data valuation is required to determine the contribution of each participant in multi-institutional collaborative learning.

</p>
</details>

<details><summary><b>Unified State Representation Learning under Data Augmentation</b>
<a href="https://arxiv.org/abs/2209.05302">arxiv:2209.05302</a>
&#x1F4C8; 4 <br>
<p>Taylor Hearn, Sravan Jayanthi, Sehoon Ha</p></summary>
<p>

**Abstract:** The capacity for rapid domain adaptation is important to increasing the applicability of reinforcement learning (RL) to real world problems. Generalization of RL agents is critical to success in the real world, yet zero-shot policy transfer is a challenging problem since even minor visual changes could make the trained agent completely fail in the new task. We propose USRA: Unified State Representation Learning under Data Augmentation, a representation learning framework that learns a latent unified state representation by performing data augmentations on its observations to improve its ability to generalize to unseen target domains. We showcase the success of our approach on the DeepMind Control Generalization Benchmark for the Walker environment and find that USRA achieves higher sample efficiency and 14.3% better domain adaptation performance compared to the best baseline results.

</p>
</details>

<details><summary><b>A Review of Challenges in Machine Learning based Automated Hate Speech Detection</b>
<a href="https://arxiv.org/abs/2209.05294">arxiv:2209.05294</a>
&#x1F4C8; 4 <br>
<p>Abhishek Velankar, Hrushikesh Patil, Raviraj Joshi</p></summary>
<p>

**Abstract:** The spread of hate speech on social media space is currently a serious issue. The undemanding access to the enormous amount of information being generated on these platforms has led people to post and react with toxic content that originates violence. Though efforts have been made toward detecting and restraining such content online, it is still challenging to identify it accurately. Deep learning based solutions have been at the forefront of identifying hateful content. However, the factors such as the context-dependent nature of hate speech, the intention of the user, undesired biases, etc. make this process overcritical. In this work, we deeply explore a wide range of challenges in automatic hate speech detection by presenting a hierarchical organization of these problems. We focus on challenges faced by machine learning or deep learning based solutions to hate speech identification. At the top level, we distinguish between data level, model level, and human level challenges. We further provide an exhaustive analysis of each level of the hierarchy with examples. This survey will help researchers to design their solutions more efficiently in the domain of hate speech detection.

</p>
</details>

<details><summary><b>SmartKex: Machine Learning Assisted SSH Keys Extraction From The Heap Dump</b>
<a href="https://arxiv.org/abs/2209.05243">arxiv:2209.05243</a>
&#x1F4C8; 4 <br>
<p>Christofer Fellicious, Stewart Sentanoe, Michael Granitzer, Hans P. Reiser</p></summary>
<p>

**Abstract:** Digital forensics is the process of extracting, preserving, and documenting evidence in digital devices. A commonly used method in digital forensics is to extract data from the main memory of a digital device. However, the main challenge is identifying the important data to be extracted. Several pieces of crucial information reside in the main memory, like usernames, passwords, and cryptographic keys such as SSH session keys. In this paper, we propose SmartKex, a machine-learning assisted method to extract session keys from heap memory snapshots of an OpenSSH process. In addition, we release an openly available dataset and the corresponding toolchain for creating additional data. Finally, we compare SmartKex with naive brute-force methods and empirically show that SmartKex can extract the session keys with high accuracy and high throughput. With the provided resources, we intend to strengthen the research on the intersection between digital forensics, cybersecurity, and machine learning.

</p>
</details>

<details><summary><b>A Differentiable Loss Function for Learning Heuristics in A*</b>
<a href="https://arxiv.org/abs/2209.05206">arxiv:2209.05206</a>
&#x1F4C8; 4 <br>
<p>Leah Chrestien, Tomas Pevny, Antonin Komenda, Stefan Edelkamp</p></summary>
<p>

**Abstract:** Optimization of heuristic functions for the A* algorithm, realized by deep neural networks, is usually done by minimizing square root loss of estimate of the cost to goal values. This paper argues that this does not necessarily lead to a faster search of A* algorithm since its execution relies on relative values instead of absolute ones. As a mitigation, we propose a L* loss, which upper-bounds the number of excessively expanded states inside the A* search. The L* loss, when used in the optimization of state-of-the-art deep neural networks for automated planning in maze domains like Sokoban and maze with teleports, significantly improves the fraction of solved problems, the quality of founded plans, and reduces the number of expanded states to approximately 50%

</p>
</details>

<details><summary><b>Personalized Federated Learning with Communication Compression</b>
<a href="https://arxiv.org/abs/2209.05148">arxiv:2209.05148</a>
&#x1F4C8; 4 <br>
<p>El Houcine Bergou, Konstantin Burlachenko, Aritra Dutta, Peter Richtárik</p></summary>
<p>

**Abstract:** In contrast to training traditional machine learning (ML) models in data centers, federated learning (FL) trains ML models over local datasets contained on resource-constrained heterogeneous edge devices. Existing FL algorithms aim to learn a single global model for all participating devices, which may not be helpful to all devices participating in the training due to the heterogeneity of the data across the devices. Recently, Hanzely and Richtárik (2020) proposed a new formulation for training personalized FL models aimed at balancing the trade-off between the traditional global model and the local models that could be trained by individual devices using their private data only. They derived a new algorithm, called Loopless Gradient Descent (L2GD), to solve it and showed that this algorithms leads to improved communication complexity guarantees in regimes when more personalization is required. In this paper, we equip their L2GD algorithm with a bidirectional compression mechanism to further reduce the communication bottleneck between the local devices and the server. Unlike other compression-based algorithms used in the FL-setting, our compressed L2GD algorithm operates on a probabilistic communication protocol, where communication does not happen on a fixed schedule. Moreover, our compressed L2GD algorithm maintains a similar convergence rate as vanilla SGD without compression. To empirically validate the efficiency of our algorithm, we perform diverse numerical experiments on both convex and non-convex problems and using various compression techniques.

</p>
</details>

<details><summary><b>Operational solar flare forecasting via video-based deep learning</b>
<a href="https://arxiv.org/abs/2209.05128">arxiv:2209.05128</a>
&#x1F4C8; 4 <br>
<p>Sabrina Guastavino, Francesco Marchetti, Federico Benvenuto, Cristina Campi, Michele Piana</p></summary>
<p>

**Abstract:** Operational flare forecasting aims at providing predictions that can be used to make decisions, typically at a daily scale, about the space weather impacts of flare occurrence. This study shows that video-based deep learning can be used for operational purposes when the training and validation sets used for the network optimization are generated while accounting for the periodicity of the solar cycle. Specifically, the paper describes an algorithm that can be applied to build up sets of active regions that are balanced according to the flare class rates associated to a specific cycle phase. These sets are used to train and validate a Long-term Recurrent Convolutional Network made of a combination of a convolutional neural network and a Long-Short Memory network. The reliability of this approach is assessed in the case of two prediction windows containing the solar storm of March 2015 and September 2017, respectively.

</p>
</details>

<details><summary><b>Ordinal Graph Gamma Belief Network for Social Recommender Systems</b>
<a href="https://arxiv.org/abs/2209.05106">arxiv:2209.05106</a>
&#x1F4C8; 4 <br>
<p>Dongsheng Wang, Chaojie Wang, Bo Chen, Mingyuan Zhou</p></summary>
<p>

**Abstract:** To build recommender systems that not only consider user-item interactions represented as ordinal variables, but also exploit the social network describing the relationships between the users, we develop a hierarchical Bayesian model termed ordinal graph factor analysis (OGFA), which jointly models user-item and user-user interactions. OGFA not only achieves good recommendation performance, but also extracts interpretable latent factors corresponding to representative user preferences. We further extend OGFA to ordinal graph gamma belief network, which is a multi-stochastic-layer deep probabilistic model that captures the user preferences and social communities at multiple semantic levels. For efficient inference, we develop a parallel hybrid Gibbs-EM algorithm, which exploits the sparsity of the graphs and is scalable to large datasets. Our experimental results show that the proposed models not only outperform recent baselines on recommendation datasets with explicit or implicit feedback, but also provide interpretable latent representations.

</p>
</details>

<details><summary><b>TMSS: An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction</b>
<a href="https://arxiv.org/abs/2209.05036">arxiv:2209.05036</a>
&#x1F4C8; 4 <br>
<p>Numan Saeed, Ikboljon Sobirov, Roba Al Majzoub, Mohammad Yaqub</p></summary>
<p>

**Abstract:** When oncologists estimate cancer patient survival, they rely on multimodal data. Even though some multimodal deep learning methods have been proposed in the literature, the majority rely on having two or more independent networks that share knowledge at a later stage in the overall model. On the other hand, oncologists do not do this in their analysis but rather fuse the information in their brain from multiple sources such as medical images and patient history. This work proposes a deep learning method that mimics oncologists' analytical behavior when quantifying cancer and estimating patient survival. We propose TMSS, an end-to-end Transformer based Multimodal network for Segmentation and Survival prediction that leverages the superiority of transformers that lies in their abilities to handle different modalities. The model was trained and validated for segmentation and prognosis tasks on the training dataset from the HEad & NeCK TumOR segmentation and the outcome prediction in PET/CT images challenge (HECKTOR). We show that the proposed prognostic model significantly outperforms state-of-the-art methods with a concordance index of 0.763+/-0.14 while achieving a comparable dice score of 0.772+/-0.030 to a standalone segmentation model. The code is publicly available.

</p>
</details>

<details><summary><b>Sample Complexity of an Adversarial Attack on UCB-based Best-arm Identification Policy</b>
<a href="https://arxiv.org/abs/2209.05692">arxiv:2209.05692</a>
&#x1F4C8; 3 <br>
<p>Varsha Pendyala</p></summary>
<p>

**Abstract:** In this work I study the problem of adversarial perturbations to rewards, in a Multi-armed bandit (MAB) setting. Specifically, I focus on an adversarial attack to a UCB type best-arm identification policy applied to a stochastic MAB. The UCB attack presented in [1] results in pulling a target arm K very often. I used the attack model of [1] to derive the sample complexity required for selecting target arm K as the best arm. I have proved that the stopping condition of UCB based best-arm identification algorithm given in [2], can be achieved by the target arm K in T rounds, where T depends only on the total number of arms and $σ$ parameter of $σ^2-$ sub-Gaussian random rewards of the arms.

</p>
</details>

<details><summary><b>One-shot Network Pruning at Initialization with Discriminative Image Patches</b>
<a href="https://arxiv.org/abs/2209.05683">arxiv:2209.05683</a>
&#x1F4C8; 3 <br>
<p>Yinan Yang, Ying Ji, Yu Wang, Heng Qi, Jien Kato</p></summary>
<p>

**Abstract:** One-shot Network Pruning at Initialization (OPaI) is an effective method to decrease network pruning costs. Recently, there is a growing belief that data is unnecessary in OPaI. However, we obtain an opposite conclusion by ablation experiments in two representative OPaI methods, SNIP and GraSP. Specifically, we find that informative data is crucial to enhancing pruning performance. In this paper, we propose two novel methods, Discriminative One-shot Network Pruning (DOP) and Super Stitching, to prune the network by high-level visual discriminative image patches. Our contributions are as follows. (1) Extensive experiments reveal that OPaI is data-dependent. (2) Super Stitching performs significantly better than the original OPaI method on benchmark ImageNet, especially in a highly compressed model.

</p>
</details>

<details><summary><b>Unsupervised representational learning with recognition-parametrised probabilistic models</b>
<a href="https://arxiv.org/abs/2209.05661">arxiv:2209.05661</a>
&#x1F4C8; 3 <br>
<p>William I. Walker, Hugo Soulat, Changmin Yu, Maneesh Sahani</p></summary>
<p>

**Abstract:** We introduce a new approach to probabilistic unsupervised learning based on the recognition-parametrised model (RPM): a normalised semi-parametric hypothesis class for joint distributions over observed and latent variables. Under the key assumption that observations are conditionally independent given the latents, RPMs directly encode the "recognition" process, parametrising both the prior distribution on the latents and their conditional distributions given observations. This recognition model is paired with non-parametric descriptions of the marginal distribution of each observed variable. Thus, the focus is on learning a good latent representation that captures dependence between the measurements. The RPM permits exact maximum likelihood learning in settings with discrete latents and a tractable prior, even when the mapping between continuous observations and the latents is expressed through a flexible model such as a neural network. We develop effective approximations for the case of continuous latent variables with tractable priors. Unlike the approximations necessary in dual-parametrised models such as Helmholtz machines and variational autoencoders, these RPM approximations introduce only minor bias, which may often vanish asymptotically. Furthermore, where the prior on latents is intractable the RPM may be combined effectively with standard probabilistic techniques such as variational Bayes. We demonstrate the model in high dimensional data settings, including a form of weakly supervised learning on MNIST digits and the discovery of latent maps from sensory observations. The RPM provides an effective way to discover, represent and reason probabilistically about the latent structure underlying observational data, functions which are critical to both animal and artificial intelligence.

</p>
</details>

<details><summary><b>Meta-learning Causal Discovery</b>
<a href="https://arxiv.org/abs/2209.05598">arxiv:2209.05598</a>
&#x1F4C8; 3 <br>
<p>Xinyue Wang, Konrad Kording</p></summary>
<p>

**Abstract:** Causal discovery (CD) from time-varying data is important in neuroscience, medicine, and machine learning. Techniques for CD include randomized experiments which are generally unbiased but expensive. It also includes algorithms like regression, matching, and Granger causality, which are only correct under strong assumptions made by human designers. However, as we found in other areas of machine learning, humans are usually not quite right and are usually outperformed by data-driven approaches. Here we test if we can improve causal discovery in a data-driven way. We take a system with a large number of causal components (transistors), the MOS 6502 processor, and meta-learn the causal discovery procedure represented as a neural network. We find that this procedure far outperforms human-designed causal discovery procedures, such as Mutual Information and Granger Causality. We argue that the causality field should consider, where possible, a supervised approach, where CD procedures are learned from large datasets with known causal relations instead of being designed by a human specialist. Our findings promise a new approach toward CD in neural and medical data and for the broader machine learning community.

</p>
</details>

<details><summary><b>BayesLDM: A Domain-Specific Language for Probabilistic Modeling of Longitudinal Data</b>
<a href="https://arxiv.org/abs/2209.05581">arxiv:2209.05581</a>
&#x1F4C8; 3 <br>
<p>Karine Tung, Steven De La Torre, Mohamed El Mistiri, Rebecca Braga De Braganca, Eric Hekler, Misha Pavel, Daniel Rivera, Pedja Klasnja, Donna Spruijt-Metz, Benjamin M. Marlin</p></summary>
<p>

**Abstract:** In this paper we present BayesLDM, a system for Bayesian longitudinal data modeling consisting of a high-level modeling language with specific features for modeling complex multivariate time series data coupled with a compiler that can produce optimized probabilistic program code for performing inference in the specified model. BayesLDM supports modeling of Bayesian network models with a specific focus on the efficient, declarative specification of dynamic Bayesian Networks (DBNs). The BayesLDM compiler combines a model specification with inspection of available data and outputs code for performing Bayesian inference for unknown model parameters while simultaneously handling missing data. These capabilities have the potential to significantly accelerate iterative modeling workflows in domains that involve the analysis of complex longitudinal data by abstracting away the process of producing computationally efficient probabilistic inference code. We describe the BayesLDM system components, evaluate the efficiency of representation and inference optimizations and provide an illustrative example of the application of the system to analyzing heterogeneous and partially observed mobile health data.

</p>
</details>

<details><summary><b>Cocktail Party Attack: Breaking Aggregation-Based Privacy in Federated Learning using Independent Component Analysis</b>
<a href="https://arxiv.org/abs/2209.05578">arxiv:2209.05578</a>
&#x1F4C8; 3 <br>
<p>Sanjay Kariyappa, Chuan Guo, Kiwan Maeng, Wenjie Xiong, G. Edward Suh, Moinuddin K Qureshi, Hsien-Hsin S. Lee</p></summary>
<p>

**Abstract:** Federated learning (FL) aims to perform privacy-preserving machine learning on distributed data held by multiple data owners. To this end, FL requires the data owners to perform training locally and share the gradient updates (instead of the private inputs) with the central server, which are then securely aggregated over multiple data owners. Although aggregation by itself does not provably offer privacy protection, prior work showed that it may suffice if the batch size is sufficiently large. In this paper, we propose the Cocktail Party Attack (CPA) that, contrary to prior belief, is able to recover the private inputs from gradients aggregated over a very large batch size. CPA leverages the crucial insight that aggregate gradients from a fully connected layer is a linear combination of its inputs, which leads us to frame gradient inversion as a blind source separation (BSS) problem (informally called the cocktail party problem). We adapt independent component analysis (ICA)--a classic solution to the BSS problem--to recover private inputs for fully-connected and convolutional networks, and show that CPA significantly outperforms prior gradient inversion attacks, scales to ImageNet-sized inputs, and works on large batch sizes of up to 1024.

</p>
</details>

<details><summary><b>Mathematical Framework for Online Social Media Regulation</b>
<a href="https://arxiv.org/abs/2209.05550">arxiv:2209.05550</a>
&#x1F4C8; 3 <br>
<p>Wasim Huleihel, Yehonathan Refael</p></summary>
<p>

**Abstract:** Social media platforms (SMPs) leverage algorithmic filtering (AF) as a means of selecting the content that constitutes a user's feed with the aim of maximizing their rewards. Selectively choosing the contents to be shown on the user's feed may yield a certain extent of influence, either minor or major, on the user's decision-making, compared to what it would have been under a natural/fair content selection. As we have witnessed over the past decade, algorithmic filtering can cause detrimental side effects, ranging from biasing individual decisions to shaping those of society as a whole, for example, diverting users' attention from whether to get the COVID-19 vaccine or inducing the public to choose a presidential candidate. The government's constant attempts to regulate the adverse effects of AF are often complicated, due to bureaucracy, legal affairs, and financial considerations. On the other hand SMPs seek to monitor their own algorithmic activities to avoid being fined for exceeding the allowable threshold. In this paper, we mathematically formalize this framework and utilize it to construct a data-driven statistical algorithm to regulate the AF from deflecting users' beliefs over time, along with sample and complexity guarantees. We show that our algorithm is robust against potential adversarial users. This state-of-the-art algorithm can be used either by authorities acting as external regulators or by SMPs for self-regulation.

</p>
</details>

<details><summary><b>Understanding Time Variations of DNN Inference in Autonomous Driving</b>
<a href="https://arxiv.org/abs/2209.05487">arxiv:2209.05487</a>
&#x1F4C8; 3 <br>
<p>Liangkai Liu, Yanzhi Wang, Weisong Shi</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) are widely used in autonomous driving due to their high accuracy for perception, decision, and control. In safety-critical systems like autonomous driving, executing tasks like sensing and perception in real-time is vital to the vehicle's safety, which requires the application's execution time to be predictable. However, non-negligible time variations are observed in DNN inference. Current DNN inference studies either ignore the time variation issue or rely on the scheduler to handle it. None of the current work explains the root causes of DNN inference time variations. Understanding the time variations of the DNN inference becomes a fundamental challenge in real-time scheduling for autonomous driving. In this work, we analyze the time variation in DNN inference in fine granularity from six perspectives: data, I/O, model, runtime, hardware, and end-to-end perception system. Six insights are derived in understanding the time variations for DNN inference.

</p>
</details>

<details><summary><b>Active Learning and Approximate Model Calibration for Automated Visual Inspection in Manufacturing</b>
<a href="https://arxiv.org/abs/2209.05486">arxiv:2209.05486</a>
&#x1F4C8; 3 <br>
<p>Jože M. Rožanec, Luka Bizjak, Elena Trajkova, Patrik Zajec, Jelle Keizer, Blaž Fortuna, Dunja Mladenić</p></summary>
<p>

**Abstract:** Quality control is a crucial activity performed by manufacturing enterprises to ensure that their products meet quality standards and avoid potential damage to the brand's reputation. The decreased cost of sensors and connectivity enabled increasing digitalization of manufacturing. In addition, artificial intelligence enables higher degrees of automation, reducing overall costs and time required for defect inspection. This research compares three active learning approaches (with single and multiple oracles) to visual inspection. We propose a novel approach to probabilities calibration of classification models and two new metrics to assess the performance of the calibration without the need for ground truth. We performed experiments on real-world data provided by Philips Consumer Lifestyle BV. Our results show that explored active learning settings can reduce the data labeling effort by between three and four percent without detriment to the overall quality goals, considering a threshold of p=0.95. Furthermore, we show that the proposed metrics successfully capture relevant information otherwise available to metrics used up to date only through ground truth data. Therefore, the proposed metrics can be used to estimate the quality of models' probability calibration without committing to a labeling effort to obtain ground truth data.

</p>
</details>

<details><summary><b>On Faithfulness and Coherence of Language Explanations for Recommendation Systems</b>
<a href="https://arxiv.org/abs/2209.05409">arxiv:2209.05409</a>
&#x1F4C8; 3 <br>
<p>Zhouhang Xie, Julian McAuley, Bodhisattwa Prasad Majumder</p></summary>
<p>

**Abstract:** Reviews contain rich information about product characteristics and user interests and thus are commonly used to boost recommender system performance. Specifically, previous work show that jointly learning to perform review generation improves rating prediction performance. Meanwhile, these model-produced reviews serve as recommendation explanations, providing the user with insights on predicted ratings. However, while existing models could generate fluent, human-like reviews, it is unclear to what degree the reviews fully uncover the rationale behind the jointly predicted rating. In this work, we perform a series of evaluations that probes state-of-the-art models and their review generation component. We show that the generated explanations are brittle and need further evaluation before being taken as literal rationales for the estimated ratings.

</p>
</details>

<details><summary><b>A Review on Visual-SLAM: Advancements from Geometric Modelling to Learning-based Semantic Scene Understanding</b>
<a href="https://arxiv.org/abs/2209.05222">arxiv:2209.05222</a>
&#x1F4C8; 3 <br>
<p>Tin Lai</p></summary>
<p>

**Abstract:** Simultaneous Localisation and Mapping (SLAM) is one of the fundamental problems in autonomous mobile robots where a robot needs to reconstruct a previously unseen environment while simultaneously localising itself with respect to the map. In particular, Visual-SLAM uses various sensors from the mobile robot for collecting and sensing a representation of the map. Traditionally, geometric model-based techniques were used to tackle the SLAM problem, which tends to be error-prone under challenging environments. Recent advancements in computer vision, such as deep learning techniques, have provided a data-driven approach to tackle the Visual-SLAM problem. This review summarises recent advancements in the Visual-SLAM domain using various learning-based methods. We begin by providing a concise overview of the geometric model-based approaches, followed by technical reviews on the current paradigms in SLAM. Then, we present the various learning-based approaches to collecting sensory inputs from mobile robots and performing scene understanding. The current paradigms in deep-learning-based semantic understanding are discussed and placed under the context of Visual-SLAM. Finally, we discuss challenges and further opportunities in the direction of learning-based approaches in Visual-SLAM.

</p>
</details>

<details><summary><b>A Comparative Study of Classical and Quantum Machine Learning Models for Sentimental Analysis</b>
<a href="https://arxiv.org/abs/2209.05142">arxiv:2209.05142</a>
&#x1F4C8; 3 <br>
<p>Diksha Sharma, Parvinder Singh, Atul Kumar</p></summary>
<p>

**Abstract:** We analyse and classify the sentiments of a text data constructed from movie reviews. For this, we use the kernel-based approach from quantum machine learning algorithms. In order to compose a quantum kernel, we use a circuit constructed using a combination of different Pauli rotational gates where the rotational parameter is a classical non-linear function of data points obtained from the text data. For analysing the performance of the proposed model, we analyse the quantum model using decision tree, gradient boosting classifier, and classical and quantum support vector machines. Our results show that quantum kernel model or quantum support vector machine outperforms all other algorithms used for analysis in terms of all evaluation metrics. In comparison to a classical support vector machine, the quantum support vector machine leads to significantly better results even with increased number of features or dimensions. The results clearly demonstrate increase in precision score by $9.4 \%$ using a quantum support vector machine as against a classical support vector machine if the number of features are $15$.

</p>
</details>

<details><summary><b>High-Fidelity Variable-Rate Image Compression via Invertible Activation Transformation</b>
<a href="https://arxiv.org/abs/2209.05054">arxiv:2209.05054</a>
&#x1F4C8; 3 <br>
<p>Shilv Cai, Zhijun Zhang, Liqun Chen, Luxin Yan, Sheng Zhong, Xu Zou</p></summary>
<p>

**Abstract:** Learning-based methods have effectively promoted the community of image compression. Meanwhile, variational autoencoder (VAE) based variable-rate approaches have recently gained much attention to avoid the usage of a set of different networks for various compression rates. Despite the remarkable performance that has been achieved, these approaches would be readily corrupted once multiple compression/decompression operations are executed, resulting in the fact that image quality would be tremendously dropped and strong artifacts would appear. Thus, we try to tackle the issue of high-fidelity fine variable-rate image compression and propose the Invertible Activation Transformation (IAT) module. We implement the IAT in a mathematical invertible manner on a single rate Invertible Neural Network (INN) based model and the quality level (QLevel) would be fed into the IAT to generate scaling and bias tensors. IAT and QLevel together give the image compression model the ability of fine variable-rate control while better maintaining the image fidelity. Extensive experiments demonstrate that the single rate image compression model equipped with our IAT module has the ability to achieve variable-rate control without any compromise. And our IAT-embedded model obtains comparable rate-distortion performance with recent learning-based image compression methods. Furthermore, our method outperforms the state-of-the-art variable-rate image compression method by a large margin, especially after multiple re-encodings.

</p>
</details>

<details><summary><b>SANCL: Multimodal Review Helpfulness Prediction with Selective Attention and Natural Contrastive Learning</b>
<a href="https://arxiv.org/abs/2209.05040">arxiv:2209.05040</a>
&#x1F4C8; 3 <br>
<p>Wei Han, Hui Chen, Zhen Hai, Soujanya Poria, Lidong Bing</p></summary>
<p>

**Abstract:** With the boom of e-commerce, Multimodal Review Helpfulness Prediction (MRHP), which aims to sort product reviews according to the predicted helpfulness scores has become a research hotspot. Previous work on this task focuses on attention-based modality fusion, information integration, and relation modeling, which primarily exposes the following drawbacks: 1) the model may fail to capture the really essential information due to its indiscriminate attention formulation; 2) lack appropriate modeling methods that take full advantage of correlation among provided data. In this paper, we propose SANCL: Selective Attention and Natural Contrastive Learning for MRHP. SANCL adopts a probe-based strategy to enforce high attention weights on the regions of greater significance. It also constructs a contrastive learning framework based on natural matching properties in the dataset. Experimental results on two benchmark datasets with three categories show that SANCL achieves state-of-the-art baseline performance with lower memory consumption.

</p>
</details>

<details><summary><b>A Guide to Employ Hyperspectral Imaging for Assessing Wheat Quality at Different Stages of Supply Chain in Australia: A Review</b>
<a href="https://arxiv.org/abs/2209.05727">arxiv:2209.05727</a>
&#x1F4C8; 2 <br>
<p>Priyabrata Karmakar, Shyh Wei Teng. Manzur Murshed, Paul Pang, Cuong Van Bui</p></summary>
<p>

**Abstract:** Wheat is one of the major staple crops across the globe. Therefore, it is mandatory to measure, maintain and improve the wheat quality for human consumption. Traditional wheat quality measurement methods are mostly invasive, destructive and limited to small samples of wheat. In a typical supply chain of wheat, there are many receival points where bulk wheat arrives, gets stored and forwarded as per the requirements. In this receival points, the application of traditional quality measurement methods is difficult and often very expensive. Therefore, there is a need for non-invasive, non-destructive real-time methods for wheat quality assessments. One such method that fulfils the above-mentioned criteria is hyperspectral imaging (HSI) for food quality measurement and it can also be applied to bulk samples. In this paper, we have investigated how HSI has been used in the literature for assessing stored wheat quality. So that the required information to implement real-time digital quality assessment methods at the different stages of Australian supply chain can be made available in a single and compact document.

</p>
</details>

<details><summary><b>Data efficient reinforcement learning and adaptive optimal perimeter control of network traffic dynamics</b>
<a href="https://arxiv.org/abs/2209.05726">arxiv:2209.05726</a>
&#x1F4C8; 2 <br>
<p>C. Chen, Y. P. Huang, W. H. K. Lam, T. L. Pan, S. C. Hsu, A. Sumalee, R. X. Zhong</p></summary>
<p>

**Abstract:** Existing data-driven and feedback traffic control strategies do not consider the heterogeneity of real-time data measurements. Besides, traditional reinforcement learning (RL) methods for traffic control usually converge slowly for lacking data efficiency. Moreover, conventional optimal perimeter control schemes require exact knowledge of the system dynamics and thus would be fragile to endogenous uncertainties. To handle these challenges, this work proposes an integral reinforcement learning (IRL) based approach to learning the macroscopic traffic dynamics for adaptive optimal perimeter control. This work makes the following primary contributions to the transportation literature: (a) A continuous-time control is developed with discrete gain updates to adapt to the discrete-time sensor data. (b) To reduce the sampling complexity and use the available data more efficiently, the experience replay (ER) technique is introduced to the IRL algorithm. (c) The proposed method relaxes the requirement on model calibration in a "model-free" manner that enables robustness against modeling uncertainty and enhances the real-time performance via a data-driven RL algorithm. (d) The convergence of the IRL-based algorithms and the stability of the controlled traffic dynamics are proven via the Lyapunov theory. The optimal control law is parameterized and then approximated by neural networks (NN), which moderates the computational complexity. Both state and input constraints are considered while no model linearization is required. Numerical examples and simulation experiments are presented to verify the effectiveness and efficiency of the proposed method.

</p>
</details>

<details><summary><b>A Capsule Network for Hierarchical Multi-Label Image Classification</b>
<a href="https://arxiv.org/abs/2209.05723">arxiv:2209.05723</a>
&#x1F4C8; 2 <br>
<p>Khondaker Tasrif Noor, Antonio Robles-Kelly, Brano Kusy</p></summary>
<p>

**Abstract:** Image classification is one of the most important areas in computer vision. Hierarchical multi-label classification applies when a multi-class image classification problem is arranged into smaller ones based upon a hierarchy or taxonomy. Thus, hierarchical classification modes generally provide multiple class predictions on each instance, whereby these are expected to reflect the structure of image classes as related to one another. In this paper, we propose a multi-label capsule network (ML-CapsNet) for hierarchical classification. Our ML-CapsNet predicts multiple image classes based on a hierarchical class-label tree structure. To this end, we present a loss function that takes into account the multi-label predictions of the network. As a result, the training approach for our ML-CapsNet uses a coarse to fine paradigm while maintaining consistency with the structure in the classification levels in the label-hierarchy. We also perform experiments using widely available datasets and compare the model with alternatives elsewhere in the literature. In our experiments, our ML-CapsNet yields a margin of improvement with respect to these alternative methods.

</p>
</details>

<details><summary><b>Generalization Bounds for Deep Transfer Learning Using Majority Predictor Accuracy</b>
<a href="https://arxiv.org/abs/2209.05709">arxiv:2209.05709</a>
&#x1F4C8; 2 <br>
<p>Cuong N. Nguyen, Lam Si Tung Ho, Vu Dinh, Tal Hassner, Cuong V. Nguyen</p></summary>
<p>

**Abstract:** We analyze new generalization bounds for deep learning models trained by transfer learning from a source to a target task. Our bounds utilize a quantity called the majority predictor accuracy, which can be computed efficiently from data. We show that our theory is useful in practice since it implies that the majority predictor accuracy can be used as a transferability measure, a fact that is also validated by our experiments.

</p>
</details>

<details><summary><b>Robin: A Novel Online Suicidal Text Corpus of Substantial Breadth and Scale</b>
<a href="https://arxiv.org/abs/2209.05707">arxiv:2209.05707</a>
&#x1F4C8; 2 <br>
<p>Daniel DiPietro, Vivek Hazari, Soroush Vosoughi</p></summary>
<p>

**Abstract:** Suicide is a major public health crisis. With more than 20,000,000 suicide attempts each year, the early detection of suicidal intent has the potential to save hundreds of thousands of lives. Traditional mental health screening methods are time-consuming, costly, and often inaccessible to disadvantaged populations; online detection of suicidal intent using machine learning offers a viable alternative. Here we present Robin, the largest non-keyword generated suicidal corpus to date, consisting of over 1.1 million online forum postings. In addition to its unprecedented size, Robin is specially constructed to include various categories of suicidal text, such as suicide bereavement and flippant references, better enabling models trained on Robin to learn the subtle nuances of text expressing suicidal ideation. Experimental results achieve state-of-the-art performance for the classification of suicidal text, both with traditional methods like logistic regression (F1=0.85), as well as with large-scale pre-trained language models like BERT (F1=0.92). Finally, we release the Robin dataset publicly as a machine learning resource with the potential to drive the next generation of suicidal sentiment research.

</p>
</details>

<details><summary><b>Vision Transformers for Action Recognition: A Survey</b>
<a href="https://arxiv.org/abs/2209.05700">arxiv:2209.05700</a>
&#x1F4C8; 2 <br>
<p>Anwaar Ulhaq, Naveed Akhtar, Ganna Pogrebna, Ajmal Mian</p></summary>
<p>

**Abstract:** Vision transformers are emerging as a powerful tool to solve computer vision problems. Recent techniques have also proven the efficacy of transformers beyond the image domain to solve numerous video-related tasks. Among those, human action recognition is receiving special attention from the research community due to its widespread applications. This article provides the first comprehensive survey of vision transformer techniques for action recognition. We analyze and summarize the existing and emerging literature in this direction while highlighting the popular trends in adapting transformers for action recognition. Due to their specialized application, we collectively refer to these methods as ``action transformers''. Our literature review provides suitable taxonomies for action transformers based on their architecture, modality, and intended objective. Within the context of action transformers, we explore the techniques to encode spatio-temporal data, dimensionality reduction, frame patch and spatio-temporal cube construction, and various representation methods. We also investigate the optimization of spatio-temporal attention in transformer layers to handle longer sequences, typically by reducing the number of tokens in a single attention operation. Moreover, we also investigate different network learning strategies, such as self-supervised and zero-shot learning, along with their associated losses for transformer-based action recognition. This survey also summarizes the progress towards gaining grounds on evaluation metric scores on important benchmarks with action transformers. Finally, it provides a discussion on the challenges, outlook, and future avenues for this research direction.

</p>
</details>

<details><summary><b>Concept-Based Explanations for Tabular Data</b>
<a href="https://arxiv.org/abs/2209.05690">arxiv:2209.05690</a>
&#x1F4C8; 2 <br>
<p>Varsha Pendyala, Jihye Choi</p></summary>
<p>

**Abstract:** The interpretability of machine learning models has been an essential area of research for the safe deployment of machine learning systems. One particular approach is to attribute model decisions to high-level concepts that humans can understand. However, such concept-based explainability for Deep Neural Networks (DNNs) has been studied mostly on image domain. In this paper, we extend TCAV, the concept attribution approach, to tabular learning, by providing an idea on how to define concepts over tabular data. On a synthetic dataset with ground-truth concept explanations and a real-world dataset, we show the validity of our method in generating interpretability results that match the human-level intuitions. On top of this, we propose a notion of fairness based on TCAV that quantifies what layer of DNN has learned representations that lead to biased predictions of the model. Also, we empirically demonstrate the relation of TCAV-based fairness to a group fairness notion, Demographic Parity.

</p>
</details>

<details><summary><b>Class-Level Logit Perturbation</b>
<a href="https://arxiv.org/abs/2209.05668">arxiv:2209.05668</a>
&#x1F4C8; 2 <br>
<p>Mengyang Li, Fengguang Su, Ou Wu, Ji Zhang</p></summary>
<p>

**Abstract:** Features, logits, and labels are the three primary data when a sample passes through a deep neural network. Feature perturbation and label perturbation receive increasing attention in recent years. They have been proven to be useful in various deep learning approaches. For example, (adversarial) feature perturbation can improve the robustness or even generalization capability of learned models. However, limited studies have explicitly explored for the perturbation of logit vectors. This work discusses several existing methods related to class-level logit perturbation. A unified viewpoint between positive/negative data augmentation and loss variations incurred by logit perturbation is established. A theoretical analysis is provided to illuminate why class-level logit perturbation is useful. Accordingly, new methodologies are proposed to explicitly learn to perturb logits for both single-label and multi-label classification tasks. Extensive experiments on benchmark image classification data sets and their long-tail versions indicated the competitive performance of our learning method. As it only perturbs on logit, it can be used as a plug-in to fuse with any existing classification algorithms. All the codes are available at https://github.com/limengyang1992/lpl.

</p>
</details>

<details><summary><b>Skip Training for Multi-Agent Reinforcement Learning Controller for Industrial Wave Energy Converters</b>
<a href="https://arxiv.org/abs/2209.05656">arxiv:2209.05656</a>
&#x1F4C8; 2 <br>
<p>Soumyendu Sarkar, Vineet Gundecha, Sahand Ghorbanpour, Alexander Shmakov, Ashwin Ramesh Babu, Alexandre Pichard, Mathieu Cocho</p></summary>
<p>

**Abstract:** Recent Wave Energy Converters (WEC) are equipped with multiple legs and generators to maximize energy generation. Traditional controllers have shown limitations to capture complex wave patterns and the controllers must efficiently maximize the energy capture. This paper introduces a Multi-Agent Reinforcement Learning controller (MARL), which outperforms the traditionally used spring damper controller. Our initial studies show that the complex nature of problems makes it hard for training to converge. Hence, we propose a novel skip training approach which enables the MARL training to overcome performance saturation and converge to more optimum controllers compared to default MARL training, boosting power generation. We also present another novel hybrid training initialization (STHTI) approach, where the individual agents of the MARL controllers can be initially trained against the baseline Spring Damper (SD) controller individually and then be trained one agent at a time or all together in future iterations to accelerate convergence. We achieved double-digit gains in energy efficiency over the baseline Spring Damper controller with the proposed MARL controllers using the Asynchronous Advantage Actor-Critic (A3C) algorithm.

</p>
</details>

<details><summary><b>Bending the Future: Autoregressive Modeling of Temporal Knowledge Graphs in Curvature-Variable Hyperbolic Spaces</b>
<a href="https://arxiv.org/abs/2209.05635">arxiv:2209.05635</a>
&#x1F4C8; 2 <br>
<p>Jihoon Sohn, Mingyu Derek Ma, Muhao Chen</p></summary>
<p>

**Abstract:** Recently there is an increasing scholarly interest in time-varying knowledge graphs, or temporal knowledge graphs (TKG). Previous research suggests diverse approaches to TKG reasoning that uses historical information. However, less attention has been given to the hierarchies within such information at different timestamps. Given that TKG is a sequence of knowledge graphs based on time, the chronology in the sequence derives hierarchies between the graphs. Furthermore, each knowledge graph has its hierarchical level which may differ from one another. To address these hierarchical characteristics in TKG, we propose HyperVC, which utilizes hyperbolic space that better encodes the hierarchies than Euclidean space. The chronological hierarchies between knowledge graphs at different timestamps are represented by embedding the knowledge graphs as vectors in a common hyperbolic space. Additionally, diverse hierarchical levels of knowledge graphs are represented by adjusting the curvatures of hyperbolic embeddings of their entities and relations. Experiments on four benchmark datasets show substantial improvements, especially on the datasets with higher hierarchical levels.

</p>
</details>

<details><summary><b>It's Not Fairness, and It's Not Fair: The Failure of Distributional Equality and the Promise of Relational Equality in Complete-Information Hiring Games</b>
<a href="https://arxiv.org/abs/2209.05602">arxiv:2209.05602</a>
&#x1F4C8; 2 <br>
<p>Benjamin Fish, Luke Stark</p></summary>
<p>

**Abstract:** Existing efforts to formulate computational definitions of fairness have largely focused on distributional notions of equality, where equality is defined by the resources or decisions given to individuals in the system. Yet existing discrimination and injustice is often the result of unequal social relations, rather than an unequal distribution of resources. Here, we show how optimizing for existing computational and economic definitions of fairness and equality fail to prevent unequal social relations. To do this, we provide an example of a self-confirming equilibrium in a simple hiring market that is relationally unequal but satisfies existing distributional notions of fairness. In doing so, we introduce a notion of blatant relational unfairness for complete-information games, and discuss how this definition helps initiate a new approach to incorporating relational equality into computational systems.

</p>
</details>

<details><summary><b>Risk-aware Meta-level Decision Making for Exploration Under Uncertainty</b>
<a href="https://arxiv.org/abs/2209.05580">arxiv:2209.05580</a>
&#x1F4C8; 2 <br>
<p>Joshua Ott, Sung-Kyun Kim, Amanda Bouman, Oriana Peltzer, Mamoru Sobue, Harrison Delecki, Mykel J. Kochenderfer, Joel Burdick, Ali-akbar Agha-mohammadi</p></summary>
<p>

**Abstract:** Robotic exploration of unknown environments is fundamentally a problem of decision making under uncertainty where the robot must account for uncertainty in sensor measurements, localization, action execution, as well as many other factors. For large-scale exploration applications, autonomous systems must overcome the challenges of sequentially deciding which areas of the environment are valuable to explore while safely evaluating the risks associated with obstacles and hazardous terrain. In this work, we propose a risk-aware meta-level decision making framework to balance the tradeoffs associated with local and global exploration. Meta-level decision making builds upon classical hierarchical coverage planners by switching between local and global policies with the overall objective of selecting the policy that is most likely to maximize reward in a stochastic environment. We use information about the environment history, traversability risk, and kinodynamic constraints to reason about the probability of successful policy execution to switch between local and global policies. We have validated our solution in both simulation and on a variety of large-scale real world hardware tests. Our results show that by balancing local and global exploration we are able to significantly explore large-scale environments more efficiently.

</p>
</details>

<details><summary><b>Intrusion Detection Systems Using Support Vector Machines on the KDDCUP'99 and NSL-KDD Datasets: A Comprehensive Survey</b>
<a href="https://arxiv.org/abs/2209.05579">arxiv:2209.05579</a>
&#x1F4C8; 2 <br>
<p>Mikel K. Ngueajio, Gloria Washington, Danda B. Rawat, Yolande Ngueabou</p></summary>
<p>

**Abstract:** With the growing rates of cyber-attacks and cyber espionage, the need for better and more powerful intrusion detection systems (IDS) is even more warranted nowadays. The basic task of an IDS is to act as the first line of defense, in detecting attacks on the internet. As intrusion tactics from intruders become more sophisticated and difficult to detect, researchers have started to apply novel Machine Learning (ML) techniques to effectively detect intruders and hence preserve internet users' information and overall trust in the entire internet network security. Over the last decade, there has been an explosion of research on intrusion detection techniques based on ML and Deep Learning (DL) architectures on various cyber security-based datasets such as the DARPA, KDDCUP'99, NSL-KDD, CAIDA, CTU-13, UNSW-NB15. In this research, we review contemporary literature and provide a comprehensive survey of different types of intrusion detection technique that applies Support Vector Machines (SVMs) algorithms as a classifier. We focus only on studies that have been evaluated on the two most widely used datasets in cybersecurity namely: the KDDCUP'99 and the NSL-KDD datasets. We provide a summary of each method, identifying the role of the SVMs classifier, and all other algorithms involved in the studies. Furthermore, we present a critical review of each method, in tabular form, highlighting the performance measures, strengths, and limitations of each of the methods surveyed.

</p>
</details>

<details><summary><b>Model-based Reinforcement Learning with Multi-step Plan Value Estimation</b>
<a href="https://arxiv.org/abs/2209.05530">arxiv:2209.05530</a>
&#x1F4C8; 2 <br>
<p>Haoxin Lin, Yihao Sun, Jiaji Zhang, Yang Yu</p></summary>
<p>

**Abstract:** A promising way to improve the sample efficiency of reinforcement learning is model-based methods, in which many explorations and evaluations can happen in the learned models to save real-world samples. However, when the learned model has a non-negligible model error, sequential steps in the model are hard to be accurately evaluated, limiting the model's utilization. This paper proposes to alleviate this issue by introducing multi-step plans to replace multi-step actions for model-based RL. We employ the multi-step plan value estimation, which evaluates the expected discounted return after executing a sequence of action plans at a given state, and updates the policy by directly computing the multi-step policy gradient via plan value estimation. The new model-based reinforcement learning algorithm MPPVE (Model-based Planning Policy Learning with Multi-step Plan Value Estimation) shows a better utilization of the learned model and achieves a better sample efficiency than state-of-the-art model-based RL approaches.

</p>
</details>

<details><summary><b>TEDL: A Two-stage Evidential Deep Learning Method for Classification Uncertainty Quantification</b>
<a href="https://arxiv.org/abs/2209.05522">arxiv:2209.05522</a>
&#x1F4C8; 2 <br>
<p>Xue Li, Wei Shen, Denis Charles</p></summary>
<p>

**Abstract:** In this paper, we propose TEDL, a two-stage learning approach to quantify uncertainty for deep learning models in classification tasks, inspired by our findings in experimenting with Evidential Deep Learning (EDL) method, a recently proposed uncertainty quantification approach based on the Dempster-Shafer theory. More specifically, we observe that EDL tends to yield inferior AUC compared with models learnt by cross-entropy loss and is highly sensitive in training. Such sensitivity is likely to cause unreliable uncertainty estimation, making it risky for practical applications. To mitigate both limitations, we propose a simple yet effective two-stage learning approach based on our analysis on the likely reasons causing such sensitivity, with the first stage learning from cross-entropy loss, followed by a second stage learning from EDL loss. We also re-formulate the EDL loss by replacing ReLU with ELU to avoid the Dying ReLU issue. Extensive experiments are carried out on varied sized training corpus collected from a large-scale commercial search engine, demonstrating that the proposed two-stage learning framework can increase AUC significantly and greatly improve training robustness.

</p>
</details>

<details><summary><b>Deep Neural Networks as Complex Networks</b>
<a href="https://arxiv.org/abs/2209.05488">arxiv:2209.05488</a>
&#x1F4C8; 2 <br>
<p>Emanuele La Malfa, Gabriele La Malfa, Claudio Caprioli, Giuseppe Nicosia, Vito Latora</p></summary>
<p>

**Abstract:** Deep Neural Networks are, from a physical perspective, graphs whose `links` and `vertices` iteratively process data and solve tasks sub-optimally. We use Complex Network Theory (CNT) to represents Deep Neural Networks (DNNs) as directed weighted graphs: within this framework, we introduce metrics to study DNNs as dynamical systems, with a granularity that spans from weights to layers, including neurons. CNT discriminates networks that differ in the number of parameters and neurons, the type of hidden layers and activations, and the objective task. We further show that our metrics discriminate low vs. high performing networks. CNT is a comprehensive method to reason about DNNs and a complementary approach to explain a model's behavior that is physically grounded to networks theory and goes beyond the well-studied input-output relation.

</p>
</details>

<details><summary><b>Self-Supervised Coordinate Projection Network for Sparse-View Computed Tomography</b>
<a href="https://arxiv.org/abs/2209.05483">arxiv:2209.05483</a>
&#x1F4C8; 2 <br>
<p>Qing Wu, Ruimin Feng, Hongjiang Wei, Jingyi Yu, Yuyao Zhang</p></summary>
<p>

**Abstract:** In the present work, we propose a Self-supervised COordinate Projection nEtwork (SCOPE) to reconstruct the artifacts-free CT image from a single SV sinogram by solving the inverse tomography imaging problem. Compared with recent related works that solve similar problems using implicit neural representation network (INR), our essential contribution is an effective and simple re-projection strategy that pushes the tomography image reconstruction quality over supervised deep learning CT reconstruction works. The proposed strategy is inspired by the simple relationship between linear algebra and inverse problems. To solve the under-determined linear equation system, we first introduce INR to constrain the solution space via image continuity prior and achieve a rough solution. And secondly, we propose to generate a dense view sinogram that improves the rank of the linear equation system and produces a more stable CT image solution space. Our experiment results demonstrate that the re-projection strategy significantly improves the image reconstruction quality (+3 dB for PSNR at least). Besides, we integrate the recent hash encoding into our SCOPE model, which greatly accelerates the model training. Finally, we evaluate SCOPE in parallel and fan X-ray beam SVCT reconstruction tasks. Experimental results indicate that the proposed SCOPE model outperforms two latest INR-based methods and two well-popular supervised DL methods quantitatively and qualitatively.

</p>
</details>

<details><summary><b>Leveraging Artificial Intelligence Techniques for Smart Palm Tree Detection: A Decade Systematic Review</b>
<a href="https://arxiv.org/abs/2209.05282">arxiv:2209.05282</a>
&#x1F4C8; 2 <br>
<p>Yosra Hajjaji, Wadii Boulila, Imed Riadh Farah</p></summary>
<p>

**Abstract:** Over the past few years, total financial investment in the agricultural sector has increased substantially. Palm tree is important for many countries' economies, particularly in northern Africa and the Middle East. Monitoring in terms of detection and counting palm trees provides useful information for various stakeholders; it helps in yield estimation and examination to ensure better crop quality and prevent pests, diseases, better irrigation, and other potential threats. Despite their importance, this information is still challenging to obtain. This study systematically reviews research articles between 2011 and 2021 on artificial intelligence (AI) technology for smart palm tree detection. A systematic review (SR) was performed using the PRISMA approach based on a four-stage selection process. Twenty-two articles were included for the synthesis activity reached from the search strategy alongside the inclusion criteria in order to answer to two main research questions. The study's findings reveal patterns, relationships, networks, and trends in applying artificial intelligence in palm tree detection over the last decade. Despite the good results in most of the studies, the effective and efficient management of large-scale palm plantations is still a challenge. In addition, countries whose economies strongly related to intelligent palm services, especially in North Africa, should give more attention to this kind of study. The results of this research could benefit both the research community and stakeholders.

</p>
</details>

<details><summary><b>Learning Obstacle-Avoiding Lattice Paths using Swarm Heuristics: Exploring the Bijection to Ordered Trees</b>
<a href="https://arxiv.org/abs/2209.05187">arxiv:2209.05187</a>
&#x1F4C8; 2 <br>
<p>Victor Parque</p></summary>
<p>

**Abstract:** Lattice paths are functional entities that model efficient navigation in discrete/grid maps. This paper presents a new scheme to generate collision-free lattice paths with utmost efficiency using the bijective property to rooted ordered trees, rendering a one-dimensional search problem. Our computational studies using ten state-of-the-art and relevant nature-inspired swarm heuristics in navigation scenarios with obstacles with convex and non-convex geometry show the practical feasibility and efficiency in rendering collision-free lattice paths. We believe our scheme may find use in devising fast algorithms for planning and combinatorial optimization in discrete maps.

</p>
</details>

<details><summary><b>Hyperbolic Self-supervised Contrastive Learning Based Network Anomaly Detection</b>
<a href="https://arxiv.org/abs/2209.05049">arxiv:2209.05049</a>
&#x1F4C8; 2 <br>
<p>Yuanjun Shi</p></summary>
<p>

**Abstract:** Anomaly detection on the attributed network has recently received increasing attention in many research fields, such as cybernetic anomaly detection and financial fraud detection. With the wide application of deep learning on graph representations, existing approaches choose to apply euclidean graph encoders as their backbone, which may lose important hierarchical information, especially in complex networks. To tackle this problem, we propose an efficient anomaly detection framework using hyperbolic self-supervised contrastive learning. Specifically, we first conduct the data augmentation by performing subgraph sampling. Then we utilize the hierarchical information in hyperbolic space through exponential mapping and logarithmic mapping and obtain the anomaly score by subtracting scores of the positive pairs from the negative pairs via a discriminating process. Finally, extensive experiments on four real-world datasets demonstrate that our approach performs superior over representative baseline approaches.

</p>
</details>

<details><summary><b>A Temporal Graphlet Kernel for Classifying Dissemination in Evolving Networks</b>
<a href="https://arxiv.org/abs/2209.07332">arxiv:2209.07332</a>
&#x1F4C8; 1 <br>
<p>Lutz Oettershagen, Nils M. Kriege, Claude Jordan, Petra Mutzel</p></summary>
<p>

**Abstract:** We introduce the \emph{temporal graphlet kernel} for classifying dissemination processes in labeled temporal graphs. Such dissemination processes can be spreading (fake) news, infectious diseases, or computer viruses in dynamic networks. The networks are modeled as labeled temporal graphs, in which the edges exist at specific points in time, and node labels change over time. The classification problem asks to discriminate dissemination processes of different origins or parameters, e.g., infectious diseases with different infection probabilities. Our new kernel represents labeled temporal graphs in the feature space of temporal graphlets, i.e., small subgraphs distinguished by their structure, time-dependent node labels, and chronological order of edges. We introduce variants of our kernel based on classes of graphlets that are efficiently countable. For the case of temporal wedges, we propose a highly efficient approximative kernel with low error in expectation. We show that our kernels are faster to compute and provide better accuracy than state-of-the-art methods.

</p>
</details>

<details><summary><b>On topological data analysis for SHM; an introduction to persistent homology</b>
<a href="https://arxiv.org/abs/2209.06155">arxiv:2209.06155</a>
&#x1F4C8; 1 <br>
<p>Tristan Gowdridge, Nikolaos Devilis, Keith Worden</p></summary>
<p>

**Abstract:** This paper aims to discuss a method of quantifying the 'shape' of data, via a methodology called topological data analysis. The main tool within topological data analysis is persistent homology; this is a means of measuring the shape of data, from the homology of a simplicial complex, calculated over a range of values. The required background theory and a method of computing persistent homology is presented here, with applications specific to structural health monitoring. These results allow for topological inference and the ability to deduce features in higher-dimensional data, that might otherwise be overlooked.
  A simplicial complex is constructed for data for a given distance parameter. This complex encodes information about the local proximity of data points. A singular homology value can be calculated from this simplicial complex. Extending this idea, the distance parameter is given for a range of values, and the homology is calculated over this range. The persistent homology is a representation of how the homological features of the data persist over this interval. The result is characteristic to the data. A method that allows for the comparison of the persistent homology for different data sets is also discussed.

</p>
</details>

<details><summary><b>CustOmics: A versatile deep-learning based strategy for multi-omics integration</b>
<a href="https://arxiv.org/abs/2209.05485">arxiv:2209.05485</a>
&#x1F4C8; 1 <br>
<p>Hakim Benkirane, Yoann Pradat, Stefan Michiels, Paul-Henry Cournède</p></summary>
<p>

**Abstract:** Recent advances in high-throughput sequencing technologies have enabled the extraction of multiple features that depict patient samples at diverse and complementary molecular levels. The generation of such data has led to new challenges in computational biology regarding the integration of high-dimensional and heterogeneous datasets that capture the interrelationships between multiple genes and their functions. Thanks to their versatility and ability to learn synthetic latent representations of complex data, deep learning methods offer promising perspectives for integrating multi-omics data. These methods have led to the conception of many original architectures that are primarily based on autoencoder models. However, due to the difficulty of the task, the integration strategy is fundamental to take full advantage of the sources' particularities without losing the global trends. This paper presents a novel strategy to build a customizable autoencoder model that adapts to the dataset used in the case of high-dimensional multi-source integration. We will assess the impact of integration strategies on the latent representation and combine the best strategies to propose a new method, CustOmics (https://github.com/HakimBenkirane/CustOmics). We focus here on the integration of data from multiple omics sources and demonstrate the performance of the proposed method on test cases for several tasks such as classification and survival analysis.

</p>
</details>

<details><summary><b>Vision Transformer with Convolutional Encoder-Decoder for Hand Gesture Recognition using 24 GHz Doppler Radar</b>
<a href="https://arxiv.org/abs/2209.05032">arxiv:2209.05032</a>
&#x1F4C8; 1 <br>
<p>Kavinda Kehelella, Gayangana Leelarathne, Dhanuka Marasinghe, Nisal Kariyawasam, Viduneth Ariyarathna, Arjuna Madanayake, Ranga Rodrigo, Chamira U. S. Edussooriya</p></summary>
<p>

**Abstract:** Transformers combined with convolutional encoders have been recently used for hand gesture recognition (HGR) using micro-Doppler signatures. We propose a vision-transformer-based architecture for HGR with multi-antenna continuous-wave Doppler radar receivers. The proposed architecture consists of three modules: a convolutional encoderdecoder, an attention module with three transformer layers, and a multi-layer perceptron. The novel convolutional decoder helps to feed patches with larger sizes to the attention module for improved feature extraction. Experimental results obtained with a dataset corresponding to a two-antenna continuous-wave Doppler radar receiver operating at 24 GHz (published by Skaria et al.) confirm that the proposed architecture achieves an accuracy of 98.3% which substantially surpasses the state-of-the-art on the used dataset.

</p>
</details>


{% endraw %}
Prev: [2022.09.11]({{ '/2022/09/11/2022.09.11.html' | relative_url }})  Next: [2022.09.13]({{ '/2022/09/13/2022.09.13.html' | relative_url }})