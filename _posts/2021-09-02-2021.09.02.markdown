## Summary for 2021-09-02, created on 2021-12-18


<details><summary><b>Learning Language-Conditioned Robot Behavior from Offline Data and Crowd-Sourced Annotation</b>
<a href="https://arxiv.org/abs/2109.01115">arxiv:2109.01115</a>
&#x1F4C8; 63 <br>
<p>Suraj Nair, Eric Mitchell, Kevin Chen, Brian Ichter, Silvio Savarese, Chelsea Finn</p></summary>
<p>

**Abstract:** We study the problem of learning a range of vision-based manipulation tasks from a large offline dataset of robot interaction. In order to accomplish this, humans need easy and effective ways of specifying tasks to the robot. Goal images are one popular form of task specification, as they are already grounded in the robot's observation space. However, goal images also have a number of drawbacks: they are inconvenient for humans to provide, they can over-specify the desired behavior leading to a sparse reward signal, or under-specify task information in the case of non-goal reaching tasks. Natural language provides a convenient and flexible alternative for task specification, but comes with the challenge of grounding language in the robot's observation space. To scalably learn this grounding we propose to leverage offline robot datasets (including highly sub-optimal, autonomously collected data) with crowd-sourced natural language labels. With this data, we learn a simple classifier which predicts if a change in state completes a language instruction. This provides a language-conditioned reward function that can then be used for offline multi-task RL. In our experiments, we find that on language-conditioned manipulation tasks our approach outperforms both goal-image specifications and language conditioned imitation techniques by more than 25%, and is able to perform visuomotor tasks from natural language, such as "open the right drawer" and "move the stapler", on a Franka Emika Panda robot.

</p>
</details>

<details><summary><b>Sequence-to-Sequence Learning with Latent Neural Grammars</b>
<a href="https://arxiv.org/abs/2109.01135">arxiv:2109.01135</a>
&#x1F4C8; 49 <br>
<p>Yoon Kim</p></summary>
<p>

**Abstract:** Sequence-to-sequence learning with neural networks has become the de facto standard for sequence prediction tasks. This approach typically models the local distribution over the next word with a powerful neural network that can condition on arbitrary context. While flexible and performant, these models often require large datasets for training and can fail spectacularly on benchmarks designed to test for compositional generalization. This work explores an alternative, hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars, where each node in the target tree is transduced by a node in the source tree. Both the source and target trees are treated as latent and induced during training. We develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. We apply this latent neural grammar to various domains -- a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation -- and find that it performs respectably compared to standard baselines.

</p>
</details>

<details><summary><b>Optimal subgroup selection</b>
<a href="https://arxiv.org/abs/2109.01077">arxiv:2109.01077</a>
&#x1F4C8; 42 <br>
<p>Henry W. J. Reeve, Timothy I. Cannings, Richard J. Samworth</p></summary>
<p>

**Abstract:** In clinical trials and other applications, we often see regions of the feature space that appear to exhibit interesting behaviour, but it is unclear whether these observed phenomena are reflected at the population level. Focusing on a regression setting, we consider the subgroup selection challenge of identifying a region of the feature space on which the regression function exceeds a pre-determined threshold. We formulate the problem as one of constrained optimisation, where we seek a low-complexity, data-dependent selection set on which, with a guaranteed probability, the regression function is uniformly at least as large as the threshold; subject to this constraint, we would like the region to contain as much mass under the marginal feature distribution as possible. This leads to a natural notion of regret, and our main contribution is to determine the minimax optimal rate for this regret in both the sample size and the Type I error probability. The rate involves a delicate interplay between parameters that control the smoothness of the regression function, as well as exponents that quantify the extent to which the optimal selection set at the population level can be approximated by families of well-behaved subsets. Finally, we expand the scope of our previous results by illustrating how they may be generalised to a treatment and control setting, where interest lies in the heterogeneous treatment effect.

</p>
</details>

<details><summary><b>Learning to Prompt for Vision-Language Models</b>
<a href="https://arxiv.org/abs/2109.01134">arxiv:2109.01134</a>
&#x1F4C8; 30 <br>
<p>Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu</p></summary>
<p>

**Abstract:** Vision-language pre-training has recently emerged as a promising alternative for representation learning. It shifts from the tradition of using images and discrete labels for learning a fixed set of weights, seen as visual concepts, to aligning images and raw text for two separate encoders. Such a paradigm benefits from a broader source of supervision and allows zero-shot transfer to downstream tasks since visual concepts can be diametrically generated from natural language, known as prompt. In this paper, we identify that a major challenge of deploying such models in practice is prompt engineering. This is because designing a proper prompt, especially for context words surrounding a class name, requires domain expertise and typically takes a significant amount of time for words tuning since a slight change in wording could have a huge impact on performance. Moreover, different downstream tasks require specific designs, further hampering the efficiency of deployment. To overcome this challenge, we propose a novel approach named context optimization (CoOp). The main idea is to model context in prompts using continuous representations and perform end-to-end learning from data while keeping the pre-trained parameters fixed. In this way, the design of task-relevant prompts can be fully automated. Experiments on 11 datasets show that CoOp effectively turns pre-trained vision-language models into data-efficient visual learners, requiring as few as one or two shots to beat hand-crafted prompts with a decent margin and able to gain significant improvements when using more shots (e.g., at 16 shots the average gain is around 17% with the highest reaching over 50%). CoOp also exhibits strong robustness to distribution shift.

</p>
</details>

<details><summary><b>Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond</b>
<a href="https://arxiv.org/abs/2109.00725">arxiv:2109.00725</a>
&#x1F4C8; 30 <br>
<p>Amir Feder, Katherine A. Keith, Emaad Manzoor, Reid Pryzant, Dhanya Sridhar, Zach Wood-Doughty, Jacob Eisenstein, Justin Grimmer, Roi Reichart, Margaret E. Roberts, Brandon M. Stewart, Victor Veitch, Diyi Yang</p></summary>
<p>

**Abstract:** A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the remaining challenges. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects, encompassing settings where text is used as an outcome, treatment, or as a means to address confounding. In addition, we explore potential uses of causal inference to improve the performance, robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the computational linguistics community.

</p>
</details>

<details><summary><b>GAM: Explainable Visual Similarity and Classification via Gradient Activation Maps</b>
<a href="https://arxiv.org/abs/2109.00951">arxiv:2109.00951</a>
&#x1F4C8; 26 <br>
<p>Oren Barkan, Omri Armstrong, Amir Hertz, Avi Caciularu, Ori Katz, Itzik Malkiel, Noam Koenigstein</p></summary>
<p>

**Abstract:** We present Gradient Activation Maps (GAM) - a machinery for explaining predictions made by visual similarity and classification models. By gleaning localized gradient and activation information from multiple network layers, GAM offers improved visual explanations, when compared to existing alternatives. The algorithmic advantages of GAM are explained in detail, and validated empirically, where it is shown that GAM outperforms its alternatives across various tasks and datasets.

</p>
</details>

<details><summary><b>Multimodal Conditionality for Natural Language Generation</b>
<a href="https://arxiv.org/abs/2109.01229">arxiv:2109.01229</a>
&#x1F4C8; 25 <br>
<p>Michael Sollami, Aashish Jain</p></summary>
<p>

**Abstract:** Large scale pretrained language models have demonstrated state-of-the-art performance in language understanding tasks. Their application has recently expanded into multimodality learning, leading to improved representations combining vision and language. However, progress in adapting language models towards conditional Natural Language Generation (NLG) has been limited to a single modality, generally text. We propose MAnTiS, Multimodal Adaptation for Text Synthesis, a general approach for multimodal conditionality in transformer-based NLG models. In this method, we pass inputs from each modality through modality-specific encoders, project to textual token space, and finally join to form a conditionality prefix. We fine-tune the pretrained language model and encoders with the conditionality prefix guiding the generation. We apply MAnTiS to the task of product description generation, conditioning a network on both product images and titles to generate descriptive text. We demonstrate that MAnTiS outperforms strong baseline approaches on standard NLG scoring metrics. Furthermore, qualitative assessments demonstrate that MAnTiS can generate human quality descriptions consistent with given multimodal inputs.

</p>
</details>

<details><summary><b>Top-N Recommendation with Counterfactual User Preference Simulation</b>
<a href="https://arxiv.org/abs/2109.02444">arxiv:2109.02444</a>
&#x1F4C8; 22 <br>
<p>Mengyue Yang, Quanyu Dai, Zhenhua Dong, Xu Chen, Xiuqiang He, Jun Wang</p></summary>
<p>

**Abstract:** Top-N recommendation, which aims to learn user ranking-based preference, has long been a fundamental problem in a wide range of applications. Traditional models usually motivate themselves by designing complex or tailored architectures based on different assumptions. However, the training data of recommender system can be extremely sparse and imbalanced, which poses great challenges for boosting the recommendation performance. To alleviate this problem, in this paper, we propose to reformulate the recommendation task within the causal inference framework, which enables us to counterfactually simulate user ranking-based preferences to handle the data scarce problem. The core of our model lies in the counterfactual question: "what would be the user's decision if the recommended items had been different?". To answer this question, we firstly formulate the recommendation process with a series of structural equation models (SEMs), whose parameters are optimized based on the observed data. Then, we actively indicate many recommendation lists (called intervention in the causal inference terminology) which are not recorded in the dataset, and simulate user feedback according to the learned SEMs for generating new training samples. Instead of randomly intervening on the recommendation list, we design a learning-based method to discover more informative training samples. Considering that the learned SEMs can be not perfect, we, at last, theoretically analyze the relation between the number of generated samples and the model prediction error, based on which a heuristic method is designed to control the negative effect brought by the prediction error. Extensive experiments are conducted based on both synthetic and real-world datasets to demonstrate the effectiveness of our framework.

</p>
</details>

<details><summary><b>Characterizing possible failure modes in physics-informed neural networks</b>
<a href="https://arxiv.org/abs/2109.01050">arxiv:2109.01050</a>
&#x1F4C8; 22 <br>
<p>Aditi S. Krishnapriyan, Amir Gholami, Shandian Zhe, Robert M. Kirby, Michael W. Mahoney</p></summary>
<p>

**Abstract:** Recent work in scientific machine learning has developed so-called physics-informed neural network (PINN) models. The typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. We demonstrate that, while existing PINN methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. In particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. We provide evidence that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. Importantly, we show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN's setup makes the loss landscape very hard to optimize. We then describe two promising solutions to address these failure modes. The first approach is to use curriculum regularization, where the PINN's loss term starts from a simple PDE regularization, and becomes progressively more complex as the NN gets trained. The second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. Extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular PINN training.

</p>
</details>

<details><summary><b>An Empirical Study on Leveraging Position Embeddings for Target-oriented Opinion Words Extraction</b>
<a href="https://arxiv.org/abs/2109.01238">arxiv:2109.01238</a>
&#x1F4C8; 10 <br>
<p>Samuel Mensah, Kai Sun, Nikolaos Aletras</p></summary>
<p>

**Abstract:** Target-oriented opinion words extraction (TOWE) (Fan et al., 2019b) is a new subtask of target-oriented sentiment analysis that aims to extract opinion words for a given aspect in text. Current state-of-the-art methods leverage position embeddings to capture the relative position of a word to the target. However, the performance of these methods depends on the ability to incorporate this information into word representations. In this paper, we explore a variety of text encoders based on pretrained word embeddings or language models that leverage part-of-speech and position embeddings, aiming to examine the actual contribution of each component in TOWE. We also adapt a graph convolutional network (GCN) to enhance word representations by incorporating syntactic information. Our experimental results demonstrate that BiLSTM-based models can effectively encode position information into word representations while using a GCN only achieves marginal gains. Interestingly, our simple methods outperform several state-of-the-art complex neural structures.

</p>
</details>

<details><summary><b>Challenges in Generalization in Open Domain Question Answering</b>
<a href="https://arxiv.org/abs/2109.01156">arxiv:2109.01156</a>
&#x1F4C8; 9 <br>
<p>Linqing Liu, Patrick Lewis, Sebastian Riedel, Pontus Stenetorp</p></summary>
<p>

**Abstract:** Recent work on Open Domain Question Answering has shown that there is a large discrepancy in model performance between novel test questions and those that largely overlap with training questions. However, it is unclear which aspects of novel questions make them challenging. Drawing upon studies on systematic generalization, we introduce and annotate questions according to three categories that measure different levels and kinds of generalization: training set overlap, compositional generalization (comp-gen), and novel-entity generalization (novel-entity). When evaluating six popular parametric and non-parametric models, we find that for the established Natural Questions and TriviaQA datasets, even the strongest model performance for comp-gen/novel-entity is 13.1/5.4% and 9.6/1.5% lower compared to that for the full test set -- indicating the challenge posed by these types of questions. Furthermore, we show that whilst non-parametric models can handle questions containing novel entities relatively well, they struggle with those requiring compositional generalization. Lastly, we find that key question difficulty factors are: cascading errors from the retrieval component, frequency of question pattern, and frequency of the entity.

</p>
</details>

<details><summary><b>On-target Adaptation</b>
<a href="https://arxiv.org/abs/2109.01087">arxiv:2109.01087</a>
&#x1F4C8; 9 <br>
<p>Dequan Wang, Shaoteng Liu, Sayna Ebrahimi, Evan Shelhamer, Trevor Darrell</p></summary>
<p>

**Abstract:** Domain adaptation seeks to mitigate the shift between training on the \emph{source} domain and testing on the \emph{target} domain. Most adaptation methods rely on the source data by joint optimization over source data and target data. Source-free methods replace the source data with a source model by fine-tuning it on target. Either way, the majority of the parameter updates for the model representation and the classifier are derived from the source, and not the target. However, target accuracy is the goal, and so we argue for optimizing as much as possible on the target data. We show significant improvement by on-target adaptation, which learns the representation purely from target data while taking only the source predictions for supervision. In the long-tailed classification setting, we show further improvement by on-target class distribution learning, which learns the (im)balance of classes from target data.

</p>
</details>

<details><summary><b>Self-timed Reinforcement Learning using Tsetlin Machine</b>
<a href="https://arxiv.org/abs/2109.00846">arxiv:2109.00846</a>
&#x1F4C8; 9 <br>
<p>Adrian Wheeldon, Alex Yakovlev, Rishad Shafik</p></summary>
<p>

**Abstract:** We present a hardware design for the learning datapath of the Tsetlin machine algorithm, along with a latency analysis of the inference datapath. In order to generate a low energy hardware which is suitable for pervasive artificial intelligence applications, we use a mixture of asynchronous design techniques - including Petri nets, signal transition graphs, dual-rail and bundled-data. The work builds on previous design of the inference hardware, and includes an in-depth breakdown of the automaton feedback, probability generation and Tsetlin automata. Results illustrate the advantages of asynchronous design in applications such as personalized healthcare and battery-powered internet of things devices, where energy is limited and latency is an important figure of merit. Challenges of static timing analysis in asynchronous circuits are also addressed.

</p>
</details>

<details><summary><b>Artificial Intelligence in Dry Eye Disease</b>
<a href="https://arxiv.org/abs/2109.01658">arxiv:2109.01658</a>
&#x1F4C8; 8 <br>
<p>Andrea M. Storås, Inga Strümke, Michael A. Riegler, Jakob Grauslund, Hugo L. Hammer, Anis Yazidi, Pål Halvorsen, Kjell G. Gundersen, Tor P. Utheim, Catherine Jackson</p></summary>
<p>

**Abstract:** Dry eye disease (DED) has a prevalence of between 5 and 50\%, depending on the diagnostic criteria used and population under study. However, it remains one of the most underdiagnosed and undertreated conditions in ophthalmology. Many tests used in the diagnosis of DED rely on an experienced observer for image interpretation, which may be considered subjective and result in variation in diagnosis. Since artificial intelligence (AI) systems are capable of advanced problem solving, use of such techniques could lead to more objective diagnosis. Although the term `AI' is commonly used, recent success in its applications to medicine is mainly due to advancements in the sub-field of machine learning, which has been used to automatically classify images and predict medical outcomes. Powerful machine learning techniques have been harnessed to understand nuances in patient data and medical images, aiming for consistent diagnosis and stratification of disease severity. This is the first literature review on the use of AI in DED. We provide a brief introduction to AI, report its current use in DED research and its potential for application in the clinic. Our review found that AI has been employed in a wide range of DED clinical tests and research applications, primarily for interpretation of interferometry, slit-lamp and meibography images. While initial results are promising, much work is still needed on model development, clinical testing and standardisation.

</p>
</details>

<details><summary><b>Adversarial Robustness for Unsupervised Domain Adaptation</b>
<a href="https://arxiv.org/abs/2109.00946">arxiv:2109.00946</a>
&#x1F4C8; 8 <br>
<p>Muhammad Awais, Fengwei Zhou, Hang Xu, Lanqing Hong, Ping Luo, Sung-Ho Bae, Zhenguo Li</p></summary>
<p>

**Abstract:** Extensive Unsupervised Domain Adaptation (UDA) studies have shown great success in practice by learning transferable representations across a labeled source domain and an unlabeled target domain with deep models. However, previous works focus on improving the generalization ability of UDA models on clean examples without considering the adversarial robustness, which is crucial in real-world applications. Conventional adversarial training methods are not suitable for the adversarial robustness on the unlabeled target domain of UDA since they train models with adversarial examples generated by the supervised loss function. In this work, we leverage intermediate representations learned by multiple robust ImageNet models to improve the robustness of UDA models. Our method works by aligning the features of the UDA model with the robust features learned by ImageNet pre-trained models along with domain adaptation training. It utilizes both labeled and unlabeled domains and instills robustness without any adversarial intervention or label requirement during domain adaptation training. Experimental results show that our method significantly improves adversarial robustness compared to the baseline while keeping clean accuracy on various UDA benchmarks.

</p>
</details>

<details><summary><b>Studying the Effects of Self-Attention for Medical Image Analysis</b>
<a href="https://arxiv.org/abs/2109.01486">arxiv:2109.01486</a>
&#x1F4C8; 7 <br>
<p>Adrit Rao, Jongchan Park, Sanghyun Woo, Joon-Young Lee, Oliver Aalami</p></summary>
<p>

**Abstract:** When the trained physician interprets medical images, they understand the clinical importance of visual features. By applying cognitive attention, they apply greater focus onto clinically relevant regions while disregarding unnecessary features. The use of computer vision to automate the classification of medical images is widely studied. However, the standard convolutional neural network (CNN) does not necessarily employ subconscious feature relevancy evaluation techniques similar to the trained medical specialist and evaluates features more generally. Self-attention mechanisms enable CNNs to focus more on semantically important regions or aggregated relevant context with long-range dependencies. By using attention, medical image analysis systems can potentially become more robust by focusing on more important clinical feature regions. In this paper, we provide a comprehensive comparison of various state-of-the-art self-attention mechanisms across multiple medical image analysis tasks. Through both quantitative and qualitative evaluations along with a clinical user-centric survey study, we aim to provide a deeper understanding of the effects of self-attention in medical computer vision tasks.

</p>
</details>

<details><summary><b>Dynamic Scene Novel View Synthesis via Deferred Spatio-temporal Consistency</b>
<a href="https://arxiv.org/abs/2109.01018">arxiv:2109.01018</a>
&#x1F4C8; 7 <br>
<p>Beatrix-Emőke Fülöp-Balogh, Eleanor Tursman, James Tompkin, Julie Digne, Nicolas Bonneel</p></summary>
<p>

**Abstract:** Structure from motion (SfM) enables us to reconstruct a scene via casual capture from cameras at different viewpoints, and novel view synthesis (NVS) allows us to render a captured scene from a new viewpoint. Both are hard with casual capture and dynamic scenes: SfM produces noisy and spatio-temporally sparse reconstructed point clouds, resulting in NVS with spatio-temporally inconsistent effects. We consider SfM and NVS parts together to ease the challenge. First, for SfM, we recover stable camera poses, then we defer the requirement for temporally-consistent points across the scene and reconstruct only a sparse point cloud per timestep that is noisy in space-time. Second, for NVS, we present a variational diffusion formulation on depths and colors that lets us robustly cope with the noise by enforcing spatio-temporal consistency via per-pixel reprojection weights derived from the input views. Together, this deferred approach generates novel views for dynamic scenes without requiring challenging spatio-temporally consistent reconstructions nor training complex models on large datasets. We demonstrate our algorithm on real-world dynamic scenes against classic and more recent learning-based baseline approaches.

</p>
</details>

<details><summary><b>Information Symmetry Matters: A Modal-Alternating Propagation Network for Few-Shot Learning</b>
<a href="https://arxiv.org/abs/2109.01295">arxiv:2109.01295</a>
&#x1F4C8; 6 <br>
<p>Zhong Ji, Zhishen Hou, Xiyao Liu, Yanwei Pang, Jungong Han</p></summary>
<p>

**Abstract:** Semantic information provides intra-class consistency and inter-class discriminability beyond visual concepts, which has been employed in Few-Shot Learning (FSL) to achieve further gains. However, semantic information is only available for labeled samples but absent for unlabeled samples, in which the embeddings are rectified unilaterally by guiding the few labeled samples with semantics. Therefore, it is inevitable to bring a cross-modal bias between semantic-guided samples and nonsemantic-guided samples, which results in an information asymmetry problem. To address this problem, we propose a Modal-Alternating Propagation Network (MAP-Net) to supplement the absent semantic information of unlabeled samples, which builds information symmetry among all samples in both visual and semantic modalities. Specifically, the MAP-Net transfers the neighbor information by the graph propagation to generate the pseudo-semantics for unlabeled samples guided by the completed visual relationships and rectify the feature embeddings. In addition, due to the large discrepancy between visual and semantic modalities, we design a Relation Guidance (RG) strategy to guide the visual relation vectors via semantics so that the propagated information is more beneficial. Extensive experimental results on three semantic-labeled datasets, i.e., Caltech-UCSD-Birds 200-2011, SUN Attribute Database, and Oxford 102 Flower, have demonstrated that our proposed method achieves promising performance and outperforms the state-of-the-art approaches, which indicates the necessity of information symmetry.

</p>
</details>

<details><summary><b>Solving Inverse Problems with Conditional-GAN Prior via Fast Network-Projected Gradient Descent</b>
<a href="https://arxiv.org/abs/2109.01105">arxiv:2109.01105</a>
&#x1F4C8; 6 <br>
<p>Muhammad Fadli Damara, Gregor Kornhardt, Peter Jung</p></summary>
<p>

**Abstract:** The projected gradient descent (PGD) method has shown to be effective in recovering compressed signals described in a data-driven way by a generative model, i.e., a generator which has learned the data distribution. Further reconstruction improvements for such inverse problems can be achieved by conditioning the generator on the measurement. The boundary equilibrium generative adversarial network (BEGAN) implements an equilibrium based loss function and an auto-encoding discriminator to better balance the performance of the generator and the discriminator. In this work we investigate a network-based projected gradient descent (NPGD) algorithm for measurement-conditional generative models to solve the inverse problem much faster than regular PGD. We combine the NPGD with conditional GAN/BEGAN to evaluate their effectiveness in solving compressed sensing type problems. Our experiments on the MNIST and CelebA datasets show that the combination of measurement conditional model with NPGD works well in recovering the compressed signal while achieving similar or in some cases even better performance along with a much faster reconstruction. The achieved reconstruction speed-up in our experiments is up to 140-175.

</p>
</details>

<details><summary><b>Self-Taught Cross-Domain Few-Shot Learning with Weakly Supervised Object Localization and Task-Decomposition</b>
<a href="https://arxiv.org/abs/2109.01302">arxiv:2109.01302</a>
&#x1F4C8; 5 <br>
<p>Xiyao Liu, Zhong Ji, Yanwei Pang, Zhongfei Zhang</p></summary>
<p>

**Abstract:** The domain shift between the source and target domain is the main challenge in Cross-Domain Few-Shot Learning (CD-FSL). However, the target domain is absolutely unknown during the training on the source domain, which results in lacking directed guidance for target tasks. We observe that since there are similar backgrounds in target domains, it can apply self-labeled samples as prior tasks to transfer knowledge onto target tasks. To this end, we propose a task-expansion-decomposition framework for CD-FSL, called Self-Taught (ST) approach, which alleviates the problem of non-target guidance by constructing task-oriented metric spaces. Specifically, Weakly Supervised Object Localization (WSOL) and self-supervised technologies are employed to enrich task-oriented samples by exchanging and rotating the discriminative regions, which generates a more abundant task set. Then these tasks are decomposed into several tasks to finish the task of few-shot recognition and rotation classification. It helps to transfer the source knowledge onto the target tasks and focus on discriminative regions. We conduct extensive experiments under the cross-domain setting including 8 target domains: CUB, Cars, Places, Plantae, CropDieases, EuroSAT, ISIC, and ChestX. Experimental results demonstrate that the proposed ST approach is applicable to various metric-based models, and provides promising improvements in CD-FSL.

</p>
</details>

<details><summary><b>Towards disease-aware image editing of chest X-rays</b>
<a href="https://arxiv.org/abs/2109.01071">arxiv:2109.01071</a>
&#x1F4C8; 5 <br>
<p>Aakash Saboo, Sai Niranjan Ramachandran, Kai Dierkes, Hacer Yalim Keles</p></summary>
<p>

**Abstract:** Disease-aware image editing by means of generative adversarial networks (GANs) constitutes a promising avenue for advancing the use of AI in the healthcare sector. Here, we present a proof of concept of this idea. While GAN-based techniques have been successful in generating and manipulating natural images, their application to the medical domain, however, is still in its infancy. Working with the CheXpert data set, we show that StyleGAN can be trained to generate realistic chest X-rays. Inspired by the Cyclic Reverse Generator (CRG) framework, we train an encoder that allows for faithfully inverting the generator on synthetic X-rays and provides organ-level reconstructions of real ones. Employing a guided manipulation of latent codes, we confer the medical condition of cardiomegaly (increased heart size) onto real X-rays from healthy patients. This work was presented in the Medical Imaging meets Neurips Workshop 2020, which was held as part of the 34th Conference on Neural Information Processing Systems (NeurIPS 2020) in Vancouver, Canada

</p>
</details>

<details><summary><b>Effect of the output activation function on the probabilities and errors in medical image segmentation</b>
<a href="https://arxiv.org/abs/2109.00903">arxiv:2109.00903</a>
&#x1F4C8; 5 <br>
<p>Lars Nieradzik, Gerik Scheuermann, Dorothee Saur, Christina Gillmann</p></summary>
<p>

**Abstract:** The sigmoid activation is the standard output activation function in binary classification and segmentation with neural networks. Still, there exist a variety of other potential output activation functions, which may lead to improved results in medical image segmentation. In this work, we consider how the asymptotic behavior of different output activation and loss functions affects the prediction probabilities and the corresponding segmentation errors. For cross entropy, we show that a faster rate of change of the activation function correlates with better predictions, while a slower rate of change can improve the calibration of probabilities. For dice loss, we found that the arctangent activation function is superior to the sigmoid function. Furthermore, we provide a test space for arbitrary output activation functions in the area of medical image segmentation. We tested seven activation functions in combination with three loss functions on four different medical image segmentation tasks to provide a classification of which function is best suited in this application scenario.

</p>
</details>

<details><summary><b>MACRPO: Multi-Agent Cooperative Recurrent Policy Optimization</b>
<a href="https://arxiv.org/abs/2109.00882">arxiv:2109.00882</a>
&#x1F4C8; 5 <br>
<p>Eshagh Kargar, Ville Kyrki</p></summary>
<p>

**Abstract:** This work considers the problem of learning cooperative policies in multi-agent settings with partially observable and non-stationary environments without a communication channel. We focus on improving information sharing between agents and propose a new multi-agent actor-critic method called \textit{Multi-Agent Cooperative Recurrent Proximal Policy Optimization} (MACRPO). We propose two novel ways of integrating information across agents and time in MACRPO: First, we use a recurrent layer in critic's network architecture and propose a new framework to use a meta-trajectory to train the recurrent layer. This allows the network to learn the cooperation and dynamics of interactions between agents, and also handle partial observability. Second, we propose a new advantage function that incorporates other agents' rewards and value functions. We evaluate our algorithm on three challenging multi-agent environments with continuous and discrete action spaces, Deepdrive-Zero, Multi-Walker, and Particle environment. We compare the results with several ablations and state-of-the-art multi-agent algorithms such as QMIX and MADDPG and also single-agent methods with shared parameters between agents such as IMPALA and APEX. The results show superior performance against other algorithms. The code is available online at https://github.com/kargarisaac/macrpo.

</p>
</details>

<details><summary><b>Tree-Constrained Graph Neural Networks For Argument Mining</b>
<a href="https://arxiv.org/abs/2110.00124">arxiv:2110.00124</a>
&#x1F4C8; 4 <br>
<p>Federico Ruggeri, Marco Lippi, Paolo Torroni</p></summary>
<p>

**Abstract:** We propose a novel architecture for Graph Neural Networks that is inspired by the idea behind Tree Kernels of measuring similarity between trees by taking into account their common substructures, named fragments. By imposing a series of regularization constraints to the learning problem, we exploit a pooling mechanism that incorporates such notion of fragments within the node soft assignment function that produces the embeddings. We present an extensive experimental evaluation on a collection of sentence classification tasks conducted on several argument mining corpora, showing that the proposed approach performs well with respect to state-of-the-art techniques.

</p>
</details>

<details><summary><b>Two Shifts for Crop Mapping: Leveraging Aggregate Crop Statistics to Improve Satellite-based Maps in New Regions</b>
<a href="https://arxiv.org/abs/2109.01246">arxiv:2109.01246</a>
&#x1F4C8; 4 <br>
<p>Dan M. Kluger, Sherrie Wang, David B. Lobell</p></summary>
<p>

**Abstract:** Crop type mapping at the field level is critical for a variety of applications in agricultural monitoring, and satellite imagery is becoming an increasingly abundant and useful raw input from which to create crop type maps. Still, in many regions crop type mapping with satellite data remains constrained by a scarcity of field-level crop labels for training supervised classification models. When training data is not available in one region, classifiers trained in similar regions can be transferred, but shifts in the distribution of crop types as well as transformations of the features between regions lead to reduced classification accuracy. We present a methodology that uses aggregate-level crop statistics to correct the classifier by accounting for these two types of shifts. To adjust for shifts in the crop type composition we present a scheme for properly reweighting the posterior probabilities of each class that are output by the classifier. To adjust for shifts in features we propose a method to estimate and remove linear shifts in the mean feature vector. We demonstrate that this methodology leads to substantial improvements in overall classification accuracy when using Linear Discriminant Analysis (LDA) to map crop types in Occitanie, France and in Western Province, Kenya. When using LDA as our base classifier, we found that in France our methodology led to percent reductions in misclassifications ranging from 2.8% to 42.2% (mean = 21.9%) over eleven different training departments, and in Kenya the percent reductions in misclassification were 6.6%, 28.4%, and 42.7% for three training regions. While our methodology was statistically motivated by the LDA classifier, it can be applied to any type of classifier. As an example, we demonstrate its successful application to improve a Random Forest classifier.

</p>
</details>

<details><summary><b>So Cloze yet so Far: N400 Amplitude is Better Predicted by Distributional Information than Human Predictability Judgements</b>
<a href="https://arxiv.org/abs/2109.01226">arxiv:2109.01226</a>
&#x1F4C8; 4 <br>
<p>James A. Michaelov, Seana Coulson, Benjamin K. Bergen</p></summary>
<p>

**Abstract:** More predictable words are easier to process - they are read faster and elicit smaller neural signals associated with processing difficulty, most notably, the N400 component of the event-related brain potential. Thus, it has been argued that prediction of upcoming words is a key component of language comprehension, and that studying the amplitude of the N400 is a valuable way to investigate the predictions that we make. In this study, we investigate whether the linguistic predictions of computational language models or humans better reflect the way in which natural language stimuli modulate the amplitude of the N400. One important difference in the linguistic predictions of humans versus computational language models is that while language models base their predictions exclusively on the preceding linguistic context, humans may rely on other factors. We find that the predictions of three top-of-the-line contemporary language models - GPT-3, RoBERTa, and ALBERT - match the N400 more closely than human predictions. This suggests that the predictive processes underlying the N400 may be more sensitive to the surface-level statistics of language than previously thought.

</p>
</details>

<details><summary><b>Benchmarking the Robustness of Instance Segmentation Models</b>
<a href="https://arxiv.org/abs/2109.01123">arxiv:2109.01123</a>
&#x1F4C8; 4 <br>
<p>Said Fahri Altindis, Yusuf Dalva, Aysegul Dundar</p></summary>
<p>

**Abstract:** This paper presents a comprehensive evaluation of instance segmentation models with respect to real-world image corruptions and out-of-domain image collections, e.g. datasets collected with different set-ups than the training datasets the models learned from. The out-of-domain image evaluation shows the generalization capability of models, an essential aspect of real-world applications, and an extensively studied topic of domain adaptation. These presented robustness and generalization evaluations are important when designing instance segmentation models for real-world applications and picking an off-the-shelf pretrained model to directly use for the task at hand. Specifically, this benchmark study includes state-of-the-art network architectures, network backbones, normalization layers, models trained starting from scratch or ImageNet pretrained networks, and the effect of multi-task training on robustness and generalization. Through this study, we gain several insights e.g. we find that normalization layers play an essential role in robustness, ImageNet pretraining does not help the robustness and the generalization of models, excluding JPEG corruption, and network backbones and copy-paste augmentations affect robustness significantly.

</p>
</details>

<details><summary><b>The Functional Correspondence Problem</b>
<a href="https://arxiv.org/abs/2109.01097">arxiv:2109.01097</a>
&#x1F4C8; 4 <br>
<p>Zihang Lai, Senthil Purushwalkam, Abhinav Gupta</p></summary>
<p>

**Abstract:** The ability to find correspondences in visual data is the essence of most computer vision tasks. But what are the right correspondences? The task of visual correspondence is well defined for two different images of same object instance. In case of two images of objects belonging to same category, visual correspondence is reasonably well-defined in most cases. But what about correspondence between two objects of completely different category -- e.g., a shoe and a bottle? Does there exist any correspondence? Inspired by humans' ability to: (a) generalize beyond semantic categories and; (b) infer functional affordances, we introduce the problem of functional correspondences in this paper. Given images of two objects, we ask a simple question: what is the set of correspondences between these two images for a given task? For example, what are the correspondences between a bottle and shoe for the task of pounding or the task of pouring. We introduce a new dataset: FunKPoint that has ground truth correspondences for 10 tasks and 20 object categories. We also introduce a modular task-driven representation for attacking this problem and demonstrate that our learned representation is effective for this task. But most importantly, because our supervision signal is not bound by semantics, we show that our learned representation can generalize better on few-shot classification problem. We hope this paper will inspire our community to think beyond semantics and focus more on cross-category generalization and learning representations for robotics tasks.

</p>
</details>

<details><summary><b>Sparsifying the Update Step in Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2109.00909">arxiv:2109.00909</a>
&#x1F4C8; 4 <br>
<p>Johannes F. Lutzeyer, Changmin Wu, Michalis Vazirgiannis</p></summary>
<p>

**Abstract:** Message-Passing Neural Networks (MPNNs), the most prominent Graph Neural Network (GNN) framework, celebrate much success in the analysis of graph-structured data. Concurrently, the sparsification of Neural Network models attracts a great amount of academic and industrial interest. In this paper, we conduct a structured study of the effect of sparsification on the trainable part of MPNNs known as the Update step. To this end, we design a series of models to successively sparsify the linear transform in the Update step. Specifically, we propose the ExpanderGNN model with a tuneable sparsification rate and the Activation-Only GNN, which has no linear transform in the Update step. In agreement with a growing trend in the literature, the sparsification paradigm is changed by initialising sparse neural network architectures rather than expensively sparsifying already trained architectures. Our novel benchmark models enable a better understanding of the influence of the Update step on model performance and outperform existing simplified benchmark models such as the Simple Graph Convolution. The ExpanderGNNs, and in some cases the Activation-Only models, achieve performance on par with their vanilla counterparts on several downstream tasks while containing significantly fewer trainable parameters. In experiments with matching parameter numbers, our benchmark models outperform the state-of-the-art GNN models. Our code is publicly available at: https://github.com/ChangminWu/ExpanderGNN.

</p>
</details>

<details><summary><b>Anatomical-Guided Attention Enhances Unsupervised PET Image Denoising Performance</b>
<a href="https://arxiv.org/abs/2109.00802">arxiv:2109.00802</a>
&#x1F4C8; 4 <br>
<p>Yuya Onishi, Fumio Hashimoto, Kibo Ote, Hiroyuki Ohba, Ryosuke Ota, Etsuji Yoshikawa, Yasuomi Ouchi</p></summary>
<p>

**Abstract:** Although supervised convolutional neural networks (CNNs) often outperform conventional alternatives for denoising positron emission tomography (PET) images, they require many low- and high-quality reference PET image pairs. Herein, we propose an unsupervised 3D PET image denoising method based on an anatomical information-guided attention mechanism. The proposed magnetic resonance-guided deep decoder (MR-GDD) utilizes the spatial details and semantic features of MR-guidance image more effectively by introducing encoder-decoder and deep decoder subnetworks. Moreover, the specific shapes and patterns of the guidance image do not affect the denoised PET image, because the guidance image is input to the network through an attention gate. In a Monte Carlo simulation of [$^{18}$F]fluoro-2-deoxy-D-glucose (FDG), the proposed method achieved the highest peak signal-to-noise ratio and structural similarity (27.92 $\pm$ 0.44 dB/0.886 $\pm$ 0.007), as compared with Gaussian filtering (26.68 $\pm$ 0.10 dB/0.807 $\pm$ 0.004), image guided filtering (27.40 $\pm$ 0.11 dB/0.849 $\pm$ 0.003), deep image prior (DIP) (24.22 $\pm$ 0.43 dB/0.737 $\pm$ 0.017), and MR-DIP (27.65 $\pm$ 0.42 dB/0.879 $\pm$ 0.007). Furthermore, we experimentally visualized the behavior of the optimization process, which is often unknown in unsupervised CNN-based restoration problems. For preclinical (using [$^{18}$F]FDG and [$^{11}$C]raclopride) and clinical (using [$^{18}$F]florbetapir) studies, the proposed method demonstrates state-of-the-art denoising performance while retaining spatial resolution and quantitative accuracy, despite using a common network architecture for various noisy PET images with 1/10th of the full counts. These results suggest that the proposed MR-GDD can reduce PET scan times and PET tracer doses considerably without impacting patients.

</p>
</details>

<details><summary><b>VIbCReg: Variance-Invariance-better-Covariance Regularization for Self-Supervised Learning on Time Series</b>
<a href="https://arxiv.org/abs/2109.00783">arxiv:2109.00783</a>
&#x1F4C8; 4 <br>
<p>Daesoo Lee, Erlend Aune</p></summary>
<p>

**Abstract:** Self-supervised learning for image representations has recently had many breakthroughs with respect to linear evaluation and fine-tuning evaluation. These approaches rely on both cleverly crafted loss functions and training setups to avoid the feature collapse problem. In this paper, we improve on the recently proposed VICReg paper, which introduced a loss function that does not rely on specialized training loops to converge to useful representations. Our method improves on a covariance term proposed in VICReg, and in addition we augment the head of the architecture by an IterNorm layer that greatly accelerates convergence of the model. Our model achieves superior performance on linear evaluation and fine-tuning evaluation on a subset of the UCR time series classification archive and the PTB-XL ECG dataset.

</p>
</details>

<details><summary><b>ConQX: Semantic Expansion of Spoken Queries for Intent Detection based on Conditioned Text Generation</b>
<a href="https://arxiv.org/abs/2109.00729">arxiv:2109.00729</a>
&#x1F4C8; 4 <br>
<p>Eyup Halit Yilmaz, Cagri Toraman</p></summary>
<p>

**Abstract:** Intent detection of spoken queries is a challenging task due to their noisy structure and short length. To provide additional information regarding the query and enhance the performance of intent detection, we propose a method for semantic expansion of spoken queries, called ConQX, which utilizes the text generation ability of an auto-regressive language model, GPT-2. To avoid off-topic text generation, we condition the input query to a structured context with prompt mining. We then apply zero-shot, one-shot, and few-shot learning. We lastly use the expanded queries to fine-tune BERT and RoBERTa for intent detection. The experimental results show that the performance of intent detection can be improved by our semantic expansion method.

</p>
</details>

<details><summary><b>MemBERT: Injecting Unstructured Knowledge into BERT</b>
<a href="https://arxiv.org/abs/2110.00125">arxiv:2110.00125</a>
&#x1F4C8; 3 <br>
<p>Federico Ruggeri, Marco Lippi, Paolo Torroni</p></summary>
<p>

**Abstract:** Transformers changed modern NLP in many ways. However, they can hardly exploit domain knowledge, and like other blackbox models, they lack interpretability. Unfortunately, structured knowledge injection, in the long run, risks to suffer from a knowledge acquisition bottleneck. We thus propose a memory enhancement of transformer models that makes use of unstructured domain knowledge expressed in plain natural language. An experimental evaluation conducted on two challenging NLP tasks demonstrates that our approach yields better performance and model interpretability than baseline transformer-based architectures.

</p>
</details>

<details><summary><b>Computing Graph Descriptors on Edge Streams</b>
<a href="https://arxiv.org/abs/2109.01494">arxiv:2109.01494</a>
&#x1F4C8; 3 <br>
<p>Zohair Raza Hassan, Imdadullah Khan, Mudassir Shabbir, Waseem Abbas</p></summary>
<p>

**Abstract:** Graph feature extraction is a fundamental task in graphs analytics. Using feature vectors (graph descriptors) in tandem with data mining algorithms that operate on Euclidean data, one can solve problems such as classification, clustering, and anomaly detection on graph-structured data. This idea has proved fruitful in the past, with spectral-based graph descriptors providing state-of-the-art classification accuracy on benchmark datasets. However, these algorithms do not scale to large graphs since: 1) they require storing the entire graph in memory, and 2) the end-user has no control over the algorithm's runtime. In this paper, we present single-pass streaming algorithms to approximate structural features of graphs (counts of subgraphs of order $k \geq 4$). Operating on edge streams allows us to avoid keeping the entire graph in memory, and controlling the sample size enables us to control the time taken by the algorithm. We demonstrate the efficacy of our descriptors by analyzing the approximation error, classification accuracy, and scalability to massive graphs. Our experiments showcase the effect of the sample size on approximation error and predictive accuracy. The proposed descriptors are applicable on graphs with millions of edges within minutes and outperform the state-of-the-art descriptors in classification accuracy.

</p>
</details>

<details><summary><b>Entity Linking and Discovery via Arborescence-based Supervised Clustering</b>
<a href="https://arxiv.org/abs/2109.01242">arxiv:2109.01242</a>
&#x1F4C8; 3 <br>
<p>Dhruv Agarwal, Rico Angell, Nicholas Monath, Andrew McCallum</p></summary>
<p>

**Abstract:** Previous work has shown promising results in performing entity linking by measuring not only the affinities between mentions and entities but also those amongst mentions. In this paper, we present novel training and inference procedures that fully utilize mention-to-mention affinities by building minimum arborescences (i.e., directed spanning trees) over mentions and entities across documents in order to make linking decisions. We also show that this method gracefully extends to entity discovery, enabling the clustering of mentions that do not have an associated entity in the knowledge base. We evaluate our approach on the Zero-Shot Entity Linking dataset and MedMentions, the largest publicly available biomedical dataset, and show significant improvements in performance for both entity linking and discovery compared to identically parameterized models. We further show significant efficiency improvements with only a small loss in accuracy over previous work, which use more computationally expensive models.

</p>
</details>

<details><summary><b>Cascade RCNN for MIDOG Challenge</b>
<a href="https://arxiv.org/abs/2109.01085">arxiv:2109.01085</a>
&#x1F4C8; 3 <br>
<p>Salar Razavi, Fariba Dambandkhameneh, Dimitri Androutsos, Susan Done, April Khademi</p></summary>
<p>

**Abstract:** Mitotic counts are one of the key indicators of breast cancer prognosis. However, accurate mitotic cell counting is still a difficult problem and is labourious. Automated methods have been proposed for this task, but are usually dependent on the training images and show poor performance on unseen domains. In this work, we present a multi-stage mitosis detection method based on a Cascade RCNN developed to be sequentially more selective against false positives. On the preliminary test set, the algorithm scores an F1-score of 0.7492.

</p>
</details>

<details><summary><b>Optimization and Sampling Under Continuous Symmetry: Examples and Lie Theory</b>
<a href="https://arxiv.org/abs/2109.01080">arxiv:2109.01080</a>
&#x1F4C8; 3 <br>
<p>Jonathan Leake, Nisheeth K. Vishnoi</p></summary>
<p>

**Abstract:** In the last few years, the notion of symmetry has provided a powerful and essential lens to view several optimization or sampling problems that arise in areas such as theoretical computer science, statistics, machine learning, quantum inference, and privacy. Here, we present two examples of nonconvex problems in optimization and sampling where continuous symmetries play -- implicitly or explicitly -- a key role in the development of efficient algorithms. These examples rely on deep and hidden connections between nonconvex symmetric manifolds and convex polytopes, and are heavily generalizable. To formulate and understand these generalizations, we then present an introduction to Lie theory -- an indispensable mathematical toolkit for capturing and working with continuous symmetries. We first present the basics of Lie groups, Lie algebras, and the adjoint actions associated with them, and we also mention the classification theorem for Lie algebras. Subsequently, we present Kostant's convexity theorem and show how it allows us to reduce linear optimization problems over orbits of Lie groups to linear optimization problems over polytopes. Finally, we present the Harish-Chandra and the Harish-Chandra--Itzykson--Zuber (HCIZ) formulas, which convert partition functions (integrals) over Lie groups into sums over the corresponding (discrete) Weyl groups, enabling efficient sampling algorithms.

</p>
</details>

<details><summary><b>Can Error Mitigation Improve Trainability of Noisy Variational Quantum Algorithms?</b>
<a href="https://arxiv.org/abs/2109.01051">arxiv:2109.01051</a>
&#x1F4C8; 3 <br>
<p>Samson Wang, Piotr Czarnik, Andrew Arrasmith, M. Cerezo, Lukasz Cincio, Patrick J. Coles</p></summary>
<p>

**Abstract:** Variational Quantum Algorithms (VQAs) are widely viewed as the best hope for near-term quantum advantage. However, recent studies have shown that noise can severely limit the trainability of VQAs, e.g., by exponentially flattening the cost landscape and suppressing the magnitudes of cost gradients. Error Mitigation (EM) shows promise in reducing the impact of noise on near-term devices. Thus, it is natural to ask whether EM can improve the trainability of VQAs. In this work, we first show that, for a broad class of EM strategies, exponential cost concentration cannot be resolved without committing exponential resources elsewhere. This class of strategies includes as special cases Zero Noise Extrapolation, Virtual Distillation, Probabilistic Error Cancellation, and Clifford Data Regression. Second, we perform analytical and numerical analysis of these EM protocols, and we find that some of them (e.g., Virtual Distillation) can make it harder to resolve cost function values compared to running no EM at all. As a positive result, we do find numerical evidence that Clifford Data Regression (CDR) can aid the training process in certain settings where cost concentration is not too severe. Our results show that care should be taken in applying EM protocols as they can either worsen or not improve trainability. On the other hand, our positive results for CDR highlight the possibility of engineering error mitigation methods to improve trainability.

</p>
</details>

<details><summary><b>Infrared Image Super-Resolution via Heterogeneous Convolutional WGAN</b>
<a href="https://arxiv.org/abs/2109.00960">arxiv:2109.00960</a>
&#x1F4C8; 3 <br>
<p>Yongsong Huang, Zetao Jiang, Qingzhong Wang, Qi Jiang, Guoming Pang</p></summary>
<p>

**Abstract:** Image super-resolution is important in many fields, such as surveillance and remote sensing. However, infrared (IR) images normally have low resolution since the optical equipment is relatively expensive. Recently, deep learning methods have dominated image super-resolution and achieved remarkable performance on visible images; however, IR images have received less attention. IR images have fewer patterns, and hence, it is difficult for deep neural networks (DNNs) to learn diverse features from IR images. In this paper, we present a framework that employs heterogeneous convolution and adversarial training, namely, heterogeneous kernel-based super-resolution Wasserstein GAN (HetSRWGAN), for IR image super-resolution. The HetSRWGAN algorithm is a lightweight GAN architecture that applies a plug-and-play heterogeneous kernel-based residual block. Moreover, a novel loss function that employs image gradients is adopted, which can be applied to an arbitrary model. The proposed HetSRWGAN achieves consistently better performance in both qualitative and quantitative evaluations. According to the experimental results, the whole training process is more stable.

</p>
</details>

<details><summary><b>A Comparative Study of Algorithms for Intelligent Traffic Signal Control</b>
<a href="https://arxiv.org/abs/2109.00937">arxiv:2109.00937</a>
&#x1F4C8; 3 <br>
<p>Hrishit Chaudhuri, Vibha Masti, Vishruth Veerendranath, S Natarajan</p></summary>
<p>

**Abstract:** In this paper, methods have been explored to effectively optimise traffic signal control to minimise waiting times and queue lengths, thereby increasing traffic flow. The traffic intersection was first defined as a Markov Decision Process, and a state representation, actions and rewards were chosen. Simulation of Urban MObility (SUMO) was used to simulate an intersection and then compare a Round Robin Scheduler, a Feedback Control mechanism and two Reinforcement Learning techniques - Deep Q Network (DQN) and Advantage Actor-Critic (A2C), as the policy for the traffic signal in the simulation under different scenarios. Finally, the methods were tested on a simulation of a real-world intersection in Bengaluru, India.

</p>
</details>

<details><summary><b>SlowFast Rolling-Unrolling LSTMs for Action Anticipation in Egocentric Videos</b>
<a href="https://arxiv.org/abs/2109.00829">arxiv:2109.00829</a>
&#x1F4C8; 3 <br>
<p>Nada Osman, Guglielmo Camporese, Pasquale Coscia, Lamberto Ballan</p></summary>
<p>

**Abstract:** Action anticipation in egocentric videos is a difficult task due to the inherently multi-modal nature of human actions. Additionally, some actions happen faster or slower than others depending on the actor or surrounding context which could vary each time and lead to different predictions. Based on this idea, we build upon RULSTM architecture, which is specifically designed for anticipating human actions, and propose a novel attention-based technique to evaluate, simultaneously, slow and fast features extracted from three different modalities, namely RGB, optical flow, and extracted objects. Two branches process information at different time scales, i.e., frame-rates, and several fusion schemes are considered to improve prediction accuracy. We perform extensive experiments on EpicKitchens-55 and EGTEA Gaze+ datasets, and demonstrate that our technique systematically improves the results of RULSTM architecture for Top-5 accuracy metric at different anticipation times.

</p>
</details>

<details><summary><b>Direct PET Image Reconstruction Incorporating Deep Image Prior and a Forward Projection Model</b>
<a href="https://arxiv.org/abs/2109.00768">arxiv:2109.00768</a>
&#x1F4C8; 3 <br>
<p>Fumio Hashimoto, Kibo Ote</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have recently achieved remarkable performance in positron emission tomography (PET) image reconstruction. In particular, CNN-based direct PET image reconstruction, which directly generates the reconstructed image from the sinogram, has potential applicability to PET image enhancements because it does not require image reconstruction algorithms, which often produce some artifacts. However, these deep learning-based, direct PET image reconstruction algorithms have the disadvantage that they require a large number of high-quality training datasets. In this study, we propose an unsupervised direct PET image reconstruction method that incorporates a deep image prior framework. Our proposed method incorporates a forward projection model with a loss function to achieve unsupervised direct PET image reconstruction from sinograms. To compare our proposed direct reconstruction method with the filtered back projection (FBP) and maximum likelihood expectation maximization (ML-EM) algorithms, we evaluated using Monte Carlo simulation data of brain [$^{18}$F]FDG PET scans. The results demonstrate that our proposed direct reconstruction quantitatively and qualitatively outperforms the FBP and ML-EM algorithms with respect to peak signal-to-noise ratio and structural similarity index.

</p>
</details>

<details><summary><b>RF-LighGBM: A probabilistic ensemble way to predict customer repurchase behaviour in community e-commerce</b>
<a href="https://arxiv.org/abs/2109.00724">arxiv:2109.00724</a>
&#x1F4C8; 3 <br>
<p>Liping Yang, Xiaxia Niu, Jun Wu</p></summary>
<p>

**Abstract:** It is reported that the number of online payment users in China has reached 854 million; with the emergence of community e-commerce platforms, the trend of integration of e-commerce and social applications is increasingly intense. Community e-commerce is not a mature and sound comprehensive e-commerce with fewer categories and low brand value. To effectively retain community users and fully explore customer value has become an important challenge for community e-commerce operators. Given the above problems, this paper uses the data-driven method to study the prediction of community e-commerce customers' repurchase behaviour. The main research contents include 1. Given the complex problem of feature engineering, the classic model RFM in the field of customer relationship management is improved, and an improved model is proposed to describe the characteristics of customer buying behaviour, which includes five indicators. 2. In view of the imbalance of machine learning training samples in SMOTE-ENN, a training sample balance using SMOTE-ENN is proposed. The experimental results show that the machine learning model can be trained more effectively on balanced samples. 3. Aiming at the complexity of the parameter adjustment process, an automatic hyperparameter optimization method based on the TPE method was proposed. Compared with other methods, the model's prediction performance is improved, and the training time is reduced by more than 450%. 4. Aiming at the weak prediction ability of a single model, the soft voting based RF-LightgBM model was proposed. The experimental results show that the RF-LighTGBM model proposed in this paper can effectively predict customer repurchase behaviour, and the F1 value is 0.859, which is better than the single model and previous research results.

</p>
</details>

<details><summary><b>Assessing Machine Learning Approaches to Address IoT Sensor Drift</b>
<a href="https://arxiv.org/abs/2109.04356">arxiv:2109.04356</a>
&#x1F4C8; 2 <br>
<p>Haining Zheng, Antonio Paiva</p></summary>
<p>

**Abstract:** The proliferation of IoT sensors and their deployment in various industries and applications has brought about numerous analysis opportunities in this Big Data era. However, drift of those sensor measurements poses major challenges to automate data analysis and the ability to effectively train and deploy models on a continuous basis. In this paper we study and test several approaches from the literature with regard to their ability to cope with and adapt to sensor drift under realistic conditions. Most of these approaches are recent and thus are representative of the current state-of-the-art. The testing was performed on a publicly available gas sensor dataset exhibiting drift over time. The results show substantial drops in sensing performance due to sensor drift in spite of the approaches. We then discuss several issues identified with current approaches and outline directions for future research to tackle them.

</p>
</details>

<details><summary><b>Parkinson's Disease Diagnosis based on Gait Cycle Analysis Through an Interpretable Interval Type-2 Neuro-Fuzzy System</b>
<a href="https://arxiv.org/abs/2109.02442">arxiv:2109.02442</a>
&#x1F4C8; 2 <br>
<p>Armin Salimi-Badr, Mohammad Hashemi, Hamidreza Saffari</p></summary>
<p>

**Abstract:** In this paper, an interpretable classifier using an interval type-2 fuzzy neural network for detecting patients suffering from Parkinson's Disease (PD) based on analyzing the gait cycle is presented. The proposed method utilizes clinical features extracted from the vertical Ground Reaction Force (vGRF), measured by 16 wearable sensors placed in the soles of subjects' shoes and learns interpretable fuzzy rules. Therefore, experts can verify the decision made by the proposed method based on investigating the firing strength of interpretable fuzzy rules. Moreover, experts can utilize the extracted fuzzy rules for patient diagnosing or adjust them based on their knowledge. To improve the robustness of the proposed method against uncertainty and noisy sensor measurements, Interval Type-2 Fuzzy Logic is applied. To learn fuzzy rules, two paradigms are proposed: 1- A batch learning approach based on clustering available samples is applied to extract initial fuzzy rules, 2- A complementary online learning is proposed to improve the rule base encountering new labeled samples. The performance of the method is evaluated for classifying patients and healthy subjects in different conditions including the presence of noise or observing new instances. Moreover, the performance of the model is compared to some previous supervised and unsupervised machine learning approaches. The final Accuracy, Precision, Recall, and F1 Score of the proposed method are 88.74%, 89.41%, 95.10%, and 92.16%. Finally, the extracted fuzzy sets for each feature are reported.

</p>
</details>

<details><summary><b>Reinforcement Learning for Battery Energy Storage Dispatch augmented with Model-based Optimizer</b>
<a href="https://arxiv.org/abs/2109.01659">arxiv:2109.01659</a>
&#x1F4C8; 2 <br>
<p>Gayathri Krishnamoorthy, Anamika Dubey</p></summary>
<p>

**Abstract:** Reinforcement learning has been found useful in solving optimal power flow (OPF) problems in electric power distribution systems. However, the use of largely model-free reinforcement learning algorithms that completely ignore the physics-based modeling of the power grid compromises the optimizer performance and poses scalability challenges. This paper proposes a novel approach to synergistically combine the physics-based models with learning-based algorithms using imitation learning to solve distribution-level OPF problems. Specifically, we propose imitation learning based improvements in deep reinforcement learning (DRL) methods to solve the OPF problem for a specific case of battery storage dispatch in the power distribution systems. The proposed imitation learning algorithm uses the approximate optimal solutions obtained from a linearized model-based OPF solver to provide a good initial policy for the DRL algorithms while improving the training efficiency. The effectiveness of the proposed approach is demonstrated using IEEE 34-bus and 123-bus distribution feeders with numerous distribution-level battery storage systems.

</p>
</details>

<details><summary><b>MitoDet: Simple and robust mitosis detection</b>
<a href="https://arxiv.org/abs/2109.01485">arxiv:2109.01485</a>
&#x1F4C8; 2 <br>
<p>Jakob Dexl, Michaela Benz, Volker Bruns, Petr Kuritcyn, Thomas Wittenberg</p></summary>
<p>

**Abstract:** Mitotic figure detection is a challenging task in digital pathology that has a direct impact on therapeutic decisions. While automated methods often achieve acceptable results under laboratory conditions, they frequently fail in the clinical deployment phase. This problem can be mainly attributed to a phenomenon called domain shift. An important source of a domain shift is introduced by different microscopes and their camera systems, which noticeably change the color representation of digitized images. In this method description we present our submitted algorithm for the Mitosis Domain Generalization Challenge, which employs a RetinaNet trained with strong data augmentation and achieves an F1 score of 0.7138 on the preliminary test set.

</p>
</details>

<details><summary><b>Unsupervised multi-latent space reinforcement learning framework for video summarization in ultrasound imaging</b>
<a href="https://arxiv.org/abs/2109.01309">arxiv:2109.01309</a>
&#x1F4C8; 2 <br>
<p>Roshan P Mathews, Mahesh Raveendranatha Panicker, Abhilash R Hareendranathan, Yale Tung Chen, Jacob L Jaremko, Brian Buchanan, Kiran Vishnu Narayan, Kesavadas C, Greeta Mathews</p></summary>
<p>

**Abstract:** The COVID-19 pandemic has highlighted the need for a tool to speed up triage in ultrasound scans and provide clinicians with fast access to relevant information. The proposed video-summarization technique is a step in this direction that provides clinicians access to relevant key-frames from a given ultrasound scan (such as lung ultrasound) while reducing resource, storage and bandwidth requirements. We propose a new unsupervised reinforcement learning (RL) framework with novel rewards that facilitates unsupervised learning avoiding tedious and impractical manual labelling for summarizing ultrasound videos to enhance its utility as a triage tool in the emergency department (ED) and for use in telemedicine. Using an attention ensemble of encoders, the high dimensional image is projected into a low dimensional latent space in terms of: a) reduced distance with a normal or abnormal class (classifier encoder), b) following a topology of landmarks (segmentation encoder), and c) the distance or topology agnostic latent representation (convolutional autoencoders). The decoder is implemented using a bi-directional long-short term memory (Bi-LSTM) which utilizes the latent space representation from the encoder. Our new paradigm for video summarization is capable of delivering classification labels and segmentation of key landmarks for each of the summarized keyframes. Validation is performed on lung ultrasound (LUS) dataset, that typically represent potential use cases in telemedicine and ED triage acquired from different medical centers across geographies (India, Spain and Canada).

</p>
</details>

<details><summary><b>On the Accuracy of Analog Neural Network Inference Accelerators</b>
<a href="https://arxiv.org/abs/2109.01262">arxiv:2109.01262</a>
&#x1F4C8; 2 <br>
<p>T. Patrick Xiao, Ben Feinberg, Christopher H. Bennett, Venkatraman Prabhakar, Prashant Saxena, Vineet Agrawal, Sapan Agarwal, Matthew J. Marinella</p></summary>
<p>

**Abstract:** Specialized accelerators have recently garnered attention as a method to reduce the power consumption of neural network inference. A promising category of accelerators utilizes nonvolatile memory arrays to both store weights and perform $\textit{in situ}$ analog computation inside the array. While prior work has explored the design space of analog accelerators to optimize performance and energy efficiency, there is seldom a rigorous evaluation of the accuracy of these accelerators. This work shows how architectural design decisions, particularly in mapping neural network parameters to analog memory cells, influence inference accuracy. When evaluated using ResNet50 on ImageNet, the resilience of the system to analog non-idealities - cell programming errors, analog-to-digital converter resolution, and array parasitic resistances - all improve when analog quantities in the hardware are made proportional to the weights in the network. Moreover, contrary to the assumptions of prior work, nearly equivalent resilience to cell imprecision can be achieved by fully storing weights as analog quantities, rather than spreading weight bits across multiple devices, often referred to as bit slicing. By exploiting proportionality, analog system designers have the freedom to match the precision of the hardware to the needs of the algorithm, rather than attempting to guarantee the same level of precision in the intermediate results as an equivalent digital accelerator. This ultimately results in an analog accelerator that is more accurate, more robust to analog errors, and more energy-efficient.

</p>
</details>

<details><summary><b>A Reliable, Self-Adaptive Face Identification Framework via Lyapunov Optimization</b>
<a href="https://arxiv.org/abs/2109.01212">arxiv:2109.01212</a>
&#x1F4C8; 2 <br>
<p>Dohyeon Kim, Joongheon Kim, Jae young Bang</p></summary>
<p>

**Abstract:** Realtime face identification (FID) from a video feed is highly computation-intensive, and may exhaust computation resources if performed on a device with a limited amount of resources (e.g., a mobile device). In general, FID performs better when images are sampled at a higher rate, minimizing false negatives. However, performing it at an overwhelmingly high rate exposes the system to the risk of a queue overflow that hampers the system's reliability. This paper proposes a novel, queue-aware FID framework that adapts the sampling rate to maximize the FID performance while avoiding a queue overflow by implementing the Lyapunov optimization. A preliminary evaluation via a trace-based simulation confirms the effectiveness of the framework.

</p>
</details>

<details><summary><b>Multi-Agent Inverse Reinforcement Learning: Suboptimal Demonstrations and Alternative Solution Concepts</b>
<a href="https://arxiv.org/abs/2109.01178">arxiv:2109.01178</a>
&#x1F4C8; 2 <br>
<p>Sage Bergerson</p></summary>
<p>

**Abstract:** Multi-agent inverse reinforcement learning (MIRL) can be used to learn reward functions from agents in social environments. To model realistic social dynamics, MIRL methods must account for suboptimal human reasoning and behavior. Traditional formalisms of game theory provide computationally tractable behavioral models, but assume agents have unrealistic cognitive capabilities. This research identifies and compares mechanisms in MIRL methods which a) handle noise, biases and heuristics in agent decision making and b) model realistic equilibrium solution concepts. MIRL research is systematically reviewed to identify solutions for these challenges. The methods and results of these studies are analyzed and compared based on factors including performance accuracy, efficiency, and descriptive quality. We found that the primary methods for handling noise, biases and heuristics in MIRL were extensions of Maximum Entropy (MaxEnt) IRL to multi-agent settings. We also found that many successful solution concepts are generalizations of the traditional Nash Equilibrium (NE). These solutions include the correlated equilibrium, logistic stochastic best response equilibrium and entropy regularized mean field NE. Methods which use recursive reasoning or updating also perform well, including the feedback NE and archive multi-agent adversarial IRL. Success in modeling specific biases and heuristics in single-agent IRL and promising results using a Theory of Mind approach in MIRL imply that modeling specific biases and heuristics may be useful. Flexibility and unbiased inference in the identified alternative solution concepts suggest that a solution concept which has both recursive and generalized characteristics may perform well at modeling realistic social interactions.

</p>
</details>

<details><summary><b>A New Semi-Automated Algorithm for Volumetric Segmentation of the Left Ventricle in Temporal 3D Echocardiography Sequences</b>
<a href="https://arxiv.org/abs/2109.01132">arxiv:2109.01132</a>
&#x1F4C8; 2 <br>
<p>Deepa Krishnaswamy, Abhilash R. Hareendranathan, Tan Suwatanaviroj, Pierre Boulanger, Harald Becher, Michelle Noga, Kumaradevan Punithakumar</p></summary>
<p>

**Abstract:** Purpose: Echocardiography is commonly used as a non-invasive imaging tool in clinical practice for the assessment of cardiac function. However, delineation of the left ventricle is challenging due to the inherent properties of ultrasound imaging, such as the presence of speckle noise and the low signal-to-noise ratio. Methods: We propose a semi-automated segmentation algorithm for the delineation of the left ventricle in temporal 3D echocardiography sequences. The method requires minimal user interaction and relies on a diffeomorphic registration approach. Advantages of the method include no dependence on prior geometrical information, training data, or registration from an atlas. Results: The method was evaluated using three-dimensional ultrasound scan sequences from 18 patients from the Mazankowski Alberta Heart Institute, Edmonton, Canada, and compared to manual delineations provided by an expert cardiologist and four other registration algorithms. The segmentation approach yielded the following results over the cardiac cycle: a mean absolute difference of 1.01 (0.21) mm, a Hausdorff distance of 4.41 (1.43) mm, and a Dice overlap score of 0.93 (0.02). Conclusions: The method performed well compared to the four other registration algorithms.

</p>
</details>

<details><summary><b>Text Classification for Predicting Multi-level Product Categories</b>
<a href="https://arxiv.org/abs/2109.01084">arxiv:2109.01084</a>
&#x1F4C8; 2 <br>
<p>Hadi Jahanshahi, Ozan Ozyegen, Mucahit Cevik, Beste Bulut, Deniz Yigit, Fahrettin F. Gonen, Ayşe Başar</p></summary>
<p>

**Abstract:** In an online shopping platform, a detailed classification of the products facilitates user navigation. It also helps online retailers keep track of the price fluctuations in a certain industry or special discounts on a specific product category. Moreover, an automated classification system may help to pinpoint incorrect or subjective categories suggested by an operator. In this study, we focus on product title classification of the grocery products. We perform a comprehensive comparison of six different text classification models to establish a strong baseline for this task, which involves testing both traditional and recent machine learning methods. In our experiments, we investigate the generalizability of the trained models to the products of other online retailers, the dynamic masking of infeasible subcategories for pretrained language models, and the benefits of incorporating product titles in multiple languages. Our numerical results indicate that dynamic masking of subcategories is effective in improving prediction accuracy. In addition, we observe that using bilingual product titles is generally beneficial, and neural network-based models perform significantly better than SVM and XGBoost models. Lastly, we investigate the reasons for the misclassified products and propose future research directions to further enhance the prediction models.

</p>
</details>

<details><summary><b>Lower Bounds on the Total Variation Distance Between Mixtures of Two Gaussians</b>
<a href="https://arxiv.org/abs/2109.01064">arxiv:2109.01064</a>
&#x1F4C8; 2 <br>
<p>Sami Davies, Arya Mazumdar, Soumyabrata Pal, Cyrus Rashtchian</p></summary>
<p>

**Abstract:** Mixtures of high dimensional Gaussian distributions have been studied extensively in statistics and learning theory. While the total variation distance appears naturally in the sample complexity of distribution learning, it is analytically difficult to obtain tight lower bounds for mixtures. Exploiting a connection between total variation distance and the characteristic function of the mixture, we provide fairly tight functional approximations. This enables us to derive new lower bounds on the total variation distance between pairs of two-component Gaussian mixtures that have a shared covariance matrix.

</p>
</details>

<details><summary><b>TrouSPI-Net: Spatio-temporal attention on parallel atrous convolutions and U-GRUs for skeletal pedestrian crossing prediction</b>
<a href="https://arxiv.org/abs/2109.00953">arxiv:2109.00953</a>
&#x1F4C8; 2 <br>
<p>Joseph Gesnouin, Steve Pechberti, Bogdan Stanciulescu, Fabien Moutarde</p></summary>
<p>

**Abstract:** Understanding the behaviors and intentions of pedestrians is still one of the main challenges for vehicle autonomy, as accurate predictions of their intentions can guarantee their safety and driving comfort of vehicles. In this paper, we address pedestrian crossing prediction in urban traffic environments by linking the dynamics of a pedestrian's skeleton to a binary crossing intention. We introduce TrouSPI-Net: a context-free, lightweight, multi-branch predictor. TrouSPI-Net extracts spatio-temporal features for different time resolutions by encoding pseudo-images sequences of skeletal joints' positions and processes them with parallel attention modules and atrous convolutions. The proposed approach is then enhanced by processing features such as relative distances of skeletal joints, bounding box positions, or ego-vehicle speed with U-GRUs. Using the newly proposed evaluation procedures for two large public naturalistic data sets for studying pedestrian behavior in traffic: JAAD and PIE, we evaluate TrouSPI-Net and analyze its performance. Experimental results show that TrouSPI-Net achieved 0.76 F1 score on JAAD and 0.80 F1 score on PIE, therefore outperforming current state-of-the-art while being lightweight and context-free.

</p>
</details>

<details><summary><b>VORRT-COLREGs: A Hybrid Velocity Obstacles and RRT Based COLREGs-Compliant Path Planner for Autonomous Surface Vessels</b>
<a href="https://arxiv.org/abs/2109.00862">arxiv:2109.00862</a>
&#x1F4C8; 2 <br>
<p>Rahul Dubey, Sushil J Louis</p></summary>
<p>

**Abstract:** This paper presents VORRT-COLREGs, a hybrid technique that combines velocity obstacles (VO) and rapidly-exploring random trees (RRT) to generate safe trajectories for autonomous surface vessels (ASVs) while following nautical rules of the road. RRT generates a set of way points and the velocity obstacles method ensures safe travel between way points. We also ensure that the actions of ASVs do not violate maritime collision guidelines. Earlier work has used RRT and VO separately to generate paths for ASVs. However, RRT does not handle highly dynamic situations well and and VO seems most suitable as a local path planner. Combining both approaches, VORRT-COLREGs is a global path planner that uses a joint forward simulation to ensure that generated paths remain valid and collision free as the situation changes. Experiments were conducted in different types of collision scenarios and with different numbers of ASVs. Results show that VORRT-COLREGS generated collision regulations (COLREGs) complaint paths in open ocean scenarios. Furthermore, VORRT-COLREGS successfully generated compliant paths within traffic separation schemes. These results show the applicability of our technique for generating paths for ASVs in different collision scenarios. To the best of our knowledge, this is the first work that combines velocity obstacles and RRT to produce safe and COLREGs complaint path for ASVs.

</p>
</details>

<details><summary><b>Inferring feature importance with uncertainties in high-dimensional data</b>
<a href="https://arxiv.org/abs/2109.00855">arxiv:2109.00855</a>
&#x1F4C8; 2 <br>
<p>Pål Vegard Johnsen, Inga Strümke, Signe Riemer-Sørensen, Andrew Thomas DeWan, Mette Langaas</p></summary>
<p>

**Abstract:** Estimating feature importance is a significant aspect of explaining data-based models. Besides explaining the model itself, an equally relevant question is which features are important in the underlying data generating process. We present a Shapley value based framework for inferring the importance of individual features, including uncertainty in the estimator. We build upon the recently published feature importance measure of SAGE (Shapley additive global importance) and introduce sub-SAGE which can be estimated without resampling for tree-based models. We argue that the uncertainties can be estimated from bootstrapping and demonstrate the approach for tree ensemble methods. The framework is exemplified on synthetic data as well as high-dimensional genomics data.

</p>
</details>

<details><summary><b>NASI: Label- and Data-agnostic Neural Architecture Search at Initialization</b>
<a href="https://arxiv.org/abs/2109.00817">arxiv:2109.00817</a>
&#x1F4C8; 2 <br>
<p>Yao Shu, Shaofeng Cai, Zhongxiang Dai, Beng Chin Ooi, Bryan Kian Hsiang Low</p></summary>
<p>

**Abstract:** Recent years have witnessed a surging interest in Neural Architecture Search (NAS). Various algorithms have been proposed to improve the search efficiency and effectiveness of NAS, i.e., to reduce the search cost and improve the generalization performance of the selected architectures, respectively. However, the search efficiency of these algorithms is severely limited by the need for model training during the search process. To overcome this limitation, we propose a novel NAS algorithm called NAS at Initialization (NASI) that exploits the capability of a Neural Tangent Kernel in being able to characterize the converged performance of candidate architectures at initialization, hence allowing model training to be completely avoided to boost the search efficiency. Besides the improved search efficiency, NASI also achieves competitive search effectiveness on various datasets like CIFAR-10/100 and ImageNet. Further, NASI is shown to be label- and data-agnostic under mild conditions, which guarantees the transferability of architectures selected by our NASI over different datasets.

</p>
</details>

<details><summary><b>Deep Learning-based mitosis detection in breast cancer histologic samples</b>
<a href="https://arxiv.org/abs/2109.00816">arxiv:2109.00816</a>
&#x1F4C8; 2 <br>
<p>Michel Halmes, Hippolyte Heuberger, Sylvain Berlemont</p></summary>
<p>

**Abstract:** This is the submission for mitosis detection in the context of the MIDOG 2021 challenge. It is based on the two-stage objection model Faster RCNN as well as DenseNet as a backbone for the neural network architecture. It achieves a F1-score of 0.6645 on the Preliminary Test Phase Leaderboard.

</p>
</details>

<details><summary><b>Semi-Supervised Learning using Siamese Networks</b>
<a href="https://arxiv.org/abs/2109.00794">arxiv:2109.00794</a>
&#x1F4C8; 2 <br>
<p>Attaullah Sahito, Eibe Frank, Bernhard Pfahringer</p></summary>
<p>

**Abstract:** Neural networks have been successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are more difficult to train successfully for semi-supervised problems where small amounts of labeled instances are available along with a large number of unlabeled instances. This work explores a new training method for semi-supervised learning that is based on similarity function learning using a Siamese network to obtain a suitable embedding. The learned representations are discriminative in Euclidean space, and hence can be used for labeling unlabeled instances using a nearest-neighbor classifier. Confident predictions of unlabeled instances are used as true labels for retraining the Siamese network on the expanded training set. This process is applied iteratively. We perform an empirical study of this iterative self-training algorithm. For improving unlabeled predictions, local learning with global consistency [22] is also evaluated.

</p>
</details>

<details><summary><b>Energy-Efficient Multi-Orchestrator Mobile Edge Learning</b>
<a href="https://arxiv.org/abs/2109.00757">arxiv:2109.00757</a>
&#x1F4C8; 2 <br>
<p>Mhd Saria Allahham, Sameh Sorour, Amr Mohamed, Aiman Erbad, Mohsen Guizani</p></summary>
<p>

**Abstract:** Mobile Edge Learning (MEL) is a collaborative learning paradigm that features distributed training of Machine Learning (ML) models over edge devices (e.g., IoT devices). In MEL, possible coexistence of multiple learning tasks with different datasets may arise. The heterogeneity in edge devices' capabilities will require the joint optimization of the learners-orchestrator association and task allocation. To this end, we aim to develop an energy-efficient framework for learners-orchestrator association and learning task allocation, in which each orchestrator gets associated with a group of learners with the same learning task based on their communication channel qualities and computational resources, and allocate the tasks accordingly. Therein, a multi objective optimization problem is formulated to minimize the total energy consumption and maximize the learning tasks' accuracy. However, solving such optimization problem requires centralization and the presence of the whole environment information at a single entity, which becomes impractical in large-scale systems. To reduce the solution complexity and to enable solution decentralization, we propose lightweight heuristic algorithms that can achieve near-optimal performance and facilitate the trade-offs between energy consumption, accuracy, and solution complexity. Simulation results show that the proposed approaches reduce the energy consumption significantly while executing multiple learning tasks compared to recent state-of-the-art methods.

</p>
</details>

<details><summary><b>Some Inapproximability Results of MAP Inference and Exponentiated Determinantal Point Processes</b>
<a href="https://arxiv.org/abs/2109.00727">arxiv:2109.00727</a>
&#x1F4C8; 2 <br>
<p>Naoto Ohsaka</p></summary>
<p>

**Abstract:** We study the computational complexity of two hard problems on determinantal point processes (DPPs). One is maximum a posteriori (MAP) inference, i.e., to find a principal submatrix having the maximum determinant. The other is probabilistic inference on exponentiated DPPs (E-DPPs), which can sharpen or weaken the diversity preference of DPPs with an exponent parameter $p$. We prove the following complexity-theoretic hardness results that explain the difficulty in approximating MAP inference and the normalizing constant for E-DPPs.
  1. Unconstrained MAP inference for an $n \times n$ matrix is NP-hard to approximate within a factor of $2^{βn}$, where $β= 10^{-10^{13}} $. This result improves upon a $(\frac{9}{8}-ε)$-factor inapproximability given by Kulesza and Taskar (2012).
  2. Log-determinant maximization is NP-hard to approximate within a factor of $\frac{5}{4}$ for the unconstrained case and within a factor of $1+10^{-10^{13}}$ for the size-constrained monotone case.
  3. The normalizing constant for E-DPPs of any (fixed) constant exponent $p \geq β^{-1} = 10^{10^{13}}$ is NP-hard to approximate within a factor of $2^{βpn}$. This gives a(nother) negative answer to open questions posed by Kulesza and Taskar (2012); Ohsaka and Matsuoka (2020).

</p>
</details>

<details><summary><b>Interactively Generating Explanations for Transformer Language Models</b>
<a href="https://arxiv.org/abs/2110.02058">arxiv:2110.02058</a>
&#x1F4C8; 1 <br>
<p>Patrick Schramowski, Felix Friedrich, Christopher Tauchmann, Kristian Kersting</p></summary>
<p>

**Abstract:** Transformer language models are state-of-the-art in a multitude of NLP tasks. Despite these successes, their opaqueness remains problematic. Recent methods aiming to provide interpretability and explainability to black-box models primarily focus on post-hoc explanations of (sometimes spurious) input-output correlations. Instead, we emphasize using prototype networks directly incorporated into the model architecture and hence explain the reasoning process behind the network's decisions. Moreover, while our architecture performs on par with several language models, it enables one to learn from user interactions. This not only offers a better understanding of language models but uses human capabilities to incorporate knowledge outside of the rigid range of purely data-driven approaches.

</p>
</details>

<details><summary><b>MutualGraphNet: A novel model for motor imagery classification</b>
<a href="https://arxiv.org/abs/2109.04361">arxiv:2109.04361</a>
&#x1F4C8; 1 <br>
<p>Yan Li, Ning Zhong, David Taniar, Haolan Zhang</p></summary>
<p>

**Abstract:** Motor imagery classification is of great significance to humans with mobility impairments, and how to extract and utilize the effective features from motor imagery electroencephalogram(EEG) channels has always been the focus of attention. There are many different methods for the motor imagery classification, but the limited understanding on human brain requires more effective methods for extracting the features of EEG data. Graph neural networks(GNNs) have demonstrated its effectiveness in classifying graph structures; and the use of GNN provides new possibilities for brain structure connection feature extraction. In this paper we propose a novel graph neural network based on the mutual information of the raw EEG channels called MutualGraphNet. We use the mutual information as the adjacency matrix combined with the spatial temporal graph convolution network(ST-GCN) could extract the transition rules of the motor imagery electroencephalogram(EEG) channels data more effectively. Experiments are conducted on motor imagery EEG data set and we compare our model with the current state-of-the-art approaches and the results suggest that MutualGraphNet is robust enough to learn the interpretable features and outperforms the current state-of-the-art methods.

</p>
</details>

<details><summary><b>A Critical Review of the state-of-the-art on Deep Neural Networks for Blood Glucose Prediction in Patients with Diabetes</b>
<a href="https://arxiv.org/abs/2109.02178">arxiv:2109.02178</a>
&#x1F4C8; 1 <br>
<p>Felix Tena, Oscar Garnica, Juan Lanchares, J. Ignacio Hidalgo</p></summary>
<p>

**Abstract:** This article compares ten recently proposed neural networks and proposes two ensemble neural network-based models for blood glucose prediction. All of them are tested under the same dataset, preprocessing workflow, and tools using the OhioT1DM Dataset at three different prediction horizons: 30, 60, and 120 minutes. We compare their performance using the most common metrics in blood glucose prediction and rank the best-performing ones using three methods devised for the statistical comparison of the performance of multiple algorithms: scmamp, model confidence set, and superior predictive ability. Our analysis highlights those models with the highest probability of being the best predictors, estimates the increase in error of the models that perform more poorly with respect to the best ones, and provides a guide for their use in clinical practice.

</p>
</details>

<details><summary><b>Data science and Machine learning in the Clouds: A Perspective for the Future</b>
<a href="https://arxiv.org/abs/2109.01661">arxiv:2109.01661</a>
&#x1F4C8; 1 <br>
<p>Hrishav Bakul Barua</p></summary>
<p>

**Abstract:** As we are fast approaching the beginning of a paradigm shift in the field of science, Data driven science (the so called fourth science paradigm) is going to be the driving force in research and innovation. From medicine to biodiversity and astronomy to geology, all these terms are somehow going to be affected by this paradigm shift. The huge amount of data to be processed under this new paradigm will be a major concern in the future and one will strongly require cloud based services in all the aspects of these computations (from storage to compute and other services). Another aspect will be energy consumption and performance of prediction jobs and tasks within such a scientific paradigm which will change the way one sees computation. Data science has heavily impacted or rather triggered the emergence of Machine Learning, Signal/Image/Video processing related algorithms, Artificial intelligence, Robotics, health informatics, geoinformatics, and many more such areas of interest. Hence, we envisage an era where Data science can deliver its promises with the help of the existing cloud based platforms and services with the addition of new services. In this article, we discuss about data driven science and Machine learning and how they are going to be linked through cloud based services in the future. It also discusses the rise of paradigms like approximate computing, quantum computing and many more in recent times and their applicability in big data processing, data science, analytics, prediction and machine learning in the cloud environments.

</p>
</details>

<details><summary><b>A Synergetic Attack against Neural Network Classifiers combining Backdoor and Adversarial Examples</b>
<a href="https://arxiv.org/abs/2109.01275">arxiv:2109.01275</a>
&#x1F4C8; 1 <br>
<p>Guanxiong Liu, Issa Khalil, Abdallah Khreishah, NhatHai Phan</p></summary>
<p>

**Abstract:** In this work, we show how to jointly exploit adversarial perturbation and model poisoning vulnerabilities to practically launch a new stealthy attack, dubbed AdvTrojan. AdvTrojan is stealthy because it can be activated only when: 1) a carefully crafted adversarial perturbation is injected into the input examples during inference, and 2) a Trojan backdoor is implanted during the training process of the model. We leverage adversarial noise in the input space to move Trojan-infected examples across the model decision boundary, making it difficult to detect. The stealthiness behavior of AdvTrojan fools the users into accidentally trust the infected model as a robust classifier against adversarial examples. AdvTrojan can be implemented by only poisoning the training data similar to conventional Trojan backdoor attacks. Our thorough analysis and extensive experiments on several benchmark datasets show that AdvTrojan can bypass existing defenses with a success rate close to 100% in most of our experimental scenarios and can be extended to attack federated learning tasks as well.

</p>
</details>

<details><summary><b>Transformer Networks for Data Augmentation of Human Physical Activity Recognition</b>
<a href="https://arxiv.org/abs/2109.01081">arxiv:2109.01081</a>
&#x1F4C8; 1 <br>
<p>Sandeep Ramachandra, Alexander Hoelzemann, Kristof Van Laerhoven</p></summary>
<p>

**Abstract:** Data augmentation is a widely used technique in classification to increase data used in training. It improves generalization and reduces amount of annotated human activity data needed for training which reduces labour and time needed with the dataset. Sensor time-series data, unlike images, cannot be augmented by computationally simple transformation algorithms. State of the art models like Recurrent Generative Adversarial Networks (RGAN) are used to generate realistic synthetic data. In this paper, transformer based generative adversarial networks which have global attention on data, are compared on PAMAP2 and Real World Human Activity Recognition data sets with RGAN. The newer approach provides improvements in time and savings in computational resources needed for data augmentation than previous approach.

</p>
</details>

<details><summary><b>Waveform Learning for Next-Generation Wireless Communication Systems</b>
<a href="https://arxiv.org/abs/2109.00998">arxiv:2109.00998</a>
&#x1F4C8; 1 <br>
<p>Fayçal Ait Aoudia, Jakob Hoydis</p></summary>
<p>

**Abstract:** We propose a learning-based method for the joint design of a transmit and receive filter, the constellation geometry and associated bit labeling, as well as a neural network (NN)-based detector. The method maximizes an achievable information rate, while simultaneously satisfying constraints on the adjacent channel leakage ratio (ACLR) and peak-to-average power ratio (PAPR). This allows control of the tradeoff between spectral containment, peak power, and communication rate. Evaluation on an additive white Gaussian noise (AWGN) channel shows significant reduction of ACLR and PAPR compared to a conventional baseline relying on quadrature amplitude modulation (QAM) and root-raised-cosine (RRC), without significant loss of information rate. When considering a 3rd Generation Partnership Project (3GPP) multipath channel, the learned waveform and neural receiver enable competitive or higher rates than an orthogonal frequency division multiplexing (OFDM) baseline, while reducing the ACLR by 10 dB and the PAPR by 2 dB. The proposed method incurs no additional complexity on the transmitter side and might be an attractive tool for waveform design of beyond-5G systems.

</p>
</details>

<details><summary><b>Knot invariants and their relations: a topological perspective</b>
<a href="https://arxiv.org/abs/2109.00831">arxiv:2109.00831</a>
&#x1F4C8; 1 <br>
<p>Dłotko Paweł, Davide Gurnari, Radmila Sazdanovic</p></summary>
<p>

**Abstract:** This work brings methods from topological data analysis to knot theory and develops new data analysis tools inspired by this application. We explore a vast collection of knot invariants and relations between then using Mapper and Ball Mapper algorithms. In particular, we develop versions of the Ball Mapper algorithm that incorporate symmetries and other relations within the data, and provide ways to compare data arising from different descriptors, such as knot invariants. Additionally, we extend the Mapper construction to the case where the range of the lens function is high dimensional rather than a 1-dimensional space, that also provides ways of visualizing functions between high-dimensional spaces. We illustrate the use of these techniques on knot theory data and draw attention to potential implications of our findings in knot theory.

</p>
</details>

<details><summary><b>Brief View and Analysis to Latest Android Security Issues and Approaches</b>
<a href="https://arxiv.org/abs/2109.00805">arxiv:2109.00805</a>
&#x1F4C8; 1 <br>
<p>Ruicong Huang</p></summary>
<p>

**Abstract:** Due to the continuous improvement of performance and functions, Android remains the most popular operating system on mobile phone today. However, various malicious applications bring great threats to the system. Over the past few years, significant changes occured in both malwares and counter measures. Specifically, malwares are continuously evolving, and advanced approaches are adopted for more accurate detection. To keep up with the latest situation, in this paper, we conduct a wide range of analysis, including latest malwares, Android security features, and approaches. We also provide some finding when we are gathering information and carrying on experiments, which we think is useful for further researches and has not been mentioned in previous works.

</p>
</details>

<details><summary><b>Non-Photorealistic Rendering of Layered Materials: A Multispectral Approach</b>
<a href="https://arxiv.org/abs/2109.00780">arxiv:2109.00780</a>
&#x1F4C8; 1 <br>
<p>Corey Toler-Franklin, Shashank Ranjan</p></summary>
<p>

**Abstract:** We present multispectral rendering techniques for visualizing layered materials found in biological specimens. We are the first to use acquired data from the near-infrared and ultraviolet spectra for non-photorealistic rendering (NPR). Several plant and animal species are more comprehensively understood by multispectral analysis. However, traditional NPR techniques ignore unique information outside the visible spectrum. We introduce algorithms and principles for processing wavelength dependent surface normals and reflectance. Our registration and feature detection methods are used to formulate stylization effects not considered by current NPR methods including: Spectral Band Shading which isolates and emphasizes shape features at specific wavelengths at multiple scales. Experts in our user study demonstrate the effectiveness of our system for applications in the biological sciences.

</p>
</details>

<details><summary><b>Learning 3D Mineral Prospectivity from 3D Geological Models with Convolutional Neural Networks: Application to a Structure-controlled Hydrothermal Gold Deposit</b>
<a href="https://arxiv.org/abs/2109.00756">arxiv:2109.00756</a>
&#x1F4C8; 1 <br>
<p>Hao Deng, Yang Zheng, Jin Chen, Shuyan Yu, Keyan Xiao, Xiancheng Mao</p></summary>
<p>

**Abstract:** The three-dimensional (3D) geological models are the typical and key data source in the 3D mineral prospecitivity modeling. Identifying prospectivity-informative predictor variables from the 3D geological models is a challenging and tedious task. Motivated by the ability of convolutional neural networks (CNNs) to learn the intrinsic features, in this paper, we present a novel method that leverages CNNs to learn 3D mineral prospectivity from the 3D geological models. By exploiting the learning ability of CNNs, the presented method allows for disentangling complex correlation to the mineralization and thus opens a door to circumvent the tedious work for designing the predictor variables. Specifically, to explore the unstructured 3D geological models with the CNNs whose input should be structured, we develop a 2D CNN framework in which the geometry of geological boundary is compiled and reorganized into multi-channel images and fed into the CNN. This ensures an effective and efficient training of CNNs while allowing the prospective model to approximate the ore-forming process. The presented method is applied to a typical structure-controlled hydrothermal deposit, the Dayingezhuang gold deposit, eastern China, in which the presented method was compared with the prospectivity modeling methods using hand-designed predictor variables. The results demonstrate the presented method capacitates a performance boost of the 3D prospectivity modeling and empowers us to decrease work-load and prospecting risk in prediction of deep-seated orebodies.

</p>
</details>

<details><summary><b>Co-Separable Nonnegative Matrix Factorization</b>
<a href="https://arxiv.org/abs/2109.00749">arxiv:2109.00749</a>
&#x1F4C8; 1 <br>
<p>Junjun Pan, Michael K. Ng</p></summary>
<p>

**Abstract:** Nonnegative matrix factorization (NMF) is a popular model in the field of pattern recognition. It aims to find a low rank approximation for nonnegative data M by a product of two nonnegative matrices W and H. In general, NMF is NP-hard to solve while it can be solved efficiently under separability assumption, which requires the columns of factor matrix are equal to columns of the input matrix. In this paper, we generalize separability assumption based on 3-factor NMF M=P_1SP_2, and require that S is a sub-matrix of the input matrix. We refer to this NMF as a Co-Separable NMF (CoS-NMF). We discuss some mathematics properties of CoS-NMF, and present the relationships with other related matrix factorizations such as CUR decomposition, generalized separable NMF(GS-NMF), and bi-orthogonal tri-factorization (BiOR-NM3F). An optimization model for CoS-NMF is proposed and alternated fast gradient method is employed to solve the model. Numerical experiments on synthetic datasets, document datasets and facial databases are conducted to verify the effectiveness of our CoS-NMF model. Compared to state-of-the-art methods, CoS-NMF model performs very well in co-clustering task, and preserves a good approximation to the input data matrix as well.

</p>
</details>

<details><summary><b>End-to-End Demand Response Model Identification and Baseline Estimation with Deep Learning</b>
<a href="https://arxiv.org/abs/2109.00741">arxiv:2109.00741</a>
&#x1F4C8; 1 <br>
<p>Yuanyuan Shi, Bolun Xu</p></summary>
<p>

**Abstract:** This paper proposes a novel end-to-end deep learning framework that simultaneously identifies demand baselines and the incentive-based agent demand response model, from the net demand measurements and incentive signals. This learning framework is modularized as two modules: 1) the decision making process of a demand response participant is represented as a differentiable optimization layer, which takes the incentive signal as input and predicts user's response; 2) the baseline demand forecast is represented as a standard neural network model, which takes relevant features and predicts user's baseline demand. These two intermediate predictions are integrated, to form the net demand forecast. We then propose a gradient-descent approach that backpropagates the net demand forecast errors to update the weights of the agent model and the weights of baseline demand forecast, jointly. We demonstrate the effectiveness of our approach through computation experiments with synthetic demand response traces and a large-scale real world demand response dataset. Our results show that the approach accurately identifies the demand response model, even without any prior knowledge about the baseline demand.

</p>
</details>

<details><summary><b>Self-supervised Multi-class Pre-training for Unsupervised Anomaly Detection and Segmentation in Medical Images</b>
<a href="https://arxiv.org/abs/2109.01303">arxiv:2109.01303</a>
&#x1F4C8; 0 <br>
<p>Yu Tian, Fengbei Liu, Guansong Pang, Yuanhong Chen, Yuyuan Liu, Johan W. Verjans, Rajvinder Singh, Gustavo Carneiro</p></summary>
<p>

**Abstract:** Unsupervised anomaly detection (UAD) that requires only normal (healthy) training images is an important tool for enabling the development of medical image analysis (MIA) applications, such as disease screening, since it is often difficult to collect and annotate abnormal (or disease) images in MIA. However, heavily relying on the normal images may cause the model training to overfit the normal class. Self-supervised pre-training is an effective solution to this problem. Unfortunately, current self-supervision methods adapted from computer vision are sub-optimal for MIA applications because they do not explore MIA domain knowledge for designing the pretext tasks or the training process. In this paper, we propose a new self-supervised pre-training method for UAD designed for MIA applications, named Multi-class Strong Augmentation via Contrastive Learning (MSACL). MSACL is based on a novel optimisation to contrast normal and multiple classes of synthetised abnormal images, with each class enforced to form a tight and dense cluster in terms of Euclidean distance and cosine similarity, where abnormal images are formed by simulating a varying number of lesions of different sizes and appearance in the normal images. In the experiments, we show that our MSACL pre-training improves the accuracy of SOTA UAD methods on many MIA benchmarks using colonoscopy, fundus screening and Covid-19 Chest X-ray datasets.

</p>
</details>

<details><summary><b>Automatic Diagnosis of Schizophrenia in EEG Signals Using CNN-LSTM Models</b>
<a href="https://arxiv.org/abs/2109.01120">arxiv:2109.01120</a>
&#x1F4C8; 0 <br>
<p>Afshin Shoeibi, Delaram Sadeghi, Parisa Moridian, Navid Ghassemi, Jonathan Heras, Roohallah Alizadehsani, Ali Khadem, Yinan Kong, Saeid Nahavandi, Yu-Dong Zhang, Juan M. Gorriz</p></summary>
<p>

**Abstract:** Schizophrenia (SZ) is a mental disorder whereby due to the secretion of specific chemicals in the brain, the function of some brain regions is out of balance, leading to the lack of coordination between thoughts, actions, and emotions. This study provides various intelligent deep learning (DL)-based methods for automated SZ diagnosis via electroencephalography (EEG) signals. The obtained results are compared with those of conventional intelligent methods. To implement the proposed methods, the dataset of the Institute of Psychiatry and Neurology in Warsaw, Poland, has been used. First, EEG signals were divided into 25 s time frames and then were normalized by z-score or norm L2. In the classification step, two different approaches were considered for SZ diagnosis via EEG signals. In this step, the classification of EEG signals was first carried out by conventional machine learning methods, e.g., support vector machine, k-nearest neighbors, decision tree, naïve Bayes, random forest, extremely randomized trees, and bagging. Various proposed DL models, namely, long short-term memories (LSTMs), one-dimensional convolutional networks (1D-CNNs), and 1D-CNN-LSTMs, were used in the following. In this step, the DL models were implemented and compared with different activation functions. Among the proposed DL models, the CNN-LSTM architecture has had the best performance. In this architecture, the ReLU activation function with the z-score and L2-combined normalization was used. The proposed CNN-LSTM model has achieved an accuracy percentage of 99.25%, better than the results of most former studies in this field. It is worth mentioning that to perform all simulations, the k-fold cross-validation method with k = 5 has been used.

</p>
</details>

<details><summary><b>Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning</b>
<a href="https://arxiv.org/abs/2109.00840">arxiv:2109.00840</a>
&#x1F4C8; 0 <br>
<p>Christos Theodoropoulos, James Henderson, Andrei C. Coman, Marie-Francine Moens</p></summary>
<p>

**Abstract:** Though language model text embeddings have revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited. In this paper, we propose a novel contrastive learning framework that trains sentence embeddings to encode the relations in a graph structure. Given a sentence (unstructured text) and its graph, we use contrastive learning to impose relation-related structure on the token-level representations of the sentence obtained with a CharacterBERT (El Boukkouri et al.,2020) model. The resulting relation-aware sentence embeddings achieve state-of-the-art results on the relation extraction task using only a simple KNN classifier, thereby demonstrating the success of the proposed method. Additional visualization by a tSNE analysis shows the effectiveness of the learned representation space compared to baselines. Furthermore, we show that we can learn a different space for named entity recognition, again using a contrastive learning objective, and demonstrate how to successfully combine both representation spaces in an entity-relation task.

</p>
</details>


[Next Page]({{ '/2021/09/01/2021.09.01.html' | relative_url }})
