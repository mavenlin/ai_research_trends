Prev: [2022.09.06]({{ '/2022/09/06/2022.09.06.html' | relative_url }})  Next: [2022.09.08]({{ '/2022/09/08/2022.09.08.html' | relative_url }})
{% raw %}
## Summary for 2022-09-07, created on 2022-09-11


<details><summary><b>AudioLM: a Language Modeling Approach to Audio Generation</b>
<a href="https://arxiv.org/abs/2209.03143">arxiv:2209.03143</a>
&#x1F4C8; 96 <br>
<p>Zalán Borsos, Raphaël Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Olivier Teboul, David Grangier, Marco Tagliasacchi, Neil Zeghidour</p></summary>
<p>

**Abstract:** We introduce AudioLM, a framework for high-quality audio generation with long-term consistency. AudioLM maps the input audio to a sequence of discrete tokens and casts audio generation as a language modeling task in this representation space. We show how existing audio tokenizers provide different trade-offs between reconstruction quality and long-term structure, and we propose a hybrid tokenization scheme to achieve both objectives. Namely, we leverage the discretized activations of a masked language model pre-trained on audio to capture long-term structure and the discrete codes produced by a neural audio codec to achieve high-quality synthesis. By training on large corpora of raw audio waveforms, AudioLM learns to generate natural and coherent continuations given short prompts. When trained on speech, and without any transcript or annotation, AudioLM generates syntactically and semantically plausible speech continuations while also maintaining speaker identity and prosody for unseen speakers. Furthermore, we demonstrate how our approach extends beyond speech by generating coherent piano music continuations, despite being trained without any symbolic representation of music.

</p>
</details>

<details><summary><b>Geometric multimodal representation learning</b>
<a href="https://arxiv.org/abs/2209.03299">arxiv:2209.03299</a>
&#x1F4C8; 57 <br>
<p>Yasha Ektefaie, George Dasoulas, Ayush Noori, Maha Farhat, Marinka Zitnik</p></summary>
<p>

**Abstract:** Graph-centric artificial intelligence (graph AI) has achieved remarkable success in modeling interacting systems prevalent in nature, from dynamical systems in biology to particle physics. The increasing heterogeneity of data calls for graph neural architectures that can combine multiple inductive biases. However, combining data from various sources is challenging because appropriate inductive bias may vary by data modality. Multimodal learning methods fuse multiple data modalities while leveraging cross-modal dependencies to address this challenge. Here, we survey 140 studies in graph-centric AI and realize that diverse data types are increasingly brought together using graphs and fed into sophisticated multimodal models. These models stratify into image-, language-, and knowledge-grounded multimodal learning. We put forward an algorithmic blueprint for multimodal graph learning based on this categorization. The blueprint serves as a way to group state-of-the-art architectures that treat multimodal data by choosing appropriately four different components. This effort can pave the way for standardizing the design of sophisticated multimodal architectures for highly complex real-world problems.

</p>
</details>

<details><summary><b>What does a platypus look like? Generating customized prompts for zero-shot image classification</b>
<a href="https://arxiv.org/abs/2209.03320">arxiv:2209.03320</a>
&#x1F4C8; 41 <br>
<p>Sarah Pratt, Rosanne Liu, Ali Farhadi</p></summary>
<p>

**Abstract:** Open vocabulary models are a promising new paradigm for image classification. Unlike traditional classification models, open vocabulary models classify among any arbitrary set of categories specified with natural language during inference. This natural language, called "prompts", typically consists of a set of hand-written templates (e.g., "a photo of a {}") which are completed with each of the category names. This work introduces a simple method to generate higher accuracy prompts, without using explicit knowledge of the image domain and with far fewer hand-constructed sentences. To achieve this, we combine open vocabulary models with large language models (LLMs) to create Customized Prompts via Language models (CuPL, pronounced "couple"). In particular, we leverage the knowledge contained in LLMs in order to generate many descriptive sentences that are customized for each object category. We find that this straightforward and general approach improves accuracy on a range of zero-shot image classification benchmarks, including over one percentage point gain on ImageNet. Finally, this method requires no additional training and remains completely zero-shot. Code is available at https://github.com/sarahpratt/CuPL.

</p>
</details>

<details><summary><b>Decoding Demographic un-fairness from Indian Names</b>
<a href="https://arxiv.org/abs/2209.03089">arxiv:2209.03089</a>
&#x1F4C8; 20 <br>
<p>Medidoddi Vahini, Jalend Bantupalli, Souvic Chakraborty, Animesh Mukherjee</p></summary>
<p>

**Abstract:** Demographic classification is essential in fairness assessment in recommender systems or in measuring unintended bias in online networks and voting systems. Important fields like education and politics, which often lay a foundation for the future of equality in society, need scrutiny to design policies that can better foster equality in resource distribution constrained by the unbalanced demographic distribution of people in the country.
  We collect three publicly available datasets to train state-of-the-art classifiers in the domain of gender and caste classification. We train the models in the Indian context, where the same name can have different styling conventions (Jolly Abraham/Kumar Abhishikta in one state may be written as Abraham Jolly/Abishikta Kumar in the other). Finally, we also perform cross-testing (training and testing on different datasets) to understand the efficacy of the above models.
  We also perform an error analysis of the prediction models. Finally, we attempt to assess the bias in the existing Indian system as case studies and find some intriguing patterns manifesting in the complex demographic layout of the sub-continent across the dimensions of gender and caste.

</p>
</details>

<details><summary><b>Multi-Scale Attention-based Multiple Instance Learning for Classification of Multi-Gigapixel Histology Images</b>
<a href="https://arxiv.org/abs/2209.03041">arxiv:2209.03041</a>
&#x1F4C8; 11 <br>
<p>Made Satria Wibawa, Kwok-Wai Lo, Lawrence Young, Nasir Rajpoot</p></summary>
<p>

**Abstract:** Histology images with multi-gigapixel of resolution yield rich information for cancer diagnosis and prognosis. Most of the time, only slide-level label is available because pixel-wise annotation is labour intensive task. In this paper, we propose a deep learning pipeline for classification in histology images. Using multiple instance learning, we attempt to predict the latent membrane protein 1 (LMP1) status of nasopharyngeal carcinoma (NPC) based on haematoxylin and eosin-stain (H&E) histology images. We utilised attention mechanism with residual connection for our aggregation layers. In our 3-fold cross-validation experiment, we achieved average accuracy, AUC and F1-score 0.936, 0.995 and 0.862, respectively. This method also allows us to examine the model interpretability by visualising attention scores. To the best of our knowledge, this is the first attempt to predict LMP1 status on NPC using deep learning.

</p>
</details>

<details><summary><b>Risk of Bias in Chest X-ray Foundation Models</b>
<a href="https://arxiv.org/abs/2209.02965">arxiv:2209.02965</a>
&#x1F4C8; 10 <br>
<p>Ben Glocker, Charles Jones, Melanie Bernhardt, Stefan Winzeck</p></summary>
<p>

**Abstract:** Foundation models are considered a breakthrough in all applications of AI, promising robust and reusable mechanisms for feature extraction, alleviating the need for large amounts of high quality training data for task-specific prediction models. However, foundation models may potentially encode and even reinforce existing biases present in historic datasets. Given the limited ability to scrutinize foundation models, it remains unclear whether the opportunities outweigh the risks in safety critical applications such as clinical decision making. In our statistical bias analysis of a recently published, and publicly available chest X-ray foundation model, we found reasons for concern as the model seems to encode protected characteristics including biological sex and racial identity, which may lead to disparate performance across subgroups in downstream applications. While research into foundation models for healthcare applications is in an early stage, we believe it is important to make the community aware of these risks to avoid harm.

</p>
</details>

<details><summary><b>Multimodal Speech Enhancement Using Burst Propagation</b>
<a href="https://arxiv.org/abs/2209.03275">arxiv:2209.03275</a>
&#x1F4C8; 9 <br>
<p>Leandro A. Passos, Ahmed Khubaib, Mohsin Raza, Ahsan Adeel</p></summary>
<p>

**Abstract:** This paper proposes the MBURST, a novel multimodal solution for audio-visual speech enhancements that consider the most recent neurological discoveries regarding pyramidal cells of the prefrontal cortex and other brain regions. The so-called burst propagation implements several criteria to address the credit assignment problem in a more biologically plausible manner: steering the sign and magnitude of plasticity through feedback, multiplexing the feedback and feedforward information across layers through different weight connections, approximating feedback and feedforward connections, and linearizing the feedback signals. MBURST benefits from such capabilities to learn correlations between the noisy signal and the visual stimuli, thus attributing meaning to the speech by amplifying relevant information and suppressing noise. Experiments conducted over a Grid Corpus and CHiME3-based dataset show that MBURST can reproduce similar mask reconstructions to the multimodal backpropagation-based baseline while demonstrating outstanding energy efficiency management, reducing the neuron firing rates to values up to \textbf{$70\%$} lower. Such a feature implies more sustainable implementations, suitable and desirable for hearing aids or any other similar embedded systems.

</p>
</details>

<details><summary><b>Morphology-preserving Autoregressive 3D Generative Modelling of the Brain</b>
<a href="https://arxiv.org/abs/2209.03177">arxiv:2209.03177</a>
&#x1F4C8; 9 <br>
<p>Petru-Daniel Tudosiu, Walter Hugo Lopez Pinaya, Mark S. Graham, Pedro Borges, Virginia Fernandez, Dai Yang, Jeremy Appleyard, Guido Novati, Disha Mehra, Mike Vella, Parashkev Nachev, Sebastien Ourselin, Jorge Cardoso</p></summary>
<p>

**Abstract:** Human anatomy, morphology, and associated diseases can be studied using medical imaging data. However, access to medical imaging data is restricted by governance and privacy concerns, data ownership, and the cost of acquisition, thus limiting our ability to understand the human body. A possible solution to this issue is the creation of a model able to learn and then generate synthetic images of the human body conditioned on specific characteristics of relevance (e.g., age, sex, and disease status). Deep generative models, in the form of neural networks, have been recently used to create synthetic 2D images of natural scenes. Still, the ability to produce high-resolution 3D volumetric imaging data with correct anatomical morphology has been hampered by data scarcity and algorithmic and computational limitations. This work proposes a generative model that can be scaled to produce anatomically correct, high-resolution, and realistic images of the human brain, with the necessary quality to allow further downstream analyses. The ability to generate a potentially unlimited amount of data not only enables large-scale studies of human anatomy and pathology without jeopardizing patient privacy, but also significantly advances research in the field of anomaly detection, modality synthesis, learning under limited data, and fair and ethical AI. Code and trained models are available at: https://github.com/AmigoLab/SynthAnatomy.

</p>
</details>

<details><summary><b>Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots</b>
<a href="https://arxiv.org/abs/2209.03463">arxiv:2209.03463</a>
&#x1F4C8; 8 <br>
<p>Wai Man Si, Michael Backes, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca Stringhini, Savvas Zannettou, Yand Zhang</p></summary>
<p>

**Abstract:** Chatbots are used in many applications, e.g., automated agents, smart home assistants, interactive characters in online games, etc. Therefore, it is crucial to ensure they do not behave in undesired manners, providing offensive or toxic responses to users. This is not a trivial task as state-of-the-art chatbot models are trained on large, public datasets openly collected from the Internet. This paper presents a first-of-its-kind, large-scale measurement of toxicity in chatbots. We show that publicly available chatbots are prone to providing toxic responses when fed toxic queries. Even more worryingly, some non-toxic queries can trigger toxic responses too. We then set out to design and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to generate non-toxic queries that make chatbots respond in a toxic manner. Our extensive experimental evaluation demonstrates that our attack is effective against public chatbot models and outperforms manually-crafted malicious queries proposed by previous work. We also evaluate three defense mechanisms against ToxicBuddy, showing that they either reduce the attack performance at the cost of affecting the chatbot's utility or are only effective at mitigating a portion of the attack. This highlights the need for more research from the computer security and online safety communities to ensure that chatbot models do not hurt their users. Overall, we are confident that ToxicBuddy can be used as an auditing tool and that our work will pave the way toward designing more effective defenses for chatbot safety.

</p>
</details>

<details><summary><b>Non-Gaussian Process Regression</b>
<a href="https://arxiv.org/abs/2209.03117">arxiv:2209.03117</a>
&#x1F4C8; 8 <br>
<p>Yaman Kındap, Simon Godsill</p></summary>
<p>

**Abstract:** Standard GPs offer a flexible modelling tool for well-behaved processes. However, deviations from Gaussianity are expected to appear in real world datasets, with structural outliers and shocks routinely observed. In these cases GPs can fail to model uncertainty adequately and may over-smooth inferences. Here we extend the GP framework into a new class of time-changed GPs that allow for straightforward modelling of heavy-tailed non-Gaussian behaviours, while retaining a tractable conditional GP structure through an infinite mixture of non-homogeneous GPs representation. The conditional GP structure is obtained by conditioning the observations on a latent transformed input space and the random evolution of the latent transformation is modelled using a Lévy process which allows Bayesian inference in both the posterior predictive density and the latent transformation function. We present Markov chain Monte Carlo inference procedures for this model and demonstrate the potential benefits compared to a standard GP.

</p>
</details>

<details><summary><b>Cerberus: Exploring Federated Prediction of Security Events</b>
<a href="https://arxiv.org/abs/2209.03050">arxiv:2209.03050</a>
&#x1F4C8; 8 <br>
<p>Mohammad Naseri, Yufei Han, Enrico Mariconti, Yun Shen, Gianluca Stringhini, Emiliano De Cristofaro</p></summary>
<p>

**Abstract:** Modern defenses against cyberattacks increasingly rely on proactive approaches, e.g., to predict the adversary's next actions based on past events. Building accurate prediction models requires knowledge from many organizations; alas, this entails disclosing sensitive information, such as network structures, security postures, and policies, which might often be undesirable or outright impossible. In this paper, we explore the feasibility of using Federated Learning (FL) to predict future security events. To this end, we introduce Cerberus, a system enabling collaborative training of Recurrent Neural Network (RNN) models for participating organizations. The intuition is that FL could potentially offer a middle-ground between the non-private approach where the training data is pooled at a central server and the low-utility alternative of only training local models. We instantiate Cerberus on a dataset obtained from a major security company's intrusion prevention product and evaluate it vis-a-vis utility, robustness, and privacy, as well as how participants contribute to and benefit from the system. Overall, our work sheds light on both the positive aspects and the challenges of using FL for this task and paves the way for deploying federated approaches to predictive security.

</p>
</details>

<details><summary><b>On the Effectiveness of Compact Biomedical Transformers</b>
<a href="https://arxiv.org/abs/2209.03182">arxiv:2209.03182</a>
&#x1F4C8; 7 <br>
<p>Omid Rohanian, Mohammadmahdi Nouriborji, Samaneh Kouchaki, David A. Clifton</p></summary>
<p>

**Abstract:** Language models pre-trained on biomedical corpora, such as BioBERT, have recently shown promising results on downstream biomedical tasks. Many existing pre-trained models, on the other hand, are resource-intensive and computationally heavy owing to factors such as embedding size, hidden dimension, and number of layers. The natural language processing (NLP) community has developed numerous strategies to compress these models utilising techniques such as pruning, quantisation, and knowledge distillation, resulting in models that are considerably faster, smaller, and subsequently easier to use in practice. By the same token, in this paper we introduce six lightweight models, namely, BioDistilBERT, BioTinyBERT, BioMobileBERT, DistilBioBERT, TinyBioBERT, and CompactBioBERT which are obtained either by knowledge distillation from a biomedical teacher or continual learning on the Pubmed dataset via the Masked Language Modelling (MLM) objective. We evaluate all of our models on three biomedical tasks and compare them with BioBERT-v1.1 to create efficient lightweight models that perform on par with their larger counterparts. All the models will be publicly available on our Huggingface profile at https://huggingface.co/nlpie and the codes used to run the experiments will be available at https://github.com/nlpie-research/Compact-Biomedical-Transformers.

</p>
</details>

<details><summary><b>On the utility and protection of optimization with differential privacy and classic regularization techniques</b>
<a href="https://arxiv.org/abs/2209.03175">arxiv:2209.03175</a>
&#x1F4C8; 7 <br>
<p>Eugenio Lomurno, Matteo matteucci</p></summary>
<p>

**Abstract:** Nowadays, owners and developers of deep learning models must consider stringent privacy-preservation rules of their training data, usually crowd-sourced and retaining sensitive information. The most widely adopted method to enforce privacy guarantees of a deep learning model nowadays relies on optimization techniques enforcing differential privacy. According to the literature, this approach has proven to be a successful defence against several models' privacy attacks, but its downside is a substantial degradation of the models' performance. In this work, we compare the effectiveness of the differentially-private stochastic gradient descent (DP-SGD) algorithm against standard optimization practices with regularization techniques. We analyze the resulting models' utility, training performance, and the effectiveness of membership inference and model inversion attacks against the learned models. Finally, we discuss differential privacy's flaws and limits and empirically demonstrate the often superior privacy-preserving properties of dropout and l2-regularization.

</p>
</details>

<details><summary><b>Semantic Interactive Learning for Text Classification: A Constructive Approach for Contextual Interactions</b>
<a href="https://arxiv.org/abs/2209.02984">arxiv:2209.02984</a>
&#x1F4C8; 7 <br>
<p>Sebastian Kiefer, Mareike Hoffmann</p></summary>
<p>

**Abstract:** Interactive Machine Learning (IML) shall enable intelligent systems to interactively learn from their end-users, and is quickly becoming more and more important. Although it puts the human in the loop, interactions are mostly performed via mutual explanations that miss contextual information. Furthermore, current model-agnostic IML strategies like CAIPI are limited to 'destructive' feedback, meaning they solely allow an expert to prevent a learner from using irrelevant features. In this work, we propose a novel interaction framework called Semantic Interactive Learning for the text domain. We frame the problem of incorporating constructive and contextual feedback into the learner as a task to find an architecture that (a) enables more semantic alignment between humans and machines and (b) at the same time helps to maintain statistical characteristics of the input domain when generating user-defined counterexamples based on meaningful corrections. Therefore, we introduce a technique called SemanticPush that is effective for translating conceptual corrections of humans to non-extrapolating training examples such that the learner's reasoning is pushed towards the desired behavior. In several experiments, we show that our method clearly outperforms CAIPI, a state of the art IML strategy, in terms of Predictive Performance as well as Local Explanation Quality in downstream multi-class classification tasks.

</p>
</details>

<details><summary><b>Boundary Guided Semantic Learning for Real-time COVID-19 Lung Infection Segmentation System</b>
<a href="https://arxiv.org/abs/2209.02934">arxiv:2209.02934</a>
&#x1F4C8; 7 <br>
<p>Runmin Cong, Yumo Zhang, Ning Yang, Haisheng Li, Xueqi Zhang, Ruochen Li, Zewen Chen, Yao Zhao, Sam Kwong</p></summary>
<p>

**Abstract:** The coronavirus disease 2019 (COVID-19) continues to have a negative impact on healthcare systems around the world, though the vaccines have been developed and national vaccination coverage rate is steadily increasing. At the current stage, automatically segmenting the lung infection area from CT images is essential for the diagnosis and treatment of COVID-19. Thanks to the development of deep learning technology, some deep learning solutions for lung infection segmentation have been proposed. However, due to the scattered distribution, complex background interference and blurred boundaries, the accuracy and completeness of the existing models are still unsatisfactory. To this end, we propose a boundary guided semantic learning network (BSNet) in this paper. On the one hand, the dual-branch semantic enhancement module that combines the top-level semantic preservation and progressive semantic integration is designed to model the complementary relationship between different high-level features, thereby promoting the generation of more complete segmentation results. On the other hand, the mirror-symmetric boundary guidance module is proposed to accurately detect the boundaries of the lesion regions in a mirror-symmetric way. Experiments on the publicly available dataset demonstrate that our BSNet outperforms the existing state-of-the-art competitors and achieves a real-time inference speed of 44 FPS.

</p>
</details>

<details><summary><b>Reconstructing signed relations from interaction data</b>
<a href="https://arxiv.org/abs/2209.03219">arxiv:2209.03219</a>
&#x1F4C8; 6 <br>
<p>Georges Andres, Giona Casiraghi, Giacomo Vaccario, Frank Schweitzer</p></summary>
<p>

**Abstract:** Positive and negative relations play an essential role in human behavior and shape the communities we live in. Despite their importance, data about signed relations is rare and commonly gathered through surveys. Interaction data is more abundant, for instance, in the form of proximity or communication data. So far, though, it could not be utilized to detect signed relations. In this paper, we show how the underlying signed relations can be extracted with such data. Employing a statistical network approach, we construct networks of signed relations in four communities. We then show that these relations correspond to the ones reported in surveys. Additionally, the inferred relations allow us to study the homophily of individuals with respect to gender, religious beliefs, and financial backgrounds. We evaluate the importance of triads in the signed network to study group cohesion.

</p>
</details>

<details><summary><b>Open-Ended Evolution for Minecraft Building Generation</b>
<a href="https://arxiv.org/abs/2209.03108">arxiv:2209.03108</a>
&#x1F4C8; 6 <br>
<p>Matthew Barthet, Antonios Liapis, Georgios N. Yannakakis</p></summary>
<p>

**Abstract:** This paper proposes a procedural content generator which evolves Minecraft buildings according to an open-ended and intrinsic definition of novelty. To realize this goal we evaluate individuals' novelty in the latent space using a 3D autoencoder, and alternate between phases of exploration and transformation. During exploration the system evolves multiple populations of CPPNs through CPPN-NEAT and constrained novelty search in the latent space (defined by the current autoencoder). We apply a set of repair and constraint functions to ensure candidates adhere to basic structural rules and constraints during evolution. During transformation, we reshape the boundaries of the latent space to identify new interesting areas of the solution space by retraining the autoencoder with novel content. In this study we evaluate five different approaches for training the autoencoder during transformation and its impact on populations' quality and diversity during evolution. Our results show that by retraining the autoencoder we can achieve better open-ended complexity compared to a static model, which is further improved when retraining using larger datasets of individuals with diverse complexities.

</p>
</details>

<details><summary><b>On the Convergence of the ELBO to Entropy Sums</b>
<a href="https://arxiv.org/abs/2209.03077">arxiv:2209.03077</a>
&#x1F4C8; 5 <br>
<p>Jörg Lücke</p></summary>
<p>

**Abstract:** The variational lower bound (a.k.a. ELBO or free energy) is the central objective for many learning algorithms including algorithms for deep unsupervised learning. Learning algorithms change model parameters such that the variational lower bound increases, and until the parameters are close to a stationary point of the learning dynamics. In this purely theoretical contribution, we show that (for a very large class of generative models) the variational lower bound is at all stationary points of learning equal to a sum of entropies. For models with one set of latents and one set observed variables, the sum consists of three entropies: (A) the (average) entropy of the variational distributions, (B) the negative entropy of the model's prior distribution, and (C) the (expected) negative entropy of the observable distributions. The obtained result applies under realistic conditions including: finite numbers of data points, at any stationary points (including saddle points) and for any family of (well behaved) variational distributions. The class of generative models for which we show the equality to entropy sums contains many (and presumably most) standard generative models (including deep models). As concrete examples we discuss probabilistic PCA and Sigmoid Belief Networks. The prerequisites we use to show equality to entropy sums are relatively mild. Concretely, the distributions of a given generative model have to be of the exponential family (with constant base measure), and a model has to satisfy a parameterization criterion (which is usually fulfilled). Proving the equality of the ELBO to entropy sums at stationary points (under the stated conditions) is the main contribution of this work.

</p>
</details>

<details><summary><b>Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition</b>
<a href="https://arxiv.org/abs/2209.02960">arxiv:2209.02960</a>
&#x1F4C8; 5 <br>
<p>Saptarshi Sinha, Hiroki Ohashi</p></summary>
<p>

**Abstract:** Long-tailed datasets, where head classes comprise much more training samples than tail classes, cause recognition models to get biased towards the head classes. Weighted loss is one of the most popular ways of mitigating this issue, and a recent work has suggested that class-difficulty might be a better clue than conventionally used class-frequency to decide the distribution of weights. A heuristic formulation was used in the previous work for quantifying the difficulty, but we empirically find that the optimal formulation varies depending on the characteristics of datasets. Therefore, we propose Difficulty-Net, which learns to predict the difficulty of classes using the model's performance in a meta-learning framework. To make it learn reasonable difficulty of a class within the context of other classes, we newly introduce two key concepts, namely the relative difficulty and the driver loss. The former helps Difficulty-Net take other classes into account when calculating difficulty of a class, while the latter is indispensable for guiding the learning to a meaningful direction. Extensive experiments on popular long-tailed datasets demonstrated the effectiveness of the proposed method, and it achieved state-of-the-art performance on multiple long-tailed datasets.

</p>
</details>

<details><summary><b>A Deep Reinforcement Learning Strategy for UAV Autonomous Landing on a Platform</b>
<a href="https://arxiv.org/abs/2209.02954">arxiv:2209.02954</a>
&#x1F4C8; 5 <br>
<p>Z. Jiang, G. Song</p></summary>
<p>

**Abstract:** With the development of industry, drones are appearing in various field. In recent years, deep reinforcement learning has made impressive gains in games, and we are committed to applying deep reinforcement learning algorithms to the field of robotics, moving reinforcement learning algorithms from game scenarios to real-world application scenarios. We are inspired by the LunarLander of OpenAI Gym, we decided to make a bold attempt in the field of reinforcement learning to control drones. At present, there is still a lack of work applying reinforcement learning algorithms to robot control, the physical simulation platform related to robot control is only suitable for the verification of classical algorithms, and is not suitable for accessing reinforcement learning algorithms for the training. In this paper, we will face this problem, bridging the gap between physical simulation platforms and intelligent agent, connecting intelligent agents to a physical simulation platform, allowing agents to learn and complete drone flight tasks in a simulator that approximates the real world. We proposed a reinforcement learning framework based on Gazebo that is a kind of physical simulation platform (ROS-RL), and used three continuous action space reinforcement learning algorithms in the framework to dealing with the problem of autonomous landing of drones. Experiments show the effectiveness of the algorithm, the task of autonomous landing of drones based on reinforcement learning achieved full success.

</p>
</details>

<details><summary><b>Grouping-matrix based Graph Pooling with Adaptive Number of Clusters</b>
<a href="https://arxiv.org/abs/2209.02939">arxiv:2209.02939</a>
&#x1F4C8; 5 <br>
<p>Sung Moon Ko, Sungjun Cho, Dae-Woong Jeong, Sehui Han, Moontae Lee, Honglak Lee</p></summary>
<p>

**Abstract:** Graph pooling is a crucial operation for encoding hierarchical structures within graphs. Most existing graph pooling approaches formulate the problem as a node clustering task which effectively captures the graph topology. Conventional methods ask users to specify an appropriate number of clusters as a hyperparameter, then assume that all input graphs share the same number of clusters. In inductive settings where the number of clusters can vary, however, the model should be able to represent this variation in its pooling layers in order to learn suitable clusters. Thus we propose GMPool, a novel differentiable graph pooling architecture that automatically determines the appropriate number of clusters based on the input data. The main intuition involves a grouping matrix defined as a quadratic form of the pooling operator, which induces use of binary classification probabilities of pairwise combinations of nodes. GMPool obtains the pooling operator by first computing the grouping matrix, then decomposing it. Extensive evaluations on molecular property prediction tasks demonstrate that our method outperforms conventional methods.

</p>
</details>

<details><summary><b>Adjusted Asymmetric Accuracy: A Well-Behaving External Cluster Validity Measure</b>
<a href="https://arxiv.org/abs/2209.02935">arxiv:2209.02935</a>
&#x1F4C8; 5 <br>
<p>Marek Gagolewski</p></summary>
<p>

**Abstract:** There is no, nor will there ever be, single best clustering algorithm, but we would still like to be able to pinpoint those which are well-performing on certain task types and filter out the systematically disappointing ones. Clustering algorithms are traditionally evaluated using either internal or external validity measures. Internal measures quantify different aspects of the obtained partitions, e.g., the average degree of cluster compactness or point separability. Yet, their validity is questionable because the clusterings they promote can sometimes be meaningless. External measures, on the other hand, compare the algorithms' outputs to the reference, ground truth groupings that are provided by experts. The commonly-used classical partition similarity scores, such as the normalised mutual information, Fowlkes-Mallows, or adjusted Rand index, might not possess all the desirable properties, e.g., they do not identify pathological edge cases correctly. Furthermore, they are not nicely interpretable: it is hard to say what a score of 0.8 really means. Its behaviour might also vary as the number of true clusters changes. This makes comparing clustering algorithms across many benchmark datasets difficult. To remedy this, we propose and analyse a new measure: an asymmetric version of the optimal set-matching accuracy. It is corrected for chance and the imbalancedness of cluster sizes.

</p>
</details>

<details><summary><b>Video Vision Transformers for Violence Detection</b>
<a href="https://arxiv.org/abs/2209.03561">arxiv:2209.03561</a>
&#x1F4C8; 4 <br>
<p>Sanskar Singh, Shivaibhav Dewangan, Ghanta Sai Krishna, Vandit Tyagi, Sainath Reddy</p></summary>
<p>

**Abstract:** Law enforcement and city safety are significantly impacted by detecting violent incidents in surveillance systems. Although modern (smart) cameras are widely available and affordable, such technological solutions are impotent in most instances. Furthermore, personnel monitoring CCTV recordings frequently show a belated reaction, resulting in the potential cause of catastrophe to people and property. Thus automated detection of violence for swift actions is very crucial. The proposed solution uses a novel end-to-end deep learning-based video vision transformer (ViViT) that can proficiently discern fights, hostile movements, and violent events in video sequences. The study presents utilizing a data augmentation strategy to overcome the downside of weaker inductive biasness while training vision transformers on a smaller training datasets. The evaluated results can be subsequently sent to local concerned authority, and the captured video can be analyzed. In comparison to state-of-theart (SOTA) approaches the proposed method achieved auspicious performance on some of the challenging benchmark datasets.

</p>
</details>

<details><summary><b>Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization</b>
<a href="https://arxiv.org/abs/2209.03549">arxiv:2209.03549</a>
&#x1F4C8; 4 <br>
<p>Shiyue Zhang, David Wan, Mohit Bansal</p></summary>
<p>

**Abstract:** The problems of unfaithful summaries have been widely discussed under the context of abstractive summarization. Though extractive summarization is less prone to the common unfaithfulness issues of abstractive summaries, does that mean extractive is equal to faithful? Turns out that the answer is no. In this work, we define a typology with five types of broad unfaithfulness problems (including and beyond not-entailment) that can appear in extractive summaries, including incorrect coreference, incomplete coreference, incorrect discourse, incomplete discourse, as well as other misleading information. We ask humans to label these problems out of 1500 English summaries produced by 15 diverse extractive systems. We find that 33% of the summaries have at least one of the five issues. To automatically detect these problems, we find that 5 existing faithfulness evaluation metrics for summarization have poor correlations with human judgment. To remedy this, we propose a new metric, ExtEval, that is designed for detecting unfaithful extractive summaries and is shown to have the best performance. We hope our work can increase the awareness of unfaithfulness problems in extractive summarization and help future work to evaluate and resolve these issues. Our data and code are publicly available at https://github.com/ZhangShiyue/extractive_is_not_faithful

</p>
</details>

<details><summary><b>Reward Delay Attacks on Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.03540">arxiv:2209.03540</a>
&#x1F4C8; 4 <br>
<p>Anindya Sarkar, Jiarui Feng, Yevgeniy Vorobeychik, Christopher Gill, Ning Zhang</p></summary>
<p>

**Abstract:** Most reinforcement learning algorithms implicitly assume strong synchrony. We present novel attacks targeting Q-learning that exploit a vulnerability entailed by this assumption by delaying the reward signal for a limited time period. We consider two types of attack goals: targeted attacks, which aim to cause a target policy to be learned, and untargeted attacks, which simply aim to induce a policy with a low reward. We evaluate the efficacy of the proposed attacks through a series of experiments. Our first observation is that reward-delay attacks are extremely effective when the goal is simply to minimize reward. Indeed, we find that even naive baseline reward-delay attacks are also highly successful in minimizing the reward. Targeted attacks, on the other hand, are more challenging, although we nevertheless demonstrate that the proposed approaches remain highly effective at achieving the attacker's targets. In addition, we introduce a second threat model that captures a minimal mitigation that ensures that rewards cannot be used out of sequence. We find that this mitigation remains insufficient to ensure robustness to attacks that delay, but preserve the order, of rewards.

</p>
</details>

<details><summary><b>A hybrid Bayesian network for medical device risk assessment and management</b>
<a href="https://arxiv.org/abs/2209.03352">arxiv:2209.03352</a>
&#x1F4C8; 4 <br>
<p>Joshua Hunte, Martin Neil, Norman Fenton</p></summary>
<p>

**Abstract:** ISO 14971 is the primary standard used for medical device risk management. While it specifies the requirements for medical device risk management, it does not specify a particular method for performing risk management. Hence, medical device manufacturers are free to develop or use any appropriate methods for managing the risk of medical devices. The most commonly used methods, such as Fault Tree Analysis (FTA), are unable to provide a reasonable basis for computing risk estimates when there are limited or no historical data available or where there is second-order uncertainty about the data. In this paper, we present a novel method for medical device risk management using hybrid Bayesian networks (BNs) that resolves the limitations of classical methods such as FTA and incorporates relevant factors affecting the risk of medical devices. The proposed BN method is generic but can be instantiated on a system-by-system basis, and we apply it to a Defibrillator device to demonstrate the process involved for medical device risk management during production and post-production. The example is validated against real-world data.

</p>
</details>

<details><summary><b>VulCurator: A Vulnerability-Fixing Commit Detector</b>
<a href="https://arxiv.org/abs/2209.03260">arxiv:2209.03260</a>
&#x1F4C8; 4 <br>
<p>Truong Giang Nguyen, Thanh Le-Cong, Hong Jin Kang, Xuan-Bach D. Le, David Lo</p></summary>
<p>

**Abstract:** Open-source software (OSS) vulnerability management process is important nowadays, as the number of discovered OSS vulnerabilities is increasing over time. Monitoring vulnerability-fixing commits is a part of the standard process to prevent vulnerability exploitation. Manually detecting vulnerability-fixing commits is, however, time consuming due to the possibly large number of commits to review. Recently, many techniques have been proposed to automatically detect vulnerability-fixing commits using machine learning. These solutions either: (1) did not use deep learning, or (2) use deep learning on only limited sources of information. This paper proposes VulCurator, a tool that leverages deep learning on richer sources of information, including commit messages, code changes and issue reports for vulnerability-fixing commit classifica- tion. Our experimental results show that VulCurator outperforms the state-of-the-art baselines up to 16.1% in terms of F1-score. VulCurator tool is publicly available at https://github.com/ntgiang71096/VFDetector and https://zenodo.org/record/7034132#.Yw3MN-xBzDI, with a demo video at https://youtu.be/uMlFmWSJYOE.

</p>
</details>

<details><summary><b>Dual Instrumental Method for Confounded Kernelized Bandits</b>
<a href="https://arxiv.org/abs/2209.03224">arxiv:2209.03224</a>
&#x1F4C8; 4 <br>
<p>Xueping Gong, Jiheng Zhang</p></summary>
<p>

**Abstract:** The contextual bandit problem is a theoretically justified framework with wide applications in various fields. While the previous study on this problem usually requires independence between noise and contexts, our work considers a more sensible setting where the noise becomes a latent confounder that affects both contexts and rewards. Such a confounded setting is more realistic and could expand to a broader range of applications. However, the unresolved confounder will cause a bias in reward function estimation and thus lead to a large regret. To deal with the challenges brought by the confounder, we apply the dual instrumental variable regression, which can correctly identify the true reward function. We prove the convergence rate of this method is near-optimal in two types of widely used reproducing kernel Hilbert spaces. Therefore, we can design computationally efficient and regret-optimal algorithms based on the theoretical guarantees for confounded bandit problems. The numerical results illustrate the efficacy of our proposed algorithms in the confounded bandit setting.

</p>
</details>

<details><summary><b>INFACT: An Online Human Evaluation Framework for Conversational Recommendation</b>
<a href="https://arxiv.org/abs/2209.03213">arxiv:2209.03213</a>
&#x1F4C8; 4 <br>
<p>Ahtsham Manzoor, Dietmar jannach</p></summary>
<p>

**Abstract:** Conversational recommender systems (CRS) are interactive agents that support their users in recommendation-related goals through multi-turn conversations. Generally, a CRS can be evaluated in various dimensions. Today's CRS mainly rely on offline(computational) measures to assess the performance of their algorithms in comparison to different baselines. However, offline measures can have limitations, for example, when the metrics for comparing a newly generated response with a ground truth do not correlate with human perceptions, because various alternative generated responses might be suitable too in a given dialog situation. Current research on machine learning-based CRS models therefore acknowledges the importance of humans in the evaluation process, knowing that pure offline measures may not be sufficient in evaluating a highly interactive system like a CRS.

</p>
</details>

<details><summary><b>Real-to-Sim: Deep Learning with Auto-Tuning to Predict Residual Errors using Sparse Data</b>
<a href="https://arxiv.org/abs/2209.03210">arxiv:2209.03210</a>
&#x1F4C8; 4 <br>
<p>Alexander Schperberg, Yusuke Tanaka, Feng Xu, Marcel Menner, Dennis Hong</p></summary>
<p>

**Abstract:** Achieving highly accurate kinematic or simulator models that are close to the real robot can facilitate model-based controls (e.g., model predictive control or linear-quadradic regulators), model-based trajectory planning (e.g., trajectory optimization), and decrease the amount of learning time necessary for reinforcement learning methods. Thus, the objective of this work is to learn the residual errors between a kinematic and/or simulator model and the real robot. This is achieved using auto-tuning and neural networks, where the parameters of a neural network are updated using an auto-tuning method that applies equations from an Unscented Kalman Filter (UKF) formulation. Using this method, we model these residual errors with only small amounts of data - a necessity as we improve the simulator/kinematic model by learning directly from hardware operation. We demonstrate our method on robotic hardware (e.g., manipulator arm), and show that with the learned residual errors, we can further close the reality gap between kinematic models, simulations, and the real robot.

</p>
</details>

<details><summary><b>Machine Learning Partners in Criminal Networks</b>
<a href="https://arxiv.org/abs/2209.03171">arxiv:2209.03171</a>
&#x1F4C8; 4 <br>
<p>Diego D. Lopes, Bruno R. da Cunha, Alvaro F. Martins, Sebastian Goncalves, Ervin K. Lenzi, Quentin S. Hanley, Matjaz Perc, Haroldo V. Ribeiro</p></summary>
<p>

**Abstract:** Recent research has shown that criminal networks have complex organizational structures, but whether this can be used to predict static and dynamic properties of criminal networks remains little explored. Here, by combining graph representation learning and machine learning methods, we show that structural properties of political corruption, police intelligence, and money laundering networks can be used to recover missing criminal partnerships, distinguish among different types of criminal and legal associations, as well as predict the total amount of money exchanged among criminal agents, all with outstanding accuracy. We also show that our approach can anticipate future criminal associations during the dynamic growth of corruption networks with significant accuracy. Thus, similar to evidence found at crime scenes, we conclude that structural patterns of criminal networks carry crucial information about illegal activities, which allows machine learning methods to predict missing information and even anticipate future criminal behavior.

</p>
</details>

<details><summary><b>Plant Species Classification Using Transfer Learning by Pretrained Classifier VGG-19</b>
<a href="https://arxiv.org/abs/2209.03076">arxiv:2209.03076</a>
&#x1F4C8; 4 <br>
<p>Thiru Siddharth, Bhupendra Singh Kirar, Dheeraj Kumar Agrawal</p></summary>
<p>

**Abstract:** Deep learning is currently the most important branch of machine learning, with applications in speech recognition, computer vision, image classification, and medical imaging analysis. Plant recognition is one of the areas where image classification can be used to identify plant species through their leaves. Botanists devote a significant amount of time to recognizing plant species by personally inspecting. This paper describes a method for dissecting color images of Swedish leaves and identifying plant species. To achieve higher accuracy, the task is completed using transfer learning with the help of pre-trained classifier VGG-19. The four primary processes of classification are image preprocessing, image augmentation, feature extraction, and recognition, which are performed as part of the overall model evaluation. The VGG-19 classifier grasps the characteristics of leaves by employing pre-defined hidden layers such as convolutional layers, max pooling layers, and fully connected layers, and finally uses the soft-max layer to generate a feature representation for all plant classes. The model obtains knowledge connected to aspects of the Swedish leaf dataset, which contains fifteen tree classes, and aids in predicting the proper class of an unknown plant with an accuracy of 99.70% which is higher than previous research works reported.

</p>
</details>

<details><summary><b>SIRA: Relightable Avatars from a Single Image</b>
<a href="https://arxiv.org/abs/2209.03027">arxiv:2209.03027</a>
&#x1F4C8; 4 <br>
<p>Pol Caselles, Eduard Ramon, Jaime Garcia, Xavier Giro-i-Nieto, Francesc Moreno-Noguer, Gil Triginer</p></summary>
<p>

**Abstract:** Recovering the geometry of a human head from a single image, while factorizing the materials and illumination is a severely ill-posed problem that requires prior information to be solved. Methods based on 3D Morphable Models (3DMM), and their combination with differentiable renderers, have shown promising results. However, the expressiveness of 3DMMs is limited, and they typically yield over-smoothed and identity-agnostic 3D shapes limited to the face region. Highly accurate full head reconstructions have recently been obtained with neural fields that parameterize the geometry using multilayer perceptrons. The versatility of these representations has also proved effective for disentangling geometry, materials and lighting. However, these methods require several tens of input images. In this paper, we introduce SIRA, a method which, from a single image, reconstructs human head avatars with high fidelity geometry and factorized lights and surface materials. Our key ingredients are two data-driven statistical models based on neural fields that resolve the ambiguities of single-view 3D surface reconstruction and appearance factorization. Experiments show that SIRA obtains state of the art results in 3D head reconstruction while at the same time it successfully disentangles the global illumination, and the diffuse and specular albedos. Furthermore, our reconstructions are amenable to physically-based appearance editing and head model relighting.

</p>
</details>

<details><summary><b>Biblio-Analysis of Cohort Intelligence (CI) Algorithm and its allied applications from Scopus and Web of Science Perspective</b>
<a href="https://arxiv.org/abs/2209.03009">arxiv:2209.03009</a>
&#x1F4C8; 4 <br>
<p>Ishaan Kale, Rahul Joshi, Kalyani Kadam</p></summary>
<p>

**Abstract:** Cohort Intelligence or CI is one of its kind of novel optimization algorithm. Since its inception, in a very short span it is applied successfully in various domains and its results are observed to be effectual in contrast to algorithm of its kind. Till date, there is no such type of bibliometric analysis carried out on CI and its related applications. So, this research paper in a way will be an ice breaker for those who want to take up CI to a new level. In this research papers, CI publications available in Scopus are analyzed through graphs, networked diagrams about authors, source titles, keywords over the years, journals over the time. In a way this bibliometric paper showcase CI, its applications and detail outs systematic review in terms its bibliometric details.

</p>
</details>

<details><summary><b>Shifting Perspective to See Difference: A Novel Multi-View Method for Skeleton based Action Recognition</b>
<a href="https://arxiv.org/abs/2209.02986">arxiv:2209.02986</a>
&#x1F4C8; 4 <br>
<p>Ruijie Hou, Yanran Li, Ningyu Zhang, Yulin Zhou, Xiaosong Yang, Zhao Wang</p></summary>
<p>

**Abstract:** Skeleton-based human action recognition is a longstanding challenge due to its complex dynamics. Some fine-grain details of the dynamics play a vital role in classification. The existing work largely focuses on designing incremental neural networks with more complicated adjacent matrices to capture the details of joints relationships. However, they still have difficulties distinguishing actions that have broadly similar motion patterns but belong to different categories. Interestingly, we found that the subtle differences in motion patterns can be significantly amplified and become easy for audience to distinct through specified view directions, where this property haven't been fully explored before. Drastically different from previous work, we boost the performance by proposing a conceptually simple yet effective Multi-view strategy that recognizes actions from a collection of dynamic view features. Specifically, we design a novel Skeleton-Anchor Proposal (SAP) module which contains a Multi-head structure to learn a set of views. For feature learning of different views, we introduce a novel Angle Representation to transform the actions under different views and feed the transformations into the baseline model. Our module can work seamlessly with the existing action classification model. Incorporated with baseline models, our SAP module exhibits clear performance gains on many challenging benchmarks. Moreover, comprehensive experiments show that our model consistently beats down the state-of-the-art and remains effective and robust especially when dealing with corrupted data. Related code will be available on https://github.com/ideal-idea/SAP .

</p>
</details>

<details><summary><b>Fact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against Fact-Verification Systems</b>
<a href="https://arxiv.org/abs/2209.03755">arxiv:2209.03755</a>
&#x1F4C8; 3 <br>
<p>Sahar Abdelnabi, Mario Fritz</p></summary>
<p>

**Abstract:** Mis- and disinformation are now a substantial global threat to our security and safety. To cope with the scale of online misinformation, one viable solution is to automate the fact-checking of claims by retrieving and verifying against relevant evidence. While major recent advances have been achieved in pushing forward the automatic fact-verification, a comprehensive evaluation of the possible attack vectors against such systems is still lacking. Particularly, the automated fact-verification process might be vulnerable to the exact disinformation campaigns it is trying to combat. In this work, we assume an adversary that automatically tampers with the online evidence in order to disrupt the fact-checking model via camouflaging the relevant evidence, or planting a misleading one. We first propose an exploratory taxonomy that spans these two targets and the different threat model dimensions. Guided by this, we design and propose several potential attack methods. We show that it is possible to subtly modify claim-salient snippets in the evidence, in addition to generating diverse and claim-aligned evidence. As a result, we highly degrade the fact-checking performance under many different permutations of the taxonomy's dimensions. The attacks are also robust against post-hoc modifications of the claim. Our analysis further hints at potential limitations in models' inference when faced with contradicting evidence. We emphasize that these attacks can have harmful implications on the inspectable and human-in-the-loop usage scenarios of such models, and we conclude by discussing challenges and directions for future defenses.

</p>
</details>

<details><summary><b>CLaCLab at SocialDisNER: Using Medical Gazetteers for Named-Entity Recognition of Disease Mentions in Spanish Tweets</b>
<a href="https://arxiv.org/abs/2209.03528">arxiv:2209.03528</a>
&#x1F4C8; 3 <br>
<p>Harsh Verma, Parsa Bagherzadeh, Sabine Bergler</p></summary>
<p>

**Abstract:** This paper summarizes the CLaC submission for SMM4H 2022 Task 10 which concerns the recognition of diseases mentioned in Spanish tweets. Before classifying each token, we encode each token with a transformer encoder using features from Multilingual RoBERTa Large, UMLS gazetteer, and DISTEMIST gazetteer, among others. We obtain a strict F1 score of 0.869, with competition mean of 0.675, standard deviation of 0.245, and median of 0.761.

</p>
</details>

<details><summary><b>AILAB-Udine@SMM4H 22: Limits of Transformers and BERT Ensembles</b>
<a href="https://arxiv.org/abs/2209.03452">arxiv:2209.03452</a>
&#x1F4C8; 3 <br>
<p>Beatrice Portelli, Simone Scaboro, Emmanuele Chersoni, Enrico Santus, Giuseppe Serra</p></summary>
<p>

**Abstract:** This paper describes the models developed by the AILAB-Udine team for the SMM4H 22 Shared Task. We explored the limits of Transformer based models on text classification, entity extraction and entity normalization, tackling Tasks 1, 2, 5, 6 and 10. The main take-aways we got from participating in different tasks are: the overwhelming positive effects of combining different architectures when using ensemble learning, and the great potential of generative models for term normalization.

</p>
</details>

<details><summary><b>Foundations and Recent Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions</b>
<a href="https://arxiv.org/abs/2209.03430">arxiv:2209.03430</a>
&#x1F4C8; 3 <br>
<p>Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency</p></summary>
<p>

**Abstract:** Multimodal machine learning is a vibrant multi-disciplinary research field that aims to design computer agents with intelligent capabilities such as understanding, reasoning, and learning through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. With the recent interest in video understanding, embodied autonomous agents, text-to-image generation, and multisensor fusion in application domains such as healthcare and robotics, multimodal machine learning has brought unique computational and theoretical challenges to the machine learning community given the heterogeneity of data sources and the interconnections often found between modalities. However, the breadth of progress in multimodal research has made it difficult to identify the common themes and open questions in the field. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this paper is designed to provide an overview of the computational and theoretical foundations of multimodal machine learning. We start by defining two key principles of modality heterogeneity and interconnections that have driven subsequent innovations, and propose a taxonomy of 6 core technical challenges: representation, alignment, reasoning, generation, transference, and quantification covering historical and recent trends. Recent technical achievements will be presented through the lens of this taxonomy, allowing researchers to understand the similarities and differences across new approaches. We end by motivating several open problems for future research as identified by our taxonomy.

</p>
</details>

<details><summary><b>The (Un)Scalability of Heuristic Approximators for NP-Hard Search Problems</b>
<a href="https://arxiv.org/abs/2209.03393">arxiv:2209.03393</a>
&#x1F4C8; 3 <br>
<p>Sumedh Pendurkar, Taoan Huang, Sven Koenig, Guni Sharon</p></summary>
<p>

**Abstract:** The A* algorithm is commonly used to solve NP-hard combinatorial optimization problems. When provided with an accurate heuristic function, A* can solve such problems in time complexity that is polynomial in the solution depth. This fact implies that accurate heuristic approximation for many such problems is also NP-hard. In this context, we examine a line of recent publications that propose the use of deep neural networks for heuristic approximation. We assert that these works suffer from inherent scalability limitations since -- under the assumption that P$\ne$NP -- such approaches result in either (a) network sizes that scale exponentially in the instance sizes or (b) heuristic approximation accuracy that scales inversely with the instance sizes. Our claim is supported by experimental results for three representative NP-hard search problems that show that fitting deep neural networks accurately to heuristic functions necessitates network sizes that scale exponentially with the instance size.

</p>
</details>

<details><summary><b>Manifold Free Riemannian Optimization</b>
<a href="https://arxiv.org/abs/2209.03269">arxiv:2209.03269</a>
&#x1F4C8; 3 <br>
<p>Boris Shustin, Haim Avron, Barak Sober</p></summary>
<p>

**Abstract:** Riemannian optimization is a principled framework for solving optimization problems where the desired optimum is constrained to a smooth manifold $\mathcal{M}$. Algorithms designed in this framework usually require some geometrical description of the manifold, which typically includes tangent spaces, retractions, and gradients of the cost function. However, in many cases, only a subset (or none at all) of these elements can be accessed due to lack of information or intractability. In this paper, we propose a novel approach that can perform approximate Riemannian optimization in such cases, where the constraining manifold is a submanifold of $\R^{D}$. At the bare minimum, our method requires only a noiseless sample set of the cost function $(\x_{i}, y_{i})\in {\mathcal{M}} \times \mathbb{R}$ and the intrinsic dimension of the manifold $\mathcal{M}$. Using the samples, and utilizing the Manifold-MLS framework (Sober and Levin 2020), we construct approximations of the missing components entertaining provable guarantees and analyze their computational costs. In case some of the components are given analytically (e.g., if the cost function and its gradient are given explicitly, or if the tangent spaces can be computed), the algorithm can be easily adapted to use the accurate expressions instead of the approximations. We analyze the global convergence of Riemannian gradient-based methods using our approach, and we demonstrate empirically the strength of this method, together with a conjugate-gradients type method based upon similar principles.

</p>
</details>

<details><summary><b>Machine Learning-based Automatic Annotation and Detection of COVID-19 Fake News</b>
<a href="https://arxiv.org/abs/2209.03162">arxiv:2209.03162</a>
&#x1F4C8; 3 <br>
<p>Mohammad Majid Akhtar, Bibhas Sharma, Ishan Karunanayake, Rahat Masood, Muhammad Ikram, Salil S. Kanhere</p></summary>
<p>

**Abstract:** COVID-19 impacted every part of the world, although the misinformation about the outbreak traveled faster than the virus. Misinformation spread through online social networks (OSN) often misled people from following correct medical practices. In particular, OSN bots have been a primary source of disseminating false information and initiating cyber propaganda. Existing work neglects the presence of bots that act as a catalyst in the spread and focuses on fake news detection in 'articles shared in posts' rather than the post (textual) content. Most work on misinformation detection uses manually labeled datasets that are hard to scale for building their predictive models. In this research, we overcome this challenge of data scarcity by proposing an automated approach for labeling data using verified fact-checked statements on a Twitter dataset. In addition, we combine textual features with user-level features (such as followers count and friends count) and tweet-level features (such as number of mentions, hashtags and urls in a tweet) to act as additional indicators to detect misinformation. Moreover, we analyzed the presence of bots in tweets and show that bots change their behavior over time and are most active during the misinformation campaign. We collected 10.22 Million COVID-19 related tweets and used our annotation model to build an extensive and original ground truth dataset for classification purposes. We utilize various machine learning models to accurately detect misinformation and our best classification model achieves precision (82%), recall (96%), and false positive rate (3.58%). Also, our bot analysis indicates that bots generated approximately 10% of misinformation tweets. Our methodology results in substantial exposure of false information, thus improving the trustworthiness of information disseminated through social media platforms.

</p>
</details>

<details><summary><b>Inference and Learning for Generative Capsule Models</b>
<a href="https://arxiv.org/abs/2209.03115">arxiv:2209.03115</a>
&#x1F4C8; 3 <br>
<p>Alfredo Nazabal, Nikolaos Tsagkas, Christopher K. I. Williams</p></summary>
<p>

**Abstract:** Capsule networks (see e.g. Hinton et al., 2018) aim to encode knowledge of and reason about the relationship between an object and its parts. In this paper we specify a generative model for such data, and derive a variational algorithm for inferring the transformation of each model object in a scene, and the assignments of observed parts to the objects. We derive a learning algorithm for the object models, based on variational expectation maximization (Jordan et al., 1999). We also study an alternative inference algorithm based on the RANSAC method of Fischler and Bolles (1981). We apply these inference methods to (i) data generated from multiple geometric objects like squares and triangles ("constellations"), and (ii) data from a parts-based model of faces. Recent work by Kosiorek et al. (2019) has used amortized inference via stacked capsule autoencoders (SCAEs) to tackle this problem -- our results show that we significantly outperform them where we can make comparisons (on the constellations data).

</p>
</details>

<details><summary><b>A learning theory for quantum photonic processors and beyond</b>
<a href="https://arxiv.org/abs/2209.03075">arxiv:2209.03075</a>
&#x1F4C8; 3 <br>
<p>Matteo Rosati</p></summary>
<p>

**Abstract:** We consider the tasks of learning quantum states, measurements and channels generated by continuous-variable (CV) quantum circuits. This family of circuits is suited to describe optical quantum technologies and in particular it includes state-of-the-art photonic processors capable of showing quantum advantage. We define classes of functions that map classical variables, encoded into the CV circuit parameters, to outcome probabilities evaluated on those circuits. We then establish efficient learnability guarantees for such classes, by computing bounds on their pseudo-dimension or covering numbers, showing that CV quantum circuits can be learned with a sample complexity that scales polynomially with the circuit's size, i.e., the number of modes. Our results establish that CV circuits can be trained efficiently using a number of training samples that, unlike their finite-dimensional counterpart, does not scale with the circuit depth.

</p>
</details>

<details><summary><b>Physics-based Digital Twins for Autonomous Thermal Food Processing: Efficient, Non-intrusive Reduced-order Modeling</b>
<a href="https://arxiv.org/abs/2209.03062">arxiv:2209.03062</a>
&#x1F4C8; 3 <br>
<p>Maximilian Kannapinn, Minh Khang Pham, Michael Schäfer</p></summary>
<p>

**Abstract:** One possible way of making thermal processing controllable is to gather real-time information on the product's current state. Often, sensory equipment cannot capture all relevant information easily or at all. Digital Twins close this gap with virtual probes in real-time simulations, synchronized with the process. This paper proposes a physics-based, data-driven Digital Twin framework for autonomous food processing. We suggest a lean Digital Twin concept that is executable at the device level, entailing minimal computational load, data storage, and sensor data requirements. This study focuses on a parsimonious experimental design for training non-intrusive reduced-order models (ROMs) of a thermal process. A correlation ($R=-0.76$) between a high standard deviation of the surface temperatures in the training data and a low root mean square error in ROM testing enables efficient selection of training data. The mean test root mean square error of the best ROM is less than 1 Kelvin (0.2 % mean average percentage error) on representative test sets. Simulation speed-ups of Sp $\approx$ 1.8E4 allow on-device model predictive control.
  The proposed Digital Twin framework is designed to be applicable within the industry. Typically, non-intrusive reduced-order modeling is required as soon as the modeling of the process is performed in software, where root-level access to the solver is not provided, such as commercial simulation software. The data-driven training of the reduced-order model is achieved with only one data set, as correlations are utilized to predict the training success a priori.

</p>
</details>

<details><summary><b>Graph Neural Networks for Low-Energy Event Classification & Reconstruction in IceCube</b>
<a href="https://arxiv.org/abs/2209.03042">arxiv:2209.03042</a>
&#x1F4C8; 3 <br>
<p>R. Abbasi, M. Ackermann, J. Adams, N. Aggarwal, J. A. Aguilar, M. Ahlers, M. Ahrens, J. M. Alameddine, A. A. Alves Jr., N. M. Amin, K. Andeen, T. Anderson, G. Anton, C. Argüelles, Y. Ashida, S. Athanasiadou, S. Axani, X. Bai, A. Balagopal V., M. Baricevic, S. W. Barwick, V. Basu, R. Bay, J. J. Beatty, K. -H. Becker</p></summary>
<p>

**Abstract:** IceCube, a cubic-kilometer array of optical sensors built to detect atmospheric and astrophysical neutrinos between 1 GeV and 1 PeV, is deployed 1.45 km to 2.45 km below the surface of the ice sheet at the South Pole. The classification and reconstruction of events from the in-ice detectors play a central role in the analysis of data from IceCube. Reconstructing and classifying events is a challenge due to the irregular detector geometry, inhomogeneous scattering and absorption of light in the ice and, below 100 GeV, the relatively low number of signal photons produced per event. To address this challenge, it is possible to represent IceCube events as point cloud graphs and use a Graph Neural Network (GNN) as the classification and reconstruction method. The GNN is capable of distinguishing neutrino events from cosmic-ray backgrounds, classifying different neutrino event types, and reconstructing the deposited energy, direction and interaction vertex. Based on simulation, we provide a comparison in the 1-100 GeV energy range to the current state-of-the-art maximum likelihood techniques used in current IceCube analyses, including the effects of known systematic uncertainties. For neutrino event classification, the GNN increases the signal efficiency by 18% at a fixed false positive rate (FPR), compared to current IceCube methods. Alternatively, the GNN offers a reduction of the FPR by over a factor 8 (to below half a percent) at a fixed signal efficiency. For the reconstruction of energy, direction, and interaction vertex, the resolution improves by an average of 13%-20% compared to current maximum likelihood techniques in the energy range of 1-30 GeV. The GNN, when run on a GPU, is capable of processing IceCube events at a rate nearly double of the median IceCube trigger rate of 2.7 kHz, which opens the possibility of using low energy neutrinos in online searches for transient events.

</p>
</details>

<details><summary><b>Bayesian learning of feature spaces for multitasks problems</b>
<a href="https://arxiv.org/abs/2209.03028">arxiv:2209.03028</a>
&#x1F4C8; 3 <br>
<p>Carlos Sevilla-Salcedo, Ascensión Gallardo-Antolín, Vanessa Gómez-Verdejo, Emilio Parrado-Hernández</p></summary>
<p>

**Abstract:** This paper presents a Bayesian framework to construct non-linear, parsimonious, shallow models for multitask regression. The proposed framework relies on the fact that Random Fourier Features (RFFs) enables the approximation of an RBF kernel by an extreme learning machine whose hidden layer is formed by RFFs. The main idea is to combine both dual views of a same model under a single Bayesian formulation that extends the Sparse Bayesian Extreme Learning Machines to multitask problems. From the kernel methods point of view, the proposed formulation facilitates the introduction of prior domain knowledge through the RBF kernel parameter. From the extreme learning machines perspective, the new formulation helps control overfitting and enables a parsimonious overall model (the models that serve each task share a same set of RFFs selected within the joint Bayesian optimisation). The experimental results show that combining advantages from kernel methods and extreme learning machines within the same framework can lead to significant improvements in the performance achieved by each of these two paradigms independently.

</p>
</details>

<details><summary><b>CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs</b>
<a href="https://arxiv.org/abs/2209.03737">arxiv:2209.03737</a>
&#x1F4C8; 2 <br>
<p>Wael Deabes, Alaa E. Abdel-Hakim</p></summary>
<p>

**Abstract:** Due to the rapid growth of Electrical Capacitance Tomography (ECT) applications in several industrial fields, there is a crucial need for developing high quality, yet fast, methodologies of image reconstruction from raw capacitance measurements. Deep learning, as an effective non-linear mapping tool for complicated functions, has been going viral in many fields including electrical tomography. In this paper, we propose a Conditional Generative Adversarial Network (CGAN) model for reconstructing ECT images from capacitance measurements. The initial image of the CGAN model is constructed from the capacitance measurement. To our knowledge, this is the first time to represent the capacitance measurements in an image form. We have created a new massive ECT dataset of 320K synthetic image measurements pairs for training, and testing the proposed model. The feasibility and generalization ability of the proposed CGAN-ECT model are evaluated using testing dataset, contaminated data and flow patterns that are not exposed to the model during the training phase. The evaluation results prove that the proposed CGAN-ECT model can efficiently create more accurate ECT images than traditional and other deep learning-based image reconstruction algorithms. CGAN-ECT achieved an average image correlation coefficient of more than 99.3% and an average relative image error about 0.07.

</p>
</details>

<details><summary><b>Knowledge Based Template Machine Translation In Low-Resource Setting</b>
<a href="https://arxiv.org/abs/2209.03554">arxiv:2209.03554</a>
&#x1F4C8; 2 <br>
<p>Zilu Tang, Derry Wijaya</p></summary>
<p>

**Abstract:** Incorporating tagging into neural machine translation (NMT) systems has shown promising results in helping translate rare words such as named entities (NE). However, translating NE in low-resource setting remains a challenge. In this work, we investigate the effect of using tags and NE hypernyms from knowledge graphs (KGs) in parallel corpus in different levels of resource conditions. We find the tag-and-copy mechanism (tag the NEs in the source sentence and copy them to the target sentence) improves translation in high-resource settings only. Introducing copying also results in polarizing effects in translating different parts-of-speech (POS). Interestingly, we find that copy accuracy for hypernyms is consistently higher than that of entities. As a way of avoiding "hard" copying and utilizing hypernym in bootstrapping rare entities, we introduced a "soft" tagging mechanism and found consistent improvement in high and low-resource settings.

</p>
</details>

<details><summary><b>A Secure and Efficient Multi-Object Grasping Detection Approach for Robotic Arms</b>
<a href="https://arxiv.org/abs/2209.03511">arxiv:2209.03511</a>
&#x1F4C8; 2 <br>
<p>Hui Wang, Jieren Cheng, Yichen Xu, Sirui Ni, Zaijia Yang, Jiangpeng Li</p></summary>
<p>

**Abstract:** Robotic arms are widely used in automatic industries. However, with wide applications of deep learning in robotic arms, there are new challenges such as the allocation of grasping computing power and the growing demand for security. In this work, we propose a robotic arm grasping approach based on deep learning and edge-cloud collaboration. This approach realizes the arbitrary grasp planning of the robot arm and considers the grasp efficiency and information security. In addition, the encoder and decoder trained by GAN enable the images to be encrypted while compressing, which ensures the security of privacy. The model achieves 92% accuracy on the OCID dataset, the image compression ratio reaches 0.03%, and the structural difference value is higher than 0.91.

</p>
</details>

<details><summary><b>Blessing of Class Diversity in Pre-training</b>
<a href="https://arxiv.org/abs/2209.03447">arxiv:2209.03447</a>
&#x1F4C8; 2 <br>
<p>Yulai Zhao, Jianshu Chen, Simon S. Du</p></summary>
<p>

**Abstract:** This paper presents a new statistical analysis aiming to explain the recent superior achievements of the pre-training techniques in natural language processing (NLP). We prove that when the classes of the pre-training task (e.g., different words in the masked language model task) are sufficiently diverse, in the sense that the least singular value of the last linear layer in pre-training (denoted as $\tildeν$) is large, then pre-training can significantly improve the sample efficiency of downstream tasks. Specially, we show the transfer learning excess risk enjoys an $O\left(\frac{1}{\tildeν \sqrt{n}}\right)$ rate, in contrast to the $O\left(\frac{1}{\sqrt{m}}\right)$ rate in the standard supervised learning. Here, $n$ is the number of pre-training data and $m$ is the number of data in the downstream task, and typically $n \gg m$. Our proof relies on a vector-form Rademacher complexity chain rule for disassembling composite function classes and a modified self-concordance condition. These techniques can be of independent interest.

</p>
</details>

<details><summary><b>Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2209.03355">arxiv:2209.03355</a>
&#x1F4C8; 2 <br>
<p>Simone Angarano, Francesco Salvetti, Mauro Martini, Marcello Chiaberge</p></summary>
<p>

**Abstract:** Single-Image Super-Resolution can support robotic tasks in environments where a reliable visual stream is required to monitor the mission, handle teleoperation or study relevant visual details. In this work, we propose an efficient Generative Adversarial Network model for real-time Super-Resolution. We adopt a tailored architecture of the original SRGAN and model quantization to boost the execution on CPU and Edge TPU devices, achieving up to 200 fps inference. We further optimize our model by distilling its knowledge to a smaller version of the network and obtain remarkable improvements compared to the standard training approach. Our experiments show that our fast and lightweight model preserves considerably satisfying image quality compared to heavier state-of-the-art models. Finally, we conduct experiments on image transmission with bandwidth degradation to highlight the advantages of the proposed system for mobile robotic applications.

</p>
</details>

<details><summary><b>Spach Transformer: Spatial and Channel-wise Transformer Based on Local and Global Self-attentions for PET Image Denoising</b>
<a href="https://arxiv.org/abs/2209.03300">arxiv:2209.03300</a>
&#x1F4C8; 2 <br>
<p>Se-In Jang, Tinsu Pan, Ye Li, Pedram Heidari, Junyu Chen, Quanzheng Li, Kuang Gong</p></summary>
<p>

**Abstract:** Position emission tomography (PET) is widely used in clinics and research due to its quantitative merits and high sensitivity, but suffers from low signal-to-noise ratio (SNR). Recently convolutional neural networks (CNNs) have been widely used to improve PET image quality. Though successful and efficient in local feature extraction, CNN cannot capture long-range dependencies well due to its limited receptive field. Global multi-head self-attention (MSA) is a popular approach to capture long-range information. However, the calculation of global MSA for 3D images has high computational costs. In this work, we proposed an efficient spatial and channel-wise encoder-decoder transformer, Spach Transformer, that can leverage spatial and channel information based on local and global MSAs. Experiments based on datasets of different PET tracers, i.e., $^{18}$F-FDG, $^{18}$F-ACBC, $^{18}$F-DCFPyL, and $^{68}$Ga-DOTATATE, were conducted to evaluate the proposed framework. Quantitative results show that the proposed Spach Transformer can achieve better performance than other reference methods.

</p>
</details>

<details><summary><b>Hardware faults that matter: Understanding and Estimating the safety impact of hardware faults on object detection DNNs</b>
<a href="https://arxiv.org/abs/2209.03225">arxiv:2209.03225</a>
&#x1F4C8; 2 <br>
<p>Syed Qutub, Florian Geissler, Yang Peng, Ralf Grafe, Michael Paulitsch, Gereon Hinz, Alois Knoll</p></summary>
<p>

**Abstract:** Object detection neural network models need to perform reliably in highly dynamic and safety-critical environments like automated driving or robotics. Therefore, it is paramount to verify the robustness of the detection under unexpected hardware faults like soft errors that can impact a systems perception module. Standard metrics based on average precision produce model vulnerability estimates at the object level rather than at an image level. As we show in this paper, this does not provide an intuitive or representative indicator of the safety-related impact of silent data corruption caused by bit flips in the underlying memory but can lead to an over- or underestimation of typical fault-induced hazards. With an eye towards safety-related real-time applications, we propose a new metric IVMOD (Image-wise Vulnerability Metric for Object Detection) to quantify vulnerability based on an incorrect image-wise object detection due to false positive (FPs) or false negative (FNs) objects, combined with a severity analysis. The evaluation of several representative object detection models shows that even a single bit flip can lead to a severe silent data corruption event with potentially critical safety implications, with e.g., up to (much greater than) 100 FPs generated, or up to approx. 90% of true positives (TPs) are lost in an image. Furthermore, with a single stuck-at-1 fault, an entire sequence of images can be affected, causing temporally persistent ghost detections that can be mistaken for actual objects (covering up to approx. 83% of the image). Furthermore, actual objects in the scene are continuously missed (up to approx. 64% of TPs are lost). Our work establishes a detailed understanding of the safety-related vulnerability of such critical workloads against hardware faults.

</p>
</details>

<details><summary><b>Efficient Implementation of Non-linear Flow Law Using Neural Network into the Abaqus Explicit FEM code</b>
<a href="https://arxiv.org/abs/2209.03190">arxiv:2209.03190</a>
&#x1F4C8; 2 <br>
<p>Olivier Pantalé, Pierre Tize Mha, Amèvi Tongne</p></summary>
<p>

**Abstract:** Machine learning techniques are increasingly used to predict material behavior in scientific applications and offer a significant advantage over conventional numerical methods. In this work, an Artificial Neural Network (ANN) model is used in a finite element formulation to define the flow law of a metallic material as a function of plastic strain, plastic strain rate and temperature. First, we present the general structure of the neural network, its operation and focus on the ability of the network to deduce, without prior learning, the derivatives of the flow law with respect to the model inputs. In order to validate the robustness and accuracy of the proposed model, we compare and analyze the performance of several network architectures with respect to the analytical formulation of a Johnson-Cook behavior law for a 42CrMo4 steel. In a second part, after having selected an Artificial Neural Network architecture with $2$ hidden layers, we present the implementation of this model in the Abaqus Explicit computational code in the form of a VUHARD subroutine. The predictive capability of the proposed model is then demonstrated during the numerical simulation of two test cases: the necking of a circular bar and a Taylor impact test. The results obtained show a very high capability of the ANN to replace the analytical formulation of a Johnson-Cook behavior law in a finite element code, while remaining competitive in terms of numerical simulation time compared to a classical approach.

</p>
</details>

<details><summary><b>A Data-driven Reduced Order Modeling Approach Applied In Context Of Numerical Analysis And Optimization Of Plastic Profile Extrusion</b>
<a href="https://arxiv.org/abs/2209.03121">arxiv:2209.03121</a>
&#x1F4C8; 2 <br>
<p>Daniel Hilger, Norbert Hosters</p></summary>
<p>

**Abstract:** In course of this work, we examine the process of plastic profile extrusion, where a polymer melt is shaped inside the so-called extrusion die and fixed in its shape by solidification in the downstream calibration unit. More precise, we focus on the development of a data-driven reduced order model (ROM) for the purpose of predicting temperature distributions within the extruded profiles inside the calibration unit. Therein, the ROM functions as a first step to our overall goal of prediction based process control in order to avoid undesired warpage and damages of the final product.

</p>
</details>

<details><summary><b>Autonomous Cooking with Digital Twin Methodology</b>
<a href="https://arxiv.org/abs/2209.03087">arxiv:2209.03087</a>
&#x1F4C8; 2 <br>
<p>Maximilian Kannapinn, Michael Schäfer</p></summary>
<p>

**Abstract:** This work introduces the concept of an autonomous cooking process based on Digital Twin method- ology. It proposes a hybrid approach of physics-based full order simulations followed by a data-driven system identification process with low errors. It makes faster-than-real-time simulations of Digital Twins feasible on a device level, without the need for cloud or high-performance computing. The concept is universally applicable to various physical processes.

</p>
</details>

<details><summary><b>On the Sparse DAG Structure Learning Based on Adaptive Lasso</b>
<a href="https://arxiv.org/abs/2209.02946">arxiv:2209.02946</a>
&#x1F4C8; 2 <br>
<p>Danru Xu, Erdun Gao, Wei Huang, Mingming Gong</p></summary>
<p>

**Abstract:** Learning the underlying casual structure, represented by Directed Acyclic Graphs (DAGs), of concerned events from fully-observational data is a crucial part of causal reasoning, but it is challenging due to the combinatorial and large search space. A recent flurry of developments recast this combinatorial problem into a continuous optimization problem by leveraging an algebraic equality characterization of acyclicity. However, these methods suffer from the fixed-threshold step after optimization, which is not a flexible and systematic way to rule out the cycle-inducing edges or false discoveries edges with small values caused by numerical precision. In this paper, we develop a data-driven DAG structure learning method without the predefined threshold, called adaptive NOTEARS [30], achieved by applying adaptive penalty levels to each parameters in the regularization term. We show that adaptive NOTEARS enjoys the oracle properties under some specific conditions. Furthermore, simulation experimental results validate the effectiveness of our method, without setting any gap of edges weights around zero.

</p>
</details>

<details><summary><b>A Novel Semi-supervised Meta Learning Method for Subject-transfer Brain-computer Interface</b>
<a href="https://arxiv.org/abs/2209.03785">arxiv:2209.03785</a>
&#x1F4C8; 1 <br>
<p>Jingcong Li, Fei Wang, Haiyun Huang, Feifei Qi, Jiahui Pan</p></summary>
<p>

**Abstract:** Brain-computer interface (BCI) provides a direct communication pathway between human brain and external devices. Before a new subject could use BCI, a calibration procedure is usually required. Because the inter- and intra-subject variances are so large that the models trained by the existing subjects perform poorly on new subjects. Therefore, effective subject-transfer and calibration method is essential. In this paper, we propose a semi-supervised meta learning (SSML) method for subject-transfer learning in BCIs. The proposed SSML learns a meta model with the existing subjects first, then fine-tunes the model in a semi-supervised learning manner, i.e. using few labeled and many unlabeled samples of target subject for calibration. It is significant for BCI applications where the labeled data are scarce or expensive while unlabeled data are readily available. To verify the SSML method, three different BCI paradigms are tested: 1) event-related potential detection; 2) emotion recognition; and 3) sleep staging. The SSML achieved significant improvements of over 15% on the first two paradigms and 4.9% on the third. The experimental results demonstrated the effectiveness and potential of the SSML method in BCI applications.

</p>
</details>

<details><summary><b>Implicit Full Waveform Inversion with Deep Neural Representation</b>
<a href="https://arxiv.org/abs/2209.03525">arxiv:2209.03525</a>
&#x1F4C8; 1 <br>
<p>Jian Sun, Kristopher Innanen</p></summary>
<p>

**Abstract:** Full waveform inversion (FWI) commonly stands for the state-of-the-art approach for imaging subsurface structures and physical parameters, however, its implementation usually faces great challenges, such as building a good initial model to escape from local minima, and evaluating the uncertainty of inversion results. In this paper, we propose the implicit full waveform inversion (IFWI) algorithm using continuously and implicitly defined deep neural representations. Compared to FWI, which is sensitive to the initial model, IFWI benefits from the increased degrees of freedom with deep learning optimization, thus allowing to start from a random initialization, which greatly reduces the risk of non-uniqueness and being trapped in local minima. Both theoretical and experimental analyses indicates that, given a random initial model, IFWI is able to converge to the global minimum and produce a high-resolution image of subsurface with fine structures. In addition, uncertainty analysis of IFWI can be easily performed by approximating Bayesian inference with various deep learning approaches, which is analyzed in this paper by adding dropout neurons. Furthermore, IFWI has a certain degree of robustness and strong generalization ability that are exemplified in the experiments of various 2D geological models. With proper setup, IFWI can also be well suited for multi-scale joint geophysical inversion.

</p>
</details>

<details><summary><b>Evaluating Temporal Patterns in Applied Infant Affect Recognition</b>
<a href="https://arxiv.org/abs/2209.03496">arxiv:2209.03496</a>
&#x1F4C8; 1 <br>
<p>Allen Chang, Lauren Klein, Marcelo R. Rosales, Weiyang Deng, Beth A. Smith, Maja J. Matarić</p></summary>
<p>

**Abstract:** Agents must monitor their partners' affective states continuously in order to understand and engage in social interactions. However, methods for evaluating affect recognition do not account for changes in classification performance that may occur during occlusions or transitions between affective states. This paper addresses temporal patterns in affect classification performance in the context of an infant-robot interaction, where infants' affective states contribute to their ability to participate in a therapeutic leg movement activity. To support robustness to facial occlusions in video recordings, we trained infant affect recognition classifiers using both facial and body features. Next, we conducted an in-depth analysis of our best-performing models to evaluate how performance changed over time as the models encountered missing data and changing infant affect. During time windows when features were extracted with high confidence, a unimodal model trained on facial features achieved the same optimal performance as multimodal models trained on both facial and body features. However, multimodal models outperformed unimodal models when evaluated on the entire dataset. Additionally, model performance was weakest when predicting an affective state transition and improved after multiple predictions of the same affective state. These findings emphasize the benefits of incorporating body features in continuous affect recognition for infants. Our work highlights the importance of evaluating variability in model performance both over time and in the presence of missing data when applying affect recognition to social interactions.

</p>
</details>

<details><summary><b>Supervised GAN Watermarking for Intellectual Property Protection</b>
<a href="https://arxiv.org/abs/2209.03466">arxiv:2209.03466</a>
&#x1F4C8; 1 <br>
<p>Jianwei Fei, Zhihua Xia, Benedetta Tondi, Mauro Barni</p></summary>
<p>

**Abstract:** We propose a watermarking method for protecting the Intellectual Property (IP) of Generative Adversarial Networks (GANs). The aim is to watermark the GAN model so that any image generated by the GAN contains an invisible watermark (signature), whose presence inside the image can be checked at a later stage for ownership verification. To achieve this goal, a pre-trained CNN watermarking decoding block is inserted at the output of the generator. The generator loss is then modified by including a watermark loss term, to ensure that the prescribed watermark can be extracted from the generated images. The watermark is embedded via fine-tuning, with reduced time complexity. Results show that our method can effectively embed an invisible watermark inside the generated images. Moreover, our method is a general one and can work with different GAN architectures, different tasks, and different resolutions of the output image. We also demonstrate the good robustness performance of the embedded watermark against several post-processing, among them, JPEG compression, noise addition, blurring, and color transformations.

</p>
</details>

<details><summary><b>Deep Learning-Based Automatic Diagnosis System for Developmental Dysplasia of the Hip</b>
<a href="https://arxiv.org/abs/2209.03440">arxiv:2209.03440</a>
&#x1F4C8; 1 <br>
<p>Yang Li, Leo Yan Li-Han, Hua Tian</p></summary>
<p>

**Abstract:** As the first-line diagnostic imaging modality, radiography plays an essential role in the early detection of developmental dysplasia of the hip (DDH). Clinically, the diagnosis of DDH relies on manual measurements and subjective evaluation of different anatomical features from pelvic radiographs. This process is inefficient and error-prone and requires years of clinical experience. In this study, we propose a deep learning-based system that automatically detects 14 keypoints from a radiograph, measures three anatomical angles (center-edge, Tönnis, and Sharp angles), and classifies DDH hips as grades I-IV based on the Crowe criteria. Moreover, a novel data-driven scoring system is proposed to quantitatively integrate the information from the three angles for DDH diagnosis. The proposed keypoint detection model achieved a mean (95% confidence interval [CI]) average precision of 0.807 (0.804-0.810). The mean (95% CI) intraclass correlation coefficients between the center-edge, Tonnis, and Sharp angles measured by the proposed model and the ground-truth were 0.957 (0.952-0.962), 0.947 (0.941-0.953), and 0.953 (0.947-0.960), respectively, which were significantly higher than those of experienced orthopedic surgeons (p<0.0001). In addition, the mean (95% CI) test diagnostic agreement (Cohen's kappa) obtained using the proposed scoring system was 0.84 (0.83-0.85), which was significantly higher than those obtained from diagnostic criteria for individual angle (0.76 [0.75-0.77]) and orthopedists (0.71 [0.63-0.79]). To the best of our knowledge, this is the first study for objective DDH diagnosis by leveraging deep learning keypoint detection and integrating different anatomical measurements, which can provide reliable and explainable support for clinical decision-making.

</p>
</details>

<details><summary><b>Causal discovery for time series with latent confounders</b>
<a href="https://arxiv.org/abs/2209.03427">arxiv:2209.03427</a>
&#x1F4C8; 1 <br>
<p>Christian Reiser</p></summary>
<p>

**Abstract:** Reconstructing the causal relationships behind the phenomena we observe is a fundamental challenge in all areas of science. Discovering causal relationships through experiments is often infeasible, unethical, or expensive in complex systems. However, increases in computational power allow us to process the ever-growing amount of data that modern science generates, leading to an emerging interest in the causal discovery problem from observational data. This work evaluates the LPCMCI algorithm, which aims to find generators compatible with a multi-dimensional, highly autocorrelated time series while some variables are unobserved. We find that LPCMCI performs much better than a random algorithm mimicking not knowing anything but is still far from optimal detection. Furthermore, LPCMCI performs best on auto-dependencies, then contemporaneous dependencies, and struggles most with lagged dependencies. The source code of this project is available online.

</p>
</details>

<details><summary><b>Using Computational Approaches in Visual Identity Design: A Visual Identity for the Design and Multimedia Courses of Faculty of Sciences and Technology of University of Coimbra</b>
<a href="https://arxiv.org/abs/2209.03420">arxiv:2209.03420</a>
&#x1F4C8; 1 <br>
<p>Sérgio M. Rebelo, Tiago Martins, Artur Rebelo, João Bicker, Penousal Machado</p></summary>
<p>

**Abstract:** Computational approaches are beginning to be used to design dynamic visual identities fuelled by data and generative processes. In this work, we explore these computational approaches in order to generate a visual identity that creates bespoke letterings and images. We achieve this developing a generative design system that automatically assembles black and white visual modules. This system generates designs performing two main methods: (i) Assisted generation; and (ii) Automatic generation. Assisted generation method produces outputs wherein the placement of modules is determined by a configuration file previous defined. On the other hand, the Automatic generation method produces outputs wherein the modules are assembled to depict an input image. This system speeds up the process of design and deployment of one visual identity design as well as it generates outputs visual coherent among them. In this paper, we compressively describe this system and its achievements.

</p>
</details>

<details><summary><b>A Survey of Neural Trees</b>
<a href="https://arxiv.org/abs/2209.03415">arxiv:2209.03415</a>
&#x1F4C8; 1 <br>
<p>Haoling Li, Jie Song, Mengqi Xue, Haofei Zhang, Jingwen Ye, Lechao Cheng, Mingli Song</p></summary>
<p>

**Abstract:** Neural networks (NNs) and decision trees (DTs) are both popular models of machine learning, yet coming with mutually exclusive advantages and limitations. To bring the best of the two worlds, a variety of approaches are proposed to integrate NNs and DTs explicitly or implicitly. In this survey, these approaches are organized in a school which we term as neural trees (NTs). This survey aims to present a comprehensive review of NTs and attempts to identify how they enhance the model interpretability. We first propose a thorough taxonomy of NTs that expresses the gradual integration and co-evolution of NNs and DTs. Afterward, we analyze NTs in terms of their interpretability and performance, and suggest possible solutions to the remaining challenges. Finally, this survey concludes with a discussion about other considerations like conditional computation and promising directions towards this field. A list of papers reviewed in this survey, along with their corresponding codes, is available at: https://github.com/zju-vipa/awesome-neural-trees

</p>
</details>

<details><summary><b>Securing the Spike: On the Transferabilty and Security of Spiking Neural Networks to Adversarial Examples</b>
<a href="https://arxiv.org/abs/2209.03358">arxiv:2209.03358</a>
&#x1F4C8; 1 <br>
<p>Nuo Xu, Kaleel Mahmood, Haowen Fang, Ethan Rathbun, Caiwen Ding, Wujie Wen</p></summary>
<p>

**Abstract:** Spiking neural networks (SNNs) have attracted much attention for their high energy efficiency and for recent advances in their classification performance. However, unlike traditional deep learning approaches, the analysis and study of the robustness of SNNs to adversarial examples remains relatively underdeveloped. In this work we advance the field of adversarial machine learning through experimentation and analyses of three important SNN security attributes. First, we show that successful white-box adversarial attacks on SNNs are highly dependent on the underlying surrogate gradient technique. Second, we analyze the transferability of adversarial examples generated by SNNs and other state-of-the-art architectures like Vision Transformers and Big Transfer CNNs. We demonstrate that SNNs are not often deceived by adversarial examples generated by Vision Transformers and certain types of CNNs. Lastly, we develop a novel white-box attack that generates adversarial examples capable of fooling both SNN models and non-SNN models simultaneously. Our experiments and analyses are broad and rigorous covering two datasets (CIFAR-10 and CIFAR-100), five different white-box attacks and twelve different classifier models.

</p>
</details>

<details><summary><b>Distilling Deep RL Models Into Interpretable Neuro-Fuzzy Systems</b>
<a href="https://arxiv.org/abs/2209.03357">arxiv:2209.03357</a>
&#x1F4C8; 1 <br>
<p>Arne Gevaert, Jonathan Peck, Yvan Saeys</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning uses a deep neural network to encode a policy, which achieves very good performance in a wide range of applications but is widely regarded as a black box model. A more interpretable alternative to deep networks is given by neuro-fuzzy controllers. Unfortunately, neuro-fuzzy controllers often need a large number of rules to solve relatively simple tasks, making them difficult to interpret. In this work, we present an algorithm to distill the policy from a deep Q-network into a compact neuro-fuzzy controller. This allows us to train compact neuro-fuzzy controllers through distillation to solve tasks that they are unable to solve directly, combining the flexibility of deep reinforcement learning and the interpretability of compact rule bases. We demonstrate the algorithm on three well-known environments from OpenAI Gym, where we nearly match the performance of a DQN agent using only 2 to 6 fuzzy rules.

</p>
</details>

<details><summary><b>AutoPruner: Transformer-Based Call Graph Pruning</b>
<a href="https://arxiv.org/abs/2209.03230">arxiv:2209.03230</a>
&#x1F4C8; 1 <br>
<p>Thanh Le-Cong, Hong Jin Kang, Truong Giang Nguyen, Stefanus Agus Haryono, David Lo, Xuan-Bach D. Le, Huynh Quyet Thang</p></summary>
<p>

**Abstract:** Constructing a static call graph requires trade-offs between soundness and precision. Program analysis techniques for constructing call graphs are unfortunately usually imprecise. To address this problem, researchers have recently proposed call graph pruning empowered by machine learning to post-process call graphs constructed by static analysis. A machine learning model is built to capture information from the call graph by extracting structural features for use in a random forest classifier. It then removes edges that are predicted to be false positives. Despite the improvements shown by machine learning models, they are still limited as they do not consider the source code semantics and thus often are not able to effectively distinguish true and false positives. In this paper, we present a novel call graph pruning technique, AutoPruner, for eliminating false positives in call graphs via both statistical semantic and structural analysis. Given a call graph constructed by traditional static analysis tools, AutoPruner takes a Transformer-based approach to capture the semantic relationships between the caller and callee functions associated with each edge in the call graph. To do so, AutoPruner fine-tunes a model of code that was pre-trained on a large corpus to represent source code based on descriptions of its semantics. Next, the model is used to extract semantic features from the functions related to each edge in the call graph. AutoPruner uses these semantic features together with the structural features extracted from the call graph to classify each edge via a feed-forward neural network. Our empirical evaluation on a benchmark dataset of real-world programs shows that AutoPruner outperforms the state-of-the-art baselines, improving on F-measure by up to 13% in identifying false-positive edges in a static call graph.

</p>
</details>

<details><summary><b>Peer to Peer Learning Platform Optimized With Machine Learning</b>
<a href="https://arxiv.org/abs/2209.03489">arxiv:2209.03489</a>
&#x1F4C8; 0 <br>
<p>Vikram Anantha</p></summary>
<p>

**Abstract:** HELM Learning (Helping Everyone Learn More) is the first online peer-to-peer learning platform which allows students (typically middle-to-high school students) to teach classes and students (typically elementary-to-middle school students) to learn from classes for free. This method of class structure (peer-to-peer learning) has been proven effective for learning, as it promotes teamwork and collaboration, and enables active learning. HELM is a unique platform as it provides an easy process for students to create, teach and learn topics in a structured, peer-to-peer environment. Since HELM was created in April 2020, it has gotten over 4000 student sign ups and 80 teachers, in 4 continents around the world. HELM has grown from a simple website-and-Google-Form platform to having a backend system coded with Python, SQL, JavaScript and HTML, hosted on an AWS service. This not only makes it easier for students to sign up (as the students' information is saved in an SQL database, meaning they can sign up for classes without having to put in their information again, as well as getting automated emails about their classes), but also makes it easier for teachers to teach (as supplemental processes such as creating Zoom links, class recording folders, sending emails to students, etc. are done automatically). In addition, HELM has a recommendation machine learning algorithm which suggests classes and subjects students would enjoy taking, based on the previous classes a student has taken. This has created an easier experience for students to sign up for classes they are interested in.

</p>
</details>

<details><summary><b>TAG: Learning Circuit Spatial Embedding From Layouts</b>
<a href="https://arxiv.org/abs/2209.03465">arxiv:2209.03465</a>
&#x1F4C8; 0 <br>
<p>Keren Zhu, Hao Chen, Walker J. Turner, George F. Kokai, Po-Hsuan Wei, David Z. Pan, Haoxing Ren</p></summary>
<p>

**Abstract:** Analog and mixed-signal (AMS) circuit designs still rely on human design expertise. Machine learning has been assisting circuit design automation by replacing human experience with artificial intelligence. This paper presents TAG, a new paradigm of learning the circuit representation from layouts leveraging text, self-attention and graph. The embedding network model learns spatial information without manual labeling. We introduce text embedding and a self-attention mechanism to AMS circuit learning. Experimental results demonstrate the ability to predict layout distances between instances with industrial FinFET technology benchmarks. The effectiveness of the circuit representation is verified by showing the transferability to three other learning tasks with limited data in the case studies: layout matching prediction, wirelength estimation, and net parasitic capacitance prediction.

</p>
</details>

<details><summary><b>A Survey on Automated Diagnosis of Alzheimer's Disease Using Optical Coherence Tomography and Angiography</b>
<a href="https://arxiv.org/abs/2209.03354">arxiv:2209.03354</a>
&#x1F4C8; 0 <br>
<p>Yasemin Turkan, F. Boray Tek</p></summary>
<p>

**Abstract:** Retinal optical coherence tomography (OCT) and optical coherence tomography angiography (OCTA) are promising tools for the (early) diagnosis of Alzheimer's disease (AD). These non-invasive imaging techniques are cost-effective and more accessible than alternative neuroimaging tools. However, interpreting and classifying multi-slice scans produced by OCT devices is time-consuming and challenging even for trained practitioners.
  There are surveys on machine learning and deep learning approaches concerning the automated analysis of OCT scans for various diseases such as glaucoma. However, the current literature lacks an extensive survey on the diagnosis of Alzheimer's disease or cognitive impairment using OCT or OCTA. This has motivated us to do a comprehensive survey aimed at machine/deep learning scientists or practitioners who require an introduction to the problem. The paper contains 1) an introduction to the medical background of Alzheimer's Disease and Cognitive Impairment and their diagnosis using OCT and OCTA imaging modalities, 2) a review of various technical proposals for the problem and the sub-problems from an automated analysis perspective, 3) a systematic review of the recent deep learning studies and available OCT/OCTA datasets directly aimed at the diagnosis of Alzheimer's Disease and Cognitive Impairment. For the latter, we used Publish or Perish Software to search for the relevant studies from various sources such as Scopus, PubMed, and Web of Science. We followed the PRISMA approach to screen an initial pool of 3073 references and determined ten relevant studies (N=10, out of 3073) that directly targeted AD diagnosis. We identified the lack of open OCT/OCTA datasets (about Alzheimer's disease) as the main issue that is impeding the progress in the field.

</p>
</details>

<details><summary><b>Learned Image Compression with Generalized Octave Convolution and Cross-Resolution Parameter Estimation</b>
<a href="https://arxiv.org/abs/2209.03353">arxiv:2209.03353</a>
&#x1F4C8; 0 <br>
<p>Haisheng Fu, Feng Liang</p></summary>
<p>

**Abstract:** The application of the context-adaptive entropy model significantly improves the rate-distortion (R-D) performance, in which hyperpriors and autoregressive models are jointly utilized to effectively capture the spatial redundancy of the latent representations. However, the latent representations still contain some spatial correlations. In addition, these methods based on the context-adaptive entropy model cannot be accelerated in the decoding process by parallel computing devices, e.g. FPGA or GPU. To alleviate these limitations, we propose a learned multi-resolution image compression framework, which exploits the recently developed octave convolutions to factorize the latent representations into the high-resolution (HR) and low-resolution (LR) parts, similar to wavelet transform, which further improves the R-D performance. To speed up the decoding, our scheme does not use context-adaptive entropy model. Instead, we exploit an additional hyper layer including hyper encoder and hyper decoder to further remove the spatial redundancy of the latent representation. Moreover, the cross-resolution parameter estimation (CRPE) is introduced into the proposed framework to enhance the flow of information and further improve the rate-distortion performance. An additional information-fidelity loss is proposed to the total loss function to adjust the contribution of the LR part to the final bit stream. Experimental results show that our method separately reduces the decoding time by approximately 73.35 % and 93.44 % compared with that of state-of-the-art learned image compression methods, and the R-D performance is still better than H.266/VVC(4:2:0) and some learning-based methods on both PSNR and MS-SSIM metrics across a wide bit rates.

</p>
</details>

<details><summary><b>DM$^2$S$^2$: Deep Multi-Modal Sequence Sets with Hierarchical Modality Attention</b>
<a href="https://arxiv.org/abs/2209.03126">arxiv:2209.03126</a>
&#x1F4C8; 0 <br>
<p>Shunsuke Kitada, Yuki Iwazaki, Riku Togashi, Hitoshi Iyatomi</p></summary>
<p>

**Abstract:** There is increasing interest in the use of multimodal data in various web applications, such as digital advertising and e-commerce. Typical methods for extracting important information from multimodal data rely on a mid-fusion architecture that combines the feature representations from multiple encoders. However, as the number of modalities increases, several potential problems with the mid-fusion model structure arise, such as an increase in the dimensionality of the concatenated multimodal features and missing modalities. To address these problems, we propose a new concept that considers multimodal inputs as a set of sequences, namely, deep multimodal sequence sets (DM$^2$S$^2$). Our set-aware concept consists of three components that capture the relationships among multiple modalities: (a) a BERT-based encoder to handle the inter- and intra-order of elements in the sequences, (b) intra-modality residual attention (IntraMRA) to capture the importance of the elements in a modality, and (c) inter-modality residual attention (InterMRA) to enhance the importance of elements with modality-level granularity further. Our concept exhibits performance that is comparable to or better than the previous set-aware models. Furthermore, we demonstrate that the visualization of the learned InterMRA and IntraMRA weights can provide an interpretation of the prediction results.

</p>
</details>


{% endraw %}
Prev: [2022.09.06]({{ '/2022/09/06/2022.09.06.html' | relative_url }})  Next: [2022.09.08]({{ '/2022/09/08/2022.09.08.html' | relative_url }})