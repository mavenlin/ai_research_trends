Prev: [2021.02.12]({{ '/2021/02/12/2021.02.12.html' | relative_url }})  Next: [2021.02.14]({{ '/2021/02/14/2021.02.14.html' | relative_url }})
{% raw %}
## Summary for 2021-02-13, created on 2021-12-24


<details><summary><b>PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them</b>
<a href="https://arxiv.org/abs/2102.07033">arxiv:2102.07033</a>
&#x1F4C8; 130 <br>
<p>Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich Küttler, Aleksandra Piktus, Pontus Stenetorp, Sebastian Riedel</p></summary>
<p>

**Abstract:** Open-domain Question Answering models which directly leverage question-answer (QA) pairs, such as closed-book QA (CBQA) models and QA-pair retrievers, show promise in terms of speed and memory compared to conventional models which retrieve and read from text corpora. QA-pair retrievers also offer interpretable answers, a high degree of control, and are trivial to update at test time with new knowledge. However, these models lack the accuracy of retrieve-and-read systems, as substantially less knowledge is covered by the available QA-pairs relative to text corpora like Wikipedia. To facilitate improved QA-pair models, we introduce Probably Asked Questions (PAQ), a very large resource of 65M automatically-generated QA-pairs. We introduce a new QA-pair retriever, RePAQ, to complement PAQ. We find that PAQ preempts and caches test questions, enabling RePAQ to match the accuracy of recent retrieve-and-read models, whilst being significantly faster. Using PAQ, we train CBQA models which outperform comparable baselines by 5%, but trail RePAQ by over 15%, indicating the effectiveness of explicit retrieval. RePAQ can be configured for size (under 500MB) or speed (over 1K questions per second) whilst retaining high accuracy. Lastly, we demonstrate RePAQ's strength at selective QA, abstaining from answering when it is likely to be incorrect. This enables RePAQ to ``back-off" to a more expensive state-of-the-art model, leading to a combined system which is both more accurate and 2x faster than the state-of-the-art model alone.

</p>
</details>

<details><summary><b>Learning Intents behind Interactions with Knowledge Graph for Recommendation</b>
<a href="https://arxiv.org/abs/2102.07057">arxiv:2102.07057</a>
&#x1F4C8; 28 <br>
<p>Xiang Wang, Tinglin Huang, Dingxian Wang, Yancheng Yuan, Zhenguang Liu, Xiangnan He, Tat-Seng Chua</p></summary>
<p>

**Abstract:** Knowledge graph (KG) plays an increasingly important role in recommender systems. A recent technical trend is to develop end-to-end models founded on graph neural networks (GNNs). However, existing GNN-based models are coarse-grained in relational modeling, failing to (1) identify user-item relation at a fine-grained level of intents, and (2) exploit relation dependencies to preserve the semantics of long-range connectivity.
  In this study, we explore intents behind a user-item interaction by using auxiliary item knowledge, and propose a new model, Knowledge Graph-based Intent Network (KGIN). Technically, we model each intent as an attentive combination of KG relations, encouraging the independence of different intents for better model capability and interpretability. Furthermore, we devise a new information aggregation scheme for GNN, which recursively integrates the relation sequences of long-range connectivity (i.e., relational paths). This scheme allows us to distill useful information about user intents and encode them into the representations of users and items. Experimental results on three benchmark datasets show that, KGIN achieves significant improvements over the state-of-the-art methods like KGAT, KGNN-LS, and CKAN. Further analyses show that KGIN offers interpretable explanations for predictions by identifying influential intents and relational paths. The implementations are available at https://github.com/huangtinglin/Knowledge_Graph_based_Intent_Network.

</p>
</details>

<details><summary><b>DeepRA: Predicting Joint Damage From Radiographs Using CNN with Attention</b>
<a href="https://arxiv.org/abs/2102.06982">arxiv:2102.06982</a>
&#x1F4C8; 28 <br>
<p>Neelambuj Chaturvedi</p></summary>
<p>

**Abstract:** Joint damage in Rheumatoid Arthritis (RA) is assessed by manually inspecting and grading radiographs of hands and feet. This is a tedious task which requires trained experts whose subjective assessment leads to low inter-rater agreement. An algorithm which can automatically predict the joint level damage in hands and feet can help optimize this process, which will eventually aid the doctors in better patient care and research. In this paper, we propose a two-staged approach which amalgamates object detection and convolution neural networks with attention which can efficiently and accurately predict the overall and joint level narrowing and erosion from patients radiographs. This approach has been evaluated on hands and feet radiographs of patients suffering from RA and has achieved a weighted root mean squared error (RMSE) of 1.358 and 1.404 in predicting joint level narrowing and erosion Sharp van der Heijde (SvH) scores which is 31% and 19% improvement with respect to the baseline SvH scores, respectively. The proposed approach achieved a weighted absolute error of 1.456 in predicting the overall damage in hands and feet radiographs for the patients which is a 79% improvement as compared to the baseline. Our method also provides an inherent capability to provide explanations for model predictions using attention weights, which is essential given the black box nature of deep learning models. The proposed approach was developed during the RA2 Dream Challenge hosted by Dream Challenges and secured 4th and 8th position in predicting overall and joint level narrowing and erosion SvH scores from radiographs.

</p>
</details>

<details><summary><b>Online Apprenticeship Learning</b>
<a href="https://arxiv.org/abs/2102.06924">arxiv:2102.06924</a>
&#x1F4C8; 28 <br>
<p>Lior Shani, Tom Zahavy, Shie Mannor</p></summary>
<p>

**Abstract:** In Apprenticeship Learning (AL), we are given a Markov Decision Process (MDP) without access to the cost function. Instead, we observe trajectories sampled by an expert that acts according to some policy. The goal is to find a policy that matches the expert's performance on some predefined set of cost functions. We introduce an online variant of AL (Online Apprenticeship Learning; OAL), where the agent is expected to perform comparably to the expert while interacting with the environment. We show that the OAL problem can be effectively solved by combining two mirror descent based no-regret algorithms: one for policy optimization and another for learning the worst case cost. To this end, we derive a convergent algorithm with $O(\sqrt{K})$ regret, where $K$ is the number of interactions with the MDP, and an additional linear error term that depends on the amount of expert trajectories available. Importantly, our algorithm avoids the need to solve an MDP at each iteration, making it more practical compared to prior AL methods. Finally, we implement a deep variant of our algorithm which shares some similarities to GAIL \cite{ho2016generative}, but where the discriminator is replaced with the costs learned by the OAL problem. Our simulations demonstrate our theoretically grounded approach outperforms the baselines.

</p>
</details>

<details><summary><b>Improving Automated Visual Fault Detection by Combining a Biologically Plausible Model of Visual Attention with Deep Learning</b>
<a href="https://arxiv.org/abs/2102.06955">arxiv:2102.06955</a>
&#x1F4C8; 27 <br>
<p>Frederik Beuth, Tobias Schlosser, Michael Friedrich, Danny Kowerko</p></summary>
<p>

**Abstract:** It is a long-term goal to transfer biological processing principles as well as the power of human recognition into machine vision and engineering systems. One of such principles is visual attention, a smart human concept which focuses processing on a part of a scene. In this contribution, we utilize attention to improve the automatic detection of defect patterns for wafers within the domain of semiconductor manufacturing. Previous works in the domain have often utilized classical machine learning approaches such as KNNs, SVMs, or MLPs, while a few have already used modern approaches like deep neural networks (DNNs). However, one problem in the domain is that the faults are often very small and have to be detected within a larger size of the chip or even the wafer. Therefore, small structures in the size of pixels have to be detected in a vast amount of image data. One interesting principle of the human brain for solving this problem is visual attention. Hence, we employ here a biologically plausible model of visual attention for automatic visual inspection. We propose a hybrid system of visual attention and a deep neural network. As demonstrated, our system achieves among other decisive advantages an improvement in accuracy from 81% to 92%, and an increase in accuracy for detecting faults from 67% to 88%. Hence, the error rates are reduced from 19% to 8%, and notably from 33% to 12% for detecting a fault in a chip. These results show that attention can greatly improve the performance of visual inspection systems. Furthermore, we conduct a broad evaluation, identifying specific advantages of the biological attention model in this application, and benchmarks standard deep learning approaches as an alternative with and without attention.
  This work is an extended arXiv version of the original conference article published in "IECON 2020", which has been extended regarding visual attention.

</p>
</details>

<details><summary><b>Multi-class Generative Adversarial Nets for Semi-supervised Image Classification</b>
<a href="https://arxiv.org/abs/2102.06944">arxiv:2102.06944</a>
&#x1F4C8; 27 <br>
<p>Saman Motamed, Farzad Khalvati</p></summary>
<p>

**Abstract:** From generating never-before-seen images to domain adaptation, applications of Generative Adversarial Networks (GANs) spread wide in the domain of vision and graphics problems. With the remarkable ability of GANs in learning the distribution and generating images of a particular class, they can be used for semi-supervised classification tasks. However, the problem is that if two classes of images share similar characteristics, the GAN might learn to generalize and hinder the classification of the two classes. In this paper, we use various images from MNIST and Fashion-MNIST datasets to illustrate how similar images cause the GAN to generalize, leading to the poor classification of images. We propose a modification to the traditional training of GANs that allows for improved multi-class classification in similar classes of images in a semi-supervised learning framework.

</p>
</details>

<details><summary><b>Wasserstein Proximal of GANs</b>
<a href="https://arxiv.org/abs/2102.06862">arxiv:2102.06862</a>
&#x1F4C8; 27 <br>
<p>Alex Tong Lin, Wuchen Li, Stanley Osher, Guido Montufar</p></summary>
<p>

**Abstract:** We introduce a new method for training generative adversarial networks by applying the Wasserstein-2 metric proximal on the generators. The approach is based on Wasserstein information geometry. It defines a parametrization invariant natural gradient by pulling back optimal transport structures from probability space to parameter space. We obtain easy-to-implement iterative regularizers for the parameter updates of implicit deep generative models. Our experiments demonstrate that this method improves the speed and stability of training in terms of wall-clock time and Fréchet Inception Distance.

</p>
</details>

<details><summary><b>CrossLight: A Cross-Layer Optimized Silicon Photonic Neural Network Accelerator</b>
<a href="https://arxiv.org/abs/2102.06960">arxiv:2102.06960</a>
&#x1F4C8; 26 <br>
<p>Febin Sunny, Asif Mirza, Mahdi Nikdast, Sudeep Pasricha</p></summary>
<p>

**Abstract:** Domain-specific neural network accelerators have seen growing interest in recent years due to their improved energy efficiency and inference performance compared to CPUs and GPUs. In this paper, we propose a novel cross-layer optimized neural network accelerator called CrossLight that leverages silicon photonics. CrossLight includes device-level engineering for resilience to process variations and thermal crosstalk, circuit-level tuning enhancements for inference latency reduction, and architecture-level optimization to enable higher resolution, better energy-efficiency, and improved throughput. On average, CrossLight offers 9.5x lower energy-per-bit and 15.9x higher performance-per-watt at 16-bit resolution than state-of-the-art photonic deep learning accelerators.

</p>
</details>

<details><summary><b>Self-Reorganizing and Rejuvenating CNNs for Increasing Model Capacity Utilization</b>
<a href="https://arxiv.org/abs/2102.06870">arxiv:2102.06870</a>
&#x1F4C8; 26 <br>
<p>Wissam J. Baddar, Seungju Han, Seonmin Rhee, Jae-Joon Han</p></summary>
<p>

**Abstract:** In this paper, we propose self-reorganizing and rejuvenating convolutional neural networks; a biologically inspired method for improving the computational resource utilization of neural networks. The proposed method utilizes the channel activations of a convolution layer in order to reorganize that layers parameters. The reorganized parameters are clustered to avoid parameter redundancies. As such, redundant neurons with similar activations are merged leaving room for the remaining parameters to rejuvenate. The rejuvenated parameters learn different features to supplement those learned by the reorganized surviving parameters. As a result, the network capacity utilization increases improving the baseline network performance without any changes to the network structure. The proposed method can be applied to various network architectures during the training stage, or applied to a pre-trained model improving its performance. Experimental results showed that the proposed method is model-agnostic and can be applied to any backbone architecture increasing its performance due to the elevated utilization of the network capacity.

</p>
</details>

<details><summary><b>Fusion of convolution neural network, support vector machine and Sobel filter for accurate detection of COVID-19 patients using X-ray images</b>
<a href="https://arxiv.org/abs/2102.06883">arxiv:2102.06883</a>
&#x1F4C8; 20 <br>
<p>Danial Sharifrazi, Roohallah Alizadehsani, Mohamad Roshanzamir, Javad Hassannataj Joloudari, Afshin Shoeibi, Mahboobeh Jafari, Sadiq Hussain, Zahra Alizadeh Sani, Fereshteh Hasanzadeh, Fahime Khozeimeh, Abbas Khosravi, Saeid Nahavandi, Maryam Panahiazar, Assef Zare, Sheikh Mohammed Shariful Islam, U Rajendra Acharya</p></summary>
<p>

**Abstract:** The coronavirus (COVID-19) is currently the most common contagious disease which is prevalent all over the world. The main challenge of this disease is the primary diagnosis to prevent secondary infections and its spread from one person to another. Therefore, it is essential to use an automatic diagnosis system along with clinical procedures for the rapid diagnosis of COVID-19 to prevent its spread. Artificial intelligence techniques using computed tomography (CT) images of the lungs and chest radiography have the potential to obtain high diagnostic performance for Covid-19 diagnosis. In this study, a fusion of convolutional neural network (CNN), support vector machine (SVM), and Sobel filter is proposed to detect COVID-19 using X-ray images. A new X-ray image dataset was collected and subjected to high pass filter using a Sobel filter to obtain the edges of the images. Then these images are fed to CNN deep learning model followed by SVM classifier with ten-fold cross validation strategy. This method is designed so that it can learn with not many data. Our results show that the proposed CNN-SVM with Sobel filtering (CNN-SVM+Sobel) achieved the highest classification accuracy of 99.02% in accurate detection of COVID-19. It showed that using Sobel filter can improve the performance of CNN. Unlike most of the other researches, this method does not use a pre-trained network. We have also validated our developed model using six public databases and obtained the highest performance. Hence, our developed model is ready for clinical application

</p>
</details>

<details><summary><b>Interactive Learning from Activity Description</b>
<a href="https://arxiv.org/abs/2102.07024">arxiv:2102.07024</a>
&#x1F4C8; 14 <br>
<p>Khanh Nguyen, Dipendra Misra, Robert Schapire, Miro Dudík, Patrick Shafto</p></summary>
<p>

**Abstract:** We present a novel interactive learning protocol that enables training request-fulfilling agents by verbally describing their activities. Unlike imitation learning (IL), our protocol allows the teaching agent to provide feedback in a language that is most appropriate for them. Compared with reward in reinforcement learning (RL), the description feedback is richer and allows for improved sample complexity. We develop a probabilistic framework and an algorithm that practically implements our protocol. Empirical results in two challenging request-fulfilling problems demonstrate the strengths of our approach: compared with RL baselines, it is more sample-efficient; compared with IL baselines, it achieves competitive success rates without requiring the teaching agent to be able to demonstrate the desired behavior using the learning agent's actions. Apart from empirical evaluation, we also provide theoretical guarantees for our algorithm under certain assumptions about the teacher and the environment.

</p>
</details>

<details><summary><b>Graph Convolution for Semi-Supervised Classification: Improved Linear Separability and Out-of-Distribution Generalization</b>
<a href="https://arxiv.org/abs/2102.06966">arxiv:2102.06966</a>
&#x1F4C8; 13 <br>
<p>Aseem Baranwal, Kimon Fountoulakis, Aukosh Jagannath</p></summary>
<p>

**Abstract:** Recently there has been increased interest in semi-supervised classification in the presence of graphical information. A new class of learning models has emerged that relies, at its most basic level, on classifying the data after first applying a graph convolution. To understand the merits of this approach, we study the classification of a mixture of Gaussians, where the data corresponds to the node attributes of a stochastic block model. We show that graph convolution extends the regime in which the data is linearly separable by a factor of roughly $1/\sqrt{D}$, where $D$ is the expected degree of a node, as compared to the mixture model data on its own. Furthermore, we find that the linear classifier obtained by minimizing the cross-entropy loss after the graph convolution generalizes to out-of-distribution data where the unseen data can have different intra- and inter-class edge probabilities from the training data.

</p>
</details>

<details><summary><b>Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning</b>
<a href="https://arxiv.org/abs/2102.06866">arxiv:2102.06866</a>
&#x1F4C8; 11 <br>
<p>Kento Nozawa, Issei Sato</p></summary>
<p>

**Abstract:** Instance discriminative self-supervised representation learning has been attracted attention thanks to its unsupervised nature and informative feature representation for downstream tasks. In practice, it commonly uses a larger number of negative samples than the number of supervised classes. However, there is an inconsistency in the existing analysis; theoretically, a large number of negative samples degrade classification performance on a downstream supervised task, while empirically, they improve the performance. We provide a novel framework to analyze this empirical result regarding negative samples using the coupon collector's problem. Our bound can implicitly incorporate the supervised loss of the downstream task in the self-supervised loss by increasing the number of negative samples. We confirm that our proposed analysis holds on real-world benchmark datasets.

</p>
</details>

<details><summary><b>On Technical Trading and Social Media Indicators in Cryptocurrencies' Price Classification Through Deep Learning</b>
<a href="https://arxiv.org/abs/2102.08189">arxiv:2102.08189</a>
&#x1F4C8; 9 <br>
<p>Marco Ortu, Nicola Uras, Claudio Conversano, Giuseppe Destefanis, Silvia Bartolucci</p></summary>
<p>

**Abstract:** This work aims to analyse the predictability of price movements of cryptocurrencies on both hourly and daily data observed from January 2017 to January 2021, using deep learning algorithms. For our experiments, we used three sets of features: technical, trading and social media indicators, considering a restricted model of only technical indicators and an unrestricted model with technical, trading and social media indicators. We verified whether the consideration of trading and social media indicators, along with the classic technical variables (such as price's returns), leads to a significative improvement in the prediction of cryptocurrencies price's changes. We conducted the study on the two highest cryptocurrencies in volume and value (at the time of the study): Bitcoin and Ethereum. We implemented four different machine learning algorithms typically used in time-series classification problems: Multi Layers Perceptron (MLP), Convolutional Neural Network (CNN), Long Short Term Memory (LSTM) neural network and Attention Long Short Term Memory (ALSTM). We devised the experiments using the advanced bootstrap technique to consider the variance problem on test samples, which allowed us to evaluate a more reliable estimate of the model's performance. Furthermore, the Grid Search technique was used to find the best hyperparameters values for each implemented algorithm. The study shows that, based on the hourly frequency results, the unrestricted model outperforms the restricted one. The addition of the trading indicators to the classic technical indicators improves the accuracy of Bitcoin and Ethereum price's changes prediction, with an increase of accuracy from a range of 51-55% for the restricted model, to 67-84% for the unrestricted model.

</p>
</details>

<details><summary><b>Deep Convolutional and Recurrent Networks for Polyphonic Instrument Classification from Monophonic Raw Audio Waveforms</b>
<a href="https://arxiv.org/abs/2102.06930">arxiv:2102.06930</a>
&#x1F4C8; 9 <br>
<p>Kleanthis Avramidis, Agelos Kratimenos, Christos Garoufis, Athanasia Zlatintsi, Petros Maragos</p></summary>
<p>

**Abstract:** Sound Event Detection and Audio Classification tasks are traditionally addressed through time-frequency representations of audio signals such as spectrograms. However, the emergence of deep neural networks as efficient feature extractors has enabled the direct use of audio signals for classification purposes. In this paper, we attempt to recognize musical instruments in polyphonic audio by only feeding their raw waveforms into deep learning models. Various recurrent and convolutional architectures incorporating residual connections are examined and parameterized in order to build end-to-end classi-fiers with low computational cost and only minimal preprocessing. We obtain competitive classification scores and useful instrument-wise insight through the IRMAS test set, utilizing a parallel CNN-BiGRU model with multiple residual connections, while maintaining a significantly reduced number of trainable parameters.

</p>
</details>

<details><summary><b>Saliency-Aware Class-Agnostic Food Image Segmentation</b>
<a href="https://arxiv.org/abs/2102.06882">arxiv:2102.06882</a>
&#x1F4C8; 9 <br>
<p>Sri Kalyan Yarlagadda, Daniel Mas Montserrat, David Guerra, Carol J. Boushey, Deborah A. Kerr, Fengqing Zhu</p></summary>
<p>

**Abstract:** Advances in image-based dietary assessment methods have allowed nutrition professionals and researchers to improve the accuracy of dietary assessment, where images of food consumed are captured using smartphones or wearable devices. These images are then analyzed using computer vision methods to estimate energy and nutrition content of the foods. Food image segmentation, which determines the regions in an image where foods are located, plays an important role in this process. Current methods are data dependent, thus cannot generalize well for different food types. To address this problem, we propose a class-agnostic food image segmentation method. Our method uses a pair of eating scene images, one before start eating and one after eating is completed. Using information from both the before and after eating images, we can segment food images by finding the salient missing objects without any prior information about the food class. We model a paradigm of top down saliency which guides the attention of the human visual system (HVS) based on a task to find the salient missing objects in a pair of images. Our method is validated on food images collected from a dietary study which showed promising results.

</p>
</details>

<details><summary><b>Query-by-Example Keyword Spotting system using Multi-head Attention and Softtriple Loss</b>
<a href="https://arxiv.org/abs/2102.07061">arxiv:2102.07061</a>
&#x1F4C8; 8 <br>
<p>Jinmiao Huang, Waseem Gharbieh, Han Suk Shim, Eugene Kim</p></summary>
<p>

**Abstract:** This paper proposes a neural network architecture for tackling the query-by-example user-defined keyword spotting task. A multi-head attention module is added on top of a multi-layered GRU for effective feature extraction, and a normalized multi-head attention module is proposed for feature aggregation. We also adopt the softtriple loss - a combination of triplet loss and softmax loss - and showcase its effectiveness. We demonstrate the performance of our model on internal datasets with different languages and the public Hey-Snips dataset. We compare the performance of our model to a baseline system and conduct an ablation study to show the benefit of each component in our architecture. The proposed work shows solid performance while preserving simplicity.

</p>
</details>

<details><summary><b>Adversarial defense for automatic speaker verification by cascaded self-supervised learning models</b>
<a href="https://arxiv.org/abs/2102.07047">arxiv:2102.07047</a>
&#x1F4C8; 8 <br>
<p>Haibin Wu, Xu Li, Andy T. Liu, Zhiyong Wu, Helen Meng, Hung-yi Lee</p></summary>
<p>

**Abstract:** Automatic speaker verification (ASV) is one of the core technologies in biometric identification. With the ubiquitous usage of ASV systems in safety-critical applications, more and more malicious attackers attempt to launch adversarial attacks at ASV systems. In the midst of the arms race between attack and defense in ASV, how to effectively improve the robustness of ASV against adversarial attacks remains an open question. We note that the self-supervised learning models possess the ability to mitigate superficial perturbations in the input after pretraining. Hence, with the goal of effective defense in ASV against adversarial attacks, we propose a standard and attack-agnostic method based on cascaded self-supervised learning models to purify the adversarial perturbations. Experimental results demonstrate that the proposed method achieves effective defense performance and can successfully counter adversarial attacks in scenarios where attackers may either be aware or unaware of the self-supervised learning models.

</p>
</details>

<details><summary><b>How Framelets Enhance Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2102.06986">arxiv:2102.06986</a>
&#x1F4C8; 8 <br>
<p>Xuebin Zheng, Bingxin Zhou, Junbin Gao, Yu Guang Wang, Pietro Lio, Ming Li, Guido Montufar</p></summary>
<p>

**Abstract:** This paper presents a new approach for assembling graph neural networks based on framelet transforms. The latter provides a multi-scale representation for graph-structured data. We decompose an input graph into low-pass and high-pass frequencies coefficients for network training, which then defines a framelet-based graph convolution. The framelet decomposition naturally induces a graph pooling strategy by aggregating the graph feature into low-pass and high-pass spectra, which considers both the feature values and geometry of the graph data and conserves the total information. The graph neural networks with the proposed framelet convolution and pooling achieve state-of-the-art performance in many node and graph prediction tasks. Moreover, we propose shrinkage as a new activation for the framelet convolution, which thresholds high-frequency information at different scales. Compared to ReLU, shrinkage activation improves model performance on denoising and signal compression: noises in both node and structure can be significantly reduced by accurately cutting off the high-pass coefficients from framelet decomposition, and the signal can be compressed to less than half its original size with well-preserved prediction performance.

</p>
</details>

<details><summary><b>Efficient Deviation Types and Learning for Hindsight Rationality in Extensive-Form Games</b>
<a href="https://arxiv.org/abs/2102.06973">arxiv:2102.06973</a>
&#x1F4C8; 8 <br>
<p>Dustin Morrill, Ryan D'Orazio, Marc Lanctot, James R. Wright, Michael Bowling, Amy Greenwald</p></summary>
<p>

**Abstract:** Hindsight rationality is an approach to playing general-sum games that prescribes no-regret learning dynamics for individual agents with respect to a set of deviations, and further describes jointly rational behavior among multiple agents with mediated equilibria. To develop hindsight rational learning in sequential decision-making settings, we formalize behavioral deviations as a general class of deviations that respect the structure of extensive-form games. Integrating the idea of time selection into counterfactual regret minimization (CFR), we introduce the extensive-form regret minimization (EFR) algorithm that achieves hindsight rationality for any given set of behavioral deviations with computation that scales closely with the complexity of the set. We identify behavioral deviation subsets, the partial sequence deviation types, that subsume previously studied types and lead to efficient EFR instances in games with moderate lengths. In addition, we present a thorough empirical analysis of EFR instantiated with different deviation types in benchmark games, where we find that stronger types typically induce better performance.

</p>
</details>

<details><summary><b>Model-free Representation Learning and Exploration in Low-rank MDPs</b>
<a href="https://arxiv.org/abs/2102.07035">arxiv:2102.07035</a>
&#x1F4C8; 7 <br>
<p>Aditya Modi, Jinglin Chen, Akshay Krishnamurthy, Nan Jiang, Alekh Agarwal</p></summary>
<p>

**Abstract:** The low rank MDP has emerged as an important model for studying representation learning and exploration in reinforcement learning. With a known representation, several model-free exploration strategies exist. In contrast, all algorithms for the unknown representation setting are model-based, thereby requiring the ability to model the full dynamics. In this work, we present the first model-free representation learning algorithms for low rank MDPs. The key algorithmic contribution is a new minimax representation learning objective, for which we provide variants with differing tradeoffs in their statistical and computational properties. We interleave this representation learning step with an exploration strategy to cover the state space in a reward-free manner. The resulting algorithms are provably sample efficient and can accommodate general function approximation to scale to complex environments.

</p>
</details>

<details><summary><b>Reasoning Over Virtual Knowledge Bases With Open Predicate Relations</b>
<a href="https://arxiv.org/abs/2102.07043">arxiv:2102.07043</a>
&#x1F4C8; 6 <br>
<p>Haitian Sun, Pat Verga, Bhuwan Dhingra, Ruslan Salakhutdinov, William W. Cohen</p></summary>
<p>

**Abstract:** We present the Open Predicate Query Language (OPQL); a method for constructing a virtual KB (VKB) trained entirely from text. Large Knowledge Bases (KBs) are indispensable for a wide-range of industry applications such as question answering and recommendation. Typically, KBs encode world knowledge in a structured, readily accessible form derived from laborious human annotation efforts. Unfortunately, while they are extremely high precision, KBs are inevitably highly incomplete and automated methods for enriching them are far too inaccurate. Instead, OPQL constructs a VKB by encoding and indexing a set of relation mentions in a way that naturally enables reasoning and can be trained without any structured supervision. We demonstrate that OPQL outperforms prior VKB methods on two different KB reasoning tasks and, additionally, can be used as an external memory integrated into a language model (OPQL-LM) leading to improvements on two open-domain question answering tasks.

</p>
</details>

<details><summary><b>Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections</b>
<a href="https://arxiv.org/abs/2102.07006">arxiv:2102.07006</a>
&#x1F4C8; 6 <br>
<p>Alexander Camuto, Xiaoyu Wang, Lingjiong Zhu, Chris Holmes, Mert Gürbüzbalaban, Umut Şimşekli</p></summary>
<p>

**Abstract:** Gaussian noise injections (GNIs) are a family of simple and widely-used regularisation methods for training neural networks, where one injects additive or multiplicative Gaussian noise to the network activations at every iteration of the optimisation algorithm, which is typically chosen as stochastic gradient descent (SGD). In this paper we focus on the so-called `implicit effect' of GNIs, which is the effect of the injected noise on the dynamics of SGD. We show that this effect induces an asymmetric heavy-tailed noise on SGD gradient updates. In order to model this modified dynamics, we first develop a Langevin-like stochastic differential equation that is driven by a general family of asymmetric heavy-tailed noise. Using this model we then formally prove that GNIs induce an `implicit bias', which varies depending on the heaviness of the tails and the level of asymmetry. Our empirical results confirm that different types of neural networks trained with GNIs are well-modelled by the proposed dynamics and that the implicit effect of these injections induces a bias that degrades the performance of networks.

</p>
</details>

<details><summary><b>Connecting Interpretability and Robustness in Decision Trees through Separation</b>
<a href="https://arxiv.org/abs/2102.07048">arxiv:2102.07048</a>
&#x1F4C8; 5 <br>
<p>Michal Moshkovitz, Yao-Yuan Yang, Kamalika Chaudhuri</p></summary>
<p>

**Abstract:** Recent research has recognized interpretability and robustness as essential properties of trustworthy classification. Curiously, a connection between robustness and interpretability was empirically observed, but the theoretical reasoning behind it remained elusive. In this paper, we rigorously investigate this connection. Specifically, we focus on interpretation using decision trees and robustness to $l_{\infty}$-perturbation. Previous works defined the notion of $r$-separation as a sufficient condition for robustness. We prove upper and lower bounds on the tree size in case the data is $r$-separated. We then show that a tighter bound on the size is possible when the data is linearly separated. We provide the first algorithm with provable guarantees both on robustness, interpretability, and accuracy in the context of decision trees. Experiments confirm that our algorithm yields classifiers that are both interpretable and robust and have high accuracy. The code for the experiments is available at https://github.com/yangarbiter/interpretable-robust-trees .

</p>
</details>

<details><summary><b>Achieving Efficiency in Black Box Simulation of Distribution Tails with Self-structuring Importance Samplers</b>
<a href="https://arxiv.org/abs/2102.07060">arxiv:2102.07060</a>
&#x1F4C8; 4 <br>
<p>Anand Deo, Karthyek Murthy</p></summary>
<p>

**Abstract:** Motivated by the increasing adoption of models which facilitate greater automation in risk management and decision-making, this paper presents a novel Importance Sampling (IS) scheme for measuring distribution tails of objectives modelled with enabling tools such as feature-based decision rules, mixed integer linear programs, deep neural networks, etc. Conventional efficient IS approaches suffer from feasibility and scalability concerns due to the need to intricately tailor the sampler to the underlying probability distribution and the objective. This challenge is overcome in the proposed black-box scheme by automating the selection of an effective IS distribution with a transformation that implicitly learns and replicates the concentration properties observed in less rare samples. This novel approach is guided by a large deviations principle that brings out the phenomenon of self-similarity of optimal IS distributions. The proposed sampler is the first to attain asymptotically optimal variance reduction across a spectrum of multivariate distributions despite being oblivious to the underlying structure. The large deviations principle additionally results in new distribution tail asymptotics capable of yielding operational insights. The applicability is illustrated by considering product distribution networks and portfolio credit risk models informed by neural networks as examples.

</p>
</details>

<details><summary><b>Diffusion Approximations for a Class of Sequential Testing Problems</b>
<a href="https://arxiv.org/abs/2102.07030">arxiv:2102.07030</a>
&#x1F4C8; 3 <br>
<p>Victor F. Araman, Rene Caldentey</p></summary>
<p>

**Abstract:** We consider a decision maker who must choose an action in order to maximize a reward function that depends also on an unknown parameter Θ. The decision maker can delay taking the action in order to experiment and gather additional information on Θ. We model the decision maker's problem using a Bayesian sequential experimentation framework and use dynamic programming and diffusion-asymptotic analysis to solve it. For that, we scale our problem in a way that both the average number of experiments that is conducted per unit of time is large and the informativeness of each individual experiment is low. Under such regime, we derive a diffusion approximation for the sequential experimentation problem, which provides a number of important insights about the nature of the problem and its solution. Our solution method also shows that the complexity of the problem grows only quadratically with the cardinality of the set of actions from which the decision maker can choose. We illustrate our methodology and results using a concrete application in the context of assortment selection and new product introduction. Specifically, we study the problem of a seller who wants to select an optimal assortment of products to launch into the marketplace and is uncertain about consumers' preferences. Motivated by emerging practices in e-commerce, we assume that the seller is able to use a crowdvoting system to learn these preferences before a final assortment decision is made. In this context, we undertake an extensive numerical analysis to assess the value of learning and demonstrate the effectiveness and robustness of the heuristics derived from the diffusion approximation.

</p>
</details>

<details><summary><b>On the Last Iterate Convergence of Momentum Methods</b>
<a href="https://arxiv.org/abs/2102.07002">arxiv:2102.07002</a>
&#x1F4C8; 3 <br>
<p>Xiaoyu Li, Mingrui Liu, Francesco Orabona</p></summary>
<p>

**Abstract:** SGD with Momentum (SGDM) is widely used for large scale optimization of machine learning problems. Yet, the theoretical understanding of this algorithm is not complete. In fact, even the most recent results require changes to the algorithm like an averaging scheme and a projection onto a bounded domain, which are never used in practice. Also, no lower bound is known for SGDM. In this paper, we prove for the first time that for any constant momentum factor, there exists a Lipschitz and convex function for which the last iterate of SGDM suffers from an error $Ω(\frac{\log T}{\sqrt{T}})$ after $T$ steps. Based on this fact, we study a new class of (both adaptive and non-adaptive) Follow-The-Regularized-Leader-based SGDM algorithms with \emph{increasing momentum} and \emph{shrinking updates}. For these algorithms, we show that the last iterate has optimal convergence $O (\frac{1}{\sqrt{T}})$ for unconstrained convex optimization problems. Further, we show that in the interpolation setting with convex and smooth functions, our new SGDM algorithm automatically converges at a rate of $O(\frac{\log T}{T})$. Empirical results are shown as well.

</p>
</details>

<details><summary><b>Learning low-rank latent mesoscale structures in networks</b>
<a href="https://arxiv.org/abs/2102.06984">arxiv:2102.06984</a>
&#x1F4C8; 3 <br>
<p>Hanbaek Lyu, Yacoub H. Kureh, Joshua Vendrow, Mason A. Porter</p></summary>
<p>

**Abstract:** It is common to use networks to encode the architecture of interactions between entities in complex systems in the physical, biological, social, and information sciences. Moreover, to study the large-scale behavior of complex systems, it is important to study mesoscale structures in networks as building blocks that influence such behavior. In this paper, we present a new approach for describing low-rank mesoscale structure in networks, and we illustrate our approach using several synthetic network models and empirical friendship, collaboration, and protein--protein interaction (PPI) networks. We find that these networks possess a relatively small number of `latent motifs' that together can successfully approximate most subnetworks at a fixed mesoscale. We use an algorithm that we call "network dictionary learning" (NDL), which combines a network sampling method and nonnegative matrix factorization, to learn the latent motifs of a given network. The ability to encode a network using a set of latent motifs has a wide range of applications to network-analysis tasks, such as comparison, denoising, and edge inference. Additionally, using our new network denoising and reconstruction (NDR) algorithm, we demonstrate how to denoise a corrupted network by using only the latent motifs that one learns directly from the corrupted networks.

</p>
</details>

<details><summary><b>Revisiting Smoothed Online Learning</b>
<a href="https://arxiv.org/abs/2102.06933">arxiv:2102.06933</a>
&#x1F4C8; 3 <br>
<p>Lijun Zhang, Wei Jiang, Shiyin Lu, Tianbao Yang</p></summary>
<p>

**Abstract:** In this paper, we revisit the problem of smoothed online learning, in which the online learner suffers both a hitting cost and a switching cost, and target two performance metrics: competitive ratio and dynamic regret with switching cost.
  To bound the competitive ratio, we assume the hitting cost is known to the learner in each round, and investigate the simple idea of balancing the two costs by an optimization problem. Surprisingly, we find that minimizing the hitting cost alone is $\max(1, \frac{2}α)$-competitive for $α$-polyhedral functions and $1 + \frac{4}λ$-competitive for $λ$-quadratic growth functions, both of which improve state-of-the-art results significantly. Moreover, when the hitting cost is both convex and $λ$-quadratic growth, we reduce the competitive ratio to $1 + \frac{2}{\sqrtλ}$ by minimizing the weighted sum of the hitting cost and the switching cost.
  To bound the dynamic regret with switching cost, we follow the standard setting of online convex optimization, in which the hitting cost is convex but hidden from the learner before making predictions. We modify Ader, an existing algorithm designed for dynamic regret, slightly to take into account the switching cost when measuring the performance. The proposed algorithm, named as Smoothed Ader, attains an optimal $O(\sqrt{T(1+P_T)})$ bound for dynamic regret with switching cost, where $P_T$ is the path-length of the comparator sequence. Furthermore, if the hitting cost is accessible in the beginning of each round, we obtain a similar guarantee without the bounded gradient condition, and establish an $Ω(\sqrt{T(1+P_T)})$ lower bound to confirm the optimality.

</p>
</details>

<details><summary><b>Improved Corruption Robust Algorithms for Episodic Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.06875">arxiv:2102.06875</a>
&#x1F4C8; 3 <br>
<p>Yifang Chen, Simon S. Du, Kevin Jamieson</p></summary>
<p>

**Abstract:** We study episodic reinforcement learning under unknown adversarial corruptions in both the rewards and the transition probabilities of the underlying system. We propose new algorithms which, compared to the existing results in (Lykouris et al., 2020), achieve strictly better regret bounds in terms of total corruptions for the tabular setting. To be specific, firstly, our regret bounds depend on more precise numerical values of total rewards corruptions and transition corruptions, instead of only on the total number of corrupted episodes. Secondly, our regret bounds are the first of their kind in the reinforcement learning setting to have the number of corruptions show up additively with respect to $\min\{\sqrt{T}, \text{PolicyGapComplexity}\}$ rather than multiplicatively. Our results follow from a general algorithmic framework that combines corruption-robust policy elimination meta-algorithms, and plug-in reward-free exploration sub-algorithms. Replacing the meta-algorithm or sub-algorithm may extend the framework to address other corrupted settings with potentially more structure.

</p>
</details>

<details><summary><b>Weight Initialization Techniques for Deep Learning Algorithms in Remote Sensing: Recent Trends and Future Perspectives</b>
<a href="https://arxiv.org/abs/2102.07004">arxiv:2102.07004</a>
&#x1F4C8; 2 <br>
<p>Wadii Boulila, Maha Driss, Mohamed Al-Sarem, Faisal Saeed, Moez Krichen</p></summary>
<p>

**Abstract:** During the last decade, several research works have focused on providing novel deep learning methods in many application fields. However, few of them have investigated the weight initialization process for deep learning, although its importance is revealed in improving deep learning performance. This can be justified by the technical difficulties in proposing new techniques for this promising research field. In this paper, a survey related to weight initialization techniques for deep algorithms in remote sensing is conducted. This survey will help practitioners to drive further research in this promising field. To the best of our knowledge, this paper constitutes the first survey focusing on weight initialization for deep learning models.

</p>
</details>

<details><summary><b>Rotation-Equivariant Deep Learning for Diffusion MRI</b>
<a href="https://arxiv.org/abs/2102.06942">arxiv:2102.06942</a>
&#x1F4C8; 2 <br>
<p>Philip Müller, Vladimir Golkov, Valentina Tomassini, Daniel Cremers</p></summary>
<p>

**Abstract:** Convolutional networks are successful, but they have recently been outperformed by new neural networks that are equivariant under rotations and translations. These new networks work better because they do not struggle with learning each possible orientation of each image feature separately. So far, they have been proposed for 2D and 3D data. Here we generalize them to 6D diffusion MRI data, ensuring joint equivariance under 3D roto-translations in image space and the matching 3D rotations in $q$-space, as dictated by the image formation. Such equivariant deep learning is appropriate for diffusion MRI, because microstructural and macrostructural features such as neural fibers can appear at many different orientations, and because even non-rotation-equivariant deep learning has so far been the best method for many diffusion MRI tasks. We validate our equivariant method on multiple-sclerosis lesion segmentation. Our proposed neural networks yield better results and require fewer scans for training compared to non-rotation-equivariant deep learning. They also inherit all the advantages of deep learning over classical diffusion MRI methods. Our implementation is available at https://github.com/philip-mueller/equivariant-deep-dmri and can be used off the shelf without understanding the mathematical background.

</p>
</details>

<details><summary><b>Synthesizing multi-layer perceptron network with ant lion, biogeography-based dragonfly algorithm evolutionary strategy invasive weed and league champion optimization hybrid algorithms in predicting heating load in residential buildings</b>
<a href="https://arxiv.org/abs/2102.08928">arxiv:2102.08928</a>
&#x1F4C8; 1 <br>
<p>Hossein Moayedi, Amir Mosavi</p></summary>
<p>

**Abstract:** The significance of heating load (HL) accurate approximation is the primary motivation of this research to distinguish the most efficient predictive model among several neural-metaheuristic models. The proposed models are through synthesizing multi-layer perceptron network (MLP) with ant lion optimization (ALO), biogeography-based optimization (BBO), dragonfly algorithm (DA), evolutionary strategy (ES), invasive weed optimization (IWO), and league champion optimization (LCA) hybrid algorithms. Each ensemble is optimized in terms of the operating population. Accordingly, the ALO-MLP, BBO-MLP, DA-MLP, ES-MLP, IWO-MLP, and LCA-MLP presented their best performance for population sizes of 350, 400, 200, 500, 50, and 300, respectively. The comparison was carried out by implementing a ranking system. Based on the obtained overall scores (OSs), the BBO (OS = 36) featured as the most capable optimization technique, followed by ALO (OS = 27) and ES (OS = 20). Due to the efficient performance of these algorithms, the corresponding MLPs can be promising substitutes for traditional methods used for HL analysis.

</p>
</details>

<details><summary><b>Fast Monocular Hand Pose Estimation on Embedded Systems</b>
<a href="https://arxiv.org/abs/2102.07067">arxiv:2102.07067</a>
&#x1F4C8; 1 <br>
<p>Shan An, Xiajie Zhang, Dong Wei, Haogang Zhu, Jianyu Yang, Konstantinos A. Tsintotas</p></summary>
<p>

**Abstract:** Hand pose estimation is a fundamental task in many human-robot interaction-related applications. However, previous approaches suffer from unsatisfying hand landmark predictions in real-world scenes and high computation burden. This paper proposes a fast and accurate framework for hand pose estimation, dubbed as "FastHand". Using a lightweight encoder-decoder network architecture, FastHand fulfills the requirements of practical applications running on embedded devices. The encoder consists of deep layers with a small number of parameters, while the decoder makes use of spatial location information to obtain more accurate results. The evaluation took place on two publicly available datasets demonstrating the improved performance of the proposed pipeline compared to other state-of-the-art approaches. FastHand offers high accuracy scores while reaching a speed of 25 frames per second on an NVIDIA Jetson TX2 graphics processing unit.

</p>
</details>

<details><summary><b>HAWKS: Evolving Challenging Benchmark Sets for Cluster Analysis</b>
<a href="https://arxiv.org/abs/2102.06940">arxiv:2102.06940</a>
&#x1F4C8; 1 <br>
<p>Cameron Shand, Richard Allmendinger, Julia Handl, Andrew Webb, John Keane</p></summary>
<p>

**Abstract:** Comprehensive benchmarking of clustering algorithms is rendered difficult by two key factors: (i)~the elusiveness of a unique mathematical definition of this unsupervised learning approach and (ii)~dependencies between the generating models or clustering criteria adopted by some clustering algorithms and indices for internal cluster validation. Consequently, there is no consensus regarding the best practice for rigorous benchmarking, and whether this is possible at all outside the context of a given application. Here, we argue that synthetic datasets must continue to play an important role in the evaluation of clustering algorithms, but that this necessitates constructing benchmarks that appropriately cover the diverse set of properties that impact clustering algorithm performance. Through our framework, HAWKS, we demonstrate the important role evolutionary algorithms play to support flexible generation of such benchmarks, allowing simple modification and extension. We illustrate two possible uses of our framework: (i)~the evolution of benchmark data consistent with a set of hand-derived properties and (ii)~the generation of datasets that tease out performance differences between a given pair of algorithms. Our work has implications for the design of clustering benchmarks that sufficiently challenge a broad range of algorithms, and for furthering insight into the strengths and weaknesses of specific approaches.

</p>
</details>

<details><summary><b>Hybrid Artificial Intelligence Methods for Predicting Air Demand in Dam Bottom Outlet</b>
<a href="https://arxiv.org/abs/2102.06929">arxiv:2102.06929</a>
&#x1F4C8; 1 <br>
<p>Aliakbar Narimani, Mahdi Moghimi, Amir Mosavi</p></summary>
<p>

**Abstract:** In large infrastructures such as dams, which have a relatively high economic value, ensuring the proper operation of the associated hydraulic facilities in different operating conditions is of utmost importance. To ensure the correct and successful operation of the dam's hydraulic equipment and prevent possible damages, including gates and downstream tunnel, to build laboratory models and perform some tests are essential (the advancement of the smart sensors based on artificial intelligence is essential). One of the causes of damage to dam bottom outlets is cavitation in downstream and between the gates, which can impact on dam facilities, and air aeration can be a solution to improve it. In the present study, six dams in different provinces in Iran has been chosen to evaluate the air entrainment in the downstream tunnel experimentally. Three artificial neural networks (ANN) based machine learning (ML) algorithms are used to model and predict the air aeration in the bottom outlet. The proposed models are trained with genetic algorithms (GA), particle swarm optimization (PSO), i.e., ANN-GA, ANN-PSO, and ANFIS-PSO. Two hydrodynamic variables, namely volume rate and opening percentage of the gate, are used as inputs into all bottom outlet models. The results showed that the most optimal model is ANFIS-PSO to predict the dependent value compared with ANN-GA and ANN-PSO. The importance of the volume rate and opening percentage of the dams' gate parameters is more effective for suitable air aeration.

</p>
</details>

<details><summary><b>Modelling Cooperation in Network Games with Spatio-Temporal Complexity</b>
<a href="https://arxiv.org/abs/2102.06911">arxiv:2102.06911</a>
&#x1F4C8; 1 <br>
<p>Michiel A. Bakker, Richard Everett, Laura Weidinger, Iason Gabriel, William S. Isaac, Joel Z. Leibo, Edward Hughes</p></summary>
<p>

**Abstract:** The real world is awash with multi-agent problems that require collective action by self-interested agents, from the routing of packets across a computer network to the management of irrigation systems. Such systems have local incentives for individuals, whose behavior has an impact on the global outcome for the group. Given appropriate mechanisms describing agent interaction, groups may achieve socially beneficial outcomes, even in the face of short-term selfish incentives. In many cases, collective action problems possess an underlying graph structure, whose topology crucially determines the relationship between local decisions and emergent global effects. Such scenarios have received great attention through the lens of network games. However, this abstraction typically collapses important dimensions, such as geometry and time, relevant to the design of mechanisms promoting cooperation. In parallel work, multi-agent deep reinforcement learning has shown great promise in modelling the emergence of self-organized cooperation in complex gridworld domains. Here we apply this paradigm in graph-structured collective action problems. Using multi-agent deep reinforcement learning, we simulate an agent society for a variety of plausible mechanisms, finding clear transitions between different equilibria over time. We define analytic tools inspired by related literatures to measure the social outcomes, and use these to draw conclusions about the efficacy of different environmental interventions. Our methods have implications for mechanism design in both human and artificial agent systems.

</p>
</details>

<details><summary><b>Mixed Nash Equilibria in the Adversarial Examples Game</b>
<a href="https://arxiv.org/abs/2102.06905">arxiv:2102.06905</a>
&#x1F4C8; 1 <br>
<p>Laurent Meunier, Meyer Scetbon, Rafael Pinot, Jamal Atif, Yann Chevaleyre</p></summary>
<p>

**Abstract:** This paper tackles the problem of adversarial examples from a game theoretic point of view. We study the open question of the existence of mixed Nash equilibria in the zero-sum game formed by the attacker and the classifier. While previous works usually allow only one player to use randomized strategies, we show the necessity of considering randomization for both the classifier and the attacker. We demonstrate that this game has no duality gap, meaning that it always admits approximate Nash equilibria. We also provide the first optimization algorithms to learn a mixture of classifiers that approximately realizes the value of this game, \emph{i.e.} procedures to build an optimally robust randomized classifier.

</p>
</details>

<details><summary><b>GPSPiChain-Blockchain based Self-Contained Family Security System in Smart Home</b>
<a href="https://arxiv.org/abs/2102.06884">arxiv:2102.06884</a>
&#x1F4C8; 1 <br>
<p>Ali Raza, Lachlan Hardy, Erin Roehrer, Soonja Yeom, Byeong ho Kang</p></summary>
<p>

**Abstract:** With advancements in technology, personal computing devices are better adapted for and further integrated into people's lives and homes. The integration of technology into society also results in an increasing desire to control who and what has access to sensitive information, especially for vulnerable people including children and the elderly. With blockchain coming in to the picture as a technology that can revolutionise the world, it is now possible to have an immutable audit trail of locational data over time. By controlling the process through inexpensive equipment in the home, it is possible to control whom has access to such personal data. This paper presents a blockchain based family security system for tracking the location of consenting family members' smart phones. The locations of the family members' smart phones are logged and stored in a private blockchain which can be accessed through a node installed in the family home on a computer. The data for the whereabouts of family members stays within the family unit and does not go to any third party. The system is implemented in a small scale (one miner and two other nodes) and the technical feasibility is discussed along with the limitations of the system. Further research will cover the integration of the system into a smart home environment, and ethical implementations of tracking, especially of vulnerable people, using the immutability of blockchain.

</p>
</details>

<details><summary><b>ThetA -- fast and robust clustering via a distance parameter</b>
<a href="https://arxiv.org/abs/2102.07028">arxiv:2102.07028</a>
&#x1F4C8; 0 <br>
<p>Eleftherios Garyfallidis, Shreyas Fadnavis, Jong Sung Park, Bramsh Qamar Chandio, Javier Guaje, Serge Koudoro, Nasim Anousheh</p></summary>
<p>

**Abstract:** Clustering is a fundamental problem in machine learning where distance-based approaches have dominated the field for many decades. This set of problems is often tackled by partitioning the data into K clusters where the number of clusters is chosen apriori. While significant progress has been made on these lines over the years, it is well established that as the number of clusters or dimensions increase, current approaches dwell in local minima resulting in suboptimal solutions. In this work, we propose a new set of distance threshold methods called Theta-based Algorithms (ThetA). Via experimental comparisons and complexity analyses we show that our proposed approach outperforms existing approaches in: a) clustering accuracy and b) time complexity. Additionally, we show that for a large class of problems, learning the optimal threshold is straightforward in comparison to learning K. Moreover, we show how ThetA can infer the sparsity of datasets in higher dimensions.

</p>
</details>

<details><summary><b>Clustering Interval-Censored Time-Series for Disease Phenotyping</b>
<a href="https://arxiv.org/abs/2102.07005">arxiv:2102.07005</a>
&#x1F4C8; 0 <br>
<p>Irene Y. Chen, Rahul G. Krishnan, David Sontag</p></summary>
<p>

**Abstract:** Unsupervised learning is often used to uncover clusters in data. However, different kinds of noise may impede the discovery of useful patterns from real-world time-series data. In this work, we focus on mitigating the interference of interval censoring in the task of clustering for disease phenotyping. We develop a deep generative, continuous-time model of time-series data that clusters time-series while correcting for censorship time. We provide conditions under which clusters and the amount of delayed entry may be identified from data under a noiseless model. On synthetic data, we demonstrate accurate, stable, and interpretable results that outperform several benchmarks. On real-world clinical datasets of heart failure and Parkinson's disease patients, we study how interval censoring can adversely affect the task of disease phenotyping. Our model corrects for this source of error and recovers known clinical subtypes.

</p>
</details>

<details><summary><b>Learning in Multi-Stage Decentralized Matching Markets</b>
<a href="https://arxiv.org/abs/2102.06988">arxiv:2102.06988</a>
&#x1F4C8; 0 <br>
<p>Xiaowu Dai, Michael I. Jordan</p></summary>
<p>

**Abstract:** Matching markets are often organized in a multi-stage and decentralized manner. Moreover, participants in real-world matching markets often have uncertain preferences. This article develops a framework for learning optimal strategies in such settings, based on a nonparametric statistical approach and variational analysis. We propose an efficient algorithm, built upon concepts of "lower uncertainty bound" and "calibrated decentralized matching," for maximizing the participants' expected payoff. We show that there exists a welfare-versus-fairness trade-off that is characterized by the uncertainty level of acceptance. Participants will strategically act in favor of a low uncertainty level to reduce competition and increase expected payoff. We prove that participants can be better off with multi-stage matching compared to single-stage matching. We demonstrate aspects of the theoretical predictions through simulations and an experiment using real data from college admissions.

</p>
</details>

<details><summary><b>Learning from Similarity-Confidence Data</b>
<a href="https://arxiv.org/abs/2102.06879">arxiv:2102.06879</a>
&#x1F4C8; 0 <br>
<p>Yuzhou Cao, Lei Feng, Yitian Xu, Bo An, Gang Niu, Masashi Sugiyama</p></summary>
<p>

**Abstract:** Weakly supervised learning has drawn considerable attention recently to reduce the expensive time and labor consumption of labeling massive data. In this paper, we investigate a novel weakly supervised learning problem of learning from similarity-confidence (Sconf) data, where we aim to learn an effective binary classifier from only unlabeled data pairs equipped with confidence that illustrates their degree of similarity (two examples are similar if they belong to the same class). To solve this problem, we propose an unbiased estimator of the classification risk that can be calculated from only Sconf data and show that the estimation error bound achieves the optimal convergence rate. To alleviate potential overfitting when flexible models are used, we further employ a risk correction scheme on the proposed risk estimator. Experimental results demonstrate the effectiveness of the proposed methods.

</p>
</details>


{% endraw %}
Prev: [2021.02.12]({{ '/2021/02/12/2021.02.12.html' | relative_url }})  Next: [2021.02.14]({{ '/2021/02/14/2021.02.14.html' | relative_url }})