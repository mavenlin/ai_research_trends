Prev: [2021.02.21]({{ '/2021/02/21/2021.02.21.html' | relative_url }})  Next: [2021.02.23]({{ '/2021/02/23/2021.02.23.html' | relative_url }})
{% raw %}
## Summary for 2021-02-22, created on 2021-12-24


<details><summary><b>Towards Causal Representation Learning</b>
<a href="https://arxiv.org/abs/2102.11107">arxiv:2102.11107</a>
&#x1F4C8; 333 <br>
<p>Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, Yoshua Bengio</p></summary>
<p>

**Abstract:** The two fields of machine learning and graphical causality arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.

</p>
</details>

<details><summary><b>On Feature Collapse and Deep Kernel Learning for Single Forward Pass Uncertainty</b>
<a href="https://arxiv.org/abs/2102.11409">arxiv:2102.11409</a>
&#x1F4C8; 44 <br>
<p>Joost van Amersfoort, Lewis Smith, Andrew Jesson, Oscar Key, Yarin Gal</p></summary>
<p>

**Abstract:** Gaussian processes are often considered a gold standard in uncertainty estimation with low dimensional data, but they have difficulty scaling to high dimensional inputs. Deep Kernel Learning (DKL) was introduced as a solution to this problem: a deep feature extractor is used to transform the inputs over which a Gaussian process' kernel is defined. However, DKL has been shown to provide unreliable uncertainty estimates in practice. We study why, and show that for certain feature extractors, "far-away" data points are mapped to the same features as those of training-set points. With this insight we propose to constrain DKL's feature extractor to approximately preserve distances through a bi-Lipschitz constraint, resulting in a feature space favorable to DKL. We obtain a model, DUE, which demonstrates uncertainty quality outperforming previous DKL and single forward pass uncertainty methods, while maintaining the speed and accuracy of softmax neural networks.

</p>
</details>

<details><summary><b>Position Information in Transformers: An Overview</b>
<a href="https://arxiv.org/abs/2102.11090">arxiv:2102.11090</a>
&#x1F4C8; 43 <br>
<p>Philipp Dufter, Martin Schmitt, Hinrich Schütze</p></summary>
<p>

**Abstract:** Transformers are arguably the main workhorse in recent Natural Language Processing research. By definition a Transformer is invariant with respect to reordering of the input. However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance. In this article, we provide an overview and theoretical comparison of existing methods to incorporate position information into Transformer models. The objectives of this survey are to (1) showcase that position information in Transformer is a vibrant and extensive research area; (2) enable the reader to compare existing methods by providing a unified notation and systematization of different approaches along important model dimensions; (3) indicate what characteristics of an application should be taken into account when selecting a position encoding; (4) provide stimuli for future research.

</p>
</details>

<details><summary><b>Reinforcement Learning with Prototypical Representations</b>
<a href="https://arxiv.org/abs/2102.11271">arxiv:2102.11271</a>
&#x1F4C8; 27 <br>
<p>Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto</p></summary>
<p>

**Abstract:** Learning effective representations in image-based environments is crucial for sample efficient Reinforcement Learning (RL). Unfortunately, in RL, representation learning is confounded with the exploratory experience of the agent -- learning a useful representation requires diverse data, while effective exploration is only possible with coherent representations. Furthermore, we would like to learn representations that not only generalize across tasks but also accelerate downstream exploration for efficient task-specific training. To address these challenges we propose Proto-RL, a self-supervised framework that ties representation learning with exploration through prototypical representations. These prototypes simultaneously serve as a summarization of the exploratory experience of an agent as well as a basis for representing observations. We pre-train these task-agnostic representations and prototypes on environments without downstream task information. This enables state-of-the-art downstream policy learning on a set of difficult continuous control tasks.

</p>
</details>

<details><summary><b>Attention Models for Point Clouds in Deep Learning: A Survey</b>
<a href="https://arxiv.org/abs/2102.10788">arxiv:2102.10788</a>
&#x1F4C8; 23 <br>
<p>Xu Wang, Yi Jin, Yigang Cen, Tao Wang, Yidong Li</p></summary>
<p>

**Abstract:** Recently, the advancement of 3D point clouds in deep learning has attracted intensive research in different application domains such as computer vision and robotic tasks. However, creating feature representation of robust, discriminative from unordered and irregular point clouds is challenging. In this paper, our ultimate goal is to provide a comprehensive overview of the point clouds feature representation which uses attention models. More than 75+ key contributions in the recent three years are summarized in this survey, including the 3D objective detection, 3D semantic segmentation, 3D pose estimation, point clouds completion etc. We provide a detailed characterization (1) the role of attention mechanisms, (2) the usability of attention models into different tasks, (3) the development trend of key technology.

</p>
</details>

<details><summary><b>Model-Based Domain Generalization</b>
<a href="https://arxiv.org/abs/2102.11436">arxiv:2102.11436</a>
&#x1F4C8; 22 <br>
<p>Alexander Robey, George J. Pappas, Hamed Hassani</p></summary>
<p>

**Abstract:** Despite remarkable success in a variety of applications, it is well-known that deep learning can fail catastrophically when presented with out-of-distribution data. Toward addressing this challenge, we consider the domain generalization problem, wherein predictors are trained using data drawn from a family of related training domains and then evaluated on a distinct and unseen test domain. We show that under a natural model of data generation and a concomitant invariance condition, the domain generalization problem is equivalent to an infinite-dimensional constrained statistical learning problem; this problem forms the basis of our approach, which we call Model-Based Domain Generalization. Due to the inherent challenges in solving constrained optimization problems in deep learning, we exploit nonconvex duality theory to develop unconstrained relaxations of this statistical problem with tight bounds on the duality gap. Based on this theoretical motivation, we propose a novel domain generalization algorithm with convergence guarantees. In our experiments, we report improvements of up to 30 percentage points over state-of-the-art domain generalization baselines on several benchmarks including ColoredMNIST, Camelyon17-WILDS, FMoW-WILDS, and PACS.

</p>
</details>

<details><summary><b>Conditional Positional Encodings for Vision Transformers</b>
<a href="https://arxiv.org/abs/2102.10882">arxiv:2102.10882</a>
&#x1F4C8; 18 <br>
<p>Xiangxiang Chu, Zhi Tian, Bo Zhang, Xinlong Wang, Xiaolin Wei, Huaxia Xia, Chunhua Shen</p></summary>
<p>

**Abstract:** We propose a conditional positional encoding (CPE) scheme for vision Transformers. Unlike previous fixed or learnable positional encodings, which are pre-defined and independent of input tokens, CPE is dynamically generated and conditioned on the local neighborhood of the input tokens. As a result, CPE can easily generalize to the input sequences that are longer than what the model has ever seen during training. Besides, CPE can keep the desired translation-invariance in the image classification task, resulting in improved classification accuracy. CPE can be effortlessly implemented with a simple Position Encoding Generator (PEG), and it can be seamlessly incorporated into the current Transformer framework. Built on PEG, we present Conditional Position encoding Vision Transformer (CPVT). We demonstrate that CPVT has visually similar attention maps compared to those with learned positional encodings. Benefit from the conditional positional encoding scheme, we obtain state-of-the-art results on the ImageNet classification task compared with vision Transformers to date. Our code will be made available at https://github.com/Meituan-AutoML/CPVT .

</p>
</details>

<details><summary><b>LogME: Practical Assessment of Pre-trained Models for Transfer Learning</b>
<a href="https://arxiv.org/abs/2102.11005">arxiv:2102.11005</a>
&#x1F4C8; 14 <br>
<p>Kaichao You, Yong Liu, Jianmin Wang, Mingsheng Long</p></summary>
<p>

**Abstract:** This paper studies task adaptive pre-trained model selection, an underexplored problem of assessing pre-trained models for the target task and select best ones from the model zoo \emph{without fine-tuning}. A few pilot works addressed the problem in transferring supervised pre-trained models to classification tasks, but they cannot handle emerging unsupervised pre-trained models or regression tasks. In pursuit of a practical assessment method, we propose to estimate the maximum value of label evidence given features extracted by pre-trained models. Unlike the maximum likelihood, the maximum evidence is \emph{immune to over-fitting}, while its expensive computation can be dramatically reduced by our carefully designed algorithm. The Logarithm of Maximum Evidence (LogME) can be used to assess pre-trained models for transfer learning: a pre-trained model with a high LogME value is likely to have good transfer performance. LogME is \emph{fast, accurate, and general}, characterizing itself as the first practical method for assessing pre-trained models. Compared with brute-force fine-tuning, LogME brings at most $3000\times$ speedup in wall-clock time and requires only $1\%$ memory footprint. It outperforms prior methods by a large margin in their setting and is applicable to new settings. It is general enough for diverse pre-trained models (supervised pre-trained and unsupervised pre-trained), downstream tasks (classification and regression), and modalities (vision and language). Code is available at this repository: \href{https://github.com/thuml/LogME}{https://github.com/thuml/LogME}.

</p>
</details>

<details><summary><b>Learning Contact Dynamics using Physically Structured Neural Networks</b>
<a href="https://arxiv.org/abs/2102.11206">arxiv:2102.11206</a>
&#x1F4C8; 10 <br>
<p>Andreas Hochlehnert, Alexander Terenin, Steindór Sæmundsson, Marc Peter Deisenroth</p></summary>
<p>

**Abstract:** Learning physically structured representations of dynamical systems that include contact between different objects is an important problem for learning-based approaches in robotics. Black-box neural networks can learn to approximately represent discontinuous dynamics, but they typically require large quantities of data and often suffer from pathological behaviour when forecasting for longer time horizons. In this work, we use connections between deep neural networks and differential equations to design a family of deep network architectures for representing contact dynamics between objects. We show that these networks can learn discontinuous contact events in a data-efficient manner from noisy observations in settings that are traditionally difficult for black-box approaches and recent physics inspired neural networks. Our results indicate that an idealised form of touch feedback -- which is heavily relied upon by biological systems -- is a key component of making this learning problem tractable. Together with the inductive biases introduced through the network architectures, our techniques enable accurate learning of contact dynamics from observations.

</p>
</details>

<details><summary><b>Improved Learning of Robot Manipulation Tasks via Tactile Intrinsic Motivation</b>
<a href="https://arxiv.org/abs/2102.11051">arxiv:2102.11051</a>
&#x1F4C8; 10 <br>
<p>Nikola Vulin, Sammy Christen, Stefan Stevsic, Otmar Hilliges</p></summary>
<p>

**Abstract:** In this paper we address the challenge of exploration in deep reinforcement learning for robotic manipulation tasks. In sparse goal settings, an agent does not receive any positive feedback until randomly achieving the goal, which becomes infeasible for longer control sequences. Inspired by touch-based exploration observed in children, we formulate an intrinsic reward based on the sum of forces between a robot's force sensors and manipulation objects that encourages physical interaction. Furthermore, we introduce contact-prioritized experience replay, a sampling scheme that prioritizes contact rich episodes and transitions. We show that our solution accelerates the exploration and outperforms state-of-the-art methods on three fundamental robot manipulation benchmarks.

</p>
</details>

<details><summary><b>VisualCheXbert: Addressing the Discrepancy Between Radiology Report Labels and Image Labels</b>
<a href="https://arxiv.org/abs/2102.11467">arxiv:2102.11467</a>
&#x1F4C8; 9 <br>
<p>Saahil Jain, Akshay Smit, Steven QH Truong, Chanh DT Nguyen, Minh-Thanh Huynh, Mudit Jain, Victoria A. Young, Andrew Y. Ng, Matthew P. Lungren, Pranav Rajpurkar</p></summary>
<p>

**Abstract:** Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17). We also find that VisualCheXbert better agrees with radiologists labeling chest X-ray images than do radiologists labeling the corresponding radiology reports by an average F1 score across several medical conditions of between 0.12 (95% CI 0.09, 0.15) and 0.21 (95% CI 0.18, 0.24).

</p>
</details>

<details><summary><b>Action Redundancy in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.11329">arxiv:2102.11329</a>
&#x1F4C8; 9 <br>
<p>Nir Baram, Guy Tennenholtz, Shie Mannor</p></summary>
<p>

**Abstract:** Maximum Entropy (MaxEnt) reinforcement learning is a powerful learning paradigm which seeks to maximize return under entropy regularization. However, action entropy does not necessarily coincide with state entropy, e.g., when multiple actions produce the same transition. Instead, we propose to maximize the transition entropy, i.e., the entropy of next states. We show that transition entropy can be described by two terms; namely, model-dependent transition entropy and action redundancy. Particularly, we explore the latter in both deterministic and stochastic settings and develop tractable approximation methods in a near model-free setup. We construct algorithms to minimize action redundancy and demonstrate their effectiveness on a synthetic environment with multiple redundant actions as well as contemporary benchmarks in Atari and Mujoco. Our results suggest that action redundancy is a fundamental problem in reinforcement learning.

</p>
</details>

<details><summary><b>Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding</b>
<a href="https://arxiv.org/abs/2102.11086">arxiv:2102.11086</a>
&#x1F4C8; 9 <br>
<p>Yangjun Ruan, Karen Ullrich, Daniel Severo, James Townsend, Ashish Khisti, Arnaud Doucet, Alireza Makhzani, Chris J. Maddison</p></summary>
<p>

**Abstract:** Latent variable models have been successfully applied in lossless compression with the bits-back coding algorithm. However, bits-back suffers from an increase in the bitrate equal to the KL divergence between the approximate posterior and the true posterior. In this paper, we show how to remove this gap asymptotically by deriving bits-back coding algorithms from tighter variational bounds. The key idea is to exploit extended space representations of Monte Carlo estimators of the marginal likelihood. Naively applied, our schemes would require more initial bits than the standard bits-back coder, but we show how to drastically reduce this additional cost with couplings in the latent space. When parallel architectures can be exploited, our coders can achieve better rates than bits-back with little additional cost. We demonstrate improved lossless compression rates in a variety of settings, especially in out-of-distribution or sequential data compression.

</p>
</details>

<details><summary><b>Anyone GAN Sing</b>
<a href="https://arxiv.org/abs/2102.11058">arxiv:2102.11058</a>
&#x1F4C8; 9 <br>
<p>Shreeviknesh Sankaran, Sukavanan Nanjundan, G. Paavai Anand</p></summary>
<p>

**Abstract:** The problem of audio synthesis has been increasingly solved using deep neural networks. With the introduction of Generative Adversarial Networks (GAN), another efficient and adjective path has opened up to solve this problem. In this paper, we present a method to synthesize the singing voice of a person using a Convolutional Long Short-term Memory (ConvLSTM) based GAN optimized using the Wasserstein loss function. Our work is inspired by WGANSing by Chandna et al. Our model inputs consecutive frame-wise linguistic and frequency features, along with singer identity and outputs vocoder features. We train the model on a dataset of 48 English songs sung and spoken by 12 non-professional singers. For inference, sequential blocks are concatenated using an overlap-add procedure. We test the model using the Mel-Cepstral Distance metric and a subjective listening test with 18 participants.

</p>
</details>

<details><summary><b>Shapley values for feature selection: The good, the bad, and the axioms</b>
<a href="https://arxiv.org/abs/2102.10936">arxiv:2102.10936</a>
&#x1F4C8; 9 <br>
<p>Daniel Fryer, Inga Strümke, Hien Nguyen</p></summary>
<p>

**Abstract:** The Shapley value has become popular in the Explainable AI (XAI) literature, thanks, to a large extent, to a solid theoretical foundation, including four "favourable and fair" axioms for attribution in transferable utility games. The Shapley value is provably the only solution concept satisfying these axioms. In this paper, we introduce the Shapley value and draw attention to its recent uses as a feature selection tool. We call into question this use of the Shapley value, using simple, abstract "toy" counterexamples to illustrate that the axioms may work against the goals of feature selection. From this, we develop a number of insights that are then investigated in concrete simulation settings, with a variety of Shapley value formulations, including SHapley Additive exPlanations (SHAP) and Shapley Additive Global importancE (SAGE).

</p>
</details>

<details><summary><b>Linear unit-tests for invariance discovery</b>
<a href="https://arxiv.org/abs/2102.10867">arxiv:2102.10867</a>
&#x1F4C8; 9 <br>
<p>Benjamin Aubin, Agnieszka Słowik, Martin Arjovsky, Leon Bottou, David Lopez-Paz</p></summary>
<p>

**Abstract:** There is an increasing interest in algorithms to learn invariant correlations across training environments. A big share of the current proposals find theoretical support in the causality literature but, how useful are they in practice? The purpose of this note is to propose six linear low-dimensional problems -- unit tests -- to evaluate different types of out-of-distribution generalization in a precise manner. Following initial experiments, none of the three recently proposed alternatives passes all tests. By providing the code to automatically replicate all the results in this manuscript (https://www.github.com/facebookresearch/InvarianceUnitTests), we hope that our unit tests become a standard steppingstone for researchers in out-of-distribution generalization.

</p>
</details>

<details><summary><b>Probing Multimodal Embeddings for Linguistic Properties: the Visual-Semantic Case</b>
<a href="https://arxiv.org/abs/2102.11115">arxiv:2102.11115</a>
&#x1F4C8; 8 <br>
<p>Adam Dahlgren Lindström, Suna Bensch, Johanna Björklund, Frank Drewes</p></summary>
<p>

**Abstract:** Semantic embeddings have advanced the state of the art for countless natural language processing tasks, and various extensions to multimodal domains, such as visual-semantic embeddings, have been proposed. While the power of visual-semantic embeddings comes from the distillation and enrichment of information through machine learning, their inner workings are poorly understood and there is a shortage of analysis tools. To address this problem, we generalize the notion of probing tasks to the visual-semantic case. To this end, we (i) discuss the formalization of probing tasks for embeddings of image-caption pairs, (ii) define three concrete probing tasks within our general framework, (iii) train classifiers to probe for those properties, and (iv) compare various state-of-the-art embeddings under the lens of the proposed probing tasks. Our experiments reveal an up to 12% increase in accuracy on visual-semantic embeddings compared to the corresponding unimodal embeddings, which suggest that the text and image dimensions represented in the former do complement each other.

</p>
</details>

<details><summary><b>DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.11492">arxiv:2102.11492</a>
&#x1F4C8; 7 <br>
<p>Xianyuan Zhan, Haoran Xu, Yue Zhang, Yusen Huo, Xiangyu Zhu, Honglei Yin, Yu Zheng</p></summary>
<p>

**Abstract:** Thermal power generation plays a dominant role in the world's electricity supply. It consumes large amounts of coal worldwide, and causes serious air pollution. Optimizing the combustion efficiency of a thermal power generating unit (TPGU) is a highly challenging and critical task in the energy industry. We develop a new data-driven AI system, namely DeepThermal, to optimize the combustion control strategy for TPGUs. At its core, is a new model-based offline reinforcement learning (RL) framework, called MORE, which leverages logged historical operational data of a TPGU to solve a highly complex constrained Markov decision process problem via purely offline training. MORE aims at simultaneously improving the long-term reward (increase combustion efficiency and reduce pollutant emission) and controlling operational risks (safety constraints satisfaction). In DeepThermal, we first learn a data-driven combustion process simulator from the offline dataset. The RL agent of MORE is then trained by combining real historical data as well as carefully filtered and processed simulation data through a novel restrictive exploration scheme. DeepThermal has been successfully deployed in four large coal-fired thermal power plants in China. Real-world experiments show that DeepThermal effectively improves the combustion efficiency of a TPGU. We also report and demonstrate the superior performance of MORE by comparing with the state-of-the-art algorithms on the standard offline RL benchmarks. To the best knowledge of the authors, DeepThermal is the first AI application that has been used to solve real-world complex mission-critical control tasks using the offline RL approach.

</p>
</details>

<details><summary><b>The FaCells. An Exploratory Study about LSTM Layers on Face Sketches Classifiers</b>
<a href="https://arxiv.org/abs/2102.11361">arxiv:2102.11361</a>
&#x1F4C8; 7 <br>
<p>Xavier Ignacio González</p></summary>
<p>

**Abstract:** Lines are human mental abstractions. A bunch of lines may form a drawing. A set of drawings can feed an LSTM network input layer, considering each draw as a list of lines and a line a list of points. This paper proposes the pointless motive to classify the gender of celebrities' portraits as an excuse for exploration in a broad, more artistic sense. Investigation results drove compelling ideas here discussed. The experiments compared different ways to represent draws to be input in a network and showed that an absolute format of coordinates (x, y) was a better performer than a relative one (Dx, Dy) with respect to prior points, most frequent in the reviewed literature. Experiments also showed that, due to the recurrent nature of LSTMs, the order of lines forming a drawing is a relevant factor for input in an LSTM classifier not studied before. A minimum 'pencil' traveled length criteria for line ordering proved suitable, possible by reducing it to a TSP particular instance. The best configuration for gender classification appears with an LSTM layer that returns the hidden state value for each input point step, followed by a global average layer along the sequence, before the output dense layer. That result guided the idea of removing the average in the network pipeline and return a per-point attribute score just by adjusting tensors dimensions. With this trick, the model detects an attribute in a drawing and also recognizes the points linked to it. Moreover, by overlapping filtered lines of portraits, an attribute's visual essence is depicted. Meet the FaCells.

</p>
</details>

<details><summary><b>A Theory of Label Propagation for Subpopulation Shift</b>
<a href="https://arxiv.org/abs/2102.11203">arxiv:2102.11203</a>
&#x1F4C8; 7 <br>
<p>Tianle Cai, Ruiqi Gao, Jason D. Lee, Qi Lei</p></summary>
<p>

**Abstract:** One of the central problems in machine learning is domain adaptation. Unlike past theoretical work, we consider a new model for subpopulation shift in the input or representation space. In this work, we propose a provably effective framework for domain adaptation based on label propagation. In our analysis, we use a simple but realistic expansion assumption, proposed in \citet{wei2021theoretical}. Using a teacher classifier trained on the source domain, our algorithm not only propagates to the target domain but also improves upon the teacher. By leveraging existing generalization bounds, we also obtain end-to-end finite-sample guarantees on the entire algorithm. In addition, we extend our theoretical framework to a more general setting of source-to-target transfer based on a third unlabeled dataset, which can be easily applied in various learning scenarios. Inspired by our theory, we adapt consistency-based semi-supervised learning methods to domain adaptation settings and gain significant improvements.

</p>
</details>

<details><summary><b>The Uncanny Similarity of Recurrence and Depth</b>
<a href="https://arxiv.org/abs/2102.11011">arxiv:2102.11011</a>
&#x1F4C8; 7 <br>
<p>Avi Schwarzschild, Arjun Gupta, Amin Ghiasi, Micah Goldblum, Tom Goldstein</p></summary>
<p>

**Abstract:** It is widely believed that deep neural networks contain layer specialization, wherein networks extract hierarchical features representing edges and patterns in shallow layers and complete objects in deeper layers. Unlike common feed-forward models that have distinct filters at each layer, recurrent networks reuse the same parameters at various depths. In this work, we observe that recurrent models exhibit the same hierarchical behaviors and the same performance benefits as depth despite reusing the same filters at every recurrence. By training models of various feed-forward and recurrent architectures on several datasets for image classification as well as maze solving, we show that recurrent networks have the ability to closely emulate the behavior of non-recurrent deep models, often doing so with far fewer parameters.

</p>
</details>

<details><summary><b>Using Prior Knowledge to Guide BERT's Attention in Semantic Textual Matching Tasks</b>
<a href="https://arxiv.org/abs/2102.10934">arxiv:2102.10934</a>
&#x1F4C8; 7 <br>
<p>Tingyu Xia, Yue Wang, Yuan Tian, Yi Chang</p></summary>
<p>

**Abstract:** We study the problem of incorporating prior knowledge into a deep Transformer-based model,i.e.,Bidirectional Encoder Representations from Transformers (BERT), to enhance its performance on semantic textual matching tasks. By probing and analyzing what BERT has already known when solving this task, we obtain better understanding of what task-specific knowledge BERT needs the most and where it is most needed. The analysis further motivates us to take a different approach than most existing works. Instead of using prior knowledge to create a new training task for fine-tuning BERT, we directly inject knowledge into BERT's multi-head attention mechanism. This leads us to a simple yet effective approach that enjoys fast training stage as it saves the model from training on additional data or tasks other than the main task. Extensive experiments demonstrate that the proposed knowledge-enhanced BERT is able to consistently improve semantic textual matching performance over the original BERT model, and the performance benefit is most salient when training data is scarce.

</p>
</details>

<details><summary><b>SALT: A Semi-automatic Labeling Tool for RGB-D Video Sequences</b>
<a href="https://arxiv.org/abs/2102.10820">arxiv:2102.10820</a>
&#x1F4C8; 7 <br>
<p>Dennis Stumpf, Stephan Krauß, Gerd Reis, Oliver Wasenmüller, Didier Stricker</p></summary>
<p>

**Abstract:** Large labeled data sets are one of the essential basics of modern deep learning techniques. Therefore, there is an increasing need for tools that allow to label large amounts of data as intuitively as possible. In this paper, we introduce SALT, a tool to semi-automatically annotate RGB-D video sequences to generate 3D bounding boxes for full six Degrees of Freedom (DoF) object poses, as well as pixel-level instance segmentation masks for both RGB and depth. Besides bounding box propagation through various interpolation techniques, as well as algorithmically guided instance segmentation, our pipeline also provides built-in pre-processing functionalities to facilitate the data set creation process. By making full use of SALT, annotation time can be reduced by a factor of up to 33.95 for bounding box creation and 8.55 for RGB segmentation without compromising the quality of the automatically generated ground truth.

</p>
</details>

<details><summary><b>Provably Correct Training of Neural Network Controllers Using Reachability Analysis</b>
<a href="https://arxiv.org/abs/2102.10806">arxiv:2102.10806</a>
&#x1F4C8; 7 <br>
<p>Xiaowu Sun, Yasser Shoukry</p></summary>
<p>

**Abstract:** In this paper, we consider the problem of training neural network (NN) controllers for nonlinear dynamical systems that are guaranteed to satisfy safety and liveness (e.g., reach-avoid) properties. Our approach is to combine model-based design methodologies for dynamical systems with data-driven approaches to achieve this target. We confine our attention to NNs with Rectifier Linear Unit (ReLU) nonlinearity which are known to represent Continuous Piece-Wise Affine (CPWA) functions. Given a mathematical model of the dynamical system, we compute a finite-state abstract model that captures the closed-loop behavior under all possible CPWA controllers. Using this finite-state abstract model, our framework identifies a family of CPWA functions guaranteed to satisfy the safety requirements. We augment the learning algorithm with a NN weight projection operator during training that enforces the resulting NN to represent a CPWA function from the provably safe family of CPWA functions. Moreover, the proposed framework uses the finite-state abstract model to identify candidate CPWA functions that may satisfy the liveness properties. Using such candidate CPWA functions, the proposed framework biases the NN training to achieve the liveness specification. We show the efficacy of the proposed framework both in simulation and on an actual robotic vehicle.

</p>
</details>

<details><summary><b>Neural Delay Differential Equations</b>
<a href="https://arxiv.org/abs/2102.10801">arxiv:2102.10801</a>
&#x1F4C8; 7 <br>
<p>Qunxi Zhu, Yao Guo, Wei Lin</p></summary>
<p>

**Abstract:** Neural Ordinary Differential Equations (NODEs), a framework of continuous-depth neural networks, have been widely applied, showing exceptional efficacy in coping with some representative datasets. Recently, an augmented framework has been successfully developed for conquering some limitations emergent in application of the original framework. Here we propose a new class of continuous-depth neural networks with delay, named as Neural Delay Differential Equations (NDDEs), and, for computing the corresponding gradients, we use the adjoint sensitivity method to obtain the delayed dynamics of the adjoint. Since the differential equations with delays are usually seen as dynamical systems of infinite dimension possessing more fruitful dynamics, the NDDEs, compared to the NODEs, own a stronger capacity of nonlinear representations. Indeed, we analytically validate that the NDDEs are of universal approximators, and further articulate an extension of the NDDEs, where the initial function of the NDDEs is supposed to satisfy ODEs. More importantly, we use several illustrative examples to demonstrate the outstanding capacities of the NDDEs and the NDDEs with ODEs' initial value. Specifically, (1) we successfully model the delayed dynamics where the trajectories in the lower-dimensional phase space could be mutually intersected, while the traditional NODEs without any argumentation are not directly applicable for such modeling, and (2) we achieve lower loss and higher accuracy not only for the data produced synthetically by complex models but also for the real-world image datasets, i.e., CIFAR10, MNIST, and SVHN. Our results on the NDDEs reveal that appropriately articulating the elements of dynamical systems into the network design is truly beneficial to promoting the network performance.

</p>
</details>

<details><summary><b>On Interaction Between Augmentations and Corruptions in Natural Corruption Robustness</b>
<a href="https://arxiv.org/abs/2102.11273">arxiv:2102.11273</a>
&#x1F4C8; 6 <br>
<p>Eric Mintun, Alexander Kirillov, Saining Xie</p></summary>
<p>

**Abstract:** Invariance to a broad array of image corruptions, such as warping, noise, or color shifts, is an important aspect of building robust models in computer vision. Recently, several new data augmentations have been proposed that significantly improve performance on ImageNet-C, a benchmark of such corruptions. However, there is still a lack of basic understanding on the relationship between data augmentations and test-time corruptions. To this end, we develop a feature space for image transforms, and then use a new measure in this space between augmentations and corruptions called the Minimal Sample Distance to demonstrate a strong correlation between similarity and performance. We then investigate recent data augmentations and observe a significant degradation in corruption robustness when the test-time corruptions are sampled to be perceptually dissimilar from ImageNet-C in this feature space. Our results suggest that test error can be improved by training on perceptually similar augmentations, and data augmentations may not generalize well beyond the existing benchmark. We hope our results and tools will allow for more robust progress towards improving robustness to image corruptions. We provide code at https://github.com/facebookresearch/augmentation-corruption.

</p>
</details>

<details><summary><b>A Relational Tsetlin Machine with Applications to Natural Language Understanding</b>
<a href="https://arxiv.org/abs/2102.10952">arxiv:2102.10952</a>
&#x1F4C8; 5 <br>
<p>Rupsa Saha, Ole-Christoffer Granmo, Vladimir I. Zadorozhny, Morten Goodwin</p></summary>
<p>

**Abstract:** TMs are a pattern recognition approach that uses finite state machines for learning and propositional logic to represent patterns. In addition to being natively interpretable, they have provided competitive accuracy for various tasks. In this paper, we increase the computing power of TMs by proposing a first-order logic-based framework with Herbrand semantics. The resulting TM is relational and can take advantage of logical structures appearing in natural language, to learn rules that represent how actions and consequences are related in the real world. The outcome is a logic program of Horn clauses, bringing in a structured view of unstructured data. In closed-domain question-answering, the first-order representation produces 10x more compact KBs, along with an increase in answering accuracy from 94.83% to 99.48%. The approach is further robust towards erroneous, missing, and superfluous information, distilling the aspects of a text that are important for real-world understanding.

</p>
</details>

<details><summary><b>Interpretative Computer-aided Lung Cancer Diagnosis: from Radiology Analysis to Malignancy Evaluation</b>
<a href="https://arxiv.org/abs/2102.10919">arxiv:2102.10919</a>
&#x1F4C8; 5 <br>
<p>Shaohua Zheng, Zhiqiang Shen, Chenhao Peia, Wangbin Ding, Haojin Lin, Jiepeng Zheng, Lin Pan, Bin Zheng, Liqin Huang</p></summary>
<p>

**Abstract:** Background and Objective:Computer-aided diagnosis (CAD) systems promote diagnosis effectiveness and alleviate pressure of radiologists. A CAD system for lung cancer diagnosis includes nodule candidate detection and nodule malignancy evaluation. Recently, deep learning-based pulmonary nodule detection has reached satisfactory performance ready for clinical application. However, deep learning-based nodule malignancy evaluation depends on heuristic inference from low-dose computed tomography volume to malignant probability, which lacks clinical cognition. Methods:In this paper, we propose a joint radiology analysis and malignancy evaluation network (R2MNet) to evaluate the pulmonary nodule malignancy via radiology characteristics analysis. Radiological features are extracted as channel descriptor to highlight specific regions of the input volume that are critical for nodule malignancy evaluation. In addition, for model explanations, we propose channel-dependent activation mapping to visualize the features and shed light on the decision process of deep neural network. Results:Experimental results on the LIDC-IDRI dataset demonstrate that the proposed method achieved area under curve of 96.27% on nodule radiology analysis and AUC of 97.52% on nodule malignancy evaluation. In addition, explanations of CDAM features proved that the shape and density of nodule regions were two critical factors that influence a nodule to be inferred as malignant, which conforms with the diagnosis cognition of experienced radiologists. Conclusion:Incorporating radiology analysis with nodule malignant evaluation, the network inference process conforms to the diagnostic procedure of radiologists and increases the confidence of evaluation results. Besides, model interpretation with CDAM features shed light on the regions which DNNs focus on when they estimate nodule malignancy probabilities.

</p>
</details>

<details><summary><b>BayesPerf: Minimizing Performance Monitoring Errors Using Bayesian Statistics</b>
<a href="https://arxiv.org/abs/2102.10837">arxiv:2102.10837</a>
&#x1F4C8; 5 <br>
<p>Subho S. Banerjee, Saurabh Jha, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer</p></summary>
<p>

**Abstract:** Hardware performance counters (HPCs) that measure low-level architectural and microarchitectural events provide dynamic contextual information about the state of the system. However, HPC measurements are error-prone due to non determinism (e.g., undercounting due to event multiplexing, or OS interrupt-handling behaviors). In this paper, we present BayesPerf, a system for quantifying uncertainty in HPC measurements by using a domain-driven Bayesian model that captures microarchitectural relationships between HPCs to jointly infer their values as probability distributions. We provide the design and implementation of an accelerator that allows for low-latency and low-power inference of the BayesPerf model for x86 and ppc64 CPUs. BayesPerf reduces the average error in HPC measurements from 40.1% to 7.6% when events are being multiplexed. The value of BayesPerf in real-time decision-making is illustrated with a simple example of scheduling of PCIe transfers.

</p>
</details>

<details><summary><b>Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation</b>
<a href="https://arxiv.org/abs/2102.10780">arxiv:2102.10780</a>
&#x1F4C8; 5 <br>
<p>Shaoxiong Feng, Xuancheng Ren, Kan Li, Xu Sun</p></summary>
<p>

**Abstract:** Neural dialogue models suffer from low-quality responses when interacted in practice, demonstrating difficulty in generalization beyond training data. Recently, knowledge distillation has been used to successfully regularize the student by transferring knowledge from the teacher. However, the teacher and the student are trained on the same dataset and tend to learn similar feature representations, whereas the most general knowledge should be found through differences. The finding of general knowledge is further hindered by the unidirectional distillation, as the student should obey the teacher and may discard some knowledge that is truly general but refuted by the teacher. To this end, we propose a novel training framework, where the learning of general knowledge is more in line with the idea of reaching consensus, i.e., finding common knowledge that is beneficial to different yet all datasets through diversified learning partners. Concretely, the training task is divided into a group of subtasks with the same number of students. Each student assigned to one subtask not only is optimized on the allocated subtask but also imitates multi-view feature representation aggregated from other students (i.e., student peers), which induces students to capture common knowledge among different subtasks and alleviates the over-fitting of students on the allocated subtasks. To further enhance generalization, we extend the unidirectional distillation to the bidirectional distillation that encourages the student and its student peers to co-evolve by exchanging complementary knowledge with each other. Empirical results and analysis demonstrate that our training framework effectively improves the model generalization without sacrificing training efficiency.

</p>
</details>

<details><summary><b>Learning Low-dimensional Manifolds for Scoring of Tissue Microarray Images</b>
<a href="https://arxiv.org/abs/2102.11396">arxiv:2102.11396</a>
&#x1F4C8; 4 <br>
<p>Donghui Yan, Jian Zou, Zhenpeng Li</p></summary>
<p>

**Abstract:** Tissue microarray (TMA) images have emerged as an important high-throughput tool for cancer study and the validation of biomarkers. Efforts have been dedicated to further improve the accuracy of TACOMA, a cutting-edge automatic scoring algorithm for TMA images. One major advance is due to deepTacoma, an algorithm that incorporates suitable deep representations of a group nature. Inspired by the recent advance in semi-supervised learning and deep learning, we propose mfTacoma to learn alternative deep representations in the context of TMA image scoring. In particular, mfTacoma learns the low-dimensional manifolds, a common latent structure in high dimensional data. Deep representation learning and manifold learning typically requires large data. By encoding deep representation of the manifolds as regularizing features, mfTacoma effectively leverages the manifold information that is potentially crude due to small data. Our experiments show that deep features by manifolds outperforms two alternatives -- deep features by linear manifolds with principal component analysis or by leveraging the group property.

</p>
</details>

<details><summary><b>Explore the Context: Optimal Data Collection for Context-Conditional Dynamics Models</b>
<a href="https://arxiv.org/abs/2102.11394">arxiv:2102.11394</a>
&#x1F4C8; 4 <br>
<p>Jan Achterhold, Joerg Stueckler</p></summary>
<p>

**Abstract:** In this paper, we learn dynamics models for parametrized families of dynamical systems with varying properties. The dynamics models are formulated as stochastic processes conditioned on a latent context variable which is inferred from observed transitions of the respective system. The probabilistic formulation allows us to compute an action sequence which, for a limited number of environment interactions, optimally explores the given system within the parametrized family. This is achieved by steering the system through transitions being most informative for the context variable. We demonstrate the effectiveness of our method for exploration on a non-linear toy-problem and two well-known reinforcement learning environments.

</p>
</details>

<details><summary><b>Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping</b>
<a href="https://arxiv.org/abs/2102.11343">arxiv:2102.11343</a>
&#x1F4C8; 4 <br>
<p>Prakhar Kaushik, Alex Gain, Adam Kortylewski, Alan Yuille</p></summary>
<p>

**Abstract:** Catastrophic forgetting in neural networks is a significant problem for continual learning. A majority of the current methods replay previous data during training, which violates the constraints of an ideal continual learning system. Additionally, current approaches that deal with forgetting ignore the problem of catastrophic remembering, i.e. the worsening ability to discriminate between data from different tasks. In our work, we introduce Relevance Mapping Networks (RMNs) which are inspired by the Optimal Overlap Hypothesis. The mappings reflects the relevance of the weights for the task at hand by assigning large weights to essential parameters. We show that RMNs learn an optimized representational overlap that overcomes the twin problem of catastrophic forgetting and remembering. Our approach achieves state-of-the-art performance across all common continual learning datasets, even significantly outperforming data replay methods while not violating the constraints for an ideal continual learning system. Moreover, RMNs retain the ability to detect data from new tasks in an unsupervised manner, thus proving their resilience against catastrophic remembering.

</p>
</details>

<details><summary><b>On the Effects of Quantisation on Model Uncertainty in Bayesian Neural Networks</b>
<a href="https://arxiv.org/abs/2102.11062">arxiv:2102.11062</a>
&#x1F4C8; 4 <br>
<p>Martin Ferianc, Partha Maji, Matthew Mattina, Miguel Rodrigues</p></summary>
<p>

**Abstract:** Bayesian neural networks (BNNs) are making significant progress in many research areas where decision-making needs to be accompanied by uncertainty estimation. Being able to quantify uncertainty while making decisions is essential for understanding when the model is over-/under-confident, and hence BNNs are attracting interest in safety-critical applications, such as autonomous driving, healthcare, and robotics. Nevertheless, BNNs have not been as widely used in industrial practice, mainly because of their increased memory and compute costs. In this work, we investigate quantisation of BNNs by compressing 32-bit floating-point weights and activations to their integer counterparts, that has already been successful in reducing the compute demand in standard pointwise neural networks. We study three types of quantised BNNs, we evaluate them under a wide range of different settings, and we empirically demonstrate that a uniform quantisation scheme applied to BNNs does not substantially decrease their quality of uncertainty estimation.

</p>
</details>

<details><summary><b>Approximation of dilation-based spatial relations to add structural constraints in neural networks</b>
<a href="https://arxiv.org/abs/2102.10923">arxiv:2102.10923</a>
&#x1F4C8; 4 <br>
<p>Mateus Riva, Pietro Gori, Florian Yger, Roberto Cesar, Isabelle Bloch</p></summary>
<p>

**Abstract:** Spatial relations between objects in an image have proved useful for structural object recognition. Structural constraints can act as regularization in neural network training, improving generalization capability with small datasets. Several relations can be modeled as a morphological dilation of a reference object with a structuring element representing the semantics of the relation, from which the degree of satisfaction of the relation between another object and the reference object can be derived. However, dilation is not differentiable, requiring an approximation to be used in the context of gradient-descent training of a network. We propose to approximate dilations using convolutions based on a kernel equal to the structuring element. We show that the proposed approximation, even if slightly less accurate than previous approximations, is definitely faster to compute and therefore more suitable for computationally intensive neural network applications.

</p>
</details>

<details><summary><b>A Fast Heuristic for Gateway Location in Wireless Backhaul of 5G Ultra-Dense Networks</b>
<a href="https://arxiv.org/abs/2103.08408">arxiv:2103.08408</a>
&#x1F4C8; 3 <br>
<p>Mital Raithatha, Aizaz U. Chaudhry, Roshdy H. M. Hafez, John W. Chinneck</p></summary>
<p>

**Abstract:** In 5G Ultra-Dense Networks, a distributed wireless backhaul is an attractive solution for forwarding traffic to the core. The macro-cell coverage area is divided into many small cells. A few of these cells are designated as gateways and are linked to the core by high-capacity fiber optic links. Each small cell is associated with one gateway and all small cells forward their traffic to their respective gateway through multi-hop mesh networks. We investigate the gateway location problem and show that finding near-optimal gateway locations improves the backhaul network capacity. An exact p-median integer linear program is formulated for comparison with our novel K-GA heuristic that combines a Genetic Algorithm (GA) with K-means clustering to find near-optimal gateway locations. We compare the performance of KGA with six other approaches in terms of average number of hops and backhaul network capacity at different node densities through extensive Monte Carlo simulations. All approaches are tested in various user distribution scenarios, including uniform distribution, bivariate Gaussian distribution, and cluster distribution. In all cases K-GA provides near-optimal results, achieving average number of hops and backhaul network capacity within 2% of optimal while saving an average of 95% of the execution time.

</p>
</details>

<details><summary><b>Bridging Breiman's Brook: From Algorithmic Modeling to Statistical Learning</b>
<a href="https://arxiv.org/abs/2102.12328">arxiv:2102.12328</a>
&#x1F4C8; 3 <br>
<p>Lucas Mentch, Giles Hooker</p></summary>
<p>

**Abstract:** In 2001, Leo Breiman wrote of a divide between "data modeling" and "algorithmic modeling" cultures. Twenty years later this division feels far more ephemeral, both in terms of assigning individuals to camps, and in terms of intellectual boundaries. We argue that this is largely due to the "data modelers" incorporating algorithmic methods into their toolbox, particularly driven by recent developments in the statistical understanding of Breiman's own Random Forest methods. While this can be simplistically described as "Breiman won", these same developments also expose the limitations of the prediction-first philosophy that he espoused, making careful statistical analysis all the more important. This paper outlines these exciting recent developments in the random forest literature which, in our view, occurred as a result of a necessary blending of the two ways of thinking Breiman originally described. We also ask what areas statistics and statisticians might currently overlook.

</p>
</details>

<details><summary><b>Neuroscience-Inspired Algorithms for the Predictive Maintenance of Manufacturing Systems</b>
<a href="https://arxiv.org/abs/2102.11450">arxiv:2102.11450</a>
&#x1F4C8; 3 <br>
<p>Arnav V. Malawade, Nathan D. Costa, Deepan Muthirayan, Pramod P. Khargonekar, Mohammad A. Al Faruque</p></summary>
<p>

**Abstract:** If machine failures can be detected preemptively, then maintenance and repairs can be performed more efficiently, reducing production costs. Many machine learning techniques for performing early failure detection using vibration data have been proposed; however, these methods are often power and data-hungry, susceptible to noise, and require large amounts of data preprocessing. Also, training is usually only performed once before inference, so they do not learn and adapt as the machine ages. Thus, we propose a method of performing online, real-time anomaly detection for predictive maintenance using Hierarchical Temporal Memory (HTM). Inspired by the human neocortex, HTMs learn and adapt continuously and are robust to noise. Using the Numenta Anomaly Benchmark, we empirically demonstrate that our approach outperforms state-of-the-art algorithms at preemptively detecting real-world cases of bearing failures and simulated 3D printer failures. Our approach achieves an average score of 64.71, surpassing state-of-the-art deep-learning (49.38) and statistical (61.06) methods.

</p>
</details>

<details><summary><b>MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch Optimization for Deployment Constrained Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.11448">arxiv:2102.11448</a>
&#x1F4C8; 3 <br>
<p>DiJia Su, Jason D. Lee, John M. Mulvey, H. Vincent Poor</p></summary>
<p>

**Abstract:** In many contemporary applications such as healthcare, finance, robotics, and recommendation systems, continuous deployment of new policies for data collection and online learning is either cost ineffective or impractical. We consider a setting that lies between pure offline reinforcement learning (RL) and pure online RL called deployment constrained RL in which the number of policy deployments for data sampling is limited. To solve this challenging task, we propose a new algorithmic learning framework called Model-based Uncertainty regularized and Sample Efficient Batch Optimization (MUSBO). Our framework discovers novel and high quality samples for each deployment to enable efficient data collection. During each offline training session, we bootstrap the policy update by quantifying the amount of uncertainty within our collected data. In the high support region (low uncertainty), we encourage our policy by taking an aggressive update. In the low support region (high uncertainty) when the policy bootstraps into the out-of-distribution region, we downweight it by our estimated uncertainty quantification. Experimental results show that MUSBO achieves state-of-the-art performance in the deployment constrained RL setting.

</p>
</details>

<details><summary><b>Parallelizing Legendre Memory Unit Training</b>
<a href="https://arxiv.org/abs/2102.11417">arxiv:2102.11417</a>
&#x1F4C8; 3 <br>
<p>Narsimha Chilkuri, Chris Eliasmith</p></summary>
<p>

**Abstract:** Recently, a new recurrent neural network (RNN) named the Legendre Memory Unit (LMU) was proposed and shown to achieve state-of-the-art performance on several benchmark datasets. Here we leverage the linear time-invariant (LTI) memory component of the LMU to construct a simplified variant that can be parallelized during training (and yet executed as an RNN during inference), thus overcoming a well known limitation of training RNNs on GPUs. We show that this reformulation that aids parallelizing, which can be applied generally to any deep network whose recurrent components are linear, makes training up to 200 times faster. Second, to validate its utility, we compare its performance against the original LMU and a variety of published LSTM and transformer networks on seven benchmarks, ranging from psMNIST to sentiment analysis to machine translation. We demonstrate that our models exhibit superior performance on all datasets, often using fewer parameters. For instance, our LMU sets a new state-of-the-art result on psMNIST, and uses half the parameters while outperforming DistilBERT and LSTM models on IMDB sentiment analysis.

</p>
</details>

<details><summary><b>Lightweight Combinational Machine Learning Algorithm for Sorting Canine Torso Radiographs</b>
<a href="https://arxiv.org/abs/2102.11385">arxiv:2102.11385</a>
&#x1F4C8; 3 <br>
<p>Masuda Akter Tonima, Fatemeh Esfahani, Austin Dehart, Youmin Zhang</p></summary>
<p>

**Abstract:** The veterinary field lacks automation in contrast to the tremendous technological advances made in the human medical field. Implementation of machine learning technology can shorten any step of the automation process. This paper explores these core concepts and starts with automation in sorting radiographs for canines by view and anatomy. This is achieved by developing a new lightweight algorithm inspired by AlexNet, Inception, and SqueezeNet. The proposed module proves to be lighter than SqueezeNet while maintaining accuracy higher than that of AlexNet, ResNet, DenseNet, and SqueezeNet.

</p>
</details>

<details><summary><b>Stratified Experience Replay: Correcting Multiplicity Bias in Off-Policy Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.11319">arxiv:2102.11319</a>
&#x1F4C8; 3 <br>
<p>Brett Daley, Cameron Hickert, Christopher Amato</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning (RL) methods rely on experience replay to approximate the minibatched supervised learning setting; however, unlike supervised learning where access to lots of training data is crucial to generalization, replay-based deep RL appears to struggle in the presence of extraneous data. Recent works have shown that the performance of Deep Q-Network (DQN) degrades when its replay memory becomes too large.
  This suggests that outdated experiences somehow impact the performance of deep RL, which should not be the case for off-policy methods like DQN. Consequently, we re-examine the motivation for sampling uniformly over a replay memory, and find that it may be flawed when using function approximation. We show that -- despite conventional wisdom -- sampling from the uniform distribution does not yield uncorrelated training samples and therefore biases gradients during training. Our theory prescribes a special non-uniform distribution to cancel this effect, and we propose a stratified sampling scheme to efficiently implement it.

</p>
</details>

<details><summary><b>You Only Compress Once: Optimal Data Compression for Estimating Linear Models</b>
<a href="https://arxiv.org/abs/2102.11297">arxiv:2102.11297</a>
&#x1F4C8; 3 <br>
<p>Jeffrey Wong, Eskil Forsell, Randall Lewis, Tobias Mao, Matthew Wardrop</p></summary>
<p>

**Abstract:** Linear models are used in online decision making, such as in machine learning, policy algorithms, and experimentation platforms. Many engineering systems that use linear models achieve computational efficiency through distributed systems and expert configuration. While there are strengths to this approach, it is still difficult to have an environment that enables researchers to interactively iterate and explore data and models, as well as leverage analytics solutions from the open source community. Consequently, innovation can be blocked.
  Conditionally sufficient statistics is a unified data compression and estimation strategy that is useful for the model development process, as well as the engineering deployment process. The strategy estimates linear models from compressed data without loss on the estimated parameters and their covariances, even when errors are autocorrelated within clusters of observations. Additionally, the compression preserves almost all interactions with the the original data, unlocking better productivity for both researchers and engineering systems.

</p>
</details>

<details><summary><b>Cognitively Aided Zero-Shot Automatic Essay Grading</b>
<a href="https://arxiv.org/abs/2102.11258">arxiv:2102.11258</a>
&#x1F4C8; 3 <br>
<p>Sandeep Mathias, Rudra Murthy, Diptesh Kanojia, Pushpak Bhattacharyya</p></summary>
<p>

**Abstract:** Automatic essay grading (AEG) is a process in which machines assign a grade to an essay written in response to a topic, called the prompt. Zero-shot AEG is when we train a system to grade essays written to a new prompt which was not present in our training data. In this paper, we describe a solution to the problem of zero-shot automatic essay grading, using cognitive information, in the form of gaze behaviour. Our experiments show that using gaze behaviour helps in improving the performance of AEG systems, especially when we provide a new essay written in response to a new prompt for scoring, by an average of almost 5 percentage points of QWK.

</p>
</details>

<details><summary><b>Image Captioning using Deep Stacked LSTMs, Contextual Word Embeddings and Data Augmentation</b>
<a href="https://arxiv.org/abs/2102.11237">arxiv:2102.11237</a>
&#x1F4C8; 3 <br>
<p>Sulabh Katiyar, Samir Kumar Borgohain</p></summary>
<p>

**Abstract:** Image Captioning, or the automatic generation of descriptions for images, is one of the core problems in Computer Vision and has seen considerable progress using Deep Learning Techniques. We propose to use Inception-ResNet Convolutional Neural Network as encoder to extract features from images, Hierarchical Context based Word Embeddings for word representations and a Deep Stacked Long Short Term Memory network as decoder, in addition to using Image Data Augmentation to avoid over-fitting. For data Augmentation, we use Horizontal and Vertical Flipping in addition to Perspective Transformations on the images. We evaluate our proposed methods with two image captioning frameworks- Encoder-Decoder and Soft Attention. Evaluation on widely used metrics have shown that our approach leads to considerable improvement in model performance.

</p>
</details>

<details><summary><b>Wider Vision: Enriching Convolutional Neural Networks via Alignment to External Knowledge Bases</b>
<a href="https://arxiv.org/abs/2102.11132">arxiv:2102.11132</a>
&#x1F4C8; 3 <br>
<p>Xuehao Liu, Sarah Jane Delany, Susan McKeever</p></summary>
<p>

**Abstract:** Deep learning models suffer from opaqueness. For Convolutional Neural Networks (CNNs), current research strategies for explaining models focus on the target classes within the associated training dataset. As a result, the understanding of hidden feature map activations is limited by the discriminative knowledge gleaned during training. The aim of our work is to explain and expand CNNs models via the mirroring or alignment of CNN to an external knowledge base. This will allow us to give a semantic context or label for each visual feature. We can match CNN feature activations to nodes in our external knowledge base. This supports knowledge-based interpretation of the features associated with model decisions. To demonstrate our approach, we build two separate graphs. We use an entity alignment method to align the feature nodes in a CNN with the nodes in a ConceptNet based knowledge graph. We then measure the proximity of CNN graph nodes to semantically meaningful knowledge base nodes. Our results show that in the aligned embedding space, nodes from the knowledge graph are close to the CNN feature nodes that have similar meanings, indicating that nodes from an external knowledge base can act as explanatory semantic references for features in the model. We analyse a variety of graph building methods in order to improve the results from our embedding space. We further demonstrate that by using hierarchical relationships from our external knowledge base, we can locate new unseen classes outside the CNN training set in our embeddings space, based on visual feature activations. This suggests that we can adapt our approach to identify unseen classes based on CNN feature activations. Our demonstrated approach of aligning a CNN with an external knowledge base paves the way to reason about and beyond the trained model, with future adaptations to explainable models and zero-shot learning.

</p>
</details>

<details><summary><b>User Factor Adaptation for User Embedding via Multitask Learning</b>
<a href="https://arxiv.org/abs/2102.11103">arxiv:2102.11103</a>
&#x1F4C8; 3 <br>
<p>Xiaolei Huang, Michael J. Paul, Robin Burke, Franck Dernoncourt, Mark Dredze</p></summary>
<p>

**Abstract:** Language varies across users and their interested fields in social media data: words authored by a user across his/her interests may have different meanings (e.g., cool) or sentiments (e.g., fast). However, most of the existing methods to train user embeddings ignore the variations across user interests, such as product and movie categories (e.g., drama vs. action). In this study, we treat the user interest as domains and empirically examine how the user language can vary across the user factor in three English social media datasets. We then propose a user embedding model to account for the language variability of user interests via a multitask learning framework. The model learns user language and its variations without human supervision. While existing work mainly evaluated the user embedding by extrinsic tasks, we propose an intrinsic evaluation via clustering and evaluate user embeddings by an extrinsic task, text classification. The experiments on the three English-language social media datasets show that our proposed approach can generally outperform baselines via adapting the user factor.

</p>
</details>

<details><summary><b>LightCAKE: A Lightweight Framework for Context-Aware Knowledge Graph Embedding</b>
<a href="https://arxiv.org/abs/2102.10826">arxiv:2102.10826</a>
&#x1F4C8; 3 <br>
<p>Zhiyuan Ning, Ziyue Qiao, Hao Dong, Yi Du, Yuanchun Zhou</p></summary>
<p>

**Abstract:** Knowledge graph embedding (KGE) models learn to project symbolic entities and relations into a continuous vector space based on the observed triplets. However, existing KGE models cannot make a proper trade-off between the graph context and the model complexity, which makes them still far from satisfactory. In this paper, we propose a lightweight framework named LightCAKE for context-aware KGE. LightCAKE explicitly models the graph context without introducing redundant trainable parameters, and uses an iterative aggregation strategy to integrate the context information into the entity/relation embeddings. As a generic framework, it can be used with many simple KGE models to achieve excellent results. Finally, extensive experiments on public benchmarks demonstrate the efficiency and effectiveness of our framework.

</p>
</details>

<details><summary><b>Decoupled and Memory-Reinforced Networks: Towards Effective Feature Learning for One-Step Person Search</b>
<a href="https://arxiv.org/abs/2102.10795">arxiv:2102.10795</a>
&#x1F4C8; 3 <br>
<p>Chuchu Han, Zhedong Zheng, Changxin Gao, Nong Sang, Yi Yang</p></summary>
<p>

**Abstract:** The goal of person search is to localize and match query persons from scene images. For high efficiency, one-step methods have been developed to jointly handle the pedestrian detection and identification sub-tasks using a single network. There are two major challenges in the current one-step approaches. One is the mutual interference between the optimization objectives of multiple sub-tasks. The other is the sub-optimal identification feature learning caused by small batch size when end-to-end training. To overcome these problems, we propose a decoupled and memory-reinforced network (DMRNet). Specifically, to reconcile the conflicts of multiple objectives, we simplify the standard tightly coupled pipelines and establish a deeply decoupled multi-task learning framework. Further, we build a memory-reinforced mechanism to boost the identification feature learning. By queuing the identification features of recently accessed instances into a memory bank, the mechanism augments the similarity pair construction for pairwise metric learning. For better encoding consistency of the stored features, a slow-moving average of the network is applied for extracting these features. In this way, the dual networks reinforce each other and converge to robust solution states. Experimentally, the proposed method obtains 93.2% and 46.9% mAP on CUHK-SYSU and PRW datasets, which exceeds all the existing one-step methods.

</p>
</details>

<details><summary><b>Universal Approximation Properties of Neural Networks for Energy-Based Physical Systems</b>
<a href="https://arxiv.org/abs/2102.11923">arxiv:2102.11923</a>
&#x1F4C8; 2 <br>
<p>Yuhan Chen, Takashi Matsubara, Takaharu Yaguchi</p></summary>
<p>

**Abstract:** In Hamiltonian mechanics and the Landau theory, many physical phenomena are modeled using energy. In this paper, we prove the universal approximation property of neural network models for such physical phenomena. We also discuss behaviors of the models for integrable Hamiltonian systems when the loss function does not vanish completely by applying the KAM theory.

</p>
</details>

<details><summary><b>Senone-aware Adversarial Multi-task Training for Unsupervised Child to Adult Speech Adaptation</b>
<a href="https://arxiv.org/abs/2102.11488">arxiv:2102.11488</a>
&#x1F4C8; 2 <br>
<p>Richeng Duan, Nancy F. Chen</p></summary>
<p>

**Abstract:** Acoustic modeling for child speech is challenging due to the high acoustic variability caused by physiological differences in the vocal tract. The dearth of publicly available datasets makes the task more challenging. In this work, we propose a feature adaptation approach by exploiting adversarial multi-task training to minimize acoustic mismatch at the senone (tied triphone states) level between adult and child speech and leverage large amounts of transcribed adult speech. We validate the proposed method on three tasks: child speech recognition, child pronunciation assessment, and child fluency score prediction. Empirical results indicate that our proposed approach consistently outperforms competitive baselines, achieving 7.7% relative error reduction on speech recognition and up to 25.2% relative gains on the evaluation tasks.

</p>
</details>

<details><summary><b>Structural Similarity of Boundary Conditions and an Efficient Local Search Algorithm for Goal Conflict Identification</b>
<a href="https://arxiv.org/abs/2102.11482">arxiv:2102.11482</a>
&#x1F4C8; 2 <br>
<p>Hongzhen Zhong, Hai Wan, Weilin Luo, Zhanhao Xiao, Jia Li, Biqing Fang</p></summary>
<p>

**Abstract:** In goal-oriented requirements engineering, goal conflict identification is of fundamental importance for requirements analysis. The task aims to find the feasible situations which make the goals diverge within the domain, called boundary conditions (BCs). However, the existing approaches for goal conflict identification fail to find sufficient BCs and general BCs which cover more combinations of circumstances. From the BCs found by these existing approaches, we have observed an interesting phenomenon that there are some pairs of BCs are similar in formula structure, which occurs frequently in the experimental cases. In other words, once a BC is found, a new BC may be discovered quickly by slightly changing the former. It inspires us to develop a local search algorithm named LOGION to find BCs, in which the structural similarity is captured by the neighborhood relation of formulae. Based on structural similarity, LOGION can find a lot of BCs in a short time. Moreover, due to the large number of BCs identified, it potentially selects more general BCs from them. By taking experiments on a set of cases, we show that LOGION effectively exploits the structural similarity of BCs. We also compare our algorithm against the two state-of-the-art approaches. The experimental results show that LOGION produces one order of magnitude more BCs than the state-of-the-art approaches and confirm that LOGION finds out more general BCs thanks to a large number of BCs.

</p>
</details>

<details><summary><b>Optimal Prediction Intervals for Macroeconomic Time Series Using Chaos and NSGA II</b>
<a href="https://arxiv.org/abs/2102.11427">arxiv:2102.11427</a>
&#x1F4C8; 2 <br>
<p>Vangala Sarveswararao, Vadlamani Ravi, Sheik Tanveer Ul Huq</p></summary>
<p>

**Abstract:** In a first-of-its-kind study, this paper proposes the formulation of constructing prediction intervals (PIs) in a time series as a bi-objective optimization problem and solves it with the help of Nondominated Sorting Genetic Algorithm (NSGA-II). We also proposed modeling the chaos present in the time series as a preprocessor in order to model the deterministic uncertainty present in the time series. Even though the proposed models are general in purpose, they are used here for quantifying the uncertainty in macroeconomic time series forecasting. Ideal PIs should be as narrow as possible while capturing most of the data points. Based on these two objectives, we formulated a bi-objective optimization problem to generate PIs in 2-stages, wherein reconstructing the phase space using Chaos theory (stage-1) is followed by generating optimal point prediction using NSGA-II and these point predictions are in turn used to obtain PIs (stage-2). We also proposed a 3-stage hybrid, wherein the 3rd stage invokes NSGA-II too in order to solve the problem of constructing PIs from the point prediction obtained in 2nd stage. The proposed models when applied to the macroeconomic time series, yielded better results in terms of both prediction interval coverage probability (PICP) and prediction interval average width (PIAW) compared to the state-of-the-art Lower Upper Bound Estimation Method (LUBE) with Gradient Descent (GD). The 3-stage model yielded better PICP compared to the 2-stage model but showed similar performance in PIAW with added computation cost of running NSGA-II second time.

</p>
</details>

<details><summary><b>MixUp Training Leads to Reduced Overfitting and Improved Calibration for the Transformer Architecture</b>
<a href="https://arxiv.org/abs/2102.11402">arxiv:2102.11402</a>
&#x1F4C8; 2 <br>
<p>Wancong Zhang, Ieshan Vaidya</p></summary>
<p>

**Abstract:** MixUp is a computer vision data augmentation technique that uses convex interpolations of input data and their labels to enhance model generalization during training. However, the application of MixUp to the natural language understanding (NLU) domain has been limited, due to the difficulty of interpolating text directly in the input space. In this study, we propose MixUp methods at the Input, Manifold, and sentence embedding levels for the transformer architecture, and apply them to finetune the BERT model for a diverse set of NLU tasks. We find that MixUp can improve model performance, as well as reduce test loss and model calibration error by up to 50%.

</p>
</details>

<details><summary><b>Direct-Search for a Class of Stochastic Min-Max Problems</b>
<a href="https://arxiv.org/abs/2102.11386">arxiv:2102.11386</a>
&#x1F4C8; 2 <br>
<p>Sotiris Anagnostidis, Aurelien Lucchi, Youssef Diouane</p></summary>
<p>

**Abstract:** Recent applications in machine learning have renewed the interest of the community in min-max optimization problems. While gradient-based optimization methods are widely used to solve such problems, there are however many scenarios where these techniques are not well-suited, or even not applicable when the gradient is not accessible. We investigate the use of direct-search methods that belong to a class of derivative-free techniques that only access the objective function through an oracle. In this work, we design a novel algorithm in the context of min-max saddle point games where one sequentially updates the min and the max player. We prove convergence of this algorithm under mild assumptions, where the objective of the max-player satisfies the Polyak-Łojasiewicz (PL) condition, while the min-player is characterized by a nonconvex objective. Our method only assumes dynamically adjusted accurate estimates of the oracle with a fixed probability. To the best of our knowledge, our analysis is the first one to address the convergence of a direct-search method for min-max objectives in a stochastic setting.

</p>
</details>

<details><summary><b>GELATO: Geometrically Enriched Latent Model for Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.11327">arxiv:2102.11327</a>
&#x1F4C8; 2 <br>
<p>Guy Tennenholtz, Nir Baram, Shie Mannor</p></summary>
<p>

**Abstract:** Offline reinforcement learning approaches can generally be divided to proximal and uncertainty-aware methods. In this work, we demonstrate the benefit of combining the two in a latent variational model. We impose a latent representation of states and actions and leverage its intrinsic Riemannian geometry to measure distance of latent samples to the data. Our proposed metrics measure both the quality of out of distribution samples as well as the discrepancy of examples in the data. We integrate our metrics in a model-based offline optimization framework, in which proximity and uncertainty can be carefully controlled. We illustrate the geodesics on a simple grid-like environment, depicting its natural inherent topology. Finally, we analyze our approach and improve upon contemporary offline RL benchmarks.

</p>
</details>

<details><summary><b>Softmax Policy Gradient Methods Can Take Exponential Time to Converge</b>
<a href="https://arxiv.org/abs/2102.11270">arxiv:2102.11270</a>
&#x1F4C8; 2 <br>
<p>Gen Li, Yuting Wei, Yuejie Chi, Yuantao Gu, Yuxin Chen</p></summary>
<p>

**Abstract:** The softmax policy gradient (PG) method, which performs gradient ascent under softmax policy parameterization, is arguably one of the de facto implementations of policy optimization in modern reinforcement learning. For $γ$-discounted infinite-horizon tabular Markov decision processes (MDPs), remarkable progress has recently been achieved towards establishing global convergence of softmax PG methods in finding a near-optimal policy. However, prior results fall short of delineating clear dependencies of convergence rates on salient parameters such as the cardinality of the state space $\mathcal{S}$ and the effective horizon $\frac{1}{1-γ}$, both of which could be excessively large. In this paper, we deliver a pessimistic message regarding the iteration complexity of softmax PG methods, despite assuming access to exact gradient computation. Specifically, we demonstrate that the softmax PG method with stepsize $η$ can take \[
  \frac{1}η |\mathcal{S}|^{2^{Ω\big(\frac{1}{1-γ}\big)}} ~\text{iterations} \] to converge, even in the presence of a benign policy initialization and an initial state distribution amenable to exploration (so that the distribution mismatch coefficient is not exceedingly large). This is accomplished by characterizing the algorithmic dynamics over a carefully-constructed MDP containing only three actions. Our exponential lower bound hints at the necessity of carefully adjusting update rules or enforcing proper regularization in accelerating PG methods.

</p>
</details>

<details><summary><b>Modeling Multi-Destination Trips with Sketch-Based Model</b>
<a href="https://arxiv.org/abs/2102.11252">arxiv:2102.11252</a>
&#x1F4C8; 2 <br>
<p>Michał Daniluk, Barbara Rychalska, Konrad Gołuchowski, Jacek Dąbrowski</p></summary>
<p>

**Abstract:** The recently proposed EMDE (Efficient Manifold Density Estimator) model achieves state of-the-art results in session-based recommendation. In this work we explore its application to Booking Data Challenge competition. The aim of the challenge is to make the best recommendation for the next destination of a user trip, based on dataset with millions of real anonymized accommodation reservations. We achieve 2nd place in this competition. First, we use Cleora - our graph embedding method - to represent cities as a directed graph and learn their vector representation. Next, we apply EMDE to predict the next user destination based on previously visited cities and some features associated with each trip. We release the source code at: https://github.com/Synerise/booking-challenge.

</p>
</details>

<details><summary><b>Federated $f$-Differential Privacy</b>
<a href="https://arxiv.org/abs/2102.11158">arxiv:2102.11158</a>
&#x1F4C8; 2 <br>
<p>Qinqing Zheng, Shuxiao Chen, Qi Long, Weijie J. Su</p></summary>
<p>

**Abstract:** Federated learning (FL) is a training paradigm where the clients collaboratively learn models by repeatedly sharing information without compromising much on the privacy of their local sensitive data. In this paper, we introduce federated $f$-differential privacy, a new notion specifically tailored to the federated setting, based on the framework of Gaussian differential privacy. Federated $f$-differential privacy operates on record level: it provides the privacy guarantee on each individual record of one client's data against adversaries. We then propose a generic private federated learning framework {PriFedSync} that accommodates a large family of state-of-the-art FL algorithms, which provably achieves federated $f$-differential privacy. Finally, we empirically demonstrate the trade-off between privacy guarantee and prediction performance for models trained by {PriFedSync} in computer vision tasks.

</p>
</details>

<details><summary><b>Comparative Fault Location Estimation by Using Image Processing in Mixed Transmission Lines</b>
<a href="https://arxiv.org/abs/2102.11085">arxiv:2102.11085</a>
&#x1F4C8; 2 <br>
<p>Serkan Budak, Bahadir Akbal</p></summary>
<p>

**Abstract:** The distance protection relays are used to determine the impedance based fault location according to the current and voltage magnitudes in the transmission lines. However, the fault location cannot be correctly detected in mixed transmission lines due to different characteristic impedance per unit length because the characteristic impedance of high voltage cable line is significantly different from overhead line. Thus, determinations of the fault section and location with the distance protection relays are difficult in the mixed transmission lines. In this study, 154 kV overhead transmission line and underground cable line are examined as the mixed transmission line for the distance protection relays. Phase to ground faults are created in the mixed transmission line. overhead line section and underground cable section are simulated by using PSCAD-EMTDC.The short circuit fault images are generated in the distance protection relay for the overhead transmission line and underground cable transmission line faults. The images include the R-X impedance diagram of the fault, and the R-X impedance diagram have been detected by applying image processing steps. Artificial neural network (ANN) and the regression methods are used for prediction of the fault location, and the results of image processing are used as the input parameters for the training process of ANN and the regression methods. The results of ANN and regression methods are compared to select the most suitable method at the end of this study for forecasting of the fault location in transmission lines.

</p>
</details>

<details><summary><b>Nonparametric adaptive active learning under local smoothness condition</b>
<a href="https://arxiv.org/abs/2102.11077">arxiv:2102.11077</a>
&#x1F4C8; 2 <br>
<p>Boris Ndjia Njike, Xavier Siebert</p></summary>
<p>

**Abstract:** Active learning is typically used to label data, when the labeling process is expensive. Several active learning algorithms have been theoretically proved to perform better than their passive counterpart. However, these algorithms rely on some assumptions, which themselves contain some specific parameters. This paper adresses the problem of adaptive active learning in a nonparametric setting with minimal assumptions. We present a novel algorithm that is valid under more general assumptions than the previously known algorithms, and that can moreover adapt to the parameters used in these assumptions. This allows us to work with a larger class of distributions, thereby avoiding to exclude important densities like gaussians. Our algorithm achieves a minimax rate of convergence, and therefore performs almost as well as the best known non-adaptive algorithms.

</p>
</details>

<details><summary><b>Debiased Kernel Methods</b>
<a href="https://arxiv.org/abs/2102.11076">arxiv:2102.11076</a>
&#x1F4C8; 2 <br>
<p>Rahul Singh</p></summary>
<p>

**Abstract:** I propose a practical procedure based on bias correction and sample splitting to calculate confidence intervals for functionals of generic kernel methods, i.e. nonparametric estimators learned in a reproducing kernel Hilbert space (RKHS). For example, an analyst may desire confidence intervals for functionals of kernel ridge regression. I propose a bias correction that mirrors kernel ridge regression. The framework encompasses (i) evaluations over discrete domains, (ii) derivatives over continuous domains, (iii) treatment effects of discrete treatments, and (iv) incremental treatment effects of continuous treatments. For the target quantity, whether it is (i)-(iv), I prove root-n consistency, Gaussian approximation, and semiparametric efficiency by finite sample arguments. I show that the classic assumptions of RKHS learning theory also imply inference.

</p>
</details>

<details><summary><b>Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2102.11010">arxiv:2102.11010</a>
&#x1F4C8; 2 <br>
<p>Ginevra Carbone, Guido Sanguinetti, Luca Bortolussi</p></summary>
<p>

**Abstract:** We consider the problem of the stability of saliency-based explanations of Neural Network predictions under adversarial attacks in a classification task. Saliency interpretations of deterministic Neural Networks are remarkably brittle even when the attacks fail, i.e. for attacks that do not change the classification label. We empirically show that interpretations provided by Bayesian Neural Networks are considerably more stable under adversarial perturbations. By leveraging recent results, we also provide a theoretical explanation of this result in terms of the geometry of adversarial attacks. Additionally, we discuss the stability of the interpretations of high level representations of the inputs in the internal layers of a Network. Our results not only confirm that Bayesian Neural Networks are more robust to adversarial attacks, but also demonstrate that Bayesian methods have the potential to provide more stable and interpretable assessments of Neural Network predictions.

</p>
</details>

<details><summary><b>Adaptive Multi-View ICA: Estimation of noise levels for optimal inference</b>
<a href="https://arxiv.org/abs/2102.10964">arxiv:2102.10964</a>
&#x1F4C8; 2 <br>
<p>Hugo Richard, Pierre Ablin, Aapo Hyvärinen, Alexandre Gramfort, Bertrand Thirion</p></summary>
<p>

**Abstract:** We consider a multi-view learning problem known as group independent component analysis (group ICA), where the goal is to recover shared independent sources from many views. The statistical modeling of this problem requires to take noise into account. When the model includes additive noise on the observations, the likelihood is intractable. By contrast, we propose Adaptive multiView ICA (AVICA), a noisy ICA model where each view is a linear mixture of shared independent sources with additive noise on the sources. In this setting, the likelihood has a tractable expression, which enables either direct optimization of the log-likelihood using a quasi-Newton method, or generalized EM. Importantly, we consider that the noise levels are also parameters that are learned from the data. This enables sources estimation with a closed-form Minimum Mean Squared Error (MMSE) estimator which weights each view according to its relative noise level. On synthetic data, AVICA yields better sources estimates than other group ICA methods thanks to its explicit MMSE estimator. On real magnetoencephalograpy (MEG) data, we provide evidence that the decomposition is less sensitive to sampling noise and that the noise variance estimates are biologically plausible. Lastly, on functional magnetic resonance imaging (fMRI) data, AVICA exhibits best performance in transferring information across views.

</p>
</details>

<details><summary><b>Learning Purified Feature Representations from Task-irrelevant Labels</b>
<a href="https://arxiv.org/abs/2102.10955">arxiv:2102.10955</a>
&#x1F4C8; 2 <br>
<p>Yinghui Li, Ruiyang Liu, Chen Wang, Li Yangning, Ning Ding, Hai-Tao Zheng</p></summary>
<p>

**Abstract:** Learning an empirically effective model with generalization using limited data is a challenging task for deep neural networks. In this paper, we propose a novel learning framework called PurifiedLearning to exploit task-irrelevant features extracted from task-irrelevant labels when training models on small-scale datasets. Particularly, we purify feature representations by using the expression of task-irrelevant information, thus facilitating the learning process of classification. Our work is built on solid theoretical analysis and extensive experiments, which demonstrate the effectiveness of PurifiedLearning. According to the theory we proved, PurifiedLearning is model-agnostic and doesn't have any restrictions on the model needed, so it can be combined with any existing deep neural networks with ease to achieve better performance. The source code of this paper will be available in the future for reproducibility.

</p>
</details>

<details><summary><b>Explainers in the Wild: Making Surrogate Explainers Robust to Distortions through Perception</b>
<a href="https://arxiv.org/abs/2102.10951">arxiv:2102.10951</a>
&#x1F4C8; 2 <br>
<p>Alexander Hepburn, Raul Santos-Rodriguez</p></summary>
<p>

**Abstract:** Explaining the decisions of models is becoming pervasive in the image processing domain, whether it is by using post-hoc methods or by creating inherently interpretable models. While the widespread use of surrogate explainers is a welcome addition to inspect and understand black-box models, assessing the robustness and reliability of the explanations is key for their success. Additionally, whilst existing work in the explainability field proposes various strategies to address this problem, the challenges of working with data in the wild is often overlooked. For instance, in image classification, distortions to images can not only affect the predictions assigned by the model, but also the explanation. Given a clean and a distorted version of an image, even if the prediction probabilities are similar, the explanation may still be different. In this paper we propose a methodology to evaluate the effect of distortions in explanations by embedding perceptual distances that tailor the neighbourhoods used to training surrogate explainers. We also show that by operating in this way, we can make the explanations more robust to distortions. We generate explanations for images in the Imagenet-C dataset and demonstrate how using a perceptual distances in the surrogate explainer creates more coherent explanations for the distorted and reference images.

</p>
</details>

<details><summary><b>Learning atrial fiber orientations and conductivity tensors from intracardiac maps using physics-informed neural networks</b>
<a href="https://arxiv.org/abs/2102.10863">arxiv:2102.10863</a>
&#x1F4C8; 2 <br>
<p>Thomas Grandits, Simone Pezzuto, Francisco Sahli Costabal, Paris Perdikaris, Thomas Pock, Gernot Plank, Rolf Krause</p></summary>
<p>

**Abstract:** Electroanatomical maps are a key tool in the diagnosis and treatment of atrial fibrillation. Current approaches focus on the activation times recorded. However, more information can be extracted from the available data. The fibers in cardiac tissue conduct the electrical wave faster, and their direction could be inferred from activation times. In this work, we employ a recently developed approach, called physics informed neural networks, to learn the fiber orientations from electroanatomical maps, taking into account the physics of the electrical wave propagation. In particular, we train the neural network to weakly satisfy the anisotropic eikonal equation and to predict the measured activation times. We use a local basis for the anisotropic conductivity tensor, which encodes the fiber orientation. The methodology is tested both in a synthetic example and for patient data. Our approach shows good agreement in both cases, with an RMSE of 2.2ms on the in-silico data and outperforming a state of the art method on the patient data. The results show a first step towards learning the fiber orientations from electroanatomical maps with physics-informed neural networks.

</p>
</details>

<details><summary><b>Residual-Aided End-to-End Learning of Communication System without Known Channel</b>
<a href="https://arxiv.org/abs/2102.10786">arxiv:2102.10786</a>
&#x1F4C8; 2 <br>
<p>Hao Jiang, Shuangkaisheng Bi, Linglong Dai</p></summary>
<p>

**Abstract:** Leveraging powerful deep learning techniques, the end-to-end (E2E) learning of communication system is able to outperform the classical communication system. Unfortunately, this communication system cannot be trained by deep learning without known channel. To deal with this problem, a generative adversarial network (GAN) based training scheme has been recently proposed to imitate the real channel. However, the gradient vanishing and overfitting problems of GAN will result in the serious performance degradation of E2E learning of communication system. To mitigate these two problems, we propose a residual aided GAN (RA-GAN) based training scheme in this paper. Particularly, inspired by the idea of residual learning, we propose a residual generator to mitigate the gradient vanishing problem by realizing a more robust gradient backpropagation. Moreover, to cope with the overfitting problem, we reconstruct the loss function for training by adding a regularizer, which limits the representation ability of RA-GAN. Simulation results show that the trained residual generator has better generation performance than the conventional generator, and the proposed RA-GAN based training scheme can achieve the near-optimal block error rate (BLER) performance with a negligible computational complexity increase in both the theoretical channel model and the ray-tracing based channel dataset.

</p>
</details>

<details><summary><b>Generalized Equivariance and Preferential Labeling for GNN Node Classification</b>
<a href="https://arxiv.org/abs/2102.11485">arxiv:2102.11485</a>
&#x1F4C8; 1 <br>
<p>Zeyu Sun, Wenjie Zhang, Lili Mou, Qihao Zhu, Yingfei Xiong, Lu Zhang</p></summary>
<p>

**Abstract:** Existing graph neural networks (GNNs) largely rely on node embeddings, which represent a node as a vector by its identity, type, or content. However, graphs with unattributed nodes widely exist in real-world applications (e.g., anonymized social networks). Previous GNNs either assign random labels to nodes (which introduces artefacts to the GNN) or assign one embedding to all nodes (which fails to explicitly distinguish one node from another). Further, when these GNNs are applied to unattributed node classification problems, they have an undesired equivariance property, which are fundamentally unable to address the data with multiple possible outputs. In this paper, we analyze the limitation of existing approaches to node classification problems. Inspired by our analysis, we propose a generalized equivariance property and a Preferential Labeling technique that satisfies the desired property asymptotically. Experimental results show that we achieve high performance in several unattributed node classification tasks.

</p>
</details>

<details><summary><b>Approximate Knowledge Graph Query Answering: From Ranking to Binary Classification</b>
<a href="https://arxiv.org/abs/2102.11389">arxiv:2102.11389</a>
&#x1F4C8; 1 <br>
<p>Ruud van Bakel, Teodor Aleksiev, Daniel Daza, Dimitrios Alivanistos, Michael Cochez</p></summary>
<p>

**Abstract:** Large, heterogeneous datasets are characterized by missing or even erroneous information. This is more evident when they are the product of community effort or automatic fact extraction methods from external sources, such as text. A special case of the aforementioned phenomenon can be seen in knowledge graphs, where this mostly appears in the form of missing or incorrect edges and nodes.
  Structured querying on such incomplete graphs will result in incomplete sets of answers, even if the correct entities exist in the graph, since one or more edges needed to match the pattern are missing. To overcome this problem, several algorithms for approximate structured query answering have been proposed. Inspired by modern Information Retrieval metrics, these algorithms produce a ranking of all entities in the graph, and their performance is further evaluated based on how high in this ranking the correct answers appear.
  In this work we take a critical look at this way of evaluation. We argue that performing a ranking-based evaluation is not sufficient to assess methods for complex query answering. To solve this, we introduce Message Passing Query Boxes (MPQB), which takes binary classification metrics back into use and shows the effect this has on the recently proposed query embedding method MPQE.

</p>
</details>

<details><summary><b>Sandwich Batch Normalization: A Drop-In Replacement for Feature Distribution Heterogeneity</b>
<a href="https://arxiv.org/abs/2102.11382">arxiv:2102.11382</a>
&#x1F4C8; 1 <br>
<p>Xinyu Gong, Wuyang Chen, Tianlong Chen, Zhangyang Wang</p></summary>
<p>

**Abstract:** We present Sandwich Batch Normalization (SaBN), a frustratingly easy improvement of Batch Normalization (BN) with only a few lines of code changes. SaBN is motivated by addressing the inherent feature distribution heterogeneity that one can be identified in many tasks, which can arise from data heterogeneity (multiple input domains) or model heterogeneity (dynamic architectures, model conditioning, etc.). Our SaBN factorizes the BN affine layer into one shared sandwich affine layer, cascaded by several parallel independent affine layers. Concrete analysis reveals that, during optimization, SaBN promotes balanced gradient norms while still preserving diverse gradient directions -- a property that many application tasks seem to favor. We demonstrate the prevailing effectiveness of SaBN as a drop-in replacement in four tasks: conditional image generation, neural architecture search (NAS), adversarial training, and arbitrary style transfer. Leveraging SaBN immediately achieves better Inception Score and FID on CIFAR-10 and ImageNet conditional image generation with three state-of-the-art GANs; boosts the performance of a state-of-the-art weight-sharing NAS algorithm significantly on NAS-Bench-201; substantially improves the robust and standard accuracies for adversarial defense; and produces superior arbitrary stylized results. We also provide visualizations and analysis to help understand why SaBN works. Codes are available at: https://github.com/VITA-Group/Sandwich-Batch-Normalization.

</p>
</details>

<details><summary><b>Quantitative photoacoustic oximetry imaging by multiple illumination learned spectral decoloring</b>
<a href="https://arxiv.org/abs/2102.11201">arxiv:2102.11201</a>
&#x1F4C8; 1 <br>
<p>Thomas Kirchner, Martin Frenz</p></summary>
<p>

**Abstract:** Significance: Quantitative measurement of blood oxygen saturation (sO$_2$) with photoacoustic (PA) imaging is one of the most sought after goals of quantitative PA imaging research due to its wide range of biomedical applications.
  Aim: A method for accurate and applicable real-time quantification of local sO$_2$ with PA imaging.
  Approach: We combine multiple illumination (MI) sensing with learned spectral decoloring (LSD); training on Monte Carlo simulations of spectrally colored absorbed energy spectra, in order to apply the trained models to real PA measurements. We validate our combined MI-LSD method on a highly reliable, reproducible and easily scalable phantom model, based on copper and nickel sulfate solutions.
  Results: With this sulfate model we see a consistently high estimation accuracy using MI-LSD, with median absolute estimation errors of 2.5 to 4.5 percentage points. We further find fewer outliers in MI-LSD estimates compared to LSD. Random forest regressors outperform previously reported neural network approaches. Conclusions: Random forest based MI-LSD is a promising method for accurate quantitative PA oximetry imaging.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for Dynamic Spectrum Sharing of LTE and NR</b>
<a href="https://arxiv.org/abs/2102.11176">arxiv:2102.11176</a>
&#x1F4C8; 1 <br>
<p>Ursula Challita, David Sandberg</p></summary>
<p>

**Abstract:** In this paper, a proactive dynamic spectrum sharing scheme between 4G and 5G systems is proposed. In particular, a controller decides on the resource split between NR and LTE every subframe while accounting for future network states such as high interference subframes and multimedia broadcast single frequency network (MBSFN) subframes. To solve this problem, a deep reinforcement learning (RL) algorithm based on Monte Carlo Tree Search (MCTS) is proposed. The introduced deep RL architecture is trained offline whereby the controller predicts a sequence of future states of the wireless access network by simulating hypothetical bandwidth splits over time starting from the current network state. The action sequence resulting in the best reward is then assigned. This is realized by predicting the quantities most directly relevant to planning, i.e., the reward, the action probabilities, and the value for each network state. Simulation results show that the proposed scheme is able to take actions while accounting for future states instead of being greedy in each subframe. The results also show that the proposed framework improves system-level performance.

</p>
</details>

<details><summary><b>Reinforcement Learning of the Prediction Horizon in Model Predictive Control</b>
<a href="https://arxiv.org/abs/2102.11122">arxiv:2102.11122</a>
&#x1F4C8; 1 <br>
<p>Eivind Bøhn, Sebastien Gros, Signe Moe, Tor Arne Johansen</p></summary>
<p>

**Abstract:** Model predictive control (MPC) is a powerful trajectory optimization control technique capable of controlling complex nonlinear systems while respecting system constraints and ensuring safe operation. The MPC's capabilities come at the cost of a high online computational complexity, the requirement of an accurate model of the system dynamics, and the necessity of tuning its parameters to the specific control application. The main tunable parameter affecting the computational complexity is the prediction horizon length, controlling how far into the future the MPC predicts the system response and thus evaluates the optimality of its computed trajectory. A longer horizon generally increases the control performance, but requires an increasingly powerful computing platform, excluding certain control applications.The performance sensitivity to the prediction horizon length varies over the state space, and this motivated the adaptive horizon model predictive control (AHMPC), which adapts the prediction horizon according to some criteria. In this paper we propose to learn the optimal prediction horizon as a function of the state using reinforcement learning (RL). We show how the RL learning problem can be formulated and test our method on two control tasks, showing clear improvements over the fixed horizon MPC scheme, while requiring only minutes of learning.

</p>
</details>

<details><summary><b>RCoNet: Deformable Mutual Information Maximization and High-order Uncertainty-aware Learning for Robust COVID-19 Detection</b>
<a href="https://arxiv.org/abs/2102.11099">arxiv:2102.11099</a>
&#x1F4C8; 1 <br>
<p>Shunjie Dong, Qianqian Yang, Yu Fu, Mei Tian, Cheng Zhuo</p></summary>
<p>

**Abstract:** The novel 2019 Coronavirus (COVID-19) infection has spread world widely and is currently a major healthcare challenge around the world. Chest Computed Tomography (CT) and X-ray images have been well recognized to be two effective techniques for clinical COVID-19 disease diagnoses. Due to faster imaging time and considerably lower cost than CT, detecting COVID-19 in chest X-ray (CXR) images is preferred for efficient diagnosis, assessment and treatment. However, considering the similarity between COVID-19 and pneumonia, CXR samples with deep features distributed near category boundaries are easily misclassified by the hyper-planes learned from limited training data. Moreover, most existing approaches for COVID-19 detection focus on the accuracy of prediction and overlook the uncertainty estimation, which is particularly important when dealing with noisy datasets. To alleviate these concerns, we propose a novel deep network named {\em RCoNet$^k_s$} for robust COVID-19 detection which employs {\em Deformable Mutual Information Maximization} (DeIM), {\em Mixed High-order Moment Feature} (MHMF) and {\em Multi-expert Uncertainty-aware Learning} (MUL). With DeIM, the mutual information (MI) between input data and the corresponding latent representations can be well estimated and maximized to capture compact and disentangled representational characteristics. Meanwhile, MHMF can fully explore the benefits of using high-order statistics and extract discriminative features of complex distributions in medical imaging. Finally, MUL creates multiple parallel dropout networks for each CXR image to evaluate uncertainty and thus prevent performance degradation caused by the noise in the data.

</p>
</details>

<details><summary><b>Determination of Fault Location in Transmission Lines with Image Processing and Artificial Neural Networks</b>
<a href="https://arxiv.org/abs/2102.11073">arxiv:2102.11073</a>
&#x1F4C8; 1 <br>
<p>Serkan Budak, Bahadir Akbal</p></summary>
<p>

**Abstract:** In order to transmit electrical energy in a continuous and quality manner, it is necessary to control it from the point of production to the point of consumption. Therefore, protection of transmission and distribution lines is essential at every stage from production to consumption. The main function of the protection relays in electrical installations should be deactivated as soon as possible in the event of short circuits in the system. The most important part of the system is energy transmission lines and distance protection relays that protect these lines. An accurate error location technique is required to make fast and efficient work. Transformer neutral point grounding in transmission lines affects the operation of the zero component current during the single phase to ground short circuit failure of a power system. Considering the relationship between the grounding system and protection systems, an appropriate grounding choice should be made. Artificial neural network (ANN) has been used in order to accurately locate short circuit faults in different grounding systems in transmission lines. Compared with support vector machines (SVM) for testing inside ANN The transmission line model is made in the PSCAD-EMTDC simulation program. Data sets were created by recording the image of the impedance change of the R-X impedance diagram of the distance protection relay in short circuit faults created in different grounding systems. The related focal points in the images are given as an introduction to different ANN models using feature extraction and image processing techniques and the ANN model with the highest fault location estimation accuracy was chosen.

</p>
</details>

<details><summary><b>Characterizing and Optimizing EDA Flows for the Cloud</b>
<a href="https://arxiv.org/abs/2102.10800">arxiv:2102.10800</a>
&#x1F4C8; 1 <br>
<p>Abdelrahman Hosny, Sherief Reda</p></summary>
<p>

**Abstract:** Cloud computing accelerates design space exploration in logic synthesis, and parameter tuning in physical design. However, deploying EDA jobs on the cloud requires EDA teams to deeply understand the characteristics of their jobs in cloud environments. Unfortunately, there has been little to no public information on these characteristics. Thus, in this paper, we formulate the problem of migrating EDA jobs to the cloud. First, we characterize the performance of four main EDA applications, namely: synthesis, placement, routing and static timing analysis. We show that different EDA jobs require different machine configurations. Second, using observations from our characterization, we propose a novel model based on Graph Convolutional Networks to predict the total runtime of a given application on different machine configurations. Our model achieves a prediction accuracy of 87%. Third, we develop a new formulation for optimizing cloud deployments in order to reduce deployment costs while meeting deadline constraints. We present a pseudo-polynomial optimal solution using a multi-choice knapsack mapping that reduces costs by 35.29%.

</p>
</details>

<details><summary><b>Weighted Graph Nodes Clustering via Gumbel Softmax</b>
<a href="https://arxiv.org/abs/2102.10775">arxiv:2102.10775</a>
&#x1F4C8; 1 <br>
<p>Deepak Bhaskar Acharya, Huaming Zhang</p></summary>
<p>

**Abstract:** Graph is a ubiquitous data structure in data science that is widely applied in social networks, knowledge representation graphs, recommendation systems, etc. When given a graph dataset consisting of one graph or more graphs, where the graphs are weighted in general, the first step is often to find clusters in the graphs. In this paper, we present some ongoing research results on graph clustering algorithms for clustering weighted graph datasets, which we name as Weighted Graph Node Clustering via Gumbel Softmax (WGCGS for short). We apply WGCGS on the Karate club weighted network dataset. Our experiments demonstrate that WGCGS can efficiently and effectively find clusters in the Karate club weighted network dataset. Our algorithm's effectiveness is demonstrated by (1) comparing the clustering result obtained from our algorithm and the given labels of the dataset; and (2) comparing various metrics between our clustering algorithm and other state-of-the-art graph clustering algorithms.

</p>
</details>

<details><summary><b>Believe The HiPe: Hierarchical Perturbation for Fast, Robust and Model-Agnostic Explanations</b>
<a href="https://arxiv.org/abs/2103.05108">arxiv:2103.05108</a>
&#x1F4C8; 0 <br>
<p>Jessica Cooper, Ognjen Arandjelović, David J Harrison</p></summary>
<p>

**Abstract:** Understanding the predictions made by Artificial Intelligence (AI) systems is becoming more and more important as deep learning models are used for increasingly complex and high-stakes tasks. Saliency mapping - an easily interpretable visual attribution method - is one important tool for this, but existing formulations are limited by either computational cost or architectural constraints. We therefore propose Hierarchical Perturbation, a very fast and completely model-agnostic method for explaining model predictions with robust saliency maps. Using standard benchmarks and datasets, we show that our saliency maps are of competitive or superior quality to those generated by existing model-agnostic methods - and are over 20X faster to compute.

</p>
</details>

<details><summary><b>Data Driven Testing of Cyber Physical Systems</b>
<a href="https://arxiv.org/abs/2102.11491">arxiv:2102.11491</a>
&#x1F4C8; 0 <br>
<p>Dmytro Humeniuk, Giuliano Antoniol, Foutse Khomh</p></summary>
<p>

**Abstract:** Consumer grade cyber-physical systems (CPS) are becoming an integral part of our life, automatizing and simplifying everyday tasks. Indeed, due to complex interactions between hardware, networking and software, developing and testing such systems is known to be a challenging task. Various quality assurance and testing strategies have been proposed. The most common approach for pre-deployment testing is to model the system and run simulations with models or software in the loop. In practice, most often, tests are run for a small number of simulations, which are selected based on the engineers' domain knowledge and experience. In this paper we propose an approach to automatically generate fault-revealing test cases for CPS. We have implemented our approach in Python, using standard frameworks and used it to generate scenarios violating temperature constraints for a smart thermostat implemented as a part of our IoT testbed. Data collected from an application managing a smart building have been used to learn models of the environment under ever changing conditions. The suggested approach allowed us to identify several pit-fails, scenarios (i.e., environment conditions and inputs), where the system behaves not as expected.

</p>
</details>

<details><summary><b>Histo-fetch -- On-the-fly processing of gigapixel whole slide images simplifies and speeds neural network training</b>
<a href="https://arxiv.org/abs/2102.11433">arxiv:2102.11433</a>
&#x1F4C8; 0 <br>
<p>Brendon Lutnick, Leema Krishna Murali, Brandon Ginley, Avi Z. Rosenberg, Pinaki Sarder</p></summary>
<p>

**Abstract:** We created a custom pipeline (histo-fetch) to efficiently extract random patches and labels from pathology whole slide images (WSIs) for input to a neural network on-the-fly. We prefetch these patches as needed during network training, avoiding the need for WSI preparation such as chopping/tiling. We demonstrate the utility of this pipeline to perform artificial stain transfer and image generation using the popular networks CycleGAN and ProGAN, respectively.

</p>
</details>

<details><summary><b>PrivateMail: Supervised Manifold Learning of Deep Features With Differential Privacy for Image Retrieval</b>
<a href="https://arxiv.org/abs/2102.10802">arxiv:2102.10802</a>
&#x1F4C8; 0 <br>
<p>Praneeth Vepakomma, Julia Balla, Ramesh Raskar</p></summary>
<p>

**Abstract:** Differential Privacy offers strong guarantees such as immutable privacy under post processing. Thus it is often looked to as a solution to learning on scattered and isolated data. This work focuses on supervised manifold learning, a paradigm that can generate fine-tuned manifolds for a target use case. Our contributions are two fold. 1) We present a novel differentially private method \textit{PrivateMail} for supervised manifold learning, the first of its kind to our knowledge. 2) We provide a novel private geometric embedding scheme for our experimental use case. We experiment on private "content based image retrieval" - embedding and querying the nearest neighbors of images in a private manner - and show extensive privacy-utility tradeoff results, as well as the computational efficiency and practicality of our methods.

</p>
</details>

<details><summary><b>Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning</b>
<a href="https://arxiv.org/abs/2102.10774">arxiv:2102.10774</a>
&#x1F4C8; 0 <br>
<p>Lanqing Li, Yuanhao Huang, Mingzhe Chen, Siteng Luo, Dijun Luo, Junzhou Huang</p></summary>
<p>

**Abstract:** Meta-learning for offline reinforcement learning (OMRL) is an understudied problem with tremendous potential impact by enabling RL algorithms in many real-world applications. A popular solution to the problem is to infer task identity as augmented state using a context-based encoder, for which efficient learning of robust task representations remains an open challenge. In this work, we provably improve upon one of the SOTA OMRL algorithms, FOCAL, by incorporating intra-task attention mechanism and inter-task contrastive learning objectives, to robustify task representation learning against sparse reward and distribution shift. Theoretical analysis and experiments are presented to demonstrate the superior performance and robustness of our end-to-end and model-free framework compared to prior algorithms across multiple meta-RL benchmarks.

</p>
</details>


{% endraw %}
Prev: [2021.02.21]({{ '/2021/02/21/2021.02.21.html' | relative_url }})  Next: [2021.02.23]({{ '/2021/02/23/2021.02.23.html' | relative_url }})