Prev: [2021.02.18]({{ '/2021/02/18/2021.02.18.html' | relative_url }})  Next: [2021.02.20]({{ '/2021/02/20/2021.02.20.html' | relative_url }})
{% raw %}
## Summary for 2021-02-19, created on 2021-12-24


<details><summary><b>Universal Approximation Theorem for Neural Networks</b>
<a href="https://arxiv.org/abs/2102.10993">arxiv:2102.10993</a>
&#x1F4C8; 50 <br>
<p>Takato Nishijima</p></summary>
<p>

**Abstract:** Is there any theoretical guarantee for the approximation ability of neural networks? The answer to this question is the "Universal Approximation Theorem for Neural Networks". This theorem states that a neural network is dense in a certain function space under an appropriate setting. This paper is a comprehensive explanation of the universal approximation theorem for feedforward neural networks, its approximation rate problem (the relation between the number of intermediate units and the approximation error), and Barron space in Japanese.

</p>
</details>

<details><summary><b>E(n) Equivariant Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2102.09844">arxiv:2102.09844</a>
&#x1F4C8; 45 <br>
<p>Victor Garcia Satorras, Emiel Hoogeboom, Max Welling</p></summary>
<p>

**Abstract:** This paper introduces a new model to learn graph neural networks equivariant to rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. In addition, whereas existing methods are limited to equivariance on 3 dimensional spaces, our model is easily scaled to higher-dimensional spaces. We demonstrate the effectiveness of our method on dynamical systems modelling, representation learning in graph autoencoders and predicting molecular properties.

</p>
</details>

<details><summary><b>Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction</b>
<a href="https://arxiv.org/abs/2102.10249">arxiv:2102.10249</a>
&#x1F4C8; 21 <br>
<p>Benfeng Xu, Quan Wang, Yajuan Lyu, Yong Zhu, Zhendong Mao</p></summary>
<p>

**Abstract:** Entities, as the essential elements in relation extraction tasks, exhibit certain structure. In this work, we formulate such structure as distinctive dependencies between mention pairs. We then propose SSAN, which incorporates these structural dependencies within the standard self-attention mechanism and throughout the overall encoding stage. Specifically, we design two alternative transformation modules inside each self-attention building block to produce attentive biases so as to adaptively regularize its attention flow. Our experiments demonstrate the usefulness of the proposed entity structure and the effectiveness of SSAN. It significantly outperforms competitive baselines, achieving new state-of-the-art results on three popular document-level relation extraction datasets. We further provide ablation and visualization to show how the entity structure guides the model for better relation extraction. Our code is publicly available.

</p>
</details>

<details><summary><b>Implicit Regularization in Tensor Factorization</b>
<a href="https://arxiv.org/abs/2102.09972">arxiv:2102.09972</a>
&#x1F4C8; 21 <br>
<p>Noam Razin, Asaf Maman, Nadav Cohen</p></summary>
<p>

**Abstract:** Recent efforts to unravel the mystery of implicit regularization in deep learning have led to a theoretical focus on matrix factorization -- matrix completion via linear neural network. As a step further towards practical deep learning, we provide the first theoretical analysis of implicit regularization in tensor factorization -- tensor completion via certain type of non-linear neural network. We circumvent the notorious difficulty of tensor problems by adopting a dynamical systems perspective, and characterizing the evolution induced by gradient descent. The characterization suggests a form of greedy low tensor rank search, which we rigorously prove under certain conditions, and empirically demonstrate under others. Motivated by tensor rank capturing the implicit regularization of a non-linear neural network, we empirically explore it as a measure of complexity, and find that it captures the essence of datasets on which neural networks generalize. This leads us to believe that tensor rank may pave way to explaining both implicit regularization in deep learning, and the properties of real-world data translating this implicit regularization to generalization.

</p>
</details>

<details><summary><b>Deep Latent Competition: Learning to Race Using Visual Control Policies in Latent Space</b>
<a href="https://arxiv.org/abs/2102.09812">arxiv:2102.09812</a>
&#x1F4C8; 20 <br>
<p>Wilko Schwarting, Tim Seyde, Igor Gilitschenski, Lucas Liebenwein, Ryan Sander, Sertac Karaman, Daniela Rus</p></summary>
<p>

**Abstract:** Learning competitive behaviors in multi-agent settings such as racing requires long-term reasoning about potential adversarial interactions. This paper presents Deep Latent Competition (DLC), a novel reinforcement learning algorithm that learns competitive visual control policies through self-play in imagination. The DLC agent imagines multi-agent interaction sequences in the compact latent space of a learned world model that combines a joint transition function with opponent viewpoint prediction. Imagined self-play reduces costly sample generation in the real world, while the latent representation enables planning to scale gracefully with observation dimensionality. We demonstrate the effectiveness of our algorithm in learning competitive behaviors on a novel multi-agent racing benchmark that requires planning from image observations. Code and videos available at https://sites.google.com/view/deep-latent-competition.

</p>
</details>

<details><summary><b>Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach</b>
<a href="https://arxiv.org/abs/2102.10242">arxiv:2102.10242</a>
&#x1F4C8; 10 <br>
<p>Haoming Jiang, Bo Dai, Mengjiao Yang, Tuo Zhao, Wei Wei</p></summary>
<p>

**Abstract:** Reliable automatic evaluation of dialogue systems under an interactive environment has long been overdue. An ideal environment for evaluating dialog systems, also known as the Turing test, needs to involve human interaction, which is usually not affordable for large-scale experiments. Though researchers have attempted to use metrics (e.g., perplexity, BLEU) in language generation tasks or some model-based reinforcement learning methods (e.g., self-play evaluation) for automatic evaluation, these methods only show a very weak correlation with the actual human evaluation in practice. To bridge such a gap, we propose a new framework named ENIGMA for estimating human evaluation scores based on recent advances of off-policy evaluation in reinforcement learning. ENIGMA only requires a handful of pre-collected experience data, and therefore does not involve human interaction with the target policy during the evaluation, making automatic evaluations feasible. More importantly, ENIGMA is model-free and agnostic to the behavior policies for collecting the experience data (see details in Section 2), which significantly alleviates the technical difficulties of modeling complex dialogue environments and human behaviors. Our experiments show that ENIGMA significantly outperforms existing methods in terms of correlation with human evaluation scores.

</p>
</details>

<details><summary><b>Learning to Persuade on the Fly: Robustness Against Ignorance</b>
<a href="https://arxiv.org/abs/2102.10156">arxiv:2102.10156</a>
&#x1F4C8; 7 <br>
<p>You Zu, Krishnamurthy Iyer, Haifeng Xu</p></summary>
<p>

**Abstract:** We study a repeated persuasion setting between a sender and a receiver, where at each time $t$, the sender observes a payoff-relevant state drawn independently and identically from an unknown prior distribution, and shares state information with the receiver, who then myopically chooses an action. As in the standard setting, the sender seeks to persuade the receiver into choosing actions that are aligned with the sender's preference by selectively sharing information about the state. However, in contrast to the standard models, the sender does not know the prior, and has to persuade while gradually learning the prior on the fly.
  We study the sender's learning problem of making persuasive action recommendations to achieve low regret against the optimal persuasion mechanism with the knowledge of the prior distribution. Our main positive result is an algorithm that, with high probability, is persuasive across all rounds and achieves $O(\sqrt{T\log T})$ regret, where $T$ is the horizon length. The core philosophy behind the design of our algorithm is to leverage robustness against the sender's ignorance of the prior. Intuitively, at each time our algorithm maintains a set of candidate priors, and chooses a persuasion scheme that is simultaneously persuasive for all of them. To demonstrate the effectiveness of our algorithm, we further prove that no algorithm can achieve regret better than $Î©(\sqrt{T})$, even if the persuasiveness requirements were significantly relaxed. Therefore, our algorithm achieves optimal regret for the sender's learning problem up to terms logarithmic in $T$.

</p>
</details>

<details><summary><b>Information-Theoretic Abstractions for Resource-Constrained Agents via Mixed-Integer Linear Programming</b>
<a href="https://arxiv.org/abs/2102.10015">arxiv:2102.10015</a>
&#x1F4C8; 7 <br>
<p>Daniel T. Larsson, Dipankar Maity, Panagiotis Tsiotras</p></summary>
<p>

**Abstract:** In this paper, a mixed-integer linear programming formulation for the problem of obtaining task-relevant, multi-resolution, graph abstractions for resource-constrained agents is presented. The formulation leverages concepts from information-theoretic signal compression, specifically the information bottleneck (IB) method, to pose a graph abstraction problem as an optimal encoder search over the space of multi-resolution trees. The abstractions emerge in a task-relevant manner as a function of agent information-processing constraints, and are not provided to the system a priori. We detail our formulation and show how the problem can be realized as an integer linear program. A non-trivial numerical example is presented to demonstrate the utility in employing our approach to obtain hierarchical tree abstractions for resource-limited agents.

</p>
</details>

<details><summary><b>An Algorithm for Stochastic and Adversarial Bandits with Switching Costs</b>
<a href="https://arxiv.org/abs/2102.09864">arxiv:2102.09864</a>
&#x1F4C8; 7 <br>
<p>ChloÃ© Rouyer, Yevgeny Seldin, NicolÃ² Cesa-Bianchi</p></summary>
<p>

**Abstract:** We propose an algorithm for stochastic and adversarial multiarmed bandits with switching costs, where the algorithm pays a price $Î»$ every time it switches the arm being played. Our algorithm is based on adaptation of the Tsallis-INF algorithm of Zimmert and Seldin (2021) and requires no prior knowledge of the regime or time horizon. In the oblivious adversarial setting it achieves the minimax optimal regret bound of $O\big((Î»K)^{1/3}T^{2/3} + \sqrt{KT}\big)$, where $T$ is the time horizon and $K$ is the number of arms. In the stochastically constrained adversarial regime, which includes the stochastic regime as a special case, it achieves a regret bound of $O\left(\big((Î»K)^{2/3} T^{1/3} + \ln T\big)\sum_{i \neq i^*} Î_i^{-1}\right)$, where $Î_i$ are the suboptimality gaps and $i^*$ is a unique optimal arm. In the special case of $Î»= 0$ (no switching costs), both bounds are minimax optimal within constants. We also explore variants of the problem, where switching cost is allowed to change over time. We provide experimental evaluation showing competitiveness of our algorithm with the relevant baselines in the stochastic, stochastically constrained adversarial, and adversarial regimes with fixed switching cost.

</p>
</details>

<details><summary><b>Probabilistic Generating Circuits</b>
<a href="https://arxiv.org/abs/2102.09768">arxiv:2102.09768</a>
&#x1F4C8; 7 <br>
<p>Honghua Zhang, Brendan Juba, Guy Van den Broeck</p></summary>
<p>

**Abstract:** Generating functions, which are widely used in combinatorics and probability theory, encode function values into the coefficients of a polynomial. In this paper, we explore their use as a tractable probabilistic model, and propose probabilistic generating circuits (PGCs) for their efficient representation. PGCs are strictly more expressive efficient than many existing tractable probabilistic models, including determinantal point processes (DPPs), probabilistic circuits (PCs) such as sum-product networks, and tractable graphical models. We contend that PGCs are not just a theoretical framework that unifies vastly different existing models, but also show great potential in modeling realistic data. We exhibit a simple class of PGCs that are not trivially subsumed by simple combinations of PCs and DPPs, and obtain competitive performance on a suite of density estimation benchmarks. We also highlight PGCs' connection to the theory of strongly Rayleigh distributions.

</p>
</details>

<details><summary><b>Neural Kalman Filtering</b>
<a href="https://arxiv.org/abs/2102.10021">arxiv:2102.10021</a>
&#x1F4C8; 6 <br>
<p>Beren Millidge, Alexander Tschantz, Anil Seth, Christopher Buckley</p></summary>
<p>

**Abstract:** The Kalman filter is a fundamental filtering algorithm that fuses noisy sensory data, a previous state estimate, and a dynamics model to produce a principled estimate of the current state. It assumes, and is optimal for, linear models and white Gaussian noise. Due to its relative simplicity and general effectiveness, the Kalman filter is widely used in engineering applications. Since many sensory problems the brain faces are, at their core, filtering problems, it is possible that the brain possesses neural circuitry that implements equivalent computations to the Kalman filter. The standard approach to Kalman filtering requires complex matrix computations that are unlikely to be directly implementable in neural circuits. In this paper, we show that a gradient-descent approximation to the Kalman filter requires only local computations with variance weighted prediction errors. Moreover, we show that it is possible under the same scheme to adaptively learn the dynamics model with a learning rule that corresponds directly to Hebbian plasticity. We demonstrate the performance of our method on a simple Kalman filtering task, and propose a neural implementation of the required equations.

</p>
</details>

<details><summary><b>Model-Invariant State Abstractions for Model-Based Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.09850">arxiv:2102.09850</a>
&#x1F4C8; 5 <br>
<p>Manan Tomar, Amy Zhang, Roberto Calandra, Matthew E. Taylor, Joelle Pineau</p></summary>
<p>

**Abstract:** Accuracy and generalization of dynamics models is key to the success of model-based reinforcement learning (MBRL). As the complexity of tasks increases, so does the sample inefficiency of learning accurate dynamics models. However, many complex tasks also exhibit sparsity in the dynamics, i.e., actions have only a local effect on the system dynamics. In this paper, we exploit this property with a causal invariance perspective in the single-task setting, introducing a new type of state abstraction called \textit{model-invariance}. Unlike previous forms of state abstractions, a model-invariance state abstraction leverages causal sparsity over state variables. This allows for compositional generalization to unseen states, something that non-factored forms of state abstractions cannot do. We prove that an optimal policy can be learned over this model-invariance state abstraction and show improved generalization in a simple toy domain. Next, we propose a practical method to approximately learn a model-invariant representation for complex domains and validate our approach by showing improved modelling performance over standard maximum likelihood approaches on challenging tasks, such as the MuJoCo-based Humanoid. Finally, within the MBRL setting we show strong performance gains with respect to sample efficiency across a host of other continuous control tasks.

</p>
</details>

<details><summary><b>VisuoSpatial Foresight for Physical Sequential Fabric Manipulation</b>
<a href="https://arxiv.org/abs/2102.09754">arxiv:2102.09754</a>
&#x1F4C8; 5 <br>
<p>Ryan Hoque, Daniel Seita, Ashwin Balakrishna, Aditya Ganapathi, Ajay Kumar Tanwani, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg</p></summary>
<p>

**Abstract:** Robotic fabric manipulation has applications in home robotics, textiles, senior care and surgery. Existing fabric manipulation techniques, however, are designed for specific tasks, making it difficult to generalize across different but related tasks. We build upon the Visual Foresight framework to learn fabric dynamics that can be efficiently reused to accomplish different sequential fabric manipulation tasks with a single goal-conditioned policy. We extend our earlier work on VisuoSpatial Foresight (VSF), which learns visual dynamics on domain randomized RGB images and depth maps simultaneously and completely in simulation. In this earlier work, we evaluated VSF on multi-step fabric smoothing and folding tasks against 5 baseline methods in simulation and on the da Vinci Research Kit (dVRK) surgical robot without any demonstrations at train or test time. A key finding was that depth sensing significantly improves performance: RGBD data yields an 80% improvement in fabric folding success rate in simulation over pure RGB data. In this work, we vary 4 components of VSF, including data generation, visual dynamics model, cost function, and optimization procedure. Results suggest that training visual dynamics models using longer, corner-based actions can improve the efficiency of fabric folding by 76% and enable a physical sequential fabric folding task that VSF could not previously perform with 90% reliability. Code, data, videos, and supplementary material are available at https://sites.google.com/view/fabric-vsf/.

</p>
</details>

<details><summary><b>A Projection Algorithm for the Unitary Weights</b>
<a href="https://arxiv.org/abs/2102.10052">arxiv:2102.10052</a>
&#x1F4C8; 4 <br>
<p>Hao-Yuan Chang</p></summary>
<p>

**Abstract:** Unitary neural networks are promising alternatives for solving the exploding and vanishing activation/gradient problem without the need for explicit normalization that reduces the inference speed. However, they often require longer training time due to the additional unitary constraints on their weight matrices. Here we show a novel algorithm using a backpropagation technique with Lie algebra for computing approximated unitary weights from their pre-trained, non-unitary counterparts. The unitary networks initialized with these approximations can reach the desired accuracies much faster, mitigating their training time penalties while maintaining inference speedups. Our approach will be instrumental in the adaptation of unitary networks, especially for those neural architectures where pre-trained weights are freely available.

</p>
</details>

<details><summary><b>Continual Learning from Synthetic Data for a Humanoid Exercise Robot</b>
<a href="https://arxiv.org/abs/2102.10034">arxiv:2102.10034</a>
&#x1F4C8; 4 <br>
<p>Nicolas Duczek, Matthias Kerzel, Stefan Wermter</p></summary>
<p>

**Abstract:** In order to detect and correct physical exercises, a Grow-When-Required Network (GWR) with recurrent connections, episodic memory and a novel subnode mechanism is developed in order to learn spatiotemporal relationships of body movements and poses. Once an exercise is performed, the information of pose and movement per frame is stored in the GWR. For every frame, the current pose and motion pair is compared against a predicted output of the GWR, allowing for feedback not only on the pose but also on the velocity of the motion. In a practical scenario, a physical exercise is performed by an expert like a physiotherapist and then used as a reference for a humanoid robot like Pepper to give feedback on a patient's execution of the same exercise. This approach, however, comes with two challenges. First, the distance from the humanoid robot and the position of the user in the camera's view of the humanoid robot have to be considered by the GWR as well, requiring a robustness against the user's positioning in the field of view of the humanoid robot. Second, since both the pose and motion are dependent on the body measurements of the original performer, the expert's exercise cannot be easily used as a reference. This paper tackles the first challenge by designing an architecture that allows for tolerances in translation and rotations regarding the center of the field of view. For the second challenge, we allow the GWR to grow online on incremental data. For evaluation, we created a novel exercise dataset with virtual avatars called the Virtual-Squat dataset. Overall, we claim that our novel architecture based on the GWR can use a learned exercise reference for different body variations through continual online learning, while preventing catastrophic forgetting, enabling for an engaging long-term human-robot interaction with a humanoid robot.

</p>
</details>

<details><summary><b>Approximation and Learning with Deep Convolutional Models: a Kernel Perspective</b>
<a href="https://arxiv.org/abs/2102.10032">arxiv:2102.10032</a>
&#x1F4C8; 4 <br>
<p>Alberto Bietti</p></summary>
<p>

**Abstract:** The empirical success of deep convolutional networks on tasks involving high-dimensional data such as images or audio suggests that they can efficiently approximate certain functions that are well-suited for such tasks. In this paper, we study this through the lens of kernel methods, by considering simple hierarchical kernels with two or three convolution and pooling layers, inspired by convolutional kernel networks. These achieve good empirical performance on standard vision datasets, while providing a simple enough description of the functional space to shed light on their inductive bias. We show that the RKHS consists of additive models of interaction terms between patches, and that its norm encourages structured spatial similarities between these terms through pooling layers. We then provide generalization bounds which illustrate how pooling yields improved sample complexity guarantees when the target function presents such regularities.

</p>
</details>

<details><summary><b>Instrumental Variable Value Iteration for Causal Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.09907">arxiv:2102.09907</a>
&#x1F4C8; 4 <br>
<p>Luofeng Liao, Zuyue Fu, Zhuoran Yang, Yixin Wang, Mladen Kolar, Zhaoran Wang</p></summary>
<p>

**Abstract:** In offline reinforcement learning (RL) an optimal policy is learnt solely from a priori collected observational data. However, in observational data, actions are often confounded by unobserved variables. Instrumental variables (IVs), in the context of RL, are the variables whose influence on the state variables are all mediated through the action. When a valid instrument is present, we can recover the confounded transition dynamics through observational data. We study a confounded Markov decision process where the transition dynamics admit an additive nonlinear functional form. Using IVs, we derive a conditional moment restriction (CMR) through which we can identify transition dynamics based on observational data. We propose a provably efficient IV-aided Value Iteration (IVVI) algorithm based on a primal-dual reformulation of CMR. To the best of our knowledge, this is the first provably efficient algorithm for instrument-aided offline RL.

</p>
</details>

<details><summary><b>A PAC-Bayes Analysis of Adversarial Robustness</b>
<a href="https://arxiv.org/abs/2102.11069">arxiv:2102.11069</a>
&#x1F4C8; 3 <br>
<p>Paul Viallard, Guillaume Vidot, Amaury Habrard, Emilie Morvant</p></summary>
<p>

**Abstract:** We propose the first general PAC-Bayesian generalization bounds for adversarial robustness, that estimate, at test time, how much a model will be invariant to imperceptible perturbations in the input. Instead of deriving a worst-case analysis of the risk of a hypothesis over all the possible perturbations, we leverage the PAC-Bayesian framework to bound the averaged risk on the perturbations for majority votes (over the whole class of hypotheses). Our theoretically founded analysis has the advantage to provide general bounds (i) that are valid for any kind of attacks (i.e., the adversarial attacks), (ii) that are tight thanks to the PAC-Bayesian framework, (iii) that can be directly minimized during the learning phase to obtain a robust model on different attacks at test time.

</p>
</details>

<details><summary><b>CDA: a Cost Efficient Content-based Multilingual Web Document Aligner</b>
<a href="https://arxiv.org/abs/2102.10246">arxiv:2102.10246</a>
&#x1F4C8; 3 <br>
<p>Thuy Vu, Alessandro Moschitti</p></summary>
<p>

**Abstract:** We introduce a Content-based Document Alignment approach (CDA), an efficient method to align multilingual web documents based on content in creating parallel training data for machine translation (MT) systems operating at the industrial level. CDA works in two steps: (i) projecting documents of a web domain to a shared multilingual space; then (ii) aligning them based on the similarity of their representations in such space. We leverage lexical translation models to build vector representations using TF-IDF. CDA achieves performance comparable with state-of-the-art systems in the WMT-16 Bilingual Document Alignment Shared Task benchmark while operating in multilingual space. Besides, we created two web-scale datasets to examine the robustness of CDA in an industrial setting involving up to 28 languages and millions of documents. The experiments show that CDA is robust, cost-effective, and is significantly superior in (i) processing large and noisy web data and (ii) scaling to new and low-resourced languages.

</p>
</details>

<details><summary><b>Generalization bounds for graph convolutional neural networks via Rademacher complexity</b>
<a href="https://arxiv.org/abs/2102.10234">arxiv:2102.10234</a>
&#x1F4C8; 3 <br>
<p>Shaogao Lv</p></summary>
<p>

**Abstract:** This paper aims at studying the sample complexity of graph convolutional networks (GCNs), by providing tight upper bounds of Rademacher complexity for GCN models with a single hidden layer. Under regularity conditions, theses derived complexity bounds explicitly depend on the largest eigenvalue of graph convolution filter and the degree distribution of the graph. Again, we provide a lower bound of Rademacher complexity for GCNs to show optimality of our derived upper bounds. Taking two commonly used examples as representatives, we discuss the implications of our results in designing graph convolution filters an graph distribution.

</p>
</details>

<details><summary><b>Hamiltonian-Driven Shadow Tomography of Quantum States</b>
<a href="https://arxiv.org/abs/2102.10132">arxiv:2102.10132</a>
&#x1F4C8; 3 <br>
<p>Hong-Ye Hu, Yi-Zhuang You</p></summary>
<p>

**Abstract:** Classical shadow tomography provides an efficient method for predicting functions of an unknown quantum state from a few measurements of the state. It relies on a unitary channel that efficiently scrambles the quantum information of the state to the measurement basis. Facing the challenge of realizing deep unitary circuits on near-term quantum devices, we explore the scenario in which the unitary channel can be shallow and is generated by a quantum chaotic Hamiltonian via time evolution. We provide an unbiased estimator of the density matrix for all ranges of the evolution time. We analyze the sample complexity of the Hamiltonian-driven shadow tomography. For Pauli observables, we find that it can be more efficient than the unitary-2-design-based shadow tomography in a sequence of intermediate time windows that range from an order-1 scrambling time to a time scale of $D^{1/6}$, given the Hilbert space dimension $D$. In particular, the efficiency of predicting diagonal Pauli observables is improved by a factor of $D$ without sacrificing the efficiency of predicting off-diagonal Pauli observables.

</p>
</details>

<details><summary><b>Image Classification using CNN for Traffic Signs in Pakistan</b>
<a href="https://arxiv.org/abs/2102.10130">arxiv:2102.10130</a>
&#x1F4C8; 3 <br>
<p>Abdul Azeem Sikander, Hamza Ali</p></summary>
<p>

**Abstract:** The autonomous automotive industry is one of the largest and most conventional projects worldwide, with many technology companies effectively designing and orienting their products towards automobile safety and accuracy. These products are performing very well over the roads in developed countries. But can fail in the first minute in an underdeveloped country because there is much difference between a developed country environment and an underdeveloped country environment. The following study proposed to train these Artificial intelligence models in environment space in an underdeveloped country like Pakistan. The proposed approach on image classification uses convolutional neural networks for image classification for the model. For model pre-training German traffic signs data set was selected then fine-tuned on Pakistan's dataset. The experimental setup showed the best results and accuracy from the previously conducted experiments. In this work to increase the accuracy, more dataset was collected to increase the size of images in every class in the data set. In the future, a low number of classes are required to be further increased where more images for traffic signs are required to be collected to get more accuracy on the training of the model over traffic signs of Pakistan's most used and popular roads motorway and national highway, whose traffic signs color, size, and shapes are different from common traffic signs.

</p>
</details>

<details><summary><b>Going beyond p-convolutions to learn grayscale morphological operators</b>
<a href="https://arxiv.org/abs/2102.10038">arxiv:2102.10038</a>
&#x1F4C8; 3 <br>
<p>Alexandre Kirszenberg, Guillaume Tochon, Elodie Puybareau, Jesus Angulo</p></summary>
<p>

**Abstract:** Integrating mathematical morphology operations within deep neural networks has been subject to increasing attention lately. However, replacing standard convolution layers with erosions or dilations is particularly challenging because the min and max operations are not differentiable. Relying on the asymptotic behavior of the counter-harmonic mean, p-convolutional layers were proposed as a possible workaround to this issue since they can perform pseudo-dilation or pseudo-erosion operations (depending on the value of their inner parameter p), and very promising results were reported. In this work, we present two new morphological layers based on the same principle as the p-convolutional layer while circumventing its principal drawbacks, and demonstrate their potential interest in further implementations within deep convolutional neural network architectures.

</p>
</details>

<details><summary><b>Analytics and Machine Learning in Vehicle Routing Research</b>
<a href="https://arxiv.org/abs/2102.10012">arxiv:2102.10012</a>
&#x1F4C8; 3 <br>
<p>Ruibin Bai, Xinan Chen, Zhi-Long Chen, Tianxiang Cui, Shuhui Gong, Wentao He, Xiaoping Jiang, Huan Jin, Jiahuan Jin, Graham Kendall, Jiawei Li, Zheng Lu, Jianfeng Ren, Paul Weng, Ning Xue, Huayan Zhang</p></summary>
<p>

**Abstract:** The Vehicle Routing Problem (VRP) is one of the most intensively studied combinatorial optimisation problems for which numerous models and algorithms have been proposed. To tackle the complexities, uncertainties and dynamics involved in real-world VRP applications, Machine Learning (ML) methods have been used in combination with analytical approaches to enhance problem formulations and algorithmic performance across different problem solving scenarios. However, the relevant papers are scattered in several traditional research fields with very different, sometimes confusing, terminologies. This paper presents a first, comprehensive review of hybrid methods that combine analytical techniques with ML tools in addressing VRP problems. Specifically, we review the emerging research streams on ML-assisted VRP modelling and ML-assisted VRP optimisation. We conclude that ML can be beneficial in enhancing VRP modelling, and improving the performance of algorithms for both online and offline VRP optimisations. Finally, challenges and future opportunities of VRP research are discussed.

</p>
</details>

<details><summary><b>Intrapapillary Capillary Loop Classification in Magnification Endoscopy: Open Dataset and Baseline Methodology</b>
<a href="https://arxiv.org/abs/2102.09963">arxiv:2102.09963</a>
&#x1F4C8; 3 <br>
<p>Luis C. Garcia-Peraza-Herrera, Martin Everson, Laurence Lovat, Hsiu-Po Wang, Wen Lun Wang, Rehan Haidry, Danail Stoyanov, Sebastien Ourselin, Tom Vercauteren</p></summary>
<p>

**Abstract:** Purpose. Early squamous cell neoplasia (ESCN) in the oesophagus is a highly treatable condition. Lesions confined to the mucosal layer can be curatively treated endoscopically. We build a computer-assisted detection (CADe) system that can classify still images or video frames as normal or abnormal with high diagnostic accuracy. Methods. We present a new benchmark dataset containing 68K binary labeled frames extracted from 114 patient videos whose imaged areas have been resected and correlated to histopathology. Our novel convolutional network (CNN) architecture solves the binary classification task and explains what features of the input domain drive the decision-making process of the network. Results. The proposed method achieved an average accuracy of 91.7 % compared to the 94.7 % achieved by a group of 12 senior clinicians. Our novel network architecture produces deeply supervised activation heatmaps that suggest the network is looking at intrapapillary capillary loop (IPCL) patterns when predicting abnormality. Conclusion. We believe that this dataset and baseline method may serve as a reference for future benchmarks on both video frame classification and explainability in the context of ESCN detection. A future work path of high clinical relevance is the extension of the classification to ESCN types.

</p>
</details>

<details><summary><b>A proof of convergence for gradient descent in the training of artificial neural networks for constant target functions</b>
<a href="https://arxiv.org/abs/2102.09924">arxiv:2102.09924</a>
&#x1F4C8; 3 <br>
<p>Patrick Cheridito, Arnulf Jentzen, Adrian Riekert, Florian Rossmannek</p></summary>
<p>

**Abstract:** Gradient descent optimization algorithms are the standard ingredients that are used to train artificial neural networks (ANNs). Even though a huge number of numerical simulations indicate that gradient descent optimization methods do indeed convergence in the training of ANNs, until today there is no rigorous theoretical analysis which proves (or disproves) this conjecture. In particular, even in the case of the most basic variant of gradient descent optimization algorithms, the plain vanilla gradient descent method, it remains an open problem to prove or disprove the conjecture that gradient descent converges in the training of ANNs. In this article we solve this problem in the special situation where the target function under consideration is a constant function. More specifically, in the case of constant target functions we prove in the training of rectified fully-connected feedforward ANNs with one-hidden layer that the risk function of the gradient descent method does indeed converge to zero. Our mathematical analysis strongly exploits the property that the rectifier function is the activation function used in the considered ANNs. A key contribution of this work is to explicitly specify a Lyapunov function for the gradient flow system of the ANN parameters. This Lyapunov function is the central tool in our convergence proof of the gradient descent method.

</p>
</details>

<details><summary><b>Back to Prior Knowledge: Joint Event Causality Extraction via Convolutional Semantic Infusion</b>
<a href="https://arxiv.org/abs/2102.09923">arxiv:2102.09923</a>
&#x1F4C8; 3 <br>
<p>Zijian Wang, Hao Wang, Xiangfeng Luo, Jianqi Gao</p></summary>
<p>

**Abstract:** Joint event and causality extraction is a challenging yet essential task in information retrieval and data mining. Recently, pre-trained language models (e.g., BERT) yield state-of-the-art results and dominate in a variety of NLP tasks. However, these models are incapable of imposing external knowledge in domain-specific extraction. Considering the prior knowledge of frequent n-grams that represent cause/effect events may benefit both event and causality extraction, in this paper, we propose convolutional knowledge infusion for frequent n-grams with different windows of length within a joint extraction framework. Knowledge infusion during convolutional filter initialization not only helps the model capture both intra-event (i.e., features in an event cluster) and inter-event (i.e., associations across event clusters) features but also boosts training convergence. Experimental results on the benchmark datasets show that our model significantly outperforms the strong BERT+CSNN baseline.

</p>
</details>

<details><summary><b>Intrinsically Motivated Open-Ended Multi-Task Learning Using Transfer Learning to Discover Task Hierarchy</b>
<a href="https://arxiv.org/abs/2102.09854">arxiv:2102.09854</a>
&#x1F4C8; 3 <br>
<p>Nicolas Duminy, Sao Mai Nguyen, Junshuai Zhu, Dominique Duhaut, Jerome Kerdreux</p></summary>
<p>

**Abstract:** In open-ended continuous environments, robots need to learn multiple parameterised control tasks in hierarchical reinforcement learning. We hypothesise that the most complex tasks can be learned more easily by transferring knowledge from simpler tasks, and faster by adapting the complexity of the actions to the task. We propose a task-oriented representation of complex actions, called procedures, to learn online task relationships and unbounded sequences of action primitives to control the different observables of the environment. Combining both goal-babbling with imitation learning, and active learning with transfer of knowledge based on intrinsic motivation, our algorithm self-organises its learning process. It chooses at any given time a task to focus on; and what, how, when and from whom to transfer knowledge. We show with a simulation and a real industrial robot arm, in cross-task and cross-learner transfer settings, that task composition is key to tackle highly complex tasks. Task decomposition is also efficiently transferred across different embodied learners and by active imitation, where the robot requests just a small amount of demonstrations and the adequate type of information. The robot learns and exploits task dependencies so as to learn tasks of every complexity.

</p>
</details>

<details><summary><b>Trends in Vehicle Re-identification Past, Present, and Future: A Comprehensive Review</b>
<a href="https://arxiv.org/abs/2102.09744">arxiv:2102.09744</a>
&#x1F4C8; 3 <br>
<p> Zakria, Jianhua Deng, Muhammad Saddam Khokhar, Muhammad Umar Aftab, Jingye Cai, Rajesh Kumar, Jay Kumar</p></summary>
<p>

**Abstract:** Vehicle Re-identification (re-id) over surveillance camera network with non-overlapping field of view is an exciting and challenging task in intelligent transportation systems (ITS). Due to its versatile applicability in metropolitan cities, it gained significant attention. Vehicle re-id matches targeted vehicle over non-overlapping views in multiple camera network. However, it becomes more difficult due to inter-class similarity, intra-class variability, viewpoint changes, and spatio-temporal uncertainty. In order to draw a detailed picture of vehicle re-id research, this paper gives a comprehensive description of the various vehicle re-id technologies, applicability, datasets, and a brief comparison of different methodologies. Our paper specifically focuses on vision-based vehicle re-id approaches, including vehicle appearance, license plate, and spatio-temporal characteristics. In addition, we explore the main challenges as well as a variety of applications in different domains. Lastly, a detailed comparison of current state-of-the-art methods performances over VeRi-776 and VehicleID datasets is summarized with future directions. We aim to facilitate future research by reviewing the work being done on vehicle re-id till to date.

</p>
</details>

<details><summary><b>GnetDet: Object Detection Optimized on a 224mW CNN Accelerator Chip at the Speed of 106FPS</b>
<a href="https://arxiv.org/abs/2103.15756">arxiv:2103.15756</a>
&#x1F4C8; 2 <br>
<p>Baohua Sun, Tao Zhang, Jiapeng Su, Hao Sha</p></summary>
<p>

**Abstract:** Object detection is widely used on embedded devices. With the wide availability of CNN (Convolutional Neural Networks) accelerator chips, the object detection applications are expected to run with low power consumption, and high inference speed. In addition, the CPU load is expected to be as low as possible for a CNN accelerator chip working as a co-processor with a host CPU. In this paper, we optimize the object detection model on the CNN accelerator chip by minimizing the CPU load. The resulting model is called GnetDet. The experimental result shows that the GnetDet model running on a 224mW chip achieves the speed of 106FPS with excellent accuracy.

</p>
</details>

<details><summary><b>nTreeClus: a Tree-based Sequence Encoder for Clustering Categorical Series</b>
<a href="https://arxiv.org/abs/2102.10252">arxiv:2102.10252</a>
&#x1F4C8; 2 <br>
<p>Hadi Jahanshahi, Mustafa Gokce Baydogan</p></summary>
<p>

**Abstract:** The overwhelming presence of categorical/sequential data in diverse domains emphasizes the importance of sequence mining. The challenging nature of sequences proves the need for continuing research to find a more accurate and faster approach providing a better understanding of their (dis)similarities. This paper proposes a new Model-based approach for clustering sequence data, namely nTreeClus. The proposed method deploys Tree-based Learners, k-mers, and autoregressive models for categorical time series, culminating with a novel numerical representation of the categorical sequences. Adopting this new representation, we cluster sequences, considering the inherent patterns in categorical time series. Accordingly, the model showed robustness to its parameter. Under different simulated scenarios, nTreeClus improved the baseline methods for various internal and external cluster validation metrics for up to 10.7% and 2.7%, respectively. The empirical evaluation using synthetic and real datasets, protein sequences, and categorical time series showed that nTreeClus is competitive or superior to most state-of-the-art algorithms.

</p>
</details>

<details><summary><b>Elastic Similarity Measures for Multivariate Time Series Classification</b>
<a href="https://arxiv.org/abs/2102.10231">arxiv:2102.10231</a>
&#x1F4C8; 2 <br>
<p>Ahmed Shifaz, Charlotte Pelletier, Francois Petitjean, Geoffrey I. Webb</p></summary>
<p>

**Abstract:** Elastic similarity measures are a class of similarity measures specifically designed to work with time series data. When scoring the similarity between two time series, they allow points that do not correspond in timestamps to be aligned. This can compensate for misalignments in the time axis of time series data, and for similar processes that proceed at variable and differing paces. Elastic similarity measures are widely used in machine learning tasks such as classification, clustering and outlier detection when using time series data.
  There is a multitude of research on various univariate elastic similarity measures. However, except for multivariate versions of the well known Dynamic Time Warping (DTW) there is a lack of work to generalise other similarity measures for multivariate cases. This paper adapts two existing strategies used in multivariate DTW, namely, Independent and Dependent DTW, to several commonly used elastic similarity measures.
  Using 23 datasets from the University of East Anglia (UEA) multivariate archive, for nearest neighbour classification, we demonstrate that each measure outperforms all others on at least one dataset and that there are datasets for which either the dependent versions of all measures are more accurate than their independent counterparts or vice versa. This latter finding suggests that these differences arise from a fundamental property of the data. We also show that an ensemble of such nearest neighbour classifiers is highly competitive with other state-of-the-art multivariate time series classifiers.

</p>
</details>

<details><summary><b>ALMA: Alternating Minimization Algorithm for Clustering Mixture Multilayer Network</b>
<a href="https://arxiv.org/abs/2102.10226">arxiv:2102.10226</a>
&#x1F4C8; 2 <br>
<p>Xing Fan, Marianna Pensky, Feng Yu, Teng Zhang</p></summary>
<p>

**Abstract:** The paper considers a Mixture Multilayer Stochastic Block Model (MMLSBM), where layers can be partitioned into groups of similar networks, and networks in each group are equipped with a distinct Stochastic Block Model. The goal is to partition the multilayer network into clusters of similar layers, and to identify communities in those layers. Jing et al. (2020) introduced the MMLSBM and developed a clustering methodology, TWIST, based on regularized tensor decomposition. The present paper proposes a different technique, an alternating minimization algorithm (ALMA), that aims at simultaneous recovery of the layer partition, together with estimation of the matrices of connection probabilities of the distinct layers. Compared to TWIST, ALMA achieves higher accuracy both theoretically and numerically.

</p>
</details>

<details><summary><b>Logarithmic Regret in Feature-based Dynamic Pricing</b>
<a href="https://arxiv.org/abs/2102.10221">arxiv:2102.10221</a>
&#x1F4C8; 2 <br>
<p>Jianyu Xu, Yu-Xiang Wang</p></summary>
<p>

**Abstract:** Feature-based dynamic pricing is an increasingly popular model of setting prices for highly differentiated products with applications in digital marketing, online sales, real estate and so on. The problem was formally studied as an online learning problem [Javanmard & Nazerzadeh, 2019] where a seller needs to propose prices on the fly for a sequence of $T$ products based on their features $x$ while having a small regret relative to the best -- "omniscient" -- pricing strategy she could have come up with in hindsight. We revisit this problem and provide two algorithms (EMLP and ONSP) for stochastic and adversarial feature settings, respectively, and prove the optimal $O(d\log{T})$ regret bounds for both. In comparison, the best existing results are $O\left(\min\left\{\frac{1}{Î»_{\min}^2}\log{T}, \sqrt{T}\right\}\right)$ and $O(T^{2/3})$ respectively, with $Î»_{\min}$ being the smallest eigenvalue of $\mathbb{E}[xx^T]$ that could be arbitrarily close to $0$. We also prove an $Î©(\sqrt{T})$ information-theoretic lower bound for a slightly more general setting, which demonstrates that "knowing-the-demand-curve" leads to an exponential improvement in feature-based dynamic pricing.

</p>
</details>

<details><summary><b>A High Performance, Low Complexity Algorithm for Multi-Player Bandits Without Collision Sensing Information</b>
<a href="https://arxiv.org/abs/2102.10200">arxiv:2102.10200</a>
&#x1F4C8; 2 <br>
<p>Cindy Trinh, Richard Combes</p></summary>
<p>

**Abstract:** Motivated by applications in cognitive radio networks, we consider the decentralized multi-player multi-armed bandit problem, without collision nor sensing information. We propose Randomized Selfish KL-UCB, an algorithm with very low computational complexity, inspired by the Selfish KL-UCB algorithm, which has been abandoned as it provably performs sub-optimally in some cases. We subject Randomized Selfish KL-UCB to extensive numerical experiments showing that it far outperforms state-of-the-art algorithms in almost all environments, sometimes by several orders of magnitude, and without the additional knowledge required by state-of-the-art algorithms. We also emphasize the potential of this algorithm for the more realistic dynamic setting, and support our claims with further experiments. We believe that the low complexity and high performance of Randomized Selfish KL-UCB makes it the most suitable for implementation in practical systems amongst known algorithms.

</p>
</details>

<details><summary><b>A theory of capacity and sparse neural encoding</b>
<a href="https://arxiv.org/abs/2102.10148">arxiv:2102.10148</a>
&#x1F4C8; 2 <br>
<p>Pierre Baldi, Roman Vershynin</p></summary>
<p>

**Abstract:** Motivated by biological considerations, we study sparse neural maps from an input layer to a target layer with sparse activity, and specifically the problem of storing $K$ input-target associations $(x,y)$, or memories, when the target vectors $y$ are sparse. We mathematically prove that $K$ undergoes a phase transition and that in general, and somewhat paradoxically, sparsity in the target layers increases the storage capacity of the map. The target vectors can be chosen arbitrarily, including in random fashion, and the memories can be both encoded and decoded by networks trained using local learning rules, including the simple Hebb rule. These results are robust under a variety of statistical assumptions on the data. The proofs rely on elegant properties of random polytopes and sub-gaussian random vector variables. Open problems and connections to capacity theories and polynomial threshold maps are discussed.

</p>
</details>

<details><summary><b>Output-Weighted Sampling for Multi-Armed Bandits with Extreme Payoffs</b>
<a href="https://arxiv.org/abs/2102.10085">arxiv:2102.10085</a>
&#x1F4C8; 2 <br>
<p>Yibo Yang, Antoine Blanchard, Themistoklis Sapsis, Paris Perdikaris</p></summary>
<p>

**Abstract:** We present a new type of acquisition functions for online decision making in multi-armed and contextual bandit problems with extreme payoffs. Specifically, we model the payoff function as a Gaussian process and formulate a novel type of upper confidence bound (UCB) acquisition function that guides exploration towards the bandits that are deemed most relevant according to the variability of the observed rewards. This is achieved by computing a tractable likelihood ratio that quantifies the importance of the output relative to the inputs and essentially acts as an \textit{attention mechanism} that promotes exploration of extreme rewards. We demonstrate the benefits of the proposed methodology across several synthetic benchmarks, as well as a realistic example involving noisy sensor network data. Finally, we provide a JAX library for efficient bandit optimization using Gaussian processes.

</p>
</details>

<details><summary><b>Hate-Alert@DravidianLangTech-EACL2021: Ensembling strategies for Transformer-based Offensive language Detection</b>
<a href="https://arxiv.org/abs/2102.10084">arxiv:2102.10084</a>
&#x1F4C8; 2 <br>
<p>Debjoy Saha, Naman Paharia, Debajit Chakraborty, Punyajoy Saha, Animesh Mukherjee</p></summary>
<p>

**Abstract:** Social media often acts as breeding grounds for different forms of offensive content. For low resource languages like Tamil, the situation is more complex due to the poor performance of multilingual or language-specific models and lack of proper benchmark datasets. Based on this shared task, Offensive Language Identification in Dravidian Languages at EACL 2021, we present an exhaustive exploration of different transformer models, We also provide a genetic algorithm technique for ensembling different models. Our ensembled models trained separately for each language secured the first position in Tamil, the second position in Kannada, and the first position in Malayalam sub-tasks. The models and codes are provided.

</p>
</details>

<details><summary><b>Sentiment Analysis for YouTube Comments in Roman Urdu</b>
<a href="https://arxiv.org/abs/2102.10075">arxiv:2102.10075</a>
&#x1F4C8; 2 <br>
<p>Tooba Tehreem</p></summary>
<p>

**Abstract:** Sentiment analysis is a vast area in the Machine learning domain. A lot of work is done on datasets and their analysis of the English Language. In Pakistan, a huge amount of data is in roman Urdu language, it is scattered all over the social sites including Twitter, YouTube, Facebook and similar applications. In this study the focus domain of dataset gathering is YouTube comments. The Dataset contains the comments of people over different Pakistani dramas and TV shows. The Dataset contains multi-class classification that is grouped The comments into positive, negative and neutral sentiment. In this Study comparative analysis is done for five supervised learning Algorithms including linear regression, SVM, KNN, Multi layer Perceptron and NaÃ¯ve Bayes classifier. Accuracy, recall, precision and F-measure are used for measuring performance. Results show that accuracy of SVM is 64 percent, which is better than the rest of the list.

</p>
</details>

<details><summary><b>Learning to Stop with Surprisingly Few Samples</b>
<a href="https://arxiv.org/abs/2102.10025">arxiv:2102.10025</a>
&#x1F4C8; 2 <br>
<p>Daniel Russo, Assaf Zeevi, Tianyi Zhang</p></summary>
<p>

**Abstract:** We consider a discounted infinite horizon optimal stopping problem. If the underlying distribution is known a priori, the solution of this problem is obtained via dynamic programming (DP) and is given by a well known threshold rule. When information on this distribution is lacking, a natural (though naive) approach is "explore-then-exploit," whereby the unknown distribution or its parameters are estimated over an initial exploration phase, and this estimate is then used in the DP to determine actions over the residual exploitation phase. We show: (i) with proper tuning, this approach leads to performance comparable to the full information DP solution; and (ii) despite common wisdom on the sensitivity of such "plug in" approaches in DP due to propagation of estimation errors, a surprisingly "short" (logarithmic in the horizon) exploration horizon suffices to obtain said performance. In cases where the underlying distribution is heavy-tailed, these observations are even more pronounced: a ${\it single \, sample}$ exploration phase suffices.

</p>
</details>

<details><summary><b>Resolving the Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information</b>
<a href="https://arxiv.org/abs/2102.10019">arxiv:2102.10019</a>
&#x1F4C8; 2 <br>
<p>Claire Lazar Reich</p></summary>
<p>

**Abstract:** Algorithmic risk assessments hold the promise of greatly advancing accurate decision-making, but in practice, multiple real-world examples have been shown to distribute errors disproportionately across demographic groups. In this paper, we characterize why error disparities arise in the first place. We show that predictive uncertainty often leads classifiers to systematically disadvantage groups with lower-mean outcomes, assigning them smaller true and false positive rates than their higher-mean counterparts. This can occur even when prediction is group-blind. We prove that to avoid these error imbalances, individuals in lower-mean groups must either be over-represented among positive classifications or be assigned more accurate predictions than those in higher-mean groups. We focus on the latter condition as a solution to bridge error rate divides and show that data acquisition for low-mean groups can increase access to opportunity. We call the strategy "affirmative information" and compare it to traditional affirmative action in the classification task of identifying creditworthy borrowers.

</p>
</details>

<details><summary><b>Discriminant Dynamic Mode Decomposition for Labeled Spatio-Temporal Data Collections</b>
<a href="https://arxiv.org/abs/2102.09973">arxiv:2102.09973</a>
&#x1F4C8; 2 <br>
<p>Naoya Takeishi, Keisuke Fujii, Koh Takeuchi, Yoshinobu Kawahara</p></summary>
<p>

**Abstract:** Extracting coherent patterns is one of the standard approaches towards understanding spatio-temporal data. Dynamic mode decomposition (DMD) is a powerful tool for extracting coherent patterns, but the original DMD and most of its variants do not consider label information, which is often available as side information of spatio-temporal data. In this work, we propose a new method for extracting distinctive coherent patterns from labeled spatio-temporal data collections, such that they contribute to major differences in a labeled set of dynamics. We achieve such pattern extraction by incorporating discriminant analysis into DMD. To this end, we define a kernel function on subspaces spanned by sets of dynamic modes and develop an objective to take both reconstruction goodness as DMD and class-separation goodness as discriminant analysis into account. We illustrate our method using a synthetic dataset and several real-world datasets. The proposed method can be a useful tool for exploratory data analysis for understanding spatio-temporal data.

</p>
</details>

<details><summary><b>Artificially Synthesising Data for Audio Classification and Segmentation to Improve Speech and Music Detection in Radio Broadcast</b>
<a href="https://arxiv.org/abs/2102.09959">arxiv:2102.09959</a>
&#x1F4C8; 2 <br>
<p>Satvik Venkatesh, David Moffat, Alexis Kirke, GÃ¶zel Shakeri, Stephen Brewster, JÃ¶rg Fachner, Helen Odell-Miller, Alex Street, Nicolas Farina, Sube Banerjee, Eduardo Reck Miranda</p></summary>
<p>

**Abstract:** Segmenting audio into homogeneous sections such as music and speech helps us understand the content of audio. It is useful as a pre-processing step to index, store, and modify audio recordings, radio broadcasts and TV programmes. Deep learning models for segmentation are generally trained on copyrighted material, which cannot be shared. Annotating these datasets is time-consuming and expensive and therefore, it significantly slows down research progress. In this study, we present a novel procedure that artificially synthesises data that resembles radio signals. We replicate the workflow of a radio DJ in mixing audio and investigate parameters like fade curves and audio ducking. We trained a Convolutional Recurrent Neural Network (CRNN) on this synthesised data and outperformed state-of-the-art algorithms for music-speech detection. This paper demonstrates the data synthesis procedure as a highly effective technique to generate large datasets to train deep neural networks for audio segmentation.

</p>
</details>

<details><summary><b>A Variance Controlled Stochastic Method with Biased Estimation for Faster Non-convex Optimization</b>
<a href="https://arxiv.org/abs/2102.09893">arxiv:2102.09893</a>
&#x1F4C8; 2 <br>
<p>Jia Bi, Steve R. Gunn</p></summary>
<p>

**Abstract:** In this paper, we proposed a new technique, {\em variance controlled stochastic gradient} (VCSG), to improve the performance of the stochastic variance reduced gradient (SVRG) algorithm. To avoid over-reducing the variance of gradient by SVRG, a hyper-parameter $Î»$ is introduced in VCSG that is able to control the reduced variance of SVRG. Theory shows that the optimization method can converge by using an unbiased gradient estimator, but in practice, biased gradient estimation can allow more efficient convergence to the vicinity since an unbiased approach is computationally more expensive. $Î»$ also has the effect of balancing the trade-off between unbiased and biased estimations. Secondly, to minimize the number of full gradient calculations in SVRG, a variance-bounded batch is introduced to reduce the number of gradient calculations required in each iteration. For smooth non-convex functions, the proposed algorithm converges to an approximate first-order stationary point (i.e. $\mathbb{E}\|\nabla{f}(x)\|^{2}\leqÎµ$) within $\mathcal{O}(min\{1/Îµ^{3/2},n^{1/4}/Îµ\})$ number of stochastic gradient evaluations, which improves the leading gradient complexity of stochastic gradient-based method SCS $(\mathcal{O}(min\{1/Îµ^{5/3},n^{2/3}/Îµ\})$. It is shown theoretically and experimentally that VCSG can be deployed to improve convergence.

</p>
</details>

<details><summary><b>Condensed Composite Memory Continual Learning</b>
<a href="https://arxiv.org/abs/2102.09890">arxiv:2102.09890</a>
&#x1F4C8; 2 <br>
<p>Felix Wiewel, Bin Yang</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) suffer from a rapid decrease in performance when trained on a sequence of tasks where only data of the most recent task is available. This phenomenon, known as catastrophic forgetting, prevents DNNs from accumulating knowledge over time. Overcoming catastrophic forgetting and enabling continual learning is of great interest since it would enable the application of DNNs in settings where unrestricted access to all the training data at any time is not always possible, e.g. due to storage limitations or legal issues. While many recently proposed methods for continual learning use some training examples for rehearsal, their performance strongly depends on the number of stored examples. In order to improve performance of rehearsal for continual learning, especially for a small number of stored examples, we propose a novel way of learning a small set of synthetic examples which capture the essence of a complete dataset. Instead of directly learning these synthetic examples, we learn a weighted combination of shared components for each example that enables a significant increase in memory efficiency. We demonstrate the performance of our method on commonly used datasets and compare it to recently proposed related methods and baselines.

</p>
</details>

<details><summary><b>SLPC: a VRNN-based approach for stochastic lidar prediction and completion in autonomous driving</b>
<a href="https://arxiv.org/abs/2102.09883">arxiv:2102.09883</a>
&#x1F4C8; 2 <br>
<p>George Eskandar, Alexander Braun, Martin Meinke, Karim Armanious, Bin Yang</p></summary>
<p>

**Abstract:** Predicting future 3D LiDAR pointclouds is a challenging task that is useful in many applications in autonomous driving such as trajectory prediction, pose forecasting and decision making. In this work, we propose a new LiDAR prediction framework that is based on generative models namely Variational Recurrent Neural Networks (VRNNs), titled Stochastic LiDAR Prediction and Completion (SLPC). Our algorithm is able to address the limitations of previous video prediction frameworks when dealing with sparse data by spatially inpainting the depth maps in the upcoming frames. Our contributions can thus be summarized as follows: we introduce the new task of predicting and completing depth maps from spatially sparse data, we present a sparse version of VRNNs and an effective self-supervised training method that does not require any labels. Experimental results illustrate the effectiveness of our framework in comparison to the state of the art methods in video prediction.

</p>
</details>

<details><summary><b>KBCNMUJAL@HASOC-Dravidian-CodeMix-FIRE2020: Using Machine Learning for Detection of Hate Speech and Offensive Code-Mixed Social Media text</b>
<a href="https://arxiv.org/abs/2102.09866">arxiv:2102.09866</a>
&#x1F4C8; 2 <br>
<p>Varsha Pathak, Manish Joshi, Prasad Joshi, Monica Mundada, Tanmay Joshi</p></summary>
<p>

**Abstract:** This paper describes the system submitted by our team, KBCNMUJAL, for Task 2 of the shared task Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC), at Forum for Information Retrieval Evaluation, December 16-20, 2020, Hyderabad, India. The datasets of two Dravidian languages Viz. Malayalam and Tamil of size 4000 observations, each were shared by the HASOC organizers. These datasets are used to train the machine using different machine learning algorithms, based on classification and regression models. The datasets consist of tweets or YouTube comments with two class labels offensive and not offensive. The machine is trained to classify such social media messages in these two categories. Appropriate n-gram feature sets are extracted to learn the specific characteristics of the Hate Speech text messages. These feature models are based on TFIDF weights of n-gram. The referred work and respective experiments show that the features such as word, character and combined model of word and character n-grams could be used to identify the term patterns of offensive text contents. As a part of the HASOC shared task, the test data sets are made available by the HASOC track organizers. The best performing classification models developed for both languages are applied on test datasets. The model which gives the highest accuracy result on training dataset for Malayalam language was experimented to predict the categories of respective test data. This system has obtained an F1 score of 0.77. Similarly the best performing model for Tamil language has obtained an F1 score of 0.87. This work has received 2nd and 3rd rank in this shared Task 2 for Malayalam and Tamil language respectively. The proposed system is named HASOC_kbcnmujal.

</p>
</details>

<details><summary><b>ISCL: Interdependent Self-Cooperative Learning for Unpaired Image Denoising</b>
<a href="https://arxiv.org/abs/2102.09858">arxiv:2102.09858</a>
&#x1F4C8; 2 <br>
<p>Kanggeun Lee, Won-Ki Jeong</p></summary>
<p>

**Abstract:** With the advent of advances in self-supervised learning, paired clean-noisy data are no longer required in deep learning-based image denoising. However, existing blind denoising methods still require the assumption with regard to noise characteristics, such as zero-mean noise distribution and pixel-wise noise-signal independence; this hinders wide adaptation of the method in the medical domain. On the other hand, unpaired learning can overcome limitations related to the assumption on noise characteristics, which makes it more feasible for collecting the training data in real-world scenarios. In this paper, we propose a novel image denoising scheme, Interdependent Self-Cooperative Learning (ISCL), that leverages unpaired learning by combining cyclic adversarial learning with self-supervised residual learning. Unlike the existing unpaired image denoising methods relying on matching data distributions in different domains, the two architectures in ISCL, designed for different tasks, complement each other and boost the learning process. To assess the performance of the proposed method, we conducted extensive experiments in various biomedical image degradation scenarios, such as noise caused by physical characteristics of electron microscopy (EM) devices (film and charging noise), and structural noise found in low-dose computer tomography (CT). We demonstrate that the image quality of our method is superior to conventional and current state-of-the-art deep learning-based image denoising methods, including supervised learning.

</p>
</details>

<details><summary><b>A GAN-Based Input-Size Flexibility Model for Single Image Dehazing</b>
<a href="https://arxiv.org/abs/2102.09796">arxiv:2102.09796</a>
&#x1F4C8; 2 <br>
<p>Shichao Kan, Yue Zhang, Fanghui Zhang, Yigang Cen</p></summary>
<p>

**Abstract:** Image-to-image translation based on generative adversarial network (GAN) has achieved state-of-the-art performance in various image restoration applications. Single image dehazing is a typical example, which aims to obtain the haze-free image of a haze one. This paper concentrates on the challenging task of single image dehazing. Based on the atmospheric scattering model, we design a novel model to directly generate the haze-free image. The main challenge of image dehazing is that the atmospheric scattering model has two parameters, i.e., transmission map and atmospheric light. When we estimate them respectively, the errors will be accumulated to compromise dehazing quality. Considering this reason and various image sizes, we propose a novel input-size flexibility conditional generative adversarial network (cGAN) for single image dehazing, which is input-size flexibility at both training and test stages for image-to-image translation with cGAN framework. We propose a simple and effective U-type residual network (UR-Net) to combine the generator and adopt the spatial pyramid pooling (SPP) to design the discriminator. Moreover, the model is trained with multi-loss function, in which the consistency loss is a novel designed loss in this paper. We finally build a multi-scale cGAN fusion model to realize state-of-the-art single image dehazing performance. The proposed models receive a haze image as input and directly output a haze-free one. Experimental results demonstrate the effectiveness and efficiency of the proposed models.

</p>
</details>

<details><summary><b>Hierarchical Recurrent Neural Networks for Conditional Melody Generation with Long-term Structure</b>
<a href="https://arxiv.org/abs/2102.09794">arxiv:2102.09794</a>
&#x1F4C8; 2 <br>
<p>Zixun Guo, Makris Dimos, Herremans Dorien</p></summary>
<p>

**Abstract:** The rise of deep learning technologies has quickly advanced many fields, including that of generative music systems. There exist a number of systems that allow for the generation of good sounding short snippets, yet, these generated snippets often lack an overarching, longer-term structure. In this work, we propose CM-HRNN: a conditional melody generation model based on a hierarchical recurrent neural network. This model allows us to generate melodies with long-term structures based on given chord accompaniments. We also propose a novel, concise event-based representation to encode musical lead sheets while retaining the notes' relative position within the bar with respect to the musical meter. With this new data representation, the proposed architecture can simultaneously model the rhythmic, as well as the pitch structures in an effective way. Melodies generated by the proposed model were extensively evaluated in quantitative experiments as well as a user study to ensure the musical quality of the output as well as to evaluate if they contain repeating patterns. We also compared the system with the state-of-the-art AttentionRNN. This comparison shows that melodies generated by CM-HRNN contain more repeated patterns (i.e., higher compression ratio) and a lower tonal tension (i.e., more tonally concise). Results from our listening test indicate that CM-HRNN outperforms AttentionRNN in terms of long-term structure and overall rating.

</p>
</details>

<details><summary><b>A Reinforcement Learning Approach to Age of Information in Multi-User Networks with HARQ</b>
<a href="https://arxiv.org/abs/2102.09774">arxiv:2102.09774</a>
&#x1F4C8; 2 <br>
<p>Elif Tugce Ceran, Deniz Gunduz, Andras Gyorgy</p></summary>
<p>

**Abstract:** Scheduling the transmission of time-sensitive information from a source node to multiple users over error-prone communication channels is studied with the goal of minimizing the long-term average age of information (AoI) at the users. A long-term average resource constraint is imposed on the source, which limits the average number of transmissions. The source can transmit only to a single user at each time slot, and after each transmission, it receives an instantaneous ACK/NACK feedback from the intended receiver, and decides when and to which user to transmit the next update. Assuming the channel statistics are known, the optimal scheduling policy is studied for both the standard automatic repeat request (ARQ) and hybrid ARQ (HARQ) protocols. Then, a reinforcement learning(RL) approach is introduced to find a near-optimal policy, which does not assume any a priori information on the random processes governing the channel states. Different RL methods including average-cost SARSAwith linear function approximation (LFA), upper confidence reinforcement learning (UCRL2), and deep Q-network (DQN) are applied and compared through numerical simulations

</p>
</details>

<details><summary><b>TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.09756">arxiv:2102.09756</a>
&#x1F4C8; 2 <br>
<p>Minchao Wu, Michael Norrish, Christian Walder, Amir Dezfouli</p></summary>
<p>

**Abstract:** We propose a novel approach to interactive theorem-proving (ITP) using deep reinforcement learning. The proposed framework is able to learn proof search strategies as well as tactic and arguments prediction in an end-to-end manner. We formulate the process of ITP as a Markov decision process (MDP) in which each state represents a set of potential derivation paths. This structure allows us to introduce a novel backtracking mechanism which enables the agent to efficiently discard (predicted) dead-end derivations and restart from promising alternatives. We implement the framework in the HOL4 theorem prover. Experimental results show that the framework outperforms existing automated theorem provers (i.e., hammers) available in HOL4 when evaluated on unseen problems. We further elaborate the role of key components of the framework using ablation studies.

</p>
</details>

<details><summary><b>Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?</b>
<a href="https://arxiv.org/abs/2102.11068">arxiv:2102.11068</a>
&#x1F4C8; 1 <br>
<p>Ning Liu, Geng Yuan, Zhengping Che, Xuan Shen, Xiaolong Ma, Qing Jin, Jian Ren, Jian Tang, Sijia Liu, Yanzhi Wang</p></summary>
<p>

**Abstract:** In deep model compression, the recent finding "Lottery Ticket Hypothesis" (LTH) (Frankle & Carbin, 2018) pointed out that there could exist a winning ticket (i.e., a properly pruned sub-network together with original weight initialization) that can achieve competitive performance than the original dense network. However, it is not easy to observe such winning property in many scenarios, where for example, a relatively large learning rate is used even if it benefits training the original dense model. In this work, we investigate the underlying condition and rationale behind the winning property, and find that the underlying reason is largely attributed to the correlation between initialized weights and final-trained weights when the learning rate is not sufficiently large. Thus, the existence of winning property is correlated with an insufficient DNN pretraining, and is unlikely to occur for a well-trained DNN. To overcome this limitation, we propose the "pruning & fine-tuning" method that consistently outperforms lottery ticket sparse training under the same pruning algorithm and the same total training epochs. Extensive experiments over multiple deep models (VGG, ResNet, MobileNet-v2) on different datasets have been conducted to justify our proposals.

</p>
</details>

<details><summary><b>CKNet: A Convolutional Neural Network Based on Koopman Operator for Modeling Latent Dynamics from Pixels</b>
<a href="https://arxiv.org/abs/2102.10205">arxiv:2102.10205</a>
&#x1F4C8; 1 <br>
<p>Yongqian Xiao, Xin Xu, QianLi Lin</p></summary>
<p>

**Abstract:** With the development of end-to-end control based on deep learning, it is important to study new system modeling techniques to realize dynamics modeling with high-dimensional inputs. In this paper, a novel Koopman-based deep convolutional network, called CKNet, is proposed to identify latent dynamics from raw pixels. CKNet learns an encoder and decoder to play the role of the Koopman eigenfunctions and modes, respectively. The Koopman eigenvalues can be approximated by eigenvalues of the learned state transition matrix. The deterministic convolutional Koopman network (DCKNet) and the variational convolutional Koopman network (VCKNet) are proposed to span some subspace for approximating the Koopman operator respectively. Because CKNet is trained under the constraints of the Koopman theory, the identified latent dynamics is in a linear form and has good interpretability. Besides, the state transition and control matrices are trained as trainable tensors so that the identified dynamics is also time-invariant. We also design an auxiliary weight term for reducing multi-step linearity and prediction losses. Experiments were conducted on two offline trained and four online trained nonlinear forced dynamical systems with continuous action spaces in Gym and Mujoco environment respectively, and the results show that identified dynamics are adequate for approximating the latent dynamics and generating clear images. Especially for offline trained cases, this work confirms CKNet from a novel perspective that we visualize the evolutionary processes of the latent states and the Koopman eigenfunctions with DCKNet and VCKNet separately to each task based on the same episode and results demonstrate that different approaches learn similar features in shapes.

</p>
</details>

<details><summary><b>Information-Theoretic Bounds for Integral Estimation</b>
<a href="https://arxiv.org/abs/2102.10199">arxiv:2102.10199</a>
&#x1F4C8; 1 <br>
<p>Donald Q. Adams, Adarsh Barik, Jean Honorio</p></summary>
<p>

**Abstract:** In this paper, we consider a zero-order stochastic oracle model of estimating definite integrals. In this model, integral estimation methods may query an oracle function for a fixed number of noisy values of the integrand function and use these values to produce an estimate of the integral. We first show that the information-theoretic error lower bound for estimating the integral of a $d$-dimensional function over a region with $l_\infty$ radius $r$ using at most $T$ queries to the oracle function is $Î©(2^d r^{d+1}\sqrt{d/T})$. Additionally, we find that the Gaussian Quadrature method under the same model achieves a rate of $O(2^{d}r^d/\sqrt{T})$ for functions with zero fourth and higher-order derivatives with respect to individual dimensions, and for Gaussian oracles, this rate is tight. For functions with nonzero fourth derivatives, the Gaussian Quadrature method achieves an upper bound which is not tight with the information-theoretic lower bound. Therefore, it is not minimax optimal, so there is space for the development of better integral estimation methods for such functions.

</p>
</details>

<details><summary><b>Co-clustering Vertices and Hyperedges via Spectral Hypergraph Partitioning</b>
<a href="https://arxiv.org/abs/2102.10169">arxiv:2102.10169</a>
&#x1F4C8; 1 <br>
<p>Yu Zhu, Boning Li, Santiago Segarra</p></summary>
<p>

**Abstract:** We propose a novel method to co-cluster the vertices and hyperedges of hypergraphs with edge-dependent vertex weights (EDVWs). In this hypergraph model, the contribution of every vertex to each of its incident hyperedges is represented through an edge-dependent weight, conferring the model higher expressivity than the classical hypergraph. In our method, we leverage random walks with EDVWs to construct a hypergraph Laplacian and use its spectral properties to embed vertices and hyperedges in a common space. We then cluster these embeddings to obtain our proposed co-clustering method, of particular relevance in applications requiring the simultaneous clustering of data entities and features. Numerical experiments using real-world data demonstrate the effectiveness of our proposed approach in comparison with state-of-the-art alternatives.

</p>
</details>

<details><summary><b>Spatial-temporal switching estimators for imaging locally concentrated dynamics</b>
<a href="https://arxiv.org/abs/2102.10167">arxiv:2102.10167</a>
&#x1F4C8; 1 <br>
<p>Parisa Karimi, Mark Butala, Zhizhen Zhao, Farzad Kamalabadi</p></summary>
<p>

**Abstract:** The evolution of images with physics-based dynamics is often spatially localized and nonlinear. A switching linear dynamic system (SLDS) is a natural model under which to pose such problems when the system's evolution randomly switches over the observation interval. Because of the high parameter space dimensionality, efficient and accurate recovery of the underlying state is challenging. The work presented in this paper focuses on the common cases where the dynamic evolution may be adequately modeled as a collection of decoupled, locally concentrated dynamic operators. Patch-based hybrid estimators are proposed for real-time reconstruction of images from noisy measurements given perfect or partial information about the underlying system dynamics. Numerical results demonstrate the effectiveness of the proposed approach for denoising in a realistic data-driven simulation of remotely sensed cloud dynamics.

</p>
</details>

<details><summary><b>Making a Case for Federated Learning in the Internet of Vehicles and Intelligent Transportation Systems</b>
<a href="https://arxiv.org/abs/2102.10142">arxiv:2102.10142</a>
&#x1F4C8; 1 <br>
<p>Dimitrios Michael Manias, Abdallah Shami</p></summary>
<p>

**Abstract:** With the incoming introduction of 5G networks and the advancement in technologies, such as Network Function Virtualization and Software Defined Networking, new and emerging networking technologies and use cases are taking shape. One such technology is the Internet of Vehicles (IoV), which describes an interconnected system of vehicles and infrastructure. Coupled with recent developments in artificial intelligence and machine learning, the IoV is transformed into an Intelligent Transportation System (ITS). There are, however, several operational considerations that hinder the adoption of ITS systems, including scalability, high availability, and data privacy. To address these challenges, Federated Learning, a collaborative and distributed intelligence technique, is suggested. Through an ITS case study, the ability of a federated model deployed on roadside infrastructure throughout the network to recover from faults by leveraging group intelligence while reducing recovery time and restoring acceptable system performance is highlighted. With a multitude of use cases and benefits, Federated Learning is a key enabler for ITS and is poised to achieve widespread implementation in 5G and beyond networks and applications.

</p>
</details>

<details><summary><b>A flow-based IDS using Machine Learning in eBPF</b>
<a href="https://arxiv.org/abs/2102.09980">arxiv:2102.09980</a>
&#x1F4C8; 1 <br>
<p>Maximilian Bachl, Joachim Fabini, Tanja Zseby</p></summary>
<p>

**Abstract:** eBPF is a new technology which allows dynamically loading pieces of code into the Linux kernel. It can greatly speed up networking since it enables the kernel to process certain packets without the involvement of a userspace program. So far eBPF has been used for simple packet filtering applications such as firewalls or Denial of Service protection. We show that it is possible to develop a flow based network intrusion detection system based on machine learning entirely in eBPF. Our solution uses a decision tree and decides for each packet whether it is malicious or not, considering the entire previous context of the network flow. We achieve a performance increase of over 20\% compared to the same solution implemented as a userspace program.

</p>
</details>

<details><summary><b>Deep Learning-based Beam Tracking for Millimeter-wave Communications under Mobility</b>
<a href="https://arxiv.org/abs/2102.09785">arxiv:2102.09785</a>
&#x1F4C8; 1 <br>
<p>Sun Hong Lim, Sunwoo Kim, Byonghyo Shim, Jun Won Choi</p></summary>
<p>

**Abstract:** In this paper, we propose a deep learning-based beam tracking method for millimeter-wave (mmWave)communications. Beam tracking is employed for transmitting the known symbols using the sounding beams and tracking time-varying channels to maintain a reliable communication link. When the pose of a user equipment (UE) device varies rapidly, the mmWave channels also tend to vary fast, which hinders seamless communication. Thus, models that can capture temporal behavior of mmWave channels caused by the motion of the device are required, to cope with this problem. Accordingly, we employa deep neural network to analyze the temporal structure and patterns underlying in the time-varying channels and the signals acquired by inertial sensors. We propose a model based on long short termmemory (LSTM) that predicts the distribution of the future channel behavior based on a sequence of input signals available at the UE. This channel distribution is used to 1) control the sounding beams adaptively for the future channel state and 2) update the channel estimate through the measurement update step under a sequential Bayesian estimation framework. Our experimental results demonstrate that the proposed method achieves a significant performance gain over the conventional beam tracking methods under various mobility scenarios.

</p>
</details>

<details><summary><b>Scaling Creative Inspiration with Fine-Grained Functional Facets of Ideas</b>
<a href="https://arxiv.org/abs/2102.09761">arxiv:2102.09761</a>
&#x1F4C8; 1 <br>
<p>Tom Hope, Ronen Tamari, Hyeonsu Kang, Daniel Hershcovich, Joel Chan, Aniket Kittur, Dafna Shahaf</p></summary>
<p>

**Abstract:** Large repositories of products, patents and scientific papers offer an opportunity for building systems that scour millions of ideas and help users discover inspirations. However, idea descriptions are typically in the form of unstructured text, lacking key structure that is required for supporting creative innovation interactions. Prior work has explored idea representations that were limited in expressivity, required significant manual effort from users, or dependent on curated knowledge bases with poor coverage. We explore a novel representation that automatically breaks up products into fine-grained functional facets capturing the purposes and mechanisms of ideas, and use it to support important creative innovation interactions: functional search for ideas, and exploration of the design space around a focal problem by viewing related problem perspectives pooled from across many products. In user studies, our approach boosts the quality of creative search and inspirations, outperforming strong baselines by 50-60%.

</p>
</details>

<details><summary><b>PRICURE: Privacy-Preserving Collaborative Inference in a Multi-Party Setting</b>
<a href="https://arxiv.org/abs/2102.09751">arxiv:2102.09751</a>
&#x1F4C8; 1 <br>
<p>Ismat Jarin, Birhanu Eshete</p></summary>
<p>

**Abstract:** When multiple parties that deal with private data aim for a collaborative prediction task such as medical image classification, they are often constrained by data protection regulations and lack of trust among collaborating parties. If done in a privacy-preserving manner, predictive analytics can benefit from the collective prediction capability of multiple parties holding complementary datasets on the same machine learning task. This paper presents PRICURE, a system that combines complementary strengths of secure multi-party computation (SMPC) and differential privacy (DP) to enable privacy-preserving collaborative prediction among multiple model owners. SMPC enables secret-sharing of private models and client inputs with non-colluding secure servers to compute predictions without leaking model parameters and inputs. DP masks true prediction results via noisy aggregation so as to deter a semi-honest client who may mount membership inference attacks. We evaluate PRICURE on neural networks across four datasets including benchmark medical image classification datasets. Our results suggest PRICURE guarantees privacy for tens of model owners and clients with acceptable accuracy loss. We also show that DP reduces membership inference attack exposure without hurting accuracy.

</p>
</details>

<details><summary><b>Autobots: Latent Variable Sequential Set Transformers</b>
<a href="https://arxiv.org/abs/2104.00563">arxiv:2104.00563</a>
&#x1F4C8; 0 <br>
<p>Roger Girgis, Florian Golemo, Felipe Codevilla, Jim Aldon D'Souza, Martin Weiss, Samira Ebrahimi Kahou, Felix Heide, Christopher Pal</p></summary>
<p>

**Abstract:** Robust multi-agent trajectory prediction is essential for the safe control of robots and vehicles that interact with humans. Many existing methods treat social and temporal information separately and therefore fall short of modelling the joint future trajectories of all agents in a socially consistent way. To address this, we propose a new class of Latent Variable Sequential Set Transformers which autoregressively model multi-agent trajectories. We refer to these architectures as "AutoBots". AutoBots model the contents of sets (e.g. representing the properties of agents in a scene) over time and employ multi-head self-attention blocks over these sequences of sets to encode the sociotemporal relationships between the different actors of a scene. This produces either the trajectory of one ego-agent or a distribution over the future trajectories for all agents under consideration. Our approach works for general sequences of sets and we provide illustrative experiments modelling the sequential structure of the multiple strokes that make up symbols in the Omniglot data. For the single-agent prediction case, we validate our model on the NuScenes motion prediction task and achieve competitive results on the global leaderboard. In the multi-agent forecasting setting, we validate our model on TrajNet. We find that our method outperforms physical extrapolation and recurrent network baselines and generates scene-consistent trajectories.

</p>
</details>

<details><summary><b>$FM^2$: Field-matrixed Factorization Machines for Recommender Systems</b>
<a href="https://arxiv.org/abs/2102.12994">arxiv:2102.12994</a>
&#x1F4C8; 0 <br>
<p>Yang Sun, Junwei Pan, Alex Zhang, Aaron Flores</p></summary>
<p>

**Abstract:** Click-through rate (CTR) prediction plays a critical role in recommender systems and online advertising. The data used in these applications are multi-field categorical data, where each feature belongs to one field. Field information is proved to be important and there are several works considering fields in their models. In this paper, we proposed a novel approach to model the field information effectively and efficiently. The proposed approach is a direct improvement of FwFM, and is named as Field-matrixed Factorization Machines (FmFM, or $FM^2$). We also proposed a new explanation of FM and FwFM within the FmFM framework, and compared it with the FFM. Besides pruning the cross terms, our model supports field-specific variable dimensions of embedding vectors, which acts as soft pruning. We also proposed an efficient way to minimize the dimension while keeping the model performance. The FmFM model can also be optimized further by caching the intermediate vectors, and it only takes thousands of floating-point operations (FLOPs) to make a prediction. Our experiment results show that it can out-perform the FFM, which is more complex. The FmFM model's performance is also comparable to DNN models which require much more FLOPs in runtime.

</p>
</details>

<details><summary><b>Linear Classifiers in Product Space Forms</b>
<a href="https://arxiv.org/abs/2102.10204">arxiv:2102.10204</a>
&#x1F4C8; 0 <br>
<p>Puoya Tabaghi, Eli Chien, Chao Pan, Jianhao Peng, Olgica MilenkoviÄ</p></summary>
<p>

**Abstract:** Embedding methods for product spaces are powerful techniques for low-distortion and low-dimensional representation of complex data structures. Nevertheless, little is known regarding downstream learning and optimization problems in such spaces. Here, we address the problem of linear classification in a product space form -- a mix of Euclidean, spherical, and hyperbolic spaces. First, we describe new formulations for linear classifiers on a Riemannian manifold using geodesics and Riemannian metrics which generalize straight lines and inner products in vector spaces, respectively. Second, we prove that linear classifiers in $d$-dimensional space forms of any curvature have the same expressive power, i.e., they can shatter exactly $d+1$ points. Third, we formalize linear classifiers in product space forms, describe the first corresponding perceptron and SVM classification algorithms, and establish rigorous convergence results for the former. We support our theoretical findings with simulation results on several datasets, including synthetic data, CIFAR-100, MNIST, Omniglot, and single-cell RNA sequencing data. The results show that learning methods applied to small-dimensional embeddings in product space forms outperform their algorithmic counterparts in each space form.

</p>
</details>

<details><summary><b>Quantifying Variational Approximation for the Log-Partition Function</b>
<a href="https://arxiv.org/abs/2102.10196">arxiv:2102.10196</a>
&#x1F4C8; 0 <br>
<p>Romain Cosson, Devavrat Shah</p></summary>
<p>

**Abstract:** Variational approximation, such as mean-field (MF) and tree-reweighted (TRW), provide a computationally efficient approximation of the log-partition function for a generic graphical model. TRW provably provides an upper bound, but the approximation ratio is generally not quantified.
  As the primary contribution of this work, we provide an approach to quantify the approximation ratio through the property of the underlying graph structure. Specifically, we argue that (a variant of) TRW produces an estimate that is within factor $\frac{1}{\sqrt{Îº(G)}}$ of the true log-partition function for any discrete pairwise graphical model over graph $G$, where $Îº(G) \in (0,1]$ captures how far $G$ is from tree structure with $Îº(G) = 1$ for trees and $2/N$ for the complete graph over $N$ vertices. As a consequence, the approximation ratio is $1$ for trees, $\sqrt{(d+1)/2}$ for any graph with maximum average degree $d$, and $\stackrel{Î²\to\infty}{\approx} 1+1/(2Î²)$ for graphs with girth (shortest cycle) at least $Î²\log N$. In general, $Îº(G)$ is the solution of a max-min problem associated with $G$ that can be evaluated in polynomial time for any graph.
  Using samples from the uniform distribution over the spanning trees of G, we provide a near linear-time variant that achieves an approximation ratio equal to the inverse of square-root of minimal (across edges) effective resistance of the graph. We connect our results to the graph partition-based approximation method and thus provide a unified perspective.
  Keywords: variational inference, log-partition function, spanning tree polytope, minimum effective resistance, min-max spanning tree, local inference

</p>
</details>

<details><summary><b>Deluca -- A Differentiable Control Library: Environments, Methods, and Benchmarking</b>
<a href="https://arxiv.org/abs/2102.09968">arxiv:2102.09968</a>
&#x1F4C8; 0 <br>
<p>Paula Gradu, John Hallman, Daniel Suo, Alex Yu, Naman Agarwal, Udaya Ghai, Karan Singh, Cyril Zhang, Anirudha Majumdar, Elad Hazan</p></summary>
<p>

**Abstract:** We present an open-source library of natively differentiable physics and robotics environments, accompanied by gradient-based control methods and a benchmark-ing suite. The introduced environments allow auto-differentiation through the simulation dynamics, and thereby permit fast training of controllers. The library features several popular environments, including classical control settings from OpenAI Gym. We also provide a novel differentiable environment, based on deep neural networks, that simulates medical ventilation. We give several use-cases of new scientific results obtained using the library. This includes a medical ventilator simulator and controller, an adaptive control method for time-varying linear dynamical systems, and new gradient-based methods for control of linear dynamical systems with adversarial perturbations.

</p>
</details>

<details><summary><b>Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss</b>
<a href="https://arxiv.org/abs/2102.09808">arxiv:2102.09808</a>
&#x1F4C8; 0 <br>
<p>Michael L. Iuzzolino, Michael C. Mozer, Samy Bengio</p></summary>
<p>

**Abstract:** Although deep feedforward neural networks share some characteristics with the primate visual system, a key distinction is their dynamics. Deep nets typically operate in serial stages wherein each layer completes its computation before processing begins in subsequent layers. In contrast, biological systems have cascaded dynamics: information propagates from neurons at all layers in parallel but transmission occurs gradually over time, leading to speed-accuracy trade offs even in feedforward architectures. We explore the consequences of biologically inspired parallel hardware by constructing cascaded ResNets in which each residual block has propagation delays but all blocks update in parallel in a stateful manner. Because information transmitted through skip connections avoids delays, the functional depth of the architecture increases over time, yielding anytime predictions that improve with internal-processing time. We introduce a temporal-difference training loss that achieves a strictly superior speed-accuracy profile over standard losses and enables the cascaded architecture to outperform state-of-the-art anytime-prediction methods. The cascaded architecture has intriguing properties, including: it classifies typical instances more rapidly than atypical instances; it is more robust to both persistent and transient noise than is a conventional ResNet; and its time-varying output trace provides a signal that can be exploited to improve information processing and inference.

</p>
</details>

<details><summary><b>Training Neural Networks is $\exists\mathbb R$-complete</b>
<a href="https://arxiv.org/abs/2102.09798">arxiv:2102.09798</a>
&#x1F4C8; 0 <br>
<p>Mikkel Abrahamsen, Linda Kleist, Tillmann Miltzow</p></summary>
<p>

**Abstract:** Given a neural network, training data, and a threshold, it was known that it is NP-hard to find weights for the neural network such that the total error is below the threshold. We determine the algorithmic complexity of this fundamental problem precisely, by showing that it is $\exists\mathbb R$-complete. This means that the problem is equivalent, up to polynomial-time reductions, to deciding whether a system of polynomial equations and inequalities with integer coefficients and real unknowns has a solution. If, as widely expected, $\exists\mathbb R$ is strictly larger than NP, our work implies that the problem of training neural networks is not even in NP.
  Neural networks are usually trained using some variation of backpropagation. The result of this paper offers an explanation why techniques commonly used to solve big instances of NP-complete problems seem not to be of use for this task. Examples of such techniques are SAT solvers, IP solvers, local search, dynamic programming, to name a few general ones.

</p>
</details>

<details><summary><b>Applications of deep learning in traffic congestion detection, prediction and alleviation: A survey</b>
<a href="https://arxiv.org/abs/2102.09759">arxiv:2102.09759</a>
&#x1F4C8; 0 <br>
<p>Nishant Kumar, Martin Raubal</p></summary>
<p>

**Abstract:** Detecting, predicting, and alleviating traffic congestion are targeted at improving the level of service of the transportation network. With increasing access to larger datasets of higher resolution, the relevance of deep learning for such tasks is increasing. Several comprehensive survey papers in recent years have summarised the deep learning applications in the transportation domain. However, the system dynamics of the transportation network vary greatly between the non-congested state and the congested state -- thereby necessitating the need for a clear understanding of the challenges specific to congestion prediction. In this survey, we present the current state of deep learning applications in the tasks related to detection, prediction, and alleviation of congestion. Recurring and non-recurring congestion are discussed separately. Our survey leads us to uncover inherent challenges and gaps in the current state of research. Finally, we present some suggestions for future research directions as answers to the identified challenges.

</p>
</details>


{% endraw %}
Prev: [2021.02.18]({{ '/2021/02/18/2021.02.18.html' | relative_url }})  Next: [2021.02.20]({{ '/2021/02/20/2021.02.20.html' | relative_url }})