Prev: [2022.08.29]({{ '/2022/08/29/2022.08.29.html' | relative_url }})  Next: [2022.08.31]({{ '/2022/08/31/2022.08.31.html' | relative_url }})
{% raw %}
## Summary for 2022-08-30, created on 2022-09-03


<details><summary><b>MeloForm: Generating Melody with Musical Form based on Expert Systems and Neural Networks</b>
<a href="https://arxiv.org/abs/2208.14345">arxiv:2208.14345</a>
&#x1F4C8; 39 <br>
<p>Peiling Lu, Xu Tan, Botao Yu, Tao Qin, Sheng Zhao, Tie-Yan Liu</p></summary>
<p>

**Abstract:** Human usually composes music by organizing elements according to the musical form to express music ideas. However, for neural network-based music generation, it is difficult to do so due to the lack of labelled data on musical form. In this paper, we develop MeloForm, a system that generates melody with musical form using expert systems and neural networks. Specifically, 1) we design an expert system to generate a melody by developing musical elements from motifs to phrases then to sections with repetitions and variations according to pre-given musical form; 2) considering the generated melody is lack of musical richness, we design a Transformer based refinement model to improve the melody without changing its musical form. MeloForm enjoys the advantages of precise musical form control by expert systems and musical richness learning via neural models. Both subjective and objective experimental evaluations demonstrate that MeloForm generates melodies with precise musical form control with 97.79% accuracy, and outperforms baseline systems in terms of subjective evaluation score by 0.75, 0.50, 0.86 and 0.89 in structure, thematic, richness and overall quality, without any labelled musical form data. Besides, MeloForm can support various kinds of forms, such as verse and chorus form, rondo form, variational form, sonata form, etc.

</p>
</details>

<details><summary><b>BioSLAM: A Bio-inspired Lifelong Memory System for General Place Recognition</b>
<a href="https://arxiv.org/abs/2208.14543">arxiv:2208.14543</a>
&#x1F4C8; 23 <br>
<p>Peng Yin, Abulikemu Abuduweili, Shiqi Zhao, Changliu Liu, Sebastian Scherer</p></summary>
<p>

**Abstract:** We present BioSLAM, a lifelong SLAM framework for learning various new appearances incrementally and maintaining accurate place recognition for previously visited areas. Unlike humans, artificial neural networks suffer from catastrophic forgetting and may forget the previously visited areas when trained with new arrivals. For humans, researchers discover that there exists a memory replay mechanism in the brain to keep the neuron active for previous events. Inspired by this discovery, BioSLAM designs a gated generative replay to control the robot's learning behavior based on the feedback rewards. Specifically, BioSLAM provides a novel dual-memory mechanism for maintenance: 1) a dynamic memory to efficiently learn new observations and 2) a static memory to balance new-old knowledge. When combined with a visual-/LiDAR- based SLAM system, the complete processing pipeline can help the agent incrementally update the place recognition ability, robust to the increasing complexity of long-term place recognition. We demonstrate BioSLAM in two incremental SLAM scenarios. In the first scenario, a LiDAR-based agent continuously travels through a city-scale environment with a 120km trajectory and encounters different types of 3D geometries (open streets, residential areas, commercial buildings). We show that BioSLAM can incrementally update the agent's place recognition ability and outperform the state-of-the-art incremental approach, Generative Replay, by 24%. In the second scenario, a LiDAR-vision-based agent repeatedly travels through a campus-scale area on a 4.5km trajectory. BioSLAM can guarantee the place recognition accuracy to outperform 15\% over the state-of-the-art approaches under different appearances. To our knowledge, BioSLAM is the first memory-enhanced lifelong SLAM system to help incremental place recognition in long-term navigation tasks.

</p>
</details>

<details><summary><b>Expressions Causing Differences in Emotion Recognition in Social Networking Service Documents</b>
<a href="https://arxiv.org/abs/2208.14244">arxiv:2208.14244</a>
&#x1F4C8; 19 <br>
<p>Tsubasa Nakagawa, Shunsuke Kitada, Hitoshi Iyatomi</p></summary>
<p>

**Abstract:** It is often difficult to correctly infer a writer's emotion from text exchanged online, and differences in recognition between writers and readers can be problematic. In this paper, we propose a new framework for detecting sentences that create differences in emotion recognition between the writer and the reader and for detecting the kinds of expressions that cause such differences. The proposed framework consists of a bidirectional encoder representations from transformers (BERT)-based detector that detects sentences causing differences in emotion recognition and an analysis that acquires expressions that characteristically appear in such sentences. The detector, based on a Japanese SNS-document dataset with emotion labels annotated by both the writer and three readers of the social networking service (SNS) documents, detected "hidden-anger sentences" with AUC = 0.772; these sentences gave rise to differences in the recognition of anger. Because SNS documents contain many sentences whose meaning is extremely difficult to interpret, by analyzing the sentences detected by this detector, we obtained several expressions that appear characteristically in hidden-anger sentences. The detected sentences and expressions do not convey anger explicitly, and it is difficult to infer the writer's anger, but if the implicit anger is pointed out, it becomes possible to guess why the writer is angry. Put into practical use, this framework would likely have the ability to mitigate problems based on misunderstandings.

</p>
</details>

<details><summary><b>Efficient Sparsely Activated Transformers</b>
<a href="https://arxiv.org/abs/2208.14580">arxiv:2208.14580</a>
&#x1F4C8; 7 <br>
<p>Salar Latifi, Saurav Muralidharan, Michael Garland</p></summary>
<p>

**Abstract:** Transformer-based neural networks have achieved state-of-the-art task performance in a number of machine learning domains including natural language processing and computer vision. To further improve their accuracy, recent work has explored the integration of dynamic behavior into these networks in the form of mixture-of-expert (MoE) layers. In this paper, we explore the introduction of MoE layers to optimize a different metric: inference latency. We introduce a novel system named PLANER that takes an existing Transformer-based network and a user-defined latency target and produces an optimized, sparsely-activated version of the original network that tries to meet the latency target while maintaining baseline accuracy. We evaluate PLANER on two real-world language modeling tasks using the Transformer-XL network and achieve inference latency reductions of over 2x at iso-accuracy.

</p>
</details>

<details><summary><b>Modeling Volatility and Dependence of European Carbon and Energy Prices</b>
<a href="https://arxiv.org/abs/2208.14311">arxiv:2208.14311</a>
&#x1F4C8; 6 <br>
<p>Jonathan Berrisch, Sven Pappert, Florian Ziel, Antonia Arsova</p></summary>
<p>

**Abstract:** We study the prices of European Emission Allowances (EUA), whereby we analyze their uncertainty and dependencies on related energy markets. We propose a probabilistic multivariate conditional time series model that exploits key characteristics of the data. The forecasting performance of the proposed model and various competing models is evaluated in an extensive rolling window forecasting study, covering almost two years out-of-sample. Thereby, we forecast 30-steps ahead. The accuracy of the multivariate probabilistic forecasts is assessed by the energy score. We discuss our findings focusing on volatility spillovers and time-varying correlations, also in view of the Russian invasion of Ukraine.

</p>
</details>

<details><summary><b>Few-shot Adaptive Object Detection with Cross-Domain CutMix</b>
<a href="https://arxiv.org/abs/2208.14586">arxiv:2208.14586</a>
&#x1F4C8; 5 <br>
<p>Yuzuru Nakamura, Yasunori Ishii, Yuki Maruyama, Takayoshi Yamashita</p></summary>
<p>

**Abstract:** In object detection, data amount and cost are a trade-off, and collecting a large amount of data in a specific domain is labor intensive. Therefore, existing large-scale datasets are used for pre-training. However, conventional transfer learning and domain adaptation cannot bridge the domain gap when the target domain differs significantly from the source domain. We propose a data synthesis method that can solve the large domain gap problem. In this method, a part of the target image is pasted onto the source image, and the position of the pasted region is aligned by utilizing the information of the object bounding box. In addition, we introduce adversarial learning to discriminate whether the original or the pasted regions. The proposed method trains on a large number of source images and a few target domain images. The proposed method achieves higher accuracy than conventional methods in a very different domain problem setting, where RGB images are the source domain, and thermal infrared images are the target domain. Similarly, the proposed method achieves higher accuracy in the cases of simulation images to real images.

</p>
</details>

<details><summary><b>Self-Supervised Pyramid Representation Learning for Multi-Label Visual Analysis and Beyond</b>
<a href="https://arxiv.org/abs/2208.14439">arxiv:2208.14439</a>
&#x1F4C8; 5 <br>
<p>Cheng-Yen Hsieh, Chih-Jung Chang, Fu-En Yang, Yu-Chiang Frank Wang</p></summary>
<p>

**Abstract:** While self-supervised learning has been shown to benefit a number of vision tasks, existing techniques mainly focus on image-level manipulation, which may not generalize well to downstream tasks at patch or pixel levels. Moreover, existing SSL methods might not sufficiently describe and associate the above representations within and across image scales. In this paper, we propose a Self-Supervised Pyramid Representation Learning (SS-PRL) framework. The proposed SS-PRL is designed to derive pyramid representations at patch levels via learning proper prototypes, with additional learners to observe and relate inherent semantic information within an image. In particular, we present a cross-scale patch-level correlation learning in SS-PRL, which allows the model to aggregate and associate information learned across patch scales. We show that, with our proposed SS-PRL for model pre-training, one can easily adapt and fine-tune the models for a variety of applications including multi-label classification, object detection, and instance segmentation.

</p>
</details>

<details><summary><b>FDB: Fraud Dataset Benchmark</b>
<a href="https://arxiv.org/abs/2208.14417">arxiv:2208.14417</a>
&#x1F4C8; 5 <br>
<p>Prince Grover, Zheng Li, Jianbo Liu, Jakub Zablocki, Hao Zhou, Julia Xu, Anqi Cheng</p></summary>
<p>

**Abstract:** Standardized datasets and benchmarks have spurred innovations in computer vision, natural language processing, multi-modal and tabular settings. We note that, as compared to other well researched fields fraud detection has numerous differences. The differences include a high class imbalance, diverse feature types, frequently changing fraud patterns, and adversarial nature of the problem. Due to these differences, the modeling approaches that are designed for other classification tasks may not work well for the fraud detection. We introduce Fraud Dataset Benchmark (FDB), a compilation of publicly available datasets catered to fraud detection. FDB comprises variety of fraud related tasks, ranging from identifying fraudulent card-not-present transactions, detecting bot attacks, classifying malicious URLs, predicting risk of loan to content moderation. The Python based library from FDB provides consistent API for data loading with standardized training and testing splits. For reference, we also provide baseline evaluations of different modeling approaches on FDB. Considering the increasing popularity of Automated Machine Learning (AutoML) for various research and business problems, we used AutoML frameworks for our baseline evaluations. For fraud prevention, the organizations that operate with limited resources and lack ML expertise often hire a team of investigators, use blocklists and manual rules, all of which are inefficient and do not scale well. Such organizations can benefit from AutoML solutions that are easy to deploy in production and pass the bar of fraud prevention requirements. We hope that FDB helps in the development of customized fraud detection techniques catered to different fraud modus operandi (MOs) as well as in the improvement of AutoML systems that can work well for all datasets in the benchmark.

</p>
</details>

<details><summary><b>k-MS: A novel clustering algorithm based on morphological reconstruction</b>
<a href="https://arxiv.org/abs/2208.14390">arxiv:2208.14390</a>
&#x1F4C8; 5 <br>
<p>É. O. Rodrigues, L. Torok, P. Liatsis, J. Viterbo, A. Conci</p></summary>
<p>

**Abstract:** This work proposes a clusterization algorithm called k-Morphological Sets (k-MS), based on morphological reconstruction and heuristics. k-MS is faster than the CPU-parallel k-Means in worst case scenarios and produces enhanced visualizations of the dataset as well as very distinct clusterizations. It is also faster than similar clusterization methods that are sensitive to density and shapes such as Mitosis and TRICLUST. In addition, k-MS is deterministic and has an intrinsic sense of maximal clusters that can be created for a given input sample and input parameters, differing from k-Means and other clusterization algorithms. In other words, given a constant k, a structuring element and a dataset, k-MS produces k or less clusters without using random/ pseudo-random functions. Finally, the proposed algorithm also provides a straightforward means for removing noise from images or datasets in general.

</p>
</details>

<details><summary><b>AutoWS-Bench-101: Benchmarking Automated Weak Supervision with 100 Labels</b>
<a href="https://arxiv.org/abs/2208.14362">arxiv:2208.14362</a>
&#x1F4C8; 5 <br>
<p>Nicholas Roberts, Xintong Li, Tzu-Heng Huang, Dyah Adila, Spencer Schoenberg, Cheng-Yu Liu, Lauren Pick, Haotian Ma, Aws Albarghouthi, Frederic Sala</p></summary>
<p>

**Abstract:** Weak supervision (WS) is a powerful method to build labeled datasets for training supervised models in the face of little-to-no labeled data. It replaces hand-labeling data with aggregating multiple noisy-but-cheap label estimates expressed by labeling functions (LFs). While it has been used successfully in many domains, weak supervision's application scope is limited by the difficulty of constructing labeling functions for domains with complex or high-dimensional features. To address this, a handful of methods have proposed automating the LF design process using a small set of ground truth labels. In this work, we introduce AutoWS-Bench-101: a framework for evaluating automated WS (AutoWS) techniques in challenging WS settings -- a set of diverse application domains on which it has been previously difficult or impossible to apply traditional WS techniques. While AutoWS is a promising direction toward expanding the application-scope of WS, the emergence of powerful methods such as zero-shot foundation models reveals the need to understand how AutoWS techniques compare or cooperate with modern zero-shot or few-shot learners. This informs the central question of AutoWS-Bench-101: given an initial set of 100 labels for each task, we ask whether a practitioner should use an AutoWS method to generate additional labels or use some simpler baseline, such as zero-shot predictions from a foundation model or supervised learning. We observe that in many settings, it is necessary for AutoWS methods to incorporate signal from foundation models if they are to outperform simple few-shot baselines, and AutoWS-Bench-101 promotes future research in this direction. We conclude with a thorough ablation study of AutoWS methods.

</p>
</details>

<details><summary><b>Persistence Initialization: A novel adaptation of the Transformer architecture for Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2208.14236">arxiv:2208.14236</a>
&#x1F4C8; 5 <br>
<p>Espen Haugsdal, Erlend Aune, Massimiliano Ruocco</p></summary>
<p>

**Abstract:** Time series forecasting is an important problem, with many real world applications. Ensembles of deep neural networks have recently achieved impressive forecasting accuracy, but such large ensembles are impractical in many real world settings. Transformer models been successfully applied to a diverse set of challenging problems. We propose a novel adaptation of the original Transformer architecture focusing on the task of time series forecasting, called Persistence Initialization. The model is initialized as a naive persistence model by using a multiplicative gating mechanism combined with a residual skip connection. We use a decoder Transformer with ReZero normalization and Rotary positional encodings, but the adaptation is applicable to any auto-regressive neural network model. We evaluate our proposed architecture on the challenging M4 dataset, achieving competitive performance compared to ensemble based methods. We also compare against existing recently proposed Transformer models for time series forecasting, showing superior performance on the M4 dataset. Extensive ablation studies show that Persistence Initialization leads to better performance and faster convergence. As the size of the model increases, only the models with our proposed adaptation gain in performance. We also perform an additional ablation study to determine the importance of the choice of normalization and positional encoding, and find both the use of Rotary encodings and ReZero normalization to be essential for good forecasting performance.

</p>
</details>

<details><summary><b>Deep Autoencoders for Anomaly Detection in Textured Images using CW-SSIM</b>
<a href="https://arxiv.org/abs/2208.14045">arxiv:2208.14045</a>
&#x1F4C8; 5 <br>
<p>Andrea Bionda, Luca Frittoli, Giacomo Boracchi</p></summary>
<p>

**Abstract:** Detecting anomalous regions in images is a frequently encountered problem in industrial monitoring. A relevant example is the analysis of tissues and other products that in normal conditions conform to a specific texture, while defects introduce changes in the normal pattern. We address the anomaly detection problem by training a deep autoencoder, and we show that adopting a loss function based on Complex Wavelet Structural Similarity (CW-SSIM) yields superior detection performance on this type of images compared to traditional autoencoder loss functions. Our experiments on well-known anomaly detection benchmarks show that a simple model trained with this loss function can achieve comparable or superior performance to state-of-the-art methods leveraging deeper, larger and more computationally demanding neural networks.

</p>
</details>

<details><summary><b>EchoGNN: Explainable Ejection Fraction Estimation with Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2208.14003">arxiv:2208.14003</a>
&#x1F4C8; 5 <br>
<p>Masoud Mokhtari, Teresa Tsang, Purang Abolmaesumi, Renjie Liao</p></summary>
<p>

**Abstract:** Ejection fraction (EF) is a key indicator of cardiac function, allowing identification of patients prone to heart dysfunctions such as heart failure. EF is estimated from cardiac ultrasound videos known as echocardiograms (echo) by manually tracing the left ventricle and estimating its volume on certain frames. These estimations exhibit high inter-observer variability due to the manual process and varying video quality. Such sources of inaccuracy and the need for rapid assessment necessitate reliable and explainable machine learning techniques. In this work, we introduce EchoGNN, a model based on graph neural networks (GNNs) to estimate EF from echo videos. Our model first infers a latent echo-graph from the frames of one or multiple echo cine series. It then estimates weights over nodes and edges of this graph, indicating the importance of individual frames that aid EF estimation. A GNN regressor uses this weighted graph to predict EF. We show, qualitatively and quantitatively, that the learned graph weights provide explainability through identification of critical frames for EF estimation, which can be used to determine when human intervention is required. On EchoNet-Dynamic public EF dataset, EchoGNN achieves EF prediction performance that is on par with state of the art and provides explainability, which is crucial given the high inter-observer variability inherent in this task.

</p>
</details>

<details><summary><b>Temporal Flow Mask Attention for Open-Set Long-Tailed Recognition of Wild Animals in Camera-Trap Images</b>
<a href="https://arxiv.org/abs/2208.14625">arxiv:2208.14625</a>
&#x1F4C8; 4 <br>
<p>Jeongsoo Kim, Sangmin Woo, Byeongjun Park, Changick Kim</p></summary>
<p>

**Abstract:** Camera traps, unmanned observation devices, and deep learning-based image recognition systems have greatly reduced human effort in collecting and analyzing wildlife images. However, data collected via above apparatus exhibits 1) long-tailed and 2) open-ended distribution problems. To tackle the open-set long-tailed recognition problem, we propose the Temporal Flow Mask Attention Network that comprises three key building blocks: 1) an optical flow module, 2) an attention residual module, and 3) a meta-embedding classifier. We extract temporal features of sequential frames using the optical flow module and learn informative representation using attention residual blocks. Moreover, we show that applying the meta-embedding technique boosts the performance of the method in open-set long-tailed recognition. We apply this method on a Korean Demilitarized Zone (DMZ) dataset. We conduct extensive experiments, and quantitative and qualitative analyses to prove that our method effectively tackles the open-set long-tailed recognition problem while being robust to unknown classes.

</p>
</details>

<details><summary><b>Blind Quality Assessment of 3D Dense Point Clouds with Structure Guided Resampling</b>
<a href="https://arxiv.org/abs/2208.14603">arxiv:2208.14603</a>
&#x1F4C8; 4 <br>
<p>Wei Zhou, Qi Yang, Qiuping Jiang, Guangtao Zhai, Weisi Lin</p></summary>
<p>

**Abstract:** Objective quality assessment of 3D point clouds is essential for the development of immersive multimedia systems in real-world applications. Despite the success of perceptual quality evaluation for 2D images and videos, blind/no-reference metrics are still scarce for 3D point clouds with large-scale irregularly distributed 3D points. Therefore, in this paper, we propose an objective point cloud quality index with Structure Guided Resampling (SGR) to automatically evaluate the perceptually visual quality of 3D dense point clouds. The proposed SGR is a general-purpose blind quality assessment method without the assistance of any reference information. Specifically, considering that the human visual system (HVS) is highly sensitive to structure information, we first exploit the unique normal vectors of point clouds to execute regional pre-processing which consists of keypoint resampling and local region construction. Then, we extract three groups of quality-related features, including: 1) geometry density features; 2) color naturalness features; 3) angular consistency features. Both the cognitive peculiarities of the human brain and naturalness regularity are involved in the designed quality-aware features that can capture the most vital aspects of distorted 3D point clouds. Extensive experiments on several publicly available subjective point cloud quality databases validate that our proposed SGR can compete with state-of-the-art full-reference, reduced-reference, and no-reference quality assessment algorithms.

</p>
</details>

<details><summary><b>Associative Learning for Network Embedding</b>
<a href="https://arxiv.org/abs/2208.14376">arxiv:2208.14376</a>
&#x1F4C8; 4 <br>
<p>Yuchen Liang, Dmitry Krotov, Mohammed J. Zaki</p></summary>
<p>

**Abstract:** The network embedding task is to represent the node in the network as a low-dimensional vector while incorporating the topological and structural information. Most existing approaches solve this problem by factorizing a proximity matrix, either directly or implicitly. In this work, we introduce a network embedding method from a new perspective, which leverages Modern Hopfield Networks (MHN) for associative learning. Our network learns associations between the content of each node and that node's neighbors. These associations serve as memories in the MHN. The recurrent dynamics of the network make it possible to recover the masked node, given that node's neighbors. Our proposed method is evaluated on different downstream tasks such as node classification and linkage prediction. The results show competitive performance compared to the common matrix factorization techniques and deep learning based methods.

</p>
</details>

<details><summary><b>Automated recognition of the pericardium contour on processed CT images using genetic algorithms</b>
<a href="https://arxiv.org/abs/2208.14375">arxiv:2208.14375</a>
&#x1F4C8; 4 <br>
<p>E. O. Rodrigues, L. O. Rodrigues, L. S. N. Oliveira, A. Conci, P. Liatsis</p></summary>
<p>

**Abstract:** This work proposes the use of Genetic Algorithms (GA) in tracing and recognizing the pericardium contour of the human heart using Computed Tomography (CT) images. We assume that each slice of the pericardium can be modelled by an ellipse, the parameters of which need to be optimally determined. An optimal ellipse would be one that closely follows the pericardium contour and, consequently, separates appropriately the epicardial and mediastinal fats of the human heart. Tracing and automatically identifying the pericardium contour aids in medical diagnosis. Usually, this process is done manually or not done at all due to the effort required. Besides, detecting the pericardium may improve previously proposed automated methodologies that separate the two types of fat associated to the human heart. Quantification of these fats provides important health risk marker information, as they are associated with the development of certain cardiovascular pathologies. Finally, we conclude that GA offers satisfiable solutions in a feasible amount of processing time.

</p>
</details>

<details><summary><b>Learning Representations for Hyper-Relational Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2208.14322">arxiv:2208.14322</a>
&#x1F4C8; 4 <br>
<p>Harry Shomer, Wei Jin, Juanhui Li, Yao Ma, Jiliang Tang</p></summary>
<p>

**Abstract:** Knowledge graphs (KGs) have gained prominence for their ability to learn representations for uni-relational facts. Recently, research has focused on modeling hyper-relational facts, which move beyond the restriction of uni-relational facts and allow us to represent more complex and real-world information. However, existing approaches for learning representations on hyper-relational KGs majorly focus on enhancing the communication from qualifiers to base triples while overlooking the flow of information from base triple to qualifiers. This can lead to suboptimal qualifier representations, especially when a large amount of qualifiers are presented. It motivates us to design a framework that utilizes multiple aggregators to learn representations for hyper-relational facts: one from the perspective of the base triple and the other one from the perspective of the qualifiers. Experiments demonstrate the effectiveness of our framework for hyper-relational knowledge graph completion across multiple datasets. Furthermore, we conduct an ablation study that validates the importance of the various components in our framework. The code to reproduce our results can be found at \url{https://github.com/HarryShomer/QUAD}.

</p>
</details>

<details><summary><b>A Black-Box Attack on Optical Character Recognition Systems</b>
<a href="https://arxiv.org/abs/2208.14302">arxiv:2208.14302</a>
&#x1F4C8; 4 <br>
<p>Samet Bayram, Kenneth Barner</p></summary>
<p>

**Abstract:** Adversarial machine learning is an emerging area showing the vulnerability of deep learning models. Exploring attack methods to challenge state of the art artificial intelligence (A.I.) models is an area of critical concern. The reliability and robustness of such A.I. models are one of the major concerns with an increasing number of effective adversarial attack methods. Classification tasks are a major vulnerable area for adversarial attacks. The majority of attack strategies are developed for colored or gray-scaled images. Consequently, adversarial attacks on binary image recognition systems have not been sufficiently studied. Binary images are simple two possible pixel-valued signals with a single channel. The simplicity of binary images has a significant advantage compared to colored and gray scaled images, namely computation efficiency. Moreover, most optical character recognition systems (O.C.R.s), such as handwritten character recognition, plate number identification, and bank check recognition systems, use binary images or binarization in their processing steps. In this paper, we propose a simple yet efficient attack method, Efficient Combinatorial Black-box Adversarial Attack, on binary image classifiers. We validate the efficiency of the attack technique on two different data sets and three classification networks, demonstrating its performance. Furthermore, we compare our proposed method with state-of-the-art methods regarding advantages and disadvantages as well as applicability.

</p>
</details>

<details><summary><b>MODNet: Multi-offset Point Cloud Denoising Network Customized for Multi-scale Patches</b>
<a href="https://arxiv.org/abs/2208.14160">arxiv:2208.14160</a>
&#x1F4C8; 4 <br>
<p>Anyi Huang, Qian Xie, Zhoutao Wang, Dening Lu, Mingqiang Wei, Jun Wang</p></summary>
<p>

**Abstract:** The intricacy of 3D surfaces often results cutting-edge point cloud denoising (PCD) models in surface degradation including remnant noise, wrongly-removed geometric details. Although using multi-scale patches to encode the geometry of a point has become the common wisdom in PCD, we find that simple aggregation of extracted multi-scale features can not adaptively utilize the appropriate scale information according to the geometric information around noisy points. It leads to surface degradation, especially for points close to edges and points on complex curved surfaces. We raise an intriguing question -- if employing multi-scale geometric perception information to guide the network to utilize multi-scale information, can eliminate the severe surface degradation problem? To answer it, we propose a Multi-offset Denoising Network (MODNet) customized for multi-scale patches. First, we extract the low-level feature of three scales patches by patch feature encoders. Second, a multi-scale perception module is designed to embed multi-scale geometric information for each scale feature and regress multi-scale weights to guide a multi-offset denoising displacement. Third, a multi-offset decoder regresses three scale offsets, which are guided by the multi-scale weights to predict the final displacement by weighting them adaptively. Experiments demonstrate that our method achieves new state-of-the-art performance on both synthetic and real-scanned datasets.

</p>
</details>

<details><summary><b>A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images</b>
<a href="https://arxiv.org/abs/2208.14125">arxiv:2208.14125</a>
&#x1F4C8; 4 <br>
<p>Dominik J. E. Waibel, Ernst Röell, Bastian Rieck, Raja Giryes, Carsten Marr</p></summary>
<p>

**Abstract:** Diffusion models are a class of generative models, showing superior performance as compared to other generative models in creating realistic images when trained on natural image datasets. We introduce DISPR, a diffusion-based model for solving the inverse problem of three-dimensional (3D) cell shape prediction from two-dimensional (2D) single cell microscopy images. Using the 2D microscopy image as a prior, DISPR is conditioned to predict realistic 3D shape reconstructions. To showcase the applicability of DISPR as a data augmentation tool in a feature-based single cell classification task, we extract morphological features from the cells grouped into six highly imbalanced classes. Adding features from predictions of DISPR to the three minority classes improved the macro F1 score from $F1_\text{macro} = 55.2 \pm 4.6\%$ to $F1_\text{macro} = 72.2 \pm 4.9\%$. With our method being the first to employ a diffusion-based model in this context, we demonstrate that diffusion models can be applied to inverse problems in 3D, and that they learn to reconstruct 3D shapes with realistic morphological features from 2D microscopy images.

</p>
</details>

<details><summary><b>Dynamic Global Sensitivity for Differentially Private Contextual Bandits</b>
<a href="https://arxiv.org/abs/2208.14555">arxiv:2208.14555</a>
&#x1F4C8; 3 <br>
<p>Huazheng Wang, David Zhao, Hongning Wang</p></summary>
<p>

**Abstract:** Bandit algorithms have become a reference solution for interactive recommendation. However, as such algorithms directly interact with users for improved recommendations, serious privacy concerns have been raised regarding its practical use. In this work, we propose a differentially private linear contextual bandit algorithm, via a tree-based mechanism to add Laplace or Gaussian noise to model parameters. Our key insight is that as the model converges during online update, the global sensitivity of its parameters shrinks over time (thus named dynamic global sensitivity). Compared with existing solutions, our dynamic global sensitivity analysis allows us to inject less noise to obtain $(ε, δ)$-differential privacy with added regret caused by noise injection in $\tilde O(\log{T}\sqrt{T}/ε)$. We provide a rigorous theoretical analysis over the amount of noise added via dynamic global sensitivity and the corresponding upper regret bound of our proposed algorithm. Experimental results on both synthetic and real-world datasets confirmed the algorithm's advantage against existing solutions.

</p>
</details>

<details><summary><b>Annotated Dataset Creation through General Purpose Language Models for non-English Medical NLP</b>
<a href="https://arxiv.org/abs/2208.14493">arxiv:2208.14493</a>
&#x1F4C8; 3 <br>
<p>Johann Frei, Frank Kramer</p></summary>
<p>

**Abstract:** Obtaining text datasets with semantic annotations is an effortful process, yet crucial for supervised training in natural language processsing (NLP). In general, developing and applying new NLP pipelines in domain-specific contexts for tasks often requires custom designed datasets to address NLP tasks in supervised machine learning fashion. When operating in non-English languages for medical data processing, this exposes several minor and major, interconnected problems such as lack of task-matching datasets as well as task-specific pre-trained models. In our work we suggest to leverage pretrained language models for training data acquisition in order to retrieve sufficiently large datasets for training smaller and more efficient models for use-case specific tasks. To demonstrate the effectiveness of your approach, we create a custom dataset which we use to train a medical NER model for German texts, GPTNERMED, yet our method remains language-independent in principle. Our obtained dataset as well as our pre-trained models are publicly available at: https://github.com/frankkramer-lab/GPTNERMED

</p>
</details>

<details><summary><b>Competition, Alignment, and Equilibria in Digital Marketplaces</b>
<a href="https://arxiv.org/abs/2208.14423">arxiv:2208.14423</a>
&#x1F4C8; 3 <br>
<p>Meena Jagadeesan, Michael I. Jordan, Nika Haghtalab</p></summary>
<p>

**Abstract:** Competition between traditional platforms is known to improve user utility by aligning the platform's actions with user preferences. But to what extent is alignment exhibited in data-driven marketplaces? To study this question from a theoretical perspective, we introduce a duopoly market where platform actions are bandit algorithms and the two platforms compete for user participation. A salient feature of this market is that the quality of recommendations depends on both the bandit algorithm and the amount of data provided by interactions from users. This interdependency between the algorithm performance and the actions of users complicates the structure of market equilibria and their quality in terms of user utility. Our main finding is that competition in this market does not perfectly align market outcomes with user utility. Interestingly, market outcomes exhibit misalignment not only when the platforms have separate data repositories, but also when the platforms have a shared data repository. Nonetheless, the data sharing assumptions impact what mechanism drives misalignment and also affect the specific form of misalignment (e.g. the quality of the best-case and worst-case market outcomes). More broadly, our work illustrates that competition in digital marketplaces has subtle consequences for user utility that merit further investigation.

</p>
</details>

<details><summary><b>Verifiable Obstacle Detection</b>
<a href="https://arxiv.org/abs/2208.14403">arxiv:2208.14403</a>
&#x1F4C8; 3 <br>
<p>Ayoosh Bansal, Hunmin Kim, Simon Yu, Bo Li, Naira Hovakimyan, Marco Caccamo, Lui Sha</p></summary>
<p>

**Abstract:** Perception of obstacles remains a critical safety concern for autonomous vehicles. Real-world collisions have shown that the autonomy faults leading to fatal collisions originate from obstacle existence detection. Open source autonomous driving implementations show a perception pipeline with complex interdependent Deep Neural Networks. These networks are not fully verifiable, making them unsuitable for safety-critical tasks.
  In this work, we present a safety verification of an existing LiDAR based classical obstacle detection algorithm. We establish strict bounds on the capabilities of this obstacle detection algorithm. Given safety standards, such bounds allow for determining LiDAR sensor properties that would reliably satisfy the standards. Such analysis has as yet been unattainable for neural network based perception systems. We provide a rigorous analysis of the obstacle detection system with empirical results based on real-world sensor data.

</p>
</details>

<details><summary><b>Evolutionary Deep Reinforcement Learning for Dynamic Slice Management in O-RAN</b>
<a href="https://arxiv.org/abs/2208.14394">arxiv:2208.14394</a>
&#x1F4C8; 3 <br>
<p>Fatemeh Lotfi, Omid Semiari, Fatemeh Afghah</p></summary>
<p>

**Abstract:** The next-generation wireless networks are required to satisfy a variety of services and criteria concurrently. To address upcoming strict criteria, a new open radio access network (O-RAN) with distinguishing features such as flexible design, disaggregated virtual and programmable components, and intelligent closed-loop control was developed. O-RAN slicing is being investigated as a critical strategy for ensuring network quality of service (QoS) in the face of changing circumstances. However, distinct network slices must be dynamically controlled to avoid service level agreement (SLA) variation caused by rapid changes in the environment. Therefore, this paper introduces a novel framework able to manage the network slices through provisioned resources intelligently. Due to diverse heterogeneous environments, intelligent machine learning approaches require sufficient exploration to handle the harshest situations in a wireless network and accelerate convergence. To solve this problem, a new solution is proposed based on evolutionary-based deep reinforcement learning (EDRL) to accelerate and optimize the slice management learning process in the radio access network's (RAN) intelligent controller (RIC) modules. To this end, the O-RAN slicing is represented as a Markov decision process (MDP) which is then solved optimally for resource allocation to meet service demand using the EDRL approach. In terms of reaching service demands, simulation results show that the proposed approach outperforms the DRL baseline by 62.2%.

</p>
</details>

<details><summary><b>Denoising Architecture for Unsupervised Anomaly Detection in Time-Series</b>
<a href="https://arxiv.org/abs/2208.14337">arxiv:2208.14337</a>
&#x1F4C8; 3 <br>
<p>Wadie Skaf, Tomáš Horváth</p></summary>
<p>

**Abstract:** Anomalies in time-series provide insights of critical scenarios across a range of industries, from banking and aerospace to information technology, security, and medicine. However, identifying anomalies in time-series data is particularly challenging due to the imprecise definition of anomalies, the frequent absence of labels, and the enormously complex temporal correlations present in such data. The LSTM Autoencoder is an Encoder-Decoder scheme for Anomaly Detection based on Long Short Term Memory Networks that learns to reconstruct time-series behavior and then uses reconstruction error to identify abnormalities. We introduce the Denoising Architecture as a complement to this LSTM Encoder-Decoder model and investigate its effect on real-world as well as artificially generated datasets. We demonstrate that the proposed architecture increases both the accuracy and the training speed, thereby, making the LSTM Autoencoder more efficient for unsupervised anomaly detection tasks.

</p>
</details>

<details><summary><b>Prediction-based One-shot Dynamic Parking Pricing</b>
<a href="https://arxiv.org/abs/2208.14231">arxiv:2208.14231</a>
&#x1F4C8; 3 <br>
<p>Seoyoung Hong, Heejoo Shin, Jeongwhan Choi, Noseong Park</p></summary>
<p>

**Abstract:** Many U.S. metropolitan cities are notorious for their severe shortage of parking spots. To this end, we present a proactive prediction-driven optimization framework to dynamically adjust parking prices. We use state-of-the-art deep learning technologies such as neural ordinary differential equations (NODEs) to design our future parking occupancy rate prediction model given historical occupancy rates and price information. Owing to the continuous and bijective characteristics of NODEs, in addition, we design a one-shot price optimization method given a pre-trained prediction model, which requires only one iteration to find the optimal solution. In other words, we optimize the price input to the pre-trained prediction model to achieve targeted occupancy rates in the parking blocks. We conduct experiments with the data collected in San Francisco and Seattle for years. Our prediction model shows the best accuracy in comparison with various temporal or spatio-temporal forecasting models. Our one-shot optimization method greatly outperforms other black-box and white-box search methods in terms of the search time and always returns the optimal price solution.

</p>
</details>

<details><summary><b>Identifying Latent Causal Content for Multi-Source Domain Adaptation</b>
<a href="https://arxiv.org/abs/2208.14161">arxiv:2208.14161</a>
&#x1F4C8; 3 <br>
<p>Yuhang Liu, Zhen Zhang, Dong Gong, Mingming Gong, Biwei Huang, Kun Zhang, Javen Qinfeng Shi</p></summary>
<p>

**Abstract:** Multi-source domain adaptation (MSDA) learns to predict the labels in target domain data, under the setting where all data from multiple source domains are labelled and the data from the target domain are unlabeled. To handle this problem, most of methods focus on learning invariant representations across domains. However, their success severely relies on the assumption that label distribution remains unchanged across domains. To mitigate it, we propose a new assumption, latent covariate shift, where the marginal distribution of the latent content variable changes across domains, and the conditional distribution of the label given the latent content remains invariant across domains. We introduce a latent style variable to complement the latent content variable forming a latent causal graph as the data and label generating process. We show that although the latent style variable is unidentifiable due to transitivity property in the latent space, the latent content variable can be identified up to simple scaling under some mild conditions. This motivates us to propose a novel method for MSDA, which learns the invariant label distribution conditional on the latent content variable, instead of learning invariant representations. Empirical evaluation on simulation and real data demonstrates the effectiveness of the proposed method, compared with many state-of-the-art methods based on invariant representation.

</p>
</details>

<details><summary><b>Weight-variant Latent Causal Models</b>
<a href="https://arxiv.org/abs/2208.14153">arxiv:2208.14153</a>
&#x1F4C8; 3 <br>
<p>Yuhang Liu, Zhen Zhang, Dong Gong, Mingming Gong, Biwei Huang, Anton van den Hengel, Kun Zhang, Javen Qinfeng Shi</p></summary>
<p>

**Abstract:** Causal representation learning exposes latent high-level causal variables behind low-level observations, which has enormous potential for a set of downstream tasks of interest. Despite this, identifying the true latent causal representation from observed data is a great challenge. In this work we focus on identifying latent causal variables. To this end, we analysis three intrinsic properties in latent space, including transitivity, permutation and scaling. We show that the transitivity severely hinders the identifiability of latent causal variables, while permutation and scaling guide the direction of identifying latent causal variable. To break the transitivity, we assume the underlying latent causal relations to be linear Gaussian models, in which the weights, mean and variance of Gaussian noise are modulated by an additionally observed variable. Under these assumptions we theoretically show that the latent causal variables can be identifiable up to trivial permutation and scaling. Built on this theoretical result, we propose a novel method, termed Structural caUsAl Variational autoEncoder, which directly learns latent causal variables, together with the mapping from the latent causal variables to the observed ones. Experimental results on synthetic and real data demonstrate the identifiable result and the ability of the proposed method for learning latent causal variables.

</p>
</details>

<details><summary><b>Airway measurement by refinement of synthetic images improves mortality prediction in idiopathic pulmonary fibrosis</b>
<a href="https://arxiv.org/abs/2208.14141">arxiv:2208.14141</a>
&#x1F4C8; 3 <br>
<p>Ashkan Pakzad, Mou-Cheng Xu, Wing Keung Cheung, Marie Vermant, Tinne Goos, Laurens J De Sadeleer, Stijn E Verleden, Wim A Wuyts, John R Hurst, Joseph Jacob</p></summary>
<p>

**Abstract:** Several chronic lung diseases, like idiopathic pulmonary fibrosis (IPF) are characterised by abnormal dilatation of the airways. Quantification of airway features on computed tomography (CT) can help characterise disease progression. Physics based airway measurement algorithms have been developed, but have met with limited success in part due to the sheer diversity of airway morphology seen in clinical practice. Supervised learning methods are also not feasible due to the high cost of obtaining precise airway annotations. We propose synthesising airways by style transfer using perceptual losses to train our model, Airway Transfer Network (ATN). We compare our ATN model with a state-of-the-art GAN-based network (simGAN) using a) qualitative assessment; b) assessment of the ability of ATN and simGAN based CT airway metrics to predict mortality in a population of 113 patients with IPF. ATN was shown to be quicker and easier to train than simGAN. ATN-based airway measurements were also found to be consistently stronger predictors of mortality than simGAN-derived airway metrics on IPF CTs. Airway synthesis by a transformation network that refines synthetic data using perceptual losses is a realistic alternative to GAN-based methods for clinical CT analyses of idiopathic pulmonary fibrosis. Our source code can be found at https://github.com/ashkanpakzad/ATN that is compatible with the existing open-source airway analysis framework, AirQuant.

</p>
</details>

<details><summary><b>Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models</b>
<a href="https://arxiv.org/abs/2208.14133">arxiv:2208.14133</a>
&#x1F4C8; 3 <br>
<p>Yong Zhong, Hongtao Liu, Xiaodong Liu, Fan Bao, Weiran Shen, Chongxuan Li</p></summary>
<p>

**Abstract:** Deep generative models (DGMs) are data-eager. Essentially, it is because learning a complex model on limited data suffers from a large variance and easily overfits. Inspired by the \emph{bias-variance dilemma}, we propose \emph{regularized deep generative model} (Reg-DGM), which leverages a nontransferable pre-trained model to reduce the variance of generative modeling with limited data. Formally, Reg-DGM optimizes a weighted sum of a certain divergence between the data distribution and the DGM and the expectation of an energy function defined by the pre-trained model w.r.t. the DGM. Theoretically, we characterize the existence and uniqueness of the global minimum of Reg-DGM in the nonparametric setting and rigorously prove the statistical benefits of Reg-DGM w.r.t. the mean squared error and the expected risk in a simple yet representative Gaussian-fitting example. Empirically, it is quite flexible to specify the DGM and the pre-trained model in Reg-DGM. In particular, with a ResNet-18 classifier pre-trained on ImageNet and a data-dependent energy function, Reg-DGM consistently improves the generation performance of strong DGMs including StyleGAN2 and ADA on several benchmarks with limited data and achieves competitive results to the state-of-the-art methods.

</p>
</details>

<details><summary><b>Super-model ecosystem: A domain-adaptation perspective</b>
<a href="https://arxiv.org/abs/2208.14092">arxiv:2208.14092</a>
&#x1F4C8; 3 <br>
<p>Fengxiang He, Dacheng Tao</p></summary>
<p>

**Abstract:** This paper attempts to establish the theoretical foundation for the emerging super-model paradigm via domain adaptation, where one first trains a very large-scale model, {\it i.e.}, super model (or foundation model in some other papers), on a large amount of data and then adapts it to various specific domains. Super-model paradigms help reduce computational and data cost and carbon emission, which is critical to AI industry, especially enormous small and medium-sized enterprises. We model the super-model paradigm as a two-stage diffusion process: (1) in the pre-training stage, the model parameter diffuses from random initials and converges to a steady distribution; and (2) in the fine-tuning stage, the model parameter is transported to another steady distribution. Both training stages can be mathematically modeled by the Uhlenbeck-Ornstein process which converges to two Maxwell-Boltzmann distributions, respectively, each of which characterizes the corresponding convergent model. An $\mathcal O(1/\sqrt{N})$ generalization bound is then established via PAC-Bayesian framework. The theory finds that the generalization error of the fine-tuning stage is dominant in domain adaptation. In addition, our theory suggests that the generalization is determined by a new measure that characterizes the domain discrepancy between the source domain and target domain, based on the covariance matrices and the shift of the converged local minimum.

</p>
</details>

<details><summary><b>An efficient and flexible inference system for serving heterogeneous ensembles of deep neural networks</b>
<a href="https://arxiv.org/abs/2208.14049">arxiv:2208.14049</a>
&#x1F4C8; 3 <br>
<p>Pierrick Pochelu, Serge G. Petiton, Bruno Conche</p></summary>
<p>

**Abstract:** Ensembles of Deep Neural Networks (DNNs) have achieved qualitative predictions but they are computing and memory intensive. Therefore, the demand is growing to make them answer a heavy workload of requests with available computational resources. Unlike recent initiatives on inference servers and inference frameworks, which focus on the prediction of single DNNs, we propose a new software layer to serve with flexibility and efficiency ensembles of DNNs.
  Our inference system is designed with several technical innovations. First, we propose a novel procedure to find a good allocation matrix between devices (CPUs or GPUs) and DNN instances. It runs successively a worst-fit to allocate DNNs into the memory devices and a greedy algorithm to optimize allocation settings and speed up the ensemble. Second, we design the inference system based on multiple processes to run asynchronously: batching, prediction, and the combination rule with an efficient internal communication scheme to avoid overhead.
  Experiments show the flexibility and efficiency under extreme scenarios: It successes to serve an ensemble of 12 heavy DNNs into 4 GPUs and at the opposite, one single DNN multi-threaded into 16 GPUs. It also outperforms the simple baseline consisting of optimizing the batch size of DNNs by a speedup up to 2.7X on the image classification task.

</p>
</details>

<details><summary><b>Online Meta-Learning for Model Update Aggregation in Federated Learning for Click-Through Rate Prediction</b>
<a href="https://arxiv.org/abs/2209.00629">arxiv:2209.00629</a>
&#x1F4C8; 2 <br>
<p>Xianghang Liu, Bartłomiej Twardowski, Tri Kurniawan Wijaya</p></summary>
<p>

**Abstract:** In Federated Learning (FL) of click-through rate (CTR) prediction, users' data is not shared for privacy protection. The learning is performed by training locally on client devices and communicating only model changes to the server. There are two main challenges: (i) the client heterogeneity, making FL algorithms that use the weighted averaging to aggregate model updates from the clients have slow progress and unsatisfactory learning results; and (ii) the difficulty of tuning the server learning rate with trial-and-error methodology due to the big computation time and resources needed for each experiment. To address these challenges, we propose a simple online meta-learning method to learn a strategy of aggregating the model updates, which adaptively weighs the importance of the clients based on their attributes and adjust the step sizes of the update. We perform extensive evaluations on public datasets. Our method significantly outperforms the state-of-the-art in both the speed of convergence and the quality of the final learning results.

</p>
</details>

<details><summary><b>Improving Operational Efficiency In EV Ridepooling Fleets By Predictive Exploitation of Idle Times</b>
<a href="https://arxiv.org/abs/2208.14852">arxiv:2208.14852</a>
&#x1F4C8; 2 <br>
<p>Jesper C. Provoost, Andreas Kamilaris, Gyözö Gidófalvi, Geert J. Heijenk, Luc J. J. Wismans</p></summary>
<p>

**Abstract:** In ridepooling systems with electric fleets, charging is a complex decision-making process. Most electric vehicle (EV) taxi services require drivers to make egoistic decisions, leading to decentralized ad-hoc charging strategies. The current state of the mobility system is often lacking or not shared between vehicles, making it impossible to make a system-optimal decision. Most existing approaches do not combine time, location and duration into a comprehensive control algorithm or are unsuitable for real-time operation. We therefore present a real-time predictive charging method for ridepooling services with a single operator, called Idle Time Exploitation (ITX), which predicts the periods where vehicles are idle and exploits these periods to harvest energy. It relies on Graph Convolutional Networks and a linear assignment algorithm to devise an optimal pairing of vehicles and charging stations, in pursuance of maximizing the exploited idle time. We evaluated our approach through extensive simulation studies on real-world datasets from New York City. The results demonstrate that ITX outperforms all baseline methods by at least 5% (equivalent to $70,000 for a 6,000 vehicle operation) per week in terms of a monetary reward function which was modeled to replicate the profitability of a real-world ridepooling system. Moreover, ITX can reduce delays by at least 4.68% in comparison with baseline methods and generally increase passenger comfort by facilitating a better spread of customers across the fleet. Our results also demonstrate that ITX enables vehicles to harvest energy during the day, stabilizing battery levels and increasing resilience to unexpected surges in demand. Lastly, compared to the best-performing baseline strategy, peak loads are reduced by 17.39% which benefits grid operators and paves the way for more sustainable use of the electrical grid.

</p>
</details>

<details><summary><b>Lifelong Learning for Question Answering with Hierarchical Prompts</b>
<a href="https://arxiv.org/abs/2208.14602">arxiv:2208.14602</a>
&#x1F4C8; 2 <br>
<p>Yi Dai, Hao Lang, Yinhe Zheng, Fei Huang, Luo Si, Yongbin Li</p></summary>
<p>

**Abstract:** QA models with lifelong learning (LL) abilities are important for practical QA applications, and architecture-based LL methods are reported to be an effective implementation for these models. However, it is non-trivial to extend previous approaches to QA tasks since they either require access to task identities in the testing phase or do not explicitly model samples from unseen tasks. In this paper, we propose Diana: a dynamic architecture-based lifelong QA model that tries to learn a sequence of QA tasks with a prompt enhanced language model. Four types of hierarchically organized prompts are used in Diana to capture QA knowledge from different granularities. Specifically, we dedicate task-level prompts to capture task-specific knowledge to retain high LL performances and maintain instance-level prompts to learn knowledge shared across different input samples to improve the model's generalization performance. Moreover, we dedicate separate prompts to explicitly model unseen tasks and introduce a set of prompt key vectors to facilitate knowledge sharing between tasks. Extensive experiments demonstrate that Diana outperforms state-of-the-art lifelong QA models, especially in handling unseen tasks.

</p>
</details>

<details><summary><b>Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning</b>
<a href="https://arxiv.org/abs/2208.14565">arxiv:2208.14565</a>
&#x1F4C8; 2 <br>
<p>Sheng Zhang, Hao Cheng, Jianfeng Gao, Hoifung Poon</p></summary>
<p>

**Abstract:** We present an efficient bi-encoder framework for named entity recognition (NER), which applies contrastive learning to map candidate text spans and entity types into the same vector representation space. Prior work predominantly approaches NER as sequence labeling or span classification. We instead frame NER as a metric learning problem that maximizes the similarity between the vector representations of an entity mention and its type. This makes it easy to handle nested and flat NER alike, and can better leverage noisy self-supervision signals. A major challenge to this bi-encoder formulation for NER lies in separating non-entity spans from entity mentions. Instead of explicitly labeling all non-entity spans as the same class Outside (O) as in most prior methods, we introduce a novel dynamic thresholding loss, which is learned in conjunction with the standard contrastive loss. Experiments show that our method performs well in both supervised and distantly supervised settings, for nested and flat NER alike, establishing new state of the art across standard datasets in the general domain (e.g., ACE2004, ACE2005) and high-value verticals such as biomedicine (e.g., GENIA, NCBI, BC5CDR, JNLPBA).

</p>
</details>

<details><summary><b>Do language models make human-like predictions about the coreferents of Italian anaphoric zero pronouns?</b>
<a href="https://arxiv.org/abs/2208.14554">arxiv:2208.14554</a>
&#x1F4C8; 2 <br>
<p>James A. Michaelov, Benjamin K. Bergen</p></summary>
<p>

**Abstract:** Some languages allow arguments to be omitted in certain contexts. Yet human language comprehenders reliably infer the intended referents of these zero pronouns, in part because they construct expectations about which referents are more likely. We ask whether Neural Language Models also extract the same expectations. We test whether 12 contemporary language models display expectations that reflect human behavior when exposed to sentences with zero pronouns from five behavioral experiments conducted in Italian by Carminati (2005). We find that three models - XGLM 2.9B, 4.5B, and 7.5B - capture the human behavior from all the experiments, with others successfully modeling some of the results. This result suggests that human expectations about coreference can be derived from exposure to language, and also indicates features of language models that allow them to better reflect human behavior.

</p>
</details>

<details><summary><b>Model-Based Reinforcement Learning with SINDy</b>
<a href="https://arxiv.org/abs/2208.14501">arxiv:2208.14501</a>
&#x1F4C8; 2 <br>
<p>Rushiv Arora, Bruno Castro da Silva, Eliot Moss</p></summary>
<p>

**Abstract:** We draw on the latest advancements in the physics community to propose a novel method for discovering the governing non-linear dynamics of physical systems in reinforcement learning (RL). We establish that this method is capable of discovering the underlying dynamics using significantly fewer trajectories (as little as one rollout with $\leq 30$ time steps) than state of the art model learning algorithms. Further, the technique learns a model that is accurate enough to induce near-optimal policies given significantly fewer trajectories than those required by model-free algorithms. It brings the benefits of model-based RL without requiring a model to be developed in advance, for systems that have physics-based dynamics.
  To establish the validity and applicability of this algorithm, we conduct experiments on four classic control tasks. We found that an optimal policy trained on the discovered dynamics of the underlying system can generalize well. Further, the learned policy performs well when deployed on the actual physical system, thus bridging the model to real system gap. We further compare our method to state-of-the-art model-based and model-free approaches, and show that our method requires fewer trajectories sampled on the true physical system compared other methods. Additionally, we explored approximate dynamics models and found that they also can perform well.

</p>
</details>

<details><summary><b>Constraining Representations Yields Models That Know What They Don't Know</b>
<a href="https://arxiv.org/abs/2208.14488">arxiv:2208.14488</a>
&#x1F4C8; 2 <br>
<p>Joao Monteiro, Pau Rodriguez, Pierre-Andre Noel, Issam Laradji, David Vazquez</p></summary>
<p>

**Abstract:** A well-known failure mode of neural networks corresponds to high confidence erroneous predictions, especially for data that somehow differs from the training distribution. Such an unsafe behaviour limits their applicability. To counter that, we show that models offering accurate confidence levels can be defined via adding constraints in their internal representations. That is, we encode class labels as fixed unique binary vectors, or class codes, and use those to enforce class-dependent activation patterns throughout the model. Resulting predictors are dubbed Total Activation Classifiers (TAC), and TAC is used as an additional component to a base classifier to indicate how reliable a prediction is. Given a data instance, TAC slices intermediate representations into disjoint sets and reduces such slices into scalars, yielding activation profiles. During training, activation profiles are pushed towards the code assigned to a given training instance. At testing time, one can predict the class corresponding to the code that best matches the activation profile of an example. Empirically, we observe that the resemblance between activation patterns and their corresponding codes results in an inexpensive unsupervised approach for inducing discriminative confidence scores. Namely, we show that TAC is at least as good as state-of-the-art confidence scores extracted from existing models, while strictly improving the model's value on the rejection setting. TAC was also observed to work well on multiple types of architectures and data modalities.

</p>
</details>

<details><summary><b>Dual Representation Learning for One-Step Clustering of Multi-View Data</b>
<a href="https://arxiv.org/abs/2208.14450">arxiv:2208.14450</a>
&#x1F4C8; 2 <br>
<p>Wei Zhang, Zhaohong Deng, Kup-Sze Choi, Jun Wang, Shitong Wang</p></summary>
<p>

**Abstract:** Multi-view data are commonly encountered in data mining applications. Effective extraction of information from multi-view data requires specific design of clustering methods to cater for data with multiple views, which is non-trivial and challenging. In this paper, we propose a novel one-step multi-view clustering method by exploiting the dual representation of both the common and specific information of different views. The motivation originates from the rationale that multi-view data contain not only the consistent knowledge between views but also the unique knowledge of each view. Meanwhile, to make the representation learning more specific to the clustering task, a one-step learning framework is proposed to integrate representation learning and clustering partition as a whole. With this framework, the representation learning and clustering partition mutually benefit each other, which effectively improve the clustering performance. Results from extensive experiments conducted on benchmark multi-view datasets clearly demonstrate the superiority of the proposed method.

</p>
</details>

<details><summary><b>A Learning-Based 3D EIT Image Reconstruction Method</b>
<a href="https://arxiv.org/abs/2208.14449">arxiv:2208.14449</a>
&#x1F4C8; 2 <br>
<p>Zhaoguang Yi, Zhou Chen, Yunjie Yang</p></summary>
<p>

**Abstract:** Deep learning has been widely employed to solve the Electrical Impedance Tomography (EIT) image reconstruction problem. Most existing physical model-based and learning-based approaches focus on 2D EIT image reconstruction. However, when they are directly extended to the 3D domain, the reconstruction performance in terms of image quality and noise robustness is hardly guaranteed mainly due to the significant increase in dimensionality. This paper presents a learning-based approach for 3D EIT image reconstruction, which is named Transposed convolution with Neurons Network (TN-Net). Simulation and experimental results show the superior performance and generalization ability of TN-Net compared with prevailing 3D EIT image reconstruction algorithms.

</p>
</details>

<details><summary><b>Machine learning in the prediction of cardiac epicardial and mediastinal fat volumes</b>
<a href="https://arxiv.org/abs/2208.14374">arxiv:2208.14374</a>
&#x1F4C8; 2 <br>
<p>É. O. Rodrigues, V. H. A. Pinheiro, P. Liatsis, A. Conci</p></summary>
<p>

**Abstract:** We propose a methodology to predict the cardiac epicardial and mediastinal fat volumes in computed tomography images using regression algorithms. The obtained results indicate that it is feasible to predict these fats with a high degree of correlation, thus alleviating the requirement for manual or automatic segmentation of both fat volumes. Instead, segmenting just one of them suffices, while the volume of the other may be predicted fairly precisely. The correlation coefficient obtained by the Rotation Forest algorithm using MLP Regressor for predicting the mediastinal fat based on the epicardial fat was 0.9876, with a relative absolute error of 14.4% and a root relative squared error of 15.7%. The best correlation coefficient obtained in the prediction of the epicardial fat based on the mediastinal was 0.9683 with a relative absolute error of 19.6% and a relative squared error of 24.9%. Moreover, we analysed the feasibility of using linear regressors, which provide an intuitive interpretation of the underlying approximations. In this case, the obtained correlation coefficient was 0.9534 for predicting the mediastinal fat based on the epicardial, with a relative absolute error of 31.6% and a root relative squared error of 30.1%. On the prediction of the epicardial fat based on the mediastinal fat, the correlation coefficient was 0.8531, with a relative absolute error of 50.43% and a root relative squared error of 52.06%. In summary, it is possible to speed up general medical analyses and some segmentation and quantification methods that are currently employed in the state-of-the-art by using this prediction approach, which consequently reduces costs and therefore enables preventive treatments that may lead to a reduction of health problems.

</p>
</details>

<details><summary><b>FAST-AID Brain: Fast and Accurate Segmentation Tool using Artificial Intelligence Developed for Brain</b>
<a href="https://arxiv.org/abs/2208.14360">arxiv:2208.14360</a>
&#x1F4C8; 2 <br>
<p>Mostafa Mehdipour Ghazi, Mads Nielsen</p></summary>
<p>

**Abstract:** Medical images used in clinical practice are heterogeneous and not the same quality as scans studied in academic research. Preprocessing breaks down in extreme cases when anatomy, artifacts, or imaging parameters are unusual or protocols are different. Methods robust to these variations are most needed. A novel deep learning method is proposed for fast and accurate segmentation of the human brain into 132 regions. The proposed model uses an efficient U-Net-like network and benefits from the intersection points of different views and hierarchical relations for the fusion of the orthogonal 2D planes and brain labels during the end-to-end training. Weakly supervised learning is deployed to take the advantage of partially labeled data for the whole brain segmentation and estimation of the intracranial volume (ICV). Moreover, data augmentation is used to expand the magnetic resonance imaging (MRI) data by generating realistic brain scans with high variability for robust training of the model while preserving data privacy. The proposed method can be applied to brain MRI data including skull or any other artifacts without preprocessing the images or a drop in performance. Several experiments using different atlases are conducted to evaluate the segmentation performance of the trained model compared to the state-of-the-art, and the results show higher segmentation accuracy and robustness of the proposed model compared to the existing methods across different intra- and inter-domain datasets.

</p>
</details>

<details><summary><b>On the Automated Segmentation of Epicardial and Mediastinal Cardiac Adipose Tissues Using Classification Algorithms</b>
<a href="https://arxiv.org/abs/2208.14352">arxiv:2208.14352</a>
&#x1F4C8; 2 <br>
<p>Érick Oliveira Rodrigues, Felipe Fernandes Cordeiro de Morais, Aura Conci</p></summary>
<p>

**Abstract:** The quantification of fat depots on the surroundings of the heart is an accurate procedure for evaluating health risk factors correlated with several diseases. However, this type of evaluation is not widely employed in clinical practice due to the required human workload. This work proposes a novel technique for the automatic segmentation of cardiac fat pads. The technique is based on applying classification algorithms to the segmentation of cardiac CT images. Furthermore, we extensively evaluate the performance of several algorithms on this task and discuss which provided better predictive models. Experimental results have shown that the mean accuracy for the classification of epicardial and mediastinal fats has been 98.4% with a mean true positive rate of 96.2%. On average, the Dice similarity index, regarding the segmented patients and the ground truth, was equal to 96.8%. Therfore, our technique has achieved the most accurate results for the automatic segmentation of cardiac fats, to date.

</p>
</details>

<details><summary><b>FUSION: Fully Unsupervised Test-Time Stain Adaptation via Fused Normalization Statistics</b>
<a href="https://arxiv.org/abs/2208.14206">arxiv:2208.14206</a>
&#x1F4C8; 2 <br>
<p>Nilanjan Chattopadhyay, Shiv Gehlot, Nitin Singhal</p></summary>
<p>

**Abstract:** Staining reveals the micro structure of the aspirate while creating histopathology slides. Stain variation, defined as a chromatic difference between the source and the target, is caused by varying characteristics during staining, resulting in a distribution shift and poor performance on the target. The goal of stain normalization is to match the target's chromatic distribution to that of the source. However, stain normalisation causes the underlying morphology to distort, resulting in an incorrect diagnosis. We propose FUSION, a new method for promoting stain-adaption by adjusting the model to the target in an unsupervised test-time scenario, eliminating the necessity for significant labelling at the target end. FUSION works by altering the target's batch normalization statistics and fusing them with source statistics using a weighting factor. The algorithm reduces to one of two extremes based on the weighting factor. Despite the lack of training or supervision, FUSION surpasses existing equivalent algorithms for classification and dense predictions (segmentation), as demonstrated by comprehensive experiments on two public datasets.

</p>
</details>

<details><summary><b>On the Trade-Off between Actionable Explanations and the Right to be Forgotten</b>
<a href="https://arxiv.org/abs/2208.14137">arxiv:2208.14137</a>
&#x1F4C8; 2 <br>
<p>Martin Pawelczyk, Tobias Leemann, Asia Biega, Gjergji Kasneci</p></summary>
<p>

**Abstract:** As machine learning (ML) models are increasingly being deployed in high-stakes applications, policymakers have suggested tighter data protection regulations (e.g., GDPR, CCPA). One key principle is the ``right to be forgotten'' which gives users the right to have their data deleted. Another key principle is the right to an actionable explanation, also known as algorithmic recourse, allowing users to reverse unfavorable decisions. To date it is unknown whether these two principles can be operationalized simultaneously. Therefore, we introduce and study the problem of recourse invalidation in the context of data deletion requests. More specifically, we theoretically and empirically analyze the behavior of popular state-of-the-art algorithms and demonstrate that the recourses generated by these algorithms are likely to be invalidated if a small number of data deletion requests (e.g., 1 or 2) warrant updates of the predictive model. For the setting of linear models and overparameterized neural networks -- studied through the lens of neural tangent kernels (NTKs) -- we suggest a framework to identify a minimal subset of critical training points, which when removed, would lead to maximize the fraction of invalidated recourses. Using our framework, we empirically establish that the removal of as little as 2 data instances from the training set can invalidate up to 95 percent of all recourses output by popular state-of-the-art algorithms. Thus, our work raises fundamental questions about the compatibility of ``the right to an actionable explanation'' in the context of the ``right to be forgotten''.

</p>
</details>

<details><summary><b>Symmetric Pruning in Quantum Neural Networks</b>
<a href="https://arxiv.org/abs/2208.14057">arxiv:2208.14057</a>
&#x1F4C8; 2 <br>
<p>Xinbiao Wang, Junyu Liu, Tongliang Liu, Yong Luo, Yuxuan Du, Dacheng Tao</p></summary>
<p>

**Abstract:** Many fundamental properties of a quantum system are captured by its Hamiltonian and ground state. Despite the significance of ground states preparation (GSP), this task is classically intractable for large-scale Hamiltonians. Quantum neural networks (QNNs), which exert the power of modern quantum machines, have emerged as a leading protocol to conquer this issue. As such, how to enhance the performance of QNNs becomes a crucial topic in GSP. Empirical evidence showed that QNNs with handcraft symmetric ansatzes generally experience better trainability than those with asymmetric ansatzes, while theoretical explanations have not been explored. To fill this knowledge gap, here we propose the effective quantum neural tangent kernel (EQNTK) and connect this concept with over-parameterization theory to quantify the convergence of QNNs towards the global optima. We uncover that the advance of symmetric ansatzes attributes to their large EQNTK value with low effective dimension, which requests few parameters and quantum circuit depth to reach the over-parameterization regime permitting a benign loss landscape and fast convergence. Guided by EQNTK, we further devise a symmetric pruning (SP) scheme to automatically tailor a symmetric ansatz from an over-parameterized and asymmetric one to greatly improve the performance of QNNs when the explicit symmetry information of Hamiltonian is unavailable. Extensive numerical simulations are conducted to validate the analytical results of EQNTK and the effectiveness of SP.

</p>
</details>

<details><summary><b>Spacecraft depth completion based on the gray image and the sparse depth map</b>
<a href="https://arxiv.org/abs/2208.14030">arxiv:2208.14030</a>
&#x1F4C8; 2 <br>
<p>Xiang Liu, Hongyuan Wang, Zhiqiang Yan, Yu Chen, Xinlong Chen, Weichun Chen</p></summary>
<p>

**Abstract:** Perceiving the three-dimensional (3D) structure of the spacecraft is a prerequisite for successfully executing many on-orbit space missions, and it can provide critical input for many downstream vision algorithms. In this paper, we propose to sense the 3D structure of spacecraft using light detection and ranging sensor (LIDAR) and a monocular camera. To this end, Spacecraft Depth Completion Network (SDCNet) is proposed to recover the dense depth map based on gray image and sparse depth map. Specifically, SDCNet decomposes the object-level spacecraft depth completion task into foreground segmentation subtask and foreground depth completion subtask, which segments the spacecraft region first and then performs depth completion on the segmented foreground area. In this way, the background interference to foreground spacecraft depth completion is effectively avoided. Moreover, an attention-based feature fusion module is also proposed to aggregate the complementary information between different inputs, which deduces the correlation between different features along the channel and the spatial dimension sequentially. Besides, four metrics are also proposed to evaluate object-level depth completion performance, which can more intuitively reflect the quality of spacecraft depth completion results. Finally, a large-scale satellite depth completion dataset is constructed for training and testing spacecraft depth completion algorithms. Empirical experiments on the dataset demonstrate the effectiveness of the proposed SDCNet, which achieves 0.25m mean absolute error of interest and 0.759m mean absolute truncation error, surpassing state-of-the-art methods by a large margin. The spacecraft pose estimation experiment is also conducted based on the depth completion results, and the experimental results indicate that the predicted dense depth map could meet the needs of downstream vision tasks.

</p>
</details>

<details><summary><b>Lesion-Specific Prediction with Discriminator-Based Supervised Guided Attention Module Enabled GANs in Multiple Sclerosis</b>
<a href="https://arxiv.org/abs/2208.14533">arxiv:2208.14533</a>
&#x1F4C8; 1 <br>
<p>Jueqi Wang, Derek Berger, Erin Mazerolle, Jean-Alexis Delamer, Jacob Levman</p></summary>
<p>

**Abstract:** Multiple Sclerosis (MS) is a chronic neurological condition characterized by the development of lesions in the white matter of the brain. T2-fluid attenuated inversion recovery (FLAIR) brain magnetic resonance imaging (MRI) provides superior visualization and characterization of MS lesions, relative to other MRI modalities. Follow-up brain FLAIR MRI in MS provides helpful information for clinicians towards monitoring disease progression. In this study, we propose a novel modification to generative adversarial networks (GANs) to predict future lesion-specific FLAIR MRI for MS at fixed time intervals. We use supervised guided attention and dilated convolutions in the discriminator, which supports making an informed prediction of whether the generated images are real or not based on attention to the lesion area, which in turn has potential to help improve the generator to predict the lesion area of future examinations more accurately. We compared our method to several baselines and one state-of-art CF-SAGAN model [1]. In conclusion, our results indicate that the proposed method achieves higher accuracy and reduces the standard deviation of the prediction errors in the lesion area compared with other models with similar overall performance.

</p>
</details>

<details><summary><b>Comparing Results of Thermographic Images Based Diagnosis for Breast Diseases</b>
<a href="https://arxiv.org/abs/2208.14410">arxiv:2208.14410</a>
&#x1F4C8; 1 <br>
<p>E. O. Rodrigues, A. Conci, T. B. Borchartt, A. C. Paiva, A. C. Silva, T. MacHenry</p></summary>
<p>

**Abstract:** This paper examines the potential contribution of infrared (IR) imaging in breast diseases detection. It compares obtained results using some algorithms for detection of malignant breast conditions such as Support Vector Machine (SVM) regarding the consistency of different approaches when applied to public data. Moreover, in order to avail the actual IR imaging's capability as a complement on clinical trials and to promote researches using high-resolution IR imaging we deemed the use of a public database revised by confidently trained breast physicians as essential. Only the static acquisition protocol is regarded in our work. We used lO2 IR single breast images from the Pro Engenharia (PROENG) public database (54 normal and 48 with some finding). These images were collected from Universidade Federal de Pernambuco (UFPE) University's Hospital. We employed the same features proposed by the authors of the work that presented the best results and achieved an accuracy of 61.7 % and Youden index of 0.24 using the Sequential Minimal Optimization (SMO) classifier.

</p>
</details>

<details><summary><b>GaitFi: Robust Device-Free Human Identification via WiFi and Vision Multimodal Learning</b>
<a href="https://arxiv.org/abs/2208.14326">arxiv:2208.14326</a>
&#x1F4C8; 1 <br>
<p>Lang Deng, Jianfei Yang, Shenghai Yuan, Han Zou, Chris Xiaoxuan Lu, Lihua Xie</p></summary>
<p>

**Abstract:** As an important biomarker for human identification, human gait can be collected at a distance by passive sensors without subject cooperation, which plays an essential role in crime prevention, security detection and other human identification applications. At present, most research works are based on cameras and computer vision techniques to perform gait recognition. However, vision-based methods are not reliable when confronting poor illuminations, leading to degrading performances. In this paper, we propose a novel multimodal gait recognition method, namely GaitFi, which leverages WiFi signals and videos for human identification. In GaitFi, Channel State Information (CSI) that reflects the multi-path propagation of WiFi is collected to capture human gaits, while videos are captured by cameras. To learn robust gait information, we propose a Lightweight Residual Convolution Network (LRCN) as the backbone network, and further propose the two-stream GaitFi by integrating WiFi and vision features for the gait retrieval task. The GaitFi is trained by the triplet loss and classification loss on different levels of features. Extensive experiments are conducted in the real world, which demonstrates that the GaitFi outperforms state-of-the-art gait recognition methods based on single WiFi or camera, achieving 94.2% for human identification tasks of 12 subjects.

</p>
</details>

<details><summary><b>DLDNN: Deterministic Lateral Displacement Design Automation by Neural Networks</b>
<a href="https://arxiv.org/abs/2208.14303">arxiv:2208.14303</a>
&#x1F4C8; 1 <br>
<p>Farzad Vatandoust, Hoseyn A. Amiri, Sima Mas-hafi</p></summary>
<p>

**Abstract:** Size-based separation of bioparticles/cells is crucial to a variety of biomedical processing steps for applications such as exosomes and DNA isolation. Design and improvement of such microfluidic devices is a challenge to best answer the demand for producing homogeneous end-result for study and use. Deterministic lateral displacement (DLD) exploits a similar principle that has drawn extensive attention over years. However, the lack of predictive understanding of the particle trajectory and its induced mode makes designing a DLD device an iterative procedure. Therefore, this paper investigates a fast versatile design automation platform to address this issue. To do so, convolutional and artificial neural networks were employed to learn velocity fields and critical diameters of a wide range of DLD configurations. Later, these networks were combined with a multi-objective evolutionary algorithm to construct the automation tool. After ensuring the accuracy of the neural networks, the developed tool was tested for 12 critical conditions. Reaching the imposed conditions, the automation components performed reliably with errors of less than 4%. Moreover, this tool is generalizable to other field-based problems and since the neural network is an integral part of this method, it enables transfer learning for similar physics. All the codes generated and used in this study alongside the pre-trained neural network models are available on https://github.com/HoseynAAmiri/DLDNN.

</p>
</details>

<details><summary><b>Leap-frog neural network for learning the symplectic evolution from partitioned data</b>
<a href="https://arxiv.org/abs/2208.14148">arxiv:2208.14148</a>
&#x1F4C8; 1 <br>
<p>Xin Li, Jian Li, Zhihong Jeff Xia</p></summary>
<p>

**Abstract:** For the Hamiltonian system, this work considers the learning and prediction of the position (q) and momentum (p) variables generated by a symplectic evolution map. Similar to Chen & Tao (2021), the symplectic map is represented by the generating function. In addition, we develop a new learning scheme by splitting the time series (q_i, p_i) into several partitions, and then train a leap-frog neural network (LFNN) to approximate the generating function between the first (i.e. initial condition) and one of the rest partitions. For predicting the system evolution in a short timescale, the LFNN could effectively avoid the issue of accumulative error. Then the LFNN is applied to learn the behavior of the 2:3 resonant Kuiper belt objects, in a much longer time period, and there are two significant improvements on the neural network constructed in our previous work (Li et al. 2022): (1) conservation of the Jacobi integral ; (2) highly accurate prediction of the orbital evolution. We propose that the LFNN may be useful to make the prediction of the long time evolution of the Hamiltonian system.

</p>
</details>

<details><summary><b>Stabilize, Decompose, and Denoise: Self-Supervised Fluoroscopy Denoising</b>
<a href="https://arxiv.org/abs/2208.14022">arxiv:2208.14022</a>
&#x1F4C8; 1 <br>
<p>Ruizhou Liu, Qiang Ma, Zhiwei Cheng, Yuanyuan Lyu, Jianji Wang, S. Kevin Zhou</p></summary>
<p>

**Abstract:** Fluoroscopy is an imaging technique that uses X-ray to obtain a real-time 2D video of the interior of a 3D object, helping surgeons to observe pathological structures and tissue functions especially during intervention. However, it suffers from heavy noise that mainly arises from the clinical use of a low dose X-ray, thereby necessitating the technology of fluoroscopy denoising. Such denoising is challenged by the relative motion between the object being imaged and the X-ray imaging system. We tackle this challenge by proposing a self-supervised, three-stage framework that exploits the domain knowledge of fluoroscopy imaging. (i) Stabilize: we first construct a dynamic panorama based on optical flow calculation to stabilize the non-stationary background induced by the motion of the X-ray detector. (ii) Decompose: we then propose a novel mask-based Robust Principle Component Analysis (RPCA) decomposition method to separate a video with detector motion into a low-rank background and a sparse foreground. Such a decomposition accommodates the reading habit of experts. (iii) Denoise: we finally denoise the background and foreground separately by a self-supervised learning strategy and fuse the denoised parts into the final output via a bilateral, spatiotemporal filter. To assess the effectiveness of our work, we curate a dedicated fluoroscopy dataset of 27 videos (1,568 frames) and corresponding ground truth. Our experiments demonstrate that it achieves significant improvements in terms of denoising and enhancement effects when compared with standard approaches. Finally, expert rating confirms this efficacy.

</p>
</details>

<details><summary><b>Data-Driven Chance Constrained AC-OPF using Hybrid Sparse Gaussian Processes</b>
<a href="https://arxiv.org/abs/2208.14814">arxiv:2208.14814</a>
&#x1F4C8; 0 <br>
<p>Mile Mitrovic, Aleksandr Lukashevich, Petr Vorobev, Vladimir Terzija, Yury Maximov, Deepjyoti Deka</p></summary>
<p>

**Abstract:** The alternating current (AC) chance-constrained optimal power flow (CC-OPF) problem addresses the economic efficiency of electricity generation and delivery under generation uncertainty. The latter is intrinsic to modern power grids because of the high amount of renewables. Despite its academic success, the AC CC-OPF problem is highly nonlinear and computationally demanding, which limits its practical impact. For improving the AC-OPF problem complexity/accuracy trade-off, the paper proposes a fast data-driven setup that uses the sparse and hybrid Gaussian processes (GP) framework to model the power flow equations with input uncertainty. We advocate the efficiency of the proposed approach by a numerical study over multiple IEEE test cases showing up to two times faster and more accurate solutions compared to the state-of-the-art methods.

</p>
</details>

<details><summary><b>Fine-Grained Distribution-Dependent Learning Curves</b>
<a href="https://arxiv.org/abs/2208.14615">arxiv:2208.14615</a>
&#x1F4C8; 0 <br>
<p>Olivier Bousquet, Steve Hanneke, Shay Moran, Jonathan Shafer, Ilya Tolstikhin</p></summary>
<p>

**Abstract:** Learning curves plot the expected error of a learning algorithm as a function of the number of labeled input samples. They are widely used by machine learning practitioners as a measure of an algorithm's performance, but classic PAC learning theory cannot explain their behavior. In this paper we introduce a new combinatorial characterization called the VCL dimension that improves and refines the recent results of Bousquet et al. (2021). Our characterization sheds new light on the structure of learning curves by providing fine-grained bounds, and showing that for classes with finite VCL, the rate of decay can be decomposed into a linear component that depends only on the hypothesis class and an exponential component that depends also on the target distribution. In particular, the finer nuance of the VCL dimension implies lower bounds that are quantitatively stronger than the bounds of Bousquet et al. (2021) and qualitatively stronger than classic 'no free lunch' lower bounds. The VCL characterization solves an open problem studied by Antos and Lugosi (1998), who asked in what cases such lower bounds exist. As a corollary, we recover their lower bound for half-spaces in $\mathbb{R}^d$, and we do so in a principled way that should be applicable to other cases as well. Finally, to provide another viewpoint on our work and how it compares to traditional PAC learning bounds, we also present an alternative formulation of our results in a language that is closer to the PAC setting.

</p>
</details>

<details><summary><b>A topic-aware graph neural network model for knowledge base updating</b>
<a href="https://arxiv.org/abs/2208.14601">arxiv:2208.14601</a>
&#x1F4C8; 0 <br>
<p>Jiajun Tong, Zhixiao Wang, Xiaobin Rui</p></summary>
<p>

**Abstract:** The open domain knowledge base is very important. It is usually extracted from encyclopedia websites and is widely used in knowledge retrieval systems, question answering systems, or recommendation systems. In practice, the key challenge is to maintain an up-to-date knowledge base. Different from Unwieldy fetching all of the data from the encyclopedia dumps, to enlarge the freshness of the knowledge base as big as possible while avoiding invalid fetching, the current knowledge base updating methods usually determine whether entities need to be updated by building a prediction model. However, these methods can only be defined in some specific fields and the result turns out to be obvious bias, due to the problem of data source and data structure. The users' query intentions are often diverse as to the open domain knowledge, so we construct a topic-aware graph network for knowledge updating based on the user query log. Our methods can be summarized as follow: 1. Extract entities through the user's log and select them as seeds 2. Scrape the attributes of seed entities in the encyclopedia website, and self-supervised construct the entity attribute graph for each entity. 3. Use the entity attribute graph to train the GNN entity update model to determine whether the entity needs to be synchronized. 4.Use the encyclopedia knowledge to match and update the filtered entity with the entity in the knowledge base according to the minimum edit times algorithm.

</p>
</details>

<details><summary><b>One-class Recommendation Systems with the Hinge Pairwise Distance Loss and Orthogonal Representations</b>
<a href="https://arxiv.org/abs/2208.14594">arxiv:2208.14594</a>
&#x1F4C8; 0 <br>
<p>Ramin Raziperchikolaei, Young-joo Chung</p></summary>
<p>

**Abstract:** In one-class recommendation systems, the goal is to learn a model from a small set of interacted users and items and then identify the positively-related user-item pairs among a large number of pairs with unknown interactions. Most previous loss functions rely on dissimilar pairs of users and items, which are selected from the ones with unknown interactions, to obtain better prediction performance. This strategy introduces several challenges such as increasing training time and hurting the performance by picking "similar pairs with the unknown interactions" as dissimilar pairs. In this paper, the goal is to only use the similar set to train the models. We point out three trivial solutions that the models converge to when they are trained only on similar pairs: collapsed, partially collapsed, and shrinking solutions. We propose two terms that can be added to the objective functions in the literature to avoid these solutions. The first one is a hinge pairwise distance loss that avoids the shrinking and collapsed solutions by keeping the average pairwise distance of all the representations greater than a margin. The second one is an orthogonality term that minimizes the correlation between the dimensions of the representations and avoids the partially collapsed solution. We conduct experiments on a variety of tasks on public and real-world datasets. The results show that our approach using only similar pairs outperforms state-of-the-art methods using similar pairs and a large number of dissimilar pairs.

</p>
</details>

<details><summary><b>A Prescriptive Learning Analytics Framework: Beyond Predictive Modelling and onto Explainable AI with Prescriptive Analytics</b>
<a href="https://arxiv.org/abs/2208.14582">arxiv:2208.14582</a>
&#x1F4C8; 0 <br>
<p>Teo Susnjak</p></summary>
<p>

**Abstract:** A significant body of recent research in the field of Learning Analytics has focused on leveraging machine learning approaches for predicting at-risk students in order to initiate timely interventions and thereby elevate retention and completion rates. The overarching feature of the majority of these research studies has been on the science of prediction only. The component of predictive analytics concerned with interpreting the internals of the models and explaining their predictions for individual cases to stakeholders has largely been neglected. Additionally, works that attempt to employ data-driven prescriptive analytics to automatically generate evidence-based remedial advice for at-risk learners are in their infancy. eXplainable AI is a field that has recently emerged providing cutting-edge tools which support transparent predictive analytics and techniques for generating tailored advice for at-risk students. This study proposes a novel framework that unifies both transparent machine learning as well as techniques for enabling prescriptive analytics. This work practically demonstrates the proposed framework using predictive models for identifying at-risk learners of programme non-completion. The study then further demonstrates how predictive modelling can be augmented with prescriptive analytics on two case studies in order to generate human-readable prescriptive feedback for those who are at risk.

</p>
</details>

<details><summary><b>Truncated Matrix Power Iteration for Differentiable DAG Learning</b>
<a href="https://arxiv.org/abs/2208.14571">arxiv:2208.14571</a>
&#x1F4C8; 0 <br>
<p>Zhen Zhang, Ignavier Ng, Dong Gong, Yuhang Liu, Ehsan M Abbasnejad, Mingming Gong, Kun Zhang, Javen Qinfeng Shi</p></summary>
<p>

**Abstract:** Recovering underlying Directed Acyclic Graph structures (DAG) from observational data is highly challenging due to the combinatorial nature of the DAG-constrained optimization problem. Recently, DAG learning has been cast as a continuous optimization problem by characterizing the DAG constraint as a smooth equality one, generally based on polynomials over adjacency matrices. Existing methods place very small coefficients on high-order polynomial terms for stabilization, since they argue that large coefficients on the higher-order terms are harmful due to numeric exploding. On the contrary, we discover that large coefficients on higher-order terms are beneficial for DAG learning, when the spectral radiuses of the adjacency matrices are small, and that larger coefficients for higher-order terms can approximate the DAG constraints much better than the small counterparts. Based on this, we propose a novel DAG learning method with efficient truncated matrix power iteration to approximate geometric series-based DAG constraints. Empirically, our DAG learning method outperforms the previous state-of-the-arts in various settings, often by a factor of 3 or more in terms of structural Hamming distance.

</p>
</details>

<details><summary><b>Embedding Functional Data: Multidimensional Scaling and Manifold Learning</b>
<a href="https://arxiv.org/abs/2208.14540">arxiv:2208.14540</a>
&#x1F4C8; 0 <br>
<p>Ery Arias-Castro, Wanli Qiao</p></summary>
<p>

**Abstract:** We adapt concepts, methodology, and theory originally developed in the areas of multidimensional scaling and dimensionality reduction for multivariate data to the functional setting. We focus on classical scaling and Isomap -- prototypical methods that have played important roles in these area -- and showcase their use in the context of functional data analysis. In the process, we highlight the crucial role that the ambient metric plays.

</p>
</details>

<details><summary><b>A further exploration of deep Multi-Agent Reinforcement Learning with Hybrid Action Space</b>
<a href="https://arxiv.org/abs/2208.14447">arxiv:2208.14447</a>
&#x1F4C8; 0 <br>
<p>Hongzhi Hua, Guixuan Wen, Kaigui Wu</p></summary>
<p>

**Abstract:** The research of extending deep reinforcement learning (drl) to multi-agent field has solved many complicated problems and made great achievements. However, almost all these studies only focus on discrete or continuous action space and there are few works having ever used multi-agent deep reinforcement learning to real-world environment problems which mostly have a hybrid action space. Therefore, in this paper, we propose two algorithms: deep multi-agent hybrid soft actor-critic (MAHSAC) and multi-agent hybrid deep deterministic policy gradients (MAHDDPG) to fill this gap. This two algorithms follow the centralized training and decentralized execution (CTDE) paradigm and could handle hybrid action space problems. Our experiences are running on multi-agent particle environment which is an easy multi-agent particle world, along with some basic simulated physics. The experimental results show that these algorithms have good performances.

</p>
</details>

<details><summary><b>Representation Learning based and Interpretable Reactor System Diagnosis Using Denoising Padded Autoencoder</b>
<a href="https://arxiv.org/abs/2208.14319">arxiv:2208.14319</a>
&#x1F4C8; 0 <br>
<p>Chengyuan Li, Zhifang Qiu, Zhangrui Yan, Meifu Li</p></summary>
<p>

**Abstract:** With the mass construction of Gen III nuclear reactors, it is a popular trend to use deep learning (DL) techniques for fast and effective diagnosis of possible accidents. To overcome the common problems of previous work in diagnosing reactor accidents using deep learning theory, this paper proposes a diagnostic process that ensures robustness to noisy and crippled data and is interpretable. First, a novel Denoising Padded Autoencoder (DPAE) is proposed for representation extraction of monitoring data, with representation extractor still effective on disturbed data with signal-to-noise ratios up to 25.0 and monitoring data missing up to 40.0%. Secondly, a diagnostic framework using DPAE encoder for extraction of representations followed by shallow statistical learning algorithms is proposed, and such stepwise diagnostic approach is tested on disturbed datasets with 41.8% and 80.8% higher classification and regression task evaluation metrics, in comparison with the end-to-end diagnostic approaches. Finally, a hierarchical interpretation algorithm using SHAP and feature ablation is presented to analyze the importance of the input monitoring parameters and validate the effectiveness of the high importance parameters. The outcomes of this study provide a referential method for building robust and interpretable intelligent reactor anomaly diagnosis systems in scenarios with high safety requirements.

</p>
</details>

<details><summary><b>Weakly Supervised Faster-RCNN+FPN to classify animals in camera trap images</b>
<a href="https://arxiv.org/abs/2208.14060">arxiv:2208.14060</a>
&#x1F4C8; 0 <br>
<p>Pierrick Pochelu, Clara Erard, Philippe Cordier, Serge G. Petiton, Bruno Conche</p></summary>
<p>

**Abstract:** Camera traps have revolutionized the animal research of many species that were previously nearly impossible to observe due to their habitat or behavior. They are cameras generally fixed to a tree that take a short sequence of images when triggered. Deep learning has the potential to overcome the workload to automate image classification according to taxon or empty images. However, a standard deep neural network classifier fails because animals often represent a small portion of the high-definition images. That is why we propose a workflow named Weakly Object Detection Faster-RCNN+FPN which suits this challenge. The model is weakly supervised because it requires only the animal taxon label per image but doesn't require any manual bounding box annotations. First, it automatically performs the weakly-supervised bounding box annotation using the motion from multiple frames. Then, it trains a Faster-RCNN+FPN model using this weak supervision. Experimental results have been obtained with two datasets from a Papua New Guinea and Missouri biodiversity monitoring campaign, then on an easily reproducible testbed.

</p>
</details>

<details><summary><b>Intelligent Perception System for Vehicle-Road Cooperation</b>
<a href="https://arxiv.org/abs/2208.14052">arxiv:2208.14052</a>
&#x1F4C8; 0 <br>
<p>Songbin Chen</p></summary>
<p>

**Abstract:** With the development of autonomous driving, the improvement of autonomous driving technology for individual vehicles has reached the bottleneck. The advancement of vehicle-road cooperation autonomous driving technology can expand the vehicle's perception range, supplement the perception blind area and improve the perception accuracy, to promote the development of autonomous driving technology and achieve vehicle-road integration. This project mainly uses lidar to develop data fusion schemes to realize the sharing and combination of vehicle and road equipment data and achieve the detection and tracking of dynamic targets. At the same time, some test scenarios for the vehicle-road cooperative system were designed and used to test our vehicle-road cooperative awareness system, which proved the advantages of vehicle-road cooperative autonomous driving over single-vehicle autonomous driving.

</p>
</details>


{% endraw %}
Prev: [2022.08.29]({{ '/2022/08/29/2022.08.29.html' | relative_url }})  Next: [2022.08.31]({{ '/2022/08/31/2022.08.31.html' | relative_url }})