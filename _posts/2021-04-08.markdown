## Summary for 2021-04-08, created on 2021-12-22


<details><summary><b>SiT: Self-supervised vIsion Transformer</b>
<a href="https://arxiv.org/abs/2104.03602">arxiv:2104.03602</a>
&#x1F4C8; 116 <br>
<p>Sara Atito, Muhammad Awais, Josef Kittler</p></summary>
<p>

**Abstract:** Self-supervised learning methods are gaining increasing traction in computer vision due to their recent success in reducing the gap with supervised learning. In natural language processing (NLP) self-supervised learning and transformers are already the methods of choice. The recent literature suggests that the transformers are becoming increasingly popular also in computer vision. So far, the vision transformers have been shown to work well when pretrained either using a large scale supervised data or with some kind of co-supervision, e.g. in terms of teacher network. These supervised pretrained vision transformers achieve very good results in downstream tasks with minimal changes. In this work we investigate the merits of self-supervised learning for pretraining image/vision transformers and then using them for downstream classification tasks. We propose Self-supervised vIsion Transformers (SiT) and discuss several self-supervised training mechanisms to obtain a pretext model. The architectural flexibility of SiT allows us to use it as an autoencoder and work with multiple self-supervised tasks seamlessly. We show that a pretrained SiT can be finetuned for a downstream classification task on small scale datasets, consisting of a few thousand images rather than several millions. The proposed approach is evaluated on standard datasets using common protocols. The results demonstrate the strength of the transformers and their suitability for self-supervised learning. We outperformed existing self-supervised learning methods by large margin. We also observed that SiT is good for few shot learning and also showed that it is learning useful representation by simply training a linear classifier on top of the learned features from SiT. Pretraining, finetuning, and evaluation codes will be available under: https://github.com/Sara-Ahmed/SiT.

</p>
</details>

<details><summary><b>Progressive Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2104.03778">arxiv:2104.03778</a>
&#x1F4C8; 46 <br>
<p>Chuong Huynh, Anh Tran, Khoa Luu, Minh Hoai</p></summary>
<p>

**Abstract:** The objective of this work is to segment high-resolution images without overloading GPU memory usage or losing the fine details in the output segmentation map. The memory constraint means that we must either downsample the big image or divide the image into local patches for separate processing. However, the former approach would lose the fine details, while the latter can be ambiguous due to the lack of a global picture. In this work, we present MagNet, a multi-scale framework that resolves local ambiguity by looking at the image at multiple magnification levels. MagNet has multiple processing stages, where each stage corresponds to a magnification level, and the output of one stage is fed into the next stage for coarse-to-fine information propagation. Each stage analyzes the image at a higher resolution than the previous stage, recovering the previously lost details due to the lossy downsampling step, and the segmentation output is progressively refined through the processing stages. Experiments on three high-resolution datasets of urban views, aerial scenes, and medical images show that MagNet consistently outperforms the state-of-the-art methods by a significant margin.

</p>
</details>

<details><summary><b>Stable deep neural network architectures for mitochondria segmentation on electron microscopy volumes</b>
<a href="https://arxiv.org/abs/2104.03577">arxiv:2104.03577</a>
&#x1F4C8; 38 <br>
<p>Daniel Franco-Barranco, Arrate Muñoz-Barrutia, Ignacio Arganda-Carreras</p></summary>
<p>

**Abstract:** Electron microscopy (EM) allows the identification of intracellular organelles such as mitochondria, providing insights for clinical and scientific studies. In recent years, a number of novel deep learning architectures have been published reporting superior performance, or even human-level accuracy, compared to previous approaches on public mitochondria segmentation datasets. Unfortunately, many of these publications do not make neither the code nor the full training details public to support the results obtained, leading to reproducibility issues and dubious model comparisons. For that reason, and following a recent code of best practices for reporting experimental results, we present an extensive study of the state-of-the-art deep learning architectures for the segmentation of mitochondria on EM volumes, and evaluate the impact in performance of different variations of 2D and 3D U-Net-like models for this task. To better understand the contribution of each component, a common set of pre- and post-processing operations has been implemented and tested with each approach. Moreover, an exhaustive sweep of hyperparameters values for all architectures have been performed and each configuration has been run multiple times to report the mean and standard deviation values of the evaluation metrics. Using this methodology, we found very stable architectures and hyperparameter configurations that consistently obtain state-of-the-art results in the well-known EPFL Hippocampus mitochondria segmentation dataset. Furthermore, we have benchmarked our proposed models on two other available datasets, Lucchi++ and Kasthuri++, where they outperform all previous works. The code derived from this research and its documentation are publicly available.

</p>
</details>

<details><summary><b>Learning What To Do by Simulating the Past</b>
<a href="https://arxiv.org/abs/2104.03946">arxiv:2104.03946</a>
&#x1F4C8; 27 <br>
<p>David Lindner, Rohin Shah, Pieter Abbeel, Anca Dragan</p></summary>
<p>

**Abstract:** Since reward functions are hard to specify, recent work has focused on learning policies from human feedback. However, such approaches are impeded by the expense of acquiring such feedback. Recent work proposed that agents have access to a source of information that is effectively free: in any environment that humans have acted in, the state will already be optimized for human preferences, and thus an agent can extract information about what humans want from the state. Such learning is possible in principle, but requires simulating all possible past trajectories that could have led to the observed state. This is feasible in gridworlds, but how do we scale it to complex tasks? In this work, we show that by combining a learned feature encoder with learned inverse models, we can enable agents to simulate human actions backwards in time to infer what they must have done. The resulting algorithm is able to reproduce a specific skill in MuJoCo environments given a single state sampled from the optimal policy for that skill.

</p>
</details>

<details><summary><b>Does Your Dermatology Classifier Know What It Doesn't Know? Detecting the Long-Tail of Unseen Conditions</b>
<a href="https://arxiv.org/abs/2104.03829">arxiv:2104.03829</a>
&#x1F4C8; 12 <br>
<p>Abhijit Guha Roy, Jie Ren, Shekoofeh Azizi, Aaron Loh, Vivek Natarajan, Basil Mustafa, Nick Pawlowski, Jan Freyberg, Yuan Liu, Zach Beaver, Nam Vo, Peggy Bui, Samantha Winter, Patricia MacWilliams, Greg S. Corrado, Umesh Telang, Yun Liu, Taylan Cemgil, Alan Karthikesalingam, Balaji Lakshminarayanan, Jim Winkens</p></summary>
<p>

**Abstract:** We develop and rigorously evaluate a deep learning based system that can accurately classify skin conditions while detecting rare conditions for which there is not enough data available for training a confident classifier. We frame this task as an out-of-distribution (OOD) detection problem. Our novel approach, hierarchical outlier detection (HOD) assigns multiple abstention classes for each training outlier class and jointly performs a coarse classification of inliers vs. outliers, along with fine-grained classification of the individual classes. We demonstrate the effectiveness of the HOD loss in conjunction with modern representation learning approaches (BiT, SimCLR, MICLe) and explore different ensembling strategies for further improving the results. We perform an extensive subgroup analysis over conditions of varying risk levels and different skin types to investigate how the OOD detection performance changes over each subgroup and demonstrate the gains of our framework in comparison to baselines. Finally, we introduce a cost metric to approximate downstream clinical impact. We use this cost metric to compare the proposed method against a baseline system, thereby making a stronger case for the overall system effectiveness in a real-world deployment scenario.

</p>
</details>

<details><summary><b>An Empirical Comparison of Instance Attribution Methods for NLP</b>
<a href="https://arxiv.org/abs/2104.04128">arxiv:2104.04128</a>
&#x1F4C8; 10 <br>
<p>Pouya Pezeshkpour, Sarthak Jain, Byron C. Wallace, Sameer Singh</p></summary>
<p>

**Abstract:** Widespread adoption of deep models has motivated a pressing need for approaches to interpret network outputs and to facilitate model debugging. Instance attribution methods constitute one means of accomplishing these goals by retrieving training instances that (may have) led to a particular prediction. Influence functions (IF; Koh and Liang 2017) provide machinery for doing this by quantifying the effect that perturbing individual train instances would have on a specific test prediction. However, even approximating the IF is computationally expensive, to the degree that may be prohibitive in many cases. Might simpler approaches (e.g., retrieving train examples most similar to a given test point) perform comparably? In this work, we evaluate the degree to which different potential instance attribution agree with respect to the importance of training samples. We find that simple retrieval methods yield training instances that differ from those identified via gradient-based methods (such as IFs), but that nonetheless exhibit desirable characteristics similar to more complex attribution methods. Code for all methods and experiments in this paper is available at: https://github.com/successar/instance_attributions_NLP.

</p>
</details>

<details><summary><b>Contextual Semi-Supervised Learning: An Approach To Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems</b>
<a href="https://arxiv.org/abs/2104.03643">arxiv:2104.03643</a>
&#x1F4C8; 8 <br>
<p>Juan Zuluaga-Gomez, Iuliia Nigmatulina, Amrutha Prasad, Petr Motlicek, Karel Veselý, Martin Kocour, Igor Szöke</p></summary>
<p>

**Abstract:** Air traffic management and specifically air-traffic control (ATC) rely mostly on voice communications between Air Traffic Controllers (ATCos) and pilots. In most cases, these voice communications follow a well-defined grammar that could be leveraged in Automatic Speech Recognition (ASR) technologies. The callsign used to address an airplane is an essential part of all ATCo-pilot communications. We propose a two-steps approach to add contextual knowledge during semi-supervised training to reduce the ASR system error rates at recognizing the part of the utterance that contains the callsign. Initially, we represent in a WFST the contextual knowledge (i.e. air-surveillance data) of an ATCo-pilot communication. Then, during Semi-Supervised Learning (SSL) the contextual knowledge is added by second-pass decoding (i.e. lattice re-scoring). Results show that `unseen domains' (e.g. data from airports not present in the supervised training data) are further aided by contextual SSL when compared to standalone SSL. For this task, we introduce the Callsign Word Error Rate (CA-WER) as an evaluation metric, which only assesses ASR performance of the spoken callsign in an utterance. We obtained a 32.1% CA-WER relative improvement applying SSL with an additional 17.5% CA-WER improvement by adding contextual knowledge during SSL on a challenging ATC-based test set gathered from LiveATC.

</p>
</details>

<details><summary><b>eGAN: Unsupervised approach to class imbalance using transfer learning</b>
<a href="https://arxiv.org/abs/2104.04162">arxiv:2104.04162</a>
&#x1F4C8; 7 <br>
<p>Ademola Okerinde, Lior Shamir, William Hsu, Tom Theis, Nasik Nafi</p></summary>
<p>

**Abstract:** Class imbalance is an inherent problem in many machine learning classification tasks. This often leads to trained models that are unusable for any practical purpose. In this study we explore an unsupervised approach to address these imbalances by leveraging transfer learning from pre-trained image classification models to encoder-based Generative Adversarial Network (eGAN). To the best of our knowledge, this is the first work to tackle this problem using GAN without needing to augment with synthesized fake images.
  In the proposed approach we use the discriminator network to output a negative or positive score. We classify as minority, test samples with negative scores and as majority those with positive scores. Our approach eliminates epistemic uncertainty in model predictions, as the P(minority) + P(majority) need not sum up to 1. The impact of transfer learning and combinations of different pre-trained image classification models at the generator and discriminator is also explored. Best result of 0.69 F1-score was obtained on CIFAR-10 classification task with imbalance ratio of 1:2500.
  Our approach also provides a mechanism of thresholding the specificity or sensitivity of our machine learning system. Keywords: Class imbalance, Transfer Learning, GAN, nash equilibrium

</p>
</details>

<details><summary><b>FACESEC: A Fine-grained Robustness Evaluation Framework for Face Recognition Systems</b>
<a href="https://arxiv.org/abs/2104.04107">arxiv:2104.04107</a>
&#x1F4C8; 7 <br>
<p>Liang Tong, Zhengzhang Chen, Jingchao Ni, Wei Cheng, Dongjin Song, Haifeng Chen, Yevgeniy Vorobeychik</p></summary>
<p>

**Abstract:** We present FACESEC, a framework for fine-grained robustness evaluation of face recognition systems. FACESEC evaluation is performed along four dimensions of adversarial modeling: the nature of perturbation (e.g., pixel-level or face accessories), the attacker's system knowledge (about training data and learning architecture), goals (dodging or impersonation), and capability (tailored to individual inputs or across sets of these). We use FACESEC to study five face recognition systems in both closed-set and open-set settings, and to evaluate the state-of-the-art approach for defending against physically realizable attacks on these. We find that accurate knowledge of neural architecture is significantly more important than knowledge of the training data in black-box attacks. Moreover, we observe that open-set face recognition systems are more vulnerable than closed-set systems under different types of attacks. The efficacy of attacks for other threat model variations, however, appears highly dependent on both the nature of perturbation and the neural network architecture. For example, attacks that involve adversarial face masks are usually more potent, even against adversarially trained models, and the ArcFace architecture tends to be more robust than the others.

</p>
</details>

<details><summary><b>Flavored Tacotron: Conditional Learning for Prosodic-linguistic Features</b>
<a href="https://arxiv.org/abs/2104.04050">arxiv:2104.04050</a>
&#x1F4C8; 7 <br>
<p>Mahsa Elyasi, Gaurav Bharaj</p></summary>
<p>

**Abstract:** Neural sequence-to-sequence text-to-speech synthesis (TTS), such as Tacotron-2, transforms text into high-quality speech. However, generating speech with natural prosody still remains a challenge. Yasuda et. al. show that unlike natural speech, Tacotron-2's encoder doesn't fully represent prosodic features (e.g. syllable stress in English) from characters, and result in flat fundamental frequency variations.
  In this work, we propose a novel carefully designed strategy for conditioning Tacotron-2 on two fundamental prosodic features in English -- stress syllable and pitch accent, that help achieve more natural prosody. To this end, we use of a classifier to learn these features in an end-to-end fashion, and apply feature conditioning at three parts of Tacotron-2's Text-To-Mel Spectrogram: pre-encoder, post-encoder, and intra-decoder. Further, we show that jointly conditioned features at pre-encoder and intra-decoder stages result in prosodically natural synthesized speech (vs. Tacotron-2), and allows the model to produce speech with more accurate pitch accent and stress patterns.
  Quantitative evaluations show that our formulation achieves higher fundamental frequency contour correlation, and lower Mel Cepstral Distortion measure between synthesized and natural speech. And subjective evaluation shows that the proposed method's Mean Opinion Score of 4.14 fairs higher than baseline Tacotron-2, 3.91, when compared against natural speech (LJSpeech corpus), 4.28.

</p>
</details>

<details><summary><b>GrASP: A Library for Extracting and Exploring Human-Interpretable Textual Patterns</b>
<a href="https://arxiv.org/abs/2104.03958">arxiv:2104.03958</a>
&#x1F4C8; 7 <br>
<p>Piyawat Lertvittayakumjorn, Leshem Choshen, Eyal Shnarch, Francesca Toni</p></summary>
<p>

**Abstract:** Data exploration is an important step of every data science and machine learning project, including those involving textual data. We provide a Python library for GrASP, an existing algorithm for drawing patterns from textual data. The library is equipped with a web-based interface empowering human users to conveniently explore the data and the extracted patterns. We also demonstrate the use of the library in two settings (spam detection and argument mining) and discuss future deployments of the library, e.g., beyond textual data exploration.

</p>
</details>

<details><summary><b>A single gradient step finds adversarial examples on random two-layers neural networks</b>
<a href="https://arxiv.org/abs/2104.03863">arxiv:2104.03863</a>
&#x1F4C8; 7 <br>
<p>Sébastien Bubeck, Yeshwanth Cherapanamjeri, Gauthier Gidel, Rémi Tachet des Combes</p></summary>
<p>

**Abstract:** Daniely and Schacham recently showed that gradient descent finds adversarial examples on random undercomplete two-layers ReLU neural networks. The term "undercomplete" refers to the fact that their proof only holds when the number of neurons is a vanishing fraction of the ambient dimension. We extend their result to the overcomplete case, where the number of neurons is larger than the dimension (yet also subexponential in the dimension). In fact we prove that a single step of gradient descent suffices. We also show this result for any subexponential width random neural network with smooth activation function.

</p>
</details>

<details><summary><b>XFORMAL: A Benchmark for Multilingual Formality Style Transfer</b>
<a href="https://arxiv.org/abs/2104.04108">arxiv:2104.04108</a>
&#x1F4C8; 6 <br>
<p>Eleftheria Briakou, Di Lu, Ke Zhang, Joel Tetreault</p></summary>
<p>

**Abstract:** We take the first step towards multilingual style transfer by creating and releasing XFORMAL, a benchmark of multiple formal reformulations of informal text in Brazilian Portuguese, French, and Italian. Results on XFORMAL suggest that state-of-the-art style transfer approaches perform close to simple baselines, indicating that style transfer is even more challenging when moving multilingual.

</p>
</details>

<details><summary><b>CLVSA: A Convolutional LSTM Based Variational Sequence-to-Sequence Model with Attention for Predicting Trends of Financial Markets</b>
<a href="https://arxiv.org/abs/2104.04041">arxiv:2104.04041</a>
&#x1F4C8; 6 <br>
<p>Jia Wang, Tong Sun, Benyuan Liu, Yu Cao, Hongwei Zhu</p></summary>
<p>

**Abstract:** Financial markets are a complex dynamical system. The complexity comes from the interaction between a market and its participants, in other words, the integrated outcome of activities of the entire participants determines the markets trend, while the markets trend affects activities of participants. These interwoven interactions make financial markets keep evolving. Inspired by stochastic recurrent models that successfully capture variability observed in natural sequential data such as speech and video, we propose CLVSA, a hybrid model that consists of stochastic recurrent networks, the sequence-to-sequence architecture, the self- and inter-attention mechanism, and convolutional LSTM units to capture variationally underlying features in raw financial trading data. Our model outperforms basic models, such as convolutional neural network, vanilla LSTM network, and sequence-to-sequence model with attention, based on backtesting results of six futures from January 2010 to December 2017. Our experimental results show that, by introducing an approximate posterior, CLVSA takes advantage of an extra regularizer based on the Kullback-Leibler divergence to prevent itself from overfitting traps.

</p>
</details>

<details><summary><b>CARRNN: A Continuous Autoregressive Recurrent Neural Network for Deep Representation Learning from Sporadic Temporal Data</b>
<a href="https://arxiv.org/abs/2104.03739">arxiv:2104.03739</a>
&#x1F4C8; 6 <br>
<p>Mostafa Mehdipour Ghazi, Lauge Sørensen, Sébastien Ourselin, Mads Nielsen</p></summary>
<p>

**Abstract:** Learning temporal patterns from multivariate longitudinal data is challenging especially in cases when data is sporadic, as often seen in, e.g., healthcare applications where the data can suffer from irregularity and asynchronicity as the time between consecutive data points can vary across features and samples, hindering the application of existing deep learning models that are constructed for complete, evenly spaced data with fixed sequence lengths. In this paper, a novel deep learning-based model is developed for modeling multiple temporal features in sporadic data using an integrated deep learning architecture based on a recurrent neural network (RNN) unit and a continuous-time autoregressive (CAR) model. The proposed model, called CARRNN, uses a generalized discrete-time autoregressive model that is trainable end-to-end using neural networks modulated by time lags to describe the changes caused by the irregularity and asynchronicity. It is applied to multivariate time-series regression tasks using data provided for Alzheimer's disease progression modeling and intensive care unit (ICU) mortality rate prediction, where the proposed model based on a gated recurrent unit (GRU) achieves the lowest prediction errors among the proposed RNN-based models and state-of-the-art methods using GRUs and long short-term memory (LSTM) networks in their architecture.

</p>
</details>

<details><summary><b>On tuning consistent annealed sampling for denoising score matching</b>
<a href="https://arxiv.org/abs/2104.03725">arxiv:2104.03725</a>
&#x1F4C8; 6 <br>
<p>Joan Serrà, Santiago Pascual, Jordi Pons</p></summary>
<p>

**Abstract:** Score-based generative models provide state-of-the-art quality for image and audio synthesis. Sampling from these models is performed iteratively, typically employing a discretized series of noise levels and a predefined scheme. In this note, we first overview three common sampling schemes for models trained with denoising score matching. Next, we focus on one of them, consistent annealed sampling, and study its hyper-parameter boundaries. We then highlight a possible formulation of such hyper-parameter that explicitly considers those boundaries and facilitates tuning when using few or a variable number of steps. Finally, we highlight some connections of the formulation with other sampling schemes.

</p>
</details>

<details><summary><b>A Simple Geometric Method for Cross-Lingual Linguistic Transformations with Pre-trained Autoencoders</b>
<a href="https://arxiv.org/abs/2104.03630">arxiv:2104.03630</a>
&#x1F4C8; 6 <br>
<p>Maarten De Raedt, Fréderic Godin, Pieter Buteneers, Chris Develder, Thomas Demeester</p></summary>
<p>

**Abstract:** Powerful sentence encoders trained for multiple languages are on the rise. These systems are capable of embedding a wide range of linguistic properties into vector representations. While explicit probing tasks can be used to verify the presence of specific linguistic properties, it is unclear whether the vector representations can be manipulated to indirectly steer such properties. For efficient learning, we investigate the use of a geometric mapping in embedding space to transform linguistic properties, without any tuning of the pre-trained sentence encoder or decoder. We validate our approach on three linguistic properties using a pre-trained multilingual autoencoder and analyze the results in both monolingual and cross-lingual settings.

</p>
</details>

<details><summary><b>Generative Landmarks</b>
<a href="https://arxiv.org/abs/2104.04055">arxiv:2104.04055</a>
&#x1F4C8; 5 <br>
<p>David Ferman, Gaurav Bharaj</p></summary>
<p>

**Abstract:** We propose a general purpose approach to detect landmarks with improved temporal consistency, and personalization. Most sparse landmark detection methods rely on laborious, manually labelled landmarks, where inconsistency in annotations over a temporal volume leads to sub-optimal landmark learning. Further, high-quality landmarks with personalization is often hard to achieve. We pose landmark detection as an image translation problem. We capture two sets of unpaired marked (with paint) and unmarked videos. We then use a generative adversarial network and cyclic consistency to predict deformations of landmark templates that simulate markers on unmarked images until these images are indistinguishable from ground-truth marked images. Our novel method does not rely on manually labelled priors, is temporally consistent, and image class agnostic -- face, and hand landmarks detection examples are shown.

</p>
</details>

<details><summary><b>Fast Regression of the Tritium Breeding Ratio in Fusion Reactors</b>
<a href="https://arxiv.org/abs/2104.04026">arxiv:2104.04026</a>
&#x1F4C8; 5 <br>
<p>Petr Mánek, Graham Van Goffrier, Vignesh Gopakumar, Nikolaos Nikolaou, Jonathan Shimwell, Ingo Waldmann</p></summary>
<p>

**Abstract:** The tritium breeding ratio (TBR) is an essential quantity for the design of modern and next-generation D-T fueled nuclear fusion reactors. Representing the ratio between tritium fuel generated in breeding blankets and fuel consumed during reactor runtime, the TBR depends on reactor geometry and material properties in a complex manner. In this work, we explored the training of surrogate models to produce a cheap but high-quality approximation for a Monte Carlo TBR model in use at the UK Atomic Energy Authority. We investigated possibilities for dimensional reduction of its feature space, reviewed 9 families of surrogate models for potential applicability, and performed hyperparameter optimisation. Here we present the performance and scaling properties of these models, the fastest of which, an artificial neural network, demonstrated $R^2=0.985$ and a mean prediction time of $0.898\ μ\mathrm{s}$, representing a relative speedup of $8\cdot 10^6$ with respect to the expensive MC model. We further present a novel adaptive sampling algorithm, Quality-Adaptive Surrogate Sampling, capable of interfacing with any of the individually studied surrogates. Our preliminary testing on a toy TBR theory has demonstrated the efficacy of this algorithm for accelerating the surrogate modelling process.

</p>
</details>

<details><summary><b>Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in Prosthetic Hand Control</b>
<a href="https://arxiv.org/abs/2104.03893">arxiv:2104.03893</a>
&#x1F4C8; 5 <br>
<p>Mehrshad Zandigohar, Mo Han, Mohammadreza Sharif, Sezen Yagmur Gunay, Mariusz P. Furmanek, Mathew Yarossi, Paolo Bonato, Cagdas Onal, Taskin Padir, Deniz Erdogmus, Gunar Schirner</p></summary>
<p>

**Abstract:** For lower arm amputees, robotic prosthetic hands offer the promise to regain the capability to perform fine object manipulation in activities of daily living. Current control methods based on physiological signals such as EEG and EMG are prone to poor inference outcomes due to motion artifacts, variability of skin electrode junction impedance over time, muscle fatigue, and other factors. Visual evidence is also susceptible to its own artifacts, most often due to object occlusion, lighting changes, variable shapes of objects depending on view-angle, among other factors. Multimodal evidence fusion using physiological and vision sensor measurements is a natural approach due to the complementary strengths of these modalities.
  In this paper, we present a Bayesian evidence fusion framework for grasp intent inference using eye-view video, gaze, and EMG from the forearm processed by neural network models. We analyze individual and fused performance as a function of time as the hand approaches the object to grasp it. For this purpose, we have also developed novel data processing and augmentation techniques to train neural network components. Our experimental data analyses demonstrate that EMG and visual evidence show complementary strengths, and as a consequence, fusion of multimodal evidence can outperform each individual evidence modality at any given time. Specifically, results indicate that, on average, fusion improves the instantaneous upcoming grasp type classification accuracy while in the reaching phase by 13.66% and 14.8%, relative to EMG and visual evidence individually. An overall fusion accuracy of 95.3% among 13 labels (compared to a chance level of 7.7%) is achieved, and more detailed analysis indicate that the correct grasp is inferred sufficiently early and with high confidence compared to the top contender, in order to allow successful robot actuation to close the loop.

</p>
</details>

<details><summary><b>Enhancing Object Detection for Autonomous Driving by Optimizing Anchor Generation and Addressing Class Imbalance</b>
<a href="https://arxiv.org/abs/2104.03888">arxiv:2104.03888</a>
&#x1F4C8; 5 <br>
<p>Manuel Carranza-García, Pedro Lara-Benítez, Jorge García-Gutiérrez, José C. Riquelme</p></summary>
<p>

**Abstract:** Object detection has been one of the most active topics in computer vision for the past years. Recent works have mainly focused on pushing the state-of-the-art in the general-purpose COCO benchmark. However, the use of such detection frameworks in specific applications such as autonomous driving is yet an area to be addressed. This study presents an enhanced 2D object detector based on Faster R-CNN that is better suited for the context of autonomous vehicles. Two main aspects are improved: the anchor generation procedure and the performance drop in minority classes. The default uniform anchor configuration is not suitable in this scenario due to the perspective projection of the vehicle cameras. Therefore, we propose a perspective-aware methodology that divides the image into key regions via clustering and uses evolutionary algorithms to optimize the base anchors for each of them. Furthermore, we add a module that enhances the precision of the second-stage header network by including the spatial information of the candidate regions proposed in the first stage. We also explore different re-weighting strategies to address the foreground-foreground class imbalance, showing that the use of a reduced version of focal loss can significantly improve the detection of difficult and underrepresented objects in two-stage detectors. Finally, we design an ensemble model to combine the strengths of the different learning strategies. Our proposal is evaluated with the Waymo Open Dataset, which is the most extensive and diverse up to date. The results demonstrate an average accuracy improvement of 6.13% mAP when using the best single model, and of 9.69% mAP with the ensemble. The proposed modifications over the Faster R-CNN do not increase computational cost and can easily be extended to optimize other anchor-based detection frameworks.

</p>
</details>

<details><summary><b>RNN Transducer Models For Spoken Language Understanding</b>
<a href="https://arxiv.org/abs/2104.03842">arxiv:2104.03842</a>
&#x1F4C8; 5 <br>
<p>Samuel Thomas, Hong-Kwang J. Kuo, George Saon, Zoltán Tüske, Brian Kingsbury, Gakuto Kurata, Zvi Kons, Ron Hoory</p></summary>
<p>

**Abstract:** We present a comprehensive study on building and adapting RNN transducer (RNN-T) models for spoken language understanding(SLU). These end-to-end (E2E) models are constructed in three practical settings: a case where verbatim transcripts are available, a constrained case where the only available annotations are SLU labels and their values, and a more restrictive case where transcripts are available but not corresponding audio. We show how RNN-T SLU models can be developed starting from pre-trained automatic speech recognition (ASR) systems, followed by an SLU adaptation step. In settings where real audio data is not available, artificially synthesized speech is used to successfully adapt various SLU models. When evaluated on two SLU data sets, the ATIS corpus and a customer call center data set, the proposed models closely track the performance of other E2E models and achieve state-of-the-art results.

</p>
</details>

<details><summary><b>Bayesian Variational Federated Learning and Unlearning in Decentralized Networks</b>
<a href="https://arxiv.org/abs/2104.03834">arxiv:2104.03834</a>
&#x1F4C8; 5 <br>
<p>Jinu Gong, Osvaldo Simeone, Joonhyuk Kang</p></summary>
<p>

**Abstract:** Federated Bayesian learning offers a principled framework for the definition of collaborative training algorithms that are able to quantify epistemic uncertainty and to produce trustworthy decisions. Upon the completion of collaborative training, an agent may decide to exercise her legal "right to be forgotten", which calls for her contribution to the jointly trained model to be deleted and discarded. This paper studies federated learning and unlearning in a decentralized network within a Bayesian framework. It specifically develops federated variational inference (VI) solutions based on the decentralized solution of local free energy minimization problems within exponential-family models and on local gossip-driven communication. The proposed protocols are demonstrated to yield efficient unlearning mechanisms.

</p>
</details>

<details><summary><b>Open Domain Generalization with Domain-Augmented Meta-Learning</b>
<a href="https://arxiv.org/abs/2104.03620">arxiv:2104.03620</a>
&#x1F4C8; 5 <br>
<p>Yang Shu, Zhangjie Cao, Chenyu Wang, Jianmin Wang, Mingsheng Long</p></summary>
<p>

**Abstract:** Leveraging datasets available to learn a model with high generalization ability to unseen domains is important for computer vision, especially when the unseen domain's annotated data are unavailable. We study a novel and practical problem of Open Domain Generalization (OpenDG), which learns from different source domains to achieve high performance on an unknown target domain, where the distributions and label sets of each individual source domain and the target domain can be different. The problem can be generally applied to diverse source domains and widely applicable to real-world applications. We propose a Domain-Augmented Meta-Learning framework to learn open-domain generalizable representations. We augment domains on both feature-level by a new Dirichlet mixup and label-level by distilled soft-labeling, which complements each domain with missing classes and other domain knowledge. We conduct meta-learning over domains by designing new meta-learning tasks and losses to preserve domain unique knowledge and generalize knowledge across domains simultaneously. Experiment results on various multi-domain datasets demonstrate that the proposed Domain-Augmented Meta-Learning (DAML) outperforms prior methods for unseen domain recognition.

</p>
</details>

<details><summary><b>Characterization of Time-variant and Time-invariant Assessment of Suicidality on Reddit using C-SSRS</b>
<a href="https://arxiv.org/abs/2104.04140">arxiv:2104.04140</a>
&#x1F4C8; 4 <br>
<p>Manas Gaur, Vamsi Aribandi, Amanuel Alambo, Ugur Kursuncu, Krishnaprasad Thirunarayan, Jonanthan Beich, Jyotishman Pathak, Amit Sheth</p></summary>
<p>

**Abstract:** Suicide is the 10th leading cause of death in the U.S (1999-2019). However, predicting when someone will attempt suicide has been nearly impossible. In the modern world, many individuals suffering from mental illness seek emotional support and advice on well-known and easily-accessible social media platforms such as Reddit. While prior artificial intelligence research has demonstrated the ability to extract valuable information from social media on suicidal thoughts and behaviors, these efforts have not considered both severity and temporality of risk. The insights made possible by access to such data have enormous clinical potential - most dramatically envisioned as a trigger to employ timely and targeted interventions (i.e., voluntary and involuntary psychiatric hospitalization) to save lives. In this work, we address this knowledge gap by developing deep learning algorithms to assess suicide risk in terms of severity and temporality from Reddit data based on the Columbia Suicide Severity Rating Scale (C-SSRS). In particular, we employ two deep learning approaches: time-variant and time-invariant modeling, for user-level suicide risk assessment, and evaluate their performance against a clinician-adjudicated gold standard Reddit corpus annotated based on the C-SSRS. Our results suggest that the time-variant approach outperforms the time-invariant method in the assessment of suicide-related ideations and supportive behaviors (AUC:0.78), while the time-invariant model performed better in predicting suicide-related behaviors and suicide attempt (AUC:0.64). The proposed approach can be integrated with clinical diagnostic interviews for improving suicide risk assessments.

</p>
</details>

<details><summary><b>Towards Agrobots: Trajectory Control of an Autonomous Tractor Using Type-2 Fuzzy Logic Controllers</b>
<a href="https://arxiv.org/abs/2104.04123">arxiv:2104.04123</a>
&#x1F4C8; 4 <br>
<p>Erdal Kayacan, Erkan Kayacan, Herman Ramon, Okyay Kaynak, Wouter Saeys</p></summary>
<p>

**Abstract:** Provision of some autonomous functions to an agricultural vehicle would lighten the job of the operator but in doing so, the accuracy should not be lost to still obtain an optimal yield. Autonomous navigation of an agricultural vehicle involves the control of different dynamic subsystems, such as the yaw angle dynamics and the longitudinal speed dynamics. In this study, a proportional-integral-derivative controller is used to control the longitudinal velocity of the tractor. For the control of the yaw angle dynamics, a proportional-derivative controller works in parallel with a type-2 fuzzy neural network. In such an arrangement, the former ensures the stability of the related subsystem, while the latter learns the system dynamics and becomes the leading controller. In this way, instead of modeling the interactions between the subsystems prior to the design of model-based control, we develop a control algorithm which learns the interactions online from the measured feedback error. In addition to the control of the stated subsystems, a kinematic controller is needed to correct the errors in both the x- and the y- axis for the trajectory tracking problem of the tractor. To demonstrate the real-time abilities of the proposed control scheme, an autonomous tractor is equipped with the use of reasonably priced sensors and actuators. Experimental results show the efficacy and efficiency of the proposed learning algorithm.

</p>
</details>

<details><summary><b>Grapheme-to-Phoneme Transformer Model for Transfer Learning Dialects</b>
<a href="https://arxiv.org/abs/2104.04091">arxiv:2104.04091</a>
&#x1F4C8; 4 <br>
<p>Eric Engelhart, Mahsa Elyasi, Gaurav Bharaj</p></summary>
<p>

**Abstract:** Grapheme-to-Phoneme (G2P) models convert words to their phonetic pronunciations. Classic G2P methods include rule-based systems and pronunciation dictionaries, while modern G2P systems incorporate learning, such as, LSTM and Transformer-based attention models. Usually, dictionary-based methods require significant manual effort to build, and have limited adaptivity on unseen words. And transformer-based models require significant training data, and do not generalize well, especially for dialects with limited data.
  We propose a novel use of transformer-based attention model that can adapt to unseen dialects of English language, while using a small dictionary. We show that our method has potential applications for accent transfer for text-to-speech, and for building robust G2P models for dialects with limited pronunciation dictionary size.
  We experiment with two English dialects: Indian and British. A model trained from scratch using 1000 words from British English dictionary, with 14211 words held out, leads to phoneme error rate (PER) of 26.877%, on a test set generated using the full dictionary. The same model pretrained on CMUDict American English dictionary, and fine-tuned on the same dataset leads to PER of 2.469% on the test set.

</p>
</details>

<details><summary><b>Just Label What You Need: Fine-Grained Active Selection for Perception and Prediction through Partially Labeled Scenes</b>
<a href="https://arxiv.org/abs/2104.03956">arxiv:2104.03956</a>
&#x1F4C8; 4 <br>
<p>Sean Segal, Nishanth Kumar, Sergio Casas, Wenyuan Zeng, Mengye Ren, Jingkang Wang, Raquel Urtasun</p></summary>
<p>

**Abstract:** Self-driving vehicles must perceive and predict the future positions of nearby actors in order to avoid collisions and drive safely. A learned deep learning module is often responsible for this task, requiring large-scale, high-quality training datasets. As data collection is often significantly cheaper than labeling in this domain, the decision of which subset of examples to label can have a profound impact on model performance. Active learning techniques, which leverage the state of the current model to iteratively select examples for labeling, offer a promising solution to this problem. However, despite the appeal of this approach, there has been little scientific analysis of active learning approaches for the perception and prediction (P&P) problem. In this work, we study active learning techniques for P&P and find that the traditional active learning formulation is ill-suited for the P&P setting. We thus introduce generalizations that ensure that our approach is both cost-aware and allows for fine-grained selection of examples through partially labeled scenes. Our experiments on a real-world, large-scale self-driving dataset suggest that fine-grained selection can improve the performance across perception, prediction, and downstream planning tasks.

</p>
</details>

<details><summary><b>The Single-Noun Prior for Image Clustering</b>
<a href="https://arxiv.org/abs/2104.03952">arxiv:2104.03952</a>
&#x1F4C8; 4 <br>
<p>Niv Cohen, Yedid Hoshen</p></summary>
<p>

**Abstract:** Self-supervised clustering methods have achieved increasing accuracy in recent years but do not yet perform as well as supervised classification methods. This contrasts with the situation for feature learning, where self-supervised features have recently surpassed the performance of supervised features on several important tasks. We hypothesize that the performance gap is due to the difficulty of specifying, without supervision, which features correspond to class differences that are semantic to humans. To reduce the performance gap, we introduce the "single-noun" prior - which states that semantic clusters tend to correspond to concepts that humans label by a single-noun. By utilizing a pre-trained network that maps images and sentences into a common space, we impose this prior obtaining a constrained optimization task. We show that our formulation is a special case of the facility location problem, and introduce a simple-yet-effective approach for solving this optimization task at scale. We test our approach on several commonly reported image clustering datasets and obtain significant accuracy gains over the best existing approaches.

</p>
</details>

<details><summary><b>Towards End-to-End Neural Face Authentication in the Wild -- Quantifying and Compensating for Directional Lighting Effects</b>
<a href="https://arxiv.org/abs/2104.03854">arxiv:2104.03854</a>
&#x1F4C8; 4 <br>
<p>Viktor Varkarakis, Wang Yao, Peter Corcoran</p></summary>
<p>

**Abstract:** The recent availability of low-power neural accelerator hardware, combined with improvements in end-to-end neural facial recognition algorithms provides, enabling technology for on-device facial authentication. The present research work examines the effects of directional lighting on a State-of-Art(SoA) neural face recognizer. A synthetic re-lighting technique is used to augment data samples due to the lack of public data-sets with sufficient directional lighting variations. Top lighting and its variants (top-left, top-right) are found to have minimal effect on accuracy, while bottom-left or bottom-right directional lighting has the most pronounced effects. Following the fine-tuning of network weights, the face recognition model is shown to achieve close to the original Receiver Operating Characteristic curve (ROC)performance across all lighting conditions and demonstrates an ability to generalize beyond the lighting augmentations used in the fine-tuning data-set. This work shows that an SoA neural face recognition model can be tuned to compensate for directional lighting effects, removing the need for a pre-processing step before applying facial recognition.

</p>
</details>

<details><summary><b>A Reinforcement Learning Environment For Job-Shop Scheduling</b>
<a href="https://arxiv.org/abs/2104.03760">arxiv:2104.03760</a>
&#x1F4C8; 4 <br>
<p>Pierre Tassel, Martin Gebser, Konstantin Schekotihin</p></summary>
<p>

**Abstract:** Scheduling is a fundamental task occurring in various automated systems applications, e.g., optimal schedules for machines on a job shop allow for a reduction of production costs and waste. Nevertheless, finding such schedules is often intractable and cannot be achieved by Combinatorial Optimization Problem (COP) methods within a given time limit. Recent advances of Deep Reinforcement Learning (DRL) in learning complex behavior enable new COP application possibilities. This paper presents an efficient DRL environment for Job-Shop Scheduling -- an important problem in the field. Furthermore, we design a meaningful and compact state representation as well as a novel, simple dense reward function, closely related to the sparse make-span minimization criteria used by COP methods. We demonstrate that our approach significantly outperforms existing DRL methods on classic benchmark instances, coming close to state-of-the-art COP approaches.

</p>
</details>

<details><summary><b>Connecting Deep-Reinforcement-Learning-based Obstacle Avoidance with Conventional Global Planners using Waypoint Generators</b>
<a href="https://arxiv.org/abs/2104.03663">arxiv:2104.03663</a>
&#x1F4C8; 4 <br>
<p>Linh Kästner, Teham Buiyan, Xinlin Zhao, Zhengcheng Shen, Cornelius Marx, Jens Lambrecht</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning has emerged as an efficient dynamic obstacle avoidance method in highly dynamic environments. It has the potential to replace overly conservative or inefficient navigation approaches. However, the integration of Deep Reinforcement Learning into existing navigation systems is still an open frontier due to the myopic nature of Deep-Reinforcement-Learning-based navigation, which hinders its widespread integration into current navigation systems. In this paper, we propose the concept of an intermediate planner to interconnect novel Deep-Reinforcement-Learning-based obstacle avoidance with conventional global planning methods using waypoint generation. Therefore, we integrate different waypoint generators into existing navigation systems and compare the joint system against traditional ones. We found an increased performance in terms of safety, efficiency and path smoothness especially in highly dynamic environments.

</p>
</details>

<details><summary><b>Half-Truth: A Partially Fake Audio Detection Dataset</b>
<a href="https://arxiv.org/abs/2104.03617">arxiv:2104.03617</a>
&#x1F4C8; 4 <br>
<p>Jiangyan Yi, Ye Bai, Jianhua Tao, Zhengkun Tian, Chenglong Wang, Tao Wang, Ruibo Fu</p></summary>
<p>

**Abstract:** Diverse promising datasets have been designed to hold back the development of fake audio detection, such as ASVspoof databases. However, previous datasets ignore an attacking situation, in which the hacker hides some small fake clips in real speech audio. This poses a serious threat since that it is difficult to distinguish the small fake clip from the whole speech utterance. Therefore, this paper develops such a dataset for half-truth audio detection (HAD). Partially fake audio in the HAD dataset involves only changing a few words in an utterance.The audio of the words is generated with the very latest state-of-the-art speech synthesis technology. We can not only detect fake uttrances but also localize manipulated regions in a speech using this dataset. Some benchmark results are presented on this dataset. The results show that partially fake audio presents much more challenging than fully fake audio for fake audio detection.

</p>
</details>

<details><summary><b>M-Net with Bidirectional ConvLSTM for Cup and Disc Segmentation in Fundus Images</b>
<a href="https://arxiv.org/abs/2104.03549">arxiv:2104.03549</a>
&#x1F4C8; 4 <br>
<p>Maleeha Khalid Khan, Syed Muhammad Anwar</p></summary>
<p>

**Abstract:** Glaucoma is a severe eye disease that is known to deteriorate optic never fibers, causing cup size to increase, which could result in permanent loss of vision. Glaucoma is the second leading cause of blindness after cataract, but glaucoma being more dangerous as it is not curable. Early diagnoses and treatment of glaucoma can help to slow the progression of glaucoma and its damages. For the detection of glaucoma, the Cup to Disc ratio (CDR) provides significant information. The CDR depends heavily on the accurate segmentation of cup and disc regions. In this paper, we have proposed a modified M-Net with bidirectional convolution long short-term memory (LSTM), based on joint cup and disc segmentation. The proposed network combines features of encoder and decoder, with bidirectional LSTM. Our proposed model segments cup and disc regions based on which the abnormalities in cup to disc ratio can be observed. The proposed model is tested on REFUGE2 data, where our model achieves a dice score of 0.92 for optic disc and an accuracy of 98.99% in segmenting cup and disc regions

</p>
</details>

<details><summary><b>Archetypal Analysis for Sparse Nonnegative Matrix Factorization: Robustness Under Misspecification</b>
<a href="https://arxiv.org/abs/2104.03527">arxiv:2104.03527</a>
&#x1F4C8; 4 <br>
<p>Kayhan Behdin, Rahul Mazumder</p></summary>
<p>

**Abstract:** We consider the problem of sparse nonnegative matrix factorization (NMF) with archetypal regularization. The goal is to represent a collection of data points as nonnegative linear combinations of a few nonnegative sparse factors with appealing geometric properties, arising from the use of archetypal regularization. We generalize the notion of robustness studied in Javadi and Montanari (2019) (without sparsity) to the notions of (a) strong robustness that implies each estimated archetype is close to the underlying archetypes and (b) weak robustness that implies there exists at least one recovered archetype that is close to the underlying archetypes. Our theoretical results on robustness guarantees hold under minimal assumptions on the underlying data, and applies to settings where the underlying archetypes need not be sparse. We propose new algorithms for our optimization problem; and present numerical experiments on synthetic and real datasets that shed further insights into our proposed framework and theoretical developments.

</p>
</details>

<details><summary><b>Individual Explanations in Machine Learning Models: A Case Study on Poverty Estimation</b>
<a href="https://arxiv.org/abs/2104.04148">arxiv:2104.04148</a>
&#x1F4C8; 3 <br>
<p>Alfredo Carrillo, Luis F. Cantú, Luis Tejerina, Alejandro Noriega</p></summary>
<p>

**Abstract:** Machine learning methods are being increasingly applied in sensitive societal contexts, where decisions impact human lives. Hence it has become necessary to build capabilities for providing easily-interpretable explanations of models' predictions. Recently in academic literature, a vast number of explanations methods have been proposed. Unfortunately, to our knowledge, little has been documented about the challenges machine learning practitioners most often face when applying them in real-world scenarios. For example, a typical procedure such as feature engineering can make some methodologies no longer applicable. The present case study has two main objectives. First, to expose these challenges and how they affect the use of relevant and novel explanations methods. And second, to present a set of strategies that mitigate such challenges, as faced when implementing explanation methods in a relevant application domain -- poverty estimation and its use for prioritizing access to social policies.

</p>
</details>

<details><summary><b>Re-designing cities with conditional adversarial networks</b>
<a href="https://arxiv.org/abs/2104.04013">arxiv:2104.04013</a>
&#x1F4C8; 3 <br>
<p>Mohamed R. Ibrahim, James Haworth, Nicola Christie</p></summary>
<p>

**Abstract:** This paper introduces a conditional generative adversarial network to redesign a street-level image of urban scenes by generating 1) an urban intervention policy, 2) an attention map that localises where intervention is needed, 3) a high-resolution street-level image (1024 X 1024 or 1536 X1536) after implementing the intervention. We also introduce a new dataset that comprises aligned street-level images of before and after urban interventions from real-life scenarios that make this research possible. The introduced method has been trained on different ranges of urban interventions applied to realistic images. The trained model shows strong performance in re-modelling cities, outperforming existing methods that apply image-to-image translation in other domains that is computed in a single GPU. This research opens the door for machine intelligence to play a role in re-thinking and re-designing the different attributes of cities based on adversarial learning, going beyond the mainstream of facial landmarks manipulation or image synthesis from semantic segmentation.

</p>
</details>

<details><summary><b>Software/Hardware Co-design for Multi-modal Multi-task Learning in Autonomous Systems</b>
<a href="https://arxiv.org/abs/2104.04000">arxiv:2104.04000</a>
&#x1F4C8; 3 <br>
<p>Cong Hao, Deming Chen</p></summary>
<p>

**Abstract:** Optimizing the quality of result (QoR) and the quality of service (QoS) of AI-empowered autonomous systems simultaneously is very challenging. First, there are multiple input sources, e.g., multi-modal data from different sensors, requiring diverse data preprocessing, sensor fusion, and feature aggregation. Second, there are multiple tasks that require various AI models to run simultaneously, e.g., perception, localization, and control. Third, the computing and control system is heterogeneous, composed of hardware components with varied features, such as embedded CPUs, GPUs, FPGAs, and dedicated accelerators. Therefore, autonomous systems essentially require multi-modal multi-task (MMMT) learning which must be aware of hardware performance and implementation strategies. While MMMT learning has been attracting intensive research interests, its applications in autonomous systems are still underexplored. In this paper, we first discuss the opportunities of applying MMMT techniques in autonomous systems and then discuss the unique challenges that must be solved. In addition, we discuss the necessity and opportunities of MMMT model and hardware co-design, which is critical for autonomous systems especially with power/resource-limited or heterogeneous platforms. We formulate the MMMT model and heterogeneous hardware implementation co-design as a differentiable optimization problem, with the objective of improving the solution quality and reducing the overall power consumption and critical path latency. We advocate for further explorations of MMMT in autonomous systems and software/hardware co-design solutions.

</p>
</details>

<details><summary><b>Deep Indexed Active Learning for Matching Heterogeneous Entity Representations</b>
<a href="https://arxiv.org/abs/2104.03986">arxiv:2104.03986</a>
&#x1F4C8; 3 <br>
<p>Arjit Jain, Sunita Sarawagi, Prithviraj Sen</p></summary>
<p>

**Abstract:** Given two large lists of records, the task in entity resolution (ER) is to find the pairs from the Cartesian product of the lists that correspond to the same real world entity. Typically, passive learning methods on tasks like ER require large amounts of labeled data to yield useful models. Active Learning is a promising approach for ER in low resource settings. However, the search space, to find informative samples for the user to label, grows quadratically for instance-pair tasks making active learning hard to scale. Previous works, in this setting, rely on hand-crafted predicates, pre-trained language model embeddings, or rule learning to prune away unlikely pairs from the Cartesian product. This blocking step can miss out on important regions in the product space leading to low recall. We propose DIAL, a scalable active learning approach that jointly learns embeddings to maximize recall for blocking and accuracy for matching blocked pairs. DIAL uses an Index-By-Committee framework, where each committee member learns representations based on powerful transformer models. We highlight surprising differences between the matcher and the blocker in the creation of the training data and the objective used to train their parameters. Experiments on five benchmark datasets and a multilingual record matching dataset show the effectiveness of our approach in terms of precision, recall and running time. Code is available at https://github.com/ArjitJ/DIAL

</p>
</details>

<details><summary><b>Field Convolutions for Surface CNNs</b>
<a href="https://arxiv.org/abs/2104.03916">arxiv:2104.03916</a>
&#x1F4C8; 3 <br>
<p>Thomas W. Mitchel, Vladimir G. Kim, Michael Kazhdan</p></summary>
<p>

**Abstract:** We present a novel surface convolution operator acting on vector fields that is based on a simple observation: instead of combining neighboring features with respect to a single coordinate parameterization defined at a given point, we have every neighbor describe the position of the point within its own coordinate frame. This formulation combines intrinsic spatial convolution with parallel transport in a scattering operation while placing no constraints on the filters themselves, providing a definition of convolution that commutes with the action of isometries, has increased descriptive potential, and is robust to noise and other nuisance factors. The result is a rich notion of convolution which we call field convolution, well-suited for CNNs on surfaces. Field convolutions are flexible, straight-forward to incorporate into surface learning frameworks, and their highly discriminating nature has cascading effects throughout the learning pipeline. Using simple networks constructed from residual field convolution blocks, we achieve state-of-the-art results on standard benchmarks in fundamental geometry processing tasks, such as shape classification, segmentation, correspondence, and sparse matching.

</p>
</details>

<details><summary><b>Classification, Slippage, Failure and Discovery</b>
<a href="https://arxiv.org/abs/2104.03886">arxiv:2104.03886</a>
&#x1F4C8; 3 <br>
<p>Marc Böhlen</p></summary>
<p>

**Abstract:** This text argues for the potential of machine learning infused classification systems as vectors for a technically-engaged and constructive technology critique. The text describes this potential with several experiments in image data creation and neural network based classification. The text considers varying aspects of slippage in classification and considers the potential for discovery - as opposed to disaster - stemming from machine learning systems when they fail to perform as anticipated.

</p>
</details>

<details><summary><b>Speech Denoising Without Clean Training Data: A Noise2Noise Approach</b>
<a href="https://arxiv.org/abs/2104.03838">arxiv:2104.03838</a>
&#x1F4C8; 3 <br>
<p>Madhav Mahesh Kashyap, Anuj Tambwekar, Krishnamoorthy Manohara, S Natarajan</p></summary>
<p>

**Abstract:** This paper tackles the problem of the heavy dependence of clean speech data required by deep learning based audio-denoising methods by showing that it is possible to train deep speech denoising networks using only noisy speech samples. Conventional wisdom dictates that in order to achieve good speech denoising performance, there is a requirement for a large quantity of both noisy speech samples and perfectly clean speech samples, resulting in a need for expensive audio recording equipment and extremely controlled soundproof recording studios. These requirements pose significant challenges in data collection, especially in economically disadvantaged regions and for low resource languages. This work shows that speech denoising deep neural networks can be successfully trained utilizing only noisy training audio. Furthermore it is revealed that such training regimes achieve superior denoising performance over conventional training regimes utilizing clean training audio targets, in cases involving complex noise distributions and low Signal-to-Noise ratios (high noise environments). This is demonstrated through experiments studying the efficacy of our proposed approach over both real-world noises and synthetic noises using the 20 layered Deep Complex U-Net architecture.

</p>
</details>

<details><summary><b>Exact Stochastic Second Order Deep Learning</b>
<a href="https://arxiv.org/abs/2104.03804">arxiv:2104.03804</a>
&#x1F4C8; 3 <br>
<p>Fares B. Mehouachi, Chaouki Kasmi</p></summary>
<p>

**Abstract:** Optimization in Deep Learning is mainly dominated by first-order methods which are built around the central concept of backpropagation. Second-order optimization methods, which take into account the second-order derivatives are far less used despite superior theoretical properties. This inadequacy of second-order methods stems from its exorbitant computational cost, poor performance, and the ineluctable non-convex nature of Deep Learning. Several attempts were made to resolve the inadequacy of second-order optimization without reaching a cost-effective solution, much less an exact solution. In this work, we show that this long-standing problem in Deep Learning could be solved in the stochastic case, given a suitable regularization of the neural network. Interestingly, we provide an expression of the stochastic Hessian and its exact eigenvalues. We provide a closed-form formula for the exact stochastic second-order Newton direction, we solve the non-convexity issue and adjust our exact solution to favor flat minima through regularization and spectral adjustment. We test our exact stochastic second-order method on popular datasets and reveal its adequacy for Deep Learning.

</p>
</details>

<details><summary><b>Few-Shot Action Recognition with Compromised Metric via Optimal Transport</b>
<a href="https://arxiv.org/abs/2104.03737">arxiv:2104.03737</a>
&#x1F4C8; 3 <br>
<p>Su Lu, Han-Jia Ye, De-Chuan Zhan</p></summary>
<p>

**Abstract:** Although vital to computer vision systems, few-shot action recognition is still not mature despite the wide research of few-shot image classification. Popular few-shot learning algorithms extract a transferable embedding from seen classes and reuse it on unseen classes by constructing a metric-based classifier. One main obstacle to applying these algorithms in action recognition is the complex structure of videos. Some existing solutions sample frames from a video and aggregate their embeddings to form a video-level representation, neglecting important temporal relations. Others perform an explicit sequence matching between two videos and define their distance as matching cost, imposing too strong restrictions on sequence ordering. In this paper, we propose Compromised Metric via Optimal Transport (CMOT) to combine the advantages of these two solutions. CMOT simultaneously considers semantic and temporal information in videos under Optimal Transport framework, and is discriminative for both content-sensitive and ordering-sensitive tasks. In detail, given two videos, we sample segments from them and cast the calculation of their distance as an optimal transport problem between two segment sequences. To preserve the inherent temporal ordering information, we additionally amend the ground cost matrix by penalizing it with the positional distance between a pair of segments. Empirical results on benchmark datasets demonstrate the superiority of CMOT.

</p>
</details>

<details><summary><b>HindSight: A Graph-Based Vision Model Architecture For Representing Part-Whole Hierarchies</b>
<a href="https://arxiv.org/abs/2104.03722">arxiv:2104.03722</a>
&#x1F4C8; 3 <br>
<p>Muhammad AbdurRafae</p></summary>
<p>

**Abstract:** This paper presents a model architecture for encoding the representations of part-whole hierarchies in images in form of a graph. The idea is to divide the image into patches of different levels and then treat all of these patches as nodes for a fully connected graph. A dynamic feature extraction module is used to extract feature representations from these patches in each graph iteration. This enables us to learn a rich graph representation of the image that encompasses the inherent part-whole hierarchical information. Utilizing proper self-supervised training techniques, such a model can be trained as a general purpose vision encoder model which can then be used for various vision related downstream tasks (e.g., Image Classification, Object Detection, Image Captioning, etc.).

</p>
</details>

<details><summary><b>Spatial Imagination With Semantic Cognition for Mobile Robots</b>
<a href="https://arxiv.org/abs/2104.03638">arxiv:2104.03638</a>
&#x1F4C8; 3 <br>
<p>Zhengcheng Shen, Linh Kästner, Jens Lambrecht</p></summary>
<p>

**Abstract:** The imagination of the surrounding environment based on experience and semantic cognition has great potential to extend the limited observations and provide more information for mapping, collision avoidance, and path planning. This paper provides a training-based algorithm for mobile robots to perform spatial imagination based on semantic cognition and evaluates the proposed method for the mapping task. We utilize a photo-realistic simulation environment, Habitat, for training and evaluation. The trained model is composed of Resent-18 as encoder and Unet as the backbone. We demonstrate that the algorithm can perform imagination for unseen parts of the object universally, by recalling the images and experience and compare our approach with traditional semantic mapping methods. It is found that our approach will improve the efficiency and accuracy of semantic mapping.

</p>
</details>

<details><summary><b>Post-Hoc Domain Adaptation via Guided Data Homogenization</b>
<a href="https://arxiv.org/abs/2104.03624">arxiv:2104.03624</a>
&#x1F4C8; 3 <br>
<p>Kurt Willis, Luis Oala</p></summary>
<p>

**Abstract:** Addressing shifts in data distributions is an important prerequisite for the deployment of deep learning models to real-world settings. A general approach to this problem involves the adjustment of models to a new domain through transfer learning. However, in many cases, this is not applicable in a post-hoc manner to deployed models and further parameter adjustments jeopardize safety certifications that were established beforehand. In such a context, we propose to deal with changes in the data distribution via guided data homogenization which shifts the burden of adaptation from the model to the data. This approach makes use of information about the training data contained implicitly in the deep learning model to learn a domain transfer function. This allows for a targeted deployment of models to unknown scenarios without changing the model itself. We demonstrate the potential of data homogenization through experiments on the CIFAR-10 and MNIST data sets.

</p>
</details>

<details><summary><b>Uncertainty-aware Remaining Useful Life predictor</b>
<a href="https://arxiv.org/abs/2104.03613">arxiv:2104.03613</a>
&#x1F4C8; 3 <br>
<p>Luca Biggio, Alexander Wieland, Manuel Arias Chao, Iason Kastanis, Olga Fink</p></summary>
<p>

**Abstract:** Remaining Useful Life (RUL) estimation is the problem of inferring how long a certain industrial asset can be expected to operate within its defined specifications. Deploying successful RUL prediction methods in real-life applications is a prerequisite for the design of intelligent maintenance strategies with the potential of drastically reducing maintenance costs and machine downtimes. In light of their superior performance in a wide range of engineering fields, Machine Learning (ML) algorithms are natural candidates to tackle the challenges involved in the design of intelligent maintenance systems. In particular, given the potentially catastrophic consequences or substantial costs associated with maintenance decisions that are either too late or too early, it is desirable that ML algorithms provide uncertainty estimates alongside their predictions. However, standard data-driven methods used for uncertainty estimation in RUL problems do not scale well to large datasets or are not sufficiently expressive to model the high-dimensional mapping from raw sensor data to RUL estimates. In this work, we consider Deep Gaussian Processes (DGPs) as possible solutions to the aforementioned limitations. We perform a thorough evaluation and comparison of several variants of DGPs applied to RUL predictions. The performance of the algorithms is evaluated on the N-CMAPSS (New Commercial Modular Aero-Propulsion System Simulation) dataset from NASA for aircraft engines. The results show that the proposed methods are able to provide very accurate RUL predictions along with sensible uncertainty estimates, providing more reliable solutions for (safety-critical) real-life industrial applications.

</p>
</details>

<details><summary><b>QD-GCN: Query-Driven Graph Convolutional Networks for Attributed Community Search</b>
<a href="https://arxiv.org/abs/2104.03583">arxiv:2104.03583</a>
&#x1F4C8; 3 <br>
<p>Yuli Jiang, Yu Rong, Hong Cheng, Xin Huang, Kangfei Zhao, Junzhou Huang</p></summary>
<p>

**Abstract:** Recently, attributed community search, a related but different problem to community detection and graph clustering, has been widely studied in the literature. Compared with the community detection that finds all existing static communities from a graph, the attributed community search (ACS) is more challenging since it aims to find dynamic communities with both cohesive structures and homogeneous node attributes given arbitrary queries. To solve the ACS problem, the most popular paradigm is to simplify the problem as two sub-problems, that is, structural matching and attribute filtering and deal with them separately. However, in real-world graphs, the community structure and the node attributes are actually correlated to each other. In this vein, current studies cannot capture these correlations which are vital for the ACS problem.
  In this paper, we propose Query-Driven Graph Convolutional Networks (QD-GCN), an end-to-end framework that unifies the community structure as well as node attribute to solve the ACS problem. In particular, QD-GCN leverages the Graph Convolutional Networks, which is a powerful tool to encode the graph topology and node attributes concurrently, as the backbones to extract the query-dependent community information from the original graph. By utilizing this query-dependent community information, QD-GCN is able to predict the target community given any queries. Experiments on real-world graphs with ground-truth communities demonstrate that QD-GCN outperforms existing attributed community search algorithms in terms of both efficiency and effectiveness.

</p>
</details>

<details><summary><b>An Empirical Study of the Effects of Sample-Mixing Methods for Efficient Training of Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2104.03535">arxiv:2104.03535</a>
&#x1F4C8; 3 <br>
<p>Makoto Takamoto, Yusuke Morishita</p></summary>
<p>

**Abstract:** It is well-known that training of generative adversarial networks (GANs) requires huge iterations before the generator's providing good-quality samples. Although there are several studies to tackle this problem, there is still no universal solution. In this paper, we investigated the effect of sample mixing methods, that is, Mixup, CutMix, and newly proposed Smoothed Regional Mix (SRMix), to alleviate this problem. The sample-mixing methods are known to enhance the accuracy and robustness in the wide range of classification problems, and can naturally be applicable to GANs because the role of the discriminator can be interpreted as the classification between real and fake samples. We also proposed a new formalism applying the sample-mixing methods to GANs with the saturated losses which do not have a clear "label" of real and fake. We performed a vast amount of numerical experiments using LSUN and CelebA datasets. The results showed that Mixup and SRMix improved the quality of the generated images in terms of FID in most cases, in particular, SRMix showed the best improvement in most cases. Our analysis indicates that the mixed-samples can provide different properties from the vanilla fake samples, and the mixing pattern strongly affects the decision of the discriminators. The generated images of Mixup have good high-level feature but low-level feature is not so impressible. On the other hand, CutMix showed the opposite tendency. Our SRMix showed the middle tendency, that is, showed good high and low level features. We believe that our finding provides a new perspective to accelerate the GANs convergence and improve the quality of generated samples.

</p>
</details>

<details><summary><b>Pseudo-supervised Deep Subspace Clustering</b>
<a href="https://arxiv.org/abs/2104.03531">arxiv:2104.03531</a>
&#x1F4C8; 3 <br>
<p>Juncheng Lv, Zhao Kang, Xiao Lu, Zenglin Xu</p></summary>
<p>

**Abstract:** Auto-Encoder (AE)-based deep subspace clustering (DSC) methods have achieved impressive performance due to the powerful representation extracted using deep neural networks while prioritizing categorical separability. However, self-reconstruction loss of an AE ignores rich useful relation information and might lead to indiscriminative representation, which inevitably degrades the clustering performance. It is also challenging to learn high-level similarity without feeding semantic labels. Another unsolved problem facing DSC is the huge memory cost due to $n\times n$ similarity matrix, which is incurred by the self-expression layer between an encoder and decoder. To tackle these problems, we use pairwise similarity to weigh the reconstruction loss to capture local structure information, while a similarity is learned by the self-expression layer. Pseudo-graphs and pseudo-labels, which allow benefiting from uncertain knowledge acquired during network training, are further employed to supervise similarity learning. Joint learning and iterative training facilitate to obtain an overall optimal solution. Extensive experiments on benchmark datasets demonstrate the superiority of our approach. By combining with the $k$-nearest neighbors algorithm, we further show that our method can address the large-scale and out-of-sample problems.

</p>
</details>

<details><summary><b>Risk-Aware Lane Selection on Highway with Dynamic Obstacles</b>
<a href="https://arxiv.org/abs/2104.04105">arxiv:2104.04105</a>
&#x1F4C8; 2 <br>
<p>Sangjae Bae, David Isele, Kikuo Fujimura, Scott J. Moura</p></summary>
<p>

**Abstract:** This paper proposes a discretionary lane selection algorithm. In particular, highway driving is considered as a targeted scenario, where each lane has a different level of traffic flow. When lane-changing is discretionary, it is advised not to change lanes unless highly beneficial, e.g., reducing travel time significantly or securing higher safety. Evaluating such "benefit" is a challenge, along with multiple surrounding vehicles in dynamic speed and heading with uncertainty. We propose a real-time lane-selection algorithm with careful cost considerations and with modularity in design. The algorithm is a search-based optimization method that evaluates uncertain dynamic positions of other vehicles under a continuous time and space domain. For demonstration, we incorporate a state-of-the-art motion planner framework (Neural Networks integrated Model Predictive Control) under a CARLA simulation environment.

</p>
</details>

<details><summary><b>Causal Decision Making and Causal Effect Estimation Are Not the Same... and Why It Matters</b>
<a href="https://arxiv.org/abs/2104.04103">arxiv:2104.04103</a>
&#x1F4C8; 2 <br>
<p>Carlos Fernández-Loría, Foster Provost</p></summary>
<p>

**Abstract:** Causal decision making (CDM) based on machine learning has become a routine part of business. Businesses algorithmically target offers, incentives, and recommendations to affect consumer behavior. Recently, we have seen an acceleration of research related to CDM and causal effect estimation (CEE) using machine-learned models. This article highlights an important perspective: CDM is not the same as CEE, and counterintuitively, accurate CEE is not necessary for accurate CDM. Our experience is that this is not well understood by practitioners or most researchers. Technically, the estimand of interest is different, and this has important implications both for modeling and for the use of statistical models for CDM. We draw on prior research to highlight three implications. (1) We should consider carefully the objective function of the causal machine learning, and if possible, optimize for accurate treatment assignment rather than for accurate effect-size estimation. (2) Confounding does not have the same effect on CDM as it does on CEE. The upshot is that for supporting CDM it may be just as good or even better to learn with confounded data as with unconfounded data. Finally, (3) causal statistical modeling may not be necessary to support CDM because a proxy target for statistical modeling might do as well or better. This third observation helps to explain at least one broad common CDM practice that seems wrong at first blush: the widespread use of non-causal models for targeting interventions. The last two implications are particularly important in practice, as acquiring (unconfounded) data on all counterfactuals can be costly and often impracticable. These observations open substantial research ground. We hope to facilitate research in this area by pointing to related articles from multiple contributing fields, including two dozen articles published the last three to four years.

</p>
</details>

<details><summary><b>Heterogeneous Dense Subhypergraph Detection</b>
<a href="https://arxiv.org/abs/2104.04047">arxiv:2104.04047</a>
&#x1F4C8; 2 <br>
<p>Mingao Yuan, Zuofeng Shang</p></summary>
<p>

**Abstract:** We study the problem of testing the existence of a heterogeneous dense subhypergraph. The null hypothesis corresponds to a heterogeneous Erdös-Rényi uniform random hypergraph and the alternative hypothesis corresponds to a heterogeneous uniform random hypergraph that contains a dense subhypergraph. We establish detection boundaries when the edge probabilities are known and construct an asymptotically powerful test for distinguishing the hypotheses. We also construct an adaptive test which does not involve edge probabilities, and hence, is more practically useful.

</p>
</details>

<details><summary><b>Semi-Supervised Learning of Classifiers from a Statistical Perspective: A Brief Review</b>
<a href="https://arxiv.org/abs/2104.04046">arxiv:2104.04046</a>
&#x1F4C8; 2 <br>
<p>Daniel Ahfock, Geoffrey J. McLachlan</p></summary>
<p>

**Abstract:** There has been increasing attention to semi-supervised learning (SSL) approaches in machine learning to forming a classifier in situations where the training data for a classifier consists of a limited number of classified observations but a much larger number of unclassified observations. This is because the procurement of classified data can be quite costly due to high acquisition costs and subsequent financial, time, and ethical issues that can arise in attempts to provide the true class labels for the unclassified data that have been acquired. We provide here a review of statistical SSL approaches to this problem, focussing on the recent result that a classifier formed from a partially classified sample can actually have smaller expected error rate than that if the sample were completely classified.

</p>
</details>

<details><summary><b>BR-NS: an Archive-less Approach to Novelty Search</b>
<a href="https://arxiv.org/abs/2104.03936">arxiv:2104.03936</a>
&#x1F4C8; 2 <br>
<p>Achkan Salehi, Alexandre Coninx, Stephane Doncieux</p></summary>
<p>

**Abstract:** As open-ended learning based on divergent search algorithms such as Novelty Search (NS) draws more and more attention from the research community, it is natural to expect that its application to increasingly complex real-world problems will require the exploration to operate in higher dimensional Behavior Spaces which will not necessarily be Euclidean. Novelty Search traditionally relies on k-nearest neighbours search and an archive of previously visited behavior descriptors which are assumed to live in a Euclidean space. This is problematic because of a number of issues. On one hand, Euclidean distance and Nearest-neighbour search are known to behave differently and become less meaningful in high dimensional spaces. On the other hand, the archive has to be bounded since, memory considerations aside, the computational complexity of finding nearest neighbours in that archive grows linearithmically with its size. A sub-optimal bound can result in "cycling" in the behavior space, which inhibits the progress of the exploration. Furthermore, the performance of NS depends on a number of algorithmic choices and hyperparameters, such as the strategies to add or remove elements to the archive and the number of neighbours to use in k-nn search. In this paper, we discuss an alternative approach to novelty estimation, dubbed Behavior Recognition based Novelty Search (BR-NS), which does not require an archive, makes no assumption on the metrics that can be defined in the behavior space and does not rely on nearest neighbours search. We conduct experiments to gain insight into its feasibility and dynamics as well as potential advantages over archive-based NS in terms of time complexity.

</p>
</details>

<details><summary><b>SerumRNN: Step by Step Audio VST Effect Programming</b>
<a href="https://arxiv.org/abs/2104.03876">arxiv:2104.03876</a>
&#x1F4C8; 2 <br>
<p>Christopher Mitcheltree, Hideki Koike</p></summary>
<p>

**Abstract:** Learning to program an audio production VST synthesizer is a time consuming process, usually obtained through inefficient trial and error and only mastered after years of experience. As an educational and creative tool for sound designers, we propose SerumRNN: a system that provides step-by-step instructions for applying audio effects to change a user's input audio towards a desired sound. We apply our system to Xfer Records Serum: currently one of the most popular and complex VST synthesizers used by the audio production community. Our results indicate that SerumRNN is consistently able to provide useful feedback for a variety of different audio effects and synthesizer presets. We demonstrate the benefits of using an iterative system and show that SerumRNN learns to prioritize effects and can discover more efficient effect order sequences than a variety of baselines.

</p>
</details>

<details><summary><b>A Bayesian Approach to Reinforcement Learning of Vision-Based Vehicular Control</b>
<a href="https://arxiv.org/abs/2104.03807">arxiv:2104.03807</a>
&#x1F4C8; 2 <br>
<p>Zahra Gharaee, Karl Holmquist, Linbo He, Michael Felsberg</p></summary>
<p>

**Abstract:** In this paper, we present a state-of-the-art reinforcement learning method for autonomous driving. Our approach employs temporal difference learning in a Bayesian framework to learn vehicle control signals from sensor data. The agent has access to images from a forward facing camera, which are preprocessed to generate semantic segmentation maps. We trained our system using both ground truth and estimated semantic segmentation input. Based on our observations from a large set of experiments, we conclude that training the system on ground truth input data leads to better performance than training the system on estimated input even if estimated input is used for evaluation. The system is trained and evaluated in a realistic simulated urban environment using the CARLA simulator. The simulator also contains a benchmark that allows for comparing to other systems and methods. The required training time of the system is shown to be lower and the performance on the benchmark superior to competing approaches.

</p>
</details>

<details><summary><b>Atrous Residual Interconnected Encoder to Attention Decoder Framework for Vertebrae Segmentation via 3D Volumetric CT Images</b>
<a href="https://arxiv.org/abs/2104.03715">arxiv:2104.03715</a>
&#x1F4C8; 2 <br>
<p>Wenqiang Li, YM Tang, Ziyang Wang, KM Yu, Sandy To</p></summary>
<p>

**Abstract:** Automatic medical image segmentation based on Computed Tomography (CT) has been widely applied for computer-aided surgery as a prerequisite. With the development of deep learning technologies, deep convolutional neural networks (DCNNs) have shown robust performance in automated semantic segmentation of medical images. However, semantic segmentation algorithms based on DCNNs still meet the challenges of feature loss between encoder and decoder, multi-scale object, restricted field of view of filters, and lack of medical image data. This paper proposes a novel algorithm for automated vertebrae segmentation via 3D volumetric spine CT images. The proposed model is based on the structure of encoder to decoder, using layer normalization to optimize mini-batch training performance. To address the concern of the information loss between encoder and decoder, we designed an Atrous Residual Path to pass more features from encoder to decoder instead of an easy shortcut connection. The proposed model also applied the attention module in the decoder part to extract features from variant scales. The proposed model is evaluated on a publicly available dataset by a variety of metrics. The experimental results show that our model achieves competitive performance compared with other state-of-the-art medical semantic segmentation methods.

</p>
</details>

<details><summary><b>Advanced Image Enhancement Method for Distant Vessels and Structures in Capsule Endoscopy</b>
<a href="https://arxiv.org/abs/2104.03668">arxiv:2104.03668</a>
&#x1F4C8; 2 <br>
<p>Olivier Rukundo, Marius Pedersen, Øistein Hovde</p></summary>
<p>

**Abstract:** This paper proposes an advanced method for contrast enhancement of capsule endoscopic images, with the main objective to obtain sufficient information about the vessels and structures in more distant (or darker) parts of capsule endoscopic images. The proposed method (PM) combines two algorithms for the enhancement of darker and brighter areas of capsule endoscopic images, respectively. The half-unit weighted bilinear algorithm (HWB) proposed in our previous work is used to enhance darker areas according to the darker map content of its HSV's component V. Enhancement of brighter areas is achieved thanks to the novel thresholded weighted-bilinear algorithm (TWB) developed to avoid overexposure and enlargement of specular highlight spots while preserving the hue, in such areas. The TWB performs enhancement operations following a gradual increment of the brightness of the brighter map content of its HSV's component V. In other words, the TWB decreases its averaged-weights as the intensity content of the component V increases. Extensive experimental demonstrations were conducted, and based on evaluation of the reference and PM enhanced images, a gastroenterologist (ØH) concluded that the PM enhanced images were the best ones based on the information about the vessels, contrast in the images, and the view or visibility of the structures in more distant parts of the capsule endoscopy images.

</p>
</details>

<details><summary><b>Extended Parallel Corpus for Amharic-English Machine Translation</b>
<a href="https://arxiv.org/abs/2104.03543">arxiv:2104.03543</a>
&#x1F4C8; 2 <br>
<p>Andargachew Mekonnen Gezmu, Andreas Nürnberger, Tesfaye Bayu Bati</p></summary>
<p>

**Abstract:** This paper describes the acquisition, preprocessing, segmentation, and alignment of an Amharic-English parallel corpus. It will be useful for machine translation of an under-resourced language, Amharic. The corpus is larger than previously compiled corpora; it is released for research purposes. We trained neural machine translation and phrase-based statistical machine translation models using the corpus. In the automatic evaluation, neural machine translation models outperform phrase-based statistical machine translation models.

</p>
</details>

<details><summary><b>Relieving the Plateau: Active Semi-Supervised Learning for a Better Landscape</b>
<a href="https://arxiv.org/abs/2104.03525">arxiv:2104.03525</a>
&#x1F4C8; 2 <br>
<p>Seo Taek Kong, Soomin Jeon, Jaewon Lee, Hongseok Lee, Kyu-Hwan Jung</p></summary>
<p>

**Abstract:** Deep learning (DL) relies on massive amounts of labeled data, and improving its labeled sample-efficiency remains one of the most important problems since its advent. Semi-supervised learning (SSL) leverages unlabeled data that are more accessible than their labeled counterparts. Active learning (AL) selects unlabeled instances to be annotated by a human-in-the-loop in hopes of better performance with less labeled data. Given the accessible pool of unlabeled data in pool-based AL, it seems natural to use SSL when training and AL to update the labeled set; however, algorithms designed for their combination remain limited. In this work, we first prove that convergence of gradient descent on sufficiently wide ReLU networks can be expressed in terms of their Gram matrix' eigen-spectrum. Equipped with a few theoretical insights, we propose convergence rate control (CRC), an AL algorithm that selects unlabeled data to improve the problem conditioning upon inclusion to the labeled set, by formulating an acquisition step in terms of improving training dynamics. Extensive experiments show that SSL algorithms coupled with CRC can achieve high performance using very few labeled data.

</p>
</details>

<details><summary><b>Multi-Density Attention Network for Loop Filtering in Video Compression</b>
<a href="https://arxiv.org/abs/2104.12865">arxiv:2104.12865</a>
&#x1F4C8; 1 <br>
<p>Zhao Wang, Changyue Ma, Yan Ye</p></summary>
<p>

**Abstract:** Video compression is a basic requirement for consumer and professional video applications alike. Video coding standards such as H.264/AVC and H.265/HEVC are widely deployed in the market to enable efficient use of bandwidth and storage for many video applications. To reduce the coding artifacts and improve the compression efficiency, neural network based loop filtering of the reconstructed video has been developed in the literature. However, loop filtering is a challenging task due to the variation in video content and sampling densities. In this paper, we propose a on-line scaling based multi-density attention network for loop filtering in video compression. The core of our approach lies in several aspects: (a) parallel multi-resolution convolution streams for extracting multi-density features, (b) single attention branch to learn the sample correlations and generate mask maps, (c) a channel-mutual attention procedure to fuse the data from multiple branches, (d) on-line scaling technique to further optimize the output results of network according to the actual signal. The proposed multi-density attention network learns rich features from multiple sampling densities and performs robustly on video content of different resolutions. Moreover, the online scaling process enhances the signal adaptability of the off-line pre-trained model. Experimental results show that 10.18% bit-rate reduction at the same video quality can be achieved over the latest Versatile Video Coding (VVC) standard. The objective performance of the proposed algorithm outperforms the state-of-the-art methods and the subjective quality improvement is obvious in terms of detail preservation and artifact alleviation.

</p>
</details>

<details><summary><b>Signal Processing and Machine Learning Techniques for Terahertz Sensing: An Overview</b>
<a href="https://arxiv.org/abs/2104.06309">arxiv:2104.06309</a>
&#x1F4C8; 1 <br>
<p>Sara Helal, Hadi Sarieddeen, Hayssam Dahrouj, Tareq Y. Al-Naffouri, Mohamed Slim Alouini</p></summary>
<p>

**Abstract:** Following the recent progress in Terahertz (THz) signal generation and radiation methods, joint THz communications and sensing applications are shaping the future of wireless systems. Towards this end, THz spectroscopy is expected to be carried over user equipment devices to identify material and gaseous components of interest. THz-specific signal processing techniques should complement this re-surged interest in THz sensing for efficient utilization of the THz band. In this paper, we present an overview of these techniques, with an emphasis on signal pre-processing (standard normal variate normalization, min-max normalization, and Savitzky-Golay filtering), feature extraction (principal component analysis, partial least squares, t-distributed stochastic neighbor embedding, and nonnegative matrix factorization), and classification techniques (support vector machines, k-nearest neighbor, discriminant analysis, and naive Bayes). We also address the effectiveness of deep learning techniques by exploring their promising sensing capabilities at the THz band. Lastly, we investigate the performance and complexity trade-offs of the studied methods in the context of joint communications and sensing; we motivate the corresponding use-cases, and we present few future research directions in the field.

</p>
</details>

<details><summary><b>Neural Network for Weighted Signal Temporal Logic</b>
<a href="https://arxiv.org/abs/2104.05435">arxiv:2104.05435</a>
&#x1F4C8; 1 <br>
<p>Ruixuan Yan, Agung Julius</p></summary>
<p>

**Abstract:** In this paper, we propose a neuro-symbolic framework called weighted Signal Temporal Logic Neural Network (wSTL-NN) that combines the characteristics of neural networks and temporal logics. Weighted Signal Temporal Logic (wSTL) formulas are recursively composed of subformulas that are combined using logical and temporal operators. The quantitative semantics of wSTL is defined such that the quantitative satisfaction of subformulas with higher weights has more influence on the quantitative satisfaction of the overall wSTL formula. In the wSTL-NN, each neuron corresponds to a wSTL subformula, and its output corresponds to the quantitative satisfaction of the formula. We use wSTL-NN to represent wSTL formulas as features to classify time series data. STL features are more explainable than those used in classical methods. The wSTL-NN is end-to-end differentiable, which allows learning of wSTL formulas to be done using back-propagation. To reduce the number of weights, we introduce two techniques to sparsify the wSTL-NN.We apply our framework to an occupancy detection time-series dataset to learn a classifier that predicts the occupancy status of an office room.

</p>
</details>

<details><summary><b>Fast, Smart Neuromorphic Sensors Based on Heterogeneous Networks and Mixed Encodings</b>
<a href="https://arxiv.org/abs/2104.04121">arxiv:2104.04121</a>
&#x1F4C8; 1 <br>
<p>Angel Yanguas-Gil</p></summary>
<p>

**Abstract:** Neuromorphic architectures are ideally suited for the implementation of smart sensors able to react, learn, and respond to a changing environment. Our work uses the insect brain as a model to understand how heterogeneous architectures, incorporating different types of neurons and encodings, can be leveraged to create systems integrating input processing, evaluation, and response. Here we show how the combination of time and rate encodings can lead to fast sensors that are able to generate a hypothesis on the input in only a few cycles and then use that hypothesis as secondary input for more detailed analysis.

</p>
</details>

<details><summary><b>Improving Solar Cell Metallization Designs using Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2104.04017">arxiv:2104.04017</a>
&#x1F4C8; 1 <br>
<p>Sumit Bhattacharya, Devanshu Arya, Debjani Bhowmick, Rajat Mani Thomas, Deepak Kumar Gupta</p></summary>
<p>

**Abstract:** Optimizing the design of solar cell metallizations is one of the ways to improve the performance of solar cells. Recently, it has been shown that Topology Optimization (TO) can be used to design complex metallization patterns for solar cells that lead to improved performance. TO generates unconventional design patterns that cannot be obtained with the traditional shape optimization methods. In this paper, we show that this design process can be improved further using a deep learning inspired strategy. We present SolarNet, a CNN-based reparameterization scheme that can be used to obtain improved metallization designs. SolarNet modifies the optimization domain such that rather than optimizing the electrode material distribution directly, the weights of a CNN model are optimized. The design generated by CNN is then evaluated using the physics equations, which in turn generates gradients for backpropagation. SolarNet is trained end-to-end involving backpropagation through the solar cell model as well as the CNN pipeline. Through application on solar cells of different shapes as well as different busbar geometries, we demonstrate that SolarNet improves the performance of solar cells compared to the traditional TO approach.

</p>
</details>

<details><summary><b>DenResCov-19: A deep transfer learning network for robust automatic classification of COVID-19, pneumonia, and tuberculosis from X-rays</b>
<a href="https://arxiv.org/abs/2104.04006">arxiv:2104.04006</a>
&#x1F4C8; 1 <br>
<p>Michail Mamalakis, Andrew J. Swift, Bart Vorselaars, Surajit Ray, Simonne Weeks, Weiping Ding, Richard H. Clayton, Louise S. Mackenzie, Abhirup Banerjee</p></summary>
<p>

**Abstract:** The global pandemic of COVID-19 is continuing to have a significant effect on the well-being of global population, increasing the demand for rapid testing, diagnosis, and treatment. Along with COVID-19, other etiologies of pneumonia and tuberculosis constitute additional challenges to the medical system. In this regard, the objective of this work is to develop a new deep transfer learning pipeline to diagnose patients with COVID-19, pneumonia, and tuberculosis, based on chest x-ray images. We observed in some instances DenseNet and Resnet have orthogonal performances. In our proposed model, we have created an extra layer with convolutional neural network blocks to combine these two models to establish superior performance over either model. The same strategy can be useful in other applications where two competing networks with complementary performance are observed. We have tested the performance of our proposed network on two-class (pneumonia vs healthy), three-class (including COVID-19), and four-class (including tuberculosis) classification problems. The proposed network has been able to successfully classify these lung diseases in all four datasets and has provided significant improvement over the benchmark networks of DenseNet, ResNet, and Inception-V3. These novel findings can deliver a state-of-the-art pre-screening fast-track decision network to detect COVID-19 and other lung pathologies.

</p>
</details>

<details><summary><b>Generalized Approach to Matched Filtering using Neural Networks</b>
<a href="https://arxiv.org/abs/2104.03961">arxiv:2104.03961</a>
&#x1F4C8; 1 <br>
<p>Jingkai Yan, Mariam Avagyan, Robert E. Colgan, Doğa Veske, Imre Bartos, John Wright, Zsuzsa Márka, Szabolcs Márka</p></summary>
<p>

**Abstract:** Gravitational wave science is a pioneering field with rapidly evolving data analysis methodology currently assimilating and inventing deep learning techniques. The bulk of the sophisticated flagship searches of the field rely on the time-tested matched filtering principle within their core. In this paper, we make a key observation on the relationship between the emerging deep learning and the traditional techniques: matched filtering is formally equivalent to a particular neural network. This means that a neural network can be constructed analytically to exactly implement matched filtering, and can be further trained on data or boosted with additional complexity for improved performance. This fundamental equivalence allows us to define a "complexity standard candle" allowing us to characterize the relative complexity of the different approaches to gravitational wave signals in a common framework. Additionally it also provides a glimpse of an intriguing symmetry that could provide clues on how neural networks approach the problem of finding signals in overwhelming noise. Moreover, we show that the proposed neural network architecture can outperform matched filtering, both with or without knowledge of a prior on the parameter distribution. When a prior is given, the proposed neural network can approach the statistically optimal performance. We also propose and investigate two different neural network architectures MNet-Shallow and MNet-Deep, both of which implement matched filtering at initialization and can be trained on data. MNet-Shallow has simpler structure, while MNet-Deep is more flexible and can deal with a wider range of distributions. Our theoretical findings are corroborated by experiments using real LIGO data and synthetic injections. Finally, our results suggest new perspectives on the role of deep learning in gravitational wave detection.

</p>
</details>

<details><summary><b>A transfer-learning approach for lesion detection in endoscopic images from the urinary tract</b>
<a href="https://arxiv.org/abs/2104.03927">arxiv:2104.03927</a>
&#x1F4C8; 1 <br>
<p>Jorge F. Lazo, Sara Moccia, Aldo Marzullo, Michele Catellani, Ottavio De Cobelli, Benoit Rosa, Michel de Mathelin, Elena De Momi</p></summary>
<p>

**Abstract:** Ureteroscopy and cystoscopy are the gold standard methods to identify and treat tumors along the urinary tract. It has been reported that during a normal procedure a rate of 10-20 % of the lesions could be missed. In this work we study the implementation of 3 different Convolutional Neural Networks (CNNs), using a 2-steps training strategy, to classify images from the urinary tract with and without lesions. A total of 6,101 images from ureteroscopy and cystoscopy procedures were collected. The CNNs were trained and tested using transfer learning in a two-steps fashion on 3 datasets. The datasets used were: 1) only ureteroscopy images, 2) only cystoscopy images and 3) the combination of both of them. For cystoscopy data, VGG performed better obtaining an Area Under the ROC Curve (AUC) value of 0.846. In the cases of ureteroscopy and the combination of both datasets, ResNet50 achieved the best results with AUC values of 0.987 and 0.940. The use of a training dataset that comprehends both domains results in general better performances, but performing a second stage of transfer learning achieves comparable ones. There is no single model which performs better in all scenarios, but ResNet50 is the network that achieves the best performances in most of them. The obtained results open the opportunity for further investigation with a view for improving lesion detection in endoscopic images of the urinary system.

</p>
</details>

<details><summary><b>BEFD: Boundary Enhancement and Feature Denoising for Vessel Segmentation</b>
<a href="https://arxiv.org/abs/2104.03768">arxiv:2104.03768</a>
&#x1F4C8; 1 <br>
<p>Mo Zhang, Fei Yu, Jie Zhao, Li Zhang, Quanzheng Li</p></summary>
<p>

**Abstract:** Blood vessel segmentation is crucial for many diagnostic and research applications. In recent years, CNN-based models have leaded to breakthroughs in the task of segmentation, however, such methods usually lose high-frequency information like object boundaries and subtle structures, which are vital to vessel segmentation. To tackle this issue, we propose Boundary Enhancement and Feature Denoising (BEFD) module to facilitate the network ability of extracting boundary information in semantic segmentation, which can be integrated into arbitrary encoder-decoder architecture in an end-to-end way. By introducing Sobel edge detector, the network is able to acquire additional edge prior, thus enhancing boundary in an unsupervised manner for medical image segmentation. In addition, we also utilize a denoising block to reduce the noise hidden in the low-level features. Experimental results on retinal vessel dataset and angiocarpy dataset demonstrate the superior performance of the new BEFD module.

</p>
</details>

<details><summary><b>Computation and Bribery of Voting Power in Delegative Simple Games</b>
<a href="https://arxiv.org/abs/2104.03692">arxiv:2104.03692</a>
&#x1F4C8; 1 <br>
<p>Gianlorenzo D'Angelo, Esmaeil Delfaraz, Hugo Gilbert</p></summary>
<p>

**Abstract:** Weighted voting games is one of the most important classes of cooperative games. Recently, Zhang and Grossi [53] proposed a variant of this class, called delegative simple games, which is well suited to analyse the relative importance of each voter in liquid democracy elections. Moreover, they defined a power index, called the delagative Banzhaf index to compute the importance of each agent (i.e., both voters and delegators) in a delegation graph based on two key parameters: the total voting weight she has accumulated and the structure of supports she receives from her delegators.
  We obtain several results related to delegative simple games. We first propose a pseudo-polynomial time algorithm to compute the delegative Banzhaf and Shapley-Shubik values in delegative simple games. We then investigate a bribery problem where the goal is to maximize/minimize the voting power/weight of a given voter in a delegation graph by changing at most a fixed number of delegations. We show that the problems of minimizing/maximizing a voter's power index value are strongly NP-hard. Furthermore, we prove that having a better approximation guarantee than $1-1/e$ to maximize the voting weight of a voter is not possible, unless $P = NP$, then we provide some parameterized complexity results for this problem. Finally, we show that finding a delegation graph with a given number of gurus that maximizes the minimum power index value an agent can have is a computationally hard problem.

</p>
</details>

<details><summary><b>MRI-based Alzheimer's disease prediction via distilling the knowledge in multi-modal data</b>
<a href="https://arxiv.org/abs/2104.03618">arxiv:2104.03618</a>
&#x1F4C8; 1 <br>
<p>Hao Guan, Chaoyue Wang, Dacheng Tao</p></summary>
<p>

**Abstract:** Mild cognitive impairment (MCI) conversion prediction, i.e., identifying MCI patients of high risks converting to Alzheimer's disease (AD), is essential for preventing or slowing the progression of AD. Although previous studies have shown that the fusion of multi-modal data can effectively improve the prediction accuracy, their applications are largely restricted by the limited availability or high cost of multi-modal data. Building an effective prediction model using only magnetic resonance imaging (MRI) remains a challenging research topic. In this work, we propose a multi-modal multi-instance distillation scheme, which aims to distill the knowledge learned from multi-modal data to an MRI-based network for MCI conversion prediction. In contrast to existing distillation algorithms, the proposed multi-instance probabilities demonstrate a superior capability of representing the complicated atrophy distributions, and can guide the MRI-based network to better explore the input MRI. To our best knowledge, this is the first study that attempts to improve an MRI-based prediction model by leveraging extra supervision distilled from multi-modal information. Experiments demonstrate the advantage of our framework, suggesting its potentials in the data-limited clinical settings.

</p>
</details>

<details><summary><b>Efficient time stepping for numerical integration using reinforcement learning</b>
<a href="https://arxiv.org/abs/2104.03562">arxiv:2104.03562</a>
&#x1F4C8; 1 <br>
<p>Michael Dellnitz, Eyke Hüllermeier, Marvin Lücke, Sina Ober-Blöbaum, Christian Offen, Sebastian Peitz, Karlson Pfannschmidt</p></summary>
<p>

**Abstract:** Many problems in science and engineering require the efficient numerical approximation of integrals, a particularly important application being the numerical solution of initial value problems for differential equations. For complex systems, an equidistant discretization is often inadvisable, as it either results in prohibitively large errors or computational effort. To this end, adaptive schemes have been developed that rely on error estimators based on Taylor series expansions. While these estimators a) rely on strong smoothness assumptions and b) may still result in erroneous steps for complex systems (and thus require step rejection mechanisms), we here propose a data-driven time stepping scheme based on machine learning, and more specifically on reinforcement learning (RL) and meta-learning. First, one or several (in the case of non-smooth or hybrid systems) base learners are trained using RL. Then, a meta-learner is trained which (depending on the system state) selects the base learner that appears to be optimal for the current situation. Several examples including both smooth and non-smooth problems demonstrate the superior performance of our approach over state-of-the-art numerical schemes. The code is available under https://github.com/lueckem/quadrature-ML.

</p>
</details>

<details><summary><b>Robust Training of Social Media Image Classification Models for Rapid Disaster Response</b>
<a href="https://arxiv.org/abs/2104.04184">arxiv:2104.04184</a>
&#x1F4C8; 0 <br>
<p>Firoj Alam, Tanvirul Alam, Muhammad Imran, Ferda Ofli</p></summary>
<p>

**Abstract:** Images shared on social media help crisis managers gain situational awareness and assess incurred damages, among other response tasks. As the volume and velocity of such content are typically high, real-time image classification has become an urgent need for a faster disaster response. Recent advances in computer vision and deep neural networks have enabled the development of models for real-time image classification for a number of tasks, including detecting crisis incidents, filtering irrelevant images, classifying images into specific humanitarian categories, and assessing the severity of the damage. To develop robust real-time models, it is necessary to understand the capability of the publicly available pre-trained models for these tasks, which remains to be under-explored in the crisis informatics literature. In this study, we address such limitations by investigating ten different network architectures for four different tasks using the largest publicly available datasets for these tasks. We also explore various data augmentation strategies, semi-supervised techniques, and a multitask learning setup. In our extensive experiments, we achieve promising results.

</p>
</details>

<details><summary><b>X2CT-FLOW: Maximum a posteriori reconstruction using a progressive flow-based deep generative model for ultra sparse-view computed tomography in ultra low-dose protocols</b>
<a href="https://arxiv.org/abs/2104.04179">arxiv:2104.04179</a>
&#x1F4C8; 0 <br>
<p>Hisaichi Shibata, Shouhei Hanaoka, Yukihiro Nomura, Takahiro Nakao, Tomomi Takenaga, Naoto Hayashi, Osamu Abe</p></summary>
<p>

**Abstract:** Ultra sparse-view computed tomography (CT) algorithms can reduce radiation exposure of patients, but those algorithms lack an explicit cycle consistency loss minimization and an explicit log-likelihood maximization in testing. Here, we propose X2CT-FLOW for the maximum a posteriori (MAP) reconstruction of a three-dimensional (3D) chest CT image from a single or a few two-dimensional (2D) projection images using a progressive flow-based deep generative model, especially for ultra low-dose protocols. The MAP reconstruction can simultaneously optimize the cycle consistency loss and the log-likelihood. The proposed algorithm is built upon a newly developed progressive flow-based deep generative model, which is featured with exact log-likelihood estimation, efficient sampling, and progressive learning. We applied X2CT-FLOW to reconstruction of 3D chest CT images from biplanar projection images without noise contamination (assuming a standard-dose protocol) and with strong noise contamination (assuming an ultra low-dose protocol). With the standard-dose protocol, our images reconstructed from 2D projected images and 3D ground-truth CT images showed good agreement in terms of structural similarity (SSIM, 0.7675 on average), peak signal-to-noise ratio (PSNR, 25.89 dB on average), mean absolute error (MAE, 0.02364 on average), and normalized root mean square error (NRMSE, 0.05731 on average). Moreover, with the ultra low-dose protocol, our images reconstructed from 2D projected images and the 3D ground-truth CT images also showed good agreement in terms of SSIM (0.7008 on average), PSNR (23.58 dB on average), MAE (0.02991 on average), and NRMSE (0.07349 on average).

</p>
</details>

<details><summary><b>The Road to Know-Where: An Object-and-Room Informed Sequential BERT for Indoor Vision-Language Navigation</b>
<a href="https://arxiv.org/abs/2104.04167">arxiv:2104.04167</a>
&#x1F4C8; 0 <br>
<p>Yuankai Qi, Zizheng Pan, Yicong Hong, Ming-Hsuan Yang, Anton van den Hengel, Qi Wu</p></summary>
<p>

**Abstract:** Vision-and-Language Navigation (VLN) requires an agent to find a path to a remote location on the basis of natural-language instructions and a set of photo-realistic panoramas. Most existing methods take the words in the instructions and the discrete views of each panorama as the minimal unit of encoding. However, this requires a model to match different nouns (e.g., TV, table) against the same input view feature. In this work, we propose an object-informed sequential BERT to encode visual perceptions and linguistic instructions at the same fine-grained level, namely objects and words. Our sequential BERT also enables the visual-textual clues to be interpreted in light of the temporal context, which is crucial to multi-round VLN tasks. Additionally, we enable the model to identify the relative direction (e.g., left/right/front/back) of each navigable location and the room type (e.g., bedroom, kitchen) of its current and final navigation goal, as such information is widely mentioned in instructions implying the desired next and final locations. We thus enable the model to know-where the objects lie in the images, and to know-where they stand in the scene. Extensive experiments demonstrate the effectiveness compared against several state-of-the-art methods on three indoor VLN tasks: REVERIE, NDH, and R2R. Project repository: https://github.com/YuankaiQi/ORIST

</p>
</details>

<details><summary><b>Individual Explanations in Machine Learning Models: A Survey for Practitioners</b>
<a href="https://arxiv.org/abs/2104.04144">arxiv:2104.04144</a>
&#x1F4C8; 0 <br>
<p>Alfredo Carrillo, Luis F. Cantú, Alejandro Noriega</p></summary>
<p>

**Abstract:** In recent years, the use of sophisticated statistical models that influence decisions in domains of high societal relevance is on the rise. Although these models can often bring substantial improvements in the accuracy and efficiency of organizations, many governments, institutions, and companies are reluctant to their adoption as their output is often difficult to explain in human-interpretable ways. Hence, these models are often regarded as black-boxes, in the sense that their internal mechanisms can be opaque to human audit. In real-world applications, particularly in domains where decisions can have a sensitive impact--e.g., criminal justice, estimating credit scores, insurance risk, health risks, etc.--model interpretability is desired. Recently, the academic literature has proposed a substantial amount of methods for providing interpretable explanations to machine learning models. This survey reviews the most relevant and novel methods that form the state-of-the-art for addressing the particular problem of explaining individual instances in machine learning. It seeks to provide a succinct review that can guide data science and machine learning practitioners in the search for appropriate methods to their problem domain.

</p>
</details>

<details><summary><b>Uncertainty-Aware Temporal Self-Learning (UATS): Semi-Supervised Learning for Segmentation of Prostate Zones and Beyond</b>
<a href="https://arxiv.org/abs/2104.03840">arxiv:2104.03840</a>
&#x1F4C8; 0 <br>
<p>Anneke Meyer, Suhita Ghosh, Daniel Schindele, Martin Schostak, Sebastian Stober, Christian Hansen, Marko Rak</p></summary>
<p>

**Abstract:** Various convolutional neural network (CNN) based concepts have been introduced for the prostate's automatic segmentation and its coarse subdivision into transition zone (TZ) and peripheral zone (PZ). However, when targeting a fine-grained segmentation of TZ, PZ, distal prostatic urethra (DPU) and the anterior fibromuscular stroma (AFS), the task becomes more challenging and has not yet been solved at the level of human performance. One reason might be the insufficient amount of labeled data for supervised training. Therefore, we propose to apply a semi-supervised learning (SSL) technique named uncertainty-aware temporal self-learning (UATS) to overcome the expensive and time-consuming manual ground truth labeling. We combine the SSL techniques temporal ensembling and uncertainty-guided self-learning to benefit from unlabeled images, which are often readily available. Our method significantly outperforms the supervised baseline and obtained a Dice coefficient (DC) of up to 78.9% , 87.3%, 75.3%, 50.6% for TZ, PZ, DPU and AFS, respectively. The obtained results are in the range of human inter-rater performance for all structures. Moreover, we investigate the method's robustness against noise and demonstrate the generalization capability for varying ratios of labeled data and on other challenging tasks, namely the hippocampus and skin lesion segmentation. UATS achieved superiority segmentation quality compared to the supervised baseline, particularly for minimal amounts of labeled data.

</p>
</details>

<details><summary><b>Towards Enabling Meta-Learning from Target Models</b>
<a href="https://arxiv.org/abs/2104.03736">arxiv:2104.03736</a>
&#x1F4C8; 0 <br>
<p>Su Lu, Han-Jia Ye, Le Gan, De-Chuan Zhan</p></summary>
<p>

**Abstract:** Meta-learning can extract an inductive bias from previous learning experience and assist the training of new tasks. It is often realized through optimizing a meta-model with the evaluation loss of task-specific solvers. Most existing algorithms sample non-overlapping $\mathit{support}$ sets and $\mathit{query}$ sets to train and evaluate the solvers respectively due to simplicity ($\mathcal{S}$/$\mathcal{Q}$ protocol). Different from $\mathcal{S}$/$\mathcal{Q}$ protocol, we can also evaluate a task-specific solver by comparing it to a target model $\mathcal{T}$, which is the optimal model for this task or a model that behaves well enough on this task ($\mathcal{S}$/$\mathcal{T}$ protocol). Although being short of research, $\mathcal{S}$/$\mathcal{T}$ protocol has unique advantages such as offering more informative supervision, but it is computationally expensive. This paper looks into this special evaluation method and takes a step towards putting it into practice. We find that with a small ratio of tasks armed with target models, classic meta-learning algorithms can be improved a lot without consuming many resources. We empirically verify the effectiveness of $\mathcal{S}$/$\mathcal{T}$ protocol in a typical application of meta-learning, $\mathit{i.e.}$, few-shot learning. In detail, after constructing target models by fine-tuning the pre-trained network on those hard tasks, we match the task-specific solvers and target models via knowledge distillation.

</p>
</details>

<details><summary><b>CLIMAT: Clinically-Inspired Multi-Agent Transformers for Knee Osteoarthritis Trajectory Forecasting</b>
<a href="https://arxiv.org/abs/2104.03642">arxiv:2104.03642</a>
&#x1F4C8; 0 <br>
<p>Huy Hoang Nguyen, Simo Saarakkala, Matthew B. Blaschko, Aleksei Tiulpin</p></summary>
<p>

**Abstract:** In medical applications, deep learning methods are built to automate diagnostic tasks. However, a clinically relevant question that practitioners usually face, is how to predict the future trajectory of a disease (prognosis). Current methods for such a problem often require domain knowledge, and are complicated to apply. In this paper, we formulate the prognosis prediction problem as a one-to-many forecasting problem from multimodal data. Inspired by a clinical decision-making process with two agents -- a radiologist and a general practitioner, we model a prognosis prediction problem with two transformer-based components that share information between each other. The first block in this model aims to analyze the imaging data, and the second block leverages the internal representations of the first one as inputs, also fusing them with auxiliary patient data. We show the effectiveness of our method in predicting the development of structural knee osteoarthritis changes over time. Our results show that the proposed method outperforms the state-of-the-art baselines in terms of various performance metrics. In addition, we empirically show that the existence of the multi-agent transformers with depths of 2 is sufficient to achieve good performances. Our code is publicly available at \url{https://github.com/MIPT-Oulu/CLIMAT}.

</p>
</details>

<details><summary><b>Can a CNN trained on the Ising model detect the phase transition of the $q$-state Potts model?</b>
<a href="https://arxiv.org/abs/2104.03632">arxiv:2104.03632</a>
&#x1F4C8; 0 <br>
<p>Kimihiko Fukushima, Kazumitsu Sakai</p></summary>
<p>

**Abstract:** Employing a deep convolutional neural network (deep CNN) trained on spin configurations of the 2D Ising model and the temperatures, we examine whether the deep CNN can detect the phase transition of the 2D $q$-state Potts model. To this end, we generate binarized images of spin configurations of the $q$-state Potts model ($q\ge 3$) by replacing the spin variables $\{0,1,\dots,\lfloor q/2\rfloor-1\}$ and $\{\lfloor q/2\rfloor,\dots,q-1\}$ with $\{0\}$ and $\{1\}$, respectively. Then, we input these images to the trained CNN to output the predicted temperatures. The binarized images of the $q$-state Potts model are entirely different from Ising spin configurations, particularly at the transition temperature. Moreover, our CNN model is not trained on the information about whether phases are ordered/disordered but is naively trained by Ising spin configurations labeled with temperatures at which they are generated. Nevertheless, the deep CNN can detect the transition point with high accuracy, regardless of the type of transition. We also find that, in the high-temperature region, the CNN outputs the temperature based on the internal energy, whereas, in the low-temperature region, the output depends on the magnetization and possibly the internal energy as well. However, in the vicinity of the transition point, the CNN may use more general factors to detect the transition point.

</p>
</details>

<details><summary><b>Arena-Rosnav: Towards Deployment of Deep-Reinforcement-Learning-Based Obstacle Avoidance into Conventional Autonomous Navigation Systems</b>
<a href="https://arxiv.org/abs/2104.03616">arxiv:2104.03616</a>
&#x1F4C8; 0 <br>
<p>Linh Kästner, Teham Buiyan, Xinlin Zhao, Lei Jiao, Zhengcheng Shen, Jens Lambrecht</p></summary>
<p>

**Abstract:** Recently, mobile robots have become important tools in various industries, especially in logistics. Deep reinforcement learning emerged as an alternative planning method to replace overly conservative approaches and promises more efficient and flexible navigation. However, deep reinforcement learning approaches are not suitable for long-range navigation due to their proneness to local minima and lack of long term memory, which hinders its widespread integration into industrial applications of mobile robotics. In this paper, we propose a navigation system incorporating deep-reinforcement-learning-based local planners into conventional navigation stacks for long-range navigation. Therefore, a framework for training and testing the deep reinforcement learning algorithms along with classic approaches is presented. We evaluated our deep-reinforcement-learning-enhanced navigation system against various conventional planners and found that our system outperforms them in terms of safety, efficiency and robustness.

</p>
</details>

<details><summary><b>PDO-e$\text{S}^\text{2}$CNNs: Partial Differential Operator Based Equivariant Spherical CNNs</b>
<a href="https://arxiv.org/abs/2104.03584">arxiv:2104.03584</a>
&#x1F4C8; 0 <br>
<p>Zhengyang Shen, Tiancheng Shen, Zhouchen Lin, Jinwen Ma</p></summary>
<p>

**Abstract:** Spherical signals exist in many applications, e.g., planetary data, LiDAR scans and digitalization of 3D objects, calling for models that can process spherical data effectively. It does not perform well when simply projecting spherical data into the 2D plane and then using planar convolution neural networks (CNNs), because of the distortion from projection and ineffective translation equivariance. Actually, good principles of designing spherical CNNs are avoiding distortions and converting the shift equivariance property in planar CNNs to rotation equivariance in the spherical domain. In this work, we use partial differential operators (PDOs) to design a spherical equivariant CNN, PDO-e$\text{S}^\text{2}$CNN, which is exactly rotation equivariant in the continuous domain. We then discretize PDO-e$\text{S}^\text{2}$CNNs, and analyze the equivariance error resulted from discretization. This is the first time that the equivariance error is theoretically analyzed in the spherical domain. In experiments, PDO-e$\text{S}^\text{2}$CNNs show greater parameter efficiency and outperform other spherical CNNs significantly on several tasks.

</p>
</details>

<details><summary><b>MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement</b>
<a href="https://arxiv.org/abs/2104.03538">arxiv:2104.03538</a>
&#x1F4C8; 0 <br>
<p>Szu-Wei Fu, Cheng Yu, Tsun-An Hsieh, Peter Plantinga, Mirco Ravanelli, Xugang Lu, Yu Tsao</p></summary>
<p>

**Abstract:** The discrepancy between the cost function used for training a speech enhancement model and human auditory perception usually makes the quality of enhanced speech unsatisfactory. Objective evaluation metrics which consider human perception can hence serve as a bridge to reduce the gap. Our previously proposed MetricGAN was designed to optimize objective metrics by connecting the metric with a discriminator. Because only the scores of the target evaluation functions are needed during training, the metrics can even be non-differentiable. In this study, we propose a MetricGAN+ in which three training techniques incorporating domain-knowledge of speech processing are proposed. With these techniques, experimental results on the VoiceBank-DEMAND dataset show that MetricGAN+ can increase PESQ score by 0.3 compared to the previous MetricGAN and achieve state-of-the-art results (PESQ score = 3.15).

</p>
</details>


[Next Page](2021/2021-04/2021-04-07.md)
