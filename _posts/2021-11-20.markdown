## Summary for 2021-11-20, created on 2021-12-17


<details><summary><b>Self-Supervised Point Cloud Completion via Inpainting</b>
<a href="https://arxiv.org/abs/2111.10701">arxiv:2111.10701</a>
&#x1F4C8; 10 <br>
<p>Himangi Mittal, Brian Okorn, Arpit Jangid, David Held</p></summary>
<p>

**Abstract:** When navigating in urban environments, many of the objects that need to be tracked and avoided are heavily occluded. Planning and tracking using these partial scans can be challenging. The aim of this work is to learn to complete these partial point clouds, giving us a full understanding of the object's geometry using only partial observations. Previous methods achieve this with the help of complete, ground-truth annotations of the target objects, which are available only for simulated datasets. However, such ground truth is unavailable for real-world LiDAR data. In this work, we present a self-supervised point cloud completion algorithm, PointPnCNet, which is trained only on partial scans without assuming access to complete, ground-truth annotations. Our method achieves this via inpainting. We remove a portion of the input data and train the network to complete the missing region. As it is difficult to determine which regions were occluded in the initial cloud and which were synthetically removed, our network learns to complete the full cloud, including the missing regions in the initial partial cloud. We show that our method outperforms previous unsupervised and weakly-supervised methods on both the synthetic dataset, ShapeNet, and real-world LiDAR dataset, Semantic KITTI.

</p>
</details>

<details><summary><b>Extracting Deformation-Aware Local Features by Learning to Deform</b>
<a href="https://arxiv.org/abs/2111.10617">arxiv:2111.10617</a>
&#x1F4C8; 9 <br>
<p>Guilherme Potje, Renato Martins, Felipe Cadar, Erickson R. Nascimento</p></summary>
<p>

**Abstract:** Despite the advances in extracting local features achieved by handcrafted and learning-based descriptors, they are still limited by the lack of invariance to non-rigid transformations. In this paper, we present a new approach to compute features from still images that are robust to non-rigid deformations to circumvent the problem of matching deformable surfaces and objects. Our deformation-aware local descriptor, named DEAL, leverages a polar sampling and a spatial transformer warping to provide invariance to rotation, scale, and image deformations. We train the model architecture end-to-end by applying isometric non-rigid deformations to objects in a simulated environment as guidance to provide highly discriminative local features. The experiments show that our method outperforms state-of-the-art handcrafted, learning-based image, and RGB-D descriptors in different datasets with both real and realistic synthetic deformable objects in still images. The source code and trained model of the descriptor are publicly available at https://www.verlab.dcc.ufmg.br/descriptors/neurips2021.

</p>
</details>

<details><summary><b>SPINE: Soft Piecewise Interpretable Neural Equations</b>
<a href="https://arxiv.org/abs/2111.10622">arxiv:2111.10622</a>
&#x1F4C8; 8 <br>
<p>Jasdeep Singh Grover, Harsh Minesh Domadia, Raj Anant Tapase, Grishma Sharma</p></summary>
<p>

**Abstract:** Relu Fully Connected Networks are ubiquitous but uninterpretable because they fit piecewise linear functions emerging from multi-layered structures and complex interactions of model weights. This paper takes a novel approach to piecewise fits by using set operations on individual pieces(parts). This is done by approximating canonical normal forms and using the resultant as a model. This gives special advantages like (a)strong correspondence of parameters to pieces of the fit function(High Interpretability); (b)ability to fit any combination of continuous functions as pieces of the piecewise function(Ease of Design); (c)ability to add new non-linearities in a targeted region of the domain(Targeted Learning); (d)simplicity of an equation which avoids layering. It can also be expressed in the general max-min representation of piecewise linear functions which gives theoretical ease and credibility. This architecture is tested on simulated regression and classification tasks and benchmark datasets including UCI datasets, MNIST, FMNIST, and CIFAR 10. This performance is on par with fully connected architectures. It can find a variety of applications where fully connected layers must be replaced by interpretable layers.

</p>
</details>

<details><summary><b>Deep Probability Estimation</b>
<a href="https://arxiv.org/abs/2111.10734">arxiv:2111.10734</a>
&#x1F4C8; 7 <br>
<p>Sheng Liu, Aakash Kaku, Weicheng Zhu, Matan Leibovich, Sreyas Mohan, Boyang Yu, Laure Zanna, Narges Razavian, Carlos Fernandez-Granda</p></summary>
<p>

**Abstract:** Reliable probability estimation is of crucial importance in many real-world applications where there is inherent uncertainty, such as weather forecasting, medical prognosis, or collision avoidance in autonomous vehicles. Probability-estimation models are trained on observed outcomes (e.g. whether it has rained or not, or whether a patient has died or not), because the ground-truth probabilities of the events of interest are typically unknown. The problem is therefore analogous to binary classification, with the important difference that the objective is to estimate probabilities rather than predicting the specific outcome. The goal of this work is to investigate probability estimation from high-dimensional data using deep neural networks. There exist several methods to improve the probabilities generated by these models but they mostly focus on classification problems where the probabilities are related to model uncertainty. In the case of problems with inherent uncertainty, it is challenging to evaluate performance without access to ground-truth probabilities. To address this, we build a synthetic dataset to study and compare different computable metrics. We evaluate existing methods on the synthetic data as well as on three real-world probability estimation tasks, all of which involve inherent uncertainty: precipitation forecasting from radar images, predicting cancer patient survival from histopathology images, and predicting car crashes from dashcam videos. Finally, we also propose a new method for probability estimation using neural networks, which modifies the training process to promote output probabilities that are consistent with empirical probabilities computed from the data. The method outperforms existing approaches on most metrics on the simulated as well as real-world data.

</p>
</details>

<details><summary><b>Deep Spoken Keyword Spotting: An Overview</b>
<a href="https://arxiv.org/abs/2111.10592">arxiv:2111.10592</a>
&#x1F4C8; 7 <br>
<p>Iván López-Espejo, Zheng-Hua Tan, John Hansen, Jesper Jensen</p></summary>
<p>

**Abstract:** Spoken keyword spotting (KWS) deals with the identification of keywords in audio streams and has become a fast-growing technology thanks to the paradigm shift introduced by deep learning a few years ago. This has allowed the rapid embedding of deep KWS in a myriad of small electronic devices with different purposes like the activation of voice assistants. Prospects suggest a sustained growth in terms of social use of this technology. Thus, it is not surprising that deep KWS has become a hot research topic among speech scientists, who constantly look for KWS performance improvement and computational complexity reduction. This context motivates this paper, in which we conduct a literature review into deep spoken KWS to assist practitioners and researchers who are interested in this technology. Specifically, this overview has a comprehensive nature by covering a thorough analysis of deep KWS systems (which includes speech features, acoustic modeling and posterior handling), robustness methods, applications, datasets, evaluation metrics, performance of deep KWS systems and audio-visual KWS. The analysis performed in this paper allows us to identify a number of directions for future research, including directions adopted from automatic speech recognition research and directions that are unique to the problem of spoken KWS.

</p>
</details>

<details><summary><b>End-to-end Learning for Fair Ranking Systems</b>
<a href="https://arxiv.org/abs/2111.10723">arxiv:2111.10723</a>
&#x1F4C8; 6 <br>
<p>James Kotary, Ferdinando Fioretto, Pascal Van Hentenryck, Ziwei Zhu</p></summary>
<p>

**Abstract:** The learning-to-rank problem aims at ranking items to maximize exposure of those most relevant to a user query. A desirable property of such ranking systems is to guarantee some notion of fairness among specified item groups. While fairness has recently been considered in the context of learning-to-rank systems, current methods cannot provide guarantees on the fairness of the proposed ranking policies.
  This paper addresses this gap and introduces Smart Predict and Optimize for Fair Ranking (SPOFR), an integrated optimization and learning framework for fairness-constrained learning to rank. The end-to-end SPOFR framework includes a constrained optimization sub-model and produces ranking policies that are guaranteed to satisfy fairness constraints while allowing for fine control of the fairness-utility tradeoff. SPOFR is shown to significantly improve current state-of-the-art fair learning-to-rank systems with respect to established performance metrics.

</p>
</details>

<details><summary><b>Representing Prior Knowledge Using Randomly, Weighted Feature Networks for Visual Relationship Detection</b>
<a href="https://arxiv.org/abs/2111.10686">arxiv:2111.10686</a>
&#x1F4C8; 6 <br>
<p>Jinyung Hong, Theodore P. Pavlic</p></summary>
<p>

**Abstract:** The single-hidden-layer Randomly Weighted Feature Network (RWFN) introduced by Hong and Pavlic (2021) was developed as an alternative to neural tensor network approaches for relational learning tasks. Its relatively small footprint combined with the use of two randomized input projections -- an insect-brain-inspired input representation and random Fourier features -- allow it to achieve rich expressiveness for relational learning with relatively low training cost. In particular, when Hong and Pavlic compared RWFN to Logic Tensor Networks (LTNs) for Semantic Image Interpretation (SII) tasks to extract structured semantic descriptions from images, they showed that the RWFN integration of the two hidden, randomized representations better captures relationships among inputs with a faster training process even though it uses far fewer learnable parameters. In this paper, we use RWFNs to perform Visual Relationship Detection (VRD) tasks, which are more challenging SII tasks. A zero-shot learning approach is used with RWFN that can exploit similarities with other seen relationships and background knowledge -- expressed with logical constraints between subjects, relations, and objects -- to achieve the ability to predict triples that do not appear in the training set. The experiments on the Visual Relationship Dataset to compare the performance between RWFNs and LTNs, one of the leading Statistical Relational Learning frameworks, show that RWFNs outperform LTNs for the predicate-detection task while using fewer number of adaptable parameters (1:56 ratio). Furthermore, background knowledge represented by RWFNs can be used to alleviate the incompleteness of training sets even though the space complexity of RWFNs is much smaller than LTNs (1:27 ratio).

</p>
</details>

<details><summary><b>Teacher-Student Training and Triplet Loss to Reduce the Effect of Drastic Face Occlusion</b>
<a href="https://arxiv.org/abs/2111.10561">arxiv:2111.10561</a>
&#x1F4C8; 5 <br>
<p>Mariana-Iuliana Georgescu, Georgian Duta, Radu Tudor Ionescu</p></summary>
<p>

**Abstract:** We study a series of recognition tasks in two realistic scenarios requiring the analysis of faces under strong occlusion. On the one hand, we aim to recognize facial expressions of people wearing Virtual Reality (VR) headsets. On the other hand, we aim to estimate the age and identify the gender of people wearing surgical masks. For all these tasks, the common ground is that half of the face is occluded. In this challenging setting, we show that convolutional neural networks (CNNs) trained on fully-visible faces exhibit very low performance levels. While fine-tuning the deep learning models on occluded faces is extremely useful, we show that additional performance gains can be obtained by distilling knowledge from models trained on fully-visible faces. To this end, we study two knowledge distillation methods, one based on teacher-student training and one based on triplet loss. Our main contribution consists in a novel approach for knowledge distillation based on triplet loss, which generalizes across models and tasks. Furthermore, we consider combining distilled models learned through conventional teacher-student training or through our novel teacher-student training based on triplet loss. We provide empirical evidence showing that, in most cases, both individual and combined knowledge distillation methods bring statistically significant performance improvements. We conduct experiments with three different neural models (VGG-f, VGG-face, ResNet-50) on various tasks (facial expression recognition, gender recognition, age estimation), showing consistent improvements regardless of the model or task.

</p>
</details>

<details><summary><b>ACR-Pose: Adversarial Canonical Representation Reconstruction Network for Category Level 6D Object Pose Estimation</b>
<a href="https://arxiv.org/abs/2111.10524">arxiv:2111.10524</a>
&#x1F4C8; 5 <br>
<p>Zhaoxin Fan, Zhengbo Song, Jian Xu, Zhicheng Wang, Kejian Wu, Hongyan Liu, Jun He</p></summary>
<p>

**Abstract:** Recently, category-level 6D object pose estimation has achieved significant improvements with the development of reconstructing canonical 3D representations. However, the reconstruction quality of existing methods is still far from excellent. In this paper, we propose a novel Adversarial Canonical Representation Reconstruction Network named ACR-Pose. ACR-Pose consists of a Reconstructor and a Discriminator. The Reconstructor is primarily composed of two novel sub-modules: Pose-Irrelevant Module (PIM) and Relational Reconstruction Module (RRM). PIM tends to learn canonical-related features to make the Reconstructor insensitive to rotation and translation, while RRM explores essential relational information between different input modalities to generate high-quality features. Subsequently, a Discriminator is employed to guide the Reconstructor to generate realistic canonical representations. The Reconstructor and the Discriminator learn to optimize through adversarial training. Experimental results on the prevalent NOCS-CAMERA and NOCS-REAL datasets demonstrate that our method achieves state-of-the-art performance.

</p>
</details>

<details><summary><b>A Review on The Division of Magnetic Resonant Prostate Images with Deep Learning</b>
<a href="https://arxiv.org/abs/2111.10683">arxiv:2111.10683</a>
&#x1F4C8; 4 <br>
<p>Elcin Huseyn, Emin Mammadov, Mohammad Hoseini</p></summary>
<p>

**Abstract:** Deep learning; it is often used in dividing processes on images in the biomedical field. In recent years, it has been observed that there is an increase in the division procedures performed on prostate images using deep learning compared to other methods of image division. Looking at the literature; It is seen that the process of dividing prostate images, which are carried out with deep learning, is an important step for the diagnosis and treatment of prostate cancer. For this reason, in this study; to be a source for future splitting operations; deep learning splitting procedures on prostate images obtained from magnetic resonance (MRI) imaging devices were examined.

</p>
</details>

<details><summary><b>Real-time Human Detection Model for Edge Devices</b>
<a href="https://arxiv.org/abs/2111.10653">arxiv:2111.10653</a>
&#x1F4C8; 4 <br>
<p>Ali Farouk Khalifa, Hesham N. Elmahdy, Eman Badr</p></summary>
<p>

**Abstract:** Building a small-sized fast surveillance system model to fit on limited resource devices is a challenging, yet an important task. Convolutional Neural Networks (CNNs) have replaced traditional feature extraction and machine learning models in detection and classification tasks. Various complex large CNN models are proposed that achieve significant improvement in the accuracy. Lightweight CNN models have been recently introduced for real-time tasks. This paper suggests a CNN-based lightweight model that can fit on a limited edge device such as Raspberry Pi. Our proposed model provides better performance time, smaller size and comparable accuracy with existing method. The model performance is evaluated on multiple benchmark datasets. It is also compared with existing models in terms of size, average processing time, and F-score. Other enhancements for future research are suggested.

</p>
</details>

<details><summary><b>PAANet: Progressive Alternating Attention for Automatic Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2111.10618">arxiv:2111.10618</a>
&#x1F4C8; 4 <br>
<p>Abhishek Srivastava, Sukalpa Chanda, Debesh Jha, Michael A. Riegler, Pål Halvorsen, Dag Johansen, Umapada Pal</p></summary>
<p>

**Abstract:** Medical image segmentation can provide detailed information for clinical analysis which can be useful for scenarios where the detailed location of a finding is important. Knowing the location of disease can play a vital role in treatment and decision-making. Convolutional neural network (CNN) based encoder-decoder techniques have advanced the performance of automated medical image segmentation systems. Several such CNN-based methodologies utilize techniques such as spatial- and channel-wise attention to enhance performance. Another technique that has drawn attention in recent years is residual dense blocks (RDBs). The successive convolutional layers in densely connected blocks are capable of extracting diverse features with varied receptive fields and thus, enhancing performance. However, consecutive stacked convolutional operators may not necessarily generate features that facilitate the identification of the target structures. In this paper, we propose a progressive alternating attention network (PAANet). We develop progressive alternating attention dense (PAAD) blocks, which construct a guiding attention map (GAM) after every convolutional layer in the dense blocks using features from all scales. The GAM allows the following layers in the dense blocks to focus on the spatial locations relevant to the target region. Every alternate PAAD block inverts the GAM to generate a reverse attention map which guides ensuing layers to extract boundary and edge-related information, refining the segmentation process. Our experiments on three different biomedical image segmentation datasets exhibit that our PAANet achieves favourable performance when compared to other state-of-the-art methods.

</p>
</details>

<details><summary><b>Constrained Deep One-Class Feature Learning For Classifying Imbalanced Medical Images</b>
<a href="https://arxiv.org/abs/2111.10610">arxiv:2111.10610</a>
&#x1F4C8; 4 <br>
<p>Long Gao, Chang Liu, Dooman Arefan, Ashok Panigrahy, Shandong Wu</p></summary>
<p>

**Abstract:** Medical image data are usually imbalanced across different classes. One-class classification has attracted increasing attention to address the data imbalance problem by distinguishing the samples of the minority class from the majority class. Previous methods generally aim to either learn a new feature space to map training samples together or to fit training samples by autoencoder-like models. These methods mainly focus on capturing either compact or descriptive features, where the information of the samples of a given one class is not sufficiently utilized. In this paper, we propose a novel deep learning-based method to learn compact features by adding constraints on the bottleneck features, and to preserve descriptive features by training an autoencoder at the same time. Through jointly optimizing the constraining loss and the autoencoder's reconstruction loss, our method can learn more relevant features associated with the given class, making the majority and minority samples more distinguishable. Experimental results on three clinical datasets (including the MRI breast images, FFDM breast images and chest X-ray images) obtains state-of-art performance compared to previous methods.

</p>
</details>

<details><summary><b>RDF-to-Text Generation with Reinforcement Learning Based Graph-augmented Structural Neural Encoders</b>
<a href="https://arxiv.org/abs/2111.10545">arxiv:2111.10545</a>
&#x1F4C8; 4 <br>
<p>Hanning Gao, Lingfei Wu, Po Hu, Zhihua Wei, Fangli Xu, Bo Long</p></summary>
<p>

**Abstract:** Considering a collection of RDF triples, the RDF-to-text generation task aims to generate a text description. Most previous methods solve this task using a sequence-to-sequence model or using a graph-based model to encode RDF triples and to generate a text sequence. Nevertheless, these approaches fail to clearly model the local and global structural information between and within RDF triples. Moreover, the previous methods also face the non-negligible problem of low faithfulness of the generated text, which seriously affects the overall performance of these models. To solve these problems, we propose a model combining two new graph-augmented structural neural encoders to jointly learn both local and global structural information in the input RDF triples. To further improve text faithfulness, we innovatively introduce a reinforcement learning (RL) reward based on information extraction (IE). We first extract triples from the generated text using a pretrained IE model and regard the correct number of the extracted triples as the additional RL reward. Experimental results on two benchmark datasets demonstrate that our proposed model outperforms the state-of-the-art baselines, and the additional reinforcement learning reward does help to improve the faithfulness of the generated text.

</p>
</details>

<details><summary><b>Real-World Semantic Grasping Detection</b>
<a href="https://arxiv.org/abs/2111.10522">arxiv:2111.10522</a>
&#x1F4C8; 4 <br>
<p>Mingshuai Dong, Shimin Wei, Jianqin Yin, Xiuli Yu</p></summary>
<p>

**Abstract:** Reducing the scope of grasping detection according to the semantic information of the target is significant to improve the accuracy of the grasping detection model and expand its application. Researchers have been trying to combine these capabilities in an end-to-end network to grasp specific objects in a cluttered scene efficiently. In this paper, we propose an end-to-end semantic grasping detection model, which can accomplish both semantic recognition and grasping detection. And we also design a target feature filtering mechanism, which only maintains the features of a single object according to the semantic information for grasping detection. This method effectively reduces the background features that are weakly correlated to the target object, thus making the features more unique and guaranteeing the accuracy and efficiency of grasping detection. Experimental results show that the proposed method can achieve 98.38% accuracy in Cornell grasping dataset Furthermore, our results on different datasets or evaluation metrics show the domain adaptability of our method over the state-of-the-art.

</p>
</details>

<details><summary><b>HeterPS: Distributed Deep Learning With Reinforcement Learning Based Scheduling in Heterogeneous Environments</b>
<a href="https://arxiv.org/abs/2111.10635">arxiv:2111.10635</a>
&#x1F4C8; 3 <br>
<p>Ji Liu, Zhihua Wu, Dianhai Yu, Yanjun Ma, Danlei Feng, Minxu Zhang, Xinxuan Wu, Xuefeng Yao, Dejing Dou</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) exploit many layers and a large number of parameters to achieve excellent performance. The training process of DNN models generally handles large-scale input data with many sparse features, which incurs high Input/Output (IO) cost, while some layers are compute-intensive. The training process generally exploits distributed computing resources to reduce training time. In addition, heterogeneous computing resources, e.g., CPUs, GPUs of multiple types, are available for the distributed training process. Thus, the scheduling of multiple layers to diverse computing resources is critical for the training process. To efficiently train a DNN model using the heterogeneous computing resources, we propose a distributed framework, i.e., Paddle-Heterogeneous Parameter Server (Paddle-HeterPS), composed of a distributed architecture and a Reinforcement Learning (RL)-based scheduling method. The advantages of Paddle-HeterPS are three-fold compared with existing frameworks. First, Paddle-HeterPS enables efficient training process of diverse workloads with heterogeneous computing resources. Second, Paddle-HeterPS exploits an RL-based method to efficiently schedule the workload of each layer to appropriate computing resources to minimize the cost while satisfying throughput constraints. Third, Paddle-HeterPS manages data storage and data communication among distributed computing resources. We carry out extensive experiments to show that Paddle-HeterPS significantly outperforms state-of-the-art approaches in terms of throughput (14.5 times higher) and monetary cost (312.3% smaller). The codes of the framework are publicly available at: https://github.com/PaddlePaddle/Paddle.

</p>
</details>

<details><summary><b>Explainable Biomedical Recommendations via Reinforcement Learning Reasoning on Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2111.10625">arxiv:2111.10625</a>
&#x1F4C8; 3 <br>
<p>Gavin Edwards, Sebastian Nilsson, Benedek Rozemberczki, Eliseo Papa</p></summary>
<p>

**Abstract:** For Artificial Intelligence to have a greater impact in biology and medicine, it is crucial that recommendations are both accurate and transparent. In other domains, a neurosymbolic approach of multi-hop reasoning on knowledge graphs has been shown to produce transparent explanations. However, there is a lack of research applying it to complex biomedical datasets and problems. In this paper, the approach is explored for drug discovery to draw solid conclusions on its applicability. For the first time, we systematically apply it to multiple biomedical datasets and recommendation tasks with fair benchmark comparisons. The approach is found to outperform the best baselines by 21.7% on average whilst producing novel, biologically relevant explanations.

</p>
</details>

<details><summary><b>Medical Knowledge-Guided Deep Learning for Imbalanced Medical Image Classification</b>
<a href="https://arxiv.org/abs/2111.10620">arxiv:2111.10620</a>
&#x1F4C8; 3 <br>
<p>Long Gao, Chang Liu, Dooman Arefan, Ashok Panigrahy, Margarita L. Zuley, Shandong Wu</p></summary>
<p>

**Abstract:** Deep learning models have gained remarkable performance on a variety of image classification tasks. However, many models suffer from limited performance in clinical or medical settings when data are imbalanced. To address this challenge, we propose a medical-knowledge-guided one-class classification approach that leverages domain-specific knowledge of classification tasks to boost the model's performance. The rationale behind our approach is that some existing prior medical knowledge can be incorporated into data-driven deep learning to facilitate model learning. We design a deep learning-based one-class classification pipeline for imbalanced image classification, and demonstrate in three use cases how we take advantage of medical knowledge of each specific classification task by generating additional middle classes to achieve higher classification performances. We evaluate our approach on three different clinical image classification tasks (a total of 8459 images) and show superior model performance when compared to six state-of-the-art methods. All codes of this work will be publicly available upon acceptance of the paper.

</p>
</details>

<details><summary><b>GMSRF-Net: An improved generalizability with global multi-scale residual fusion network for polyp segmentation</b>
<a href="https://arxiv.org/abs/2111.10614">arxiv:2111.10614</a>
&#x1F4C8; 3 <br>
<p>Abhishek Srivastava, Sukalpa Chanda, Debesh Jha, Umapada Pal, Sharib Ali</p></summary>
<p>

**Abstract:** Colonoscopy is a gold standard procedure but is highly operator-dependent. Efforts have been made to automate the detection and segmentation of polyps, a precancerous precursor, to effectively minimize missed rate. Widely used computer-aided polyp segmentation systems actuated by encoder-decoder have achieved high performance in terms of accuracy. However, polyp segmentation datasets collected from varied centers can follow different imaging protocols leading to difference in data distribution. As a result, most methods suffer from performance drop and require re-training for each specific dataset. We address this generalizability issue by proposing a global multi-scale residual fusion network (GMSRF-Net). Our proposed network maintains high-resolution representations while performing multi-scale fusion operations for all resolution scales. To further leverage scale information, we design cross multi-scale attention (CMSA) and multi-scale feature selection (MSFS) modules within the GMSRF-Net. The repeated fusion operations gated by CMSA and MSFS demonstrate improved generalizability of the network. Experiments conducted on two different polyp segmentation datasets show that our proposed GMSRF-Net outperforms the previous top-performing state-of-the-art method by 8.34% and 10.31% on unseen CVC-ClinicDB and unseen Kvasir-SEG, in terms of dice coefficient.

</p>
</details>

<details><summary><b>Satellite Based Computing Networks with Federated Learning</b>
<a href="https://arxiv.org/abs/2111.10586">arxiv:2111.10586</a>
&#x1F4C8; 3 <br>
<p>Hao Chen, Ming Xiao, Zhibo Pang</p></summary>
<p>

**Abstract:** Driven by the ever-increasing penetration and proliferation of data-driven applications, a new generation of wireless communication, the sixth-generation (6G) mobile system enhanced by artificial intelligence (AI), has attracted substantial research interests. Among various candidate technologies of 6G, low earth orbit (LEO) satellites have appealing characteristics of ubiquitous wireless access. However, the costs of satellite communication (SatCom) are still high, relative to counterparts of ground mobile networks. To support massively interconnected devices with intelligent adaptive learning and reduce expensive traffic in SatCom, we propose federated learning (FL) in LEO-based satellite communication networks. We first review the state-of-the-art LEO-based SatCom and related machine learning (ML) techniques, and then analyze four possible ways of combining ML with satellite networks. The learning performance of the proposed strategies is evaluated by simulation and results reveal that FL-based computing networks improve the performance of communication overheads and latency. Finally, we discuss future research topics along this research direction.

</p>
</details>

<details><summary><b>Quaternion-Based Graph Convolution Network for Recommendation</b>
<a href="https://arxiv.org/abs/2111.10536">arxiv:2111.10536</a>
&#x1F4C8; 3 <br>
<p>Yaxing Fang, Pengpeng Zhao, Guanfeng Liu, Yanchi Liu, Victor S. Sheng, Lei Zhao, Xiaofang Zhou</p></summary>
<p>

**Abstract:** Graph Convolution Network (GCN) has been widely applied in recommender systems for its representation learning capability on user and item embeddings. However, GCN is vulnerable to noisy and incomplete graphs, which are common in real world, due to its recursive message propagation mechanism. In the literature, some work propose to remove the feature transformation during message propagation, but making it unable to effectively capture the graph structural features. Moreover, they model users and items in the Euclidean space, which has been demonstrated to have high distortion when modeling complex graphs, further degrading the capability to capture the graph structural features and leading to sub-optimal performance. To this end, in this paper, we propose a simple yet effective Quaternion-based Graph Convolution Network (QGCN) recommendation model. In the proposed model, we utilize the hyper-complex Quaternion space to learn user and item representations and feature transformation to improve both performance and robustness. Specifically, we first embed all users and items into the Quaternion space. Then, we introduce the quaternion embedding propagation layers with quaternion feature transformation to perform message propagation. Finally, we combine the embeddings generated at each layer with the mean pooling strategy to obtain the final embeddings for recommendation. Extensive experiments on three public benchmark datasets demonstrate that our proposed QGCN model outperforms baseline methods by a large margin.

</p>
</details>

<details><summary><b>Adversarial Sampling for Solving Differential Equations with Neural Networks</b>
<a href="https://arxiv.org/abs/2111.12024">arxiv:2111.12024</a>
&#x1F4C8; 2 <br>
<p>Kshitij Parwani, Pavlos Protopapas</p></summary>
<p>

**Abstract:** Neural network-based methods for solving differential equations have been gaining traction. They work by improving the differential equation residuals of a neural network on a sample of points in each iteration. However, most of them employ standard sampling schemes like uniform or perturbing equally spaced points. We present a novel sampling scheme which samples points adversarially to maximize the loss of the current solution estimate. A sampler architecture is described along with the loss terms used for training. Finally, we demonstrate that this scheme outperforms pre-existing schemes by comparing both on a number of problems.

</p>
</details>

<details><summary><b>Low-Discrepancy Points via Energetic Variational Inference</b>
<a href="https://arxiv.org/abs/2111.10722">arxiv:2111.10722</a>
&#x1F4C8; 2 <br>
<p>Yindong Chen, Yiwei Wang, Lulu Kang, Chun Liu</p></summary>
<p>

**Abstract:** In this paper, we propose a deterministic variational inference approach and generate low-discrepancy points by minimizing the kernel discrepancy, also known as the Maximum Mean Discrepancy or MMD. Based on the general energetic variational inference framework by Wang et. al. (2021), minimizing the kernel discrepancy is transformed to solving a dynamic ODE system via the explicit Euler scheme. We name the resulting algorithm EVI-MMD and demonstrate it through examples in which the target distribution is fully specified, partially specified up to the normalizing constant, and empirically known in the form of training data. Its performances are satisfactory compared to alternative methods in the applications of distribution approximation, numerical integration, and generative learning. The EVI-MMD algorithm overcomes the bottleneck of the existing MMD-descent algorithms, which are mostly applicable to two-sample problems. Algorithms with more sophisticated structures and potential advantages can be developed under the EVI framework.

</p>
</details>

<details><summary><b>PAC-Learning Uniform Ergodic Communicative Networks</b>
<a href="https://arxiv.org/abs/2111.10708">arxiv:2111.10708</a>
&#x1F4C8; 2 <br>
<p>Yihan He</p></summary>
<p>

**Abstract:** This work addressed the problem of learning a network with communication between vertices. The communication between vertices is presented in the form of perturbation on the measure. We studied the scenario where samples are drawn from a uniform ergodic Random Graph Process (RGPs for short), which provides a natural mathematical context for the problem of interest. For the binary classification problem, the result we obtained gives uniform learn-ability as the worst-case theoretical limits. We introduced the structural Rademacher complexity, which naturally fused into the VC theory to upperbound the first moment. With the martingale method and Marton's coupling, we establish the tail bound for uniform convergence and give consistency guarantee for empirical risk minimizer. The technique used in this work to obtain high probability bounds is of independent interest to other mixing processes with and without network structure.

</p>
</details>

<details><summary><b>Faster Deterministic Approximation Algorithms for Correlation Clustering and Cluster Deletion</b>
<a href="https://arxiv.org/abs/2111.10699">arxiv:2111.10699</a>
&#x1F4C8; 2 <br>
<p>Nate Veldt</p></summary>
<p>

**Abstract:** Correlation clustering is a framework for partitioning datasets based on pairwise similarity and dissimilarity scores, and has been used for diverse applications in bioinformatics, social network analysis, and computer vision. Although many approximation algorithms have been designed for this problem, the best theoretical results rely on obtaining lower bounds via expensive linear programming relaxations. In this paper we prove new relationships between correlation clustering problems and edge labeling problems related to the principle of strong triadic closure. We use these connections to develop new approximation algorithms for correlation clustering that have deterministic constant factor approximation guarantees and avoid the canonical linear programming relaxation. Our approach also extends to a variant of correlation clustering called cluster deletion, that strictly prohibits placing negative edges inside clusters. Our results include 4-approximation algorithms for cluster deletion and correlation clustering, based on simplified linear programs with far fewer constraints than the canonical relaxations. More importantly, we develop faster techniques that are purely combinatorial, based on computing maximal matchings in certain auxiliary graphs and hypergraphs. This leads to a combinatorial 6-approximation for complete unweighted correlation clustering, which is the best deterministic result for any method that does not rely on linear programming. We also present the first combinatorial constant factor approximation for cluster deletion.

</p>
</details>

<details><summary><b>Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming</b>
<a href="https://arxiv.org/abs/2111.10698">arxiv:2111.10698</a>
&#x1F4C8; 2 <br>
<p>Yizhen Zheng, Ming Jin, Shirui Pan, Yuan-Fang Li, Hao Peng, Ming Li, Zhao Li</p></summary>
<p>

**Abstract:** Graph representation learning (GRL) is critical for graph-structured data analysis. However, most of the existing graph neural networks (GNNs) heavily rely on labeling information, which is normally expensive to obtain in the real world. Existing unsupervised GRL methods suffer from certain limitations, such as the heavy reliance on monotone contrastiveness and limited scalability. To overcome the aforementioned problems, in light of the recent advancements in graph contrastive learning, we introduce a novel self-supervised graph representation learning algorithm via Graph Contrastive Adjusted Zooming, namely G-Zoom, to learn node representations by leveraging the proposed adjusted zooming scheme. Specifically, this mechanism enables G-Zoom to explore and extract self-supervision signals from a graph from multiple scales: micro (i.e., node-level), meso (i.e., neighbourhood-level), and macro (i.e., subgraph-level). Firstly, we generate two augmented views of the input graph via two different graph augmentations. Then, we establish three different contrastiveness on the above three scales progressively, from node, neighbouring, to subgraph level, where we maximize the agreement between graph representations across scales. While we can extract valuable clues from a given graph on the micro and macro perspectives, the neighbourhood-level contrastiveness offers G-Zoom the capability of a customizable option based on our adjusted zooming scheme to manually choose an optimal viewpoint that lies between the micro and macro perspectives to better understand the graph data. Additionally, to make our model scalable to large graphs, we employ a parallel graph diffusion approach to decouple model training from the graph size. We have conducted extensive experiments on real-world datasets, and the results demonstrate that our proposed model outperforms state-of-the-art methods consistently.

</p>
</details>

<details><summary><b>Image-Like Graph Representations for Improved Molecular Property Prediction</b>
<a href="https://arxiv.org/abs/2111.10695">arxiv:2111.10695</a>
&#x1F4C8; 2 <br>
<p>Toni Sagayaraj, Carsten Eickhoff</p></summary>
<p>

**Abstract:** Research into deep learning models for molecular property prediction has primarily focused on the development of better Graph Neural Network (GNN) architectures. Though new GNN variants continue to improve performance, their modifications share a common theme of alleviating problems intrinsic to their fundamental graph-to-graph nature. In this work, we examine these limitations and propose a new molecular representation that bypasses the need for GNNs entirely, dubbed CubeMol. Our fixed-dimensional stochastic representation, when paired with a transformer model, exceeds the performance of state-of-the-art GNN models and provides a path for scalability.

</p>
</details>

<details><summary><b>Doing More by Doing Less: How Structured Partial Backpropagation Improves Deep Learning Clusters</b>
<a href="https://arxiv.org/abs/2111.10672">arxiv:2111.10672</a>
&#x1F4C8; 2 <br>
<p>Adarsh Kumar, Kausik Subramanian, Shivaram Venkataraman, Aditya Akella</p></summary>
<p>

**Abstract:** Many organizations employ compute clusters equipped with accelerators such as GPUs and TPUs for training deep learning models in a distributed fashion. Training is resource-intensive, consuming significant compute, memory, and network resources. Many prior works explore how to reduce training resource footprint without impacting quality, but their focus on a subset of the bottlenecks (typically only the network) limits their ability to improve overall cluster utilization. In this work, we exploit the unique characteristics of deep learning workloads to propose Structured Partial Backpropagation(SPB), a technique that systematically controls the amount of backpropagation at individual workers in distributed training. This simultaneously reduces network bandwidth, compute utilization, and memory footprint while preserving model quality. To efficiently leverage the benefits of SPB at cluster level, we introduce JigSaw, a SPB aware scheduler, which does scheduling at the iteration level for Deep Learning Training(DLT) jobs. We find that JigSaw can improve large scale cluster efficiency by as high as 28\%.

</p>
</details>

<details><summary><b>Generalizing Graph Neural Networks on Out-Of-Distribution Graphs</b>
<a href="https://arxiv.org/abs/2111.10657">arxiv:2111.10657</a>
&#x1F4C8; 2 <br>
<p>Shaohua Fan, Xiao Wang, Chuan Shi, Peng Cui, Bai Wang</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) are proposed without considering the agnostic distribution shifts between training and testing graphs, inducing the degeneration of the generalization ability of GNNs on Out-Of-Distribution (OOD) settings. The fundamental reason for such degeneration is that most GNNs are developed based on the I.I.D hypothesis. In such a setting, GNNs tend to exploit subtle statistical correlations existing in the training set for predictions, even though it is a spurious correlation. However, such spurious correlations may change in testing environments, leading to the failure of GNNs. Therefore, eliminating the impact of spurious correlations is crucial for stable GNNs. To this end, we propose a general causal representation framework, called StableGNN. The main idea is to extract high-level representations from graph data first and resort to the distinguishing ability of causal inference to help the model get rid of spurious correlations. Particularly, we exploit a graph pooling layer to extract subgraph-based representations as high-level representations. Furthermore, we propose a causal variable distinguishing regularizer to correct the biased training distribution. Hence, GNNs would concentrate more on the stable correlations. Extensive experiments on both synthetic and real-world OOD graph datasets well verify the effectiveness, flexibility and interpretability of the proposed framework.

</p>
</details>

<details><summary><b>Simple End-to-end Deep Learning Model for CDR-H3 Loop Structure Prediction</b>
<a href="https://arxiv.org/abs/2111.10656">arxiv:2111.10656</a>
&#x1F4C8; 2 <br>
<p>Natalia Zenkova, Ekaterina Sedykh, Tatiana Shugaeva, Vladislav Strashko, Timofei Ermak, Aleksei Shpilman</p></summary>
<p>

**Abstract:** Predicting a structure of an antibody from its sequence is important since it allows for a better design process of synthetic antibodies that play a vital role in the health industry. Most of the structure of an antibody is conservative. The most variable and hard-to-predict part is the {\it third complementarity-determining region of the antibody heavy chain} (CDR H3). Lately, deep learning has been employed to solve the task of CDR H3 prediction. However, current state-of-the-art methods are not end-to-end, but rather they output inter-residue distances and orientations to the RosettaAntibody package that uses this additional information alongside statistical and physics-based methods to predict the 3D structure. This does not allow a fast screening process and, therefore, inhibits the development of targeted synthetic antibodies. In this work, we present an end-to-end model to predict CDR H3 loop structure, that performs on par with state-of-the-art methods in terms of accuracy but an order of magnitude faster. We also raise an issue with a commonly used RosettaAntibody benchmark that leads to data leaks, i.e., the presence of identical sequences in the train and test datasets.

</p>
</details>

<details><summary><b>Implicit Acoustic Echo Cancellation for Keyword Spotting and Device-Directed Speech Detection</b>
<a href="https://arxiv.org/abs/2111.10639">arxiv:2111.10639</a>
&#x1F4C8; 2 <br>
<p>Samuele Cornell, Thomas Balestri, Thibaud Sénéchal</p></summary>
<p>

**Abstract:** In many speech-enabled human-machine interaction scenarios, user speech can overlap with the device playback audio. In these instances, the performance of tasks such as keyword-spotting (KWS) and device-directed speech detection (DDD) can degrade significantly. To address this problem, we propose an implicit acoustic echo cancellation (iAEC) framework where a neural network is trained to exploit the additional information from a reference microphone channel to learn to ignore the interfering signal and improve detection performance. We study this framework for the tasks of KWS and DDD on, respectively, an augmented version of Google Speech Commands v2 and a real-world Alexa device dataset. Notably, we show a $56\%$ reduction in false-reject rate for the DDD task during device playback conditions. We also show comparable or superior performance over a strong end-to-end neural echo cancellation + KWS baseline for the KWS task with an order of magnitude less computational requirements.

</p>
</details>

<details><summary><b>Semi-supervised Impedance Inversion by Bayesian Neural Network Based on 2-d CNN Pre-training</b>
<a href="https://arxiv.org/abs/2111.10596">arxiv:2111.10596</a>
&#x1F4C8; 2 <br>
<p>Muyang Ge, Wenlong Wang, Wangxiangming Zheng</p></summary>
<p>

**Abstract:** Seismic impedance inversion can be performed with a semi-supervised learning algorithm, which only needs a few logs as labels and is less likely to get overfitted. However, classical semi-supervised learning algorithm usually leads to artifacts on the predicted impedance image. In this artical, we improve the semi-supervised learning from two aspects. First, by replacing 1-d convolutional neural network (CNN) layers in deep learning structure with 2-d CNN layers and 2-d maxpooling layers, the prediction accuracy is improved. Second, prediction uncertainty can also be estimated by embedding the network into a Bayesian inference framework. Local reparameterization trick is used during forward propagation of the network to reduce sampling cost. Tests with Marmousi2 model and SEAM model validate the feasibility of the proposed strategy.

</p>
</details>

<details><summary><b>Generating meta-learning tasks to evolve parametric loss for classification learning</b>
<a href="https://arxiv.org/abs/2111.10583">arxiv:2111.10583</a>
&#x1F4C8; 2 <br>
<p>Zhaoyang Hai, Xiabi Liu, Yuchen Ren, Nouman Q. Soomro</p></summary>
<p>

**Abstract:** The field of meta-learning has seen a dramatic rise in interest in recent years. In existing meta-learning approaches, learning tasks for training meta-models are usually collected from public datasets, which brings the difficulty of obtaining a sufficient number of meta-learning tasks with a large amount of training data. In this paper, we propose a meta-learning approach based on randomly generated meta-learning tasks to obtain a parametric loss for classification learning based on big data. The loss is represented by a deep neural network, called meta-loss network (MLN). To train the MLN, we construct a large number of classification learning tasks through randomly generating training data, validation data, and corresponding ground-truth linear classifier. Our approach has two advantages. First, sufficient meta-learning tasks with large number of training data can be obtained easily. Second, the ground-truth classifier is given, so that the difference between the learned classifier and the ground-truth model can be measured to reflect the performance of MLN more precisely than validation accuracy. Based on this difference, we apply the evolutionary strategy algorithm to find out the optimal MLN. The resultant MLN not only leads to satisfactory learning effects on generated linear classifier learning tasks for testing, but also behaves very well on generated nonlinear classifier learning tasks and various public classification tasks. Our MLN stably surpass cross-entropy (CE) and mean square error (MSE) in testing accuracy and generalization ability. These results illustrate the possibility of achieving satisfactory meta-learning effects using generated learning tasks.

</p>
</details>

<details><summary><b>Learning Non-Stationary Time-Series with Dynamic Pattern Extractions</b>
<a href="https://arxiv.org/abs/2111.10559">arxiv:2111.10559</a>
&#x1F4C8; 2 <br>
<p>Xipei Wang, Haoyu Zhang, Yuanbo Zhang, Meng Wang, Jiarui Song, Tin Lai, Matloob Khushi</p></summary>
<p>

**Abstract:** The era of information explosion had prompted the accumulation of a tremendous amount of time-series data, including stationary and non-stationary time-series data. State-of-the-art algorithms have achieved a decent performance in dealing with stationary temporal data. However, traditional algorithms that tackle stationary time-series do not apply to non-stationary series like Forex trading. This paper investigates applicable models that can improve the accuracy of forecasting future trends of non-stationary time-series sequences. In particular, we focus on identifying potential models and investigate the effects of recognizing patterns from historical data. We propose a combination of \rebuttal{the} seq2seq model based on RNN, along with an attention mechanism and an enriched set features extracted via dynamic time warping and zigzag peak valley indicators. Customized loss functions and evaluating metrics have been designed to focus more on the predicting sequence's peaks and valley points. Our results show that our model can predict 4-hour future trends with high accuracy in the Forex dataset, which is crucial in realistic scenarios to assist foreign exchange trading decision making. We further provide evaluations of the effects of various loss functions, evaluation metrics, model variants, and components on model performance.

</p>
</details>

<details><summary><b>Edge-Enhanced Global Disentangled Graph Neural Network for Sequential Recommendation</b>
<a href="https://arxiv.org/abs/2111.10539">arxiv:2111.10539</a>
&#x1F4C8; 2 <br>
<p>Yunyi Li, Pengpeng Zhao, Guanfeng Liu, Yanchi Liu, Victor S. Sheng, Jiajie Xu, Xiaofang Zhou</p></summary>
<p>

**Abstract:** Sequential recommendation has been a widely popular topic of recommender systems. Existing works have contributed to enhancing the prediction ability of sequential recommendation systems based on various methods, such as recurrent networks and self-attention mechanisms. However, they fail to discover and distinguish various relationships between items, which could be underlying factors which motivate user behaviors. In this paper, we propose an Edge-Enhanced Global Disentangled Graph Neural Network (EGD-GNN) model to capture the relation information between items for global item representation and local user intention learning. At the global level, we build a global-link graph over all sequences to model item relationships. Then a channel-aware disentangled learning layer is designed to decompose edge information into different channels, which can be aggregated to represent the target item from its neighbors. At the local level, we apply a variational auto-encoder framework to learn user intention over the current sequence. We evaluate our proposed method on three real-world datasets. Experimental results show that our model can get a crucial improvement over state-of-the-art baselines and is able to distinguish item features.

</p>
</details>

<details><summary><b>Predicting Student's Performance Through Data Mining</b>
<a href="https://arxiv.org/abs/2112.01247">arxiv:2112.01247</a>
&#x1F4C8; 1 <br>
<p>Aaditya Bhusal</p></summary>
<p>

**Abstract:** Predicting the performance of students early and as accurately as possible is one of the biggest challenges of educational institutions. Analyzing the performance of students early can help in finding the strengths and weakness of students and help the perform better in examinations. Using machine learning the student's performance can be predicted with the help of students' data collected from Learning Management Systems (LMS). The data collected from LMSs can provide insights about student's behavior that will result in good or bad performance in examinations which then can be studied and used in helping students performing poorly in examinations to perform better.

</p>
</details>

<details><summary><b>Incentive Mechanisms for Federated Learning: From Economic and Game Theoretic Perspective</b>
<a href="https://arxiv.org/abs/2111.11850">arxiv:2111.11850</a>
&#x1F4C8; 1 <br>
<p>Xuezhen Tu, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Yang Zhang, Juan Li</p></summary>
<p>

**Abstract:** Federated learning (FL) becomes popular and has shown great potentials in training large-scale machine learning (ML) models without exposing the owners' raw data. In FL, the data owners can train ML models based on their local data and only send the model updates rather than raw data to the model owner for aggregation. To improve learning performance in terms of model accuracy and training completion time, it is essential to recruit sufficient participants. Meanwhile, the data owners are rational and may be unwilling to participate in the collaborative learning process due to the resource consumption. To address the issues, there have been various works recently proposed to motivate the data owners to contribute their resources. In this paper, we provide a comprehensive review for the economic and game theoretic approaches proposed in the literature to design various schemes for stimulating data owners to participate in FL training process. In particular, we first present the fundamentals and background of FL, economic theories commonly used in incentive mechanism design. Then, we review applications of game theory and economic approaches applied for incentive mechanisms design of FL. Finally, we highlight some open issues and future research directions concerning incentive mechanism design of FL.

</p>
</details>

<details><summary><b>Learning algorithms versus automatability of Frege systems</b>
<a href="https://arxiv.org/abs/2111.10626">arxiv:2111.10626</a>
&#x1F4C8; 1 <br>
<p>Ján Pich, Rahul Santhanam</p></summary>
<p>

**Abstract:** We connect learning algorithms and algorithms automating proof search in propositional proof systems: for every sufficiently strong, well-behaved propositional proof system $P$, we prove that the following statements are equivalent,
  1. Provable learning: $P$ proves efficiently that p-size circuits are learnable by subexponential-size circuits over the uniform distribution with membership queries.
  2. Provable automatability: $P$ proves efficiently that $P$ is automatable by non-uniform circuits on propositional formulas expressing p-size circuit lower bounds.
  Here, $P$ is sufficiently strong and well-behaved if I.-III. holds: I. $P$ p-simulates Jeřábek's system $WF$ (which strengthens the Extended Frege system $EF$ by a surjective weak pigeonhole principle); II. $P$ satisfies some basic properties of standard proof systems which p-simulate $WF$; III. $P$ proves efficiently for some Boolean function $h$ that $h$ is hard on average for circuits of subexponential size. For example, if III. holds for $P=WF$, then Items 1 and 2 are equivalent for $P=WF$.
  If there is a function $h\in NE\cap coNE$ which is hard on average for circuits of size $2^{n/4}$, for each sufficiently big $n$, then there is an explicit propositional proof system $P$ satisfying properties I.-III., i.e. the equivalence of Items 1 and 2 holds for $P$.

</p>
</details>

<details><summary><b>Vehicular Visible Light Communications Noise Analysis and Autoencoder Based Denoising</b>
<a href="https://arxiv.org/abs/2111.10588">arxiv:2111.10588</a>
&#x1F4C8; 1 <br>
<p>Bugra Turan, O. Nuri Koc, Emrah Kar, Sinem Coleri</p></summary>
<p>

**Abstract:** Vehicular visible light communications (V-VLC) is a promising intelligent transportation systems (ITS) technology for vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications with the utilization of light-emitting diodes (LEDs). The main degrading factor for the performance of V-VLC systems is noise. Unlike traditional radio frequency (RF) based systems, V-VLC systems include many noise sources: solar radiation, background lighting from vehicles, streets, parking garages, and tunnel lights. Traditional V-VLC system noise modeling is based on the additive white Gaussian noise assumption in the form of shot and thermal noise. In this paper, to investigate both time-correlated and white noise components of the V-VLC channel, we propose a noise analysis based on Allan variance (AVAR), which provides a time-series analysis method to identify noise from the data. We also propose a generalized Wiener process-based V-VLC channel noise synthesis methodology to generate different noise components. We further propose a convolutional autoencoder(CAE) based denoising scheme to reduce V-VLC signal noise, which achieves reconstruction root mean square error (RMSE) of 0.0442 and 0.0474 for indoor and outdoor channels, respectively.

</p>
</details>

<details><summary><b>Accelerating non-LTE synthesis and inversions with graph networks</b>
<a href="https://arxiv.org/abs/2111.10552">arxiv:2111.10552</a>
&#x1F4C8; 1 <br>
<p>A. Vicente Arévalo, A. Asensio Ramos, S. Esteban Pozuelo</p></summary>
<p>

**Abstract:** Context: The computational cost of fast non-LTE synthesis is one of the challenges that limits the development of 2D and 3D inversion codes. It also makes the interpretation of observations of lines formed in the chromosphere and transition region a slow and computationally costly process, which limits the inference of the physical properties on rather small fields of view. Having access to a fast way of computing the deviation from the LTE regime through the departure coefficients could largely alleviate this problem. Aims: We propose to build and train a graph network that quickly predicts the atomic level populations without solving the non-LTE problem. Methods: We find an optimal architecture for the graph network for predicting the departure coefficients of the levels of an atom from the physical conditions of a model atmosphere. A suitable dataset with a representative sample of potential model atmospheres is used for training. This dataset has been computed using existing non-LTE synthesis codes. Results: The graph network has been integrated into existing synthesis and inversion codes for the particular case of \caii. We demonstrate orders of magnitude gain in computing speed. We analyze the generalization capabilities of the graph network and demonstrate that it produces good predicted departure coefficients for unseen models. We implement this approach in \hazel\ and show how the inversions nicely compare with those obtained with standard non-LTE inversion codes. Our approximate method opens up the possibility of extracting physical information from the chromosphere on large fields-of-view with time evolution. This allows us to understand better this region of the Sun, where large spatial and temporal scales are crucial.

</p>
</details>


[Next Page](2021/2021-11/2021-11-19.md)
