Prev: [2022.09.25]({{ '/2022/09/25/2022.09.25.html' | relative_url }})  Next: [2022.09.27]({{ '/2022/09/27/2022.09.27.html' | relative_url }})
{% raw %}
## Summary for 2022-09-26, created on 2022-09-30


<details><summary><b>Learning to Learn with Generative Models of Neural Network Checkpoints</b>
<a href="https://arxiv.org/abs/2209.12892">arxiv:2209.12892</a>
&#x1F4C8; 380 <br>
<p>William Peebles, Ilija Radosavovic, Tim Brooks, Alexei A. Efros, Jitendra Malik</p></summary>
<p>

**Abstract:** We explore a data-driven approach for learning to optimize neural networks. We construct a dataset of neural network checkpoints and train a generative model on the parameters. In particular, our model is a conditional diffusion transformer that, given an initial input parameter vector and a prompted loss, error, or return, predicts the distribution over parameter updates that achieve the desired metric. At test time, it can optimize neural networks with unseen parameters for downstream tasks in just one update. We find that our approach successfully generates parameters for a wide range of loss prompts. Moreover, it can sample multimodal parameter solutions and has favorable scaling properties. We apply our method to different neural network architectures and tasks in supervised and reinforcement learning.

</p>
</details>

<details><summary><b>EPIC-KITCHENS VISOR Benchmark: VIdeo Segmentations and Object Relations</b>
<a href="https://arxiv.org/abs/2209.13064">arxiv:2209.13064</a>
&#x1F4C8; 139 <br>
<p>Ahmad Darkhalil, Dandan Shan, Bin Zhu, Jian Ma, Amlan Kar, Richard Higgins, Sanja Fidler, David Fouhey, Dima Damen</p></summary>
<p>

**Abstract:** We introduce VISOR, a new dataset of pixel annotations and a benchmark suite for segmenting hands and active objects in egocentric video. VISOR annotates videos from EPIC-KITCHENS, which comes with a new set of challenges not encountered in current video segmentation datasets. Specifically, we need to ensure both short- and long-term consistency of pixel-level annotations as objects undergo transformative interactions, e.g. an onion is peeled, diced and cooked - where we aim to obtain accurate pixel-level annotations of the peel, onion pieces, chopping board, knife, pan, as well as the acting hands. VISOR introduces an annotation pipeline, AI-powered in parts, for scalability and quality. In total, we publicly release 272K manual semantic masks of 257 object classes, 9.9M interpolated dense masks, 67K hand-object relations, covering 36 hours of 179 untrimmed videos. Along with the annotations, we introduce three challenges in video object segmentation, interaction understanding and long-term reasoning.
  For data, code and leaderboards: http://epic-kitchens.github.io/VISOR

</p>
</details>

<details><summary><b>It Takes Two: Learning to Plan for Human-Robot Cooperative Carrying</b>
<a href="https://arxiv.org/abs/2209.12890">arxiv:2209.12890</a>
&#x1F4C8; 123 <br>
<p>Eley Ng, Ziang Liu, Monroe Kennedy III</p></summary>
<p>

**Abstract:** Collaborative table-carrying is a complex task due to the continuous nature of the action and state-spaces, multimodality of strategies, existence of obstacles in the environment, and the need for instantaneous adaptation to other agents. In this work, we present a method for predicting realistic motion plans for cooperative human-robot teams on a table-carrying task. Using a Variational Recurrent Neural Network, VRNN, to model the variation in the trajectory of a human-robot team over time, we are able to capture the distribution over the team's future states while leveraging information from interaction history. The key to our approach is in our model's ability to leverage human demonstration data and generate trajectories that synergize well with humans during test time. We show that the model generates more human-like motion compared to a baseline, centralized sampling-based planner, Rapidly-exploring Random Trees (RRT). Furthermore, we evaluate the VRNN planner with a human partner and show its ability to both generate more human-like paths and achieve higher task success rate than RRT can while planning with a human. Finally, we demonstrate that a LoCoBot using the VRNN planner can complete the task successfully with a human controlling another LoCoBot.

</p>
</details>

<details><summary><b>Advanced Skills by Learning Locomotion and Local Navigation End-to-End</b>
<a href="https://arxiv.org/abs/2209.12827">arxiv:2209.12827</a>
&#x1F4C8; 41 <br>
<p>Nikita Rudin, David Hoeller, Marko Bjelonic, Marco Hutter</p></summary>
<p>

**Abstract:** The common approach for local navigation on challenging environments with legged robots requires path planning, path following and locomotion, which usually requires a locomotion control policy that accurately tracks a commanded velocity. However, by breaking down the navigation problem into these sub-tasks, we limit the robot's capabilities since the individual tasks do not consider the full solution space. In this work, we propose to solve the complete problem by training an end-to-end policy with deep reinforcement learning. Instead of continuously tracking a precomputed path, the robot needs to reach a target position within a provided time. The task's success is only evaluated at the end of an episode, meaning that the policy does not need to reach the target as fast as possible. It is free to select its path and the locomotion gait. Training a policy in this way opens up a larger set of possible solutions, which allows the robot to learn more complex behaviors. We compare our approach to velocity tracking and additionally show that the time dependence of the task reward is critical to successfully learn these new behaviors. Finally, we demonstrate the successful deployment of policies on a real quadrupedal robot. The robot is able to cross challenging terrains, which were not possible previously, while using a more energy-efficient gait and achieving a higher success rate.

</p>
</details>

<details><summary><b>Dialog Acts for Task-Driven Embodied Agents</b>
<a href="https://arxiv.org/abs/2209.12953">arxiv:2209.12953</a>
&#x1F4C8; 39 <br>
<p>Spandana Gella, Aishwarya Padmakumar, Patrick Lange, Dilek Hakkani-Tur</p></summary>
<p>

**Abstract:** Embodied agents need to be able to interact in natural language understanding task descriptions and asking appropriate follow up questions to obtain necessary information to be effective at successfully accomplishing tasks for a wide range of users. In this work, we propose a set of dialog acts for modelling such dialogs and annotate the TEACh dataset that includes over 3,000 situated, task oriented conversations (consisting of 39.5k utterances in total) with dialog acts. TEACh-DA is one of the first large scale dataset of dialog act annotations for embodied task completion. Furthermore, we demonstrate the use of this annotated dataset in training models for tagging the dialog acts of a given utterance, predicting the dialog act of the next response given a dialog history, and use the dialog acts to guide agent's non-dialog behaviour. In particular, our experiments on the TEACh Execution from Dialog History task where the model predicts the sequence of low level actions to be executed in the environment for embodied task completion, demonstrate that dialog acts can improve end task success rate by up to 2 points compared to the system without dialog acts.

</p>
</details>

<details><summary><b>Multi-Task Adversarial Training Algorithm for Multi-Speaker Neural Text-to-Speech</b>
<a href="https://arxiv.org/abs/2209.12549">arxiv:2209.12549</a>
&#x1F4C8; 16 <br>
<p>Yusuke Nakai, Yuki Saito, Kenta Udagawa, Hiroshi Saruwatari</p></summary>
<p>

**Abstract:** We propose a novel training algorithm for a multi-speaker neural text-to-speech (TTS) model based on multi-task adversarial training. A conventional generative adversarial network (GAN)-based training algorithm significantly improves the quality of synthetic speech by reducing the statistical difference between natural and synthetic speech. However, the algorithm does not guarantee the generalization performance of the trained TTS model in synthesizing voices of unseen speakers who are not included in the training data. Our algorithm alternatively trains two deep neural networks: multi-task discriminator and multi-speaker neural TTS model (i.e., generator of GANs). The discriminator is trained not only to distinguish between natural and synthetic speech but also to verify the speaker of input speech is existent or non-existent (i.e., newly generated by interpolating seen speakers' embedding vectors). Meanwhile, the generator is trained to minimize the weighted sum of the speech reconstruction loss and adversarial loss for fooling the discriminator, which achieves high-quality multi-speaker TTS even if the target speaker is unseen. Experimental evaluation shows that our algorithm improves the quality of synthetic speech better than a conventional GANSpeech algorithm.

</p>
</details>

<details><summary><b>Defining and Characterizing Reward Hacking</b>
<a href="https://arxiv.org/abs/2209.13085">arxiv:2209.13085</a>
&#x1F4C8; 10 <br>
<p>Joar Skalse, Nikolaus H. R. Howe, Dmitrii Krasheninnikov, David Krueger</p></summary>
<p>

**Abstract:** We provide the first formal definition of reward hacking, a phenomenon where optimizing an imperfect proxy reward function, $\mathcal{\tilde{R}}$, leads to poor performance according to the true reward function, $\mathcal{R}$. We say that a proxy is unhackable if increasing the expected proxy return can never decrease the expected true return. Intuitively, it might be possible to create an unhackable proxy by leaving some terms out of the reward function (making it "narrower") or overlooking fine-grained distinctions between roughly equivalent outcomes, but we show this is usually not the case. A key insight is that the linearity of reward (in state-action visit counts) makes unhackability a very strong condition. In particular, for the set of all stochastic policies, two reward functions can only be unhackable if one of them is constant. We thus turn our attention to deterministic policies and finite sets of stochastic policies, where non-trivial unhackable pairs always exist, and establish necessary and sufficient conditions for the existence of simplifications, an important special case of unhackability. Our results reveal a tension between using reward functions to specify narrow tasks and aligning AI systems with human values.

</p>
</details>

<details><summary><b>ImmunoLingo: Linguistics-based formalization of the antibody language</b>
<a href="https://arxiv.org/abs/2209.12635">arxiv:2209.12635</a>
&#x1F4C8; 10 <br>
<p>Mai Ha Vu, Philippe A. Robert, Rahmad Akbar, Bartlomiej Swiatczak, Geir Kjetil Sandve, Dag Trygve Truslew Haug, Victor Greiff</p></summary>
<p>

**Abstract:** Apparent parallels between natural language and biological sequence have led to a recent surge in the application of deep language models (LMs) to the analysis of antibody and other biological sequences. However, a lack of a rigorous linguistic formalization of biological sequence languages, which would define basic components, such as lexicon (i.e., the discrete units of the language) and grammar (i.e., the rules that link sequence well-formedness, structure, and meaning) has led to largely domain-unspecific applications of LMs, which do not take into account the underlying structure of the biological sequences studied. A linguistic formalization, on the other hand, establishes linguistically-informed and thus domain-adapted components for LM applications. It would facilitate a better understanding of how differences and similarities between natural language and biological sequences influence the quality of LMs, which is crucial for the design of interpretable models with extractable sequence-functions relationship rules, such as the ones underlying the antibody specificity prediction problem. Deciphering the rules of antibody specificity is crucial to accelerating rational and in silico biotherapeutic drug design. Here, we formalize the properties of the antibody language and thereby establish not only a foundation for the application of linguistic tools in adaptive immune receptor analysis but also for the systematic immunolinguistic studies of immune receptor specificity in general.

</p>
</details>

<details><summary><b>A connection between probability, physics and neural networks</b>
<a href="https://arxiv.org/abs/2209.12737">arxiv:2209.12737</a>
&#x1F4C8; 8 <br>
<p>Sascha Ranftl</p></summary>
<p>

**Abstract:** We illustrate an approach that can be exploited for constructing neural networks which a priori obey physical laws. We start with a simple single-layer neural network (NN) but refrain from choosing the activation functions yet. Under certain conditions and in the infinite-width limit, we may apply the central limit theorem, upon which the NN output becomes Gaussian. We may then investigate and manipulate the limit network by falling back on Gaussian process (GP) theory. It is observed that linear operators acting upon a GP again yield a GP. This also holds true for differential operators defining differential equations and describing physical laws. If we demand the GP, or equivalently the limit network, to obey the physical law, then this yields an equation for the covariance function or kernel of the GP, whose solution equivalently constrains the model to obey the physical law. The central limit theorem then suggests that NNs can be constructed to obey a physical law by choosing the activation functions such that they match a particular kernel in the infinite-width limit. The activation functions constructed in this way guarantee the NN to a priori obey the physics, up to the approximation error of non-infinite network width. Simple examples of the homogeneous 1D-Helmholtz equation are discussed and compared to naive kernels and activations.

</p>
</details>

<details><summary><b>LOViS: Learning Orientation and Visual Signals for Vision and Language Navigation</b>
<a href="https://arxiv.org/abs/2209.12723">arxiv:2209.12723</a>
&#x1F4C8; 8 <br>
<p>Yue Zhang, Parisa Kordjamshidi</p></summary>
<p>

**Abstract:** Understanding spatial and visual information is essential for a navigation agent who follows natural language instructions. The current Transformer-based VLN agents entangle the orientation and vision information, which limits the gain from the learning of each information source. In this paper, we design a neural agent with explicit Orientation and Vision modules. Those modules learn to ground spatial information and landmark mentions in the instructions to the visual environment more effectively. To strengthen the spatial reasoning and visual perception of the agent, we design specific pre-training tasks to feed and better utilize the corresponding modules in our final navigation model. We evaluate our approach on both Room2room (R2R) and Room4room (R4R) datasets and achieve the state of the art results on both benchmarks.

</p>
</details>

<details><summary><b>Liquid Structural State-Space Models</b>
<a href="https://arxiv.org/abs/2209.12951">arxiv:2209.12951</a>
&#x1F4C8; 7 <br>
<p>Ramin Hasani, Mathias Lechner, Tsun-Hsuan Wang, Makram Chahine, Alexander Amini, Daniela Rus</p></summary>
<p>

**Abstract:** A proper parametrization of state transition matrices of linear state-space models (SSMs) followed by standard nonlinearities enables them to efficiently learn representations from sequential data, establishing the state-of-the-art on a large series of long-range sequence modeling benchmarks. In this paper, we show that we can improve further when the structural SSM such as S4 is given by a linear liquid time-constant (LTC) state-space model. LTC neural networks are causal continuous-time neural networks with an input-dependent state transition module, which makes them learn to adapt to incoming inputs at inference. We show that by using a diagonal plus low-rank decomposition of the state transition matrix introduced in S4, and a few simplifications, the LTC-based structural state-space model, dubbed Liquid-S4, achieves the new state-of-the-art generalization across sequence modeling tasks with long-term dependencies such as image, text, audio, and medical time-series, with an average performance of 87.32% on the Long-Range Arena benchmark. On the full raw Speech Command recognition, dataset Liquid-S4 achieves 96.78% accuracy with a 30% reduction in parameter counts compared to S4. The additional gain in performance is the direct result of the Liquid-S4's kernel structure that takes into account the similarities of the input sequence samples during training and inference.

</p>
</details>

<details><summary><b>Self-supervised Denoising via Low-rank Tensor Approximated Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2209.12715">arxiv:2209.12715</a>
&#x1F4C8; 7 <br>
<p>Chenyin Gao, Shu Yang, Anru R. Zhang</p></summary>
<p>

**Abstract:** Noise is ubiquitous during image acquisition. Sufficient denoising is often an important first step for image processing. In recent decades, deep neural networks (DNNs) have been widely used for image denoising. Most DNN-based image denoising methods require a large-scale dataset or focus on supervised settings, in which single/pairs of clean images or a set of noisy images are required. This poses a significant burden on the image acquisition process. Moreover, denoisers trained on datasets of limited scale may incur over-fitting. To mitigate these issues, we introduce a new self-supervised framework for image denoising based on the Tucker low-rank tensor approximation. With the proposed design, we are able to characterize our denoiser with fewer parameters and train it based on a single image, which considerably improves the model generalizability and reduces the cost of data acquisition. Extensive experiments on both synthetic and real-world noisy images have been conducted. Empirical results show that our proposed method outperforms existing non-learning-based methods (e.g., low-pass filter, non-local mean), single-image unsupervised denoisers (e.g., DIP, NN+BM3D) evaluated on both in-sample and out-sample datasets. The proposed method even achieves comparable performances with some supervised methods (e.g., DnCNN).

</p>
</details>

<details><summary><b>The Ability of Self-Supervised Speech Models for Audio Representations</b>
<a href="https://arxiv.org/abs/2209.12900">arxiv:2209.12900</a>
&#x1F4C8; 6 <br>
<p>Tung-Yu Wu, Chen-An Li, Tzu-Han Lin, Tsu-Yuan Hsu, Hung-Yi Lee</p></summary>
<p>

**Abstract:** Self-supervised learning (SSL) speech models have achieved unprecedented success in speech representation learning, but some questions regarding their representation ability remain unanswered. This paper addresses two of them: (1) Can SSL speech models deal with non-speech audio?; (2) Would different SSL speech models have insights into diverse aspects of audio features? To answer the two questions, we conduct extensive experiments on abundant speech and non-speech audio datasets to evaluate the representation ability of currently state-of-the-art SSL speech models, which are wav2vec 2.0 and HuBERT in this paper. These experiments are carried out during NeurIPS 2021 HEAR Challenge as a standard evaluation pipeline provided by competition officials. Results show that (1) SSL speech models could extract meaningful features of a wide range of non-speech audio, while they may also fail on certain types of datasets; (2) different SSL speech models have insights into different aspects of audio features. The two conclusions provide a foundation for the ensemble of representation models. We further propose an ensemble framework to fuse speech representation models' embeddings. Our framework outperforms state-of-the-art SSL speech/audio models and has generally superior performance on abundant datasets compared with other teams in HEAR Challenge. Our code is available at https://github.com/tony10101105/HEAR-2021-NeurIPS-Challenge -- NTU-GURA.

</p>
</details>

<details><summary><b>Out-of-Distribution Detection with Hilbert-Schmidt Independence Optimization</b>
<a href="https://arxiv.org/abs/2209.12807">arxiv:2209.12807</a>
&#x1F4C8; 6 <br>
<p>Jingyang Lin, Yu Wang, Qi Cai, Yingwei Pan, Ting Yao, Hongyang Chao, Tao Mei</p></summary>
<p>

**Abstract:** Outlier detection tasks have been playing a critical role in AI safety. There has been a great challenge to deal with this task. Observations show that deep neural network classifiers usually tend to incorrectly classify out-of-distribution (OOD) inputs into in-distribution classes with high confidence. Existing works attempt to solve the problem by explicitly imposing uncertainty on classifiers when OOD inputs are exposed to the classifier during training. In this paper, we propose an alternative probabilistic paradigm that is both practically useful and theoretically viable for the OOD detection tasks. Particularly, we impose statistical independence between inlier and outlier data during training, in order to ensure that inlier data reveals little information about OOD data to the deep estimator during training. Specifically, we estimate the statistical dependence between inlier and outlier data through the Hilbert-Schmidt Independence Criterion (HSIC), and we penalize such metric during training. We also associate our approach with a novel statistical test during the inference time coupled with our principled motivation. Empirical results show that our method is effective and robust for OOD detection on various benchmarks. In comparison to SOTA models, our approach achieves significant improvement regarding FPR95, AUROC, and AUPR metrics. Code is available: \url{https://github.com/jylins/hood}.

</p>
</details>

<details><summary><b>Learning GFlowNets from partial episodes for improved convergence and stability</b>
<a href="https://arxiv.org/abs/2209.12782">arxiv:2209.12782</a>
&#x1F4C8; 6 <br>
<p>Kanika Madan, Jarrid Rector-Brooks, Maksym Korablyov, Emmanuel Bengio, Moksh Jain, Andrei Nica, Tom Bosc, Yoshua Bengio, Nikolay Malkin</p></summary>
<p>

**Abstract:** Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($λ$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($λ$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($λ$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was possible before. We also perform a comparative analysis of stochastic gradient dynamics, shedding light on the bias-variance tradeoff in GFlowNet training and the advantages of subtrajectory balance.

</p>
</details>

<details><summary><b>LSAP: Rethinking Inversion Fidelity, Perception and Editability in GAN Latent Space</b>
<a href="https://arxiv.org/abs/2209.12746">arxiv:2209.12746</a>
&#x1F4C8; 6 <br>
<p>Cao Pu, Lu Yang, Dongxv Liu, Zhiwei Liu, Wenguan Wang, Shan Li, Qing Song</p></summary>
<p>

**Abstract:** As the methods evolve, inversion is mainly divided into two steps. The first step is Image Embedding, in which an encoder or optimization process embeds images to get the corresponding latent codes. Afterward, the second step aims to refine the inversion and editing results, which we named Result Refinement. Although the second step significantly improves fidelity, perception and editability are almost unchanged, deeply dependent on inverse latent codes attained in the first step. Therefore, a crucial problem is gaining the latent codes with better perception and editability while retaining the reconstruction fidelity. In this work, we first point out that these two characteristics are related to the degree of alignment (or disalignment) of the inverse codes with the synthetic distribution. Then, we propose Latent Space Alignment Inversion Paradigm (LSAP), which consists of evaluation metric and solution for this problem. Specifically, we introduce Normalized Style Space ($\mathcal{S^N}$ space) and $\mathcal{S^N}$ Cosine Distance (SNCD) to measure disalignment of inversion methods. Since our proposed SNCD is differentiable, it can be optimized in both encoder-based and optimization-based embedding methods to conduct a uniform solution. Extensive experiments in various domains demonstrate that SNCD effectively reflects perception and editability, and our alignment paradigm archives the state-of-the-art in both two steps. Code is available on https://github.com/caopulan/GANInverter.

</p>
</details>

<details><summary><b>Towards Multimodal Multitask Scene Understanding Models for Indoor Mobile Agents</b>
<a href="https://arxiv.org/abs/2209.13156">arxiv:2209.13156</a>
&#x1F4C8; 5 <br>
<p>Yao-Hung Hubert Tsai, Hanlin Goh, Ali Farhadi, Jian Zhang</p></summary>
<p>

**Abstract:** The perception system in personalized mobile agents requires developing indoor scene understanding models, which can understand 3D geometries, capture objectiveness, analyze human behaviors, etc. Nonetheless, this direction has not been well-explored in comparison with models for outdoor environments (e.g., the autonomous driving system that includes pedestrian prediction, car detection, traffic sign recognition, etc.). In this paper, we first discuss the main challenge: insufficient, or even no, labeled data for real-world indoor environments, and other challenges such as fusion between heterogeneous sources of information (e.g., RGB images and Lidar point clouds), modeling relationships between a diverse set of outputs (e.g., 3D object locations, depth estimation, and human poses), and computational efficiency. Then, we describe MMISM (Multi-modality input Multi-task output Indoor Scene understanding Model) to tackle the above challenges. MMISM considers RGB images as well as sparse Lidar points as inputs and 3D object detection, depth completion, human pose estimation, and semantic segmentation as output tasks. We show that MMISM performs on par or even better than single-task models; e.g., we improve the baseline 3D object detection results by 11.7% on the benchmark ARKitScenes dataset.

</p>
</details>

<details><summary><b>Automatic Identification and Classification of Share Buybacks and their Effect on Short-, Mid- and Long-Term Returns</b>
<a href="https://arxiv.org/abs/2209.12863">arxiv:2209.12863</a>
&#x1F4C8; 5 <br>
<p>Thilo Reintjes</p></summary>
<p>

**Abstract:** This thesis investigates share buybacks, specifically share buyback announcements. It addresses how to recognize such announcements, the excess return of share buybacks, and the prediction of returns after a share buyback announcement. We illustrate two NLP approaches for the automated detection of share buyback announcements. Even with very small amounts of training data, we can achieve an accuracy of up to 90%. This thesis utilizes these NLP methods to generate a large dataset consisting of 57,155 share buyback announcements. By analyzing this dataset, this thesis aims to show that most companies, which have a share buyback announced are underperforming the MSCI World. A minority of companies, however, significantly outperform the MSCI World. This significant overperformance leads to a net gain when looking at the averages of all companies. If the benchmark index is adjusted for the respective size of the companies, the average overperformance disappears, and the majority underperforms even greater. However, it was found that companies that announce a share buyback with a volume of at least 1% of their market cap, deliver, on average, a significant overperformance, even when using an adjusted benchmark. It was also found that companies that announce share buybacks in times of crisis emerge better than the overall market. Additionally, the generated dataset was used to train 72 machine learning models. Through this, it was able to find many strategies that could achieve an accuracy of up to 77% and generate great excess returns. A variety of performance indicators could be improved across six different time frames and a significant overperformance was identified. This was achieved by training several models for different tasks and time frames as well as combining these different models, generating significant improvement by fusing weak learners, in order to create one strong learner.

</p>
</details>

<details><summary><b>AirTrack: Onboard Deep Learning Framework for Long-Range Aircraft Detection and Tracking</b>
<a href="https://arxiv.org/abs/2209.12849">arxiv:2209.12849</a>
&#x1F4C8; 5 <br>
<p>Sourish Ghosh, Jay Patrikar, Brady Moon, Milad Moghassem Hamidi, and Sebastian Scherer</p></summary>
<p>

**Abstract:** Detect-and-Avoid (DAA) capabilities are critical for safe operations of unmanned aircraft systems (UAS). This paper introduces, AirTrack, a real-time vision-only detect and tracking framework that respects the size, weight, and power (SWaP) constraints of sUAS systems. Given the low Signal-to-Noise ratios (SNR) of far away aircraft, we propose using full resolution images in a deep learning framework that aligns successive images to remove ego-motion. The aligned images are then used downstream in cascaded primary and secondary classifiers to improve detection and tracking performance on multiple metrics. We show that AirTrack outperforms state-of-the art baselines on the Amazon Airborne Object Tracking (AOT) Dataset. Multiple real world flight tests with a Cessna 172 interacting with general aviation traffic and additional near-collision flight tests with a Bell helicopter flying towards a UAS in a controlled setting showcase that the proposed approach satisfies the newly introduced ASTM F3442/F3442M standard for DAA. Empirical evaluations show that our system has a probability of track of more than 95% up to a range of 700m. Video available at https://youtu.be/H3lL_Wjxjpw .

</p>
</details>

<details><summary><b>ComplexWoundDB: A Database for Automatic Complex Wound Tissue Categorization</b>
<a href="https://arxiv.org/abs/2209.12822">arxiv:2209.12822</a>
&#x1F4C8; 5 <br>
<p>Talita A. Pereira, Regina C. Popim, Leandro A. Passos, Danillo R. Pereira, Clayton R. Pereira, João P. Papa</p></summary>
<p>

**Abstract:** Complex wounds usually face partial or total loss of skin thickness, healing by secondary intention. They can be acute or chronic, figuring infections, ischemia and tissue necrosis, and association with systemic diseases. Research institutes around the globe report countless cases, ending up in a severe public health problem, for they involve human resources (e.g., physicians and health care professionals) and negatively impact life quality. This paper presents a new database for automatically categorizing complex wounds with five categories, i.e., non-wound area, granulation, fibrinoid tissue, and dry necrosis, hematoma. The images comprise different scenarios with complex wounds caused by pressure, vascular ulcers, diabetes, burn, and complications after surgical interventions. The dataset, called ComplexWoundDB, is unique because it figures pixel-level classifications from $27$ images obtained in the wild, i.e., images are collected at the patients' homes, labeled by four health professionals. Further experiments with distinct machine learning techniques evidence the challenges in addressing the problem of computer-aided complex wound tissue categorization. The manuscript sheds light on future directions in the area, with a detailed comparison among other databased widely used in the literature.

</p>
</details>

<details><summary><b>Shrinking unit: a Graph Convolution-Based Unit for CNN-like 3D Point Cloud Feature Extractors</b>
<a href="https://arxiv.org/abs/2209.12770">arxiv:2209.12770</a>
&#x1F4C8; 5 <br>
<p>Alberto Tamajo, Bastian Plaß, Thomas Klauer</p></summary>
<p>

**Abstract:** 3D point clouds have attracted increasing attention in architecture, engineering, and construction due to their high-quality object representation and efficient acquisition methods. Consequently, many point cloud feature detection methods have been proposed in the literature to automate some workflows, such as their classification or part segmentation. Nevertheless, the performance of point cloud automated systems significantly lags behind their image counterparts. While part of this failure stems from the irregularity, unstructuredness, and disorder of point clouds, which makes the task of point cloud feature detection significantly more challenging than the image one, we argue that a lack of inspiration from the image domain might be the primary cause of such a gap. Indeed, given the overwhelming success of Convolutional Neural Networks (CNNs) in image feature detection, it seems reasonable to design their point cloud counterparts, but none of the proposed approaches closely resembles them. Specifically, even though many approaches generalise the convolution operation in point clouds, they fail to emulate the CNNs multiple-feature detection and pooling operations. For this reason, we propose a graph convolution-based unit, dubbed Shrinking unit, that can be stacked vertically and horizontally for the design of CNN-like 3D point cloud feature extractors. Given that self, local and global correlations between points in a point cloud convey crucial spatial geometric information, we also leverage them during the feature extraction process. We evaluate our proposal by designing a feature extractor model for the ModelNet-10 benchmark dataset and achieve 90.64% classification accuracy, demonstrating that our innovative idea is effective. Our code is available at github.com/albertotamajo/Shrinking-unit.

</p>
</details>

<details><summary><b>DeepFusion: A Robust and Modular 3D Object Detector for Lidars, Cameras and Radars</b>
<a href="https://arxiv.org/abs/2209.12729">arxiv:2209.12729</a>
&#x1F4C8; 5 <br>
<p>Florian Drews, Di Feng, Florian Faion, Lars Rosenbaum, Michael Ulrich, Claudius Gläser</p></summary>
<p>

**Abstract:** We propose DeepFusion, a modular multi-modal architecture to fuse lidars, cameras and radars in different combinations for 3D object detection. Specialized feature extractors take advantage of each modality and can be exchanged easily, making the approach simple and flexible. Extracted features are transformed into bird's-eye-view as a common representation for fusion. Spatial and semantic alignment is performed prior to fusing modalities in the feature space. Finally, a detection head exploits rich multi-modal features for improved 3D detection performance. Experimental results for lidar-camera, lidar-camera-radar and camera-radar fusion show the flexibility and effectiveness of our fusion approach. In the process, we study the largely unexplored task of faraway car detection up to 225 meters, showing the benefits of our lidar-camera fusion. Furthermore, we investigate the required density of lidar points for 3D object detection and illustrate implications at the example of robustness against adverse weather conditions. Moreover, ablation studies on our camera-radar fusion highlight the importance of accurate depth estimation.

</p>
</details>

<details><summary><b>Prayatul Matrix: A Direct Comparison Approach to Evaluate Performance of Supervised Machine Learning Models</b>
<a href="https://arxiv.org/abs/2209.12728">arxiv:2209.12728</a>
&#x1F4C8; 5 <br>
<p>Anupam Biswas</p></summary>
<p>

**Abstract:** Performance comparison of supervised machine learning (ML) models are widely done in terms of different confusion matrix based scores obtained on test datasets. However, a dataset comprises several instances having different difficulty levels. Therefore, it is more logical to compare effectiveness of ML models on individual instances instead of comparing scores obtained for the entire dataset. In this paper, an alternative approach is proposed for direct comparison of supervised ML models in terms of individual instances within the dataset. A direct comparison matrix called \emph{Prayatul Matrix} is introduced, which accounts for comparative outcome of two ML algorithms on different instances of a dataset. Five different performance measures are designed based on prayatul matrix. Efficacy of the proposed approach as well as designed measures is analyzed with four classification techniques on three datasets. Also analyzed on four large-scale complex image datasets with four deep learning models namely ResNet50V2, MobileNetV2, EfficientNet, and XceptionNet. Results are evident that the newly designed measure are capable of giving more insight about the comparing ML algorithms, which were impossible with existing confusion matrix based scores like accuracy, precision and recall.

</p>
</details>

<details><summary><b>Exploring Attention GAN for Vehicle Motion Prediction</b>
<a href="https://arxiv.org/abs/2209.12674">arxiv:2209.12674</a>
&#x1F4C8; 5 <br>
<p>Carlos Gómez-Huélamo, Marcos V. Conde, Miguel Ortiz, Santiago Montiel, Rafael Barea, Luis M. Bergasa</p></summary>
<p>

**Abstract:** The design of a safe and reliable Autonomous Driving stack (ADS) is one of the most challenging tasks of our era. These ADS are expected to be driven in highly dynamic environments with full autonomy, and a reliability greater than human beings. In that sense, to efficiently and safely navigate through arbitrarily complex traffic scenarios, ADS must have the ability to forecast the future trajectories of surrounding actors. Current state-of-the-art models are typically based on Recurrent, Graph and Convolutional networks, achieving noticeable results in the context of vehicle prediction. In this paper we explore the influence of attention in generative models for motion prediction, considering both physical and social context to compute the most plausible trajectories. We first encode the past trajectories using a LSTM network, which serves as input to a Multi-Head Self-Attention module that computes the social context. On the other hand, we formulate a weighted interpolation to calculate the velocity and orientation in the last observation frame in order to calculate acceptable target points, extracted from the driveable of the HDMap information, which represents our physical context. Finally, the input of our generator is a white noise vector sampled from a multivariate normal distribution while the social and physical context are its conditions, in order to predict plausible trajectories. We validate our method using the Argoverse Motion Forecasting Benchmark 1.1, achieving competitive unimodal results.

</p>
</details>

<details><summary><b>Speech Forensics: Blind Voice Mimicry Detection</b>
<a href="https://arxiv.org/abs/2209.12573">arxiv:2209.12573</a>
&#x1F4C8; 5 <br>
<p>Sahar Al Ajmi, Khizar Hayat, Alaa M. Al Obaidi, Naresh Kumar, Munaf Najmuldeen, Baptiste Magnier</p></summary>
<p>

**Abstract:** Audio is one of the most used way of human communication, but at the same time it can be easily misused by to trick people. With the revolution of AI, the related technologies are now accessible to almost everyone thus making it simple for the criminals to commit crimes and forgeries. In this work, we introduce a deep learning method to develop a classifier that will blindly classify an input audio as real or mimicked. The proposed model was trained on a set of important features extracted from a large dataset of audios to get a classifier that was tested on the same set of features from different audios. Two datasets were created for this work; an all English data set and a mixed data set (Arabic and English). These datasets have been made available through GitHub for the use of the research community at https://github.com/SaSs7/Dataset. For the purpose of comparison, the audios were also classified through human inspection with the subjects being the native speakers. The ensued results were interesting and exhibited formidable accuracy.

</p>
</details>

<details><summary><b>Towards Simple and Efficient Task-Adaptive Pre-training for Text Classification</b>
<a href="https://arxiv.org/abs/2209.12943">arxiv:2209.12943</a>
&#x1F4C8; 4 <br>
<p>Arnav Ladkat, Aamir Miyajiwala, Samiksha Jagadale, Rekha Kulkarni, Raviraj Joshi</p></summary>
<p>

**Abstract:** Language models are pre-trained using large corpora of generic data like book corpus, common crawl and Wikipedia, which is essential for the model to understand the linguistic characteristics of the language. New studies suggest using Domain Adaptive Pre-training (DAPT) and Task-Adaptive Pre-training (TAPT) as an intermediate step before the final finetuning task. This step helps cover the target domain vocabulary and improves the model performance on the downstream task. In this work, we study the impact of training only the embedding layer on the model's performance during TAPT and task-specific finetuning. Based on our study, we propose a simple approach to make the intermediate step of TAPT for BERT-based models more efficient by performing selective pre-training of BERT layers. We show that training only the BERT embedding layer during TAPT is sufficient to adapt to the vocabulary of the target domain and achieve comparable performance. Our approach is computationally efficient, with 78\% fewer parameters trained during TAPT. The proposed embedding layer finetuning approach can also be an efficient domain adaptation technique.

</p>
</details>

<details><summary><b>ERASE-Net: Efficient Segmentation Networks for Automotive Radar Signals</b>
<a href="https://arxiv.org/abs/2209.12940">arxiv:2209.12940</a>
&#x1F4C8; 4 <br>
<p>Shihong Fang, Haoran Zhu, Devansh Bisla, Anna Choromanska, Satish Ravindran, Dongyin Ren, Ryan Wu</p></summary>
<p>

**Abstract:** Among various sensors for assisted and autonomous driving systems, automotive radar has been considered as a robust and low-cost solution even in adverse weather or lighting conditions. With the recent development of radar technologies and open-sourced annotated data sets, semantic segmentation with radar signals has become very promising. However, existing methods are either computationally expensive or discard significant amounts of valuable information from raw 3D radar signals by reducing them to 2D planes via averaging. In this work, we introduce ERASE-Net, an Efficient RAdar SEgmentation Network to segment the raw radar signals semantically. The core of our approach is the novel detect-then-segment method for raw radar signals. It first detects the center point of each object, then extracts a compact radar signal representation, and finally performs semantic segmentation. We show that our method can achieve superior performance on radar semantic segmentation task compared to the state-of-the-art (SOTA) technique. Furthermore, our approach requires up to 20x less computational resources. Finally, we show that the proposed ERASE-Net can be compressed by 40% without significant loss in performance, significantly more than the SOTA network, which makes it a more promising candidate for practical automotive applications.

</p>
</details>

<details><summary><b>Multi-encoder attention-based architectures for sound recognition with partial visual assistance</b>
<a href="https://arxiv.org/abs/2209.12826">arxiv:2209.12826</a>
&#x1F4C8; 4 <br>
<p>Wim Boes, Hugo Van hamme</p></summary>
<p>

**Abstract:** Large-scale sound recognition data sets typically consist of acoustic recordings obtained from multimedia libraries. As a consequence, modalities other than audio can often be exploited to improve the outputs of models designed for associated tasks. Frequently, however, not all contents are available for all samples of such a collection: For example, the original material may have been removed from the source platform at some point, and therefore, non-auditory features can no longer be acquired.
  We demonstrate that a multi-encoder framework can be employed to deal with this issue by applying this method to attention-based deep learning systems, which are currently part of the state of the art in the domain of sound recognition. More specifically, we show that the proposed model extension can successfully be utilized to incorporate partially available visual information into the operational procedures of such networks, which normally only use auditory features during training and inference. Experimentally, we verify that the considered approach leads to improved predictions in a number of evaluation scenarios pertaining to audio tagging and sound event detection. Additionally, we scrutinize some properties and limitations of the presented technique.

</p>
</details>

<details><summary><b>Material Prediction for Design Automation Using Graph Representation Learning</b>
<a href="https://arxiv.org/abs/2209.12793">arxiv:2209.12793</a>
&#x1F4C8; 4 <br>
<p>Shijie Bian, Daniele Grandi, Kaveh Hassani, Elliot Sadler, Bodia Borijin, Axel Fernandes, Andrew Wang, Thomas Lu, Richard Otis, Nhut Ho, Bingbing Li</p></summary>
<p>

**Abstract:** Successful material selection is critical in designing and manufacturing products for design automation. Designers leverage their knowledge and experience to create high-quality designs by selecting the most appropriate materials through performance, manufacturability, and sustainability evaluation. Intelligent tools can help designers with varying expertise by providing recommendations learned from prior designs. To enable this, we introduce a graph representation learning framework that supports the material prediction of bodies in assemblies. We formulate the material selection task as a node-level prediction task over the assembly graph representation of CAD models and tackle it using Graph Neural Networks (GNNs). Evaluations over three experimental protocols performed on the Fusion 360 Gallery dataset indicate the feasibility of our approach, achieving a 0.75 top-3 micro-f1 score. The proposed framework can scale to large datasets and incorporate designers' knowledge into the learning process. These capabilities allow the framework to serve as a recommendation system for design automation and a baseline for future work, narrowing the gap between human designers and intelligent design agents.

</p>
</details>

<details><summary><b>Hamiltonian Monte Carlo for efficient Gaussian sampling: long and random steps</b>
<a href="https://arxiv.org/abs/2209.12771">arxiv:2209.12771</a>
&#x1F4C8; 4 <br>
<p>Simon Apers, Sander Gribling, Dániel Szilágyi</p></summary>
<p>

**Abstract:** Hamiltonian Monte Carlo (HMC) is a Markov chain algorithm for sampling from a high-dimensional distribution with density $e^{-f(x)}$, given access to the gradient of $f$. A particular case of interest is that of a $d$-dimensional Gaussian distribution with covariance matrix $Σ$, in which case $f(x) = x^\top Σ^{-1} x$. We show that HMC can sample from a distribution that is $\varepsilon$-close in total variation distance using $\widetilde{O}(\sqrtκ d^{1/4} \log(1/\varepsilon))$ gradient queries, where $κ$ is the condition number of $Σ$. Our algorithm uses long and random integration times for the Hamiltonian dynamics. This contrasts with (and was motivated by) recent results that give an $\widetildeΩ(κd^{1/2})$ query lower bound for HMC with fixed integration times, even for the Gaussian case.

</p>
</details>

<details><summary><b>Multi-modal Video Chapter Generation</b>
<a href="https://arxiv.org/abs/2209.12694">arxiv:2209.12694</a>
&#x1F4C8; 4 <br>
<p>Xiao Cao, Zitan Chen, Canyu Le, Lei Meng</p></summary>
<p>

**Abstract:** Chapter generation becomes practical technique for online videos nowadays. The chapter breakpoints enable users to quickly find the parts they want and get the summative annotations. However, there is no public method and dataset for this task. To facilitate the research along this direction, we introduce a new dataset called Chapter-Gen, which consists of approximately 10k user-generated videos with annotated chapter information. Our data collection procedure is fast, scalable and does not require any additional manual annotation. On top of this dataset, we design an effective baseline specificlly for video chapters generation task. which captures two aspects of a video,including visual dynamics and narration text. It disentangles local and global video features for localization and title generation respectively. To parse the long video efficiently, a skip sliding window mechanism is designed to localize potential chapters. And a cross attention multi-modal fusion module is developed to aggregate local features for title generation. Our experiments demonstrate that the proposed framework achieves superior results over existing methods which illustrate that the method design for similar task cannot be transfered directly even after fine-tuning. Code and dataset are available at https://github.com/czt117/MVCG.

</p>
</details>

<details><summary><b>MaxMatch: Semi-Supervised Learning with Worst-Case Consistency</b>
<a href="https://arxiv.org/abs/2209.12611">arxiv:2209.12611</a>
&#x1F4C8; 4 <br>
<p>Yangbangyan Jiang, Xiaodan Li, Yuefeng Chen, Yuan He, Qianqian Xu, Zhiyong Yang, Xiaochun Cao, Qingming Huang</p></summary>
<p>

**Abstract:** In recent years, great progress has been made to incorporate unlabeled data to overcome the inefficiently supervised problem via semi-supervised learning (SSL). Most state-of-the-art models are based on the idea of pursuing consistent model predictions over unlabeled data toward the input noise, which is called consistency regularization. Nonetheless, there is a lack of theoretical insights into the reason behind its success. To bridge the gap between theoretical and practical results, we propose a worst-case consistency regularization technique for SSL in this paper. Specifically, we first present a generalization bound for SSL consisting of the empirical loss terms observed on labeled and unlabeled training data separately. Motivated by this bound, we derive an SSL objective that minimizes the largest inconsistency between an original unlabeled sample and its multiple augmented variants. We then provide a simple but effective algorithm to solve the proposed minimax problem, and theoretically prove that it converges to a stationary point. Experiments on five popular benchmark datasets validate the effectiveness of our proposed method.

</p>
</details>

<details><summary><b>Deep Manifold Hashing: A Divide-and-Conquer Approach for Semi-Paired Unsupervised Cross-Modal Retrieval</b>
<a href="https://arxiv.org/abs/2209.12599">arxiv:2209.12599</a>
&#x1F4C8; 4 <br>
<p>Yufeng Shi, Xinge You, Jiamiao Xu, Feng Zheng, Qinmu Peng, Weihua Ou</p></summary>
<p>

**Abstract:** Hashing that projects data into binary codes has shown extraordinary talents in cross-modal retrieval due to its low storage usage and high query speed. Despite their empirical success on some scenarios, existing cross-modal hashing methods usually fail to cross modality gap when fully-paired data with plenty of labeled information is nonexistent. To circumvent this drawback, motivated by the Divide-and-Conquer strategy, we propose Deep Manifold Hashing (DMH), a novel method of dividing the problem of semi-paired unsupervised cross-modal retrieval into three sub-problems and building one simple yet efficiency model for each sub-problem. Specifically, the first model is constructed for obtaining modality-invariant features by complementing semi-paired data based on manifold learning, whereas the second model and the third model aim to learn hash codes and hash functions respectively. Extensive experiments on three benchmarks demonstrate the superiority of our DMH compared with the state-of-the-art fully-paired and semi-paired unsupervised cross-modal hashing methods.

</p>
</details>

<details><summary><b>Improving Document Image Understanding with Reinforcement Finetuning</b>
<a href="https://arxiv.org/abs/2209.12561">arxiv:2209.12561</a>
&#x1F4C8; 4 <br>
<p>Bao-Sinh Nguyen, Dung Tien Le, Hieu M. Vu, Tuan Anh D. Nguyen, Minh-Tien Nguyen, Hung Le</p></summary>
<p>

**Abstract:** Successful Artificial Intelligence systems often require numerous labeled data to extract information from document images. In this paper, we investigate the problem of improving the performance of Artificial Intelligence systems in understanding document images, especially in cases where training data is limited. We address the problem by proposing a novel finetuning method using reinforcement learning. Our approach treats the Information Extraction model as a policy network and uses policy gradient training to update the model to maximize combined reward functions that complement the traditional cross-entropy losses. Our experiments on four datasets using labels and expert feedback demonstrate that our finetuning mechanism consistently improves the performance of a state-of-the-art information extractor, especially in the small training data regime.

</p>
</details>

<details><summary><b>Improving Multi-fidelity Optimization with a Recurring Learning Rate for Hyperparameter Tuning</b>
<a href="https://arxiv.org/abs/2209.12499">arxiv:2209.12499</a>
&#x1F4C8; 4 <br>
<p>HyunJae Lee, Gihyeon Lee, Junhwan Kim, Sungjun Cho, Dohyun Kim, Donggeun Yoo</p></summary>
<p>

**Abstract:** Despite the evolution of Convolutional Neural Networks (CNNs), their performance is surprisingly dependent on the choice of hyperparameters. However, it remains challenging to efficiently explore large hyperparameter search space due to the long training times of modern CNNs. Multi-fidelity optimization enables the exploration of more hyperparameter configurations given budget by early termination of unpromising configurations. However, it often results in selecting a sub-optimal configuration as training with the high-performing configuration typically converges slowly in an early phase. In this paper, we propose Multi-fidelity Optimization with a Recurring Learning rate (MORL) which incorporates CNNs' optimization process into multi-fidelity optimization. MORL alleviates the problem of slow-starter and achieves a more precise low-fidelity approximation. Our comprehensive experiments on general image classification, transfer learning, and semi-supervised learning demonstrate the effectiveness of MORL over other multi-fidelity optimization methods such as Successive Halving Algorithm (SHA) and Hyperband. Furthermore, it achieves significant performance improvements over hand-tuned hyperparameter configuration within a practical budget.

</p>
</details>

<details><summary><b>Online Submodular Coordination with Bounded Tracking Regret: Theory, Algorithm, and Applications to Multi-Robot Coordination</b>
<a href="https://arxiv.org/abs/2209.12429">arxiv:2209.12429</a>
&#x1F4C8; 4 <br>
<p>Zirui Xu, Hongyu Zhou, Vasileios Tzoumas</p></summary>
<p>

**Abstract:** We enable efficient and effective coordination in unpredictable environments, ie., in environments whose future evolution is unknown a priori and even adversarial. We are motivated by the future of autonomy that involves multiple robots coordinating in dynamic, unstructured, and adversarial environments to complete complex tasks such as target tracking, image covering, and area monitoring. Such tasks are often modeled as submodular maximization coordination problems. We thus introduce the first submodular coordination algorithm with bounded tracking regret, ie., with bounded suboptimality with respect to optimal time-varying actions that know the future a priori. The bound gracefully degrades with the environments' capacity to change adversarially. It also quantifies how often the robots must re-select actions to "learn" to coordinate as if they knew the future a priori. Our algorithm generalizes the seminal Sequential Greedy algorithm by Fisher et al. to unpredictable environments, leveraging submodularity and algorithms for the problem of tracking the best expert. We validate our algorithm in simulated scenarios of target tracking.

</p>
</details>

<details><summary><b>Feature-based model selection for object detection from point cloud data</b>
<a href="https://arxiv.org/abs/2209.12419">arxiv:2209.12419</a>
&#x1F4C8; 4 <br>
<p>Kairi Tokuda, Ryoichi Shinkuma, Takehiro Sato, Eiji Oki</p></summary>
<p>

**Abstract:** Smart monitoring using three-dimensional (3D) image sensors has been attracting attention in the context of smart cities. In smart monitoring, object detection from point cloud data acquired by 3D image sensors is implemented for detecting moving objects such as vehicles and pedestrians to ensure safety on the road. However, the features of point cloud data are diversified due to the characteristics of light detection and ranging (LIDAR) units used as 3D image sensors or the install position of the 3D image sensors. Although a variety of deep learning (DL) models for object detection from point cloud data have been studied to date, no research has considered how to use multiple DL models in accordance with the features of the point cloud data. In this work, we propose a feature-based model selection framework that creates various DL models by using multiple DL methods and by utilizing training data with pseudo incompleteness generated by two artificial techniques: sampling and noise adding. It selects the most suitable DL model for the object detection task in accordance with the features of the point cloud data acquired in the real environment. To demonstrate the effectiveness of the proposed framework, we compare the performance of multiple DL models using benchmark datasets created from the KITTI dataset and present example results of object detection obtained through a real outdoor experiment. Depending on the situation, the detection accuracy varies up to 32% between DL models, which confirms the importance of selecting an appropriate DL model according to the situation.

</p>
</details>

<details><summary><b>Taking a Respite from Representation Learning for Molecular Property Prediction</b>
<a href="https://arxiv.org/abs/2209.13492">arxiv:2209.13492</a>
&#x1F4C8; 3 <br>
<p>Jianyuan Deng, Zhibo Yang, Hehe Wang, Iwao Ojima, Dimitris Samaras, Fusheng Wang</p></summary>
<p>

**Abstract:** Artificial intelligence (AI) has been widely applied in drug discovery with a major task as molecular property prediction. Despite the boom of AI techniques in molecular representation learning, some key aspects underlying molecular property prediction haven't been carefully examined yet. In this study, we conducted a systematic comparison on three representative models, random forest, MolBERT and GROVER, which utilize three major molecular representations, extended-connectivity fingerprints, SMILES strings and molecular graphs, respectively. Notably, MolBERT and GROVER, are pretrained on large-scale unlabelled molecule corpuses in a self-supervised manner. In addition to the commonly used MoleculeNet benchmark datasets, we also assembled a suite of opioids-related datasets for downstream prediction evaluation. We first conducted dataset profiling on label distribution and structural analyses; we also examined the activity cliffs issue in the opioids-related datasets. Then, we trained 4,320 predictive models and evaluated the usefulness of the learned representations. Furthermore, we explored into the model evaluation by studying the effect of statistical tests, evaluation metrics and task settings. Finally, we dissected the chemical space generalization into inter-scaffold and intra-scaffold generalization and measured prediction performance to evaluate model generalizbility under both settings. By taking this respite, we reflected on the key aspects underlying molecular property prediction, the awareness of which can, hopefully, bring better AI techniques in this field.

</p>
</details>

<details><summary><b>Activation Learning by Local Competitions</b>
<a href="https://arxiv.org/abs/2209.13400">arxiv:2209.13400</a>
&#x1F4C8; 3 <br>
<p>Hongchao Zhou</p></summary>
<p>

**Abstract:** The backpropagation that drives the success of deep learning is most likely different from the learning mechanism of the brain. In this paper, we develop a biology-inspired learning rule that discovers features by local competitions among neurons, following the idea of Hebb's famous proposal. It is demonstrated that the unsupervised features learned by this local learning rule can serve as a pre-training model to improve the performance of some supervised learning tasks. More importantly, this local learning rule enables us to build a new learning paradigm very different from the backpropagation, named activation learning, where the output activation of the neural network roughly measures how probable the input patterns are. The activation learning is capable of learning plentiful local features from few shots of input patterns, and demonstrates significantly better performances than the backpropagation algorithm when the number of training samples is relatively small. This learning paradigm unifies unsupervised learning, supervised learning and generative models, and is also more secure against adversarial attack, paving a road to some possibilities of creating general-task neural networks.

</p>
</details>

<details><summary><b>MonoGraspNet: 6-DoF Grasping with a Single RGB Image</b>
<a href="https://arxiv.org/abs/2209.13036">arxiv:2209.13036</a>
&#x1F4C8; 3 <br>
<p>Guangyao Zhai, Dianye Huang, Shun-Cheng Wu, Hyunjun Jung, Yan Di, Fabian Manhardt, Federico Tombari, Nassir Navab, Benjamin Busam</p></summary>
<p>

**Abstract:** 6-DoF robotic grasping is a long-lasting but unsolved problem. Recent methods utilize strong 3D networks to extract geometric grasping representations from depth sensors, demonstrating superior accuracy on common objects but perform unsatisfactorily on photometrically challenging objects, e.g., objects in transparent or reflective materials. The bottleneck lies in that the surface of these objects can not reflect back accurate depth due to the absorption or refraction of light. In this paper, in contrast to exploiting the inaccurate depth data, we propose the first RGB-only 6-DoF grasping pipeline called MonoGraspNet that utilizes stable 2D features to simultaneously handle arbitrary object grasping and overcome the problems induced by photometrically challenging objects. MonoGraspNet leverages keypoint heatmap and normal map to recover the 6-DoF grasping poses represented by our novel representation parameterized with 2D keypoints with corresponding depth, grasping direction, grasping width, and angle. Extensive experiments in real scenes demonstrate that our method can achieve competitive results in grasping common objects and surpass the depth-based competitor by a large margin in grasping photometrically challenging objects. To further stimulate robotic manipulation research, we additionally annotate and open-source a multi-view and multi-scene real-world grasping dataset, containing 120 objects of mixed photometric complexity with 20M accurate grasping labels.

</p>
</details>

<details><summary><b>FaRO 2: an Open Source, Configurable Smart City Framework for Real-Time Distributed Vision and Biometric Systems</b>
<a href="https://arxiv.org/abs/2209.12962">arxiv:2209.12962</a>
&#x1F4C8; 3 <br>
<p>Joel Brogan, Nell Barber, David Cornett, David Bolme</p></summary>
<p>

**Abstract:** Recent global growth in the interest of smart cities has led to trillions of dollars of investment toward research and development. These connected cities have the potential to create a symbiosis of technology and society and revolutionize the cost of living, safety, ecological sustainability, and quality of life of societies on a world-wide scale. Some key components of the smart city construct are connected smart grids, self-driving cars, federated learning systems, smart utilities, large-scale public transit, and proactive surveillance systems. While exciting in prospect, these technologies and their subsequent integration cannot be attempted without addressing the potential societal impacts of such a high degree of automation and data sharing. Additionally, the feasibility of coordinating so many disparate tasks will require a fast, extensible, unifying framework. To that end, we propose FaRO2, a completely reimagined successor to FaRO1, built from the ground up. FaRO2 affords all of the same functionality as its predecessor, serving as a unified biometric API harness that allows for seamless evaluation, deployment, and simple pipeline creation for heterogeneous biometric software. FaRO2 additionally provides a fully declarative capability for defining and coordinating custom machine learning and sensor pipelines, allowing the distribution of processes across otherwise incompatible hardware and networks. FaRO2 ultimately provides a way to quickly configure, hot-swap, and expand large coordinated or federated systems online without interruptions for maintenance. Because much of the data collected in a smart city contains Personally Identifying Information (PII), FaRO2 also provides built-in tools and layers to ensure secure and encrypted streaming, storage, and access of PII data across distributed systems.

</p>
</details>

<details><summary><b>Learning and Deploying Robust Locomotion Policies with Minimal Dynamics Randomization</b>
<a href="https://arxiv.org/abs/2209.12878">arxiv:2209.12878</a>
&#x1F4C8; 3 <br>
<p>Luigi Campanaro, Siddhant Gangapurwala, Wolfgang Merkt, Ioannis Havoutis</p></summary>
<p>

**Abstract:** Training deep reinforcement learning (DRL) locomotion policies often requires massive amounts of data to converge to the desired behavior. In this regard, simulators provide a cheap and abundant source. For successful sim-to-real transfer, exhaustively engineered approaches such as system identification, dynamics randomization, and domain adaptation are generally employed. As an alternative, we investigate a simple strategy of random force injection (RFI) to perturb system dynamics during training. We show that the application of random forces enables us to emulate dynamics randomization.This allows us to obtain locomotion policies that are robust to variations in system dynamics. We further extend RFI, referred to as extended random force injection (ERFI), by introducing an episodic actuation offset. We demonstrate that ERFI provides additional robustness for variations in system mass offering on average a 61% improved performance over RFI. We also show that ERFI is sufficient to perform a successful sim-to-real transfer on two different quadrupedal platforms, ANYmal C and Unitree A1, even for perceptive locomotion over uneven terrain in outdoor environments.

</p>
</details>

<details><summary><b>Word to Sentence Visual Semantic Similarity for Caption Generation: Lessons Learned</b>
<a href="https://arxiv.org/abs/2209.12817">arxiv:2209.12817</a>
&#x1F4C8; 3 <br>
<p>Ahmed Sabir</p></summary>
<p>

**Abstract:** This paper focuses on enhancing the captions generated by image-caption generation systems. We propose an approach for improving caption generation systems by choosing the most closely related output to the image rather than the most likely output produced by the model. Our model revises the language generation output beam search from a visual context perspective. We employ a visual semantic measure in a word and sentence level manner to match the proper caption to the related information in the image. The proposed approach can be applied to any caption system as a post-processing based method.

</p>
</details>

<details><summary><b>Fast-FNet: Accelerating Transformer Encoder Models via Efficient Fourier Layers</b>
<a href="https://arxiv.org/abs/2209.12816">arxiv:2209.12816</a>
&#x1F4C8; 3 <br>
<p>Nurullah Sevim, Ege Ozan Özyedek, Furkan Şahinuç, Aykut Koç</p></summary>
<p>

**Abstract:** Transformer-based language models utilize the attention mechanism for substantial performance improvements in almost all natural language processing (NLP) tasks. Similar attention structures are also extensively studied in several other areas. Although the attention mechanism enhances the model performances significantly, its quadratic complexity prevents efficient processing of long sequences. Recent works focused on eliminating the disadvantages of computational inefficiency and showed that transformer-based models can still reach competitive results without the attention layer. A pioneering study proposed the FNet, which replaces the attention layer with the Fourier Transform (FT) in the transformer encoder architecture. FNet achieves competitive performances concerning the original transformer encoder model while accelerating training process by removing the computational burden of the attention mechanism. However, the FNet model ignores essential properties of the FT from the classical signal processing that can be leveraged to increase model efficiency further. We propose different methods to deploy FT efficiently in transformer encoder models. Our proposed architectures have smaller number of model parameters, shorter training times, less memory usage, and some additional performance improvements. We demonstrate these improvements through extensive experiments on common benchmarks.

</p>
</details>

<details><summary><b>Towards Fine-Dining Recipe Generation with Generative Pre-trained Transformers</b>
<a href="https://arxiv.org/abs/2209.12774">arxiv:2209.12774</a>
&#x1F4C8; 3 <br>
<p>Konstantinos Katserelis, Konstantinos Skianis</p></summary>
<p>

**Abstract:** Food is essential to human survival. So much so that we have developed different recipes to suit our taste needs. In this work, we propose a novel way of creating new, fine-dining recipes from scratch using Transformers, specifically auto-regressive language models. Given a small dataset of food recipes, we try to train models to identify cooking techniques, propose novel recipes, and test the power of fine-tuning with minimal data.

</p>
</details>

<details><summary><b>Quasi-Conservative Score-based Generative Models</b>
<a href="https://arxiv.org/abs/2209.12753">arxiv:2209.12753</a>
&#x1F4C8; 3 <br>
<p>Chen-Hao Chao, Wei-Fang Sun, Bo-Wun Cheng, Chun-Yi Lee</p></summary>
<p>

**Abstract:** Existing Score-based Generative Models (SGMs) can be categorized into constrained SGMs (CSGMs) or unconstrained SGMs (USGMs) according to their parameterization approaches. CSGMs model the probability density functions as Boltzmann distributions, and assign their predictions as the negative gradients of some scalar-valued energy functions. On the other hand, USGMs employ flexible architectures capable of directly estimating scores without the need to explicitly model energy functions. In this paper, we demonstrate that the architectural constraints of CSGMs may limit their score-matching ability. In addition, we show that USGMs' inability to preserve the property of conservativeness may lead to serious sampling inefficiency and degraded sampling performance in practice. To address the above issues, we propose Quasi-Conservative Score-based Generative Models (QCSGMs) for keeping the advantages of both CSGMs and USGMs. Our theoretical derivations demonstrate that the training objective of QCSGMs can be efficiently integrated into the training processes by leveraging the Hutchinson trace estimator. In addition, our experimental results on the Cifar-10, Cifar-100, ImageNet, and SVHN datasets validate the effectiveness of QCSGMs. Finally, we justify the advantage of QCSGMs using an example of a one-layered autoencoder.

</p>
</details>

<details><summary><b>Learning Variational Models with Unrolling and Bilevel Optimization</b>
<a href="https://arxiv.org/abs/2209.12651">arxiv:2209.12651</a>
&#x1F4C8; 3 <br>
<p>Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz</p></summary>
<p>

**Abstract:** In this paper we consider the problem learning of variational models in the context of supervised learning via risk minimization. Our goal is to provide a deeper understanding of the two approaches of learning of variational models via bilevel optimization and via algorithm unrolling. The former considers the variational model as a lower level optimization problem below the risk minimization problem, while the latter replaces the lower level optimization problem by an algorithm that solves said problem approximately. Both approaches are used in practice, but, unrolling is much simpler from a computational point of view. To analyze and compare the two approaches, we consider a simple toy model, and compute all risks and the respective estimators explicitly. We show that unrolling can be better than the bilevel optimization approach, but also that the performance of unrolling can depend significantly on further parameters, sometimes in unexpected ways: While the stepsize of the unrolled algorithm matters a lot, the number of unrolled iterations only matters if the number is even or odd, and these two cases are notably different.

</p>
</details>

<details><summary><b>FORESEE: Model-based Reinforcement Learning using Unscented Transform with application to Tuning of Control Barrier Functions</b>
<a href="https://arxiv.org/abs/2209.12644">arxiv:2209.12644</a>
&#x1F4C8; 3 <br>
<p>Hardik Parwana, Dimitra Panagou</p></summary>
<p>

**Abstract:** In this paper, we introduce a novel online model-based reinforcement learning algorithm that uses Unscented Transform to propagate uncertainty for the prediction of the future reward. Previous approaches either approximate the state distribution at each step of the prediction horizon with a Gaussian, or perform Monte Carlo simulations to estimate the rewards. Our method, depending on the number of sigma points employed, can propagate either mean and covariance with minimal points, or higher-order moments with more points similarly to Monte Carlo. The whole framework is implemented as a computational graph for online training. Furthermore, in order to prevent explosion in the number of sigma points when propagating through a generic state-dependent uncertainty model, we add sigma-point expansion and contraction layers to our graph, which are designed using the principle of moment matching. Finally, we propose gradient descent inspired by Sequential Quadratic Programming to update policy parameters in the presence of state constraints. We demonstrate the proposed method with two applications in simulation. The first one designs a stabilizing controller for the cart-pole problem when the dynamics is known with state-dependent uncertainty. The second example, following up on our previous work, tunes the parameters of a control barrier function-based Quadratic Programming controller for a leader-follower problem in the presence of input constraints.

</p>
</details>

<details><summary><b>Two-Tailed Averaging: Anytime Adaptive Once-in-a-while Optimal Iterate Averaging for Stochastic Optimization</b>
<a href="https://arxiv.org/abs/2209.12581">arxiv:2209.12581</a>
&#x1F4C8; 3 <br>
<p>Gábor Melis</p></summary>
<p>

**Abstract:** Tail averaging improves on Polyak averaging's non-asymptotic behaviour by excluding a number of leading iterates of stochastic optimization from its calculations. In practice, with a finite number of optimization steps and a learning rate that cannot be annealed to zero, tail averaging can get much closer to a local minimum point of the training loss than either the individual iterates or the Polyak average. However, the number of leading iterates to ignore is an important hyperparameter, and starting averaging too early or too late leads to inefficient use of resources or suboptimal solutions. Setting this hyperparameter to improve generalization is even more difficult, especially in the presence of other hyperparameters and overfitting. Furthermore, before averaging starts, the loss is only weakly informative of the final performance, which makes early stopping unreliable. To alleviate these problems, we propose an anytime variant of tail averaging, that has no hyperparameters and approximates the optimal tail at all optimization steps. Our algorithm is based on two running averages with adaptive lengths bounded in terms of the optimal tail length, one of which achieves approximate optimality with some regularity. Requiring only the additional storage for two sets of weights and periodic evaluation of the loss, the proposed two-tailed averaging algorithm is a practical and widely applicable method for improving stochastic optimization.

</p>
</details>

<details><summary><b>Least-squares methods for nonnegative matrix factorization over rational functions</b>
<a href="https://arxiv.org/abs/2209.12579">arxiv:2209.12579</a>
&#x1F4C8; 3 <br>
<p>Cécile Hautecoeur, Lieven De Lathauwer, Nicolas Gillis, François Glineur</p></summary>
<p>

**Abstract:** Nonnegative Matrix Factorization (NMF) models are widely used to recover linearly mixed nonnegative data. When the data is made of samplings of continuous signals, the factors in NMF can be constrained to be samples of nonnegative rational functions, which allow fairly general models; this is referred to as NMF using rational functions (R-NMF). We first show that, under mild assumptions, R-NMF has an essentially unique factorization unlike NMF, which is crucial in applications where ground-truth factors need to be recovered such as blind source separation problems. Then we present different approaches to solve R-NMF: the R-HANLS, R-ANLS and R-NLS methods. From our tests, no method significantly outperforms the others, and a trade-off should be done between time and accuracy. Indeed, R-HANLS is fast and accurate for large problems, while R-ANLS is more accurate, but also more resources demanding, both in time and memory. R-NLS is very accurate but only for small problems. Moreover, we show that R-NMF outperforms NMF in various tasks including the recovery of semi-synthetic continuous signals, and a classification problem of real hyperspectral signals.

</p>
</details>

<details><summary><b>Clustering by Direct Optimization of the Medoid Silhouette</b>
<a href="https://arxiv.org/abs/2209.12553">arxiv:2209.12553</a>
&#x1F4C8; 3 <br>
<p>Lars Lenssen, Erich Schubert</p></summary>
<p>

**Abstract:** The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder. There are many different clustering quality measures, which try to provide a general measure to validate clustering results. A very popular measure is the Silhouette. We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, and provide two fast versions for the direct optimization. We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM. One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\times$ speedup compared to the original PAMMEDSIL algorithm.

</p>
</details>

<details><summary><b>Unifying Model-Based and Neural Network Feedforward: Physics-Guided Neural Networks with Linear Autoregressive Dynamics</b>
<a href="https://arxiv.org/abs/2209.12489">arxiv:2209.12489</a>
&#x1F4C8; 3 <br>
<p>Johan Kon, Dennis Bruijnen, Jeroen van de Wijdeven, Marcel Heertjes, Tom Oomen</p></summary>
<p>

**Abstract:** Unknown nonlinear dynamics often limit the tracking performance of feedforward control. The aim of this paper is to develop a feedforward control framework that can compensate these unknown nonlinear dynamics using universal function approximators. The feedforward controller is parametrized as a parallel combination of a physics-based model and a neural network, where both share the same linear autoregressive (AR) dynamics. This parametrization allows for efficient output-error optimization through Sanathanan-Koerner (SK) iterations. Within each SK-iteration, the output of the neural network is penalized in the subspace of the physics-based model through orthogonal projection-based regularization, such that the neural network captures only the unmodelled dynamics, resulting in interpretable models.

</p>
</details>

<details><summary><b>On Projections to Linear Subspaces</b>
<a href="https://arxiv.org/abs/2209.12485">arxiv:2209.12485</a>
&#x1F4C8; 3 <br>
<p>Erik Thordsen, Erich Schubert</p></summary>
<p>

**Abstract:** The merit of projecting data onto linear subspaces is well known from, e.g., dimension reduction. One key aspect of subspace projections, the maximum preservation of variance (principal component analysis), has been thoroughly researched and the effect of random linear projections on measures such as intrinsic dimensionality still is an ongoing effort. In this paper, we investigate the less explored depths of linear projections onto explicit subspaces of varying dimensionality and the expectations of variance that ensue. The result is a new family of bounds for Euclidean distances and inner products. We showcase the quality of these bounds as well as investigate the intimate relation to intrinsic dimensionality estimation.

</p>
</details>

<details><summary><b>Delayed Geometric Discounts: An Alternative Criterion for Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.12483">arxiv:2209.12483</a>
&#x1F4C8; 3 <br>
<p>Firas Jarboui, Ahmed Akakzia</p></summary>
<p>

**Abstract:** The endeavor of artificial intelligence (AI) is to design autonomous agents capable of achieving complex tasks. Namely, reinforcement learning (RL) proposes a theoretical background to learn optimal behaviors. In practice, RL algorithms rely on geometric discounts to evaluate this optimality. Unfortunately, this does not cover decision processes where future returns are not exponentially less valuable. Depending on the problem, this limitation induces sample-inefficiency (as feed-backs are exponentially decayed) and requires additional curricula/exploration mechanisms (to deal with sparse, deceptive or adversarial rewards). In this paper, we tackle these issues by generalizing the discounted problem formulation with a family of delayed objective functions. We investigate the underlying RL problem to derive: 1) the optimal stationary solution and 2) an approximation of the optimal non-stationary control. The devised algorithms solved hard exploration problems on tabular environment and improved sample-efficiency on classic simulated robotics benchmarks.

</p>
</details>

<details><summary><b>RetiFluidNet: A Self-Adaptive and Multi-Attention Deep Convolutional Network for Retinal OCT Fluid Segmentation</b>
<a href="https://arxiv.org/abs/2209.12468">arxiv:2209.12468</a>
&#x1F4C8; 3 <br>
<p>Reza Rasti, Armin Biglari, Mohammad Rezapourian, Ziyun Yang, Sina Farsiu</p></summary>
<p>

**Abstract:** Optical coherence tomography (OCT) helps ophthalmologists assess macular edema, accumulation of fluids, and lesions at microscopic resolution. Quantification of retinal fluids is necessary for OCT-guided treatment management, which relies on a precise image segmentation step. As manual analysis of retinal fluids is a time-consuming, subjective, and error-prone task, there is increasing demand for fast and robust automatic solutions. In this study, a new convolutional neural architecture named RetiFluidNet is proposed for multi-class retinal fluid segmentation. The model benefits from hierarchical representation learning of textural, contextual, and edge features using a new self-adaptive dual-attention (SDA) module, multiple self-adaptive attention-based skip connections (SASC), and a novel multi-scale deep self supervision learning (DSL) scheme. The attention mechanism in the proposed SDA module enables the model to automatically extract deformation-aware representations at different levels, and the introduced SASC paths further consider spatial-channel interdependencies for concatenation of counterpart encoder and decoder units, which improve representational capability. RetiFluidNet is also optimized using a joint loss function comprising a weighted version of dice overlap and edge-preserved connectivity-based losses, where several hierarchical stages of multi-scale local losses are integrated into the optimization process. The model is validated based on three publicly available datasets: RETOUCH, OPTIMA, and DUKE, with comparisons against several baselines. Experimental results on the datasets prove the effectiveness of the proposed model in retinal OCT fluid segmentation and reveal that the suggested method is more effective than existing state-of-the-art fluid segmentation algorithms in adapting to retinal OCT scans recorded by various image scanning instruments.

</p>
</details>

<details><summary><b>Searching a High-Performance Feature Extractor for Text Recognition Network</b>
<a href="https://arxiv.org/abs/2209.13139">arxiv:2209.13139</a>
&#x1F4C8; 2 <br>
<p>Hui Zhang, Quanming Yao, James T. Kwok, Xiang Bai</p></summary>
<p>

**Abstract:** Feature extractor plays a critical role in text recognition (TR), but customizing its architecture is relatively less explored due to expensive manual tweaking. In this work, inspired by the success of neural architecture search (NAS), we propose to search for suitable feature extractors. We design a domain-specific search space by exploring principles for having good feature extractors. The space includes a 3D-structured space for the spatial model and a transformed-based space for the sequential model. As the space is huge and complexly structured, no existing NAS algorithms can be applied. We propose a two-stage algorithm to effectively search in the space. In the first stage, we cut the space into several blocks and progressively train each block with the help of an auxiliary head. We introduce the latency constraint into the second stage and search sub-network from the trained supernet via natural gradient descent. In experiments, a series of ablation studies are performed to better understand the designed space, search algorithm, and searched architectures. We also compare the proposed method with various state-of-the-art ones on both hand-written and scene TR tasks. Extensive results show that our approach can achieve better recognition performance with less latency.

</p>
</details>

<details><summary><b>3D Scene Flow Estimation on Pseudo-LiDAR: Bridging the Gap on Estimating Point Motion</b>
<a href="https://arxiv.org/abs/2209.13130">arxiv:2209.13130</a>
&#x1F4C8; 2 <br>
<p>Chaokang Jiang, Guangming Wang, Yanzi Miao, Hesheng Wang</p></summary>
<p>

**Abstract:** 3D scene flow characterizes how the points at the current time flow to the next time in the 3D Euclidean space, which possesses the capacity to infer autonomously the non-rigid motion of all objects in the scene. The previous methods for estimating scene flow from images have limitations, which split the holistic nature of 3D scene flow by estimating optical flow and disparity separately. Learning 3D scene flow from point clouds also faces the difficulties of the gap between synthesized and real data and the sparsity of LiDAR point clouds. In this paper, the generated dense depth map is utilized to obtain explicit 3D coordinates, which achieves direct learning of 3D scene flow from 2D images. The stability of the predicted scene flow is improved by introducing the dense nature of 2D pixels into the 3D space. Outliers in the generated 3D point cloud are removed by statistical methods to weaken the impact of noisy points on the 3D scene flow estimation task. Disparity consistency loss is proposed to achieve more effective unsupervised learning of 3D scene flow. The proposed method of self-supervised learning of 3D scene flow on real-world images is compared with a variety of methods for learning on the synthesized dataset and learning on LiDAR point clouds. The comparisons of multiple scene flow metrics are shown to demonstrate the effectiveness and superiority of introducing pseudo-LiDAR point cloud to scene flow estimation.

</p>
</details>

<details><summary><b>FG-UAP: Feature-Gathering Universal Adversarial Perturbation</b>
<a href="https://arxiv.org/abs/2209.13113">arxiv:2209.13113</a>
&#x1F4C8; 2 <br>
<p>Zhixing Ye, Xinwen Cheng, Xiaolin Huang</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) are susceptible to elaborately designed perturbations, whether such perturbations are dependent or independent of images. The latter one, called Universal Adversarial Perturbation (UAP), is very attractive for model robustness analysis, since its independence of input reveals the intrinsic characteristics of the model. Relatively, another interesting observation is Neural Collapse (NC), which means the feature variability may collapse during the terminal phase of training. Motivated by this, we propose to generate UAP by attacking the layer where NC phenomenon happens. Because of NC, the proposed attack could gather all the natural images' features to its surrounding, which is hence called Feature-Gathering UAP (FG-UAP).
  We evaluate the effectiveness our proposed algorithm on abundant experiments, including untargeted and targeted universal attacks, attacks under limited dataset, and transfer-based black-box attacks among different architectures including Vision Transformers, which are believed to be more robust. Furthermore, we investigate FG-UAP in the view of NC by analyzing the labels and extracted features of adversarial examples, finding that collapse phenomenon becomes stronger after the model is corrupted. The code will be released when the paper is accepted.

</p>
</details>

<details><summary><b>Controlling mean exit time of stochastic dynamical systems based on quasipotential and machine learning</b>
<a href="https://arxiv.org/abs/2209.13098">arxiv:2209.13098</a>
&#x1F4C8; 2 <br>
<p>Yang Li, Shenglan Yuan, Shengyuan Xu</p></summary>
<p>

**Abstract:** The mean exit time escaping basin of attraction in the presence of white noise is of practical importance in various scientific fields. In this work, we propose a strategy to control mean exit time of general stochastic dynamical systems to achieve a desired value based on the quasipotential concept and machine learning. Specifically, we develop a neural network architecture to compute the global quasipotential function. Then we design a systematic iterated numerical algorithm to calculate the controller for a given mean exit time. Moreover, we identify the most probable path between metastable attractors with help of the effective Hamilton-Jacobi scheme and the trained neural network. Numerical experiments demonstrate that our control strategy is effective and sufficiently accurate.

</p>
</details>

<details><summary><b>WaterNeRF: Neural Radiance Fields for Underwater Scenes</b>
<a href="https://arxiv.org/abs/2209.13091">arxiv:2209.13091</a>
&#x1F4C8; 2 <br>
<p>Advaith Venkatramanan Sethuraman, Manikandasriram Srinivasan Ramanagopal, Katherine A. Skinner</p></summary>
<p>

**Abstract:** Underwater imaging is a critical task performed by marine robots for a wide range of applications including aquaculture, marine infrastructure inspection, and environmental monitoring. However, water column effects, such as attenuation and backscattering, drastically change the color and quality of imagery captured underwater. Due to varying water conditions and range-dependency of these effects, restoring underwater imagery is a challenging problem. This impacts downstream perception tasks including depth estimation and 3D reconstruction. In this paper, we advance state-of-the-art in neural radiance fields (NeRFs) to enable physics-informed dense depth estimation and color correction. Our proposed method, WaterNeRF, estimates parameters of a physics-based model for underwater image formation, leading to a hybrid data-driven and model-based solution. After determining the scene structure and radiance field, we can produce novel views of degraded as well as corrected underwater images, along with dense depth of the scene. We evaluate the proposed method qualitatively and quantitatively on a real underwater dataset.

</p>
</details>

<details><summary><b>EEG-based Image Feature Extraction for Visual Classification using Deep Learning</b>
<a href="https://arxiv.org/abs/2209.13090">arxiv:2209.13090</a>
&#x1F4C8; 2 <br>
<p>Alankrit Mishra, Nikhil Raj, Garima Bajwa</p></summary>
<p>

**Abstract:** While capable of segregating visual data, humans take time to examine a single piece, let alone thousands or millions of samples. The deep learning models efficiently process sizeable information with the help of modern-day computing. However, their questionable decision-making process has raised considerable concerns. Recent studies have identified a new approach to extract image features from EEG signals and combine them with standard image features. These approaches make deep learning models more interpretable and also enables faster converging of models with fewer samples. Inspired by recent studies, we developed an efficient way of encoding EEG signals as images to facilitate a more subtle understanding of brain signals with deep learning models. Using two variations in such encoding methods, we classified the encoded EEG signals corresponding to 39 image classes with a benchmark accuracy of 70% on the layered dataset of six subjects, which is significantly higher than the existing work. Our image classification approach with combined EEG features achieved an accuracy of 82% compared to the slightly better accuracy of a pure deep learning approach; nevertheless, it demonstrates the viability of the theory.

</p>
</details>

<details><summary><b>Why neural networks find simple solutions: the many regularizers of geometric complexity</b>
<a href="https://arxiv.org/abs/2209.13083">arxiv:2209.13083</a>
&#x1F4C8; 2 <br>
<p>Benoit Dherin, Michael Munn, Mihaela Rosca, David G. T. Barrett</p></summary>
<p>

**Abstract:** In many contexts, simpler models are preferable to more complex models and the control of this model complexity is the goal for many methods in machine learning such as regularization, hyperparameter tuning and architecture design. In deep learning, it has been difficult to understand the underlying mechanisms of complexity control, since many traditional measures are not naturally suitable for deep neural networks. Here we develop the notion of geometric complexity, which is a measure of the variability of the model function, computed using a discrete Dirichlet energy. Using a combination of theoretical arguments and empirical results, we show that many common training heuristics such as parameter norm regularization, spectral norm regularization, flatness regularization, implicit gradient regularization, noise regularization and the choice of parameter initialization all act to control geometric complexity, providing a unifying framework in which to characterize the behavior of deep learning models.

</p>
</details>

<details><summary><b>FedStack: Personalized activity monitoring using stacked federated learning</b>
<a href="https://arxiv.org/abs/2209.13080">arxiv:2209.13080</a>
&#x1F4C8; 2 <br>
<p>Thanveer Shaik, Xiaohui Tao, Niall Higgins, Raj Gururajan, Yuefeng Li, Xujuan Zhou, U Rajendra Acharya</p></summary>
<p>

**Abstract:** Recent advances in remote patient monitoring (RPM) systems can recognize various human activities to measure vital signs, including subtle motions from superficial vessels. There is a growing interest in applying artificial intelligence (AI) to this area of healthcare by addressing known limitations and challenges such as predicting and classifying vital signs and physical movements, which are considered crucial tasks. Federated learning is a relatively new AI technique designed to enhance data privacy by decentralizing traditional machine learning modeling. However, traditional federated learning requires identical architectural models to be trained across the local clients and global servers. This limits global model architecture due to the lack of local models heterogeneity. To overcome this, a novel federated learning architecture, FedStack, which supports ensembling heterogeneous architectural client models was proposed in this study. This work offers a protected privacy system for hospitalized in-patients in a decentralized approach and identifies optimum sensor placement. The proposed architecture was applied to a mobile health sensor benchmark dataset from 10 different subjects to classify 12 routine activities. Three AI models, ANN, CNN, and Bi-LSTM were trained on individual subject data. The federated learning architecture was applied to these models to build local and global models capable of state of the art performances. The local CNN model outperformed ANN and Bi-LSTM models on each subject data. Our proposed work has demonstrated better performance for heterogeneous stacking of the local models compared to homogeneous stacking. This work sets the stage to build an enhanced RPM system that incorporates client privacy to assist with clinical observations for patients in an acute mental health facility and ultimately help to prevent unexpected death.

</p>
</details>

<details><summary><b>Off-policy estimation of linear functionals: Non-asymptotic theory for semi-parametric efficiency</b>
<a href="https://arxiv.org/abs/2209.13075">arxiv:2209.13075</a>
&#x1F4C8; 2 <br>
<p>Wenlong Mou, Martin J. Wainwright, Peter L. Bartlett</p></summary>
<p>

**Abstract:** The problem of estimating a linear functional based on observational data is canonical in both the causal inference and bandit literatures. We analyze a broad class of two-stage procedures that first estimate the treatment effect function, and then use this quantity to estimate the linear functional. We prove non-asymptotic upper bounds on the mean-squared error of such procedures: these bounds reveal that in order to obtain non-asymptotically optimal procedures, the error in estimating the treatment effect should be minimized in a certain weighted $L^2$-norm. We analyze a two-stage procedure based on constrained regression in this weighted norm, and establish its instance-dependent optimality in finite samples via matching non-asymptotic local minimax lower bounds. These results show that the optimal non-asymptotic risk, in addition to depending on the asymptotically efficient variance, depends on the weighted norm distance between the true outcome function and its approximation by the richest function class supported by the sample size.

</p>
</details>

<details><summary><b>Training Efficient Controllers via Analytic Policy Gradient</b>
<a href="https://arxiv.org/abs/2209.13052">arxiv:2209.13052</a>
&#x1F4C8; 2 <br>
<p>Nina Wiedemann, Valentin Wüest, Antonio Loquercio, Matthias Müller, Dario Floreano, Davide Scaramuzza</p></summary>
<p>

**Abstract:** Control design for robotic systems is complex and often requires solving an optimization to follow a trajectory accurately. Online optimization approaches like Model Predictive Control (MPC) have been shown to achieve great tracking performance, but require high computing power. Conversely, learning-based offline optimization approaches, such as Reinforcement Learning (RL), allow fast and efficient execution on the robot but hardly match the accuracy of MPC in trajectory tracking tasks. In systems with limited compute, such as aerial vehicles, an accurate controller that is efficient at execution time is imperative. We propose an Analytic Policy Gradient (APG) method to tackle this problem. APG exploits the availability of differentiable simulators by training a controller offline with gradient descent on the tracking error. We address training instabilities that frequently occur with APG through curriculum learning and experiment on a widely used controls benchmark, the CartPole, and two common aerial robots, a quadrotor and a fixed-wing drone. Our proposed method outperforms both model-based and model-free RL methods in terms of tracking error. Concurrently, it achieves similar performance to MPC while requiring more than an order of magnitude less computation time. Our work provides insights into the potential of APG as a promising control method for robotics. To facilitate the exploration of APG, we open-source our code and make it available at https://github.com/lis-epfl/apg_trajectory_tracking.

</p>
</details>

<details><summary><b>Understanding Hindsight Goal Relabeling Requires Rethinking Divergence Minimization</b>
<a href="https://arxiv.org/abs/2209.13046">arxiv:2209.13046</a>
&#x1F4C8; 2 <br>
<p>Lunjun Zhang, Bradly C. Stadie</p></summary>
<p>

**Abstract:** Hindsight goal relabeling has become a foundational technique for multi-goal reinforcement learning (RL). The idea is quite simple: any arbitrary trajectory can be seen as an expert demonstration for reaching the trajectory's end state. Intuitively, this procedure trains a goal-conditioned policy to imitate a sub-optimal expert. However, this connection between imitation and hindsight relabeling is not well understood. Modern imitation learning algorithms are described in the language of divergence minimization, and yet it remains an open problem how to recast hindsight goal relabeling into that framework. In this work, we develop a unified objective for goal-reaching that explains such a connection, from which we can derive goal-conditioned supervised learning (GCSL) and the reward function in hindsight experience replay (HER) from first principles. Experimentally, we find that despite recent advances in goal-conditioned behaviour cloning (BC), multi-goal Q-learning can still outperform BC-like methods; moreover, a vanilla combination of both actually hurts model performance. Under our framework, we study when BC is expected to help, and empirically validate our findings. Our work further bridges goal-reaching and generative modeling, illustrating the nuances and new pathways of extending the success of generative models to RL.

</p>
</details>

<details><summary><b>Evaluation of Medical Image Segmentation Models for Uncertain, Small or Empty Reference Annotations</b>
<a href="https://arxiv.org/abs/2209.13008">arxiv:2209.13008</a>
&#x1F4C8; 2 <br>
<p>Sophie Ostmeier, Brian Axelrod, Jeroen Bertels, Fabian Isensee, Maarten G. Lansberg, Soren Christensen, Gregory W. Albers, Li-Jia Li, Jeremy J. Heit</p></summary>
<p>

**Abstract:** Performance metrics for medical image segmentation models are used to measure agreement between the reference annotation and the prediction. A common set of metrics is used in the development of such models to make results more comparable. However, there is a mismatch between the distributions in public data sets and cases encountered in clinical practice. Many common metrics fail to measure the impact of this mismatch, especially for clinical data sets containing uncertain, small or empty reference annotation. Thus, models may not be validated for clinically meaningful agreement by such metrics. Dimensions of evaluating clinical value include independence from reference annotation volume size, consideration of uncertainty of reference annotations, reward of volumetric and/or location agreement and reward of correct classification of empty reference annotations. Unlike common public data sets, our in-house data set is more representative. It contains uncertain, small or empty reference annotations. We examine publicly available metrics on the predictions of a deep learning framework in order to identify for which settings common metrics provide clinical meaningful results. We compare to a public benchmark data set without uncertain, small or empty reference annotations. The code will be published.

</p>
</details>

<details><summary><b>Going Further With Winograd Convolutions: Tap-Wise Quantization for Efficient Inference on 4x4 Tile</b>
<a href="https://arxiv.org/abs/2209.12982">arxiv:2209.12982</a>
&#x1F4C8; 2 <br>
<p>Renzo Andri, Beatrice Bussolino, Antonio Cipolletta, Lukas Cavigelli, Zhe Wang</p></summary>
<p>

**Abstract:** Most of today's computer vision pipelines are built around deep neural networks, where convolution operations require most of the generally high compute effort. The Winograd convolution algorithm computes convolutions with fewer MACs compared to the standard algorithm, reducing the operation count by a factor of 2.25x for 3x3 convolutions when using the version with 2x2-sized tiles $F_2$. Even though the gain is significant, the Winograd algorithm with larger tile sizes, i.e., $F_4$, offers even more potential in improving throughput and energy efficiency, as it reduces the required MACs by 4x. Unfortunately, the Winograd algorithm with larger tile sizes introduces numerical issues that prevent its use on integer domain-specific accelerators and higher computational overhead to transform input and output data between spatial and Winograd domains.
  To unlock the full potential of Winograd $F_4$, we propose a novel tap-wise quantization method that overcomes the numerical issues of using larger tiles, enabling integer-only inference. Moreover, we present custom hardware units that process the Winograd transformations in a power- and area-efficient way, and we show how to integrate such custom modules in an industrial-grade, programmable DSA. An extensive experimental evaluation on a large set of state-of-the-art computer vision benchmarks reveals that the tap-wise quantization algorithm makes the quantized Winograd $F_4$ network almost as accurate as the FP32 baseline. The Winograd-enhanced DSA achieves up to 1.85x gain in energy efficiency and up to 1.83x end-to-end speed-up for state-of-the-art segmentation and detection networks.

</p>
</details>

<details><summary><b>Developing Machine-Learned Potentials for Coarse-Grained Molecular Simulations: Challenges and Pitfalls</b>
<a href="https://arxiv.org/abs/2209.12948">arxiv:2209.12948</a>
&#x1F4C8; 2 <br>
<p>Eleonora Ricci, George Giannakopoulos, Vangelis Karkaletsis, Doros N. Theodorou, Niki Vergadou</p></summary>
<p>

**Abstract:** Coarse graining (CG) enables the investigation of molecular properties for larger systems and at longer timescales than the ones attainable at the atomistic resolution. Machine learning techniques have been recently proposed to learn CG particle interactions, i.e. develop CG force fields. Graph representations of molecules and supervised training of a graph convolutional neural network architecture are used to learn the potential of mean force through a force matching scheme. In this work, the force acting on each CG particle is correlated to a learned representation of its local environment that goes under the name of SchNet, constructed via continuous filter convolutions. We explore the application of SchNet models to obtain a CG potential for liquid benzene, investigating the effect of model architecture and hyperparameters on the thermodynamic, dynamical, and structural properties of the simulated CG systems, reporting and discussing challenges encountered and future directions envisioned.

</p>
</details>

<details><summary><b>Investigation of Machine Learning-based Coarse-Grained Mapping Schemes for Organic Molecules</b>
<a href="https://arxiv.org/abs/2209.12946">arxiv:2209.12946</a>
&#x1F4C8; 2 <br>
<p>Dimitris Nasikas, Eleonora Ricci, George Giannakopoulos, Vangelis Karkaletsis, Doros N. Theodorou, Niki Vergadou</p></summary>
<p>

**Abstract:** Due to the wide range of timescales that are present in macromolecular systems, hierarchical multiscale strategies are necessary for their computational study. Coarse-graining (CG) allows to establish a link between different system resolutions and provides the backbone for the development of robust multiscale simulations and analyses. The CG mapping process is typically system- and application-specific, and it relies on chemical intuition. In this work, we explored the application of a Machine Learning strategy, based on Variational Autoencoders, for the development of suitable mapping schemes from the atomistic to the coarse-grained space of molecules with increasing chemical complexity. An extensive evaluation of the effect of the model hyperparameters on the training process and on the final output was performed, and an existing method was extended with the definition of different loss functions and the implementation of a selection criterion that ensures physical consistency of the output. The relationship between the input feature choice and the reconstruction accuracy was analyzed, supporting the need to introduce rotational invariance into the system. Strengths and limitations of the approach, both in the mapping and in the backmapping steps, are highlighted and critically discussed.

</p>
</details>

<details><summary><b>End-to-End Affordance Learning for Robotic Manipulation</b>
<a href="https://arxiv.org/abs/2209.12941">arxiv:2209.12941</a>
&#x1F4C8; 2 <br>
<p>Yiran Geng, Boshi An, Haoran Geng, Yuanpei Chen, Yaodong Yang, Hao Dong</p></summary>
<p>

**Abstract:** Learning to manipulate 3D objects in an interactive environment has been a challenging problem in Reinforcement Learning (RL). In particular, it is hard to train a policy that can generalize over objects with different semantic categories, diverse shape geometry and versatile functionality. Recently, the technique of visual affordance has shown great prospects in providing object-centric information priors with effective actionable semantics. As such, an effective policy can be trained to open a door by knowing how to exert force on the handle. However, to learn the affordance, it often requires human-defined action primitives, which limits the range of applicable tasks. In this study, we take advantage of visual affordance by using the contact information generated during the RL training process to predict contact maps of interest. Such contact prediction process then leads to an end-to-end affordance learning framework that can generalize over different types of manipulation tasks. Surprisingly, the effectiveness of such framework holds even under the multi-stage and the multi-agent scenarios. We tested our method on eight types of manipulation tasks. Results showed that our methods outperform baseline algorithms, including visual-based affordance methods and RL methods, by a large margin on the success rate. The demonstration can be found at https://sites.google.com/view/rlafford/.

</p>
</details>

<details><summary><b>Approximate Description Length, Covering Numbers, and VC Dimension</b>
<a href="https://arxiv.org/abs/2209.12882">arxiv:2209.12882</a>
&#x1F4C8; 2 <br>
<p>Amit Daniely, Gal Katzhendler</p></summary>
<p>

**Abstract:** Recently, Daniely and Granot [arXiv:1910.05697] introduced a new notion of complexity called Approximate Description Length (ADL). They used it to derive novel generalization bounds for neural networks, that despite substantial work, were out of reach for more classical techniques such as discretization, Covering Numbers and Rademacher Complexity. In this paper we explore how ADL relates to classical notions of function complexity such as Covering Numbers and VC Dimension. We find that for functions whose range is the reals, ADL is essentially equivalent to these classical complexity measures. However, this equivalence breaks for functions with high dimensional range.

</p>
</details>

<details><summary><b>Variationally Mimetic Operator Networks</b>
<a href="https://arxiv.org/abs/2209.12871">arxiv:2209.12871</a>
&#x1F4C8; 2 <br>
<p>Dhruv Patel, Deep Ray, Michael R. A. Abdelmalik, Thomas J. R. Hughes, Assad A. Oberai</p></summary>
<p>

**Abstract:** Operator networks have emerged as promising deep learning tools for approximating the solution to partial differential equations (PDEs). These networks map input functions that describe material properties, forcing functions and boundary data to the solution of a PDE. This work describes a new architecture for operator networks that mimics the form of the numerical solution obtained from an approximation of the variational or weak formulation of the problem. The application of these ideas to a generic elliptic PDE leads to a variationally mimetic operator network (VarMiON). Like the conventional Deep Operator Network (DeepONet) the VarMiON is also composed of a sub-network that constructs the basis functions for the output and another that constructs the coefficients for these basis functions. However, in contrast to the DeepONet, in the VarMiON the architecture of these networks is precisely determined. An analysis of the error in the VarMiON solution reveals that it contains contributions from the error in the training data, the training error, quadrature error in sampling input and output functions, and a "covering error" that measures the distance between the test input functions and the nearest functions in the training dataset. It also depends on the stability constants for the exact network and its VarMiON approximation. The application of the VarMiON to a canonical elliptic PDE reveals that for approximately the same number of network parameters, on average the VarMiON incurs smaller errors than a standard DeepONet. Further, its performance is more robust to variations in input functions, the techniques used to sample the input and output functions, the techniques used to construct the basis functions, and the number of input functions.

</p>
</details>

<details><summary><b>Distance Measures for Geometric Graphs</b>
<a href="https://arxiv.org/abs/2209.12869">arxiv:2209.12869</a>
&#x1F4C8; 2 <br>
<p>Sushovan Majhi, Carola Wenk</p></summary>
<p>

**Abstract:** A geometric graph is a combinatorial graph, endowed with a geometry that is inherited from its embedding in a Euclidean space. Formulation of a meaningful measure of (dis-)similarity in both the combinatorial and geometric structures of two such geometric graphs is a challenging problem in pattern recognition. We study two notions of distance measures for geometric graphs, called the geometric edit distance (GED) and geometric graph distance (GGD). While the former is based on the idea of editing one graph to transform it into the other graph, the latter is inspired by inexact matching of the graphs. For decades, both notions have been lending themselves well as measures of similarity between attributed graphs. If used without any modification, however, they fail to provide a meaningful distance measure for geometric graphs -- even cease to be a metric. We have curated their associated cost functions for the context of geometric graphs. Alongside studying the metric properties of GED and GGD, we investigate how the two notions compare. We further our understanding of the computational aspects of GGD by showing that the distance is $\mathcal{NP}$-hard to compute, even if the graphs are planar and arbitrary cost coefficients are allowed.

</p>
</details>

<details><summary><b>Efficient Multi-Prize Lottery Tickets: Enhanced Accuracy, Training, and Inference Speed</b>
<a href="https://arxiv.org/abs/2209.12839">arxiv:2209.12839</a>
&#x1F4C8; 2 <br>
<p>Hao Cheng, Pu Zhao, Yize Li, Xue Lin, James Diffenderfer, Ryan Goldhahn, Bhavya Kailkhura</p></summary>
<p>

**Abstract:** Recently, Diffenderfer and Kailkhura proposed a new paradigm for learning compact yet highly accurate binary neural networks simply by pruning and quantizing randomly weighted full precision neural networks. However, the accuracy of these multi-prize tickets (MPTs) is highly sensitive to the optimal prune ratio, which limits their applicability. Furthermore, the original implementation did not attain any training or inference speed benefits. In this report, we discuss several improvements to overcome these limitations. We show the benefit of the proposed techniques by performing experiments on CIFAR-10.

</p>
</details>

<details><summary><b>Targeted Separation and Convergence with Kernel Discrepancies</b>
<a href="https://arxiv.org/abs/2209.12835">arxiv:2209.12835</a>
&#x1F4C8; 2 <br>
<p>Alessandro Barp, Carl-Johann Simon-Gabriel, Mark Girolami, Lester Mackey</p></summary>
<p>

**Abstract:** Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD) have grown central to a wide range of applications, including hypothesis testing, sampler selection, distribution approximation, and variational inference. In each setting, these kernel-based discrepancy measures are required to (i) separate a target P from other probability measures or even (ii) control weak convergence to P. In this article we derive new sufficient and necessary conditions to ensure (i) and (ii). For MMDs on separable metric spaces, we characterize those kernels that separate Bochner embeddable measures and introduce simple conditions for separating all measures with unbounded kernels and for controlling convergence with bounded kernels. We use these results on $\mathbb{R}^d$ to substantially broaden the known conditions for KSD separation and convergence control and to develop the first KSDs known to exactly metrize weak convergence to P. Along the way, we highlight the implications of our results for hypothesis testing, measuring and improving sample quality, and sampling with Stein variational gradient descent.

</p>
</details>

<details><summary><b>Do ever larger octopi still amplify reporting biases? Evidence from judgments of typical colour</b>
<a href="https://arxiv.org/abs/2209.12786">arxiv:2209.12786</a>
&#x1F4C8; 2 <br>
<p>Fangyu Liu, Julian Martin Eisenschlos, Jeremy R. Cole, Nigel Collier</p></summary>
<p>

**Abstract:** Language models (LMs) trained on raw texts have no direct access to the physical world. Gordon and Van Durme (2013) point out that LMs can thus suffer from reporting bias: texts rarely report on common facts, instead focusing on the unusual aspects of a situation. If LMs are only trained on text corpora and naively memorise local co-occurrence statistics, they thus naturally would learn a biased view of the physical world. While prior studies have repeatedly verified that LMs of smaller scales (e.g., RoBERTa, GPT-2) amplify reporting bias, it remains unknown whether such trends continue when models are scaled up. We investigate reporting bias from the perspective of colour in larger language models (LLMs) such as PaLM and GPT-3. Specifically, we query LLMs for the typical colour of objects, which is one simple type of perceptually grounded physical common sense. Surprisingly, we find that LLMs significantly outperform smaller LMs in determining an object's typical colour and more closely track human judgments, instead of overfitting to surface patterns stored in texts. This suggests that very large models of language alone are able to overcome certain types of reporting bias that are characterized by local co-occurrences.

</p>
</details>

<details><summary><b>An Explainable Machine Learning Approach to Visual-Interactive Labeling: A Case Study on Non-communicable Disease Data</b>
<a href="https://arxiv.org/abs/2209.12778">arxiv:2209.12778</a>
&#x1F4C8; 2 <br>
<p>Donlapark Ponnoprat, Parichart Pattarapanitchai, Phimphaka Taninpong, Suthep Suantai</p></summary>
<p>

**Abstract:** We introduce a new visual-interactive tool: Explainable Labeling Assistant (XLabel) that takes an explainable machine learning approach to data labeling. The main component of XLabel is the Explainable Boosting Machine (EBM), a predictive model that can calculate the contribution of each input feature towards the final prediction. As a case study, we use XLabel to predict the labels of four non-communicable diseases (NCDs): diabetes, hypertension, chronic kidney disease, and dyslipidemia. We demonstrate that EBM is an excellent choice of predictive model by comparing it against a rule-based and four other machine learning models. By performing 5-fold cross-validation on 427 medical records, EBM's prediction accuracy, precision, and F1-score are greater than 0.95 in all four NCDs. It performed as well as two black-box models and outperformed the other models in these metrics. In an additional experiment, when 40% of the records were intentionally mislabeled, EBM could recall the correct labels of more than 90% of these records.

</p>
</details>

<details><summary><b>Text Summarization with Oracle Expectation</b>
<a href="https://arxiv.org/abs/2209.12714">arxiv:2209.12714</a>
&#x1F4C8; 2 <br>
<p>Yumo Xu, Mirella Lapata</p></summary>
<p>

**Abstract:** Extractive summarization produces summaries by identifying and concatenating the most important sentences in a document. Since most summarization datasets do not come with gold labels indicating whether document sentences are summary-worthy, different labeling algorithms have been proposed to extrapolate oracle extracts for model training. In this work, we identify two flaws with the widely used greedy labeling approach: it delivers suboptimal and deterministic oracles. To alleviate both issues, we propose a simple yet effective labeling algorithm that creates soft, expectation-based sentence labels. We define a new learning objective for extractive summarization which incorporates learning signals from multiple oracle summaries and prove it is equivalent to estimating the oracle expectation for each document sentence. Without any architectural modifications, the proposed labeling scheme achieves superior performance on a variety of summarization benchmarks across domains and languages, in both supervised and zero-shot settings.

</p>
</details>

<details><summary><b>Multi-Agent Sequential Decision-Making via Communication</b>
<a href="https://arxiv.org/abs/2209.12713">arxiv:2209.12713</a>
&#x1F4C8; 2 <br>
<p>Ziluo Ding, Kefan Su, Weixin Hong, Liwen Zhu, Tiejun Huang, Zongqing Lu</p></summary>
<p>

**Abstract:** Communication helps agents to obtain information about others so that better coordinated behavior can be learned. Some existing work communicates predicted future trajectory with others, hoping to get clues about what others would do for better coordination. However, circular dependencies sometimes can occur when agents are treated synchronously so it is hard to coordinate decision-making. In this paper, we propose a novel communication scheme, Sequential Communication (SeqComm). SeqComm treats agents asynchronously (the upper-level agents make decisions before the lower-level ones) and has two communication phases. In negotiation phase, agents determine the priority of decision-making by communicating hidden states of observations and comparing the value of intention, which is obtained by modeling the environment dynamics. In launching phase, the upper-level agents take the lead in making decisions and communicate their actions with the lower-level agents. Theoretically, we prove the policies learned by SeqComm are guaranteed to improve monotonically and converge. Empirically, we show that SeqComm outperforms existing methods in various multi-agent cooperative tasks.

</p>
</details>

<details><summary><b>Bounded Simplex-Structured Matrix Factorization</b>
<a href="https://arxiv.org/abs/2209.12638">arxiv:2209.12638</a>
&#x1F4C8; 2 <br>
<p>Olivier Vu Thanh, Nicolas Gillis, Fabian Lecron</p></summary>
<p>

**Abstract:** In this paper, we propose a new low-rank matrix factorization model dubbed bounded simplex-structured matrix factorization (BSSMF). Given an input matrix $X$ and a factorization rank $r$, BSSMF looks for a matrix $W$ with $r$ columns and a matrix $H$ with $r$ rows such that $X \approx WH$ where the entries in each column of $W$ are bounded, that is, they belong to given intervals, and the columns of $H$ belong to the probability simplex, that is, $H$ is column stochastic. BSSMF generalizes nonnegative matrix factorization (NMF), and simplex-structured matrix factorization (SSMF). BSSMF is particularly well suited when the entries of the input matrix $X$ belong to a given interval; for example when the rows of $X$ represent images, or $X$ is a rating matrix such as in the Netflix and MovieLens data sets where the entries of $X$ belong to the interval $[1,5]$. The simplex-structured matrix $H$ not only leads to an easily understandable decomposition providing a soft clustering of the columns of $X$, but implies that the entries of each column of $WH$ belong to the same intervals as the columns of $W$. In this paper, we first propose a fast algorithm for BSSMF, even in the presence of missing data in $X$. Then we provide identifiability conditions for BSSMF, that is, we provide conditions under which BSSMF admits a unique decomposition, up to trivial ambiguities. Finally, we illustrate the effectiveness of BSSMF on two applications: extraction of features in a set of images, and the matrix completion problem for recommender systems.

</p>
</details>

<details><summary><b>Myopia prediction for adolescents via time-aware deep learning</b>
<a href="https://arxiv.org/abs/2209.12546">arxiv:2209.12546</a>
&#x1F4C8; 2 <br>
<p>Junjia Huang, Wei Ma, Rong Li, Na Zhao, Tao Zhou</p></summary>
<p>

**Abstract:** Background: Quantitative prediction of the adolescents' spherical equivalent based on their variable-length historical vision records.
  Methods: From October 2019 to March 2022, we examined binocular uncorrected visual acuity, axial length, corneal curvature, and axial of 75,172 eyes from 37,586 adolescents aged 6-20 years in Chengdu, China. 80\% samples consist of the training set and the remaining 20\% form the testing set. Time-Aware Long Short-Term Memory was used to quantitatively predict the adolescents' spherical equivalent within two and a half years.
  Result: The mean absolute prediction error on the testing set was 0.273-0.257 for spherical equivalent, ranging from 0.189-0.160 to 0.596-0.473 if we consider different lengths of historical records and different prediction durations.
  Conclusions: Time-Aware Long Short-Term Memory was applied to captured the temporal features in irregularly sampled time series, which is more in line with the characteristics of real data and thus has higher applicability, and helps to identify the progression of myopia earlier. The overall error 0.273 is much smaller than the criterion for clinically acceptable prediction, say 0.75.

</p>
</details>

<details><summary><b>Deep generative model super-resolves spatially correlated multiregional climate data</b>
<a href="https://arxiv.org/abs/2209.12433">arxiv:2209.12433</a>
&#x1F4C8; 2 <br>
<p>Norihiro Oyama, Noriko N. Ishizaki, Satoshi Koide, Hiroaki Yoshida</p></summary>
<p>

**Abstract:** Super-resolving the coarse outputs of global climate simulations, termed downscaling, is crucial in making political and social decisions on systems requiring long-term climate change projections. Existing fast super-resolution techniques, however, have yet to preserve the spatially correlated nature of climatological data, which is particularly important when we address systems with spatial expanse, such as the development of transportation infrastructure. Herein, we show an adversarial network-based machine learning enables us to correctly reconstruct the inter-regional spatial correlations in downscaling with high magnification up to fifty, while maintaining the pixel-wise statistical consistency. Direct comparison with the measured meteorological data of temperature and precipitation distributions reveals that integrating climatologically important physical information is essential for the accurate downscaling, which prompts us to call our approach $π$SRGAN (Physics Informed Super-Resolution Generative Adversarial Network). The present method has a potential application to the inter-regionally consistent assessment of the climate change impact.

</p>
</details>

<details><summary><b>Learning Continuous Control Policies for Information-Theoretic Active Perception</b>
<a href="https://arxiv.org/abs/2209.12427">arxiv:2209.12427</a>
&#x1F4C8; 2 <br>
<p>Pengzhi Yang, Yuhan Liu, Shumon Koga, Arash Asgharivaskasi, Nikolay Atanasov</p></summary>
<p>

**Abstract:** This paper proposes a method for learning continuous control policies for active landmark localization and exploration using an information-theoretic cost. We consider a mobile robot detecting landmarks within a limited sensing range, and tackle the problem of learning a control policy that maximizes the mutual information between the landmark states and the sensor observations. We employ a Kalman filter to convert the partially observable problem in the landmark state to Markov decision process (MDP), a differentiable field of view to shape the reward, and an attention-based neural network to represent the control policy. The approach is further unified with active volumetric mapping to promote exploration in addition to landmark localization. The performance is demonstrated in several simulated landmark localization tasks in comparison with benchmark methods.

</p>
</details>

<details><summary><b>Review for AI-based Open-Circuit Faults Diagnosis Methods in Power Electronics Converters</b>
<a href="https://arxiv.org/abs/2209.14058">arxiv:2209.14058</a>
&#x1F4C8; 1 <br>
<p>Chuang Liu, Lei Kou, Guowei Cai, Zihan Zhao, Zhe Zhang</p></summary>
<p>

**Abstract:** Power electronics converters have been widely used in aerospace system, DC transmission, distributed energy, smart grid and so forth, and the reliability of power electronics converters has been a hotspot in academia and industry. It is of great significance to carry out power electronics converters open-circuit faults monitoring and intelligent fault diagnosis to avoid secondary faults, reduce time and cost of operation and maintenance, and improve the reliability of power electronics system. Firstly, the faults features of power electronic converters are analyzed and summarized. Secondly, some AI-based fault diagnosis methods and application examples in power electronics converters are reviewed, and a fault diagnosis method based on the combination of random forests and transient fault features is proposed for three-phase power electronics converters. Finally, the future research challenges and directions of AI-based fault diagnosis methods are pointed out.

</p>
</details>

<details><summary><b>PearNet: A Pearson Correlation-based Graph Attention Network for Sleep Stage Recognition</b>
<a href="https://arxiv.org/abs/2209.13645">arxiv:2209.13645</a>
&#x1F4C8; 1 <br>
<p>Jianchao Lu, Yuzhe Tian, Shuang Wang, Michael Sheng, Xi Zheng</p></summary>
<p>

**Abstract:** Sleep stage recognition is crucial for assessing sleep and diagnosing chronic diseases. Deep learning models, such as Convolutional Neural Networks and Recurrent Neural Networks, are trained using grid data as input, making them not capable of learning relationships in non-Euclidean spaces. Graph-based deep models have been developed to address this issue when investigating the external relationship of electrode signals across different brain regions. However, the models cannot solve problems related to the internal relationships between segments of electrode signals within a specific brain region. In this study, we propose a Pearson correlation-based graph attention network, called PearNet, as a solution to this problem. Graph nodes are generated based on the spatial-temporal features extracted by a hierarchical feature extraction method, and then the graph structure is learned adaptively to build node connections. Based on our experiments on the Sleep-EDF-20 and Sleep-EDF-78 datasets, PearNet performs better than the state-of-the-art baselines.

</p>
</details>

<details><summary><b>Modeling Polyp Activity of Paragorgia arborea Using Supervised Learning</b>
<a href="https://arxiv.org/abs/2209.13644">arxiv:2209.13644</a>
&#x1F4C8; 1 <br>
<p>Arne Johanson, Sascha Flögel, Wolf-Christian Dullo, Peter Linke, Wilhelm Hasselbring</p></summary>
<p>

**Abstract:** While the distribution patterns of cold-water corals, such as Paragorgia arborea, have received increasing attention in recent studies, little is known about their in situ activity patterns. In this paper, we examine polyp activity in P. arborea using machine learning techniques to analyze high-resolution time series data and photographs obtained from an autonomous lander cluster deployed in the Stjernsund, Norway. An interactive illustration of the models derived in this paper is provided online as supplementary material. We find that the best predictor of the degree of extension of the coral polyps is current direction with a lag of three hours. Other variables that are not directly associated with water currents, such as temperature and salinity, offer much less information concerning polyp activity. Interestingly, the degree of polyp extension can be predicted more reliably by sampling the laminar flows in the water column above the measurement site than by sampling the more turbulent flows in the direct vicinity of the corals. Our results show that the activity patterns of the P. arborea polyps are governed by the strong tidal current regime of the Stjernsund. It appears that P. arborea does not react to shorter changes in the ambient current regime but instead adjusts its behavior in accordance with the large-scale pattern of the tidal cycle itself in order to optimize nutrient uptake.

</p>
</details>

<details><summary><b>DVGAN: Stabilize Wasserstein GAN training for time-domain Gravitational Wave physics</b>
<a href="https://arxiv.org/abs/2209.13592">arxiv:2209.13592</a>
&#x1F4C8; 1 <br>
<p>Tom Dooney, Stefano Bromuri, Lyana Curier</p></summary>
<p>

**Abstract:** Simulating time-domain observations of gravitational wave (GW) detector environments will allow for a better understanding of GW sources, augment datasets for GW signal detection and help in characterizing the noise of the detectors, leading to better physics. This paper presents a novel approach to simulating fixed-length time-domain signals using a three-player Wasserstein Generative Adversarial Network (WGAN), called DVGAN, that includes an auxiliary discriminator that discriminates on the derivatives of input signals. An ablation study is used to compare the effects of including adversarial feedback from an auxiliary derivative discriminator with a vanilla two-player WGAN. We show that discriminating on derivatives can stabilize the learning of GAN components on 1D continuous signals during their training phase. This results in smoother generated signals that are less distinguishable from real samples and better capture the distributions of the training data. DVGAN is also used to simulate real transient noise events captured in the advanced LIGO GW detector.

</p>
</details>

<details><summary><b>Experimental validation of machine-learning based spectral-spatial power evolution shaping using Raman amplifiers</b>
<a href="https://arxiv.org/abs/2209.13401">arxiv:2209.13401</a>
&#x1F4C8; 1 <br>
<p>Mehran Soltani, Francesco Da Ros, Andrea Carena, Darko Zibar</p></summary>
<p>

**Abstract:** We experimentally validate a real-time machine learning framework, capable of controlling the pump power values of Raman amplifiers to shape the signal power evolution in two-dimensions (2D): frequency and fiber distance. In our setup, power values of four first-order counter-propagating pumps are optimized to achieve the desired 2D power profile. The pump power optimization framework includes a convolutional neural network (CNN) followed by differential evolution (DE) technique, applied online to the amplifier setup to automatically achieve the target 2D power profiles. The results on achievable 2D profiles show that the framework is able to guarantee very low maximum absolute error (MAE) (<0.5 dB) between the obtained and the target 2D profiles. Moreover, the framework is tested in a multi-objective design scenario where the goal is to achieve the 2D profiles with flat gain levels at the end of the span, jointly with minimum spectral excursion over the entire fiber length. In this case, the experimental results assert that for 2D profiles with the target flat gain levels, the DE obtains less than 1 dB maximum gain deviation, when the setup is not physically limited in the pump power values. The simulation results also prove that with enough pump power available, better gain deviation (less than 0.6 dB) for higher target gain levels is achievable.

</p>
</details>

<details><summary><b>Ki-67 Index Measurement in Breast Cancer Using Digital Image Analysis</b>
<a href="https://arxiv.org/abs/2209.13155">arxiv:2209.13155</a>
&#x1F4C8; 1 <br>
<p>Hsiang-Wei Huang, Wen-Tsung Huang, Hsun-Heng Tsai</p></summary>
<p>

**Abstract:** Ki-67 is a nuclear protein that can be produced during cell proliferation. The Ki67 index is a valuable prognostic variable in several kinds of cancer. In breast cancer, the index is even routinely checked in many patients. Currently, pathologists use the immunohistochemistry method to calculate the percentage of Ki-67 positive malignant cells as Ki-67 index. The higher score usually means more aggressive tumor behavior. In clinical practice, the measurement of Ki-67 index relies on visual identifying method and manual counting. However, visual and manual assessment method is timeconsuming and leads to poor reproducibility because of different scoring standards or limited tumor area under assessment. Here, we use digital image processing technics including image binarization and image morphological operations to create a digital image analysis method to interpretate Ki-67 index. Then, 10 breast cancer specimens are used as validation with high accuracy (correlation efficiency r = 0.95127). With the assistance of digital image analysis, pathologists can interpretate the Ki67 index more efficiently, precisely with excellent reproducibility.

</p>
</details>

<details><summary><b>BayesNetCNN: incorporating uncertainty in neural networks for image-based classification tasks</b>
<a href="https://arxiv.org/abs/2209.13096">arxiv:2209.13096</a>
&#x1F4C8; 1 <br>
<p>Matteo Ferrante, Tommaso Boccato, Nicola Toschi</p></summary>
<p>

**Abstract:** The willingness to trust predictions formulated by automatic algorithms is key in a vast number of domains. However, a vast number of deep architectures are only able to formulate predictions without an associated uncertainty. In this paper, we propose a method to convert a standard neural network into a Bayesian neural network and estimate the variability of predictions by sampling different networks similar to the original one at each forward pass. We couple our methods with a tunable rejection-based approach that employs only the fraction of the dataset that the model is able to classify with an uncertainty below a user-set threshold. We test our model in a large cohort of brain images from Alzheimer's Disease patients, where we tackle discrimination of patients from healthy controls based on morphometric images only. We demonstrate how combining the estimated uncertainty with a rejection-based approach increases classification accuracy from 0.86 to 0.95 while retaining 75% of the test set. In addition, the model can select cases to be recommended for manual evaluation based on excessive uncertainty. We believe that being able to estimate the uncertainty of a prediction, along with tools that can modulate the behavior of the network to a degree of confidence that the user is informed about (and comfortable with) can represent a crucial step in the direction of user compliance and easier integration of deep learning tools into everyday tasks currently performed by human operators.

</p>
</details>

<details><summary><b>Efficient Noise Filtration of Images by Low-Rank Singular Vector Approximations of Geodesics' Gramian Matrix</b>
<a href="https://arxiv.org/abs/2209.13094">arxiv:2209.13094</a>
&#x1F4C8; 1 <br>
<p>Kelum Gajamannage, Yonggi Park, Sunil Mathur</p></summary>
<p>

**Abstract:** Modern society is interested in capturing high-resolution and fine-quality images due to the surge of sophisticated cameras. However, the noise contamination in the images not only inferior people's expectations but also conversely affects the subsequent processes if such images are utilized in computer vision tasks such as remote sensing, object tracking, etc. Even though noise filtration plays an essential role, real-time processing of a high-resolution image is limited by the hardware limitations of the image-capturing instruments. Geodesic Gramian Denoising (GGD) is a manifold-based noise filtering method that we introduced in our past research which utilizes a few prominent singular vectors of the geodesics' Gramian matrix for the noise filtering process. The applicability of GDD is limited as it encounters $\mathcal{O}(n^6)$ when denoising a given image of size $n\times n$ since GGD computes the prominent singular vectors of a $n^2 \times n^2$ data matrix that is implemented by singular value decomposition (SVD). In this research, we increase the efficiency of our GGD framework by replacing its SVD step with four diverse singular vector approximation techniques. Here, we compare both the computational time and the noise filtering performance between the four techniques integrated into GGD.

</p>
</details>

<details><summary><b>Static Knowledge vs. Dynamic Argumentation: A Dual Theory Based on Kripke Semantics</b>
<a href="https://arxiv.org/abs/2209.13082">arxiv:2209.13082</a>
&#x1F4C8; 1 <br>
<p>Xinyu Wang, Momoka Fujieda</p></summary>
<p>

**Abstract:** This paper establishes a dual theory about knowledge and argumentation. Our idea is rooted at both epistemic logic and argumentation theory, and we aim to merge these two fields, not just in a superficial way but to thoroughly disclose the intrinsic relevance between knowledge and argumentation. Specifically, we define epistemic Kripke models and argument Kripke models as a dual pair, and then work out a two-way generation method between these two types of Kripke models. Such generation is rigorously justified by a duality theorem on modal formulae's invariance. We also provide realistic examples to demonstrate our generation, through which our framework's practical utility gets strongly advocated. We finally propose a philosophical thesis that knowledge is essentially dynamic, and we draw certain connection to Maxwell's demon as well as the well-known proverb "knowledge is power".

</p>
</details>

<details><summary><b>Accelerating the Genetic Algorithm for Large-scale Traveling Salesman Problems by Cooperative Coevolutionary Pointer Network with Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.13077">arxiv:2209.13077</a>
&#x1F4C8; 1 <br>
<p>Rui Zhong, Enzhi Zhang, Masaharu Munetomo</p></summary>
<p>

**Abstract:** In this paper, we propose a two-stage optimization strategy for solving the Large-scale Traveling Salesman Problems (LSTSPs) named CCPNRL-GA. First, we hypothesize that the participation of a well-performed individual as an elite can accelerate the convergence of optimization. Based on this hypothesis, in the first stage, we cluster the cities and decompose the LSTSPs into multiple subcomponents, and each subcomponent is optimized with a reusable Pointer Network (PtrNet). After subcomponents optimization, we combine all sub-tours to form a valid solution, this solution joins the second stage of optimization with GA. We validate the performance of our proposal on 10 LSTSPs and compare it with traditional EAs. Experimental results show that the participation of an elite individual can greatly accelerate the optimization of LSTSPs, and our proposal has broad prospects for dealing with LSTSPs.

</p>
</details>

<details><summary><b>Effective Invertible Arbitrary Image Rescaling</b>
<a href="https://arxiv.org/abs/2209.13055">arxiv:2209.13055</a>
&#x1F4C8; 1 <br>
<p>Zhihong Pan, Baopu Li, Dongliang He, Wenhao Wu, Errui Ding</p></summary>
<p>

**Abstract:** Great successes have been achieved using deep learning techniques for image super-resolution (SR) with fixed scales. To increase its real world applicability, numerous models have also been proposed to restore SR images with arbitrary scale factors, including asymmetric ones where images are resized to different scales along horizontal and vertical directions. Though most models are only optimized for the unidirectional upscaling task while assuming a predefined downscaling kernel for low-resolution (LR) inputs, recent models based on Invertible Neural Networks (INN) are able to increase upscaling accuracy significantly by optimizing the downscaling and upscaling cycle jointly. However, limited by the INN architecture, it is constrained to fixed integer scale factors and requires one model for each scale. Without increasing model complexity, a simple and effective invertible arbitrary rescaling network (IARN) is proposed to achieve arbitrary image rescaling by training only one model in this work. Using innovative components like position-aware scale encoding and preemptive channel splitting, the network is optimized to convert the non-invertible rescaling cycle to an effectively invertible process. It is shown to achieve a state-of-the-art (SOTA) performance in bidirectional arbitrary rescaling without compromising perceptual quality in LR outputs. It is also demonstrated to perform well on tests with asymmetric scales using the same network architecture.

</p>
</details>

<details><summary><b>Electron energy loss spectroscopy database synthesis and automation of core-loss edge recognition by deep-learning neural networks</b>
<a href="https://arxiv.org/abs/2209.13026">arxiv:2209.13026</a>
&#x1F4C8; 1 <br>
<p>Lingli Kong, Zhengran Ji, Huolin L. Xin</p></summary>
<p>

**Abstract:** The ionization edges encoded in the electron energy loss spectroscopy (EELS) spectra enable advanced material analysis including composition analyses and elemental quantifications. The development of the parallel EELS instrument and fast, sensitive detectors have greatly improved the acquisition speed of EELS spectra. However, the traditional way of core-loss edge recognition is experience based and human labor dependent, which limits the processing speed. So far, the low signal-noise ratio and the low jump ratio of the core-loss edges on the raw EELS spectra have been challenging for the automation of edge recognition. In this work, a convolutional-bidirectional long short-term memory neural network (CNN-BiLSTM) is proposed to automate the detection and elemental identification of core-loss edges from raw spectra. An EELS spectral database is synthesized by using our forward model to assist in the training and validation of the neural network. To make the synthesized spectra resemble the real spectra, we collected a large library of experimentally acquired EELS core edges. In synthesize the training library, the edges are modeled by fitting the multi-gaussian model to the real edges from experiments, and the noise and instrumental imperfectness are simulated and added. The well-trained CNN-BiLSTM network is tested against both the simulated spectra and real spectra collected from experiments. The high accuracy of the network, 94.9 %, proves that, without complicated preprocessing of the raw spectra, the proposed CNN-BiLSTM network achieves the automation of core-loss edge recognition for EELS spectra with high accuracy.

</p>
</details>

<details><summary><b>Environmental and Social Sustainability of Creative-Ai</b>
<a href="https://arxiv.org/abs/2209.12879">arxiv:2209.12879</a>
&#x1F4C8; 1 <br>
<p>André Holzapfel, Petra Jääskeläinen, Anna-Kaisa Kaila</p></summary>
<p>

**Abstract:** The recent developments of artificial intelligence increase its capability for the creation of arts in both largely autonomous and collaborative contexts. In both contexts, Ai aims to imitate, combine, and extend existing artistic styles, and can transform creative practices. In our ongoing research, we investigate such Creative-Ai from sustainability and ethical perspectives. The two main focus areas are understanding the environmental sustainability aspects (material, practices) in the context of artistic processes that involve Creative-Ai, and ethical issues related to who gets to be involved in the creation process (power, authorship, ownership). This paper provides an outline of our ongoing research in these two directions. We will present our interdisciplinary approach, which combines interviews, workshops, online ethnography, and energy measurements, to address our research questions: How is Creative-Ai currently used by artist communities, and which future applications do artists imagine? When Ai is applied to creating art, how might it impact the economy and environment? And, how can answers to these questions guide requirements for intellectual property regimes for Creative-Ai?

</p>
</details>

<details><summary><b>Towards Direct Comparison of Community Structures in Social Networks</b>
<a href="https://arxiv.org/abs/2209.12841">arxiv:2209.12841</a>
&#x1F4C8; 1 <br>
<p>Soumita Das, Anupam Biswas</p></summary>
<p>

**Abstract:** Community detection algorithms are in general evaluated by comparing evaluation metric values for the communities obtained with different algorithms. The evaluation metrics that are used for measuring quality of the communities incorporate the topological information of entities like connectivity of the nodes within or outside the communities. However, while comparing the metric values it loses direct involvement of topological information of the communities in the comparison process. In this paper, a direct comparison approach is proposed where topological information of the communities obtained with two algorithms are compared directly. A quality measure namely \emph{Topological Variance (TV)} is designed based on direct comparison of topological information of the communities. Considering the newly designed quality measure, two ranking schemes are developed. The efficacy of proposed quality metric as well as the ranking scheme is studied with eight widely used real-world datasets and six community detection algorithms.

</p>
</details>

<details><summary><b>Abductive forgetting</b>
<a href="https://arxiv.org/abs/2209.12825">arxiv:2209.12825</a>
&#x1F4C8; 1 <br>
<p>Paolo Liberatore</p></summary>
<p>

**Abstract:** Abductive forgetting is removing variables from a logical formula while maintaining its abductive explanations. It is defined in either of two ways, depending on its intended application. Both differ from the usual forgetting, which maintains consequences rather than explanations. Differently from that, abductive forgetting from a propositional formula may not be expressed by any propositional formula. A necessary and sufficient condition tells when it is. Checking this condition is ¶{3}-complete, and is in ¶{4} if minimality of explanations is required. A way to guarantee expressibility of abductive forgetting is to switch from propositional to default logic. Another is to introduce new variables.

</p>
</details>

<details><summary><b>EasyRec: An easy-to-use, extendable and efficient framework for building industrial recommendation systems</b>
<a href="https://arxiv.org/abs/2209.12766">arxiv:2209.12766</a>
&#x1F4C8; 1 <br>
<p>Mengli Cheng, Yue Gao, Guoqiang Liu, HongSheng Jin, Xiaowen Zhang</p></summary>
<p>

**Abstract:** We present EasyRec, an easy-to-use, extendable and efficient recommendation framework for building industrial recommendation systems. Our EasyRec framework is superior in the following aspects: first, EasyRec adopts a modular and pluggable design pattern to reduce the efforts to build custom models; second, EasyRec implements hyper-parameter optimization and feature selection algorithms to improve model performance automatically; third, EasyRec applies online learning to fast adapt to the ever-changing data distribution. The code is released: https://github.com/alibaba/EasyRec.

</p>
</details>

<details><summary><b>Just-In-Time Learning for Operational Risk Assessment in Power Grids</b>
<a href="https://arxiv.org/abs/2209.12762">arxiv:2209.12762</a>
&#x1F4C8; 1 <br>
<p>Oliver Stover, Pranav Karve, Sankaran Mahadevan, Wenbo Chen, Haoruo Zhao, Mathieu Tanneau, Pascal Van Hentenryck</p></summary>
<p>

**Abstract:** In a grid with a significant share of renewable generation, operators will need additional tools to evaluate the operational risk due to the increased volatility in load and generation. The computational requirements of the forward uncertainty propagation problem, which must solve numerous security-constrained economic dispatch (SCED) optimizations, is a major barrier for such real-time risk assessment. This paper proposes a Just-In-Time Risk Assessment Learning Framework (JITRALF) as an alternative. JITRALF trains risk surrogates, one for each hour in the day, using Machine Learning (ML) to predict the quantities needed to estimate risk, without explicitly solving the SCED problem. This significantly reduces the computational burden of the forward uncertainty propagation and allows for fast, real-time risk estimation. The paper also proposes a novel, asymmetric loss function and shows that models trained using the asymmetric loss perform better than those using symmetric loss functions. JITRALF is evaluated on the French transmission system for assessing the risk of insufficient operating reserves, the risk of load shedding, and the expected operating cost.

</p>
</details>

<details><summary><b>Machine Learning for Improved Gas Network Models in Coordinated Energy Systems</b>
<a href="https://arxiv.org/abs/2209.12731">arxiv:2209.12731</a>
&#x1F4C8; 1 <br>
<p>Adriano Arrigo, Mihály Dolányi, Kenneth Bruninx, Jean-François Toubeau</p></summary>
<p>

**Abstract:** The current energy transition promotes the convergence of operation between the power and natural gas systems. In that direction, it becomes paramount to improve the modeling of non-convex natural gas flow dynamics within the coordinated power and gas dispatch. In this work, we propose a neural-network-constrained optimization method which includes a regression model of the Weymouth equation, based on supervised machine learning. The Weymouth equation links gas flow to inlet and outlet pressures for each pipeline via a quadratic equality, which is captured by a neural network. The latter is encoded via a tractable mixed-integer linear program into the set of constraints. In addition, our proposed framework is capable of considering bidirectionality without having recourse to complex and potentially inaccurate convexification approaches. We further enhance our model by introducing a reformulation of the activation function, which improves the computational efficiency. An extensive numerical study based on the real-life Belgian power and gas systems shows that the proposed methodology yields promising results in terms of accuracy and tractability.

</p>
</details>

<details><summary><b>Power System Anomaly Detection and Classification Utilizing WLS-EKF State Estimation and Machine Learning</b>
<a href="https://arxiv.org/abs/2209.12629">arxiv:2209.12629</a>
&#x1F4C8; 1 <br>
<p>Sajjad Asefi, Mile Mitrovic, Dragan Ćetenović, Victor Levi, Elena Gryazina, Vladimir Terzija</p></summary>
<p>

**Abstract:** Power system state estimation is being faced with different types of anomalies. These might include bad data caused by gross measurement errors or communication system failures. Sudden changes in load or generation can be considered as anomaly depending on the implemented state estimation method. Additionally, considering power grid as a cyber physical system, state estimation becomes vulnerable to false data injection attacks. The existing methods for anomaly classification cannot accurately classify (discriminate between) the above-mentioned three types of anomalies, especially when it comes to discrimination between sudden load changes and false data injection attacks. This paper presents a new algorithm for detecting anomaly presence, classifying the anomaly type and identifying the origin of the anomaly, i.e., measurements that contain gross errors in case of bad data, or bus(es) associated with load(s) experiencing a sudden change, or state variables targeted by false data injection attack. The algorithm combines analytical and machine learning (ML) approaches. The first stage exploits an analytical approach to detect anomaly presence by combining $χ^2$-test and anomaly detection index. The second stage utilizes ML for the classification of anomaly type and identification of its origin, with particular reference to discrimination between sudden load changes and false data injection attacks. The proposed ML based method is trained to be independent of the network configuration which eliminates retraining of the algorithm after network topology changes. The results obtained by implementing the proposed algorithm on IEEE 14 bus test system demonstrate the accuracy and effectiveness of the proposed algorithm.

</p>
</details>

<details><summary><b>Multi-Hour Ahead Dst Index Prediction Using Multi-Fidelity Boosted Neural Networks</b>
<a href="https://arxiv.org/abs/2209.12571">arxiv:2209.12571</a>
&#x1F4C8; 1 <br>
<p>A. Hu, E. Camporeale, B. Swiger</p></summary>
<p>

**Abstract:** The Disturbance storm time (Dst) index has been widely used as a proxy for the ring current intensity, and therefore as a measure of geomagnetic activity. It is derived by measurements from four ground magnetometers in the geomagnetic equatorial regions.
  We present a new model for predicting $Dst$ with a lead time between 1 and 6 hours. The model is first developed using a Gated Recurrent Unit (GRU) network that is trained using solar wind parameters. The uncertainty of the $Dst$ model is then estimated by using the ACCRUE method [Camporeale et al. 2021]. Finally, a multi-fidelity boosting method is developed in order to enhance the accuracy of the model and reduce its associated uncertainty. It is shown that the developed model can predict $Dst$ 6 hours ahead with a root-mean-square-error (RMSE) of 13.54 $\mathrm{nT}$. This is significantly better than the persistence model and a simple GRU model.

</p>
</details>

<details><summary><b>Neural-FacTOR: Neural Representation Learning for Website Fingerprinting Attack over TOR Anonymity</b>
<a href="https://arxiv.org/abs/2209.12482">arxiv:2209.12482</a>
&#x1F4C8; 1 <br>
<p>Haili Sun, Yan Huang, Lansheng Han, Xiang Long, Hongle Liu, Chunjie Zhou</p></summary>
<p>

**Abstract:** TOR (The Onion Router) network is a widely used open source anonymous communication tool, the abuse of TOR makes it difficult to monitor the proliferation of online crimes such as to access criminal websites. Most existing approches for TOR network de-anonymization heavily rely on manually extracted features resulting in time consuming and poor performance. To tackle the shortcomings, this paper proposes a neural representation learning approach to recognize website fingerprint based on classification algorithm. We constructed a new website fingerprinting attack model based on convolutional neural network (CNN) with dilation and causal convolution, which can improve the perception field of CNN as well as capture the sequential characteristic of input data. Experiments on three mainstream public datasets show that the proposed model is robust and effective for the website fingerprint classification and improves the accuracy by 12.21% compared with the state-of-the-art methods.

</p>
</details>

<details><summary><b>Learned Force Fields Are Ready For Ground State Catalyst Discovery</b>
<a href="https://arxiv.org/abs/2209.12466">arxiv:2209.12466</a>
&#x1F4C8; 1 <br>
<p>Michael Schaarschmidt, Morgane Riviere, Alex M. Ganose, James S. Spencer, Alexander L. Gaunt, James Kirkpatrick, Simon Axelrod, Peter W. Battaglia, Jonathan Godwin</p></summary>
<p>

**Abstract:** We present evidence that learned density functional theory (``DFT'') force fields are ready for ground state catalyst discovery. Our key finding is that relaxation using forces from a learned potential yields structures with similar or lower energy to those relaxed using the RPBE functional in over 50\% of evaluated systems, despite the fact that the predicted forces differ significantly from the ground truth. This has the surprising implication that learned potentials may be ready for replacing DFT in challenging catalytic systems such as those found in the Open Catalyst 2020 dataset. Furthermore, we show that a force field trained on a locally harmonic energy surface with the same minima as a target DFT energy is also able to find lower or similar energy structures in over 50\% of cases. This ``Easy Potential'' converges in fewer steps than a standard model trained on true energies and forces, which further accelerates calculations. Its success illustrates a key point: learned potentials can locate energy minima even when the model has high force errors. The main requirement for structure optimisation is simply that the learned potential has the correct minima. Since learned potentials are fast and scale linearly with system size, our results open the possibility of quickly finding ground states for large systems.

</p>
</details>

<details><summary><b>Shuffle-QUDIO: accelerate distributed VQE with trainability enhancement and measurement reduction</b>
<a href="https://arxiv.org/abs/2209.12454">arxiv:2209.12454</a>
&#x1F4C8; 1 <br>
<p>Yang Qian, Yuxuan Du, Dacheng Tao</p></summary>
<p>

**Abstract:** The variational quantum eigensolver (VQE) is a leading strategy that exploits noisy intermediate-scale quantum (NISQ) machines to tackle chemical problems outperforming classical approaches. To gain such computational advantages on large-scale problems, a feasible solution is the QUantum DIstributed Optimization (QUDIO) scheme, which partitions the original problem into $K$ subproblems and allocates them to $K$ quantum machines followed by the parallel optimization. Despite the provable acceleration ratio, the efficiency of QUDIO may heavily degrade by the synchronization operation. To conquer this issue, here we propose Shuffle-QUDIO to involve shuffle operations into local Hamiltonians during the quantum distributed optimization. Compared with QUDIO, Shuffle-QUDIO significantly reduces the communication frequency among quantum processors and simultaneously achieves better trainability. Particularly, we prove that Shuffle-QUDIO enables a faster convergence rate over QUDIO. Extensive numerical experiments are conducted to verify that Shuffle-QUDIO allows both a wall-clock time speedup and low approximation error in the tasks of estimating the ground state energy of molecule. We empirically demonstrate that our proposal can be seamlessly integrated with other acceleration techniques, such as operator grouping, to further improve the efficacy of VQE.

</p>
</details>

<details><summary><b>Truth and Preferences -- A Game Approach for Qualitative Choice Logic</b>
<a href="https://arxiv.org/abs/2209.12777">arxiv:2209.12777</a>
&#x1F4C8; 0 <br>
<p>Robert Freiman, Michael Bernreiter</p></summary>
<p>

**Abstract:** In this paper, we introduce game-theoretic semantics (GTS) for Qualitative Choice Logic (QCL), which, in order to express preferences, extends classical propositional logic with an additional connective called ordered disjunction. Firstly, we demonstrate that game semantics can capture existing degree-based semantics for QCL in a natural way. Secondly, we show that game semantics can be leveraged to derive new semantics for the language of QCL. In particular, we present a new semantics that makes use of GTS negation and, by doing so, avoids problems with negation in existing QCL-semantics.

</p>
</details>

<details><summary><b>Improving Image Clustering through Sample Ranking and Its Application to remote--sensing images</b>
<a href="https://arxiv.org/abs/2209.12621">arxiv:2209.12621</a>
&#x1F4C8; 0 <br>
<p>Qinglin Li, Guoping Qiu</p></summary>
<p>

**Abstract:** Image clustering is a very useful technique that is widely applied to various areas, including remote sensing. Recently, visual representations by self-supervised learning have greatly improved the performance of image clustering. To further improve the well-trained clustering models, this paper proposes a novel method by first ranking samples within each cluster based on the confidence in their belonging to the current cluster and then using the ranking to formulate a weighted cross-entropy loss to train the model. For ranking the samples, we developed a method for computing the likelihood of samples belonging to the current clusters based on whether they are situated in densely populated neighborhoods, while for training the model, we give a strategy for weighting the ranked samples. We present extensive experimental results that demonstrate that the new technique can be used to improve the State-of-the-Art image clustering models, achieving accuracy performance gains ranging from $2.1\%$ to $15.9\%$. Performing our method on a variety of datasets from remote sensing, we show that our method can be effectively applied to remote--sensing images.

</p>
</details>

<details><summary><b>Generating Compressed Combinatory Proof Structures -- An Approach to Automated First-Order Theorem Proving</b>
<a href="https://arxiv.org/abs/2209.12592">arxiv:2209.12592</a>
&#x1F4C8; 0 <br>
<p>Christoph Wernhard</p></summary>
<p>

**Abstract:** Representing a proof tree by a combinator term that reduces to the tree lets subtle forms of duplication within the tree materialize as duplicated subterms of the combinator term. In a DAG representation of the combinator term these straightforwardly factor into shared subgraphs. To search for proofs, combinator terms can be enumerated, like clausal tableaux, interwoven with unification of formulas that are associated with nodes of the enumerated structures. To restrict the search space, the enumeration can be based on proof schemas defined as parameterized combinator terms. We introduce here this "combinator term as proof structure" approach to automated first-order proving, present an implementation and first experimental results. The approach builds on a term view of proof structures rooted in condensed detachment and the connection method. It realizes features known from the connection structure calculus, which has not been implemented so far.

</p>
</details>

<details><summary><b>Convergence rate of the (1+1)-evolution strategy on locally strongly convex functions with lipschitz continuous gradient and their monotonic transformations</b>
<a href="https://arxiv.org/abs/2209.12467">arxiv:2209.12467</a>
&#x1F4C8; 0 <br>
<p>Daiki Morinaga, Kazuto Fukuchi, Jun Sakuma, Youhei Akimoto</p></summary>
<p>

**Abstract:** Evolution strategy (ES) is one of promising classes of algorithms for black-box continuous optimization. Despite its broad successes in applications, theoretical analysis on the speed of its convergence is limited on convex quadratic functions and their monotonic transformation. In this study, an upper bound and a lower bound of the rate of linear convergence of the (1+1)-ES on locally $L$-strongly convex functions with $U$-Lipschitz continuous gradient are derived as $\exp\left(-Ω_{d\to\infty}\left(\frac{L}{d\cdot U}\right)\right)$ and $\exp\left(-\frac1d\right)$, respectively. Notably, any prior knowledge on the mathematical properties of the objective function such as Lipschitz constant is not given to the algorithm, whereas the existing analyses of derivative-free optimization algorithms require them.

</p>
</details>


{% endraw %}
Prev: [2022.09.25]({{ '/2022/09/25/2022.09.25.html' | relative_url }})  Next: [2022.09.27]({{ '/2022/09/27/2022.09.27.html' | relative_url }})