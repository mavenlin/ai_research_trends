## Summary for 2021-05-14, created on 2021-12-21


<details><summary><b>Long Short-term Memory RNN</b>
<a href="https://arxiv.org/abs/2105.06756">arxiv:2105.06756</a>
&#x1F4C8; 69 <br>
<p>Christian Bakke Vennerød, Adrian Kjærran, Erling Stray Bugge</p></summary>
<p>

**Abstract:** This paper is based on a machine learning project at the Norwegian University of Science and Technology, fall 2020. The project was initiated with a literature review on the latest developments within time-series forecasting methods in the scientific community over the past five years. The paper summarizes the essential aspects of this research. Furthermore, in this paper, we introduce an LSTM cell's architecture, and explain how different components go together to alter the cell's memory and predict the output. Also, the paper provides the necessary formulas and foundations to calculate a forward iteration through an LSTM. Then, the paper refers to some practical applications and research that emphasize the strength and weaknesses of LSTMs, shown within the time-series domain and the natural language processing (NLP) domain. Finally, alternative statistical methods for time series predictions are highlighted, where the paper outline ARIMA and exponential smoothing. Nevertheless, as LSTMs can be viewed as a complex architecture, the paper assumes that the reader has some knowledge of essential machine learning aspects, such as the multi-layer perceptron, activation functions, overfitting, backpropagation, bias, over- and underfitting, and more.

</p>
</details>

<details><summary><b>Priors in Bayesian Deep Learning: A Review</b>
<a href="https://arxiv.org/abs/2105.06868">arxiv:2105.06868</a>
&#x1F4C8; 34 <br>
<p>Vincent Fortuin</p></summary>
<p>

**Abstract:** While the choice of prior is one of the most critical parts of the Bayesian inference workflow, recent Bayesian deep learning models have often fallen back on vague priors, such as standard Gaussians. In this review, we highlight the importance of prior choices for Bayesian deep learning and present an overview of different priors that have been proposed for (deep) Gaussian processes, variational autoencoders, and Bayesian neural networks. We also outline different methods of learning priors for these models from data. We hope to motivate practitioners in Bayesian deep learning to think more carefully about the prior specification for their models and to provide them with some inspiration in this regard.

</p>
</details>

<details><summary><b>Learning a Universal Template for Few-shot Dataset Generalization</b>
<a href="https://arxiv.org/abs/2105.07029">arxiv:2105.07029</a>
&#x1F4C8; 31 <br>
<p>Eleni Triantafillou, Hugo Larochelle, Richard Zemel, Vincent Dumoulin</p></summary>
<p>

**Abstract:** Few-shot dataset generalization is a challenging variant of the well-studied few-shot classification problem where a diverse training set of several datasets is given, for the purpose of training an adaptable model that can then learn classes from new datasets using only a few examples. To this end, we propose to utilize the diverse training set to construct a universal template: a partial model that can define a wide array of dataset-specialized models, by plugging in appropriate components. For each new few-shot classification problem, our approach therefore only requires inferring a small number of parameters to insert into the universal template. We design a separate network that produces an initialization of those parameters for each given task, and we then fine-tune its proposed initialization via a few steps of gradient descent. Our approach is more parameter-efficient, scalable and adaptable compared to previous methods, and achieves the state-of-the-art on the challenging Meta-Dataset benchmark.

</p>
</details>

<details><summary><b>Prescriptive Process Monitoring for Cost-Aware Cycle Time Reduction</b>
<a href="https://arxiv.org/abs/2105.07111">arxiv:2105.07111</a>
&#x1F4C8; 23 <br>
<p>Zahra Dasht Bozorgi, Irene Teinemaa, Marlon Dumas, Marcello La Rosa, Artem Polyvyanyy</p></summary>
<p>

**Abstract:** Reducing cycle time is a recurrent concern in the field of business process management. Depending on the process, various interventions may be triggered to reduce the cycle time of a case, for example, using a faster shipping service in an order-to-delivery process or giving a phone call to a customer to obtain missing information rather than waiting passively. Each of these interventions comes with a cost. This paper tackles the problem of determining if and when to trigger a time-reducing intervention in a way that maximizes the total net gain. The paper proposes a prescriptive process monitoring method that uses orthogonal random forest models to estimate the causal effect of triggering a time-reducing intervention for each ongoing case of a process. Based on this causal effect estimate, the method triggers interventions according to a user-defined policy. The method is evaluated on two real-life logs.

</p>
</details>

<details><summary><b>Do Context-Aware Translation Models Pay the Right Attention?</b>
<a href="https://arxiv.org/abs/2105.06977">arxiv:2105.06977</a>
&#x1F4C8; 22 <br>
<p>Kayo Yin, Patrick Fernandes, Danish Pruthi, Aditi Chaudhary, André F. T. Martins, Graham Neubig</p></summary>
<p>

**Abstract:** Context-aware machine translation models are designed to leverage contextual information, but often fail to do so. As a result, they inaccurately disambiguate pronouns and polysemous words that require context for resolution. In this paper, we ask several questions: What contexts do human translators use to resolve ambiguous words? Are models paying large amounts of attention to the same context? What if we explicitly train them to do so? To answer these questions, we introduce SCAT (Supporting Context for Ambiguous Translations), a new English-French dataset comprising supporting context words for 14K translations that professional translators found useful for pronoun disambiguation. Using SCAT, we perform an in-depth analysis of the context used to disambiguate, examining positional and lexical characteristics of the supporting words. Furthermore, we measure the degree of alignment between the model's attention scores and the supporting context from SCAT, and apply a guided attention strategy to encourage agreement between the two.

</p>
</details>

<details><summary><b>QAConv: Question Answering on Informative Conversations</b>
<a href="https://arxiv.org/abs/2105.06912">arxiv:2105.06912</a>
&#x1F4C8; 22 <br>
<p>Chien-Sheng Wu, Andrea Madotto, Wenhao Liu, Pascale Fung, Caiming Xiong</p></summary>
<p>

**Abstract:** This paper introduces QAConv, a new question answering (QA) dataset that uses conversations as a knowledge source. We focus on informative conversations including business emails, panel discussions, and work channels. Unlike open-domain and task-oriented dialogues, these conversations are usually long, complex, asynchronous, and involve strong domain knowledge. In total, we collect 34,204 QA pairs, including span-based, free-form, and unanswerable questions, from 10,259 selected conversations with both human-written and machine-generated questions. We segment long conversations into chunks, and use a question generator and dialogue summarizer as auxiliary tools to collect multi-hop questions. The dataset has two testing scenarios, chunk mode and full mode, depending on whether the grounded chunk is provided or retrieved from a large conversational pool. Experimental results show that state-of-the-art QA systems trained on existing QA datasets have limited zero-shot ability and tend to predict our questions as unanswerable. Fine-tuning such systems on our corpus can achieve significant improvement up to 23.6% and 13.6% in both chunk mode and full mode, respectively.

</p>
</details>

<details><summary><b>Exploiting Aliasing for Manga Restoration</b>
<a href="https://arxiv.org/abs/2105.06830">arxiv:2105.06830</a>
&#x1F4C8; 10 <br>
<p>Minshan Xie, Menghan Xia, Tien-Tsin Wong</p></summary>
<p>

**Abstract:** As a popular entertainment art form, manga enriches the line drawings details with bitonal screentones. However, manga resources over the Internet usually show screentone artifacts because of inappropriate scanning/rescaling resolution. In this paper, we propose an innovative two-stage method to restore quality bitonal manga from degraded ones. Our key observation is that the aliasing induced by downsampling bitonal screentones can be utilized as informative clues to infer the original resolution and screentones. First, we predict the target resolution from the degraded manga via the Scale Estimation Network (SE-Net) with spatial voting scheme. Then, at the target resolution, we restore the region-wise bitonal screentones via the Manga Restoration Network (MR-Net) discriminatively, depending on the degradation degree. Specifically, the original screentones are directly restored in pattern-identifiable regions, and visually plausible screentones are synthesized in pattern-agnostic regions. Quantitative evaluation on synthetic data and visual assessment on real-world cases illustrate the effectiveness of our method.

</p>
</details>

<details><summary><b>Analyzing Images for Music Recommendation</b>
<a href="https://arxiv.org/abs/2105.07135">arxiv:2105.07135</a>
&#x1F4C8; 9 <br>
<p>Anant Baijal, Vivek Agarwal, Danny Hyun</p></summary>
<p>

**Abstract:** Experiencing images with suitable music can greatly enrich the overall user experience. The proposed image analysis method treats an artwork image differently from a photograph image. Automatic image classification is performed using deep-learning based models. An illustrative analysis showcasing the ability of our deep-models to inherently learn and utilize perceptually relevant features when classifying artworks is also presented. The Mean Opinion Score (MOS) obtained from subjective assessments of the respective image and recommended music pairs supports the effectiveness of our approach.

</p>
</details>

<details><summary><b>Verification of Image-based Neural Network Controllers Using Generative Models</b>
<a href="https://arxiv.org/abs/2105.07091">arxiv:2105.07091</a>
&#x1F4C8; 8 <br>
<p>Sydney M. Katz, Anthony L. Corso, Christopher A. Strong, Mykel J. Kochenderfer</p></summary>
<p>

**Abstract:** Neural networks are often used to process information from image-based sensors to produce control actions. While they are effective for this task, the complex nature of neural networks makes their output difficult to verify and predict, limiting their use in safety-critical systems. For this reason, recent work has focused on combining techniques in formal methods and reachability analysis to obtain guarantees on the closed-loop performance of neural network controllers. However, these techniques do not scale to the high-dimensional and complicated input space of image-based neural network controllers. In this work, we propose a method to address these challenges by training a generative adversarial network (GAN) to map states to plausible input images. By concatenating the generator network with the control network, we obtain a network with a low-dimensional input space. This insight allows us to use existing closed-loop verification tools to obtain formal guarantees on the performance of image-based controllers. We apply our approach to provide safety guarantees for an image-based neural network controller for an autonomous aircraft taxi problem. We guarantee that the controller will keep the aircraft on the runway and guide the aircraft towards the center of the runway. The guarantees we provide are with respect to the set of input images modeled by our generator network, so we provide a recall metric to evaluate how well the generator captures the space of plausible images.

</p>
</details>

<details><summary><b>Out-of-Manifold Regularization in Contextual Embedding Space for Text Classification</b>
<a href="https://arxiv.org/abs/2105.06750">arxiv:2105.06750</a>
&#x1F4C8; 7 <br>
<p>Seonghyeon Lee, Dongha Lee, Hwanjo Yu</p></summary>
<p>

**Abstract:** Recent studies on neural networks with pre-trained weights (i.e., BERT) have mainly focused on a low-dimensional subspace, where the embedding vectors computed from input words (or their contexts) are located. In this work, we propose a new approach to finding and regularizing the remainder of the space, referred to as out-of-manifold, which cannot be accessed through the words. Specifically, we synthesize the out-of-manifold embeddings based on two embeddings obtained from actually-observed words, to utilize them for fine-tuning the network. A discriminator is trained to detect whether an input embedding is located inside the manifold or not, and simultaneously, a generator is optimized to produce new embeddings that can be easily identified as out-of-manifold by the discriminator. These two modules successfully collaborate in a unified and end-to-end manner for regularizing the out-of-manifold. Our extensive evaluation on various text classification benchmarks demonstrates the effectiveness of our approach, as well as its good compatibility with existing data augmentation techniques which aim to enhance the manifold.

</p>
</details>

<details><summary><b>XAI Handbook: Towards a Unified Framework for Explainable AI</b>
<a href="https://arxiv.org/abs/2105.06677">arxiv:2105.06677</a>
&#x1F4C8; 7 <br>
<p>Sebastian Palacio, Adriano Lucieri, Mohsin Munir, Jörn Hees, Sheraz Ahmed, Andreas Dengel</p></summary>
<p>

**Abstract:** The field of explainable AI (XAI) has quickly become a thriving and prolific community. However, a silent, recurrent and acknowledged issue in this area is the lack of consensus regarding its terminology. In particular, each new contribution seems to rely on its own (and often intuitive) version of terms like "explanation" and "interpretation". Such disarray encumbers the consolidation of advances in the field towards the fulfillment of scientific and regulatory demands e.g., when comparing methods or establishing their compliance with respect to biases and fairness constraints. We propose a theoretical framework that not only provides concrete definitions for these terms, but it also outlines all steps necessary to produce explanations and interpretations. The framework also allows for existing contributions to be re-contextualized such that their scope can be measured, thus making them comparable to other methods. We show that this framework is compliant with desiderata on explanations, on interpretability and on evaluation metrics. We present a use-case showing how the framework can be used to compare LIME, SHAP and MDNet, establishing their advantages and shortcomings. Finally, we discuss relevant trends in XAI as well as recommendations for future work, all from the standpoint of our framework.

</p>
</details>

<details><summary><b>Application of Three Different Machine Learning Methods on Strategy Creation for Profitable Trades on Cryptocurrency Markets</b>
<a href="https://arxiv.org/abs/2105.06827">arxiv:2105.06827</a>
&#x1F4C8; 6 <br>
<p>Mohsen Asgari, Hossein Khasteh</p></summary>
<p>

**Abstract:** AI and data driven solutions have been applied to different fields with outperforming and promising results. In this research work we apply k-Nearest Neighbours, eXtreme Gradient Boosting and Random Forest classifiers to direction detection problem of three cryptocurrency markets. Our input data includes price data and technical indicators. We use these classifiers to design a strategy to trade in those markets. Our test results on unseen data shows a great potential for this approach in helping investors with an expert system to exploit the market and gain profit. Our highest gain for an unseen 66 day span is 860 dollars per 1800 dollars investment. We also discuss limitations of these approaches and their potential impact to Efficient Market Hypothesis.

</p>
</details>

<details><summary><b>Domestic waste detection and grasping points for robotic picking up</b>
<a href="https://arxiv.org/abs/2105.06825">arxiv:2105.06825</a>
&#x1F4C8; 6 <br>
<p>Victor De Gea, Santiago T. Puente, Pablo Gil</p></summary>
<p>

**Abstract:** This paper presents an AI system applied to location and robotic grasping. Experimental setup is based on a parameter study to train a deep-learning network based on Mask-RCNN to perform waste location in indoor and outdoor environment, using five different classes and generating a new waste dataset. Initially the AI system obtain the RGBD data of the environment, followed by the detection of objects using the neural network. Later, the 3D object shape is computed using the network result and the depth channel. Finally, the shape is used to compute grasping for a robot arm with a two-finger gripper. The objective is to classify the waste in groups to improve a recycling strategy.

</p>
</details>

<details><summary><b>Maximizing Mutual Information Across Feature and Topology Views for Learning Graph Representations</b>
<a href="https://arxiv.org/abs/2105.06715">arxiv:2105.06715</a>
&#x1F4C8; 6 <br>
<p>Xiaolong Fan, Maoguo Gong, Yue Wu, Hao Li</p></summary>
<p>

**Abstract:** Recently, maximizing mutual information has emerged as a powerful method for unsupervised graph representation learning. The existing methods are typically effective to capture information from the topology view but ignore the feature view. To circumvent this issue, we propose a novel approach by exploiting mutual information maximization across feature and topology views. Specifically, we first utilize a multi-view representation learning module to better capture both local and global information content across feature and topology views on graphs. To model the information shared by the feature and topology spaces, we then develop a common representation learning module using mutual information maximization and reconstruction loss minimization. To explicitly encourage diversity between graph representations from the same view, we also introduce a disagreement regularization to enlarge the distance between representations from the same view. Experiments on synthetic and real-world datasets demonstrate the effectiveness of integrating feature and topology views. In particular, compared with the previous supervised methods, our proposed method can achieve comparable or even better performance under the unsupervised representation and linear evaluation protocol.

</p>
</details>

<details><summary><b>Plot and Rework: Modeling Storylines for Visual Storytelling</b>
<a href="https://arxiv.org/abs/2105.06950">arxiv:2105.06950</a>
&#x1F4C8; 5 <br>
<p>Chi-Yang Hsu, Yun-Wei Chu, Ting-Hao 'Kenneth' Huang, Lun-Wei Ku</p></summary>
<p>

**Abstract:** Writing a coherent and engaging story is not easy. Creative writers use their knowledge and worldview to put disjointed elements together to form a coherent storyline, and work and rework iteratively toward perfection. Automated visual storytelling (VIST) models, however, make poor use of external knowledge and iterative generation when attempting to create stories. This paper introduces PR-VIST, a framework that represents the input image sequence as a story graph in which it finds the best path to form a storyline. PR-VIST then takes this path and learns to generate the final story via an iterative training process. This framework produces stories that are superior in terms of diversity, coherence, and humanness, per both automatic and human evaluations. An ablation study shows that both plotting and reworking contribute to the model's superiority.

</p>
</details>

<details><summary><b>Quantified Sleep: Machine learning techniques for observational n-of-1 studies</b>
<a href="https://arxiv.org/abs/2105.06811">arxiv:2105.06811</a>
&#x1F4C8; 5 <br>
<p>Gianluca Truda</p></summary>
<p>

**Abstract:** This paper applies statistical learning techniques to an observational Quantified-Self (QS) study to build a descriptive model of sleep quality. A total of 472 days of my sleep data was collected with an Oura ring and combined with lifestyle, environmental, and psychological data. Such n-of-1 QS projects pose a number of challenges: heterogeneous data sources; missing values; high dimensionality; dynamic feedback loops; human biases. This paper directly addresses these challenges with an end-to-end QS pipeline that produces robust descriptive models. Sleep quality is one of the most difficult modelling targets in QS research, due to high noise and a large number of weakly-contributing factors. Sleep quality was selected so that approaches from this paper would generalise to most other n-of-1 QS projects. Techniques are presented for combining and engineering features for the different classes of data types, sample frequencies, and schema - including event logs, weather, and geo-spatial data. Statistical analyses for outliers, normality, (auto)correlation, stationarity, and missing data are detailed, along with a proposed method for hierarchical clustering to identify correlated groups of features. The missing data was overcome using a combination of knowledge-based and statistical techniques, including several multivariate imputation algorithms. "Markov unfolding" is presented for collapsing the time series into a collection of independent observations, whilst incorporating historical information. The final model was interpreted in two ways: by inspecting the internal $β$-parameters, and using the SHAP framework. These two interpretation techniques were combined to produce a list of the 16 most-predictive features, demonstrating that an observational study can greatly narrow down the number of features that need to be considered when designing interventional QS studies.

</p>
</details>

<details><summary><b>Efficient PAC Reinforcement Learning in Regular Decision Processes</b>
<a href="https://arxiv.org/abs/2105.06784">arxiv:2105.06784</a>
&#x1F4C8; 5 <br>
<p>Alessandro Ronca, Giuseppe De Giacomo</p></summary>
<p>

**Abstract:** Recently regular decision processes have been proposed as a well-behaved form of non-Markov decision process. Regular decision processes are characterised by a transition function and a reward function that depend on the whole history, though regularly (as in regular languages). In practice both the transition and the reward functions can be seen as finite transducers. We study reinforcement learning in regular decision processes. Our main contribution is to show that a near-optimal policy can be PAC-learned in polynomial time in a set of parameters that describe the underlying decision process. We argue that the identified set of parameters is minimal and it reasonably captures the difficulty of a regular decision process.

</p>
</details>

<details><summary><b>NeuroGen: activation optimized image synthesis for discovery neuroscience</b>
<a href="https://arxiv.org/abs/2105.07140">arxiv:2105.07140</a>
&#x1F4C8; 4 <br>
<p>Zijin Gu, Keith W. Jamison, Meenakshi Khosla, Emily J. Allen, Yihan Wu, Thomas Naselaris, Kendrick Kay, Mert R. Sabuncu, Amy Kuceyeski</p></summary>
<p>

**Abstract:** Functional MRI (fMRI) is a powerful technique that has allowed us to characterize visual cortex responses to stimuli, yet such experiments are by nature constructed based on a priori hypotheses, limited to the set of images presented to the individual while they are in the scanner, are subject to noise in the observed brain responses, and may vary widely across individuals. In this work, we propose a novel computational strategy, which we call NeuroGen, to overcome these limitations and develop a powerful tool for human vision neuroscience discovery. NeuroGen combines an fMRI-trained neural encoding model of human vision with a deep generative network to synthesize images predicted to achieve a target pattern of macro-scale brain activation. We demonstrate that the reduction of noise that the encoding model provides, coupled with the generative network's ability to produce images of high fidelity, results in a robust discovery architecture for visual neuroscience. By using only a small number of synthetic images created by NeuroGen, we demonstrate that we can detect and amplify differences in regional and individual human brain response patterns to visual stimuli. We then verify that these discoveries are reflected in the several thousand observed image responses measured with fMRI. We further demonstrate that NeuroGen can create synthetic images predicted to achieve regional response patterns not achievable by the best-matching natural images. The NeuroGen framework extends the utility of brain encoding models and opens up a new avenue for exploring, and possibly precisely controlling, the human visual system.

</p>
</details>

<details><summary><b>A Large Visual, Qualitative and Quantitative Dataset of Web Pages</b>
<a href="https://arxiv.org/abs/2105.07113">arxiv:2105.07113</a>
&#x1F4C8; 4 <br>
<p>Christian Mejia-Escobar, Miguel Cazorla, Ester Martinez-Martin</p></summary>
<p>

**Abstract:** The World Wide Web is not only one of the most important platforms of communication and information at present, but also an area of growing interest for scientific research. This motivates a lot of work and projects that require large amounts of data. However, there is no dataset that integrates the parameters and visual appearance of Web pages, because its collection is a costly task in terms of time and effort. With the support of various computer tools and programming scripts, we have created a large dataset of 49,438 Web pages. It consists of visual, textual and numerical data types, includes all countries worldwide, and considers a broad range of topics such as art, entertainment, economy, business, education, government, news, media, science, and environment, covering different cultural characteristics and varied design preferences. In this paper, we describe the process of collecting, debugging and publishing the final product, which is freely available. To demonstrate the usefulness of our dataset, we expose a binary classification model for detecting error Web pages, and a multi-class Web subject-based categorization, both problems using convolutional neural networks.

</p>
</details>

<details><summary><b>An Effective Baseline for Robustness to Distributional Shift</b>
<a href="https://arxiv.org/abs/2105.07107">arxiv:2105.07107</a>
&#x1F4C8; 4 <br>
<p>Sunil Thulasidasan, Sushil Thapa, Sayera Dhaubhadel, Gopinath Chennupati, Tanmoy Bhattacharya, Jeff Bilmes</p></summary>
<p>

**Abstract:** Refraining from confidently predicting when faced with categories of inputs different from those seen during training is an important requirement for the safe deployment of deep learning systems. While simple to state, this has been a particularly challenging problem in deep learning, where models often end up making overconfident predictions in such situations. In this work we present a simple, but highly effective approach to deal with out-of-distribution detection that uses the principle of abstention: when encountering a sample from an unseen class, the desired behavior is to abstain from predicting. Our approach uses a network with an extra abstention class and is trained on a dataset that is augmented with an uncurated set that consists of a large number of out-of-distribution (OoD) samples that are assigned the label of the abstention class; the model is then trained to learn an effective discriminator between in and out-of-distribution samples. We compare this relatively simple approach against a wide variety of more complex methods that have been proposed both for out-of-distribution detection as well as uncertainty modeling in deep learning, and empirically demonstrate its effectiveness on a wide variety of of benchmarks and deep architectures for image recognition and text classification, often outperforming existing approaches by significant margins. Given the simplicity and effectiveness of this method, we propose that this approach be used as a new additional baseline for future work in this domain.

</p>
</details>

<details><summary><b>Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2105.07059">arxiv:2105.07059</a>
&#x1F4C8; 4 <br>
<p>Chenyu You, Ruihan Zhao, Lawrence Staib, James S. Duncan</p></summary>
<p>

**Abstract:** Automated segmentation in medical image analysis is a challenging task that requires a large amount of manually labeled data. However, manually annotating medical data is often laborious, and most existing learning-based approaches fail to accurately delineate object boundaries without effective geometric constraints. Contrastive learning, a sub-area of self-supervised learning, has recently been noted as a promising direction in multiple application fields. In this work, we present a novel Contrastive Voxel-wise Representation Distillation (CVRD) method with geometric constraints to learn global-local visual representations for volumetric medical image segmentation with limited annotations. Our framework can effectively learn global and local features by capturing 3D spatial context and rich anatomical information. Specifically, we introduce a voxel-to-volume contrastive algorithm to learn global information from 3D images, and propose to perform local voxel-to-voxel distillation to explicitly make use of local cues in the embedding space. Moreover, we integrate an elastic interaction-based active contour model as a geometric regularization term to enable fast and reliable object delineations in an end-to-end learning manner. Results on the Atrial Segmentation Challenge dataset demonstrate superiority of our proposed scheme, especially in a setting with a very limited number of annotated data. The code will be available at https://github.com/charlesyou999648/CVRD.

</p>
</details>

<details><summary><b>Non-decreasing Quantile Function Network with Efficient Exploration for Distributional Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2105.06696">arxiv:2105.06696</a>
&#x1F4C8; 4 <br>
<p>Fan Zhou, Zhoufan Zhu, Qi Kuang, Liwen Zhang</p></summary>
<p>

**Abstract:** Although distributional reinforcement learning (DRL) has been widely examined in the past few years, there are two open questions people are still trying to address. One is how to ensure the validity of the learned quantile function, the other is how to efficiently utilize the distribution information. This paper attempts to provide some new perspectives to encourage the future in-depth studies in these two fields. We first propose a non-decreasing quantile function network (NDQFN) to guarantee the monotonicity of the obtained quantile estimates and then design a general exploration framework called distributional prediction error (DPE) for DRL which utilizes the entire distribution of the quantile function. In this paper, we not only discuss the theoretical necessity of our method but also show the performance gain it achieves in practice by comparing with some competitors on Atari 2600 Games especially in some hard-explored games.

</p>
</details>

<details><summary><b>Unsupervised MRI Reconstruction via Zero-Shot Learned Adversarial Transformers</b>
<a href="https://arxiv.org/abs/2105.08059">arxiv:2105.08059</a>
&#x1F4C8; 3 <br>
<p>Yilmaz Korkmaz, Salman UH Dar, Mahmut Yurt, Muzaffer Özbey, Tolga Çukur</p></summary>
<p>

**Abstract:** Supervised deep learning has swiftly become a workhorse for accelerated MRI in recent years, offering state-of-the-art performance in image reconstruction from undersampled acquisitions. Training deep supervised models requires large datasets of undersampled and fully-sampled acquisitions typically from a matching set of subjects. Given scarce access to large medical datasets, this limitation has sparked interest in unsupervised methods that reduce reliance on fully-sampled ground-truth data. A common framework is based on the deep image prior, where network-driven regularization is enforced directly during inference on undersampled acquisitions. Yet, canonical convolutional architectures are suboptimal in capturing long-range relationships, and randomly initialized networks may hamper convergence. To address these limitations, here we introduce a novel unsupervised MRI reconstruction method based on zero-Shot Learned Adversarial TransformERs (SLATER). SLATER embodies a deep adversarial network with cross-attention transformer blocks to map noise and latent variables onto MR images. This unconditional network learns a high-quality MRI prior in a self-supervised encoding task. A zero-shot reconstruction is performed on undersampled test data, where inference is performed by optimizing network parameters, latent and noise variables to ensure maximal consistency to multi-coil MRI data. Comprehensive experiments on brain MRI datasets clearly demonstrate the superior performance of SLATER against several state-of-the-art unsupervised methods.

</p>
</details>

<details><summary><b>High-Robustness, Low-Transferability Fingerprinting of Neural Networks</b>
<a href="https://arxiv.org/abs/2105.07078">arxiv:2105.07078</a>
&#x1F4C8; 3 <br>
<p>Siyue Wang, Xiao Wang, Pin-Yu Chen, Pu Zhao, Xue Lin</p></summary>
<p>

**Abstract:** This paper proposes Characteristic Examples for effectively fingerprinting deep neural networks, featuring high-robustness to the base model against model pruning as well as low-transferability to unassociated models. This is the first work taking both robustness and transferability into consideration for generating realistic fingerprints, whereas current methods lack practical assumptions and may incur large false positive rates. To achieve better trade-off between robustness and transferability, we propose three kinds of characteristic examples: vanilla C-examples, RC-examples, and LTRC-example, to derive fingerprints from the original base model. To fairly characterize the trade-off between robustness and transferability, we propose Uniqueness Score, a comprehensive metric that measures the difference between robustness and transferability, which also serves as an indicator to the false alarm problem.

</p>
</details>

<details><summary><b>Visual analogy: Deep learning versus compositional models</b>
<a href="https://arxiv.org/abs/2105.07065">arxiv:2105.07065</a>
&#x1F4C8; 3 <br>
<p>Nicholas Ichien, Qing Liu, Shuhao Fu, Keith J. Holyoak, Alan Yuille, Hongjing Lu</p></summary>
<p>

**Abstract:** Is analogical reasoning a task that must be learned to solve from scratch by applying deep learning models to massive numbers of reasoning problems? Or are analogies solved by computing similarities between structured representations of analogs? We address this question by comparing human performance on visual analogies created using images of familiar three-dimensional objects (cars and their subregions) with the performance of alternative computational models. Human reasoners achieved above-chance accuracy for all problem types, but made more errors in several conditions (e.g., when relevant subregions were occluded). We compared human performance to that of two recent deep learning models (Siamese Network and Relation Network) directly trained to solve these analogy problems, as well as to that of a compositional model that assesses relational similarity between part-based representations. The compositional model based on part representations, but not the deep learning models, generated qualitative performance similar to that of human reasoners.

</p>
</details>

<details><summary><b>Scaling Ensemble Distribution Distillation to Many Classes with Proxy Targets</b>
<a href="https://arxiv.org/abs/2105.06987">arxiv:2105.06987</a>
&#x1F4C8; 3 <br>
<p>Max Ryabinin, Andrey Malinin, Mark Gales</p></summary>
<p>

**Abstract:** Ensembles of machine learning models yield improved system performance as well as robust and interpretable uncertainty estimates; however, their inference costs may often be prohibitively high. \emph{Ensemble Distribution Distillation} is an approach that allows a single model to efficiently capture both the predictive performance and uncertainty estimates of an ensemble. For classification, this is achieved by training a Dirichlet distribution over the ensemble members' output distributions via the maximum likelihood criterion. Although theoretically principled, this criterion exhibits poor convergence when applied to large-scale tasks where the number of classes is very high. In our work, we analyze this effect and show that the Dirichlet log-likelihood criterion classes with low probability induce larger gradients than high-probability classes. This forces the model to focus on the distribution of the ensemble tail-class probabilities. We propose a new training objective that minimizes the reverse KL-divergence to a \emph{Proxy-Dirichlet} target derived from the ensemble. This loss resolves the gradient issues of Ensemble Distribution Distillation, as we demonstrate both theoretically and empirically on the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes, respectively.

</p>
</details>

<details><summary><b>BNNpriors: A library for Bayesian neural network inference with different prior distributions</b>
<a href="https://arxiv.org/abs/2105.06964">arxiv:2105.06964</a>
&#x1F4C8; 3 <br>
<p>Vincent Fortuin, Adrià Garriga-Alonso, Mark van der Wilk, Laurence Aitchison</p></summary>
<p>

**Abstract:** Bayesian neural networks have shown great promise in many applications where calibrated uncertainty estimates are crucial and can often also lead to a higher predictive performance. However, it remains challenging to choose a good prior distribution over their weights. While isotropic Gaussian priors are often chosen in practice due to their simplicity, they do not reflect our true prior beliefs well and can lead to suboptimal performance. Our new library, BNNpriors, enables state-of-the-art Markov Chain Monte Carlo inference on Bayesian neural networks with a wide range of predefined priors, including heavy-tailed ones, hierarchical ones, and mixture priors. Moreover, it follows a modular approach that eases the design and implementation of new custom priors. It has facilitated foundational discoveries on the nature of the cold posterior effect in Bayesian neural networks and will hopefully catalyze future research as well as practical applications in this area.

</p>
</details>

<details><summary><b>Adapting deep generative approaches for getting synthetic data with realistic marginal distributions</b>
<a href="https://arxiv.org/abs/2105.06907">arxiv:2105.06907</a>
&#x1F4C8; 3 <br>
<p>Kiana Farhadyar, Federico Bonofiglio, Daniela Zoeller, Harald Binder</p></summary>
<p>

**Abstract:** Synthetic data generation is of great interest in diverse applications, such as for privacy protection. Deep generative models, such as variational autoencoders (VAEs), are a popular approach for creating such synthetic datasets from original data. Despite the success of VAEs, there are limitations when it comes to the bimodal and skewed marginal distributions. These deviate from the unimodal symmetric distributions that are encouraged by the normality assumption typically used for the latent representations in VAEs. While there are extensions that assume other distributions for the latent space, this does not generally increase flexibility for data with many different distributions. Therefore, we propose a novel method, pre-transformation variational autoencoders (PTVAEs), to specifically address bimodal and skewed data, by employing pre-transformations at the level of original variables. Two types of transformations are used to bring the data close to a normal distribution by a separate parameter optimization for each variable in a dataset. We compare the performance of our method with other state-of-the-art methods for synthetic data generation. In addition to the visual comparison, we use a utility measurement for a quantitative evaluation. The results show that the PTVAE approach can outperform others in both bimodal and skewed data generation. Furthermore, the simplicity of the approach makes it usable in combination with other extensions of VAE.

</p>
</details>

<details><summary><b>Salient Feature Extractor for Adversarial Defense on Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2105.06807">arxiv:2105.06807</a>
&#x1F4C8; 3 <br>
<p>Jinyin Chen, Ruoxi Chen, Haibin Zheng, Zhaoyan Ming, Wenrong Jiang, Chen Cui</p></summary>
<p>

**Abstract:** Recent years have witnessed unprecedented success achieved by deep learning models in the field of computer vision. However, their vulnerability towards carefully crafted adversarial examples has also attracted the increasing attention of researchers. Motivated by the observation that adversarial examples are due to the non-robust feature learned from the original dataset by models, we propose the concepts of salient feature(SF) and trivial feature(TF). The former represents the class-related feature, while the latter is usually adopted to mislead the model. We extract these two features with coupled generative adversarial network model and put forward a novel detection and defense method named salient feature extractor (SFE) to defend against adversarial attacks. Concretely, detection is realized by separating and comparing the difference between SF and TF of the input. At the same time, correct labels are obtained by re-identifying SF to reach the purpose of defense. Extensive experiments are carried out on MNIST, CIFAR-10, and ImageNet datasets where SFE shows state-of-the-art results in effectiveness and efficiency compared with baselines. Furthermore, we provide an interpretable understanding of the defense and detection process.

</p>
</details>

<details><summary><b>Facial Age Estimation using Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2105.06746">arxiv:2105.06746</a>
&#x1F4C8; 3 <br>
<p>Adrian Kjærran, Christian Bakke Vennerød, Erling Stray Bugge</p></summary>
<p>

**Abstract:** This paper is a part of a student project in Machine Learning at the Norwegian University of Science and Technology. In this paper, a deep convolutional neural network with five convolutional layers and three fully-connected layers is presented to estimate the ages of individuals based on images. The model is in its entirety trained from scratch, where a combination of three different datasets is used as training data. These datasets are the APPA dataset, UTK dataset, and the IMDB dataset. The images were preprocessed using a proprietary face-recognition software. Our model is evaluated on both a held-out test set, and on the Adience benchmark. On the test set, our model achieves a categorical accuracy of 52%. On the Adience benchmark, our model proves inferior compared with other leading models, with an exact accuray of 30%, and an one-off accuracy of 46%. Furthermore, a script was created, allowing users to estimate their age directly using their web camera. The script, alongside all other code, is located in our GitHub repository: AgeNet.

</p>
</details>

<details><summary><b>Image Super-Resolution Quality Assessment: Structural Fidelity Versus Statistical Naturalness</b>
<a href="https://arxiv.org/abs/2105.07139">arxiv:2105.07139</a>
&#x1F4C8; 2 <br>
<p>Wei Zhou, Zhou Wang, Zhibo Chen</p></summary>
<p>

**Abstract:** Single image super-resolution (SISR) algorithms reconstruct high-resolution (HR) images with their low-resolution (LR) counterparts. It is desirable to develop image quality assessment (IQA) methods that can not only evaluate and compare SISR algorithms, but also guide their future development. In this paper, we assess the quality of SISR generated images in a two-dimensional (2D) space of structural fidelity versus statistical naturalness. This allows us to observe the behaviors of different SISR algorithms as a tradeoff in the 2D space. Specifically, SISR methods are traditionally designed to achieve high structural fidelity but often sacrifice statistical naturalness, while recent generative adversarial network (GAN) based algorithms tend to create more natural-looking results but lose significantly on structural fidelity. Furthermore, such a 2D evaluation can be easily fused to a scalar quality prediction. Interestingly, we find that a simple linear combination of a straightforward local structural fidelity and a global statistical naturalness measures produce surprisingly accurate predictions of SISR image quality when tested using public subject-rated SISR image datasets. Code of the proposed SFSN model is publicly available at \url{https://github.com/weizhou-geek/SFSN}.

</p>
</details>

<details><summary><b>Interpretable Drug Synergy Prediction with Graph Neural Networks for Human-AI Collaboration in Healthcare</b>
<a href="https://arxiv.org/abs/2105.07082">arxiv:2105.07082</a>
&#x1F4C8; 2 <br>
<p>Zehao Dong, Heming Zhang, Yixin Chen, Fuhai Li</p></summary>
<p>

**Abstract:** We investigate molecular mechanisms of resistant or sensitive response of cancer drug combination therapies in an inductive and interpretable manner. Though deep learning algorithms are widely used in the drug synergy prediction problem, it is still an open problem to formulate the prediction model with biological meaning to investigate the mysterious mechanisms of synergy (MoS) for the human-AI collaboration in healthcare systems. To address the challenges, we propose a deep graph neural network, IDSP (Interpretable Deep Signaling Pathways), to incorporate the gene-gene as well as gene-drug regulatory relationships in synergic drug combination predictions. IDSP automatically learns weights of edges based on the gene and drug node relations, i.e., signaling interactions, by a multi-layer perceptron (MLP) and aggregates information in an inductive manner. The proposed architecture generates interpretable drug synergy prediction by detecting important signaling interactions, and can be implemented when the underlying molecular mechanism encounters unseen genes or signaling pathways. We test IDWSP on signaling networks formulated by genes from 46 core cancer signaling pathways and drug combinations from NCI ALMANAC drug combination screening data. The experimental results demonstrated that 1) IDSP can learn from the underlying molecular mechanism to make prediction without additional drug chemical information while achieving highly comparable performance with current state-of-art methods; 2) IDSP show superior generality and flexibility to implement the synergy prediction task on both transductive tasks and inductive tasks. 3) IDSP can generate interpretable results by detecting different salient signaling patterns (i.e. MoS) for different cell lines.

</p>
</details>

<details><summary><b>Node Selection Toward Faster Convergence for Federated Learning on Non-IID Data</b>
<a href="https://arxiv.org/abs/2105.07066">arxiv:2105.07066</a>
&#x1F4C8; 2 <br>
<p>Hongda Wu, Ping Wang</p></summary>
<p>

**Abstract:** Federated Learning (FL) is a distributed learning paradigm that enables a large number of resource-limited nodes to collaboratively train a model without data sharing. The non-independent-and-identically-distributed (non-i.i.d.) data samples invoke discrepancy between global and local objectives, making the FL model slow to converge. In this paper, we proposed Optimal Aggregation algorithm for better aggregation, which finds out the optimal subset of local updates of participating nodes in each global round, by identifying and excluding the adverse local updates via checking the relationship between the local gradient and the global gradient. Then, we proposed a Probabilistic Node Selection framework (FedPNS) to dynamically change the probability for each node to be selected based on the output of Optimal Aggregation. FedPNS can preferentially select nodes that propel faster model convergence. The unbiasedness of the proposed FedPNS design is illustrated and the convergence rate improvement of FedPNS over the commonly adopted Federated Averaging (FedAvg) algorithm is analyzed theoretically. Experimental results demonstrate the effectiveness of FedPNS in accelerating the FL convergence rate, as compared to FedAvg with random node selection.

</p>
</details>

<details><summary><b>A Monotone Approximate Dynamic Programming Approach for the Stochastic Scheduling, Allocation, and Inventory Replenishment Problem: Applications to Drone and Electric Vehicle Battery Swap Stations</b>
<a href="https://arxiv.org/abs/2105.07026">arxiv:2105.07026</a>
&#x1F4C8; 2 <br>
<p>Amin Asadi, Sarah Nurre Pinkley</p></summary>
<p>

**Abstract:** There is a growing interest in using electric vehicles (EVs) and drones for many applications. However, battery-oriented issues, including range anxiety and battery degradation, impede adoption. Battery swap stations are one alternative to reduce these concerns that allow the swap of depleted for full batteries in minutes. We consider the problem of deriving actions at a battery swap station when explicitly considering the uncertain arrival of swap demand, battery degradation, and replacement. We model the operations at a battery swap station using a finite horizon Markov Decision Process model for the stochastic scheduling, allocation, and inventory replenishment problem (SAIRP), which determines when and how many batteries are charged, discharged, and replaced over time. We present theoretical proofs for the monotonicity of the value function and monotone structure of an optimal policy for special SAIRP cases. Due to the curses of dimensionality, we develop a new monotone approximate dynamic programming (ADP) method, which intelligently initializes a value function approximation using regression. In computational tests, we demonstrate the superior performance of the new regression-based monotone ADP method as compared to exact methods and other monotone ADP methods. Further, with the tests, we deduce policy insights for drone swap stations.

</p>
</details>

<details><summary><b>Minimal Cycle Representatives in Persistent Homology using Linear Programming: an Empirical Study with User's Guide</b>
<a href="https://arxiv.org/abs/2105.07025">arxiv:2105.07025</a>
&#x1F4C8; 2 <br>
<p>Lu Li, Connor Thompson, Gregory Henselman-Petrusek, Chad Giusti, Lori Ziegelmeier</p></summary>
<p>

**Abstract:** Cycle representatives of persistent homology classes can be used to provide descriptions of topological features in data. However, the non-uniqueness of these representatives creates ambiguity and can lead to many different interpretations of the same set of classes. One approach to solving this problem is to optimize the choice of representative against some measure that is meaningful in the context of the data. In this work, we provide a study of the effectiveness and computational cost of several $\ell_1$-minimization optimization procedures for constructing homological cycle bases for persistent homology with rational coefficients in dimension one, including uniform-weighted and length-weighted edge-loss algorithms as well as uniform-weighted and area-weighted triangle-loss algorithms. We conduct these optimizations via standard linear programming methods, applying general-purpose solvers to optimize over column bases of simplicial boundary matrices.
  Our key findings are: (i) optimization is effective in reducing the size of cycle representatives, (ii) the computational cost of optimizing a basis of cycle representatives exceeds the cost of computing such a basis in most data sets we consider, (iii) the choice of linear solvers matters a lot to the computation time of optimizing cycles, (iv) the computation time of solving an integer program is not significantly longer than the computation time of solving a linear program for most of the cycle representatives, using the Gurobi linear solver, (v) strikingly, whether requiring integer solutions or not, we almost always obtain a solution with the same cost and almost all solutions found have entries in {-1, 0, 1} and therefore, are also solutions to a restricted $\ell_0$ optimization problem, and (vi) we obtain qualitatively different results for generators in Erdős-Rényi random clique complexes.

</p>
</details>

<details><summary><b>A hyperparameter-tuning approach to automated inverse planning</b>
<a href="https://arxiv.org/abs/2105.07024">arxiv:2105.07024</a>
&#x1F4C8; 2 <br>
<p>Kelsey Maass, Aleksandr Aravkin, Minsun Kim</p></summary>
<p>

**Abstract:** Radiotherapy inverse planning often requires planners to modify parameters in the treatment planning system's objective function to produce clinically acceptable plans. Due to the manual steps in this process, plan quality can vary depending on the planning time available and the planner's skills. This study investigates two hyperparameter-tuning methods for automated inverse planning. Because this framework does not train a model on previously-optimized plans, it can be readily adapted to practice pattern changes, and plan quality is not limited by that of a training cohort. We selected 10 patients who received lung SBRT using manually-generated clinical plans. We used random sampling (RS) and Bayesian optimization (BO) to tune parameters using linear-quadratic utility functions based on 11 clinical goals. Normalizing all plans to have PTV D95 equal to 48 Gy, we compared plan quality for the automatically-generated and manually-generated plans. We also investigated the impact of iteration count on the automatically-generated plans, comparing planning time and plan utility for RS and BO plans with and without stopping criteria. Without stopping criteria, the median planning time was 1.9 and 2.3 hours for RS and BO plans. The OAR doses in the RS and BO plans had a median percent difference (MPD) of 48.7% and 60.4% below clinical dose limits and an MPD of 2.8% and 3.3% below clinical plan doses. With stopping criteria, the utility decreased by an MPD of 5.3% and 3.9% for RS and BO plans, but the median planning time was reduced to 0.5 and 0.7 hours, and the OAR doses still had an MPD of 42.9% and 49.7% below clinical dose limits and an MPD of 0.3% and 1.8% below clinical plan doses. This study demonstrates that hyperparameter-tuning approaches to automated inverse planning can reduce active planning time with plan quality that is similar to or better than manually-generated plans.

</p>
</details>

<details><summary><b>Thompson Sampling for Gaussian Entropic Risk Bandits</b>
<a href="https://arxiv.org/abs/2105.06960">arxiv:2105.06960</a>
&#x1F4C8; 2 <br>
<p>Ming Liang Ang, Eloise Y. Y. Lim, Joel Q. L. Chang</p></summary>
<p>

**Abstract:** The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem that exemplifies exploration-exploitation tradeoff. Standard formulations exclude risk in decision making. Risknotably complicates the basic reward-maximising objectives, in part because there is no universally agreed definition of it. In this paper, we consider an entropic risk (ER) measure and explore the performance of a Thompson sampling-based algorithm ERTS under this risk measure by providing regret bounds for ERTS and corresponding instance dependent lower bounds.

</p>
</details>

<details><summary><b>On Measuring the Diversity of Organizational Networks</b>
<a href="https://arxiv.org/abs/2105.06929">arxiv:2105.06929</a>
&#x1F4C8; 2 <br>
<p>Zeinab S. Jalali, Krishnaram Kenthapadi, Sucheta Soundarajan</p></summary>
<p>

**Abstract:** The interaction patterns of employees in social and professional networks play an important role in the success of employees and organizations as a whole. However, in many fields there is a severe under-representation of minority groups; moreover, minority individuals may be segregated from the rest of the network or isolated from one another. While the problem of increasing the representation of minority groups in various fields has been well-studied, diver- sification in terms of numbers alone may not be sufficient: social relationships should also be considered. In this work, we consider the problem of assigning a set of employment candidates to positions in a social network so that diversity and overall fitness are maximized, and propose Fair Employee Assignment (FairEA), a novel algorithm for finding such a matching. The output from FairEA can be used as a benchmark by organizations wishing to evaluate their hiring and assignment practices. On real and synthetic networks, we demonstrate that FairEA does well at finding high-fitness, high-diversity matchings.

</p>
</details>

<details><summary><b>Hierarchical Architectures in Reservoir Computing Systems</b>
<a href="https://arxiv.org/abs/2105.06923">arxiv:2105.06923</a>
&#x1F4C8; 2 <br>
<p>John Moon, Wei D. Lu</p></summary>
<p>

**Abstract:** Reservoir computing (RC) offers efficient temporal data processing with a low training cost by separating recurrent neural networks into a fixed network with recurrent connections and a trainable linear network. The quality of the fixed network, called reservoir, is the most important factor that determines the performance of the RC system. In this paper, we investigate the influence of the hierarchical reservoir structure on the properties of the reservoir and the performance of the RC system. Analogous to deep neural networks, stacking sub-reservoirs in series is an efficient way to enhance the nonlinearity of data transformation to high-dimensional space and expand the diversity of temporal information captured by the reservoir. These deep reservoir systems offer better performance when compared to simply increasing the size of the reservoir or the number of sub-reservoirs. Low frequency components are mainly captured by the sub-reservoirs in later stage of the deep reservoir structure, similar to observations that more abstract information can be extracted by layers in the late stage of deep neural networks. When the total size of the reservoir is fixed, tradeoff between the number of sub-reservoirs and the size of each sub-reservoir needs to be carefully considered, due to the degraded ability of individual sub-reservoirs at small sizes. Improved performance of the deep reservoir structure alleviates the difficulty of implementing the RC system on hardware systems.

</p>
</details>

<details><summary><b>Fit4CAD: A point cloud benchmark for fitting simple geometric primitives in CAD objects</b>
<a href="https://arxiv.org/abs/2105.06858">arxiv:2105.06858</a>
&#x1F4C8; 2 <br>
<p>Chiara Romanengo, Andrea Raffo, Yifan Qie, Nabil Anwer, Bianca Falcidieno</p></summary>
<p>

**Abstract:** We propose Fit4CAD, a benchmark for the evaluation and comparison of methods for fitting simple geometric primitives in point clouds representing CAD objects. This benchmark is meant to help both method developers and those who want to identify the best performing tools. The Fit4CAD dataset is composed by 225 high quality point clouds, each of which has been obtained by sampling a CAD object. The way these elements were created by using existing platforms and datasets makes the benchmark easily expandable. The dataset is already split into a training set and a test set. To assess performance and accuracy of the different primitive fitting methods, various measures are defined. To demonstrate the effective use of Fit4CAD, we have tested it on two methods belonging to two different categories of approaches to the primitive fitting problem: a clustering method based on a primitive growing framework and a parametric method based on the Hough transform.

</p>
</details>

<details><summary><b>A cost-benefit analysis of cross-lingual transfer methods</b>
<a href="https://arxiv.org/abs/2105.06813">arxiv:2105.06813</a>
&#x1F4C8; 2 <br>
<p>Guilherme Moraes Rosa, Luiz Henrique Bonifacio, Leandro Rodrigues de Souza, Roberto Lotufo, Rodrigo Nogueira</p></summary>
<p>

**Abstract:** An effective method for cross-lingual transfer is to fine-tune a bilingual or multilingual model on a supervised dataset in one language and evaluating it on another language in a zero-shot manner. Translating examples at training time or inference time are also viable alternatives. However, there are costs associated with these methods that are rarely addressed in the literature. In this work, we analyze cross-lingual methods in terms of their effectiveness (e.g., accuracy), development and deployment costs, as well as their latencies at inference time. Our experiments on three tasks indicate that the best cross-lingual method is highly task-dependent. Finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three datasets used in this work. Based on these results, we question the need for manually labeled training data in a target language. Code and translated datasets are available at https://github.com/unicamp-dl/cross-lingual-analysis

</p>
</details>

<details><summary><b>SAT-Based Rigorous Explanations for Decision Lists</b>
<a href="https://arxiv.org/abs/2105.06782">arxiv:2105.06782</a>
&#x1F4C8; 2 <br>
<p>Alexey Ignatiev, Joao Marques-Silva</p></summary>
<p>

**Abstract:** Decision lists (DLs) find a wide range of uses for classification problems in Machine Learning (ML), being implemented in a number of ML frameworks. DLs are often perceived as interpretable. However, building on recent results for decision trees (DTs), we argue that interpretability is an elusive goal for some DLs. As a result, for some uses of DLs, it will be important to compute (rigorous) explanations. Unfortunately, and in clear contrast with the case of DTs, this paper shows that computing explanations for DLs is computationally hard. Motivated by this result, the paper proposes propositional encodings for computing abductive explanations (AXps) and contrastive explanations (CXps) of DLs. Furthermore, the paper investigates the practical efficiency of a MARCO-like approach for enumerating explanations. The experimental results demonstrate that, for DLs used in practical settings, the use of SAT oracles offers a very efficient solution, and that complete enumeration of explanations is most often feasible.

</p>
</details>

<details><summary><b>DialogSum: A Real-Life Scenario Dialogue Summarization Dataset</b>
<a href="https://arxiv.org/abs/2105.06762">arxiv:2105.06762</a>
&#x1F4C8; 2 <br>
<p>Yulong Chen, Yang Liu, Liang Chen, Yue Zhang</p></summary>
<p>

**Abstract:** Proposal of large-scale datasets has facilitated research on deep neural models for news summarization. Deep learning can also be potentially useful for spoken dialogue summarization, which can benefit a range of real-life scenarios including customer service management and medication tracking. To this end, we propose DialogSum, a large-scale labeled dialogue summarization dataset. We conduct empirical analysis on DialogSum using state-of-the-art neural summarizers. Experimental results show unique challenges in dialogue summarization, such as spoken terms, special discourse structures, coreferences and ellipsis, pragmatics and social common sense, which require specific representation learning technologies to better deal with.

</p>
</details>

<details><summary><b>Discovering the Rationale of Decisions: Experiments on Aligning Learning and Reasoning</b>
<a href="https://arxiv.org/abs/2105.06758">arxiv:2105.06758</a>
&#x1F4C8; 2 <br>
<p>Cor Steging, Silja Renooij, Bart Verheij</p></summary>
<p>

**Abstract:** In AI and law, systems that are designed for decision support should be explainable when pursuing justice. In order for these systems to be fair and responsible, they should make correct decisions and make them using a sound and transparent rationale. In this paper, we introduce a knowledge-driven method for model-agnostic rationale evaluation using dedicated test cases, similar to unit-testing in professional software development. We apply this new method in a set of machine learning experiments aimed at extracting known knowledge structures from artificial datasets from fictional and non-fictional legal settings. We show that our method allows us to analyze the rationale of black-box machine learning systems by assessing which rationale elements are learned or not. Furthermore, we show that the rationale can be adjusted using tailor-made training data based on the results of the rationale evaluation.

</p>
</details>

<details><summary><b>Estimating Disentangled Belief about Hidden State and Hidden Task for Meta-RL</b>
<a href="https://arxiv.org/abs/2105.06660">arxiv:2105.06660</a>
&#x1F4C8; 2 <br>
<p>Kei Akuzawa, Yusuke Iwasawa, Yutaka Matsuo</p></summary>
<p>

**Abstract:** There is considerable interest in designing meta-reinforcement learning (meta-RL) algorithms, which enable autonomous agents to adapt new tasks from small amount of experience. In meta-RL, the specification (such as reward function) of current task is hidden from the agent. In addition, states are hidden within each task owing to sensor noise or limitations in realistic environments. Therefore, the meta-RL agent faces the challenge of specifying both the hidden task and states based on small amount of experience. To address this, we propose estimating disentangled belief about task and states, leveraging an inductive bias that the task and states can be regarded as global and local features of each task. Specifically, we train a hierarchical state-space model (HSSM) parameterized by deep neural networks as an environment model, whose global and local latent variables correspond to task and states, respectively. Because the HSSM does not allow analytical computation of posterior distribution, i.e., belief, we employ amortized inference to approximate it. After the belief is obtained, we can augment observations of a model-free policy with the belief to efficiently train the policy. Moreover, because task and state information are factorized and interpretable, the downstream policy training is facilitated compared with the prior methods that did not consider the hierarchical nature. Empirical validations on a GridWorld environment confirm that the HSSM can separate the hidden task and states information. Then, we compare the meta-RL agent with the HSSM to prior meta-RL methods in MuJoCo environments, and confirm that our agent requires less training data and reaches higher final performance.

</p>
</details>

<details><summary><b>One Network to Solve Them All: A Sequential Multi-Task Joint Learning Network Framework for MR Imaging Pipeline</b>
<a href="https://arxiv.org/abs/2105.06653">arxiv:2105.06653</a>
&#x1F4C8; 2 <br>
<p>Zhiwen Wang, Wenjun Xia, Zexin Lu, Yongqiang Huang, Yan Liu, Hu Chen, Jiliu Zhou, Yi Zhang</p></summary>
<p>

**Abstract:** Magnetic resonance imaging (MRI) acquisition, reconstruction, and segmentation are usually processed independently in the conventional practice of MRI workflow. It is easy to notice that there are significant relevances among these tasks and this procedure artificially cuts off these potential connections, which may lead to losing clinically important information for the final diagnosis. To involve these potential relations for further performance improvement, a sequential multi-task joint learning network model is proposed to train a combined end-to-end pipeline in a differentiable way, aiming at exploring the mutual influence among those tasks simultaneously. Our design consists of three cascaded modules: 1) deep sampling pattern learning module optimizes the $k$-space sampling pattern with predetermined sampling rate; 2) deep reconstruction module is dedicated to reconstructing MR images from the undersampled data using the learned sampling pattern; 3) deep segmentation module encodes MR images reconstructed from the previous module to segment the interested tissues. The proposed model retrieves the latently interactive and cyclic relations among those tasks, from which each task will be mutually beneficial. The proposed framework is verified on MRB dataset, which achieves superior performance on other SOTA methods in terms of both reconstruction and segmentation.

</p>
</details>

<details><summary><b>Importance Weighted Adversarial Discriminative Transfer for Anomaly Detection</b>
<a href="https://arxiv.org/abs/2105.06649">arxiv:2105.06649</a>
&#x1F4C8; 2 <br>
<p>Cangning Fan, Fangyi Zhang, Peng Liu, Xiuyu Sun, Hao Li, Ting Xiao, Wei Zhao, Xianglong Tang</p></summary>
<p>

**Abstract:** Previous transfer methods for anomaly detection generally assume the availability of labeled data in source or target domains. However, such an assumption is not valid in most real applications where large-scale labeled data are too expensive. Therefore, this paper proposes an importance weighted adversarial autoencoder-based method to transfer anomaly detection knowledge in an unsupervised manner, particularly for a rarely studied scenario where a target domain has no labeled normal/abnormal data while only normal data from a related source domain exist. Specifically, the method learns to align the distributions of normal data in both source and target domains, but leave the distribution of abnormal data in the target domain unchanged. In this way, an obvious gap can be produced between the distributions of normal and abnormal data in the target domain, therefore enabling the anomaly detection in the domain. Extensive experiments on multiple synthetic datasets and the UCSD benchmark demonstrate the effectiveness of our approach.

</p>
</details>

<details><summary><b>Real-Time COVID-19 Diagnosis from X-Ray Images Using Deep CNN and Extreme Learning Machines Stabilized by Chimp Optimization Algorithm</b>
<a href="https://arxiv.org/abs/2106.01435">arxiv:2106.01435</a>
&#x1F4C8; 1 <br>
<p>Hu Tianqing, Mohammad Khishe, Mokhtar Mohammadi, Gholam-Reza Parvizi, Sarkhel H. Taher Karim, Tarik A. Rashid</p></summary>
<p>

**Abstract:** Real-time detection of COVID-19 using radiological images has gained priority due to the increasing demand for fast diagnosis of COVID-19 cases. This paper introduces a novel two-phase approach for classifying chest X-ray images. Deep Learning (DL) methods fail to cover these aspects since training and fine-tuning the model's parameters consume much time. In this approach, the first phase comes to train a deep CNN working as a feature extractor, and the second phase comes to use Extreme Learning Machines (ELMs) for real-time detection. The main drawback of ELMs is to meet the need of a large number of hidden-layer nodes to gain a reliable and accurate detector in applying image processing since the detective performance remarkably depends on the setting of initial weights and biases. Therefore, this paper uses Chimp Optimization Algorithm (ChOA) to improve results and increase the reliability of the network while maintaining real-time capability. The designed detector is to be benchmarked on the COVID-Xray-5k and COVIDetectioNet datasets, and the results are verified by comparing it with the classic DCNN, Genetic Algorithm optimized ELM (GA-ELM), Cuckoo Search optimized ELM (CS-ELM), and Whale Optimization Algorithm optimized ELM (WOA-ELM). The proposed approach outperforms other comparative benchmarks with 98.25% and 99.11% as ultimate accuracy on the COVID-Xray-5k and COVIDetectioNet datasets, respectively, and it led relative error to reduce as the amount of 1.75% and 1.01% as compared to a convolutional CNN. More importantly, the time needed for training deep ChOA-ELM is only 0.9474 milliseconds, and the overall testing time for 3100 images is 2.937 seconds.

</p>
</details>

<details><summary><b>Evolving Deep Convolutional Neural Network by Hybrid Sine-Cosine and Extreme Learning Machine for Real-time COVID19 Diagnosis from X-Ray Images</b>
<a href="https://arxiv.org/abs/2105.14192">arxiv:2105.14192</a>
&#x1F4C8; 1 <br>
<p>Wu Chao, Mohammad Khishe, Mokhtar Mohammadi, Sarkhel H. Taher Karim, Tarik A. Rashid</p></summary>
<p>

**Abstract:** The COVID19 pandemic globally and significantly has affected the life and health of many communities. The early detection of infected patients is effective in fighting COVID19. Using radiology (X-Ray) images is perhaps the fastest way to diagnose the patients. Thereby, deep Convolutional Neural Networks (CNNs) can be considered as applicable tools to diagnose COVID19 positive cases. Due to the complicated architecture of a deep CNN, its real-time training and testing become a challenging problem. This paper proposes using the Extreme Learning Machine (ELM) instead of the last fully connected layer to address this deficiency. However, the parameters' stochastic tuning of ELM's supervised section causes the final model unreliability. Therefore, to cope with this problem and maintain network reliability, the sine-cosine algorithm was utilized to tune the ELM's parameters. The designed network is then benchmarked on the COVID-Xray-5k dataset, and the results are verified by a comparative study with canonical deep CNN, ELM optimized by cuckoo search, ELM optimized by genetic algorithm, and ELM optimized by whale optimization algorithm. The proposed approach outperforms comparative benchmarks with a final accuracy of 98.83% on the COVID-Xray-5k dataset, leading to a relative error reduction of 2.33% compared to a canonical deep CNN. Even more critical, the designed network's training time is only 0.9421 milliseconds and the overall detection test time for 3100 images is 2.721 seconds.

</p>
</details>

<details><summary><b>Extracting Variable-Depth Logical Document Hierarchy from Long Documents: Method, Evaluation, and Application</b>
<a href="https://arxiv.org/abs/2105.09297">arxiv:2105.09297</a>
&#x1F4C8; 1 <br>
<p>Rongyu Cao, Yixuan Cao, Ganbin Zhou, Ping Luo</p></summary>
<p>

**Abstract:** In this paper, we study the problem of extracting variable-depth "logical document hierarchy" from long documents, namely organizing the recognized "physical document objects" into hierarchical structures. The discovery of logical document hierarchy is the vital step to support many downstream applications. However, long documents, containing hundreds or even thousands of pages and variable-depth hierarchy, challenge the existing methods. To address these challenges, we develop a framework, namely Hierarchy Extraction from Long Document (HELD), where we "sequentially" insert each physical object at the proper on of the current tree. Determining whether each possible position is proper or not can be formulated as a binary classification problem. To further improve its effectiveness and efficiency, we study the design variants in HELD, including traversal orders of the insertion positions, heading extraction explicitly or implicitly, tolerance to insertion errors in predecessor steps, and so on. The empirical experiments based on thousands of long documents from Chinese, English financial market and English scientific publication show that the HELD model with the "root-to-leaf" traversal order and explicit heading extraction is the best choice to achieve the tradeoff between effectiveness and efficiency with the accuracy of 0.9726, 0.7291 and 0.9578 in Chinese financial, English financial and arXiv datasets, respectively. Finally, we show that logical document hierarchy can be employed to significantly improve the performance of the downstream passage retrieval task. In summary, we conduct a systematic study on this task in terms of methods, evaluations, and applications.

</p>
</details>

<details><summary><b>Conjunction Data Messages behave as a Poisson Process</b>
<a href="https://arxiv.org/abs/2105.08509">arxiv:2105.08509</a>
&#x1F4C8; 1 <br>
<p>Francisco Caldas, Claudia Soares, Cláudia Nunes, Marta Guimarães, Mariana Filipe, Rodrigo Ventura</p></summary>
<p>

**Abstract:** Space debris is a major problem in space exploration. International bodies continuously monitor a large database of orbiting objects and emit warnings in the form of conjunction data messages. An important question for satellite operators is to estimate when fresh information will arrive so that they can react timely but sparingly with satellite maneuvers. We propose a statistical learning model of the message arrival process, allowing us to answer two important questions: (1) Will there be any new message in the next specified time interval? (2) When exactly and with what uncertainty will the next message arrive? The average prediction error for question (2) of our Bayesian Poisson process model is smaller than the baseline in more than 4 hours in a test set of 50k close encounter events.

</p>
</details>

<details><summary><b>Hardware Synthesis of State-Space Equations; Application to FPGA Implementation of Shallow and Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2105.07131">arxiv:2105.07131</a>
&#x1F4C8; 1 <br>
<p>Amir-Hossein Kiamarzi, Pezhman Torabi, Reza Sameni</p></summary>
<p>

**Abstract:** Nowadays, shallow and deep Neural Networks (NNs) have vast applications including biomedical engineering, image processing, computer vision, and speech recognition. Many researchers have developed hardware accelerators including field-programmable gate arrays (FPGAs) for implementing high-performance and energy efficient NNs. Apparently, the hardware architecture design process is specific and time-consuming for each NN. Therefore, a systematic way to design, implement and optimize NNs is highly demanded. The paper presents a systematic approach to implement state-space models in register transfer level (RTL), with special interest for NN implementation. The proposed design flow is based on the iterative nature of state-space models and the analogy between state-space formulations and finite-state machines. The method can be used in linear/nonlinear and time-varying/time-invariant systems. It can also be used to implement either intrinsically iterative systems (widely used in various domains such as signal processing, numerical analysis, computer arithmetic, and control engineering), or systems that could be rewritten in equivalent iterative forms. The implementation of recurrent NNs such as long short-term memory (LSTM) NNs, which have intrinsic state-space forms, are another major applications for this framework. As a case study, it is shown that state-space systems can be used for the systematic implementation and optimization of NNs (as nonlinear and time-varying dynamic systems). An RTL code generating software is also provided online, which simplifies the automatic generation of NNs of arbitrary size.

</p>
</details>

<details><summary><b>Measuring the User Satisfaction in a Recommendation Interface with Multiple Carousels</b>
<a href="https://arxiv.org/abs/2105.07062">arxiv:2105.07062</a>
&#x1F4C8; 1 <br>
<p>Nicolò Felicioni, Maurizio Ferrari Dacrema, Paolo Cremonesi</p></summary>
<p>

**Abstract:** It is common for video-on-demand and music streaming services to adopt a user interface composed of several recommendation lists, i.e. widgets or swipeable carousels, each generated according to a specific criterion or algorithm (e.g. most recent, top popular, recommended for you, editors' choice, etc.). Selecting the appropriate combination of carousel has significant impact on user satisfaction. A crucial aspect of this user interface is that to measure the relevance a new carousel for the user it is not sufficient to account solely for its individual quality. Instead, it should be considered that other carousels will already be present in the interface. This is not considered by traditional evaluation protocols for recommenders systems, in which each carousel is evaluated in isolation, regardless of (i) which other carousels are displayed to the user and (ii) the relative position of the carousel with respect to other carousels. Hence, we propose a two-dimensional evaluation protocol for a carousel setting that will measure the quality of a recommendation carousel based on how much it improves upon the quality of an already available set of carousels. Our evaluation protocol takes into account also the position bias, i.e. users do not explore the carousels sequentially, but rather concentrate on the top-left corner of the screen.
  We report experiments on the movie domain and notice that under a carousel setting the definition of which criteria has to be preferred to generate a list of recommended items changes with respect to what is commonly understood.

</p>
</details>

<details><summary><b>A Hypothesis Testing Approach to Nonstationary Source Separation</b>
<a href="https://arxiv.org/abs/2105.06958">arxiv:2105.06958</a>
&#x1F4C8; 1 <br>
<p>Reza Sameni, Christian Jutten</p></summary>
<p>

**Abstract:** The extraction of nonstationary signals from blind and semi-blind multivariate observations is a recurrent problem. Numerous algorithms have been developed for this problem, which are based on the exact or approximate joint diagonalization of second or higher order cumulant matrices/tensors of multichannel data. While a great body of research has been dedicated to joint diagonalization algorithms, the selection of the diagonalized matrix/tensor set remains highly problem-specific. Herein, various methods for nonstationarity identification are reviewed and a new general framework based on hypothesis testing is proposed, which results in a classification/clustering perspective to semi-blind source separation of nonstationary components. The proposed method is applied to noninvasive fetal ECG extraction, as case study.

</p>
</details>

<details><summary><b>Deep Learning Based RIS Channel Extrapolation with Element-grouping</b>
<a href="https://arxiv.org/abs/2105.06850">arxiv:2105.06850</a>
&#x1F4C8; 1 <br>
<p>Shunbo Zhang, Shun Zhang, Feifei Gao, Jianpeng Ma, Octavia A. Dobre</p></summary>
<p>

**Abstract:** Reconfigurable intelligent surface (RIS) is considered as a revolutionary technology for future wireless communication networks. In this letter, we consider the acquisition of the cascaded channels, which is a challenging task due to the massive number of passive RIS elements. To reduce the pilot overhead, we adopt the element-grouping strategy, where each element in one group shares the same reflection coefficient and is assumed to have the same channel condition. We analyze the channel interference caused by the element-grouping strategy and further design two deep learning based networks. The first one aims to refine the partial channels by eliminating the interference, while the second one tries to extrapolate the full channels from the refined partial channels. We cascade the two networks and jointly train them. Simulation results show that the proposed scheme provides significant gain compared to the conventional element-grouping method without interference elimination.

</p>
</details>

<details><summary><b>Partitioned Deep Learning of Fluid-Structure Interaction</b>
<a href="https://arxiv.org/abs/2105.06785">arxiv:2105.06785</a>
&#x1F4C8; 1 <br>
<p>Amin Totounferoush, Axel Schumacher, Miriam Schulte</p></summary>
<p>

**Abstract:** We present a partitioned neural network-based framework for learning of fluid-structure interaction (FSI) problems. We decompose the simulation domain into two smaller sub-domains, i.e., fluid and solid domains, and incorporate an independent neural network for each. A library is used to couple the two networks which takes care of boundary data communication, data mapping and equation coupling. Simulation data are used for training of the both neural networks. We use a combination of convolutional and recurrent neural networks (CNN and RNN) to account for both spatial and temporal connectivity. A quasi-Newton method is used to accelerate the FSI coupling convergence. We observe a very good agreement between the results of the presented framework and the classical numerical methods for simulation of 1d fluid flow inside an elastic tube. This work is a preliminary step for using neural networks to speed-up the FSI coupling convergence by providing an accurate initial guess in each time step for classical numerical solvers

</p>
</details>

<details><summary><b>Cybersecurity Anomaly Detection in Adversarial Environments</b>
<a href="https://arxiv.org/abs/2105.06742">arxiv:2105.06742</a>
&#x1F4C8; 1 <br>
<p>David A. Bierbrauer, Alexander Chang, Will Kritzer, Nathaniel D. Bastian</p></summary>
<p>

**Abstract:** The proliferation of interconnected battlefield information-sharing devices, known as the Internet of Battlefield Things (IoBT), introduced several security challenges. Inherent to the IoBT operating environment is the practice of adversarial machine learning, which attempts to circumvent machine learning models. This work examines the feasibility of cost-effective unsupervised learning and graph-based methods for anomaly detection in the network intrusion detection system setting, and also leverages an ensemble approach to supervised learning of the anomaly detection problem. We incorporate a realistic adversarial training mechanism when training supervised models to enable strong classification performance in adversarial environments. The results indicate that the unsupervised and graph-based methods were outperformed in detecting anomalies (malicious activity) by the supervised stacking ensemble method with two levels. This model consists of three different classifiers in the first level, followed by either a Naive Bayes or Decision Tree classifier for the second level. The model maintains an F1-score above 0.97 for malicious samples across all tested level two classifiers. Notably, Naive Bayes is the fastest level two classifier averaging 1.12 seconds while Decision Tree maintains the highest AUC score of 0.98.

</p>
</details>

<details><summary><b>A Heuristically Assisted Deep Reinforcement Learning Approach for Network Slice Placement</b>
<a href="https://arxiv.org/abs/2105.06741">arxiv:2105.06741</a>
&#x1F4C8; 1 <br>
<p>Jose Jurandir Alves Esteves, Amina Boubendir, Fabrice Guillemin, Pierre Sens</p></summary>
<p>

**Abstract:** Network Slice placement with the problem of allocation of resources from a virtualized substrate network is an optimization problem which can be formulated as a multiobjective Integer Linear Programming (ILP) problem. However, to cope with the complexity of such a continuous task and seeking for optimality and automation, the use of Machine Learning (ML) techniques appear as a promising approach. We introduce a hybrid placement solution based on Deep Reinforcement Learning (DRL) and a dedicated optimization heuristic based on the Power of Two Choices principle. The DRL algorithm uses the so-called Asynchronous Advantage Actor Critic (A3C) algorithm for fast learning, and Graph Convolutional Networks (GCN) to automate feature extraction from the physical substrate network. The proposed Heuristically-Assisted DRL (HA-DRL) allows to accelerate the learning process and gain in resource usage when compared against other state-of-the-art approaches as the evaluation results evidence.

</p>
</details>

<details><summary><b>Verification of Size Invariance in DNN Activations using Concept Embeddings</b>
<a href="https://arxiv.org/abs/2105.06727">arxiv:2105.06727</a>
&#x1F4C8; 1 <br>
<p>Gesina Schwalbe</p></summary>
<p>

**Abstract:** The benefits of deep neural networks (DNNs) have become of interest for safety critical applications like medical ones or automated driving. Here, however, quantitative insights into the DNN inner representations are mandatory. One approach to this is concept analysis, which aims to establish a mapping between the internal representation of a DNN and intuitive semantic concepts. Such can be sub-objects like human body parts that are valuable for validation of pedestrian detection. To our knowledge, concept analysis has not yet been applied to large object detectors, specifically not for sub-parts. Therefore, this work first suggests a substantially improved version of the Net2Vec approach (arXiv:1801.03454) for post-hoc segmentation of sub-objects. Its practical applicability is then demonstrated on a new concept dataset by two exemplary assessments of three standard networks, including the larger Mask R-CNN model (arXiv:1703.06870): (1) the consistency of body part similarity, and (2) the invariance of internal representations of body parts with respect to the size in pixels of the depicted person. The findings show that the representation of body parts is mostly size invariant, which may suggest an early intelligent fusion of information in different size categories.

</p>
</details>

<details><summary><b>Innovation Compression for Communication-efficient Distributed Optimization with Linear Convergence</b>
<a href="https://arxiv.org/abs/2105.06697">arxiv:2105.06697</a>
&#x1F4C8; 1 <br>
<p>Jiaqi Zhang, Keyou You, Lihua Xie</p></summary>
<p>

**Abstract:** Information compression is essential to reduce communication cost in distributed optimization over peer-to-peer networks. This paper proposes a communication-efficient linearly convergent distributed (COLD) algorithm to solve strongly convex optimization problems. By compressing innovation vectors, which are the differences between decision vectors and their estimates, COLD is able to achieve linear convergence for a class of $δ$-contracted compressors. We explicitly quantify how the compression affects the convergence rate and show that COLD matches the same rate of its uncompressed version. To accommodate a wider class of compressors that includes the binary quantizer, we further design a novel dynamical scaling mechanism and obtain the linearly convergent Dyna-COLD. Importantly, our results strictly improve existing results for the quantized consensus problem. Numerical experiments demonstrate the advantages of both algorithms under different compressors.

</p>
</details>

<details><summary><b>SA-GAN: Structure-Aware GAN for Organ-Preserving Synthetic CT Generation</b>
<a href="https://arxiv.org/abs/2105.07044">arxiv:2105.07044</a>
&#x1F4C8; 0 <br>
<p>Hajar Emami, Ming Dong, Siamak Nejad-Davarani, Carri Glide-Hurst</p></summary>
<p>

**Abstract:** In medical image synthesis, model training could be challenging due to the inconsistencies between images of different modalities even with the same patient, typically caused by internal status/tissue changes as different modalities are usually obtained at a different time. This paper proposes a novel deep learning method, Structure-aware Generative Adversarial Network (SA-GAN), that preserves the shapes and locations of in-consistent structures when generating medical images. SA-GAN is employed to generate synthetic computed tomography (synCT) images from magnetic resonance imaging (MRI) with two parallel streams: the global stream translates the input from the MRI to the CT domain while the local stream automatically segments the inconsistent organs, maintains their locations and shapes in MRI, and translates the organ intensities to CT. Through extensive experiments on a pelvic dataset, we demonstrate that SA-GAN provides clinically acceptable accuracy on both synCTs and organ segmentation and supports MR-only treatment planning in disease sites with internal organ status changes.

</p>
</details>

<details><summary><b>Posterior Regularization on Bayesian Hierarchical Mixture Clustering</b>
<a href="https://arxiv.org/abs/2105.06903">arxiv:2105.06903</a>
&#x1F4C8; 0 <br>
<p>Weipeng Huang, Tin Lok James Ng, Nishma Laitonjam, Neil J. Hurley</p></summary>
<p>

**Abstract:** Bayesian hierarchical mixture clustering (BHMC) is an interesting model that improves on the traditional Bayesian hierarchical clustering approaches. Regarding the parent-to-node diffusion in the generative process, BHMC replaces the conventional Gaussian-to-Gaussian (G2G) kernels with a Hierarchical Dirichlet Process Mixture Model (HDPMM). However, the drawback of the BHMC lies in that it might obtain comparatively high nodal variance in the higher levels (i.e., those closer to the root node). This can be interpreted as that the separation between the nodes, in particular those in the higher levels, might be weak. Attempting to overcome this drawback, we consider a recent inferential framework named posterior regularization, which facilitates a simple manner to impose extra constraints on a Bayesian model to address some weakness of the original model. Hence, to enhance the separation of clusters, we apply posterior regularization to impose max-margin constraints on the nodes at every level of the hierarchy. In this paper, we illustrate how the framework integrates with the BHMC and achieves the desired improvements over the original model.

</p>
</details>

<details><summary><b>A Frequency Domain Constraint for Synthetic and Real X-ray Image Super Resolution</b>
<a href="https://arxiv.org/abs/2105.06887">arxiv:2105.06887</a>
&#x1F4C8; 0 <br>
<p>Qing Ma, Jae Chul Koh, WonSook Lee</p></summary>
<p>

**Abstract:** Synthetic X-ray images are simulated X-ray images projected from CT data. High-quality synthetic X-ray images can facilitate various applications such as surgical image guidance systems and VR training simulations. However, it is difficult to produce high-quality arbitrary view synthetic X-ray images in real-time due to different CT slice thickness, high computational cost, and the complexity of algorithms. Our goal is to generate high-resolution synthetic X-ray images in real-time by upsampling low-resolution images with deep learning-based super-resolution methods. Reference-based Super Resolution (RefSR) has been well studied in recent years and has shown higher performance than traditional Single Image Super-Resolution (SISR). It can produce fine details by utilizing the reference image but still inevitably generates some artifacts and noise. In this paper, we introduce frequency domain loss as a constraint to further improve the quality of the RefSR results with fine details and without obvious artifacts. To the best of our knowledge, this is the first paper utilizing the frequency domain for the loss functions in the field of super-resolution. We achieved good results in evaluating our method on both synthetic and real X-ray image datasets.

</p>
</details>

<details><summary><b>Predicting speech intelligibility from EEG in a non-linear classification paradigm</b>
<a href="https://arxiv.org/abs/2105.06844">arxiv:2105.06844</a>
&#x1F4C8; 0 <br>
<p>Bernd Accou, Mohammad Jalilpour Monesi, Hugo Van hamme, Tom Francart</p></summary>
<p>

**Abstract:** Objective: Currently, only behavioral speech understanding tests are available, which require active participation of the person being tested. As this is infeasible for certain populations, an objective measure of speech intelligibility is required. Recently, brain imaging data has been used to establish a relationship between stimulus and brain response. Linear models have been successfully linked to speech intelligibility but require per-subject training. We present a deep-learning-based model incorporating dilated convolutions that operates in a match/mismatch paradigm. The accuracy of the model's match/mismatch predictions can be used as a proxy for speech intelligibility without subject-specific (re)training. Approach: We evaluated the performance of the model as a function of input segment length, EEG frequency band and receptive field size while comparing it to multiple baseline models. Next, we evaluated performance on held-out data and finetuning. Finally, we established a link between the accuracy of our model and the state-of-the-art behavioral MATRIX test. Main results: The dilated convolutional model significantly outperformed the baseline models for every input segment length, for all EEG frequency bands except the delta and theta band, and receptive field sizes between 250 and 500 ms. Additionally, finetuning significantly increased the accuracy on a held-out dataset. Finally, a significant correlation (r=0.59, p=0.0154) was found between the speech reception threshold estimated using the behavioral MATRIX test and our objective method. Significance: Our method is the first to predict the speech reception threshold from EEG for unseen subjects, contributing to objective measures of speech intelligibility.

</p>
</details>

<details><summary><b>DARNet: Dual-Attention Residual Network for Automatic Diagnosis of COVID-19 via CT Images</b>
<a href="https://arxiv.org/abs/2105.06779">arxiv:2105.06779</a>
&#x1F4C8; 0 <br>
<p>Jun Shi, Huite Yi, Shulan Ruan, Zhaohui Wang, Xiaoyu Hao, Hong An, Wei Wei</p></summary>
<p>

**Abstract:** The ongoing global pandemic of Coronavirus Disease 2019 (COVID-19) poses a serious threat to public health and the economy. Rapid and accurate diagnosis of COVID-19 is crucial to prevent the further spread of the disease and reduce its mortality. Chest Computed tomography (CT) is an effective tool for the early diagnosis of lung diseases including pneumonia. However, detecting COVID-19 from CT is demanding and prone to human errors as some early-stage patients may have negative findings on images. Recently, many deep learning methods have achieved impressive performance in this regard. Despite their effectiveness, most of these methods underestimate the rich spatial information preserved in the 3D structure or suffer from the propagation of errors. To address this problem, we propose a Dual-Attention Residual Network (DARNet) to automatically identify COVID-19 from other common pneumonia (CP) and healthy people using 3D chest CT images. Specifically, we design a dual-attention module consisting of channel-wise attention and depth-wise attention mechanisms. The former is utilized to enhance channel independence, while the latter is developed to recalibrate the depth-level features. Then, we integrate them in a unified manner to extract and refine the features at different levels to further improve the diagnostic performance. We evaluate DARNet on a large public CT dataset and obtain superior performance. Besides, the ablation study and visualization analysis prove the effectiveness and interpretability of the proposed method.

</p>
</details>


[Next Page](2021/2021-05/2021-05-13.md)
