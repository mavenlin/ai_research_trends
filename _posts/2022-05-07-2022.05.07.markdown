Prev: [2022.05.06]({{ '/2022/05/06/2022.05.06.html' | relative_url }})  Next: [2022.05.08]({{ '/2022/05/08/2022.05.08.html' | relative_url }})
{% raw %}
## Summary for 2022-05-07, created on 2022-05-14


<details><summary><b>Transformer-Empowered 6G Intelligent Networks: From Massive MIMO Processing to Semantic Communication</b>
<a href="https://arxiv.org/abs/2205.03770">arxiv:2205.03770</a>
&#x1F4C8; 9 <br>
<p>Yang Wang, Zhen Gao, Dezhi Zheng, Sheng Chen, Deniz Gündüz, H. Vincent Poor</p></summary>
<p>

**Abstract:** 6G wireless networks are foreseen to speed up the convergence of the physical and cyber worlds and to enable a paradigm-shift in the way we deploy and exploit communication networks. Machine learning, in particular deep learning (DL), is going to be one of the key technological enablers of 6G by offering a new paradigm for the design and optimization of networks with a high level of intelligence. In this article, we introduce an emerging DL architecture, known as the transformer, and discuss its potential impact on 6G network design. We first discuss the differences between the transformer and classical DL architectures, and emphasize the transformer's self-attention mechanism and strong representation capabilities, which make it particularly appealing in tackling various challenges in wireless network design. Specifically, we propose transformer-based solutions for massive multiple-input multiple-output (MIMO) systems and various semantic communication problems in 6G networks. Finally, we discuss key challenges and open issues in transformer-based solutions, and identify future research directions for their deployment in intelligent 6G networks.

</p>
</details>

<details><summary><b>ConceptDistil: Model-Agnostic Distillation of Concept Explanations</b>
<a href="https://arxiv.org/abs/2205.03601">arxiv:2205.03601</a>
&#x1F4C8; 8 <br>
<p>João Bento Sousa, Ricardo Moreira, Vladimir Balayan, Pedro Saleiro, Pedro Bizarro</p></summary>
<p>

**Abstract:** Concept-based explanations aims to fill the model interpretability gap for non-technical humans-in-the-loop. Previous work has focused on providing concepts for specific models (eg, neural networks) or data types (eg, images), and by either trying to extract concepts from an already trained network or training self-explainable models through multi-task learning. In this work, we propose ConceptDistil, a method to bring concept explanations to any black-box classifier using knowledge distillation. ConceptDistil is decomposed into two components:(1) a concept model that predicts which domain concepts are present in a given instance, and (2) a distillation model that tries to mimic the predictions of a black-box model using the concept model predictions. We validate ConceptDistil in a real world use-case, showing that it is able to optimize both tasks, bringing concept-explainability to any black-box model.

</p>
</details>

<details><summary><b>Math-KG: Construction and Applications of Mathematical Knowledge Graph</b>
<a href="https://arxiv.org/abs/2205.03772">arxiv:2205.03772</a>
&#x1F4C8; 7 <br>
<p>Jianing Wang</p></summary>
<p>

**Abstract:** Recently, the explosion of online education platforms makes a success in encouraging us to easily access online education resources. However, most of them ignore the integration of massive unstructured information, which inevitably brings the problem of \textit{information overload} and \textit{knowledge trek}. In this paper, we proposed a mathematical knowledge graph named Math-KG, which automatically constructed by the pipeline method with the natural language processing technology to integrate the resources of the mathematics. It is built from the corpora of Baidu Baike, Wikipedia. We implement a simple application system to validate the proposed Math-KG can make contributions on a series of scenes, including faults analysis and semantic search. The system is publicly available at GitHub \footnote{\url{https://github.com/wjn1996/Mathematical-Knowledge-Entity-Recognition}.}.

</p>
</details>

<details><summary><b>Keratoconus Classifier for Smartphone-based Corneal Topographer</b>
<a href="https://arxiv.org/abs/2205.03702">arxiv:2205.03702</a>
&#x1F4C8; 5 <br>
<p>Siddhartha Gairola, Pallavi Joshi, Anand Balasubramaniam, Kaushik Murali, Nipun Kwatra, Mohit Jain</p></summary>
<p>

**Abstract:** Keratoconus is a severe eye disease that leads to deformation of the cornea. It impacts people aged 10-25 years and is the leading cause of blindness in that demography. Corneal topography is the gold standard for keratoconus diagnosis. It is a non-invasive process performed using expensive and bulky medical devices called corneal topographers. This makes it inaccessible to large populations, especially in the Global South. Low-cost smartphone-based corneal topographers, such as SmartKC, have been proposed to make keratoconus diagnosis accessible. Similar to medical-grade topographers, SmartKC outputs curvature heatmaps and quantitative metrics that need to be evaluated by doctors for keratoconus diagnosis. An automatic scheme for evaluation of these heatmaps and quantitative values can play a crucial role in screening keratoconus in areas where doctors are not available. In this work, we propose a dual-head convolutional neural network (CNN) for classifying keratoconus on the heatmaps generated by SmartKC. Since SmartKC is a new device and only had a small dataset (114 samples), we developed a 2-stage transfer learning strategy -- using historical data collected from a medical-grade topographer and a subset of SmartKC data -- to satisfactorily train our network. This, combined with our domain-specific data augmentations, achieved a sensitivity of 91.3% and a specificity of 94.2%.

</p>
</details>

<details><summary><b>Label Adversarial Learning for Skeleton-level to Pixel-level Adjustable Vessel Segmentation</b>
<a href="https://arxiv.org/abs/2205.03646">arxiv:2205.03646</a>
&#x1F4C8; 5 <br>
<p>Mingchao Li, Kun Huang, Zetian Zhang, Xiao Ma, Qiang Chen</p></summary>
<p>

**Abstract:** You can have your cake and eat it too. Microvessel segmentation in optical coherence tomography angiography (OCTA) images remains challenging. Skeleton-level segmentation shows clear topology but without diameter information, while pixel-level segmentation shows a clear caliber but low topology. To close this gap, we propose a novel label adversarial learning (LAL) for skeleton-level to pixel-level adjustable vessel segmentation. LAL mainly consists of two designs: a label adversarial loss and an embeddable adjustment layer. The label adversarial loss establishes an adversarial relationship between the two label supervisions, while the adjustment layer adjusts the network parameters to match the different adversarial weights. Such a design can efficiently capture the variation between the two supervisions, making the segmentation continuous and tunable. This continuous process allows us to recommend high-quality vessel segmentation with clear caliber and topology. Experimental results show that our results outperform manual annotations of current public datasets and conventional filtering effects. Furthermore, such a continuous process can also be used to generate an uncertainty map representing weak vessel boundaries and noise.

</p>
</details>

<details><summary><b>Towards Computationally Feasible Deep Active Learning</b>
<a href="https://arxiv.org/abs/2205.03598">arxiv:2205.03598</a>
&#x1F4C8; 5 <br>
<p>Akim Tsvigun, Artem Shelmanov, Gleb Kuzmin, Leonid Sanochkin, Daniil Larionov, Gleb Gusev, Manvel Avetisian, Leonid Zhukov</p></summary>
<p>

**Abstract:** Active learning (AL) is a prominent technique for reducing the annotation effort required for training machine learning models. Deep learning offers a solution for several essential obstacles to deploying AL in practice but introduces many others. One of such problems is the excessive computational resources required to train an acquisition model and estimate its uncertainty on instances in the unlabeled pool. We propose two techniques that tackle this issue for text classification and tagging tasks, offering a substantial reduction of AL iteration duration and the computational overhead introduced by deep acquisition models in AL. We also demonstrate that our algorithm that leverages pseudo-labeling and distilled models overcomes one of the essential obstacles revealed previously in the literature. Namely, it was shown that due to differences between an acquisition model used to select instances during AL and a successor model trained on the labeled data, the benefits of AL can diminish. We show that our algorithm, despite using a smaller and faster acquisition model, is capable of training a more expressive successor model with higher performance.

</p>
</details>

<details><summary><b>Number Entity Recognition</b>
<a href="https://arxiv.org/abs/2205.03559">arxiv:2205.03559</a>
&#x1F4C8; 5 <br>
<p>Dhanasekar Sundararaman, Vivek Subramanian, Guoyin Wang, Liyan Xu, Lawrence Carin</p></summary>
<p>

**Abstract:** Numbers are essential components of text, like any other word tokens, from which natural language processing (NLP) models are built and deployed. Though numbers are typically not accounted for distinctly in most NLP tasks, there is still an underlying amount of numeracy already exhibited by NLP models. In this work, we attempt to tap this potential of state-of-the-art NLP models and transfer their ability to boost performance in related tasks. Our proposed classification of numbers into entities helps NLP models perform well on several tasks, including a handcrafted Fill-In-The-Blank (FITB) task and on question answering using joint embeddings, outperforming the BERT and RoBERTa baseline classification.

</p>
</details>

<details><summary><b>Towards a Progression-Aware Autonomous Dialogue Agent</b>
<a href="https://arxiv.org/abs/2205.03692">arxiv:2205.03692</a>
&#x1F4C8; 4 <br>
<p>Abraham Sanders, Tomek Strzalkowski, Mei Si, Albert Chang, Deepanshu Dey, Jonas Braasch, Dakuo Wang</p></summary>
<p>

**Abstract:** Recent advances in large-scale language modeling and generation have enabled the creation of dialogue agents that exhibit human-like responses in a wide range of conversational scenarios spanning a diverse set of tasks, from general chit-chat to focused goal-oriented discourse. While these agents excel at generating high-quality responses that are relevant to prior context, they suffer from a lack of awareness of the overall direction in which the conversation is headed, and the likelihood of task success inherent therein. Thus, we propose a framework in which dialogue agents can evaluate the progression of a conversation toward or away from desired outcomes, and use this signal to inform planning for subsequent responses. Our framework is composed of three key elements: (1) the notion of a "global" dialogue state (GDS) space, (2) a task-specific progression function (PF) computed in terms of a conversation's trajectory through this space, and (3) a planning mechanism based on dialogue rollouts by which an agent may use progression signals to select its next response.

</p>
</details>

<details><summary><b>BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with Graph Information Bottleneck</b>
<a href="https://arxiv.org/abs/2205.03612">arxiv:2205.03612</a>
&#x1F4C8; 4 <br>
<p>Kaizhong Zheng, Shujian Yu, Baojuan Li, Robert Jenssen, Badong Chen</p></summary>
<p>

**Abstract:** Developing a new diagnostic models based on the underlying biological mechanisms rather than subjective symptoms for psychiatric disorders is an emerging consensus. Recently, machine learning-based classifiers using functional connectivity (FC) for psychiatric disorders and healthy controls are developed to identify brain markers. However, existing machine learningbased diagnostic models are prone to over-fitting (due to insufficient training samples) and perform poorly in new test environment. Furthermore, it is difficult to obtain explainable and reliable brain biomarkers elucidating the underlying diagnostic decisions. These issues hinder their possible clinical applications. In this work, we propose BrainIB, a new graph neural network (GNN) framework to analyze functional magnetic resonance images (fMRI), by leveraging the famed Information Bottleneck (IB) principle. BrainIB is able to identify the most informative regions in the brain (i.e., subgraph) and generalizes well to unseen data. We evaluate the performance of BrainIB against 6 popular brain network classification methods on two multi-site, largescale datasets and observe that our BrainIB always achieves the highest diagnosis accuracy. It also discovers the subgraph biomarkers which are consistent to clinical and neuroimaging findings.

</p>
</details>

<details><summary><b>Multi-Target Active Object Tracking with Monte Carlo Tree Search and Target Motion Modeling</b>
<a href="https://arxiv.org/abs/2205.03555">arxiv:2205.03555</a>
&#x1F4C8; 4 <br>
<p>Zheng Chen, Jian Zhao, Mingyu Yang, Wengang Zhou, Houqiang Li</p></summary>
<p>

**Abstract:** In this work, we are dedicated to multi-target active object tracking (AOT), where there are multiple targets as well as multiple cameras in the environment. The goal is maximize the overall target coverage of all cameras. Previous work makes a strong assumption that each camera is fixed in a location and only allowed to rotate, which limits its application. In this work, we relax the setting by allowing all cameras to both move along the boundary lines and rotate. In our setting, the action space becomes much larger, which leads to much higher computational complexity to identify the optimal action. To this end, we propose to leverage the action selection from multi-agent reinforcement learning (MARL) network to prune the search tree of Monte Carlo Tree Search (MCTS) method, so as to find the optimal action more efficiently. Besides, we model the motion of the targets to predict the future position of the targets, which makes a better estimation of the future environment state in the MCTS process. We establish a multi-target 2D environment to simulate the sports games, and experimental results demonstrate that our method can effectively improve the target coverage.

</p>
</details>

<details><summary><b>Adaptive Graph Convolutional Network Framework for Multidimensional Time Series Prediction</b>
<a href="https://arxiv.org/abs/2205.04885">arxiv:2205.04885</a>
&#x1F4C8; 3 <br>
<p>Ning Wang</p></summary>
<p>

**Abstract:** In the real world, long sequence time-series forecasting (LSTF) is needed in many cases, such as power consumption prediction and air quality prediction.Multi-dimensional long time series model has more strict requirements on the model, which not only needs to effectively capture the accurate long-term dependence between input and output, but also needs to capture the relationship between data of different dimensions.Recent research shows that the Informer model based on Transformer has achieved excellent performance in long time series prediction.However, this model still has some deficiencies in multidimensional prediction,it cannot capture the relationship between different dimensions well. We improved Informer to address its shortcomings in multidimensional forecasting. First,we introduce an adaptive graph neural network to capture hidden dimension dependencies in mostly time series prediction. Secondly,we integrate adaptive graph convolutional networks into various spatio-temporal series prediction models to solve the defect that they cannot capture the relationship between different dimensions. Thirdly,After experimental testing with multiple data sets, the accuracy of our framework improved by about 10\% after being introduced into the model.

</p>
</details>

<details><summary><b>Mutual Distillation Learning Network for Trajectory-User Linking</b>
<a href="https://arxiv.org/abs/2205.03773">arxiv:2205.03773</a>
&#x1F4C8; 3 <br>
<p>Wei Chen, Shuzhe Li, Chao Huang, Yanwei Yu, Yongguo Jiang, Junyu Dong</p></summary>
<p>

**Abstract:** Trajectory-User Linking (TUL), which links trajectories to users who generate them, has been a challenging problem due to the sparsity in check-in mobility data. Existing methods ignore the utilization of historical data or rich contextual features in check-in data, resulting in poor performance for TUL task. In this paper, we propose a novel Mutual distillation learning network to solve the TUL problem for sparse check-in mobility data, named MainTUL. Specifically, MainTUL is composed of a Recurrent Neural Network (RNN) trajectory encoder that models sequential patterns of input trajectory and a temporal-aware Transformer trajectory encoder that captures long-term time dependencies for the corresponding augmented historical trajectories. Then, the knowledge learned on historical trajectories is transferred between the two trajectory encoders to guide the learning of both encoders to achieve mutual distillation of information. Experimental results on two real-world check-in mobility datasets demonstrate the superiority of MainTUL against state-of-the-art baselines. The source code of our model is available at https://github.com/Onedean/MainTUL.

</p>
</details>

<details><summary><b>Empowering parameter-efficient transfer learning by recognizing the kernel structure in self-attention</b>
<a href="https://arxiv.org/abs/2205.03720">arxiv:2205.03720</a>
&#x1F4C8; 3 <br>
<p>Yifan Chen, Devamanyu Hazarika, Mahdi Namazifar, Yang Liu, Di Jin, Dilek Hakkani-Tur</p></summary>
<p>

**Abstract:** The massive amount of trainable parameters in the pre-trained language models (PLMs) makes them hard to be deployed to multiple downstream tasks. To address this issue, parameter-efficient transfer learning methods have been proposed to tune only a few parameters during fine-tuning while freezing the rest. This paper looks at existing methods along this line through the \textit{kernel lens}. Motivated by the connection between self-attention in transformer-based PLMs and kernel learning, we propose \textit{kernel-wise adapters}, namely \textit{Kernel-mix}, that utilize the kernel structure in self-attention to guide the assignment of the tunable parameters. These adapters use guidelines found in classical kernel learning and enable separate parameter tuning for each attention head. Our empirical results, over a diverse set of natural language generation and understanding tasks, show that our proposed adapters can attain or improve the strong performance of existing baselines.

</p>
</details>

<details><summary><b>Multi-level Contrastive Learning for Cross-lingual Spoken Language Understanding</b>
<a href="https://arxiv.org/abs/2205.03656">arxiv:2205.03656</a>
&#x1F4C8; 3 <br>
<p>Shining Liang, Linjun Shou, Jian Pei, Ming Gong, Wanli Zuo, Xianglin Zuo, Daxin Jiang</p></summary>
<p>

**Abstract:** Although spoken language understanding (SLU) has achieved great success in high-resource languages, such as English, it remains challenging in low-resource languages mainly due to the lack of high quality training data. The recent multilingual code-switching approach samples some words in an input utterance and replaces them by expressions in some other languages of the same meaning. The multilingual code-switching approach achieves better alignments of representations across languages in zero-shot cross-lingual SLU. Surprisingly, all existing multilingual code-switching methods disregard the inherent semantic structure in SLU, i.e., most utterances contain one or more slots, and each slot consists of one or more words. In this paper, we propose to exploit the "utterance-slot-word" structure of SLU and systematically model this structure by a multi-level contrastive learning framework at the utterance, slot, and word levels. We develop novel code-switching schemes to generate hard negative examples for contrastive learning at all levels. Furthermore, we develop a label-aware joint model to leverage label semantics for cross-lingual knowledge transfer. Our experimental results show that our proposed methods significantly improve the performance compared with the strong baselines on two zero-shot cross-lingual SLU benchmark datasets.

</p>
</details>

<details><summary><b>Search-Based Testing of Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2205.04887">arxiv:2205.04887</a>
&#x1F4C8; 2 <br>
<p>Martin Tappler, Filip Cano Córdoba, Bernhard K. Aichernig, Bettina Könighofer</p></summary>
<p>

**Abstract:** Evaluation of deep reinforcement learning (RL) is inherently challenging. Especially the opaqueness of learned policies and the stochastic nature of both agents and environments make testing the behavior of deep RL agents difficult. We present a search-based testing framework that enables a wide range of novel analysis capabilities for evaluating the safety and performance of deep RL agents. For safety testing, our framework utilizes a search algorithm that searches for a reference trace that solves the RL task. The backtracking states of the search, called boundary states, pose safety-critical situations. We create safety test-suites that evaluate how well the RL agent escapes safety-critical situations near these boundary states. For robust performance testing, we create a diverse set of traces via fuzz testing. These fuzz traces are used to bring the agent into a wide variety of potentially unknown states from which the average performance of the agent is compared to the average performance of the fuzz traces. We apply our search-based testing approach on RL for Nintendo's Super Mario Bros.

</p>
</details>

<details><summary><b>RoViST:Learning Robust Metrics for Visual Storytelling</b>
<a href="https://arxiv.org/abs/2205.03774">arxiv:2205.03774</a>
&#x1F4C8; 2 <br>
<p>Eileen Wang, Caren Han, Josiah Poon</p></summary>
<p>

**Abstract:** Visual storytelling (VST) is the task of generating a story paragraph that describes a given image sequence. Most existing storytelling approaches have evaluated their models using traditional natural language generation metrics like BLEU or CIDEr. However, such metrics based on n-gram matching tend to have poor correlation with human evaluation scores and do not explicitly consider other criteria necessary for storytelling such as sentence structure or topic coherence. Moreover, a single score is not enough to assess a story as it does not inform us about what specific errors were made by the model. In this paper, we propose 3 evaluation metrics sets that analyses which aspects we would look for in a good story: 1) visual grounding, 2) coherence, and 3) non-redundancy. We measure the reliability of our metric sets by analysing its correlation with human judgement scores on a sample of machine stories obtained from 4 state-of-the-arts models trained on the Visual Storytelling Dataset (VIST). Our metric sets outperforms other metrics on human correlation, and could be served as a learning based evaluation metric set that is complementary to existing rule-based metrics.

</p>
</details>

<details><summary><b>Select and Calibrate the Low-confidence: Dual-Channel Consistency based Graph Convolutional Networks</b>
<a href="https://arxiv.org/abs/2205.03753">arxiv:2205.03753</a>
&#x1F4C8; 2 <br>
<p>Shuhao Shi, Jian Chen, Kai Qiao, Shuai Yang, Linyuan Wang, Bin Yan</p></summary>
<p>

**Abstract:** The Graph Convolutional Networks (GCNs) have achieved excellent results in node classification tasks, but the model's performance at low label rates is still unsatisfactory. Previous studies in Semi-Supervised Learning (SSL) for graph have focused on using network predictions to generate soft pseudo-labels or instructing message propagation, which inevitably contains the incorrect prediction due to the over-confident in the predictions. Our proposed Dual-Channel Consistency based Graph Convolutional Networks (DCC-GCN) uses dual-channel to extract embeddings from node features and topological structures, and then achieves reliable low-confidence and high-confidence samples selection based on dual-channel consistency. We further confirmed that the low-confidence samples obtained based on dual-channel consistency were low in accuracy, constraining the model's performance. Unlike previous studies ignoring low-confidence samples, we calibrate the feature embeddings of the low-confidence samples by using the neighborhood's high-confidence samples. Our experiments have shown that the DCC-GCN can more accurately distinguish between low-confidence and high-confidence samples, and can also significantly improve the accuracy of low-confidence samples. We conducted extensive experiments on the benchmark datasets and demonstrated that DCC-GCN is significantly better than state-of-the-art baselines at different label rates.

</p>
</details>

<details><summary><b>End-to-End Rubbing Restoration Using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2205.03743">arxiv:2205.03743</a>
&#x1F4C8; 2 <br>
<p>Gongbo Sun, Zijie Zheng, Ming Zhang</p></summary>
<p>

**Abstract:** Rubbing restorations are significant for preserving world cultural history. In this paper, we propose the RubbingGAN model for restoring incomplete rubbing characters. Specifically, we collect characters from the Zhang Menglong Bei and build up the first rubbing restoration dataset. We design the first generative adversarial network for rubbing restoration. Based on the dataset we collect, we apply the RubbingGAN to learn the Zhang Menglong Bei font style and restore the characters. The results of experiments show that RubbingGAN can repair both slightly and severely incomplete rubbing characters fast and effectively.

</p>
</details>

<details><summary><b>Category-Independent Articulated Object Tracking with Factor Graphs</b>
<a href="https://arxiv.org/abs/2205.03721">arxiv:2205.03721</a>
&#x1F4C8; 2 <br>
<p>Nick Heppert, Toki Migimatsu, Brent Yi, Claire Chen, Jeannette Bohg</p></summary>
<p>

**Abstract:** Robots deployed in human-centric environments may need to manipulate a diverse range of articulated objects, such as doors, dishwashers, and cabinets. Articulated objects often come with unexpected articulation mechanisms that are inconsistent with categorical priors: for example, a drawer might rotate about a hinge joint instead of sliding open. We propose a category-independent framework for predicting the articulation models of unknown objects from sequences of RGB-D images. The prediction is performed by a two-step process: first, a visual perception module tracks object part poses from raw images, and second, a factor graph takes these poses and infers the articulation model including the current configuration between the parts as a 6D twist. We also propose a manipulation-oriented metric to evaluate predicted joint twists in terms of how well a compliant robot controller would be able to manipulate the articulated object given the predicted twist. We demonstrate that our visual perception and factor graph modules outperform baselines on simulated data and show the applicability of our factor graph on real world data.

</p>
</details>

<details><summary><b>Rate-Optimal Contextual Online Matching Bandit</b>
<a href="https://arxiv.org/abs/2205.03699">arxiv:2205.03699</a>
&#x1F4C8; 2 <br>
<p>Yuantong Li, Chi-hua Wang, Guang Cheng, Will Wei Sun</p></summary>
<p>

**Abstract:** Two-sided online matching platforms have been employed in various markets. However, agents' preferences in present market are usually implicit and unknown and must be learned from data. With the growing availability of side information involved in the decision process, modern online matching methodology demands the capability to track preference dynamics for agents based on their contextual information. This motivates us to consider a novel Contextual Online Matching Bandit prOblem (COMBO), which allows dynamic preferences in matching decisions. Existing works focus on multi-armed bandit with static preference, but this is insufficient: the two-sided preference changes as along as one-side's contextual information updates, resulting in non-static matching. In this paper, we propose a Centralized Contextual - Explore Then Commit (CC-ETC) algorithm to adapt to the COMBO. CC-ETC solves online matching with dynamic preference. In theory, we show that CC-ETC achieves a sublinear regret upper bound O(log(T)) and is a rate-optimal algorithm by proving a matching lower bound. In the experiments, we demonstrate that CC-ETC is robust to variant preference schemes, dimensions of contexts, reward noise levels, and contexts variation levels.

</p>
</details>

<details><summary><b>Playing Tic-Tac-Toe Games with Intelligent Single-pixel Imaging</b>
<a href="https://arxiv.org/abs/2205.03663">arxiv:2205.03663</a>
&#x1F4C8; 2 <br>
<p>Shuming Jiao, Jiaxiang Li, Wei Huang, Zibang Zhang</p></summary>
<p>

**Abstract:** Single-pixel imaging (SPI) is a novel optical imaging technique by replacing a two-dimensional pixelated sensor with a single-pixel detector and pattern illuminations. SPI have been extensively used for various tasks related to image acquisition and processing. In this work, a novel non-image-based task of playing Tic-Tac-Toe games interactively is merged into the framework of SPI. An optoelectronic artificial intelligent (AI) player with minimal digital computation can detect the game states, generate optimal moves and display output results mainly by pattern illumination and single-pixel detection. Simulated and experimental results demonstrate the feasibility of proposed scheme and its unbeatable performance against human players.

</p>
</details>

<details><summary><b>Towards Robust 3D Object Recognition with Dense-to-Sparse Deep Domain Adaptation</b>
<a href="https://arxiv.org/abs/2205.03654">arxiv:2205.03654</a>
&#x1F4C8; 2 <br>
<p>Prajval Kumar Murali, Cong Wang, Ravinder Dahiya, Mohsen Kaboli</p></summary>
<p>

**Abstract:** Three-dimensional (3D) object recognition is crucial for intelligent autonomous agents such as autonomous vehicles and robots alike to operate effectively in unstructured environments. Most state-of-art approaches rely on relatively dense point clouds and performance drops significantly for sparse point clouds. Unsupervised domain adaption allows to minimise the discrepancy between dense and sparse point clouds with minimal unlabelled sparse point clouds, thereby saving additional sparse data collection, annotation and retraining costs. In this work, we propose a novel method for point cloud based object recognition with competitive performance with state-of-art methods on dense and sparse point clouds while being trained only with dense point clouds.

</p>
</details>

<details><summary><b>Automatic Block-wise Pruning with Auxiliary Gating Structures for Deep Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2205.03602">arxiv:2205.03602</a>
&#x1F4C8; 2 <br>
<p>Zhaofeng Si, Honggang Qi, Xiaoyu Song</p></summary>
<p>

**Abstract:** Convolutional neural networks are prevailing in deep learning tasks. However, they suffer from massive cost issues when working on mobile devices. Network pruning is an effective method of model compression to handle such problems. This paper presents a novel structured network pruning method with auxiliary gating structures which assigns importance marks to blocks in backbone network as a criterion when pruning. Block-wise pruning is then realized by proposed voting strategy, which is different from prevailing methods who prune a model in small granularity like channel-wise. We further develop a three-stage training scheduling for the proposed architecture incorporating knowledge distillation for better performance. Our experiments demonstrate that our method can achieve state-of-the-arts compression performance for the classification tasks. In addition, our approach can integrate synergistically with other pruning methods by providing pretrained models, thus achieving a better performance than the unpruned model with over 93\% FLOPs reduced.

</p>
</details>

<details><summary><b>Automatic Detection of Interplanetary Coronal Mass Ejections in Solar Wind In Situ Data</b>
<a href="https://arxiv.org/abs/2205.03578">arxiv:2205.03578</a>
&#x1F4C8; 2 <br>
<p>Hannah T. Rüdisser, Andreas Windisch, Ute V. Amerstorfer, Christian Möstl, Tanja Amerstorfer, Rachel L. Bailey, Martin A. Reiss</p></summary>
<p>

**Abstract:** Interplanetary coronal mass ejections (ICMEs) are one of the main drivers for space weather disturbances. In the past, different approaches have been used to automatically detect events in existing time series resulting from solar wind in situ observations. However, accurate and fast detection still remains a challenge when facing the large amount of data from different instruments. For the automatic detection of ICMEs we propose a pipeline using a method that has recently proven successful in medical image segmentation. Comparing it to an existing method, we find that while achieving similar results, our model outperforms the baseline regarding training time by a factor of approximately 20, thus making it more applicable for other datasets. The method has been tested on in situ data from the Wind spacecraft between 1997 and 2015 with a True Skill Statistic (TSS) of 0.64. Out of the 640 ICMEs, 466 were detected correctly by our algorithm, producing a total of 254 False Positives. Additionally, it produced reasonable results on datasets with fewer features and smaller training sets from Wind, STEREO-A and STEREO-B with True Skill Statistics of 0.56, 0.57 and 0.53, respectively. Our pipeline manages to find the start of an ICME with a mean absolute error (MAE) of around 2 hours and 56 minutes, and the end time with a MAE of 3 hours and 20 minutes. The relatively fast training allows straightforward tuning of hyperparameters and could therefore easily be used to detect other structures and phenomena in solar wind data, such as corotating interaction regions.

</p>
</details>

<details><summary><b>Data-Driven Approximations of Chance Constrained Programs in Nonstationary Environments</b>
<a href="https://arxiv.org/abs/2205.03748">arxiv:2205.03748</a>
&#x1F4C8; 1 <br>
<p>Shuhao Yan, Francesca Parise, Eilyan Bitar</p></summary>
<p>

**Abstract:** We study sample average approximations (SAA) of chance constrained programs. SAA methods typically approximate the actual distribution in the chance constraint using an empirical distribution constructed from random samples assumed to be independent and identically distributed according to the actual distribution. In this paper, we consider a nonstationary variant of this problem, where the random samples are assumed to be independently drawn in a sequential fashion from an unknown and possibly time-varying distribution. This nonstationarity may be driven by changing environmental conditions present in many real-world applications. To account for the potential nonstationarity in the data generation process, we propose a novel robust SAA method exploiting information about the Wasserstein distance between the sequence of data-generating distributions and the actual chance constraint distribution. As a key result, we obtain distribution-free estimates of the sample size required to ensure that the robust SAA method will yield solutions that are feasible for the chance constraint under the actual distribution with high confidence.

</p>
</details>

<details><summary><b>Decoupled-and-Coupled Networks: Self-Supervised Hyperspectral Image Super-Resolution with Subpixel Fusion</b>
<a href="https://arxiv.org/abs/2205.03742">arxiv:2205.03742</a>
&#x1F4C8; 1 <br>
<p>Danfeng Hong, Jing Yao, Deyu Meng, Naoto Yokoya, Jocelyn Chanussot</p></summary>
<p>

**Abstract:** Enormous efforts have been recently made to super-resolve hyperspectral (HS) images with the aid of high spatial resolution multispectral (MS) images. Most prior works usually perform the fusion task by means of multifarious pixel-level priors. Yet the intrinsic effects of a large distribution gap between HS-MS data due to differences in the spatial and spectral resolution are less investigated. The gap might be caused by unknown sensor-specific properties or highly-mixed spectral information within one pixel (due to low spatial resolution). To this end, we propose a subpixel-level HS super-resolution framework by devising a novel decoupled-and-coupled network, called DC-Net, to progressively fuse HS-MS information from the pixel- to subpixel-level, from the image- to feature-level. As the name suggests, DC-Net first decouples the input into common (or cross-sensor) and sensor-specific components to eliminate the gap between HS-MS images before further fusion, and then fully blends them by a model-guided coupled spectral unmixing (CSU) net. More significantly, we append a self-supervised learning module behind the CSU net by guaranteeing the material consistency to enhance the detailed appearances of the restored HS product. Extensive experimental results show the superiority of our method both visually and quantitatively and achieve a significant improvement in comparison with the state-of-the-arts. Furthermore, the codes and datasets will be available at https://sites.google.com/view/danfeng-hong for the sake of reproducibility.

</p>
</details>

<details><summary><b>FRC-TOuNN: Topology Optimization of Continuous Fiber Reinforced Composites using Neural Network</b>
<a href="https://arxiv.org/abs/2205.03737">arxiv:2205.03737</a>
&#x1F4C8; 1 <br>
<p>Aaditya Chandrasekhar, Amir Mirzendehdel, Morad Behandish, Krishnan Suresh</p></summary>
<p>

**Abstract:** In this paper, we present a topology optimization (TO) framework to simultaneously optimize the matrix topology and fiber distribution of functionally graded continuous fiber-reinforced composites (FRC). Current approaches in density-based TO for FRC use the underlying finite element mesh both for analysis and design representation. This poses several limitations while enforcing sub-element fiber spacing and generating high-resolution continuous fibers. In contrast, we propose a mesh-independent representation based on a neural network (NN) both to capture the matrix topology and fiber distribution. The implicit NN-based representation enables geometric and material queries at a higher resolution than a mesh discretization. This leads to the accurate extraction of functionally-graded continuous fibers. Further, by integrating the finite element simulations into the NN computational framework, we can leverage automatic differentiation for end-to-end automated sensitivity analysis, i.e., we no longer need to manually derive cumbersome sensitivity expressions. We demonstrate the effectiveness and computational efficiency of the proposed method through several numerical examples involving various objective functions. We also show that the optimized continuous fiber reinforced composites can be directly fabricated at high resolution using additive manufacturing.

</p>
</details>

<details><summary><b>Optimal Lighting Control in Greenhouses Using Bayesian Neural Networks for Sunlight Prediction</b>
<a href="https://arxiv.org/abs/2205.03733">arxiv:2205.03733</a>
&#x1F4C8; 1 <br>
<p>Shirin Afzali, Yajie Bao, Marc W. van Iersel, Javad Mohammadpour Velni</p></summary>
<p>

**Abstract:** Controlling the environmental parameters, including light in greenhouses, increases the crop yield; however, the electricity cost of supplemental lighting can be high. Therefore, the importance of applying cost-effective lighting methods arises. In this paper, an optimal supplemental lighting control approach is developed considering a variational inference Bayesian Neural Network (BNN) model for sunlight prediction. The predictive model is validated through testing the model on the historical solar data of a site located at North Carolina ($R^{2}$=0.9971, RMSE=1.8%). The proposed lighting approach is shown to minimize electricity cost by considering the BNN-based sunlight prediction, plant light needs, and variable electricity pricing when solving the underlying optimization problem. For evaluation, the new strategy is compared to: 1) a Markov-based prediction method, which solves the same optimization problem, assuming a Markov model for sunlight prediction; 2) a heuristic method which aims to supply a fixed amount of light. Simulation studies are conducted to examine the electricity cost improvements of the BNN-based approach. The results show that the BNN-based approach reduces cost by (on average) 2.27% and 43.91% compared to the Markov prediction-based method and the heuristic method, respectively, throughout a year.

</p>
</details>

<details><summary><b>Block Modulating Video Compression: An Ultra Low Complexity Image Compression Encoder for Resource Limited Platforms</b>
<a href="https://arxiv.org/abs/2205.03677">arxiv:2205.03677</a>
&#x1F4C8; 1 <br>
<p>Yujia Xue, Siming Zheng, Waleed Tahir, Zhengjue Wang, Hao Zhang, Ziyi Meng, Lei Tian, Xin Yuan</p></summary>
<p>

**Abstract:** We consider the image and video compression on resource limited platforms. An ultra low-cost image encoder, named Block Modulating Video Compression (BMVC) with an encoding complexity ${\cal O}(1)$ is proposed to be implemented on mobile platforms with low consumption of power and computation resources. We also develop two types of BMVC decoders, implemented by deep neural networks. The first BMVC decoder is based on the Plug-and-Play (PnP) algorithm, which is flexible to different compression ratios. And the second decoder is a memory efficient end-to-end convolutional neural network, which aims for real-time decoding. Extensive results on the high definition images and videos demonstrate the superior performance of the proposed codec and the robustness against bit quantization.

</p>
</details>

<details><summary><b>Deep learning approximations for non-local nonlinear PDEs with Neumann boundary conditions</b>
<a href="https://arxiv.org/abs/2205.03672">arxiv:2205.03672</a>
&#x1F4C8; 1 <br>
<p>Victor Boussange, Sebastian Becker, Arnulf Jentzen, Benno Kuckuck, Loïc Pellissier</p></summary>
<p>

**Abstract:** Nonlinear partial differential equations (PDEs) are used to model dynamical processes in a large number of scientific fields, ranging from finance to biology. In many applications standard local models are not sufficient to accurately account for certain non-local phenomena such as, e.g., interactions at a distance. In order to properly capture these phenomena non-local nonlinear PDE models are frequently employed in the literature. In this article we propose two numerical methods based on machine learning and on Picard iterations, respectively, to approximately solve non-local nonlinear PDEs. The proposed machine learning-based method is an extended variant of a deep learning-based splitting-up type approximation method previously introduced in the literature and utilizes neural networks to provide approximate solutions on a subset of the spatial domain of the solution. The Picard iterations-based method is an extended variant of the so-called full history recursive multilevel Picard approximation scheme previously introduced in the literature and provides an approximate solution for a single point of the domain. Both methods are mesh-free and allow non-local nonlinear PDEs with Neumann boundary conditions to be solved in high dimensions. In the two methods, the numerical difficulties arising due to the dimensionality of the PDEs are avoided by (i) using the correspondence between the expected trajectory of reflected stochastic processes and the solution of PDEs (given by the Feynman-Kac formula) and by (ii) using a plain vanilla Monte Carlo integration to handle the non-local term. We evaluate the performance of the two methods on five different PDEs arising in physics and biology. In all cases, the methods yield good results in up to 10 dimensions with short run times. Our work extends recently developed methods to overcome the curse of dimensionality in solving PDEs.

</p>
</details>

<details><summary><b>Automated Algorithm Selection for Radar Network Configuration</b>
<a href="https://arxiv.org/abs/2205.03670">arxiv:2205.03670</a>
&#x1F4C8; 1 <br>
<p>Quentin Renau, Johann Dreo, Alain Peres, Yann Semet, Carola Doerr, Benjamin Doerr</p></summary>
<p>

**Abstract:** The configuration of radar networks is a complex problem that is often performed manually by experts with the help of a simulator. Different numbers and types of radars as well as different locations that the radars shall cover give rise to different instances of the radar configuration problem. The exact modeling of these instances is complex, as the quality of the configurations depends on a large number of parameters, on internal radar processing, and on the terrains on which the radars need to be placed. Classic optimization algorithms can therefore not be applied to this problem, and we rely on "trial-and-error" black-box approaches.
  In this paper, we study the performances of 13~black-box optimization algorithms on 153~radar network configuration problem instances. The algorithms perform considerably better than human experts. Their ranking, however, depends on the budget of configurations that can be evaluated and on the elevation profile of the location. We therefore also investigate automated algorithm selection approaches. Our results demonstrate that a pipeline that extracts instance features from the elevation of the terrain performs on par with the classical, far more expensive approach that extracts features from the objective function.

</p>
</details>

<details><summary><b>Variational Sparse Coding with Learned Thresholding</b>
<a href="https://arxiv.org/abs/2205.03665">arxiv:2205.03665</a>
&#x1F4C8; 1 <br>
<p>Kion Fallah, Christopher J. Rozell</p></summary>
<p>

**Abstract:** Sparse coding strategies have been lauded for their parsimonious representations of data that leverage low dimensional structure. However, inference of these codes typically relies on an optimization procedure with poor computational scaling in high-dimensional problems. For example, sparse inference in the representations learned in the high-dimensional intermediary layers of deep neural networks (DNNs) requires an iterative minimization to be performed at each training step. As such, recent, quick methods in variational inference have been proposed to infer sparse codes by learning a distribution over the codes with a DNN. In this work, we propose a new approach to variational sparse coding that allows us to learn sparse distributions by thresholding samples, avoiding the use of problematic relaxations. We first evaluate and analyze our method by training a linear generator, showing that it has superior performance, statistical efficiency, and gradient estimation compared to other sparse distributions. We then compare to a standard variational autoencoder using a DNN generator on the Fashion MNIST and CelebA datasets

</p>
</details>

<details><summary><b>Deep Reinforcement Learning-Based Adaptive IRS Control with Limited Feedback Codebooks</b>
<a href="https://arxiv.org/abs/2205.03636">arxiv:2205.03636</a>
&#x1F4C8; 1 <br>
<p>Junghoon Kim, Seyyedali Hosseinalipour, Andrew C. Marcum, Taejoon Kim, David J. Love, Christopher G. Brinton</p></summary>
<p>

**Abstract:** Intelligent reflecting surfaces (IRS) consist of configurable meta-atoms, which can alter the wireless propagation environment through design of their reflection coefficients. We consider adaptive IRS control in the practical setting where (i) the IRS reflection coefficients are attained by adjusting tunable elements embedded in the meta-atoms, (ii) the IRS reflection coefficients are affected by the incident angles of the incoming signals, (iii) the IRS is deployed in multi-path, time-varying channels, and (iv) the feedback link from the base station (BS) to the IRS has a low data rate. Conventional optimization-based IRS control protocols, which rely on channel estimation and conveying the optimized variables to the IRS, are not practical in this setting due to the difficulty of channel estimation and the low data rate of the feedback channel. To address these challenges, we develop a novel adaptive codebook-based limited feedback protocol to control the IRS. We propose two solutions for adaptive IRS codebook design: (i) random adjacency (RA), which utilizes correlations across the channel realizations, and (ii) deep neural network policy-based IRS control (DPIC), which is based on a deep reinforcement learning. Numerical evaluations show that the data rate and average data rate over one coherence time are improved substantially by the proposed schemes.

</p>
</details>

<details><summary><b>Ultra-fast image categorization in vivo and in silico</b>
<a href="https://arxiv.org/abs/2205.03635">arxiv:2205.03635</a>
&#x1F4C8; 1 <br>
<p>Jean-Nicolas Jérémie, Laurent U Perrinet</p></summary>
<p>

**Abstract:** Humans are able to robustly categorize images and can, for instance, detect the presence of an animal in a briefly flashed image in as little as 120 ms. Initially inspired by neuroscience, deep-learning algorithms literally bloomed up in the last decade such that the accuracy of machines is at present superior to humans for visual recognition tasks. However, these artificial networks are usually trained and evaluated on very specific tasks, for instance on the 1000 separate categories of ImageNet. In that regard, biological visual systems are more flexible and efficient compared to artificial systems on generic ecological tasks. In order to deepen this comparison, we re-trained the standard VGG Convolutional Neural Network (CNN) on two independent tasks which are ecologically relevant for humans: one task defined as detecting the presence of an animal and the other as detecting the presence of an artifact. We show that retraining the network achieves human-like performance level which is reported in psychophysical tasks. We also compare the accuracy of the detection on an image-by-image basis. This showed in particular that the two models perform better when combining their outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). These re-trained models could reproduce some unexpected behavioral observations from humans psychophysics such as the robustness to rotations (e.g. upside-down or slanted image) or to a grayscale transformation.

</p>
</details>

<details><summary><b>Deep Quality Assessment of Compressed Videos: A Subjective and Objective Study</b>
<a href="https://arxiv.org/abs/2205.03630">arxiv:2205.03630</a>
&#x1F4C8; 1 <br>
<p>Liqun Lin, Zheng Wang, Jiachen He, Weiling Chen, Yiwen Xu, Tiesong Zhao</p></summary>
<p>

**Abstract:** In the video coding process, the perceived quality of a compressed video is evaluated by full-reference quality evaluation metrics. However, it is difficult to obtain reference videos with perfect quality. To solve this problem, it is critical to design no-reference compressed video quality assessment algorithms, which assists in measuring the quality of experience on the server side and resource allocation on the network side. Convolutional Neural Network (CNN) has shown its advantage in Video Quality Assessment (VQA) with promising successes in recent years. A large-scale quality database is very important for learning accurate and powerful compressed video quality metrics. In this work, a semi-automatic labeling method is adopted to build a large-scale compressed video quality database, which allows us to label a large number of compressed videos with manageable human workload. The resulting Compressed Video quality database with Semi-Automatic Ratings (CVSAR), so far the largest of compressed video quality database. We train a no-reference compressed video quality assessment model with a 3D CNN for SpatioTemporal Feature Extraction and Evaluation (STFEE). Experimental results demonstrate that the proposed method outperforms state-of-the-art metrics and achieves promising generalization performance in cross-database tests. The CVSAR database and STFEE model will be made publicly available to facilitate reproducible research.

</p>
</details>

<details><summary><b>Determination of class-specific variables in nonparametric multiple-class classification</b>
<a href="https://arxiv.org/abs/2205.03623">arxiv:2205.03623</a>
&#x1F4C8; 1 <br>
<p>Wan-Ping Nicole Chen, Yuan-chin Ivan Chang</p></summary>
<p>

**Abstract:** As technology advanced, collecting data via automatic collection devices become popular, thus we commonly face data sets with lengthy variables, especially when these data sets are collected without specific research goals beforehand. It has been pointed out in the literature that the difficulty of high-dimensional classification problems is intrinsically caused by too many noise variables useless for reducing classification error, which offer less benefits for decision-making, and increase complexity, and confusion in model-interpretation. A good variable selection strategy is therefore a must for using such kinds of data well; especially when we expect to use their results for the succeeding applications/studies, where the model-interpretation ability is essential. hus, the conventional classification measures, such as accuracy, sensitivity, precision, cannot be the only performance tasks. In this paper, we propose a probability-based nonparametric multiple-class classification method, and integrate it with the ability of identifying high impact variables for individual class such that we can have more information about its classification rule and the character of each class as well. The proposed method can have its prediction power approximately equal to that of the Bayes rule, and still retains the ability of "model-interpretation." We report the asymptotic properties of the proposed method, and use both synthesized and real data sets to illustrate its properties under different classification situations. We also separately discuss the variable identification, and training sample size determination, and summarize those procedures as algorithms such that users can easily implement them with different computing languages.

</p>
</details>

<details><summary><b>Multi-View Video Coding with GAN Latent Learning</b>
<a href="https://arxiv.org/abs/2205.03599">arxiv:2205.03599</a>
&#x1F4C8; 1 <br>
<p>Chengdong Lan, Cheng Luo, Hao Yan, Tiesong Zhao, Sam Kwong</p></summary>
<p>

**Abstract:** The introduction of multiple viewpoints inevitably increases the bitrates to store and transmit video scenes. To reduce the compressed bitrates, researchers have developed to skip intermediate viewpoints during compression and delivery, and finally reconstruct them with Side Information (SI). Generally, the depth maps can be utilized to construct SI; however, it shows inferior performance with inaccurate reconstruction or high bitrates. In this paper, we propose a multi-view video coding based on SI of Generative Adversarial Network (GAN). At the encoder, we construct a spatio-temporal Epipolar Plane Image (EPI) and further utilize convolutional network to extract the latent code of GAN as SI; while at the decoder side, we combine the SI and adjacent viewpoints to reconstruct intermediate views by the generator of GAN. In particular, we set a joint encoder constraint of reconstruction cost and SI entropy, in order to achieve an optimal tradeoff between reconstruction quality and bitrate overhead. Experiments show a significantly improved Rate-Distortion (RD) performance compared with the state-of-the-art methods.

</p>
</details>

<details><summary><b>Efficient VVC Intra Prediction Based on Deep Feature Fusion and Probability Estimation</b>
<a href="https://arxiv.org/abs/2205.03587">arxiv:2205.03587</a>
&#x1F4C8; 1 <br>
<p>Tiesong Zhao, Yuhang Huang, Weize Feng, Yiwen Xu, Sam Kwong</p></summary>
<p>

**Abstract:** The ever-growing multimedia traffic has underscored the importance of effective multimedia codecs. Among them, the up-to-date lossy video coding standard, Versatile Video Coding (VVC), has been attracting attentions of video coding community. However, the gain of VVC is achieved at the cost of significant encoding complexity, which brings the need to realize fast encoder with comparable Rate Distortion (RD) performance. In this paper, we propose to optimize the VVC complexity at intra-frame prediction, with a two-stage framework of deep feature fusion and probability estimation. At the first stage, we employ the deep convolutional network to extract the spatialtemporal neighboring coding features. Then we fuse all reference features obtained by different convolutional kernels to determine an optimal intra coding depth. At the second stage, we employ a probability-based model and the spatial-temporal coherence to select the candidate partition modes within the optimal coding depth. Finally, these selected depths and partitions are executed whilst unnecessary computations are excluded. Experimental results on standard database demonstrate the superiority of proposed method, especially for High Definition (HD) and Ultra-HD (UHD) video sequences.

</p>
</details>

<details><summary><b>SPQE: Structure-and-Perception-Based Quality Evaluation for Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2205.03584">arxiv:2205.03584</a>
&#x1F4C8; 1 <br>
<p>Keke Zhang, Tiesong Zhao, Weiling Chen, Yuzhen Niu, Jinsong Hu</p></summary>
<p>

**Abstract:** The image Super-Resolution (SR) technique has greatly improved the visual quality of images by enhancing their resolutions. It also calls for an efficient SR Image Quality Assessment (SR-IQA) to evaluate those algorithms or their generated images. In this paper, we focus on the SR-IQA under deep learning and propose a Structure-and-Perception-based Quality Evaluation (SPQE). In emerging deep-learning-based SR, a generated high-quality, visually pleasing image may have different structures from its corresponding low-quality image. In such case, how to balance the quality scores between no-reference perceptual quality and referenced structural similarity is a critical issue. To help ease this problem, we give a theoretical analysis on this tradeoff and further calculate adaptive weights for the two types of quality scores. We also propose two deep-learning-based regressors to model the no-reference and referenced scores. By combining the quality scores and their weights, we propose a unified SPQE metric for SR-IQA. Experimental results demonstrate that the proposed method outperforms the state-of-the-arts in different datasets.

</p>
</details>

<details><summary><b>Deep learning for spatio-temporal forecasting -- application to solar energy</b>
<a href="https://arxiv.org/abs/2205.03571">arxiv:2205.03571</a>
&#x1F4C8; 0 <br>
<p>Vincent Le Guen</p></summary>
<p>

**Abstract:** This thesis tackles the subject of spatio-temporal forecasting with deep learning. The motivating application at Electricity de France (EDF) is short-term solar energy forecasting with fisheye images. We explore two main research directions for improving deep forecasting methods by injecting external physical knowledge. The first direction concerns the role of the training loss function. We show that differentiable shape and temporal criteria can be leveraged to improve the performances of existing models. We address both the deterministic context with the proposed DILATE loss function and the probabilistic context with the STRIPE model. Our second direction is to augment incomplete physical models with deep data-driven networks for accurate forecasting. For video prediction, we introduce the PhyDNet model that disentangles physical dynamics from residual information necessary for prediction, such as texture or details. We further propose a learning framework (APHYNITY) that ensures a principled and unique linear decomposition between physical and data-driven components under mild assumptions, leading to better forecasting performances and parameter identification.

</p>
</details>


{% endraw %}
Prev: [2022.05.06]({{ '/2022/05/06/2022.05.06.html' | relative_url }})  Next: [2022.05.08]({{ '/2022/05/08/2022.05.08.html' | relative_url }})