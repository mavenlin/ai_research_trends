Prev: [2021.01.15]({{ '/2021/01/15/2021.01.15.html' | relative_url }})  Next: [2021.01.17]({{ '/2021/01/17/2021.01.17.html' | relative_url }})
{% raw %}
## Summary for 2021-01-16, created on 2021-12-24


<details><summary><b>Asynchronous Multi-View SLAM</b>
<a href="https://arxiv.org/abs/2101.06562">arxiv:2101.06562</a>
&#x1F4C8; 60 <br>
<p>Anqi Joyce Yang, Can Cui, Ioan Andrei BÃ¢rsan, Raquel Urtasun, Shenlong Wang</p></summary>
<p>

**Abstract:** Existing multi-camera SLAM systems assume synchronized shutters for all cameras, which is often not the case in practice. In this work, we propose a generalized multi-camera SLAM formulation which accounts for asynchronous sensor observations. Our framework integrates a continuous-time motion model to relate information across asynchronous multi-frames during tracking, local mapping, and loop closing. For evaluation, we collected AMV-Bench, a challenging new SLAM dataset covering 482 km of driving recorded using our asynchronous multi-camera robotic platform. AMV-Bench is over an order of magnitude larger than previous multi-view HD outdoor SLAM datasets, and covers diverse and challenging motions and environments. Our experiments emphasize the necessity of asynchronous sensor modeling, and show that the use of multiple cameras is critical towards robust and accurate SLAM in challenging outdoor scenes. For additional information, please see the project website at: https://www.cs.toronto.edu/~ajyang/amv-slam

</p>
</details>

<details><summary><b>Free Lunch for Few-shot Learning: Distribution Calibration</b>
<a href="https://arxiv.org/abs/2101.06395">arxiv:2101.06395</a>
&#x1F4C8; 59 <br>
<p>Shuo Yang, Lu Liu, Min Xu</p></summary>
<p>

**Abstract:** Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples, then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy on two datasets (~5% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation.

</p>
</details>

<details><summary><b>Temporal Clustering of Disorder Events During the COVID-19 Pandemic</b>
<a href="https://arxiv.org/abs/2101.06458">arxiv:2101.06458</a>
&#x1F4C8; 30 <br>
<p>Gian Maria Campedelli, Maria Rita D'Orsogna</p></summary>
<p>

**Abstract:** The COVID-19 pandemic has unleashed multiple public health, socio-economic, and institutional crises. Measures taken to slow the spread of the virus have fostered significant strain between authorities and citizens, leading to waves of social unrest and anti-government demonstrations. We study the temporal nature of pandemic-related disorder events as tallied by the "COVID-19 Disorder Tracker" initiative by focusing on the three countries with the largest number of incidents, India, Israel, and Mexico. By fitting Poisson and Hawkes processes to the stream of data, we find that disorder events are inter-dependent and self-excite in all three countries. Geographic clustering confirms these features at the subnational level, indicating that nationwide disorders emerge as the convergence of meso-scale patterns of self-excitation. Considerable diversity is observed among countries when computing correlations of events between subnational clusters; these are discussed in the context of specific political, societal and geographic characteristics. Israel, the most territorially compact and where large scale protests were coordinated in response to government lockdowns, displays the largest reactivity and the shortest period of influence following an event, as well as the strongest nationwide synchrony. In Mexico, where complete lockdown orders were never mandated, reactivity and nationwide synchrony are lowest. Our work highlights the need for authorities to promote local information campaigns to ensure that livelihoods and virus containment policies are not perceived as mutually exclusive.

</p>
</details>

<details><summary><b>GENIE: A Leaderboard for Human-in-the-Loop Evaluation of Text Generation</b>
<a href="https://arxiv.org/abs/2101.06561">arxiv:2101.06561</a>
&#x1F4C8; 27 <br>
<p>Daniel Khashabi, Gabriel Stanovsky, Jonathan Bragg, Nicholas Lourie, Jungo Kasai, Yejin Choi, Noah A. Smith, Daniel S. Weld</p></summary>
<p>

**Abstract:** Leaderboards have eased model development for many NLP datasets by standardizing their evaluation and delegating it to an independent external repository. Their adoption, however, is so far limited to tasks that can be reliably evaluated in an automatic manner. This work introduces GENIE, an extensible human evaluation leaderboard, which brings the ease of leaderboards to text generation tasks. GENIE automatically posts leaderboard submissions to crowdsourcing platforms asking human annotators to evaluate them on various axes (e.g., correctness, conciseness, fluency) and compares their answers to various automatic metrics. We introduce several datasets in English to GENIE, representing four core challenges in text generation: machine translation, summarization, commonsense reasoning, and machine comprehension. We provide formal granular evaluation metrics and identify areas for future research. We make GENIE publicly available and hope that it will spur progress in language generation models as well as their automatic and manual evaluation.

</p>
</details>

<details><summary><b>TrafficSim: Learning to Simulate Realistic Multi-Agent Behaviors</b>
<a href="https://arxiv.org/abs/2101.06557">arxiv:2101.06557</a>
&#x1F4C8; 24 <br>
<p>Simon Suo, Sebastian Regalado, Sergio Casas, Raquel Urtasun</p></summary>
<p>

**Abstract:** Simulation has the potential to massively scale evaluation of self-driving systems enabling rapid development as well as safe deployment. To close the gap between simulation and the real world, we need to simulate realistic multi-agent behaviors. Existing simulation environments rely on heuristic-based models that directly encode traffic rules, which cannot capture irregular maneuvers (e.g., nudging, U-turns) and complex interactions (e.g., yielding, merging). In contrast, we leverage real-world data to learn directly from human demonstration and thus capture a more diverse set of actor behaviors. To this end, we propose TrafficSim, a multi-agent behavior model for realistic traffic simulation. In particular, we leverage an implicit latent variable model to parameterize a joint actor policy that generates socially-consistent plans for all actors in the scene jointly. To learn a robust policy amenable for long horizon simulation, we unroll the policy in training and optimize through the fully differentiable simulation across time. Our learning objective incorporates both human demonstrations as well as common sense. We show TrafficSim generates significantly more realistic and diverse traffic scenarios as compared to a diverse set of baselines. Notably, we can exploit trajectories generated by TrafficSim as effective data augmentation for training better motion planner.

</p>
</details>

<details><summary><b>SceneGen: Learning to Generate Realistic Traffic Scenes</b>
<a href="https://arxiv.org/abs/2101.06541">arxiv:2101.06541</a>
&#x1F4C8; 19 <br>
<p>Shuhan Tan, Kelvin Wong, Shenlong Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun</p></summary>
<p>

**Abstract:** We consider the problem of generating realistic traffic scenes automatically. Existing methods typically insert actors into the scene according to a set of hand-crafted heuristics and are limited in their ability to model the true complexity and diversity of real traffic scenes, thus inducing a content gap between synthesized traffic scenes versus real ones. As a result, existing simulators lack the fidelity necessary to train and test self-driving vehicles. To address this limitation, we present SceneGen, a neural autoregressive model of traffic scenes that eschews the need for rules and heuristics. In particular, given the ego-vehicle state and a high definition map of surrounding area, SceneGen inserts actors of various classes into the scene and synthesizes their sizes, orientations, and velocities. We demonstrate on two large-scale datasets SceneGen's ability to faithfully model distributions of real traffic scenes. Moreover, we show that SceneGen coupled with sensor simulation can be used to train perception models that generalize to the real world.

</p>
</details>

<details><summary><b>GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving</b>
<a href="https://arxiv.org/abs/2101.06543">arxiv:2101.06543</a>
&#x1F4C8; 17 <br>
<p>Yun Chen, Frieda Rong, Shivam Duggal, Shenlong Wang, Xinchen Yan, Sivabalan Manivasagam, Shangjie Xue, Ersin Yumer, Raquel Urtasun</p></summary>
<p>

**Abstract:** Scalable sensor simulation is an important yet challenging open problem for safety-critical domains such as self-driving. Current works in image simulation either fail to be photorealistic or do not model the 3D environment and the dynamic objects within, losing high-level control and physical realism. In this paper, we present GeoSim, a geometry-aware image composition process which synthesizes novel urban driving scenarios by augmenting existing images with dynamic objects extracted from other scenes and rendered at novel poses. Towards this goal, we first build a diverse bank of 3D objects with both realistic geometry and appearance from sensor data. During simulation, we perform a novel geometry-aware simulation-by-composition procedure which 1) proposes plausible and realistic object placements into a given scene, 2) render novel views of dynamic objects from the asset bank, and 3) composes and blends the rendered image segments. The resulting synthetic images are realistic, traffic-aware, and geometrically consistent, allowing our approach to scale to complex use cases. We demonstrate two such important applications: long-range realistic video simulation across multiple camera sensors, and synthetic data generation for data augmentation on downstream segmentation tasks. Please check https://tmux.top/publication/geosim/ for high-resolution video results.

</p>
</details>

<details><summary><b>Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks</b>
<a href="https://arxiv.org/abs/2101.06475">arxiv:2101.06475</a>
&#x1F4C8; 13 <br>
<p>Maxwell Mbabilla Aladago, Lorenzo Torresani</p></summary>
<p>

**Abstract:** In contrast to traditional weight optimization in a continuous space, we demonstrate the existence of effective random networks whose weights are never updated. By selecting a weight among a fixed set of random values for each individual connection, our method uncovers combinations of random weights that match the performance of traditionally-trained networks of the same capacity. We refer to our networks as "slot machines" where each reel (connection) contains a fixed set of symbols (random values). Our backpropagation algorithm "spins" the reels to seek "winning" combinations, i.e., selections of random weight values that minimize the given loss. Quite surprisingly, we find that allocating just a few random values to each connection (e.g., 8 values per connection) yields highly competitive combinations despite being dramatically more constrained compared to traditionally learned weights. Moreover, finetuning these combinations often improves performance over the trained baselines. A randomly initialized VGG-19 with 8 values per connection contains a combination that achieves 91% test accuracy on CIFAR-10. Our method also achieves an impressive performance of 98.2% on MNIST for neural networks containing only random weights.

</p>
</details>

<details><summary><b>AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles</b>
<a href="https://arxiv.org/abs/2101.06549">arxiv:2101.06549</a>
&#x1F4C8; 10 <br>
<p>Jingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren, Raquel Urtasun</p></summary>
<p>

**Abstract:** As self-driving systems become better, simulating scenarios where the autonomy stack may fail becomes more important. Traditionally, those scenarios are generated for a few scenes with respect to the planning module that takes ground-truth actor states as input. This does not scale and cannot identify all possible autonomy failures, such as perception failures due to occlusion. In this paper, we propose AdvSim, an adversarial framework to generate safety-critical scenarios for any LiDAR-based autonomy system. Given an initial traffic scenario, AdvSim modifies the actors' trajectories in a physically plausible manner and updates the LiDAR sensor data to match the perturbed world. Importantly, by simulating directly from sensor data, we obtain adversarial scenarios that are safety-critical for the full autonomy stack. Our experiments show that our approach is general and can identify thousands of semantically meaningful safety-critical scenarios for a wide range of modern self-driving systems. Furthermore, we show that the robustness and safety of these systems can be further improved by training them with scenarios generated by AdvSim.

</p>
</details>

<details><summary><b>LookOut: Diverse Multi-Future Prediction and Planning for Self-Driving</b>
<a href="https://arxiv.org/abs/2101.06547">arxiv:2101.06547</a>
&#x1F4C8; 10 <br>
<p>Alexander Cui, Sergio Casas, Abbas Sadat, Renjie Liao, Raquel Urtasun</p></summary>
<p>

**Abstract:** In this paper, we present LookOut, a novel autonomy system that perceives the environment, predicts a diverse set of futures of how the scene might unroll and estimates the trajectory of the SDV by optimizing a set of contingency plans over these future realizations. In particular, we learn a diverse joint distribution over multi-agent future trajectories in a traffic scene that covers a wide range of future modes with high sample efficiency while leveraging the expressive power of generative models. Unlike previous work in diverse motion forecasting, our diversity objective explicitly rewards sampling future scenarios that require distinct reactions from the self-driving vehicle for improved safety. Our contingency planner then finds comfortable and non-conservative trajectories that ensure safe reactions to a wide range of future scenarios. Through extensive evaluations, we show that our model demonstrates significantly more diverse and sample-efficient motion forecasting in a large-scale self-driving dataset as well as safer and less-conservative motion plans in long-term closed-loop simulations when compared to current state-of-the-art models.

</p>
</details>

<details><summary><b>Towards Searching Efficient and Accurate Neural Network Architectures in Binary Classification Problems</b>
<a href="https://arxiv.org/abs/2101.06511">arxiv:2101.06511</a>
&#x1F4C8; 10 <br>
<p>Yigit Alparslan, Ethan Jacob Moyer, Isamu Mclean Isozaki, Daniel Schwartz, Adam Dunlop, Shesh Dave, Edward Kim</p></summary>
<p>

**Abstract:** In recent years, deep neural networks have had great success in machine learning and pattern recognition. Architecture size for a neural network contributes significantly to the success of any neural network. In this study, we optimize the selection process by investigating different search algorithms to find a neural network architecture size that yields the highest accuracy. We apply binary search on a very well-defined binary classification network search space and compare the results to those of linear search. We also propose how to relax some of the assumptions regarding the dataset so that our solution can be generalized to any binary classification problem. We report a 100-fold running time improvement over the naive linear search when we apply the binary search method to our datasets in order to find the best architecture candidate. By finding the optimal architecture size for any binary classification problem quickly, we hope that our research contributes to discovering intelligent algorithms for optimizing architecture size selection in machine learning.

</p>
</details>

<details><summary><b>Self-Supervised Representation Learning from Flow Equivariance</b>
<a href="https://arxiv.org/abs/2101.06553">arxiv:2101.06553</a>
&#x1F4C8; 9 <br>
<p>Yuwen Xiong, Mengye Ren, Wenyuan Zeng, Raquel Urtasun</p></summary>
<p>

**Abstract:** Self-supervised representation learning is able to learn semantically meaningful features; however, much of its recent success relies on multiple crops of an image with very few objects. Instead of learning view-invariant representation from simple images, humans learn representations in a complex world with changing scenes by observing object movement, deformation, pose variation, and ego motion. Motivated by this ability, we present a new self-supervised learning representation framework that can be directly deployed on a video stream of complex scenes with many moving objects. Our framework features a simple flow equivariance objective that encourages the network to predict the features of another frame by applying a flow transformation to the features of the current frame. Our representations, learned from high-resolution raw video, can be readily used for downstream tasks on static images. Readout experiments on challenging semantic segmentation, instance segmentation, and object detection benchmarks show that we are able to outperform representations obtained from previous state-of-the-art methods including SimCLR and BYOL.

</p>
</details>

<details><summary><b>Multi-objective Search of Robust Neural Architectures against Multiple Types of Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2101.06507">arxiv:2101.06507</a>
&#x1F4C8; 9 <br>
<p>Jia Liu, Yaochu Jin</p></summary>
<p>

**Abstract:** Many existing deep learning models are vulnerable to adversarial examples that are imperceptible to humans. To address this issue, various methods have been proposed to design network architectures that are robust to one particular type of adversarial attacks. It is practically impossible, however, to predict beforehand which type of attacks a machine learn model may suffer from. To address this challenge, we propose to search for deep neural architectures that are robust to five types of well-known adversarial attacks using a multi-objective evolutionary algorithm. To reduce the computational cost, a normalized error rate of a randomly chosen attack is calculated as the robustness for each newly generated neural architecture at each generation. All non-dominated network architectures obtained by the proposed method are then fully trained against randomly chosen adversarial attacks and tested on two widely used datasets. Our experimental results demonstrate the superiority of optimized neural architectures found by the proposed approach over state-of-the-art networks that are widely used in the literature in terms of the classification accuracy under different adversarial attacks.

</p>
</details>

<details><summary><b>Mispronunciation Detection in Non-native (L2) English with Uncertainty Modeling</b>
<a href="https://arxiv.org/abs/2101.06396">arxiv:2101.06396</a>
&#x1F4C8; 9 <br>
<p>Daniel Korzekwa, Jaime Lorenzo-Trueba, Szymon Zaporowski, Shira Calamaro, Thomas Drugman, Bozena Kostek</p></summary>
<p>

**Abstract:** A common approach to the automatic detection of mispronunciation in language learning is to recognize the phonemes produced by a student and compare it to the expected pronunciation of a native speaker. This approach makes two simplifying assumptions: a) phonemes can be recognized from speech with high accuracy, b) there is a single correct way for a sentence to be pronounced. These assumptions do not always hold, which can result in a significant amount of false mispronunciation alarms. We propose a novel approach to overcome this problem based on two principles: a) taking into account uncertainty in the automatic phoneme recognition step, b) accounting for the fact that there may be multiple valid pronunciations. We evaluate the model on non-native (L2) English speech of German, Italian and Polish speakers, where it is shown to increase the precision of detecting mispronunciations by up to 18% (relative) compared to the common approach.

</p>
</details>

<details><summary><b>Deep Cox Mixtures for Survival Regression</b>
<a href="https://arxiv.org/abs/2101.06536">arxiv:2101.06536</a>
&#x1F4C8; 8 <br>
<p>Chirag Nagpal, Steve Yadlowsky, Negar Rostamzadeh, Katherine Heller</p></summary>
<p>

**Abstract:** Survival analysis is a challenging variation of regression modeling because of the presence of censoring, where the outcome measurement is only partially known, due to, for example, loss to follow up. Such problems come up frequently in medical applications, making survival analysis a key endeavor in biostatistics and machine learning for healthcare, with Cox regression models being amongst the most commonly employed models. We describe a new approach for survival analysis regression models, based on learning mixtures of Cox regressions to model individual survival distributions. We propose an approximation to the Expectation Maximization algorithm for this model that does hard assignments to mixture groups to make optimization efficient. In each group assignment, we fit the hazard ratios within each group using deep neural networks, and the baseline hazard for each mixture component non-parametrically.
  We perform experiments on multiple real world datasets, and look at the mortality rates of patients across ethnicity and gender. We emphasize the importance of calibration in healthcare settings and demonstrate that our approach outperforms classical and modern survival analysis baselines, both in terms of discriminative performance and calibration, with large gains in performance on the minority demographics.

</p>
</details>

<details><summary><b>Data-driven discovery of multiscale chemical reactions governed by the law of mass action</b>
<a href="https://arxiv.org/abs/2101.06589">arxiv:2101.06589</a>
&#x1F4C8; 7 <br>
<p>Juntao Huang, Yizhou Zhou, Wen-An Yong</p></summary>
<p>

**Abstract:** In this paper, we propose a data-driven method to discover multiscale chemical reactions governed by the law of mass action. First, we use a single matrix to represent the stoichiometric coefficients for both the reactants and products in a system without catalysis reactions. The negative entries in the matrix denote the stoichiometric coefficients for the reactants and the positive ones for the products. Second, we find that the conventional optimization methods usually get stuck in the local minima and could not find the true solution in learning the multiscale chemical reactions. To overcome this difficulty, we propose a partial-parameters-freezing (PPF) technique to progressively determine the network parameters by using the fact that the stoichiometric coefficients are integers. With such a technique, the dimension of the searching space is gradually reduced in the training process and the global mimina can be eventually obtained. Several numerical experiments including the classical Michaelis-Menten kinetics, the hydrogen oxidation reactions, and the simplified GRI-3.0 mechanism verify the good performance of our algorithm in learning the multiscale chemical reactions. The code is available at \url{https://github.com/JuntaoHuang/multiscale-chemical-reaction}.

</p>
</details>

<details><summary><b>Cost-Efficient Online Hyperparameter Optimization</b>
<a href="https://arxiv.org/abs/2101.06590">arxiv:2101.06590</a>
&#x1F4C8; 5 <br>
<p>Jingkang Wang, Mengye Ren, Ilija Bogunovic, Yuwen Xiong, Raquel Urtasun</p></summary>
<p>

**Abstract:** Recent work on hyperparameters optimization (HPO) has shown the possibility of training certain hyperparameters together with regular parameters. However, these online HPO algorithms still require running evaluation on a set of validation examples at each training step, steeply increasing the training cost. To decide when to query the validation loss, we model online HPO as a time-varying Bayesian optimization problem, on top of which we propose a novel \textit{costly feedback} setting to capture the concept of the query cost. Under this setting, standard algorithms are cost-inefficient as they evaluate on the validation set at every round. In contrast, the cost-efficient GP-UCB algorithm proposed in this paper queries the unknown function only when the model is less confident about current decisions. We evaluate our proposed algorithm by tuning hyperparameters online for VGG and ResNet on CIFAR-10 and ImageNet100. Our proposed online HPO algorithm reaches human expert-level performance within a single run of the experiment, while incurring only modest computational overhead compared to regular training.

</p>
</details>

<details><summary><b>Diversified Patch-based Style Transfer with Shifted Style Normalization</b>
<a href="https://arxiv.org/abs/2101.06381">arxiv:2101.06381</a>
&#x1F4C8; 5 <br>
<p>Zhizhong Wang, Lei Zhao, Haibo Chen, Zhiwen Zuo, Ailin Li, Wei Xing, Dongming Lu</p></summary>
<p>

**Abstract:** Gram-based and patch-based approaches are two important research lines of image style transfer. Recent diversified Gram-based methods have been able to produce multiple and diverse reasonable solutions for the same content and style inputs. However, as another popular research interest, the diversity of patch-based methods remains challenging due to the stereotyped style swapping process based on nearest patch matching. To resolve this dilemma, in this paper, we dive into the core style swapping process of patch-based style transfer and explore possible ways to diversify it. What stands out is an operation called shifted style normalization (SSN), the most effective and efficient way to empower existing patch-based methods to generate diverse results for arbitrary styles. The key insight is to use an important intuition that neural patches with higher activation values could contribute more to diversity. Theoretical analyses and extensive experiments are conducted to demonstrate the effectiveness of our method, and compared with other possible options and state-of-the-art algorithms, it shows remarkable superiority in both diversity and efficiency.

</p>
</details>

<details><summary><b>Transformer-Based Models for Question Answering on COVID19</b>
<a href="https://arxiv.org/abs/2101.11432">arxiv:2101.11432</a>
&#x1F4C8; 4 <br>
<p>Hillary Ngai, Yoona Park, John Chen, Mahboobeh Parsapoor</p></summary>
<p>

**Abstract:** In response to the Kaggle's COVID-19 Open Research Dataset (CORD-19) challenge, we have proposed three transformer-based question-answering systems using BERT, ALBERT, and T5 models. Since the CORD-19 dataset is unlabeled, we have evaluated the question-answering models' performance on two labeled questions answers datasets \textemdash CovidQA and CovidGQA. The BERT-based QA system achieved the highest F1 score (26.32), while the ALBERT-based QA system achieved the highest Exact Match (13.04). However, numerous challenges are associated with developing high-performance question-answering systems for the ongoing COVID-19 pandemic and future pandemics. At the end of this paper, we discuss these challenges and suggest potential solutions to address them.

</p>
</details>

<details><summary><b>Optimized and autonomous machine learning framework for characterizing pores, particles, grains and grain boundaries in microstructural images</b>
<a href="https://arxiv.org/abs/2101.06474">arxiv:2101.06474</a>
&#x1F4C8; 4 <br>
<p>Roberto Perera, Davide Guzzetti, Vinamra Agrawal</p></summary>
<p>

**Abstract:** Additively manufactured metals exhibit heterogeneous microstructure which dictates their material and failure properties. Experimental microstructural characterization techniques generate a large amount of data that requires expensive computationally resources. In this work, an optimized machine learning (ML) framework is proposed to autonomously and efficiently characterize pores, particles, grains and grain boundaries (GBs) from a given microstructure image. First, using a classifier Convolutional Neural Network (CNN), defects such as pores, powder particles, or GBs were recognized from a given microstructure. Depending on the type of defect, two different processes were used. For powder particles or pores, binary segmentations were generated using an optimized Convolutional Encoder-Decoder Network (CEDN). The binary segmentations were used to used obtain particle and pore size and bounding boxes using an object detection ML network (YOLOv5). For GBs, another optimized CEDN was developed to generate RGB segmentation images, which were used to obtain grain size distribution using two regression CNNS. To optimize the RGB CEDN, the Deep Emulator Network SEarch (DENSE) method which employs the Covariance Matrix Adaptation - Evolution Strategy (CMA-ES) was implemented. The optimized RGB segmentation network showed a substantial reduction in training time and GPU usage compared to the unoptimized network, while maintaining high accuracy. Lastly, the proposed framework showed a significant improvement in analysis time when compared to conventional methods.

</p>
</details>

<details><summary><b>Bayesian Inference Forgetting</b>
<a href="https://arxiv.org/abs/2101.06417">arxiv:2101.06417</a>
&#x1F4C8; 4 <br>
<p>Shaopeng Fu, Fengxiang He, Yue Xu, Dacheng Tao</p></summary>
<p>

**Abstract:** The right to be forgotten has been legislated in many countries but the enforcement in machine learning would cause unbearable costs: companies may need to delete whole models learned from massive resources due to single individual requests. Existing works propose to remove the knowledge learned from the requested data via its influence function which is no longer naturally well-defined in Bayesian inference. This paper proposes a {\it Bayesian inference forgetting} (BIF) framework to realize the right to be forgotten in Bayesian inference. In the BIF framework, we develop forgetting algorithms for variational inference and Markov chain Monte Carlo. We show that our algorithms can provably remove the influence of single datums on the learned models. Theoretical analysis demonstrates that our algorithms have guaranteed generalizability. Experiments of Gaussian mixture models on the synthetic dataset and Bayesian neural networks on the real-world data verify the feasibility of our methods. The source code package is available at \url{https://github.com/fshp971/BIF}.

</p>
</details>

<details><summary><b>Adversarial Attacks On Multi-Agent Communication</b>
<a href="https://arxiv.org/abs/2101.06560">arxiv:2101.06560</a>
&#x1F4C8; 3 <br>
<p>James Tu, Tsunhsuan Wang, Jingkang Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun</p></summary>
<p>

**Abstract:** Growing at a fast pace, modern autonomous systems will soon be deployed at scale, opening up the possibility for cooperative multi-agent systems. Sharing information and distributing workloads allow autonomous agents to better perform tasks and increase computation efficiency. However, shared information can be modified to execute adversarial attacks on deep learning models that are widely employed in modern systems. Thus, we aim to study the robustness of such systems and focus on exploring adversarial attacks in a novel multi-agent setting where communication is done through sharing learned intermediate representations of neural networks. We observe that an indistinguishable adversarial message can severely degrade performance, but becomes weaker as the number of benign agents increases. Furthermore, we show that black-box transfer attacks are more difficult in this setting when compared to directly perturbing the inputs, as it is necessary to align the distribution of learned representations with domain adaptation. Our work studies robustness at the neural network level to contribute an additional layer of fault tolerance to modern security protocols for more secure multi-agent systems.

</p>
</details>

<details><summary><b>Evaluating Online and Offline Accuracy Traversal Algorithms for k-Complete Neural Network Architectures</b>
<a href="https://arxiv.org/abs/2101.06518">arxiv:2101.06518</a>
&#x1F4C8; 3 <br>
<p>Yigit Alparslan, Ethan Jacob Moyer, Edward Kim</p></summary>
<p>

**Abstract:** Architecture sizes for neural networks have been studied widely and several search methods have been offered to find the best architecture size in the shortest amount of time possible. In this paper, we study compact neural network architectures for binary classification and investigate improvements in speed and accuracy when favoring overcomplete architecture candidates that have a very high-dimensional representation of the input. We hypothesize that an overcomplete model architecture that creates a relatively high-dimensional representation of the input will be not only be more accurate but would also be easier and faster to find. In an NxM search space, we propose an online traversal algorithm that finds the best architecture candidate in O(1) time for best case and O(N) amortized time for average case for any compact binary classification problem by using k-completeness as heuristics in our search. The two other offline search algorithms we implement are brute force traversal and diagonal traversal, which both find the best architecture candidate in O(NxM) time. We compare our new algorithm to brute force and diagonal searching as a baseline and report search time improvement of 52.1% over brute force and of 15.4% over diagonal search to find the most accurate neural network architecture when given the same dataset. In all cases discussed in the paper, our online traversal algorithm can find an accurate, if not better, architecture in significantly shorter amount of time.

</p>
</details>

<details><summary><b>Binary strings of finite VC dimension</b>
<a href="https://arxiv.org/abs/2101.06490">arxiv:2101.06490</a>
&#x1F4C8; 3 <br>
<p>Hunter R Johnson</p></summary>
<p>

**Abstract:** Any binary string can be associated with a unary predicate $P$ on $\mathbb{N}$. In this paper we investigate subsets named by a predicate $P$ such that the relation $P(x+y)$ has finite VC dimension. This provides a measure of complexity for binary strings with different properties than the standard string complexity function (based on diversity of substrings). We prove that strings of bounded VC dimension are meagre in the topology of the reals, provide simple rules for bounding the VC dimension of a string, and show that the bi-infinite strings of VC dimension $d$ are a non-sofic shift space. Additionally we characterize the irreducible strings of low VC dimension (0,1 and 2), and provide connections to mathematical logic.

</p>
</details>

<details><summary><b>Latent Variable Models for Visual Question Answering</b>
<a href="https://arxiv.org/abs/2101.06399">arxiv:2101.06399</a>
&#x1F4C8; 3 <br>
<p>Zixu Wang, Yishu Miao, Lucia Specia</p></summary>
<p>

**Abstract:** Current work on Visual Question Answering (VQA) explore deterministic approaches conditioned on various types of image and question features. We posit that, in addition to image and question pairs, other modalities are useful for teaching machine to carry out question answering. Hence in this paper, we propose latent variable models for VQA where extra information (e.g. captions and answer categories) are incorporated as latent variables, which are observed during training but in turn benefit question-answering performance at test time. Experiments on the VQA v2.0 benchmarking dataset demonstrate the effectiveness of our proposed models: they improve over strong baselines, especially those that do not rely on extensive language-vision pre-training.

</p>
</details>

<details><summary><b>SelfMatch: Combining Contrastive Self-Supervision and Consistency for Semi-Supervised Learning</b>
<a href="https://arxiv.org/abs/2101.06480">arxiv:2101.06480</a>
&#x1F4C8; 2 <br>
<p>Byoungjip Kim, Jinho Choo, Yeong-Dae Kwon, Seongho Joe, Seungjai Min, Youngjune Gwon</p></summary>
<p>

**Abstract:** This paper introduces SelfMatch, a semi-supervised learning method that combines the power of contrastive self-supervised learning and consistency regularization. SelfMatch consists of two stages: (1) self-supervised pre-training based on contrastive learning and (2) semi-supervised fine-tuning based on augmentation consistency regularization. We empirically demonstrate that SelfMatch achieves the state-of-the-art results on standard benchmark datasets such as CIFAR-10 and SVHN. For example, for CIFAR-10 with 40 labeled examples, SelfMatch achieves 93.19% accuracy that outperforms the strong previous methods such as MixMatch (52.46%), UDA (70.95%), ReMixMatch (80.9%), and FixMatch (86.19%). We note that SelfMatch can close the gap between supervised learning (95.87%) and semi-supervised learning (93.19%) by using only a few labels for each class.

</p>
</details>

<details><summary><b>Learning the Implicit Semantic Representation on Graph-Structured Data</b>
<a href="https://arxiv.org/abs/2101.06471">arxiv:2101.06471</a>
&#x1F4C8; 2 <br>
<p>Likang Wu, Zhi Li, Hongke Zhao, Qi Liu, Jun Wang, Mengdi Zhang, Enhong Chen</p></summary>
<p>

**Abstract:** Existing representation learning methods in graph convolutional networks are mainly designed by describing the neighborhood of each node as a perceptual whole, while the implicit semantic associations behind highly complex interactions of graphs are largely unexploited. In this paper, we propose a Semantic Graph Convolutional Networks (SGCN) that explores the implicit semantics by learning latent semantic-paths in graphs. In previous work, there are explorations of graph semantics via meta-paths. However, these methods mainly rely on explicit heterogeneous information that is hard to be obtained in a large amount of graph-structured data. SGCN first breaks through this restriction via leveraging the semantic-paths dynamically and automatically during the node aggregating process. To evaluate our idea, we conduct sufficient experiments on several standard datasets, and the empirical results show the superior performance of our model.

</p>
</details>

<details><summary><b>Robustness to Augmentations as a Generalization metric</b>
<a href="https://arxiv.org/abs/2101.06459">arxiv:2101.06459</a>
&#x1F4C8; 2 <br>
<p>Sumukh Aithal K, Dhruva Kashyap, Natarajan Subramanyam</p></summary>
<p>

**Abstract:** Generalization is the ability of a model to predict on unseen domains and is a fundamental task in machine learning. Several generalization bounds, both theoretical and empirical have been proposed but they do not provide tight bounds .In this work, we propose a simple yet effective method to predict the generalization performance of a model by using the concept that models that are robust to augmentations are more generalizable than those which are not. We experiment with several augmentations and composition of augmentations to check the generalization capacity of a model. We also provide a detailed motivation behind the proposed method. The proposed generalization metric is calculated based on the change in the output of the model after augmenting the input. The proposed method was the first runner up solution for the NeurIPS competition on Predicting Generalization in Deep Learning.

</p>
</details>

<details><summary><b>Hashing and metric learning for charged particle tracking</b>
<a href="https://arxiv.org/abs/2101.06428">arxiv:2101.06428</a>
&#x1F4C8; 2 <br>
<p>Sabrina Amrouche, Moritz Kiehn, Tobias Golling, Andreas Salzburger</p></summary>
<p>

**Abstract:** We propose a novel approach to charged particle tracking at high intensity particle colliders based on Approximate Nearest Neighbors search. With hundreds of thousands of measurements per collision to be reconstructed e.g. at the High Luminosity Large Hadron Collider, the currently employed combinatorial track finding approaches become inadequate. Here, we use hashing techniques to separate measurements into buckets of 20-50 hits and increase their purity using metric learning. Two different approaches are studied to further resolve tracks inside buckets: Local Fisher Discriminant Analysis and Neural Networks for triplet similarity learning. We demonstrate the proposed approach on simulated collisions and show significant speed improvement with bucket tracking efficiency of 96% and a fake rate of 8% on unseen particle events.

</p>
</details>

<details><summary><b>Morphological Change Forecasting for Prostate Glands using Feature-based Registration and Kernel Density Extrapolation</b>
<a href="https://arxiv.org/abs/2101.06425">arxiv:2101.06425</a>
&#x1F4C8; 2 <br>
<p>Qianye Yang, Tom Vercauteren, Yunguan Fu, Francesco Giganti, Nooshin Ghavami, Vasilis Stavrinides, Caroline Moore, Matt Clarkson, Dean Barratt, Yipeng Hu</p></summary>
<p>

**Abstract:** Organ morphology is a key indicator for prostate disease diagnosis and prognosis. For instance, In longitudinal study of prostate cancer patients under active surveillance, the volume, boundary smoothness and their changes are closely monitored on time-series MR image data. In this paper, we describe a new framework for forecasting prostate morphological changes, as the ability to detect such changes earlier than what is currently possible may enable timely treatment or avoiding unnecessary confirmatory biopsies. In this work, an efficient feature-based MR image registration is first developed to align delineated prostate gland capsules to quantify the morphological changes using the inferred dense displacement fields (DDFs). We then propose to use kernel density estimation (KDE) of the probability density of the DDF-represented \textit{future morphology changes}, between current and future time points, before the future data become available. The KDE utilises a novel distance function that takes into account morphology, stage-of-progression and duration-of-change, which are considered factors in such subject-specific forecasting. We validate the proposed approach on image masks unseen to registration network training, without using any data acquired at the future target time points. The experiment results are presented on a longitudinal data set with 331 images from 73 patients, yielding an average Dice score of 0.865 on a holdout set, between the ground-truth and the image masks warped by the KDE-predicted-DDFs.

</p>
</details>

<details><summary><b>Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in GPS-Denied Environments</b>
<a href="https://arxiv.org/abs/2101.06414">arxiv:2101.06414</a>
&#x1F4C8; 2 <br>
<p>Ashish Kumar, Mohit Vohra, Ravi Prakash, L. Behera</p></summary>
<p>

**Abstract:** In this work, we present a pragmatic approach to enable unmanned aerial vehicle (UAVs) to autonomously perform highly complicated tasks of object pick and place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is primarily focused on the task of assembling large 3D structures in outdoors and GPS-denied environments. Primary contributions of this system are: (i) a novel computationally efficient deep learning based unified multi-task visual perception system for target localization, part segmentation, and tracking, (ii) a novel deep learning based grasp state estimation, (iii) a retracting electromagnetic gripper design, (iv) a remote computing approach which exploits state-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the UAVs to execute compute intensive tasks on remote high end compute servers, and (v) system integration in which several system components are weaved together in order to develop an optimized software stack. We use DJI Matrice-600 Pro, a hex-rotor UAV and interface it with the custom designed gripper. Our framework is deployed on the specified UAV in order to report the performance analysis of the individual modules. Apart from the manipulation system, we also highlight several hidden challenges associated with the UAVs in this context.

</p>
</details>

<details><summary><b>Informative core identification in complex networks</b>
<a href="https://arxiv.org/abs/2101.06388">arxiv:2101.06388</a>
&#x1F4C8; 2 <br>
<p>Ruizhong Miao, Tianxi Li</p></summary>
<p>

**Abstract:** In network analysis, the core structure of modeling interest is usually hidden in a larger network in which most structures are not informative. The noise and bias introduced by the non-informative component in networks can obscure the salient structure and limit many network modeling procedures' effectiveness. This paper introduces a novel core-periphery model for the non-informative periphery structure of networks without imposing a specific form for the informative core structure. We propose spectral algorithms for core identification as a data preprocessing step for general downstream network analysis tasks based on the model. The algorithm enjoys a strong theoretical guarantee of accuracy and is scalable for large networks. We evaluate the proposed method by extensive simulation studies demonstrating various advantages over many traditional core-periphery methods. The method is applied to extract the informative core structure from a citation network and give more informative results in the downstream hierarchical community detection.

</p>
</details>

<details><summary><b>Improve Global Glomerulosclerosis Classification with Imbalanced Data using CircleMix Augmentation</b>
<a href="https://arxiv.org/abs/2101.07654">arxiv:2101.07654</a>
&#x1F4C8; 1 <br>
<p>Yuzhe Lu, Haichun Yang, Zheyu Zhu, Ruining Deng, Agnes B. Fogo, Yuankai Huo</p></summary>
<p>

**Abstract:** The classification of glomerular lesions is a routine and essential task in renal pathology. Recently, machine learning approaches, especially deep learning algorithms, have been used to perform computer-aided lesion characterization of glomeruli. However, one major challenge of developing such methods is the naturally imbalanced distribution of different lesions. In this paper, we propose CircleMix, a novel data augmentation technique, to improve the accuracy of classifying globally sclerotic glomeruli with a hierarchical learning strategy. Different from the recently proposed CutMix method, the CircleMix augmentation is optimized for the ball-shaped biomedical objects, such as glomeruli. 6,861 glomeruli with five classes (normal, periglomerular fibrosis, obsolescent glomerulosclerosis, solidified glomerulosclerosis, and disappearing glomerulosclerosis) were employed to develop and evaluate the proposed methods. From five-fold cross-validation, the proposed CircleMix augmentation achieved superior performance (Balanced Accuracy=73.0%) compared with the EfficientNet-B0 baseline (Balanced Accuracy=69.4%)

</p>
</details>

<details><summary><b>Tailored Learning-Based Scheduling for Kubernetes-Oriented Edge-Cloud System</b>
<a href="https://arxiv.org/abs/2101.06582">arxiv:2101.06582</a>
&#x1F4C8; 1 <br>
<p>Yiwen Han, Shihao Shen, Xiaofei Wang, Shiqiang Wang, Victor C. M. Leung</p></summary>
<p>

**Abstract:** Kubernetes (k8s) has the potential to merge the distributed edge and the cloud but lacks a scheduling framework specifically for edge-cloud systems. Besides, the hierarchical distribution of heterogeneous resources and the complex dependencies among requests and resources make the modeling and scheduling of k8s-oriented edge-cloud systems particularly sophisticated. In this paper, we introduce KaiS, a learning-based scheduling framework for such edge-cloud systems to improve the long-term throughput rate of request processing. First, we design a coordinated multi-agent actor-critic algorithm to cater to decentralized request dispatch and dynamic dispatch spaces within the edge cluster. Second, for diverse system scales and structures, we use graph neural networks to embed system state information, and combine the embedding results with multiple policy networks to reduce the orchestration dimensionality by stepwise scheduling. Finally, we adopt a two-time-scale scheduling mechanism to harmonize request dispatch and service orchestration, and present the implementation design of deploying the above algorithms compatible with native k8s components. Experiments using real workload traces show that KaiS can successfully learn appropriate scheduling policies, irrespective of request arrival patterns and system scales. Moreover, KaiS can enhance the average system throughput rate by 14.3% while reducing scheduling cost by 34.7% compared to baselines.

</p>
</details>

<details><summary><b>Deep-Mobility: A Deep Learning Approach for an Efficient and Reliable 5G Handover</b>
<a href="https://arxiv.org/abs/2101.06558">arxiv:2101.06558</a>
&#x1F4C8; 1 <br>
<p>Rahul Arun Paropkari, Anurag Thantharate, Cory Beard</p></summary>
<p>

**Abstract:** 5G cellular networks are being deployed all over the world and this architecture supports ultra-dense network (UDN) deployment. Small cells have a very important role in providing 5G connectivity to the end users. Exponential increases in devices, data and network demands make it mandatory for the service providers to manage handovers better, to cater to the services that a user desire. In contrast to any traditional handover improvement scheme, we develop a 'Deep-Mobility' model by implementing a deep learning neural network (DLNN) to manage network mobility, utilizing in-network deep learning and prediction. We use network key performance indicators (KPIs) to train our model to analyze network traffic and handover requirements. In this method, RF signal conditions are continuously observed and tracked using deep learning neural networks such as the Recurrent neural network (RNN) or Long Short-Term Memory network (LSTM) and system level inputs are also considered in conjunction, to take a collective decision for a handover. We can study multiple parameters and interactions between system events along with the user mobility, which would then trigger a handoff in any given scenario. Here, we show the fundamental modeling approach and demonstrate usefulness of our model while investigating impacts and sensitivities of certain KPIs from the user equipment (UE) and network side.

</p>
</details>

<details><summary><b>Big Data application in congestion detection and classification using Apache spark</b>
<a href="https://arxiv.org/abs/2101.06524">arxiv:2101.06524</a>
&#x1F4C8; 1 <br>
<p>Atousa Zarindast, Anuj Sharma</p></summary>
<p>

**Abstract:** With the era of big data, an explosive amount of information is now available. This enormous increase of Big Data in both academia and industry requires large-scale data processing systems. A large body of research is behind optimizing Spark's performance to make it state of the art, a fast and general data processing system. Many science and engineering fields have advanced with Big Data analytics, such as Biology, finance, and transportation. Intelligent transportation systems (ITS) gain popularity and direct benefit from the richness of information. The objective is to improve the safety and management of transportation networks by reducing congestion and incidents. The first step toward the goal is better understanding, modeling, and detecting congestion across a network efficiently and effectively. In this study, we introduce an efficient congestion detection model. The underlying network consists of 3017 segments in I-35, I-80, I-29, and I-380 freeways with an overall length of 1570 miles and averaged (0.4-0.6) miles per segment. The result of congestion detection shows the proposed method is 90% accurate while has reduced computation time by 99.88%.

</p>
</details>

<details><summary><b>Learning Robust Hybrid Control Barrier Functions for Uncertain Systems</b>
<a href="https://arxiv.org/abs/2101.06492">arxiv:2101.06492</a>
&#x1F4C8; 1 <br>
<p>Alexander Robey, Lars Lindemann, Stephen Tu, Nikolai Matni</p></summary>
<p>

**Abstract:** The need for robust control laws is especially important in safety-critical applications. We propose robust hybrid control barrier functions as a means to synthesize control laws that ensure robust safety. Based on this notion, we formulate an optimization problem for learning robust hybrid control barrier functions from data. We identify sufficient conditions on the data such that feasibility of the optimization problem ensures correctness of the learned robust hybrid control barrier functions. Our techniques allow us to safely expand the region of attraction of a compass gait walker that is subject to model uncertainty.

</p>
</details>

<details><summary><b>Adversarial cycle-consistent synthesis of cerebral microbleeds for data augmentation</b>
<a href="https://arxiv.org/abs/2101.06468">arxiv:2101.06468</a>
&#x1F4C8; 1 <br>
<p>Khrystyna Faryna, Kevin Koschmieder, Marcella M. Paul, Thomas van den Heuvel, Anke van der Eerden, Rashindra Manniesing, Bram van Ginneken</p></summary>
<p>

**Abstract:** We propose a novel framework for controllable pathological image synthesis for data augmentation. Inspired by CycleGAN, we perform cycle-consistent image-to-image translation between two domains: healthy and pathological. Guided by a semantic mask, an adversarially trained generator synthesizes pathology on a healthy image in the specified location. We demonstrate our approach on an institutional dataset of cerebral microbleeds in traumatic brain injury patients. We utilize synthetic images generated with our method for data augmentation in cerebral microbleeds detection. Enriching the training dataset with synthetic images exhibits the potential to increase detection performance for cerebral microbleeds in traumatic brain injury patients.

</p>
</details>

<details><summary><b>An MCMC Method to Sample from Lattice Distributions</b>
<a href="https://arxiv.org/abs/2101.06453">arxiv:2101.06453</a>
&#x1F4C8; 1 <br>
<p>Anand Jerry George, Navin Kashyap</p></summary>
<p>

**Abstract:** We introduce a Markov Chain Monte Carlo (MCMC) algorithm to generate samples from probability distributions supported on a $d$-dimensional lattice $Î= \mathbf{B}\mathbb{Z}^d$, where $\mathbf{B}$ is a full-rank matrix. Specifically, we consider lattice distributions $P_Î$ in which the probability at a lattice point is proportional to a given probability density function, $f$, evaluated at that point. To generate samples from $P_Î$, it suffices to draw samples from a pull-back measure $P_{\mathbb{Z}^d}$ defined on the integer lattice. The probability of an integer lattice point under $P_{\mathbb{Z}^d}$ is proportional to the density function $Ï= |\det(\mathbf{B})|f\circ \mathbf{B}$. The algorithm we present in this paper for sampling from $P_{\mathbb{Z}^d}$ is based on the Metropolis-Hastings framework. In particular, we use $Ï$ as the proposal distribution and calculate the Metropolis-Hastings acceptance ratio for a well-chosen target distribution. We can use any method, denoted by ALG, that ideally draws samples from the probability density $Ï$, to generate a proposed state. The target distribution is a piecewise sigmoidal distribution, chosen such that the coordinate-wise rounding of a sample drawn from the target distribution gives a sample from $P_{\mathbb{Z}^d}$. When ALG is ideal, we show that our algorithm is uniformly ergodic if $-\log(Ï)$ satisfies a gradient Lipschitz condition.

</p>
</details>

<details><summary><b>Scale factor point spread function matching: Beyond aliasing in image resampling</b>
<a href="https://arxiv.org/abs/2101.06440">arxiv:2101.06440</a>
&#x1F4C8; 1 <br>
<p>M. Jorge Cardoso, Marc Modat, Tom Vercauteren, Sebastien Ourselin</p></summary>
<p>

**Abstract:** Imaging devices exploit the Nyquist-Shannon sampling theorem to avoid both aliasing and redundant oversampling by design. Conversely, in medical image resampling, images are considered as continuous functions, are warped by a spatial transformation, and are then sampled on a regular grid. In most cases, the spatial warping changes the frequency characteristics of the continuous function and no special care is taken to ensure that the resampling grid respects the conditions of the sampling theorem. This paper shows that this oversight introduces artefacts, including aliasing, that can lead to important bias in clinical applications. One notable exception to this common practice is when multi-resolution pyramids are constructed, with low-pass "anti-aliasing" filters being applied prior to downsampling. In this work, we illustrate why similar caution is needed when resampling images under general spatial transformations and propose a novel method that is more respectful of the sampling theorem, minimising aliasing and loss of information. We introduce the notion of scale factor point spread function (sfPSF) and employ Gaussian kernels to achieve a computationally tractable resampling scheme that can cope with arbitrary non-linear spatial transformations and grid sizes. Experiments demonstrate significant (p<1e-4) technical and clinical implications of the proposed method.

</p>
</details>

<details><summary><b>A Novel Local Binary Pattern Based Blind Feature Image Steganography</b>
<a href="https://arxiv.org/abs/2101.06383">arxiv:2101.06383</a>
&#x1F4C8; 1 <br>
<p>Soumendu Chakraborty, Anand Singh Jalal</p></summary>
<p>

**Abstract:** Steganography methods in general terms tend to embed more and more secret bits in the cover images. Most of these methods are designed to embed secret information in such a way that the change in the visual quality of the resulting stego image is not detectable. There exists some methods which preserve the global structure of the cover after embedding. However, the embedding capacity of these methods is very less. In this paper a novel feature based blind image steganography technique is proposed, which preserves the LBP (Local binary pattern) feature of the cover with comparable embedding rates. Local binary pattern is a well known image descriptor used for image representation. The proposed scheme computes the local binary pattern to hide the bits of the secret image in such a way that the local relationship that exists in the cover are preserved in the resulting stego image. The performance of the proposed steganography method has been tested on several images of different types to show the robustness. State of the art LSB based steganography methods are compared with the proposed method to show the effectiveness of feature based image steganography

</p>
</details>

<details><summary><b>Dynamical prediction of two meteorological factors using the deep neural network and the long short term memory $(1)$</b>
<a href="https://arxiv.org/abs/2101.09356">arxiv:2101.09356</a>
&#x1F4C8; 0 <br>
<p>Ki Hong Shin, Jae Won Jung, Sung Kyu Seo, Cheol Hwan You, Dong In Lee, Jisun Lee, Ki Ho Chang, Woon Seon Jung, Kyungsik Kim</p></summary>
<p>

**Abstract:** It is important to calculate and analyze temperature and humidity prediction accuracies among quantitative meteorological forecasting. This study manipulates the extant neural network methods to foster the predictive accuracy. To achieve such tasks, we analyze and explore the predictive accuracy and performance in the neural networks using two combined meteorological factors (temperature and humidity). Simulated studies are performed by applying the artificial neural network (ANN), deep neural network (DNN), extreme learning machine (ELM), long short-term memory (LSTM), and long short-term memory with peephole connections (LSTM-PC) machine learning methods, and the accurate prediction value are compared to that obtained from each other methods. Data are extracted from low frequency time-series of ten metropolitan cities of South Korea from March 2014 to February 2020 to validate our observations. To test the robustness of methods, the error of LSTM is found to outperform that of the other four methods in predictive accuracy. Particularly, as testing results, the temperature prediction of LSTM in summer in Tongyeong has a root mean squared error (RMSE) value of 0.866 lower than that of other neural network methods, while the mean absolute percentage error (MAPE) value of LSTM for humidity prediction is 5.525 in summer in Mokpo, significantly better than other metropolitan cities.

</p>
</details>

<details><summary><b>ConE: A Concurrent Edit Detection Tool for Large Scale Software Development</b>
<a href="https://arxiv.org/abs/2101.06542">arxiv:2101.06542</a>
&#x1F4C8; 0 <br>
<p>Chandra Maddila, Nachiappan Nagappan, Christian Bird, Georgios Gousios, Arie van Deursen</p></summary>
<p>

**Abstract:** Modern, complex software systems are being continuously extended and adjusted. The developers responsible for this may come from different teams or organizations, and may be distributed over the world. This may make it difficult to keep track of what other developers are doing, which may result in multiple developers concurrently editing the same code areas. This, in turn, may lead to hard-to-merge changes or even merge conflicts, logical bugs that are difficult to detect, duplication of work, and wasted developer productivity. To address this, we explore the extent of this problem in the pull request based software development model. We study half a year of changes made to six large repositories in Microsoft in which at least 1,000 pull requests are created each month. We find that files concurrently edited in different pull requests are more likely to introduce bugs. Motivated by these findings, we design, implement, and deploy a service named ConE (Concurrent Edit Detector) that proactively detects pull requests containing concurrent edits, to help mitigate the problems caused by them. ConE has been designed to scale, and to minimize false alarms while still flagging relevant concurrently edited files. Key concepts of ConE include the detection of the Extent of Overlap between pull requests, and the identification of Rarely Concurrently Edited Files. To evaluate ConE, we report on its operational deployment on 234 repositories inside Microsoft. ConE assessed 26,000 pull requests and made 775 recommendations about conflicting changes, which were rated as useful in over 70% (554) of the cases. From interviews with 48 users we learned that they believed ConE would save time in conflict resolution and avoiding duplicate work, and that over 90% intend to keep using the service on a daily basis.

</p>
</details>

<details><summary><b>A Renormalization Group Approach to Connect Discrete- and Continuous-Time Descriptions of Gaussian Processes</b>
<a href="https://arxiv.org/abs/2101.06482">arxiv:2101.06482</a>
&#x1F4C8; 0 <br>
<p>Federica Ferretti, Victor ChardÃ¨s, Thierry Mora, Aleksandra M Walczak, Irene Giardina</p></summary>
<p>

**Abstract:** Discretization of continuous stochastic processes is needed to numerically simulate them or to infer models from experimental time series. However, depending on the nature of the process, the same discretization scheme, if not accurate enough, may perform very differently for the two tasks. Exact discretizations, which work equally well at any scale, are characterized by the property of invariance under coarse-graining. Motivated by this observation, we build an explicit Renormalization Group approach for Gaussian time series generated by auto-regressive models. We show that the RG fixed points correspond to discretizations of linear SDEs, and only come in the form of first order Markov processes or non-Markovian ones. This fact provides an alternative explanation of why standard delay-vector embedding procedures fail in reconstructing partially observed noise-driven systems. We also suggest a possible effective Markovian discretization for the inference of partially observed underdamped equilibrium processes based on the exploitation of the Einstein relation.

</p>
</details>


{% endraw %}
Prev: [2021.01.15]({{ '/2021/01/15/2021.01.15.html' | relative_url }})  Next: [2021.01.17]({{ '/2021/01/17/2021.01.17.html' | relative_url }})