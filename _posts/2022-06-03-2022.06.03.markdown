Prev: [2022.06.02]({{ '/2022/06/02/2022.06.02.html' | relative_url }})  Next: [2022.06.04]({{ '/2022/06/04/2022.06.04.html' | relative_url }})
{% raw %}
## Summary for 2022-06-03, created on 2022-06-13


<details><summary><b>Toward a realistic model of speech processing in the brain with self-supervised learning</b>
<a href="https://arxiv.org/abs/2206.01685">arxiv:2206.01685</a>
&#x1F4C8; 2320 <br>
<p>Juliette Millet, Charlotte Caucheteux, Pierre Orhan, Yves Boubenec, Alexandre Gramfort, Ewan Dunbar, Christophe Pallier, Jean-Remi King</p></summary>
<p>

**Abstract:** Several deep neural networks have recently been shown to generate activations similar to those of the brain in response to the same input. These algorithms, however, remain largely implausible: they require (1) extraordinarily large amounts of data, (2) unobtainable supervised labels, (3) textual rather than raw sensory input, and / or (4) implausibly large memory (e.g. thousands of contextual words). These elements highlight the need to identify algorithms that, under these limitations, would suffice to account for both behavioral and brain responses. Focusing on the issue of speech processing, we here hypothesize that self-supervised algorithms trained on the raw waveform constitute a promising candidate. Specifically, we compare a recent self-supervised architecture, Wav2Vec 2.0, to the brain activity of 412 English, French, and Mandarin individuals recorded with functional Magnetic Resonance Imaging (fMRI), while they listened to ~1h of audio books. Our results are four-fold. First, we show that this algorithm learns brain-like representations with as little as 600 hours of unlabelled speech -- a quantity comparable to what infants can be exposed to during language acquisition. Second, its functional hierarchy aligns with the cortical hierarchy of speech processing. Third, different training regimes reveal a functional specialization akin to the cortex: Wav2Vec 2.0 learns sound-generic, speech-specific and language-specific representations similar to those of the prefrontal and temporal cortices. Fourth, we confirm the similarity of this specialization with the behavior of 386 additional participants. These elements, resulting from the largest neuroimaging benchmark to date, show how self-supervised learning can account for a rich organization of speech processing in the brain, and thus delineate a path to identify the laws of language acquisition which shape the human brain.

</p>
</details>

<details><summary><b>Extreme Compression for Pre-trained Transformers Made Simple and Efficient</b>
<a href="https://arxiv.org/abs/2206.01859">arxiv:2206.01859</a>
&#x1F4C8; 1900 <br>
<p>Xiaoxia Wu, Zhewei Yao, Minjia Zhang, Conglong Li, Yuxiong He</p></summary>
<p>

**Abstract:** Extreme compression, particularly ultra-low bit precision (binary/ternary) quantization, has been proposed to fit large NLP models on resource-constraint devices. However, to preserve the accuracy for such aggressive compression schemes, cutting-edge methods usually introduce complicated compression pipelines, e.g., multi-stage expensive knowledge distillation with extensive hyperparameter tuning. Also, they oftentimes focus less on smaller transformer models that have already been heavily compressed via knowledge distillation and lack a systematic study to show the effectiveness of their methods. In this paper, we perform a very comprehensive systematic study to measure the impact of many key hyperparameters and training strategies from previous works. As a result, we find out that previous baselines for ultra-low bit precision quantization are significantly under-trained. Based on our study, we propose a simple yet effective compression pipeline for extreme compression, named XTC. XTC demonstrates that (1) we can skip the pre-training knowledge distillation to obtain a 5-layer BERT while achieving better performance than previous state-of-the-art methods, e.g., the 6-layer TinyBERT; (2) extreme quantization plus layer reduction is able to reduce the model size by 50x, resulting in new state-of-the-art results on GLUE tasks.

</p>
</details>

<details><summary><b>ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers</b>
<a href="https://arxiv.org/abs/2206.01861">arxiv:2206.01861</a>
&#x1F4C8; 374 <br>
<p>Zhewei Yao, Reza Yazdani Aminabadi, Minjia Zhang, Xiaoxia Wu, Conglong Li, Yuxiong He</p></summary>
<p>

**Abstract:** How to efficiently serve ever-larger trained natural language models in practice has become exceptionally challenging even for powerful cloud servers due to their prohibitive memory/computation requirements. In this work, we present an efficient and affordable post-training quantization approach to compress large Transformer-based models, termed as ZeroQuant. ZeroQuant is an end-to-end quantization and inference pipeline with three main components: (1) a fine-grained hardware-friendly quantization scheme for both weight and activations; (2) a novel affordable layer-by-layer knowledge distillation algorithm (LKD) even without the access to the original training data; (3) a highly-optimized quantization system backend support to remove the quantization/dequantization overhead. As such, we are able to show that: (1) ZeroQuant can reduce the precision for weights and activations to INT8 in a cost-free way for both BERT and GPT3-style models with minimal accuracy impact, which leads to up to 5.19x/4.16x speedup on those models compared to FP16 inference; (2) ZeroQuant plus LKD affordably quantize the weights in the fully-connected module to INT4 along with INT8 weights in the attention module and INT8 activations, resulting in 3x memory footprint reduction compared to the FP16 model; (3) ZeroQuant can be directly applied to two of the largest open-sourced language models, including GPT-J6B and GPT-NeoX20, for which our INT8 model achieves similar accuracy as the FP16 model but achieves up to 5.2x better efficiency.

</p>
</details>

<details><summary><b>Compositional Visual Generation with Composable Diffusion Models</b>
<a href="https://arxiv.org/abs/2206.01714">arxiv:2206.01714</a>
&#x1F4C8; 164 <br>
<p>Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, Joshua B. Tenenbaum</p></summary>
<p>

**Abstract:** Large text-guided diffusion models, such as DALLE-2, are able to generate stunning photorealistic images given natural language descriptions. While such models are highly flexible, they struggle to understand the composition of certain concepts, such as confusing the attributes of different objects or relations between objects. In this paper, we propose an alternative structured approach for compositional generation using diffusion models. An image is generated by composing a set of diffusion models, with each of them modeling a certain component of the image. To do this, we interpret diffusion models as energy-based models in which the data distributions defined by the energy functions may be explicitly combined. The proposed method can generate scenes at test time that are substantially more complex than those seen in training, composing sentence descriptions, object relations, human facial attributes, and even generalizing to new combinations that are rarely seen in the real world. We further illustrate how our approach may be used to compose pre-trained text-guided diffusion models and generate photorealistic images containing all the details described in the input descriptions, including the binding of certain object attributes that have been shown difficult for DALLE-2. These results point to the effectiveness of the proposed method in promoting structured generalization for visual generation. Project page: https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/

</p>
</details>

<details><summary><b>Learning Probabilistic Structural Representation for Biomedical Image Segmentation</b>
<a href="https://arxiv.org/abs/2206.01742">arxiv:2206.01742</a>
&#x1F4C8; 79 <br>
<p>Xiaoling Hu, Dimitris Samaras, Chao Chen</p></summary>
<p>

**Abstract:** Accurate segmentation of various fine-scale structures from biomedical images is a very important yet challenging problem. Existing methods use topological information as an additional training loss, but are ultimately learning a pixel-wise representation. In this paper, we propose the first deep learning method to learn a structural representation. We use discrete Morse theory and persistent homology to construct an one-parameter family of structures as the structural representation space. Furthermore, we learn a probabilistic model that can do inference tasks on such a structural representation space. We empirically demonstrate the strength of our method, i.e., generating true structures rather than pixel-maps with better topological integrity, and facilitating a human-in-the-loop annotation pipeline using the sampling of structures and structure-aware uncertainty.

</p>
</details>

<details><summary><b>Reinforcement Learning with Neural Radiance Fields</b>
<a href="https://arxiv.org/abs/2206.01634">arxiv:2206.01634</a>
&#x1F4C8; 65 <br>
<p>Danny Driess, Ingmar Schubert, Pete Florence, Yunzhu Li, Marc Toussaint</p></summary>
<p>

**Abstract:** It is a long-standing problem to find effective representations for training reinforcement learning (RL) agents. This paper demonstrates that learning state representations with supervision from Neural Radiance Fields (NeRFs) can improve the performance of RL compared to other learned representations or even low-dimensional, hand-engineered state information. Specifically, we propose to train an encoder that maps multiple image observations to a latent space describing the objects in the scene. The decoder built from a latent-conditioned NeRF serves as the supervision signal to learn the latent space. An RL algorithm then operates on the learned latent space as its state representation. We call this NeRF-RL. Our experiments indicate that NeRF as supervision leads to a latent space better suited for the downstream RL tasks involving robotic object manipulations like hanging mugs on hooks, pushing objects, or opening doors. Video: https://dannydriess.github.io/nerf-rl

</p>
</details>

<details><summary><b>Revisiting the "Video" in Video-Language Understanding</b>
<a href="https://arxiv.org/abs/2206.01720">arxiv:2206.01720</a>
&#x1F4C8; 47 <br>
<p>Shyamal Buch, Cristóbal Eyzaguirre, Adrien Gaidon, Jiajun Wu, Li Fei-Fei, Juan Carlos Niebles</p></summary>
<p>

**Abstract:** What makes a video task uniquely suited for videos, beyond what can be understood from a single image? Building on recent progress in self-supervised image-language models, we revisit this question in the context of video and language tasks. We propose the atemporal probe (ATP), a new model for video-language analysis which provides a stronger bound on the baseline accuracy of multimodal models constrained by image-level understanding. By applying this model to standard discriminative video and language tasks, such as video question answering and text-to-video retrieval, we characterize the limitations and potential of current video-language benchmarks. We find that understanding of event temporality is often not necessary to achieve strong or state-of-the-art performance, even compared with recent large-scale video-language models and in contexts intended to benchmark deeper video-level understanding. We also demonstrate how ATP can improve both video-language dataset and model design. We describe a technique for leveraging ATP to better disentangle dataset subsets with a higher concentration of temporally challenging data, improving benchmarking efficacy for causal and temporal understanding. Further, we show that effectively integrating ATP into full video-level temporal models can improve efficiency and state-of-the-art accuracy.

</p>
</details>

<details><summary><b>On the duality between contrastive and non-contrastive self-supervised learning</b>
<a href="https://arxiv.org/abs/2206.02574">arxiv:2206.02574</a>
&#x1F4C8; 21 <br>
<p>Quentin Garrido, Yubei Chen, Adrien Bardes, Laurent Najman, Yann Lecun</p></summary>
<p>

**Abstract:** Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show how design choices in the criterion can influence the optimization process and downstream performance. We also challenge the popular assumptions that contrastive and non-contrastive methods, respectively, need large batch sizes and output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and noncontrastive methods in certain regimes can be significantly reduced given better network design choice and hyperparameter tuning.

</p>
</details>

<details><summary><b>Prescriptive maintenance with causal machine learning</b>
<a href="https://arxiv.org/abs/2206.01562">arxiv:2206.01562</a>
&#x1F4C8; 21 <br>
<p>Toon Vanderschueren, Robert Boute, Tim Verdonck, Bart Baesens, Wouter Verbeke</p></summary>
<p>

**Abstract:** Machine maintenance is a challenging operational problem, where the goal is to plan sufficient preventive maintenance to avoid machine failures and overhauls. Maintenance is often imperfect in reality and does not make the asset as good as new. Although a variety of imperfect maintenance policies have been proposed in the literature, these rely on strong assumptions regarding the effect of maintenance on the machine's condition, assuming the effect is (1) deterministic or governed by a known probability distribution, and (2) machine-independent. This work proposes to relax both assumptions by learning the effect of maintenance conditional on a machine's characteristics from observational data on similar machines using existing methodologies for causal inference. By predicting the maintenance effect, we can estimate the number of overhauls and failures for different levels of maintenance and, consequently, optimize the preventive maintenance frequency to minimize the total estimated cost. We validate our proposed approach using real-life data on more than 4,000 maintenance contracts from an industrial partner. Empirical results show that our novel, causal approach accurately predicts the maintenance effect and results in individualized maintenance schedules that are more accurate and cost-effective than supervised or non-individualized approaches.

</p>
</details>

<details><summary><b>Beyond Tabula Rasa: Reincarnating Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2206.01626">arxiv:2206.01626</a>
&#x1F4C8; 10 <br>
<p>Rishabh Agarwal, Max Schwarzer, Pablo Samuel Castro, Aaron Courville, Marc G. Bellemare</p></summary>
<p>

**Abstract:** Learning tabula rasa, that is without any prior knowledge, is the prevalent workflow in reinforcement learning (RL) research. However, RL systems, when applied to large-scale settings, rarely operate tabula rasa. Such large-scale systems undergo multiple design or algorithmic changes during their development cycle and use ad hoc approaches for incorporating these changes without re-training from scratch, which would have been prohibitively expensive. Additionally, the inefficiency of deep RL typically excludes researchers without access to industrial-scale resources from tackling computationally-demanding problems. To address these issues, we present reincarnating RL as an alternative workflow, where prior computational work (e.g., learned policies) is reused or transferred between design iterations of an RL agent, or from one RL agent to another. As a step towards enabling reincarnating RL from any agent to any other agent, we focus on the specific setting of efficiently transferring an existing sub-optimal policy to a standalone value-based RL agent. We find that existing approaches fail in this setting and propose a simple algorithm to address their limitations. Equipped with this algorithm, we demonstrate reincarnating RL's gains over tabula rasa RL on Atari 2600 games, a challenging locomotion task, and the real-world problem of navigating stratospheric balloons. Overall, this work argues for an alternative approach to RL research, which we believe could significantly improve real-world RL adoption and help democratize it further.

</p>
</details>

<details><summary><b>R2U++: A Multiscale Recurrent Residual U-Net with Dense Skip Connections for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2206.01793">arxiv:2206.01793</a>
&#x1F4C8; 9 <br>
<p>Mehreen Mubashar, Hazrat Ali, Christer Gronlund, Shoaib Azmat</p></summary>
<p>

**Abstract:** U-Net is a widely adopted neural network in the domain of medical image segmentation. Despite its quick embracement by the medical imaging community, its performance suffers on complicated datasets. The problem can be ascribed to its simple feature extracting blocks: encoder/decoder, and the semantic gap between encoder and decoder. Variants of U-Net (such as R2U-Net) have been proposed to address the problem of simple feature extracting blocks by making the network deeper, but it does not deal with the semantic gap problem. On the other hand, another variant UNET++ deals with the semantic gap problem by introducing dense skip connections but has simple feature extraction blocks. To overcome these issues, we propose a new U-Net based medical image segmentation architecture R2U++. In the proposed architecture, the adapted changes from vanilla U-Net are: (1) the plain convolutional backbone is replaced by a deeper recurrent residual convolution block. The increased field of view with these blocks aids in extracting crucial features for segmentation which is proven by improvement in the overall performance of the network. (2) The semantic gap between encoder and decoder is reduced by dense skip pathways. These pathways accumulate features coming from multiple scales and apply concatenation accordingly. The modified architecture has embedded multi-depth models, and an ensemble of outputs taken from varying depths improves the performance on foreground objects appearing at various scales in the images. The performance of R2U++ is evaluated on four distinct medical imaging modalities: electron microscopy (EM), X-rays, fundus, and computed tomography (CT). The average gain achieved in IoU score is 1.5+-0.37% and in dice score is 0.9+-0.33% over UNET++, whereas, 4.21+-2.72 in IoU and 3.47+-1.89 in dice score over R2U-Net across different medical imaging segmentation datasets.

</p>
</details>

<details><summary><b>Egocentric Video-Language Pretraining</b>
<a href="https://arxiv.org/abs/2206.01670">arxiv:2206.01670</a>
&#x1F4C8; 9 <br>
<p>Kevin Qinghong Lin, Alex Jinpeng Wang, Mattia Soldan, Michael Wray, Rui Yan, Eric Zhongcong Xu, Difei Gao, Rongcheng Tu, Wenzhe Zhao, Weijie Kong, Chengfei Cai, Hongfa Wang, Dima Damen, Bernard Ghanem, Wei Liu, Mike Zheng Shou</p></summary>
<p>

**Abstract:** Video-Language Pretraining (VLP), aiming to learn transferable representation to advance a wide range of video-text downstream tasks, has recently received increasing attention. Dominant works that achieve strong performance rely on large-scale, 3rd-person video-text datasets, such as HowTo100M. In this work, we exploit the recently released Ego4D dataset to pioneer Egocentric VLP along three directions. (i) We create EgoClip, a 1st-person video-text pretraining dataset comprising 3.8M clip-text pairs well-chosen from Ego4D, covering a large variety of human daily activities. (ii) We propose a novel pretraining objective, dubbed as EgoNCE, which adapts video-text contrastive learning to egocentric domain by mining egocentric-aware positive and negative samples. (iii) We introduce EgoMCQ, a development benchmark that is close to EgoClip and hence can support effective validation and fast exploration of our design decisions regarding EgoClip and EgoNCE. Furthermore, we demonstrate strong performance on five egocentric downstream tasks across three datasets: video-text retrieval on EPIC-KITCHENS-100; action recognition on Charades-Ego; and natural language query, moment query, and object state change classification on Ego4D challenge benchmarks. The dataset and code will be available at https://github.com/showlab/EgoVLP.

</p>
</details>

<details><summary><b>Do-Operation Guided Causal Representation Learning with Reduced Supervision Strength</b>
<a href="https://arxiv.org/abs/2206.01802">arxiv:2206.01802</a>
&#x1F4C8; 8 <br>
<p>Jiageng Zhu, Hanchen Xie, Wael AbdAlmageed</p></summary>
<p>

**Abstract:** Causal representation learning has been proposed to encode relationships between factors presented in the high dimensional data. However, existing methods suffer from merely using a large amount of labeled data and ignore the fact that samples generated by the same causal mechanism follow the same causal relationships. In this paper, we seek to explore such information by leveraging do-operation for reducing supervision strength. We propose a framework which implements do-operation by swapping latent cause and effect factors encoded from a pair of inputs. Moreover, we also identify the inadequacy of existing causal representation metrics empirically and theoretically, and introduce new metrics for better evaluation. Experiments conducted on both synthetic and real datasets demonstrate the superiorities of our method compared with state-of-the-art methods.

</p>
</details>

<details><summary><b>Dynamic Kernel Selection for Improved Generalization and Memory Efficiency in Meta-learning</b>
<a href="https://arxiv.org/abs/2206.01690">arxiv:2206.01690</a>
&#x1F4C8; 8 <br>
<p>Arnav Chavan, Rishabh Tiwari, Udbhav Bamba, Deepak K. Gupta</p></summary>
<p>

**Abstract:** Gradient based meta-learning methods are prone to overfit on the meta-training set, and this behaviour is more prominent with large and complex networks. Moreover, large networks restrict the application of meta-learning models on low-power edge devices. While choosing smaller networks avoid these issues to a certain extent, it affects the overall generalization leading to reduced performance. Clearly, there is an approximately optimal choice of network architecture that is best suited for every meta-learning problem, however, identifying it beforehand is not straightforward. In this paper, we present MetaDOCK, a task-specific dynamic kernel selection strategy for designing compressed CNN models that generalize well on unseen tasks in meta-learning. Our method is based on the hypothesis that for a given set of similar tasks, not all kernels of the network are needed by each individual task. Rather, each task uses only a fraction of the kernels, and the selection of the kernels per task can be learnt dynamically as a part of the inner update steps. MetaDOCK compresses the meta-model as well as the task-specific inner models, thus providing significant reduction in model size for each task, and through constraining the number of active kernels for every task, it implicitly mitigates the issue of meta-overfitting. We show that for the same inference budget, pruned versions of large CNN models obtained using our approach consistently outperform the conventional choices of CNN models. MetaDOCK couples well with popular meta-learning approaches such as iMAML. The efficacy of our method is validated on CIFAR-fs and mini-ImageNet datasets, and we have observed that our approach can provide improvements in model accuracy of up to 2% on standard meta-learning benchmark, while reducing the model size by more than 75%.

</p>
</details>

<details><summary><b>Visual Clues: Bridging Vision and Language Foundations for Image Paragraph Captioning</b>
<a href="https://arxiv.org/abs/2206.01843">arxiv:2206.01843</a>
&#x1F4C8; 7 <br>
<p>Yujia Xie, Luowei Zhou, Xiyang Dai, Lu Yuan, Nguyen Bach, Ce Liu, Michael Zeng</p></summary>
<p>

**Abstract:** People say, "A picture is worth a thousand words". Then how can we get the rich information out of the image? We argue that by using visual clues to bridge large pretrained vision foundation models and language models, we can do so without any extra cross-modal training. Thanks to the strong zero-shot capability of foundation models, we start by constructing a rich semantic representation of the image (e.g., image tags, object attributes / locations, captions) as a structured textual prompt, called visual clues, using a vision foundation model. Based on visual clues, we use large language model to produce a series of comprehensive descriptions for the visual content, which is then verified by the vision model again to select the candidate that aligns best with the image. We evaluate the quality of generated descriptions by quantitative and qualitative measurement. The results demonstrate the effectiveness of such a structured semantic representation.

</p>
</details>

<details><summary><b>Drawing out of Distribution with Neuro-Symbolic Generative Models</b>
<a href="https://arxiv.org/abs/2206.01829">arxiv:2206.01829</a>
&#x1F4C8; 7 <br>
<p>Yichao Liang, Joshua B. Tenenbaum, Tuan Anh Le, N. Siddharth</p></summary>
<p>

**Abstract:** Learning general-purpose representations from perceptual inputs is a hallmark of human intelligence. For example, people can write out numbers or characters, or even draw doodles, by characterizing these tasks as different instantiations of the same generic underlying process -- compositional arrangements of different forms of pen strokes. Crucially, learning to do one task, say writing, implies reasonable competence at another, say drawing, on account of this shared process. We present Drawing out of Distribution (DooD), a neuro-symbolic generative model of stroke-based drawing that can learn such general-purpose representations. In contrast to prior work, DooD operates directly on images, requires no supervision or expensive test-time inference, and performs unsupervised amortised inference with a symbolic stroke model that better enables both interpretability and generalization. We evaluate DooD on its ability to generalise across both data and tasks. We first perform zero-shot transfer from one dataset (e.g. MNIST) to another (e.g. Quickdraw), across five different datasets, and show that DooD clearly outperforms different baselines. An analysis of the learnt representations further highlights the benefits of adopting a symbolic stroke model. We then adopt a subset of the Omniglot challenge tasks, and evaluate its ability to generate new exemplars (both unconditionally and conditionally), and perform one-shot classification, showing that DooD matches the state of the art. Taken together, we demonstrate that DooD does indeed capture general-purpose representations across both data and task, and takes a further step towards building general and robust concept-learning systems.

</p>
</details>

<details><summary><b>Deep Radiomic Analysis for Predicting Coronavirus Disease 2019 in Computerized Tomography and X-ray Images</b>
<a href="https://arxiv.org/abs/2206.01903">arxiv:2206.01903</a>
&#x1F4C8; 6 <br>
<p>Ahmad Chaddad, Lama Hassan, Christian Desrosiers</p></summary>
<p>

**Abstract:** This paper proposes to encode the distribution of features learned from a convolutional neural network using a Gaussian Mixture Model. These parametric features, called GMM-CNN, are derived from chest computed tomography and X-ray scans of patients with Coronavirus Disease 2019. We use the proposed GMM-CNN features as input to a robust classifier based on random forests to differentiate between COVID-19 and other pneumonia cases. Our experiments assess the advantage of GMM-CNN features compared to standard CNN classification on test images. Using a random forest classifier (80\% samples for training; 20\% samples for testing), GMM-CNN features encoded with two mixture components provided a significantly better performance than standard CNN classification (p\,$<$\,0.05). Specifically, our method achieved an accuracy in the range of 96.00\,--\,96.70\% and an area under the ROC curve in the range of 99.29\,--\,99.45\%, with the best performance obtained by combining GMM-CNN features from both computed tomography and X-ray images. Our results suggest that the proposed GMM-CNN features could improve the prediction of COVID-19 in chest computed tomography and X-ray scans.

</p>
</details>

<details><summary><b>QAGCN: A Graph Convolutional Network-based Multi-Relation Question Answering System</b>
<a href="https://arxiv.org/abs/2206.01818">arxiv:2206.01818</a>
&#x1F4C8; 6 <br>
<p>Ruijie Wang, Luca Rossetto, Michael Cochez, Abraham Bernstein</p></summary>
<p>

**Abstract:** Answering multi-relation questions over knowledge graphs is a challenging task as it requires multi-step reasoning over a huge number of possible paths. Reasoning-based methods with complex reasoning mechanisms, such as reinforcement learning-based sequential decision making, have been regarded as the default pathway for this task. However, these mechanisms are difficult to implement and train, which hampers their reproducibility and transferability to new domains. In this paper, we propose QAGCN - a simple but effective and novel model that leverages attentional graph convolutional networks that can perform multi-step reasoning during the encoding of knowledge graphs. As a consequence, complex reasoning mechanisms are avoided. In addition, to improve efficiency, we retrieve answers using highly-efficient embedding computations and, for better interpretability, we extract interpretable paths for returned answers. On widely adopted benchmark datasets, the proposed model has been demonstrated competitive against state-of-the-art methods that rely on complex reasoning mechanisms. We also conducted extensive experiments to scrutinize the efficiency and contribution of each component of our model.

</p>
</details>

<details><summary><b>PROMISSING: Pruning Missing Values in Neural Networks</b>
<a href="https://arxiv.org/abs/2206.01640">arxiv:2206.01640</a>
&#x1F4C8; 6 <br>
<p>Seyed Mostafa Kia, Nastaran Mohammadian Rad, Daniel van Opstal, Bart van Schie, Andre F. Marquand, Josien Pluim, Wiepke Cahn, Hugo G. Schnack</p></summary>
<p>

**Abstract:** While data are the primary fuel for machine learning models, they often suffer from missing values, especially when collected in real-world scenarios. However, many off-the-shelf machine learning models, including artificial neural network models, are unable to handle these missing values directly. Therefore, extra data preprocessing and curation steps, such as data imputation, are inevitable before learning and prediction processes. In this study, we propose a simple and intuitive yet effective method for pruning missing values (PROMISSING) during learning and inference steps in neural networks. In this method, there is no need to remove or impute the missing values; instead, the missing values are treated as a new source of information (representing what we do not know). Our experiments on simulated data, several classification and regression benchmarks, and a multi-modal clinical dataset show that PROMISSING results in similar prediction performance compared to various imputation techniques. In addition, our experiments show models trained using PROMISSING techniques are becoming less decisive in their predictions when facing incomplete samples with many unknowns. This finding hopefully advances machine learning models from being pure predicting machines to more realistic thinkers that can also say "I do not know" when facing incomplete sources of information.

</p>
</details>

<details><summary><b>Beyond Opinion Mining: Summarizing Opinions of Customer Reviews</b>
<a href="https://arxiv.org/abs/2206.01543">arxiv:2206.01543</a>
&#x1F4C8; 6 <br>
<p>Reinald Kim Amplayo, Arthur Bražinskas, Yoshi Suhara, Xiaolan Wang, Bing Liu</p></summary>
<p>

**Abstract:** Customer reviews are vital for making purchasing decisions in the Information Age. Such reviews can be automatically summarized to provide the user with an overview of opinions. In this tutorial, we present various aspects of opinion summarization that are useful for researchers and practitioners. First, we will introduce the task and major challenges. Then, we will present existing opinion summarization solutions, both pre-neural and neural. We will discuss how summarizers can be trained in the unsupervised, few-shot, and supervised regimes. Each regime has roots in different machine learning methods, such as auto-encoding, controllable text generation, and variational inference. Finally, we will discuss resources and evaluation methods and conclude with the future directions. This three-hour tutorial will provide a comprehensive overview over major advances in opinion summarization. The listeners will be well-equipped with the knowledge that is both useful for research and practical applications.

</p>
</details>

<details><summary><b>Modeling of Textures to Predict Immune Cell Status and Survival of Brain Tumour Patients</b>
<a href="https://arxiv.org/abs/2206.01897">arxiv:2206.01897</a>
&#x1F4C8; 5 <br>
<p>Ahmad Chaddad, Mingli Zhang, Lama Hassan, Tamim Niazi</p></summary>
<p>

**Abstract:** Radiomics has shown a capability for different types of cancers such as glioma to predict the clinical outcome. It can have a non-invasive means of evaluating the immunotherapy response prior to treatment. However, the use of deep convolutional neural networks (CNNs)-based radiomics requires large training image sets. To avoid this problem, we investigate a new imaging features that model distribution with a Gaussian mixture model (GMM) of learned 3D CNN features. Using these deep radiomic features (DRFs), we aim to predict the immune marker status (low versus high) and overall survival for glioma patients. We extract the DRFs by aggregating the activation maps of a pre-trained 3D-CNN within labeled tumor regions of MRI scans that corresponded immune markers of 151 patients. Our experiments are performed to assess the relationship between the proposed DRFs, three immune cell markers (Macrophage M1, Neutrophils and T Cells Follicular Helper), and measure their association with overall survival. Using the random forest (RF) model, DRFs was able to predict the immune marker status with area under the ROC curve (AUC) of 78.67, 83.93 and 75.67\% for Macrophage M1, Neutrophils and T Cells Follicular Helper, respectively. Combined the immune markers with DRFs and clinical variables, Kaplan-Meier estimator and Log-rank test achieved the most significant difference between predicted groups of patients (short-term versus long-term survival) with p\,=\,4.31$\times$10$^{-7}$ compared to p\,=\,0.03 for Immune cell markers, p\,=\,0.07 for clinical variables , and p\,=\,1.45$\times$10$^{-5}$ for DRFs. Our findings indicate that the proposed features (DRFs) used in RF models may significantly consider prognosticating patients with brain tumour prior to surgery through regularly acquired imaging data.

</p>
</details>

<details><summary><b>Debiased Machine Learning without Sample-Splitting for Stable Estimators</b>
<a href="https://arxiv.org/abs/2206.01825">arxiv:2206.01825</a>
&#x1F4C8; 5 <br>
<p>Qizhao Chen, Vasilis Syrgkanis, Morgane Austern</p></summary>
<p>

**Abstract:** Estimation and inference on causal parameters is typically reduced to a generalized method of moments problem, which involves auxiliary functions that correspond to solutions to a regression or classification problem. Recent line of work on debiased machine learning shows how one can use generic machine learning estimators for these auxiliary problems, while maintaining asymptotic normality and root-$n$ consistency of the target parameter of interest, while only requiring mean-squared-error guarantees from the auxiliary estimation algorithms. The literature typically requires that these auxiliary problems are fitted on a separate sample or in a cross-fitting manner. We show that when these auxiliary estimation algorithms satisfy natural leave-one-out stability properties, then sample splitting is not required. This allows for sample re-use, which can be beneficial in moderately sized sample regimes. For instance, we show that the stability properties that we propose are satisfied for ensemble bagged estimators, built via sub-sampling without replacement, a popular technique in machine learning practice.

</p>
</details>

<details><summary><b>Uncertainty Estimation in Machine Learning</b>
<a href="https://arxiv.org/abs/2206.01749">arxiv:2206.01749</a>
&#x1F4C8; 5 <br>
<p>Valentin Arkov</p></summary>
<p>

**Abstract:** Most machine learning techniques are based upon statistical learning theory, often simplified for the sake of computing speed. This paper is focused on the uncertainty aspect of mathematical modeling in machine learning. Regression analysis is chosen to further investigate the evaluation aspect of uncertainty in model coefficients and, more importantly, in the output feature value predictions. A survey demonstrates major stages in the conventional least squares approach to the creation of the regression model, along with its uncertainty estimation. On the other hand, it is shown that in machine learning the model complexity and severe nonlinearity become serious obstacles to uncertainty evaluation. Furthermore, the process of machine model training demands high computing power, not available at the level of personal computers. This is why so-called pre-trained models are widely used in such areas of machine learning as natural language processing. The latest example of a pre-trained model is the Generative Pre-trained Transformer 3 with hundreds of billions of parameters and a half-terabyte training dataset. Similarly, mathematical models built from real data are growing in complexity which is accompanied by the growing amount of training data. However, when machine models and their predictions are used in decision-making, one needs to estimate uncertainty and evaluate accompanying risks. This problem could be resolved with non-parametric techniques at the expense of greater demand for computing power, which can be offered by modern supercomputers available, including those utilizing graphical and tensor processing units along with the conventional central processors.

</p>
</details>

<details><summary><b>Automatic Quantification of Volumes and Biventricular Function in Cardiac Resonance. Validation of a New Artificial Intelligence Approach</b>
<a href="https://arxiv.org/abs/2206.01746">arxiv:2206.01746</a>
&#x1F4C8; 5 <br>
<p>Ariel H. Curiale, MatÍas E. Calandrelli, Lucca Dellazoppa, Mariano Trevisan, Jorge Luis BociÁn, Juan Pablo Bonifacio, GermÁn Mato</p></summary>
<p>

**Abstract:** Background: Artificial intelligence techniques have shown great potential in cardiology, especially in quantifying cardiac biventricular function, volume, mass, and ejection fraction (EF). However, its use in clinical practice is not straightforward due to its poor reproducibility with cases from daily practice, among other reasons. Objectives: To validate a new artificial intelligence tool in order to quantify the cardiac biventricular function (volume, mass, and EF). To analyze its robustness in the clinical area, and the computational times compared with conventional methods. Methods: A total of 189 patients were analyzed: 89 from a regional center and 100 from a public center. The method proposes two convolutional networks that include anatomical information of the heart to reduce classification errors. Results: A high concordance (Pearson coefficient) was observed between manual quantification and the proposed quantification of cardiac function (0.98, 0.92, 0.96 and 0.8 for volumes and biventricular EF) in about 5 seconds per study. Conclusions: This method quantifies biventricular function and volumes in seconds with an accuracy equivalent to that of a specialist.

</p>
</details>

<details><summary><b>ArgRewrite V.2: an Annotated Argumentative Revisions Corpus</b>
<a href="https://arxiv.org/abs/2206.01677">arxiv:2206.01677</a>
&#x1F4C8; 5 <br>
<p>Omid Kashefi, Tazin Afrin, Meghan Dale, Christopher Olshefski, Amanda Godley, Diane Litman, Rebecca Hwa</p></summary>
<p>

**Abstract:** Analyzing how humans revise their writings is an interesting research question, not only from an educational perspective but also in terms of artificial intelligence. Better understanding of this process could facilitate many NLP applications, from intelligent tutoring systems to supportive and collaborative writing environments. Developing these applications, however, requires revision corpora, which are not widely available. In this work, we present ArgRewrite V.2, a corpus of annotated argumentative revisions, collected from two cycles of revisions to argumentative essays about self-driving cars. Annotations are provided at different levels of purpose granularity (coarse and fine) and scope (sentential and subsentential). In addition, the corpus includes the revision goal given to each writer, essay scores, annotation verification, pre- and post-study surveys collected from participants as meta-data. The variety of revision unit scope and purpose granularity levels in ArgRewrite, along with the inclusion of new types of meta-data, can make it a useful resource for research and applications that involve revision analysis. We demonstrate some potential applications of ArgRewrite V.2 in the development of automatic revision purpose predictors, as a training source and benchmark.

</p>
</details>

<details><summary><b>Understanding deep learning via decision boundary</b>
<a href="https://arxiv.org/abs/2206.01515">arxiv:2206.01515</a>
&#x1F4C8; 5 <br>
<p>Shiye Lei, Fengxiang He, Yancheng Yuan, Dacheng Tao</p></summary>
<p>

**Abstract:** This paper discovers that the neural network with lower decision boundary (DB) variability has better generalizability. Two new notions, algorithm DB variability and $(ε, η)$-data DB variability, are proposed to measure the decision boundary variability from the algorithm and data perspectives. Extensive experiments show significant negative correlations between the decision boundary variability and the generalizability. From the theoretical view, two lower bounds based on algorithm DB variability are proposed and do not explicitly depend on the sample size. We also prove an upper bound of order $\mathcal{O}\left(\frac{1}{\sqrt{m}}+ε+η\log\frac{1}η\right)$ based on data DB variability. The bound is convenient to estimate without the requirement of labels, and does not explicitly depend on the network size which is usually prohibitively large in deep learning.

</p>
</details>

<details><summary><b>Fair Classification via Transformer Neural Networks: Case Study of an Educational Domain</b>
<a href="https://arxiv.org/abs/2206.01410">arxiv:2206.01410</a>
&#x1F4C8; 5 <br>
<p>Modar Sulaiman, Kallol Roy</p></summary>
<p>

**Abstract:** Educational technologies nowadays increasingly use data and Machine Learning (ML) models. This gives the students, instructors, and administrators support and insights for the optimum policy. However, it is well acknowledged that ML models are subject to bias, which raises concern about the fairness, bias, and discrimination of using these automated ML algorithms in education and its unintended and unforeseen negative consequences. The contribution of bias during the decision-making comes from datasets used for training ML models and the model architecture. This paper presents a preliminary investigation of fairness constraint in transformer neural networks on Law School and Student-Mathematics datasets. The used transformer models transform these raw datasets into a richer representation space of natural language processing (NLP) while solving fairness classification. We have employed fairness metrics for evaluation and check the trade-off between fairness and accuracy. We have reported the various metrics of F1, SPD, EOD, and accuracy for different architectures from the transformer model class.

</p>
</details>

<details><summary><b>Learning "best" kernels from data in Gaussian process regression. With application to aerodynamics</b>
<a href="https://arxiv.org/abs/2206.02563">arxiv:2206.02563</a>
&#x1F4C8; 4 <br>
<p>Jean-Luc Akian, Luc Bonnet, Houman Owhadi, Éric Savin</p></summary>
<p>

**Abstract:** This paper introduces algorithms to select/design kernels in Gaussian process regression/kriging surrogate modeling techniques. We adopt the setting of kernel method solutions in ad hoc functional spaces, namely Reproducing Kernel Hilbert Spaces (RKHS), to solve the problem of approximating a regular target function given observations of it, i.e. supervised learning. A first class of algorithms is kernel flow, which was introduced in a context of classification in machine learning. It can be seen as a nested cross-validation procedure whereby a "best" kernel is selected such that the loss of accuracy incurred by removing some part of the dataset (typically half of it) is minimized. A second class of algorithms is called spectral kernel ridge regression, and aims at selecting a "best" kernel such that the norm of the function to be approximated is minimal in the associated RKHS. Within Mercer's theorem framework, we obtain an explicit construction of that "best" kernel in terms of the main features of the target function. Both approaches of learning kernels from data are illustrated by numerical examples on synthetic test functions, and on a classical test case in turbulence modeling validation for transonic flows about a two-dimensional airfoil.

</p>
</details>

<details><summary><b>Initial Study into Application of Feature Density and Linguistically-backed Embedding to Improve Machine Learning-based Cyberbullying Detection</b>
<a href="https://arxiv.org/abs/2206.01889">arxiv:2206.01889</a>
&#x1F4C8; 4 <br>
<p>Juuso Eronen, Michal Ptaszynski, Fumito Masui, Gniewosz Leliwa, Michal Wroczynski, Mateusz Piech, Aleksander Smywinski-Pohl</p></summary>
<p>

**Abstract:** In this research, we study the change in the performance of machine learning (ML) classifiers when various linguistic preprocessing methods of a dataset were used, with the specific focus on linguistically-backed embeddings in Convolutional Neural Networks (CNN). Moreover, we study the concept of Feature Density and confirm its potential to comparatively predict the performance of ML classifiers, including CNN. The research was conducted on a Formspring dataset provided in a Kaggle competition on automatic cyberbullying detection. The dataset was re-annotated by objective experts (psychologists), as the importance of professional annotation in cyberbullying research has been indicated multiple times. The study confirmed the effectiveness of Neural Networks in cyberbullying detection and the correlation between classifier performance and Feature Density while also proposing a new approach of training various linguistically-backed embeddings for Convolutional Neural Networks.

</p>
</details>

<details><summary><b>Challenges to Solving Combinatorially Hard Long-Horizon Deep RL Tasks</b>
<a href="https://arxiv.org/abs/2206.01812">arxiv:2206.01812</a>
&#x1F4C8; 4 <br>
<p>Andrew C. Li, Pashootan Vaezipoor, Rodrigo Toro Icarte, Sheila A. McIlraith</p></summary>
<p>

**Abstract:** Deep reinforcement learning has shown promise in discrete domains requiring complex reasoning, including games such as Chess, Go, and Hanabi. However, this type of reasoning is less often observed in long-horizon, continuous domains with high-dimensional observations, where instead RL research has predominantly focused on problems with simple high-level structure (e.g. opening a drawer or moving a robot as fast as possible). Inspired by combinatorially hard optimization problems, we propose a set of robotics tasks which admit many distinct solutions at the high-level, but require reasoning about states and rewards thousands of steps into the future for the best performance. Critically, while RL has traditionally suffered on complex, long-horizon tasks due to sparse rewards, our tasks are carefully designed to be solvable without specialized exploration. Nevertheless, our investigation finds that standard RL methods often neglect long-term effects due to discounting, while general-purpose hierarchical RL approaches struggle unless additional abstract domain knowledge can be exploited.

</p>
</details>

<details><summary><b>Robust Topological Inference in the Presence of Outliers</b>
<a href="https://arxiv.org/abs/2206.01795">arxiv:2206.01795</a>
&#x1F4C8; 4 <br>
<p>Siddharth Vishwanath, Bharath K. Sriperumbudur, Kenji Fukumizu, Satoshi Kuriki</p></summary>
<p>

**Abstract:** The distance function to a compact set plays a crucial role in the paradigm of topological data analysis. In particular, the sublevel sets of the distance function are used in the computation of persistent homology -- a backbone of the topological data analysis pipeline. Despite its stability to perturbations in the Hausdorff distance, persistent homology is highly sensitive to outliers. In this work, we develop a framework of statistical inference for persistent homology in the presence of outliers. Drawing inspiration from recent developments in robust statistics, we propose a $\textit{median-of-means}$ variant of the distance function ($\textsf{MoM Dist}$), and establish its statistical properties. In particular, we show that, even in the presence of outliers, the sublevel filtrations and weighted filtrations induced by $\textsf{MoM Dist}$ are both consistent estimators of the true underlying population counterpart, and their rates of convergence in the bottleneck metric are controlled by the fraction of outliers in the data. Finally, we demonstrate the advantages of the proposed methodology through simulations and applications.

</p>
</details>

<details><summary><b>Orthogonal Transform based Generative Adversarial Network for Image Dehazing</b>
<a href="https://arxiv.org/abs/2206.01743">arxiv:2206.01743</a>
&#x1F4C8; 4 <br>
<p>Ahlad Kumar, Mantra Sanathra, Manish Khare, Vijeta Khare</p></summary>
<p>

**Abstract:** Image dehazing has become one of the crucial preprocessing steps for any computer vision task. Most of the dehazing methods try to estimate the transmission map along with the atmospheric light to get the dehazed image in the image domain. In this paper, we propose a novel end-to-end architecture that directly estimates dehazed image in Krawtchouk transform domain. For this a customized Krawtchouk Convolution Layer (KCL) in the architecture is added. KCL is constructed using Krawtchouk basis functions which converts the image from the spatial domain to the Krawtchouk transform domain. Another convolution layer is added at the end of the architecture named as Inverse Krawtchouk Convolution Layer (IKCL) which converts the image back to the spatial domain from the transform domain. It has been observed that the haze is mainly present in lower frequencies of hazy images, wherein the Krawtchouk transform helps to analyze the high and low frequencies of the images separately. We have divided our architecture into two branches, the upper branch deals with the higher frequencies while the lower branch deals with the lower frequencies of the image. The lower branch is made deeper in terms of the layers as compared to the upper branch to address the haze present in the lower frequencies. Using the proposed Orthogonal Transform based Generative Adversarial Network (OTGAN) architecture for image dehazing, we were able to achieve competitive results when compared to the present state-of-the-art methods.

</p>
</details>

<details><summary><b>A Learning-Based Method for Automatic Operator Selection in the Fanoos XAI System</b>
<a href="https://arxiv.org/abs/2206.01722">arxiv:2206.01722</a>
&#x1F4C8; 4 <br>
<p>David Bayani</p></summary>
<p>

**Abstract:** We describe an extension of the Fanoos XAI system [Bayani et al 2022] which enables the system to learn the appropriate action to take in order to satisfy a user's request for description to be made more or less abstract. Specifically, descriptions of systems under analysis are stored in states, and in order to make a description more or less abstract, Fanoos selects an operator from a large library to apply to the state and generate a new description. Prior work on Fanoos predominately used hand-written methods for operator-selection; this current work allows Fanoos to leverage experience to learn the best operator to apply in a particular situation, balancing exploration and exploitation, leveraging expert insights when available, and utilizing similarity between the current state and past states. Additionally, in order to bootstrap the learning process (i.e., like in curriculum learning), we describe a simulated user which we implemented; this simulation allows Fanoos to gain general insights that enable reasonable courses of action, insights which later can be refined by experience with real users, as opposed to interacting with humans completely from scratch. Code implementing the methods described in the paper can be found at https://github/DBay-ani/Operator_Selection_Learning_Extensions_For_Fanoos.

</p>
</details>

<details><summary><b>KCRL: Krasovskii-Constrained Reinforcement Learning with Guaranteed Stability in Nonlinear Dynamical Systems</b>
<a href="https://arxiv.org/abs/2206.01704">arxiv:2206.01704</a>
&#x1F4C8; 4 <br>
<p>Sahin Lale, Yuanyuan Shi, Guannan Qu, Kamyar Azizzadenesheli, Adam Wierman, Anima Anandkumar</p></summary>
<p>

**Abstract:** Learning a dynamical system requires stabilizing the unknown dynamics to avoid state blow-ups. However, current reinforcement learning (RL) methods lack stabilization guarantees, which limits their applicability for the control of safety-critical systems. We propose a model-based RL framework with formal stability guarantees, Krasovskii Constrained RL (KCRL), that adopts Krasovskii's family of Lyapunov functions as a stability constraint. The proposed method learns the system dynamics up to a confidence interval using feature representation, e.g. Random Fourier Features. It then solves a constrained policy optimization problem with a stability constraint based on Krasovskii's method using a primal-dual approach to recover a stabilizing policy. We show that KCRL is guaranteed to learn a stabilizing policy in a finite number of interactions with the underlying unknown system. We also derive the sample complexity upper bound for stabilization of unknown nonlinear dynamical systems via the KCRL framework.

</p>
</details>

<details><summary><b>Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank</b>
<a href="https://arxiv.org/abs/2206.01702">arxiv:2206.01702</a>
&#x1F4C8; 4 <br>
<p>Mouxiang Chen, Chenghao Liu, Zemin Liu, Jianling Sun</p></summary>
<p>

**Abstract:** Unbiased learning to rank (ULTR) aims to train an unbiased ranking model from biased user click logs. Most of the current ULTR methods are based on the examination hypothesis (EH), which assumes that the click probability can be factorized into two scalar functions, one related to ranking features and the other related to bias factors. Unfortunately, the interactions among features, bias factors and clicks are complicated in practice, and usually cannot be factorized in this independent way. Fitting click data with EH could lead to model misspecification and bring the approximation error.
  In this paper, we propose a vector-based EH and formulate the click probability as a dot product of two vector functions. This solution is complete due to its universality in fitting arbitrary click functions. Based on it, we propose a novel model named Vectorization to adaptively learn the relevance embeddings and sort documents by projecting embeddings onto a base vector. Extensive experiments show that our method significantly outperforms the state-of-the-art ULTR methods on complex real clicks as well as simple simulated clicks.

</p>
</details>

<details><summary><b>Measuring Gender Bias in Word Embeddings of Gendered Languages Requires Disentangling Grammatical Gender Signals</b>
<a href="https://arxiv.org/abs/2206.01691">arxiv:2206.01691</a>
&#x1F4C8; 4 <br>
<p>Shiva Omrani Sabbaghi, Aylin Caliskan</p></summary>
<p>

**Abstract:** Does the grammatical gender of a language interfere when measuring the semantic gender information captured by its word embeddings? A number of anomalous gender bias measurements in the embeddings of gendered languages suggest this possibility. We demonstrate that word embeddings learn the association between a noun and its grammatical gender in grammatically gendered languages, which can skew social gender bias measurements. Consequently, word embedding post-processing methods are introduced to quantify, disentangle, and evaluate grammatical gender signals. The evaluation is performed on five gendered languages from the Germanic, Romance, and Slavic branches of the Indo-European language family. Our method reduces the strength of grammatical gender signals, which is measured in terms of effect size (Cohen's d), by a significant average of d = 1.3 for French, German, and Italian, and d = 0.56 for Polish and Spanish. Once grammatical gender is disentangled, the association between over 90% of 10,000 inanimate nouns and their assigned grammatical gender weakens, and cross-lingual bias results from the Word Embedding Association Test (WEAT) become more congruent with country-level implicit bias measurements. The results further suggest that disentangling grammatical gender signals from word embeddings may lead to improvement in semantic machine learning tasks.

</p>
</details>

<details><summary><b>Pruning for Interpretable, Feature-Preserving Circuits in CNNs</b>
<a href="https://arxiv.org/abs/2206.01627">arxiv:2206.01627</a>
&#x1F4C8; 4 <br>
<p>Chris Hamblin, Talia Konkle, George Alvarez</p></summary>
<p>

**Abstract:** Deep convolutional neural networks are a powerful model class for a range of computer vision problems, but it is difficult to interpret the image filtering process they implement, given their sheer size. In this work, we introduce a method for extracting 'feature-preserving circuits' from deep CNNs, leveraging methods from saliency-based neural network pruning. These circuits are modular sub-functions, embedded within the network, containing only a subset of convolutional kernels relevant to a target feature. We compare the efficacy of 3 saliency-criteria for extracting these sparse circuits. Further, we show how 'sub-feature' circuits can be extracted, that preserve a feature's responses to particular images, dividing the feature into even sparser filtering processes. We also develop a tool for visualizing 'circuit diagrams', which render the entire image filtering process implemented by circuits in a parsable format.

</p>
</details>

<details><summary><b>Acquiring and Modelling Abstract Commonsense Knowledge via Conceptualization</b>
<a href="https://arxiv.org/abs/2206.01532">arxiv:2206.01532</a>
&#x1F4C8; 4 <br>
<p>Mutian He, Tianqing Fang, Weiqi Wang, Yangqiu Song</p></summary>
<p>

**Abstract:** Conceptualization, or viewing entities and situations as instances of abstract concepts in mind and making inferences based on that, is a vital component in human intelligence for commonsense reasoning. Although recent artificial intelligence has made progress in acquiring and modelling commonsense, attributed to large neural language models and commonsense knowledge graphs (CKGs), conceptualization is yet to thoroughly be introduced, making current approaches ineffective to cover knowledge about countless diverse entities and situations in the real world. To address the problem, we thoroughly study the possible role of conceptualization in commonsense reasoning, and formulate a framework to replicate human conceptual induction from acquiring abstract knowledge about abstract concepts. Aided by the taxonomy Probase, we develop tools for contextualized conceptualization on ATOMIC, a large-scale human annotated CKG. We annotate a dataset for the validity of conceptualizations for ATOMIC on both event and triple level, develop a series of heuristic rules based on linguistic features, and train a set of neural models, so as to generate and verify abstract knowledge. Based on these components, a pipeline to acquire abstract knowledge is built. A large abstract CKG upon ATOMIC is then induced, ready to be instantiated to infer about unseen entities or situations. Furthermore, experiments find directly augmenting data with abstract triples to be helpful in commonsense modelling.

</p>
</details>

<details><summary><b>Latent Topology Induction for Understanding Contextualized Representations</b>
<a href="https://arxiv.org/abs/2206.01512">arxiv:2206.01512</a>
&#x1F4C8; 4 <br>
<p>Yao Fu, Mirella Lapata</p></summary>
<p>

**Abstract:** In this work, we study the representation space of contextualized embeddings and gain insight into the hidden topology of large language models. We show there exists a network of latent states that summarize linguistic properties of contextualized representations. Instead of seeking alignments to existing well-defined annotations, we infer this latent network in a fully unsupervised way using a structured variational autoencoder. The induced states not only serve as anchors that mark the topology (neighbors and connectivity) of the representation manifold but also reveal the internal mechanism of encoding sentences. With the induced network, we: (1). decompose the representation space into a spectrum of latent states which encode fine-grained word meanings with lexical, morphological, syntactic and semantic information; (2). show state-state transitions encode rich phrase constructions and serve as the backbones of the latent space. Putting the two together, we show that sentences are represented as a traversal over the latent network where state-state transition chains encode syntactic templates and state-word emissions fill in the content. We demonstrate these insights with extensive experiments and visualizations.

</p>
</details>

<details><summary><b>Causality Learning With Wasserstein Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2206.01496">arxiv:2206.01496</a>
&#x1F4C8; 4 <br>
<p>Hristo Petkov, Colin Hanley, Feng Dong</p></summary>
<p>

**Abstract:** Conventional methods for causal structure learning from data face significant challenges due to combinatorial search space. Recently, the problem has been formulated into a continuous optimization framework with an acyclicity constraint to learn Directed Acyclic Graphs (DAGs). Such a framework allows the utilization of deep generative models for causal structure learning to better capture the relations between data sample distributions and DAGs. However, so far no study has experimented with the use of Wasserstein distance in the context of causal structure learning. Our model named DAG-WGAN combines the Wasserstein-based adversarial loss with an acyclicity constraint in an auto-encoder architecture. It simultaneously learns causal structures while improving its data generation capability. We compare the performance of DAG-WGAN with other models that do not involve the Wasserstein metric in order to identify its contribution to causal structure learning. Our model performs better with high cardinality data according to our experiments.

</p>
</details>

<details><summary><b>Transferring Studies Across Embodiments: A Case Study in Confusion Detection</b>
<a href="https://arxiv.org/abs/2206.01493">arxiv:2206.01493</a>
&#x1F4C8; 4 <br>
<p>Na Li, Robert Ross</p></summary>
<p>

**Abstract:** Human-robot studies are expensive to conduct and difficult to control, and as such researchers sometimes turn to human-avatar interaction in the hope of faster and cheaper data collection that can be transferred to the robot domain. In terms of our work, we are particularly interested in the challenge of detecting and modelling user confusion in interaction, and as part of this research programme, we conducted situated dialogue studies to investigate users' reactions in confusing scenarios that we give in both physical and virtual environments. In this paper, we present a combined review of these studies and the results that we observed across these two embodiments. For the physical embodiment, we used a Pepper Robot, while for the virtual modality, we used a 3D avatar. Our study shows that despite attitudinal differences and technical control limitations, there were a number of similarities detected in user behaviour and self-reporting results across embodiment options. This work suggests that, while avatar interaction is no true substitute for robot interaction studies, sufficient care in study design may allow well executed human-avatar studies to supplement more challenging human-robot studies.

</p>
</details>

<details><summary><b>Dynamic Structured Illumination Microscopy with a Neural Space-time Model</b>
<a href="https://arxiv.org/abs/2206.01397">arxiv:2206.01397</a>
&#x1F4C8; 4 <br>
<p>Ruiming Cao, Fanglin Linda Liu, Li-Hao Yeh, Laura Waller</p></summary>
<p>

**Abstract:** Structured illumination microscopy (SIM) reconstructs a super-resolved image from multiple raw images; hence, acquisition speed is limited, making it unsuitable for dynamic scenes. We propose a new method, Speckle Flow SIM, that models sample motion during the data capture in order to reconstruct dynamic scenes with super-resolution. Speckle Flow SIM uses fixed speckle illumination and relies on sample motion to capture a sequence of raw images. Then, the spatio-temporal relationship of the dynamic scene is modeled using a neural space-time model with coordinate-based multi-layer perceptrons (MLPs), and the motion dynamics and the super-resolved scene are jointly recovered. We validated Speckle Flow SIM in simulation and built a simple, inexpensive experimental setup with off-the-shelf components. We demonstrated that Speckle Flow SIM can reconstruct a dynamic scene with deformable motion and 1.88x the diffraction-limited resolution in experiment.

</p>
</details>

<details><summary><b>Soft Adversarial Training Can Retain Natural Accuracy</b>
<a href="https://arxiv.org/abs/2206.01904">arxiv:2206.01904</a>
&#x1F4C8; 3 <br>
<p>Abhijith Sharma, Apurva Narayan</p></summary>
<p>

**Abstract:** Adversarial training for neural networks has been in the limelight in recent years. The advancement in neural network architectures over the last decade has led to significant improvement in their performance. It sparked an interest in their deployment for real-time applications. This process initiated the need to understand the vulnerability of these models to adversarial attacks. It is instrumental in designing models that are robust against adversaries. Recent works have proposed novel techniques to counter the adversaries, most often sacrificing natural accuracy. Most suggest training with an adversarial version of the inputs, constantly moving away from the original distribution. The focus of our work is to use abstract certification to extract a subset of inputs for (hence we call it 'soft') adversarial training. We propose a training framework that can retain natural accuracy without sacrificing robustness in a constrained setting. Our framework specifically targets moderately critical applications which require a reasonable balance between robustness and accuracy. The results testify to the idea of soft adversarial training for the defense against adversarial attacks. At last, we propose the scope of future work for further improvement of this framework.

</p>
</details>

<details><summary><b>Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios</b>
<a href="https://arxiv.org/abs/2206.01900">arxiv:2206.01900</a>
&#x1F4C8; 3 <br>
<p>Keisuke Fujii, Koh Takeuchi, Atsushi Kuribayashi, Naoya Takeishi, Yoshinobu Kawahara, Kazuya Takeda</p></summary>
<p>

**Abstract:** Evaluation of intervention in a multi-agent system, e.g., when humans should intervene in autonomous driving systems and when a player should pass to teammates for a good shot, is challenging in various engineering and scientific fields. Estimating the individual treatment effect (ITE) using counterfactual long-term prediction is practical to evaluate such interventions. However, most of the conventional frameworks did not consider the time-varying complex structure of multi-agent relationships and covariate counterfactual prediction. This may sometimes lead to erroneous assessments of ITE and interpretation problems. Here we propose an interpretable, counterfactual recurrent network in multi-agent systems to estimate the effect of the intervention. Our model leverages graph variational recurrent neural networks and theory-based computation with domain knowledge for the ITE estimation framework based on long-term prediction of multi-agent covariates and outcomes, which can confirm under the circumstances under which the intervention is effective. On simulated models of an automated vehicle and biological agents with time-varying confounders, we show that our methods achieved lower estimation errors in counterfactual covariates and the most effective treatment timing than the baselines. Furthermore, using real basketball data, our methods performed realistic counterfactual predictions and evaluated the counterfactual passes in shot scenarios.

</p>
</details>

<details><summary><b>Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2206.01888">arxiv:2206.01888</a>
&#x1F4C8; 3 <br>
<p>Young Wu, Jermey McMahan, Xiaojin Zhu, Qiaomin Xie</p></summary>
<p>

**Abstract:** We expose the danger of reward poisoning in offline multi-agent reinforcement learning (MARL), whereby an attacker can modify the reward vectors to different learners in an offline data set while incurring a poisoning cost. Based on the poisoned data set, all rational learners using some confidence-bound-based MARL algorithm will infer that a target policy - chosen by the attacker and not necessarily a solution concept originally - is the Markov perfect dominant strategy equilibrium for the underlying Markov Game, hence they will adopt this potentially damaging target policy in the future. We characterize the exact conditions under which the attacker can install a target policy. We further show how the attacker can formulate a linear program to minimize its poisoning cost. Our work shows the need for robust MARL against adversarial attacks.

</p>
</details>

<details><summary><b>Learning in Congestion Games with Bandit Feedback</b>
<a href="https://arxiv.org/abs/2206.01880">arxiv:2206.01880</a>
&#x1F4C8; 3 <br>
<p>Qiwen Cui, Zhihan Xiong, Maryam Fazel, Simon S. Du</p></summary>
<p>

**Abstract:** Learning Nash equilibria is a central problem in multi-agent systems. In this paper, we investigate congestion games, a class of games with benign theoretical structure and broad real-world applications. We first propose a centralized algorithm based on the optimism in the face of uncertainty principle for congestion games with (semi-)bandit feedback, and obtain finite-sample guarantees. Then we propose a decentralized algorithm via a novel combination of the Frank-Wolfe method and G-optimal design. By exploiting the structure of the congestion game, we show the sample complexity of both algorithms depends only polynomially on the number of players and the number of facilities, but not the size of the action set, which can be exponentially large in terms of the number of facilities. We further define a new problem class, Markov congestion games, which allows us to model the non-stationarity in congestion games. We propose a centralized algorithm for Markov congestion games, whose sample complexity again has only polynomial dependence on all relevant problem parameters, but not the size of the action set.

</p>
</details>

<details><summary><b>Model-Informed Generative Adversarial Network (MI-GAN) for Learning Optimal Power Flow</b>
<a href="https://arxiv.org/abs/2206.01864">arxiv:2206.01864</a>
&#x1F4C8; 3 <br>
<p>Yuxuan Li, Chaoyue Zhao, Chenang Liu</p></summary>
<p>

**Abstract:** The optimal power flow (OPF) problem, as a critical component of power system operations, becomes increasingly difficult to solve due to the variability, intermittency, and unpredictability of renewable energy brought to the power system. Although traditional optimization techniques, such as stochastic and robust optimization approaches, could be used to address the OPF problem in the face of renewable energy uncertainty, their effectiveness in dealing with large-scale problems remains limited. As a result, deep learning techniques, such as neural networks, have recently been developed to improve computational efficiency in solving large-scale OPF problems. However, the feasibility and optimality of the solution may not be guaranteed. In this paper, we propose an optimization model-informed generative adversarial network (MI-GAN) framework to solve OPF under uncertainty. The main contributions are summarized into three aspects: (1) to ensure feasibility and improve optimality of generated solutions, three important layers are proposed: feasibility filter layer, comparison layer, and gradient-guided layer; (2) in the GAN-based framework, an efficient model-informed selector incorporating these three new layers is established; and (3) a new recursive iteration algorithm is also proposed to improve solution optimality. The numerical results on IEEE test systems show that the proposed method is very effective and promising.

</p>
</details>

<details><summary><b>Coffee Roast Intelligence</b>
<a href="https://arxiv.org/abs/2206.01841">arxiv:2206.01841</a>
&#x1F4C8; 3 <br>
<p>Sakdipat Ontoum, Thitaree Khemanantakul, Pornphat Sroison, Tuul Triyason, Bunthit Watanapa</p></summary>
<p>

**Abstract:** As the coffee industry has grown, there would be more demand for roasted coffee beans, as well as increased rivalry for selling coffee and attracting customers. As the flavor of each variety of coffee is dependent on the degree of roasting of the coffee beans, it is vital to maintain a consistent quality related to the degree of roasting. Each barista has their own method for determining the degree of roasting. However, extrinsic circumstances such as light, fatigue, and other factors may alter their judgment. As a result, the quality of the coffee cannot be controlled. The Coffee Roast Intelligence application is a machine learning-based study of roasted coffee bean degrees classification produced as an Android application platform that identifies the color of coffee beans by photographing or uploading them while roasting. This application displays the text showing at what level the coffee beans have been roasted, as well as informs the percent chance of class prediction to the consumers. Users may also keep track of the result of the predictions related to the roasting level of coffee beans.

</p>
</details>

<details><summary><b>Detection of Fibrosis in Cine Magnetic Resonance Images Using Artificial Intelligence Techniques</b>
<a href="https://arxiv.org/abs/2206.01745">arxiv:2206.01745</a>
&#x1F4C8; 3 <br>
<p>Ariel. H. Curiale, Facundo Cabrera, Pablo Jimenez, Jorgelina Medus, GermÁn Mato, MatÍas E. Calandrelli</p></summary>
<p>

**Abstract:** Background: Artificial intelligence techniques have demonstrated great potential in cardiology, especially to detect imperceptible patterns for the human eye. In this sense, these techniques seem to be adequate to identify patterns in the myocardial texture which could lead to characterize and quantify fibrosis. Purpose: The aim of this study was to postulate a new artificial intelligence method to identify fibrosis in cine cardiac magnetic resonance (CMR) imaging. Methods: A retrospective observational study was carried out in a population of 75 subjects from a clinical center of San Carlos de Bariloche. The proposed method analyzes the myocardial texture in cine CMR images using a convolutional neural network to determine local myocardial tissue damage. Results: An accuracy of 89% for quantifying local tissue damage was observed for the validation data set and 70% for the test set. In addition, the qualitative analysis showed a high spatial correlation in lesion location. Conclusions: The postulated method enables to spatially identify fibrosis using only the information from cine nuclear magnetic resonance studies, demonstrating the potential of this technique to quantify myocardial viability in the future or to study the lesions etiology

</p>
</details>

<details><summary><b>SNAKE: Shape-aware Neural 3D Keypoint Field</b>
<a href="https://arxiv.org/abs/2206.01724">arxiv:2206.01724</a>
&#x1F4C8; 3 <br>
<p>Chengliang Zhong, Peixing You, Xiaoxue Chen, Hao Zhao, Fuchun Sun, Guyue Zhou, Xiaodong Mu, Chuang Gan, Wenbing Huang</p></summary>
<p>

**Abstract:** Detecting 3D keypoints from point clouds is important for shape reconstruction, while this work investigates the dual question: can shape reconstruction benefit 3D keypoint detection? Existing methods either seek salient features according to statistics of different orders or learn to predict keypoints that are invariant to transformation. Nevertheless, the idea of incorporating shape reconstruction into 3D keypoint detection is under-explored. We argue that this is restricted by former problem formulations. To this end, a novel unsupervised paradigm named SNAKE is proposed, which is short for shape-aware neural 3D keypoint field. Similar to recent coordinate-based radiance or distance field, our network takes 3D coordinates as inputs and predicts implicit shape indicators and keypoint saliency simultaneously, thus naturally entangling 3D keypoint detection and shape reconstruction. We achieve superior performance on various public benchmarks, including standalone object datasets ModelNet40, KeypointNet, SMPL meshes and scene-level datasets 3DMatch and Redwood. Intrinsic shape awareness brings several advantages as follows. (1) SNAKE generates 3D keypoints consistent with human semantic annotation, even without such supervision. (2) SNAKE outperforms counterparts in terms of repeatability, especially when the input point clouds are down-sampled. (3) the generated keypoints allow accurate geometric registration, notably in a zero-shot setting. Codes are available at https://github.com/zhongcl-thu/SNAKE

</p>
</details>

<details><summary><b>Decentralized Optimistic Hyperpolicy Mirror Descent: Provably No-Regret Learning in Markov Games</b>
<a href="https://arxiv.org/abs/2206.01588">arxiv:2206.01588</a>
&#x1F4C8; 3 <br>
<p>Wenhao Zhan, Jason D. Lee, Zhuoran Yang</p></summary>
<p>

**Abstract:** We study decentralized policy learning in Markov games where we control a single agent to play with nonstationary and possibly adversarial opponents. Our goal is to develop a no-regret online learning algorithm that (i) takes actions based on the local information observed by the agent and (ii) is able to find the best policy in hindsight. For such a problem, the nonstationary state transitions due to the varying opponent pose a significant challenge. In light of a recent hardness result \citep{liu2022learning}, we focus on the setting where the opponent's previous policies are revealed to the agent for decision making. With such an information structure, we propose a new algorithm, \underline{D}ecentralized \underline{O}ptimistic hype\underline{R}policy m\underline{I}rror de\underline{S}cent (DORIS), which achieves $\sqrt{K}$-regret in the context of general function approximation, where $K$ is the number of episodes. Moreover, when all the agents adopt DORIS, we prove that their mixture policy constitutes an approximate coarse correlated equilibrium. In particular, DORIS maintains a \textit{hyperpolicy} which is a distribution over the policy space. The hyperpolicy is updated via mirror descent, where the update direction is obtained by an optimistic variant of least-squares policy evaluation. Furthermore, to illustrate the power of our method, we apply DORIS to constrained and vector-valued MDPs, which can be formulated as zero-sum Markov games with a fictitious opponent.

</p>
</details>

<details><summary><b>Extracting Similar Questions From Naturally-occurring Business Conversations</b>
<a href="https://arxiv.org/abs/2206.01585">arxiv:2206.01585</a>
&#x1F4C8; 3 <br>
<p>Xiliang Zhu, David Rossouw, Shayna Gardiner, Simon Corston-Oliver</p></summary>
<p>

**Abstract:** Pre-trained contextualized embedding models such as BERT are a standard building block in many natural language processing systems. We demonstrate that the sentence-level representations produced by some off-the-shelf contextualized embedding models have a narrow distribution in the embedding space, and thus perform poorly for the task of identifying semantically similar questions in real-world English business conversations. We describe a method that uses appropriately tuned representations and a small set of exemplars to group questions of interest to business users in a visualization that can be used for data exploration or employee coaching.

</p>
</details>

<details><summary><b>Optimal Weak to Strong Learning</b>
<a href="https://arxiv.org/abs/2206.01563">arxiv:2206.01563</a>
&#x1F4C8; 3 <br>
<p>Kasper Green Larsen, Martin Ritzert</p></summary>
<p>

**Abstract:** The classic algorithm AdaBoost allows to convert a weak learner, that is an algorithm that produces a hypothesis which is slightly better than chance, into a strong learner, achieving arbitrarily high accuracy when given enough training data. We present a new algorithm that constructs a strong learner from a weak learner but uses less training data than AdaBoost and all other weak to strong learners to achieve the same generalization bounds. A sample complexity lower bound shows that our new algorithm uses the minimum possible amount of training data and is thus optimal. Hence, this work settles the sample complexity of the classic problem of constructing a strong learner from a weak learner.

</p>
</details>

<details><summary><b>Truly Mesh-free Physics-Informed Neural Networks</b>
<a href="https://arxiv.org/abs/2206.01545">arxiv:2206.01545</a>
&#x1F4C8; 3 <br>
<p>Fabricio Arend Torres, Marcello Massimo Negri, Monika Nagy-Huber, Maxim Samarin, Volker Roth</p></summary>
<p>

**Abstract:** Physics-informed Neural Networks (PINNs) have recently emerged as a principled way to include prior physical knowledge in form of partial differential equations (PDEs) into neural networks. Although generally viewed as being mesh-free, current approaches still rely on collocation points obtained within a bounded region, even in settings with spatially sparse signals. Furthermore, if the boundaries are not known, the selection of such a region may be arbitrary, resulting in a large proportion of collocation points being selected in areas of low relevance. To resolve this, we present a mesh-free and adaptive approach termed particle-density PINN (pdPINN), which is inspired by the microscopic viewpoint of fluid dynamics. Instead of sampling from a bounded region, we propose to sample directly from the distribution over the (fluids) particle positions, eliminating the need to introduce boundaries while adaptively focusing on the most relevant regions. This is achieved by reformulating the modeled fluid density as an unnormalized probability distribution from which we sample with dynamic Monte Carlo methods. We further generalize pdPINNs to different settings that allow interpreting a positive scalar quantity as a particle density, such as the evolution of the temperature in the heat equation. The utility of our approach is demonstrated on experiments for modeling (non-steady) compressible fluids in up to three dimensions and a two-dimensional diffusion problem, illustrating the high flexibility and sample efficiency compared to existing refinement methods for PINNs.

</p>
</details>

<details><summary><b>Indirect Active Learning</b>
<a href="https://arxiv.org/abs/2206.01454">arxiv:2206.01454</a>
&#x1F4C8; 3 <br>
<p>Shashank Singh</p></summary>
<p>

**Abstract:** Traditional models of active learning assume a learner can directly manipulate or query a covariate $X$ in order to study its relationship with a response $Y$. However, if $X$ is a feature of a complex system, it may be possible only to indirectly influence $X$ by manipulating a control variable $Z$, a scenario we refer to as Indirect Active Learning. Under a nonparametric model of Indirect Active Learning with a fixed budget, we study minimax convergence rates for estimating the relationship between $X$ and $Y$ locally at a point, obtaining different rates depending on the complexities and noise levels of the relationships between $Z$ and $X$ and between $X$ and $Y$. We also identify minimax rates for passive learning under comparable assumptions. In many cases, our results show that, while there is an asymptotic benefit to active learning, this benefit is fully realized by a simple two-stage learner that runs two passive experiments in sequence.

</p>
</details>

<details><summary><b>Rate-Optimal Online Convex Optimization in Adaptive Linear Control</b>
<a href="https://arxiv.org/abs/2206.01426">arxiv:2206.01426</a>
&#x1F4C8; 3 <br>
<p>Asaf Cassel, Alon Cohen, Tomer Koren</p></summary>
<p>

**Abstract:** We consider the problem of controlling an unknown linear dynamical system under adversarially changing convex costs and full feedback of both the state and cost function. We present the first computationally-efficient algorithm that attains an optimal $\smash{\sqrt{T}}$-regret rate compared to the best stabilizing linear controller in hindsight, while avoiding stringent assumptions on the costs such as strong convexity. Our approach is based on a careful design of non-convex lower confidence bounds for the online costs, and uses a novel technique for computationally-efficient regret minimization of these bounds that leverages their particular non-convex structure.

</p>
</details>

<details><summary><b>Generalization for multiclass classification with overparameterized linear models</b>
<a href="https://arxiv.org/abs/2206.01399">arxiv:2206.01399</a>
&#x1F4C8; 3 <br>
<p>Vignesh Subramanian, Rahul Arya, Anant Sahai</p></summary>
<p>

**Abstract:** Via an overparameterized linear model with Gaussian features, we provide conditions for good generalization for multiclass classification of minimum-norm interpolating solutions in an asymptotic setting where both the number of underlying features and the number of classes scale with the number of training points. The survival/contamination analysis framework for understanding the behavior of overparameterized learning problems is adapted to this setting, revealing that multiclass classification qualitatively behaves like binary classification in that, as long as there are not too many classes (made precise in the paper), it is possible to generalize well even in some settings where the corresponding regression tasks would not generalize. Besides various technical challenges, it turns out that the key difference from the binary classification setting is that there are relatively fewer positive training examples of each class in the multiclass setting as the number of classes increases, making the multiclass problem "harder" than the binary one.

</p>
</details>

<details><summary><b>Effects of Auxiliary Knowledge on Continual Learning</b>
<a href="https://arxiv.org/abs/2206.02577">arxiv:2206.02577</a>
&#x1F4C8; 2 <br>
<p>Giovanni Bellitto, Matteo Pennisi, Simone Palazzo, Lorenzo Bonicelli, Matteo Boschini, Simone Calderara, Concetto Spampinato</p></summary>
<p>

**Abstract:** In Continual Learning (CL), a neural network is trained on a stream of data whose distribution changes over time. In this context, the main problem is how to learn new information without forgetting old knowledge (i.e., Catastrophic Forgetting). Most existing CL approaches focus on finding solutions to preserve acquired knowledge, so working on the past of the model. However, we argue that as the model has to continually learn new tasks, it is also important to put focus on the present knowledge that could improve following tasks learning. In this paper we propose a new, simple, CL algorithm that focuses on solving the current task in a way that might facilitate the learning of the next ones. More specifically, our approach combines the main data stream with a secondary, diverse and uncorrelated stream, from which the network can draw auxiliary knowledge. This helps the model from different perspectives, since auxiliary data may contain useful features for the current and the next tasks and incoming task classes can be mapped onto auxiliary classes. Furthermore, the addition of data to the current task is implicitly making the classifier more robust as we are forcing the extraction of more discriminative features. Our method can outperform existing state-of-the-art models on the most common CL Image Classification benchmarks.

</p>
</details>

<details><summary><b>Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2021</b>
<a href="https://arxiv.org/abs/2206.02573">arxiv:2206.02573</a>
&#x1F4C8; 2 <br>
<p>Yi Cheng, Fen Fang, Ying Sun</p></summary>
<p>

**Abstract:** In this report, we present the technical details of our approach to the EPIC-KITCHENS-100 Unsupervised Domain Adaptation (UDA) Challenge for Action Recognition. The EPIC-KITCHENS-100 dataset consists of daily kitchen activities focusing on the interaction between human hands and their surrounding objects. It is very challenging to accurately recognize these fine-grained activities, due to the presence of distracting objects and visually similar action classes, especially in the unlabelled target domain. Based on an existing method for video domain adaptation, i.e., TA3N, we propose to learn hand-centric features by leveraging the hand bounding box information for UDA on fine-grained action recognition. This helps reduce the distraction from background as well as facilitate the learning of domain-invariant features. To achieve high quality hand localization, we adopt an uncertainty-aware domain adaptation network, i.e., MEAA, to train a domain-adaptive hand detector, which only uses very limited hand bounding box annotations in the source domain but can generalize well to the unlabelled target domain. Our submission achieved the 1st place in terms of top-1 action recognition accuracy, using only RGB and optical flow modalities as input.

</p>
</details>

<details><summary><b>The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural Network for Online Gesture Recognition</b>
<a href="https://arxiv.org/abs/2206.01910">arxiv:2206.01910</a>
&#x1F4C8; 2 <br>
<p>Zihao Zhao, Yanhong Wang, Qiaosha Zou, Tie Xu, Fangbo Tao, Jiansong Zhang, Xiaoan Wang, C. -J. Richard Shi, Junwen Luo, Yuan Xie</p></summary>
<p>

**Abstract:** Action recognition is an exciting research avenue for artificial intelligence since it may be a game changer in the emerging industrial fields such as robotic visions and automobiles. However, current deep learning faces major challenges for such applications because of the huge computational cost and the inefficient learning. Hence, we develop a novel brain-inspired Spiking Neural Network (SNN) based system titled Spiking Gating Flow (SGF) for online action learning. The developed system consists of multiple SGF units which assembled in a hierarchical manner. A single SGF unit involves three layers: a feature extraction layer, an event-driven layer and a histogram-based training layer. To demonstrate the developed system capabilities, we employ a standard Dynamic Vision Sensor (DVS) gesture classification as a benchmark. The results indicate that we can achieve 87.5% accuracy which is comparable with Deep Learning (DL), but at smaller training/inference data number ratio 1.5:1. And only a single training epoch is required during the learning process. Meanwhile, to the best of our knowledge, this is the highest accuracy among the non-backpropagation algorithm based SNNs. At last, we conclude the few-shot learning paradigm of the developed network: 1) a hierarchical structure-based network design involves human prior knowledge; 2) SNNs for content based global dynamic feature detection.

</p>
</details>

<details><summary><b>Evaluation of creating scoring opportunities for teammates in soccer via trajectory prediction</b>
<a href="https://arxiv.org/abs/2206.01899">arxiv:2206.01899</a>
&#x1F4C8; 2 <br>
<p>Masakiyo Teranishi, Kazushi Tsutsui, Kazuya Takeda, Keisuke Fujii</p></summary>
<p>

**Abstract:** Evaluating the individual movements for teammates in soccer players is crucial for assessing teamwork, scouting, and fan engagement. It has been said that players in a 90-min game do not have the ball for about 87 minutes on average. However, it has remained difficult to evaluate an attacking player without receiving the ball, and to reveal how movement contributes to the creation of scoring opportunities for teammates. In this paper, we evaluate players who create off-ball scoring opportunities by comparing actual movements with the reference movements generated via trajectory prediction. First, we predict the trajectories of players using a graph variational recurrent neural network that can accurately model the relationship between players and predict the long-term trajectory. Next, based on the difference in the modified off-ball evaluation index between the actual and the predicted trajectory as a reference, we evaluate how the actual movement contributes to scoring opportunity compared to the predicted movement. For verification, we examined the relationship with the annual salary, the goals, and the rating in the game by experts for all games of a team in a professional soccer league in a year. The results show that the annual salary and the proposed indicator correlated significantly, which could not be explained by the existing indicators and goals. Our results suggest the effectiveness of the proposed method as an indicator for a player without the ball to create a scoring chance for teammates.

</p>
</details>

<details><summary><b>Saliency Attack: Towards Imperceptible Black-box Adversarial Attack</b>
<a href="https://arxiv.org/abs/2206.01898">arxiv:2206.01898</a>
&#x1F4C8; 2 <br>
<p>Zeyu Dai, Shengcai Liu, Ke Tang, Qing Li</p></summary>
<p>

**Abstract:** Deep neural networks are vulnerable to adversarial examples, even in the black-box setting where the attacker is only accessible to the model output. Recent studies have devised effective black-box attacks with high query efficiency. However, such performance is often accompanied by compromises in attack imperceptibility, hindering the practical use of these approaches. In this paper, we propose to restrict the perturbations to a small salient region to generate adversarial examples that can hardly be perceived. This approach is readily compatible with many existing black-box attacks and can significantly improve their imperceptibility with little degradation in attack success rate. Further, we propose the Saliency Attack, a new black-box attack aiming to refine the perturbations in the salient region to achieve even better imperceptibility. Extensive experiments show that compared to the state-of-the-art black-box attacks, our approach achieves much better imperceptibility scores, including most apparent distortion (MAD), $L_0$ and $L_2$ distances, and also obtains significantly higher success rates judged by a human-like threshold on MAD. Importantly, the perturbations generated by our approach are interpretable to some extent. Finally, it is also demonstrated to be robust to different detection-based defenses.

</p>
</details>

<details><summary><b>A Superimposed Divide-and-Conquer Image Recognition Method for SEM Images of Nanoparticles on The Surface of Monocrystalline silicon with High Aggregation Degree</b>
<a href="https://arxiv.org/abs/2206.01884">arxiv:2206.01884</a>
&#x1F4C8; 2 <br>
<p>Ruiling Xiao, Jiayang Niu</p></summary>
<p>

**Abstract:** The nanoparticle size and distribution information in the SEM images of silicon crystals are generally counted by manual methods. The realization of automatic machine recognition is significant in materials science. This paper proposed a superposition partitioning image recognition method to realize automatic recognition and information statistics of silicon crystal nanoparticle SEM images. Especially for the complex and highly aggregated characteristics of silicon crystal particle size, an accurate recognition step and contour statistics method based on morphological processing are given. This method has technical reference value for the recognition of Monocrystalline silicon surface nanoparticle images under different SEM shooting conditions. Besides, it outperforms other methods in terms of recognition accuracy and algorithm efficiency.

</p>
</details>

<details><summary><b>An Unpooling Layer for Graph Generation</b>
<a href="https://arxiv.org/abs/2206.01874">arxiv:2206.01874</a>
&#x1F4C8; 2 <br>
<p>Yinglong Guo, Dongmian Zou, Gilad Lerman</p></summary>
<p>

**Abstract:** We propose a novel and trainable graph unpooling layer for effective graph generation. Given a graph with features, the unpooling layer enlarges this graph and learns its desired new structure and features. Since this unpooling layer is trainable, it can be applied to graph generation either in the decoder of a variational autoencoder or in the generator of a generative adversarial network (GAN). We prove that the unpooled graph remains connected and any connected graph can be sequentially unpooled from a 3-nodes graph. We apply the unpooling layer within the GAN generator. Since the most studied instance of graph generation is molecular generation, we test our ideas in this context. Using the QM9 and ZINC datasets, we demonstrate the improvement obtained by using the unpooling layer instead of an adjacency-matrix-based approach.

</p>
</details>

<details><summary><b>Estimating the Effect of Team Hitting Strategies Using Counterfactual Virtual Simulation in Baseball</b>
<a href="https://arxiv.org/abs/2206.01871">arxiv:2206.01871</a>
&#x1F4C8; 2 <br>
<p>Hiroshi Nakahara, Kazuya Takeda, Keisuke Fujii</p></summary>
<p>

**Abstract:** In baseball, every play on the field is quantitatively evaluated and has an effect on individual and team strategies. The weighted on base average (wOBA) is well known as a measure of an batter's hitting contribution. However, this measure ignores the game situation, such as the runners on base, which coaches and batters are known to consider when employing multiple hitting strategies, yet, the effectiveness of these strategies is unknown. This is probably because (1) we cannot obtain the batter's strategy and (2) it is difficult to estimate the effect of the strategies. Here, we propose a new method for estimating the effect using counterfactual batting simulation. To this end, we propose a deep learning model that transforms batting ability when batting strategy is changed. This method can estimate the effects of various strategies, which has been traditionally difficult with actual game data. We found that, when the switching cost of batting strategies can be ignored, the use of different strategies increased runs. When the switching cost is considered, the conditions for increasing runs were limited. Our validation results suggest that our simulation could clarify the effect of using multiple batting strategies.

</p>
</details>

<details><summary><b>The Gamma Generalized Normal Distribution: A Descriptor of SAR Imagery</b>
<a href="https://arxiv.org/abs/2206.01826">arxiv:2206.01826</a>
&#x1F4C8; 2 <br>
<p>G. M. Cordeiro, R. J. Cintra, L. C. Rêgo, A. D. C. Nascimento</p></summary>
<p>

**Abstract:** We propose a new four-parameter distribution for modeling synthetic aperture radar (SAR) imagery named the gamma generalized normal (GGN) by combining the gamma and generalized normal distributions. A mathematical characterization of the new distribution is provided by identifying the limit behavior and by calculating the density and moment expansions. The GGN model performance is evaluated on both synthetic and actual data and, for that, maximum likelihood estimation and random number generation are discussed. The proposed distribution is compared with the beta generalized normal distribution (BGN), which has already shown to appropriately represent SAR imagery. The performance of these two distributions are measured by means of statistics which provide evidence that the GGN can outperform the BGN distribution in some contexts.

</p>
</details>

<details><summary><b>Additive MIL: Intrinsic Interpretability for Pathology</b>
<a href="https://arxiv.org/abs/2206.01794">arxiv:2206.01794</a>
&#x1F4C8; 2 <br>
<p>Syed Ashar Javed, Dinkar Juyal, Harshith Padigela, Amaro Taylor-Weiner, Limin Yu, Aaditya Prakash</p></summary>
<p>

**Abstract:** Multiple Instance Learning (MIL) has been widely applied in pathology towards solving critical problems such as automating cancer diagnosis and grading, predicting patient prognosis, and therapy response. Deploying these models in a clinical setting requires careful inspection of these black boxes during development and deployment to identify failures and maintain physician trust. In this work, we propose a simple formulation of MIL models, which enables interpretability while maintaining similar predictive performance. Our Additive MIL models enable spatial credit assignment such that the contribution of each region in the image can be exactly computed and visualized. We show that our spatial credit assignment coincides with regions used by pathologists during diagnosis and improves upon classical attention heatmaps from attention MIL models. We show that any existing MIL model can be made additive with a simple change in function composition. We also show how these models can debug model failures, identify spurious features, and highlight class-wise regions of interest, enabling their use in high-stakes environments such as clinical decision-making.

</p>
</details>

<details><summary><b>Optimal Competitive-Ratio Control</b>
<a href="https://arxiv.org/abs/2206.01782">arxiv:2206.01782</a>
&#x1F4C8; 2 <br>
<p>Oron Sabag, Sahin Lale, Babak Hassibi</p></summary>
<p>

**Abstract:** Inspired by competitive policy designs approaches in online learning, new control paradigms such as competitive-ratio and regret-optimal control have been recently proposed as alternatives to the classical $\mathcal{H}_2$ and $\mathcal{H}_\infty$ approaches. These competitive metrics compare the control cost of the designed controller against the cost of a clairvoyant controller, which has access to past, present, and future disturbances in terms of ratio and difference, respectively. While prior work provided the optimal solution for the regret-optimal control problem, in competitive-ratio control, the solution is only provided for the sub-optimal problem. In this work, we derive the optimal solution to the competitive-ratio control problem. We show that the optimal competitive ratio formula can be computed as the maximal eigenvalue of a simple matrix, and provide a state-space controller that achieves the optimal competitive ratio. We conduct an extensive numerical study to verify this analytical solution, and demonstrate that the optimal competitive-ratio controller outperforms other controllers on several large scale practical systems. The key techniques that underpin our explicit solution is a reduction of the control problem to a Nehari problem, along with a novel factorization of the clairvoyant controller's cost. We reveal an interesting relation between the explicit solutions that now exist for both competitive control paradigms by formulating a regret-optimal control framework with weight functions that can also be utilized for practical purposes.

</p>
</details>

<details><summary><b>Monkeypox Image Data collection</b>
<a href="https://arxiv.org/abs/2206.01774">arxiv:2206.01774</a>
&#x1F4C8; 2 <br>
<p>Md Manjurul Ahsan, Muhammad Ramiz Uddin, Shahana Akter Luna</p></summary>
<p>

**Abstract:** This paper explains the initial Monkeypox Open image data collection procedure. It was created by assembling images collected from websites, newspapers, and online portals and currently contains around 1905 images after data augmentation.

</p>
</details>

<details><summary><b>Radar Guided Dynamic Visual Attention for Resource-Efficient RGB Object Detection</b>
<a href="https://arxiv.org/abs/2206.01772">arxiv:2206.01772</a>
&#x1F4C8; 2 <br>
<p>Hemant Kumawat, Saibal Mukhopadhyay</p></summary>
<p>

**Abstract:** An autonomous system's perception engine must provide an accurate understanding of the environment for it to make decisions. Deep learning based object detection networks experience degradation in the performance and robustness for small and far away objects due to a reduction in object's feature map as we move to higher layers of the network. In this work, we propose a novel radar-guided spatial attention for RGB images to improve the perception quality of autonomous vehicles operating in a dynamic environment. In particular, our method improves the perception of small and long range objects, which are often not detected by the object detectors in RGB mode. The proposed method consists of two RGB object detectors, namely the Primary detector and a lightweight Secondary detector. The primary detector takes a full RGB image and generates primary detections. Next, the radar proposal framework creates regions of interest (ROIs) for object proposals by projecting the radar point cloud onto the 2D RGB image. These ROIs are cropped and fed to the secondary detector to generate secondary detections which are then fused with the primary detections via non-maximum suppression. This method helps in recovering the small objects by preserving the object's spatial features through an increase in their receptive field. We evaluate our fusion method on the challenging nuScenes dataset and show that our fusion method with SSD-lite as primary and secondary detector improves the baseline primary yolov3 detector's recall by 14% while requiring three times fewer computational resources.

</p>
</details>

<details><summary><b>[Re] Badder Seeds: Reproducing the Evaluation of Lexical Methods for Bias Measurement</b>
<a href="https://arxiv.org/abs/2206.01767">arxiv:2206.01767</a>
&#x1F4C8; 2 <br>
<p>Jille van der Togt, Lea Tiyavorabun, Matteo Rosati, Giulio Starace</p></summary>
<p>

**Abstract:** Combating bias in NLP requires bias measurement. Bias measurement is almost always achieved by using lexicons of seed terms, i.e. sets of words specifying stereotypes or dimensions of interest. This reproducibility study focuses on the original authors' main claim that the rationale for the construction of these lexicons needs thorough checking before usage, as the seeds used for bias measurement can themselves exhibit biases. The study aims to evaluate the reproducibility of the quantitative and qualitative results presented in the paper and the conclusions drawn thereof. We reproduce most of the results supporting the original authors' general claim: seed sets often suffer from biases that affect their performance as a baseline for bias metrics. Generally, our results mirror the original paper's. They are slightly different on select occasions, but not in ways that undermine the paper's general intent to show the fragility of seed sets.

</p>
</details>

<details><summary><b>Federated Deep Learning Meets Autonomous Vehicle Perception: Design and Verification</b>
<a href="https://arxiv.org/abs/2206.01748">arxiv:2206.01748</a>
&#x1F4C8; 2 <br>
<p>Shuai Wang, Chengyang Li, Qi Hao, Chengzhong Xu, Derrick Wing Kwan Ng, Yonina C. Eldar, H. Vincent Poor</p></summary>
<p>

**Abstract:** Realizing human-like perception is a challenge in open driving scenarios due to corner cases and visual occlusions. To gather knowledge of rare and occluded instances, federated learning empowered connected autonomous vehicle (FLCAV) has been proposed, which leverages vehicular networks to establish federated deep neural networks (DNNs) from distributed data captured by vehicles and road sensors. Without the need of data aggregation, FLCAV preserves privacy while reducing communication and annotation costs compared with conventional centralized learning. However, it is challenging to determine the network resources and road sensor poses for multi-stage training with multi-modal datasets in multi-variant scenarios. This article presents networking and training frameworks for FLCAV perception. Multi-layer graph resource allocation and vehicle-road pose contrastive methods are proposed to address the network management and sensor pose problems, respectively. We also develop CarlaFLCAV, a software platform that implements the above system and methods. Experimental results confirm the superiority of the proposed techniques compared with various benchmarks.

</p>
</details>

<details><summary><b>BaCaDI: Bayesian Causal Discovery with Unknown Interventions</b>
<a href="https://arxiv.org/abs/2206.01665">arxiv:2206.01665</a>
&#x1F4C8; 2 <br>
<p>Alexander Hägele, Jonas Rothfuss, Lars Lorch, Vignesh Ram Somnath, Bernhard Schölkopf, Andreas Krause</p></summary>
<p>

**Abstract:** Learning causal structures from observation and experimentation is a central task in many domains. For example, in biology, recent advances allow us to obtain single-cell expression data under multiple interventions such as drugs or gene knockouts. However, a key challenge is that often the targets of the interventions are uncertain or unknown. Thus, standard causal discovery methods can no longer be used. To fill this gap, we propose a Bayesian framework (BaCaDI) for discovering the causal structure that underlies data generated under various unknown experimental/interventional conditions. BaCaDI is fully differentiable and operates in the continuous space of latent probabilistic representations of both causal structures and interventions. This enables us to approximate complex posteriors via gradient-based variational inference and to reason about the epistemic uncertainty in the predicted structure. In experiments on synthetic causal discovery tasks and simulated gene-expression data, BaCaDI outperforms related methods in identifying causal structures and intervention targets. Finally, we demonstrate that, thanks to its rigorous Bayesian approach, our method provides well-calibrated uncertainty estimates.

</p>
</details>

<details><summary><b>Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2206.01663">arxiv:2206.01663</a>
&#x1F4C8; 2 <br>
<p>Jiaju Qi, Lei Lei, Kan Zheng, Simon X. Yang</p></summary>
<p>

**Abstract:** Nowadays, the application of microgrids (MG) with renewable energy is becoming more and more extensive, which creates a strong need for dynamic energy management. In this paper, deep reinforcement learning (DRL) is applied to learn an optimal policy for making joint energy dispatch (ED) and unit commitment (UC) decisions in an isolated MG, with the aim for reducing the total power generation cost on the premise of ensuring the supply-demand balance. In order to overcome the challenge of discrete-continuous hybrid action space due to joint ED and UC, we propose a DRL algorithm, i.e., the hybrid action finite-horizon DDPG (HAFH-DDPG), that seamlessly integrates two classical DRL algorithms, i.e., deep Q-network (DQN) and deep deterministic policy gradient (DDPG), based on a finite-horizon dynamic programming (DP) framework. Moreover, a diesel generator (DG) selection strategy is presented to support a simplified action space for reducing the computation complexity of this algorithm. Finally, the effectiveness of our proposed algorithm is verified through comparison with several baseline algorithms by experiments with real-world data set.

</p>
</details>

<details><summary><b>Mirror modular cloning and fast quantum associative retrieval</b>
<a href="https://arxiv.org/abs/2206.01644">arxiv:2206.01644</a>
&#x1F4C8; 2 <br>
<p>M. C. Diamantini, C. A. Trugenberger</p></summary>
<p>

**Abstract:** We show that a quantum state can be perfectly cloned up to global mirroring with a unitary transformation that depends on one single parameter. We then show that this is equivalent to "perfect" cloning for quantum associative memories which, as a consequence efficiently hold exponentially more information than their classical counterparts. Finally, we present a quantum associative retrieval algorithm which can correct corrupted inputs and is exponentially faster than the Grover algorithm.

</p>
</details>

<details><summary><b>MCD: Marginal Contrastive Discrimination for conditional density estimation</b>
<a href="https://arxiv.org/abs/2206.01592">arxiv:2206.01592</a>
&#x1F4C8; 2 <br>
<p>Benjamin Riu</p></summary>
<p>

**Abstract:** We consider the problem of conditional density estimation, which is a major topic of interest in the fields of statistical and machine learning. Our method, called Marginal Contrastive Discrimination, MCD, reformulates the conditional density function into two factors, the marginal density function of the target variable and a ratio of density functions which can be estimated through binary classification. Like noise-contrastive methods, MCD can leverage state-of-the-art supervised learning techniques to perform conditional density estimation, including neural networks. Our benchmark reveals that our method significantly outperforms in practice existing methods on most density models and regression datasets.

</p>
</details>

<details><summary><b>Employing Socially Interactive Agents for Robotic Neurorehabilitation Training</b>
<a href="https://arxiv.org/abs/2206.01587">arxiv:2206.01587</a>
&#x1F4C8; 2 <br>
<p>Rhythm Arora, Matteo Lavit Nicora, Pooja Prajod, Daniele Panzeri, Elisabeth André, Patrick Gebhard, Matteo Malosio</p></summary>
<p>

**Abstract:** In today's world, many patients with cognitive impairments and motor dysfunction seek the attention of experts to perform specific conventional therapies to improve their situation. However, due to a lack of neurorehabilitation professionals, patients suffer from severe effects that worsen their condition. In this paper, we present a technological approach for a novel robotic neurorehabilitation training system. It relies on a combination of a rehabilitation device, signal classification methods, supervised machine learning models for training adaptation, training exercises, and socially interactive agents as a user interface. Together with a professional, the system can be trained towards the patient's specific needs. Furthermore, after a training phase, patients are enabled to train independently at home without the assistance of a physical therapist with a socially interactive agent in the role of a coaching assistant.

</p>
</details>

<details><summary><b>Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination</b>
<a href="https://arxiv.org/abs/2206.01535">arxiv:2206.01535</a>
&#x1F4C8; 2 <br>
<p>Yizhen Zheng, Shirui Pan, Vincent Cs Lee, Yu Zheng, Philip S. Yu</p></summary>
<p>

**Abstract:** Graph contrastive learning (GCL) alleviates the heavy reliance on label information for graph representation learning (GRL) via self-supervised learning schemes. The core idea is to learn by maximising mutual information for similar instances, which requires similarity computation between two node instances. However, this operation can be computationally expensive. For example, the time complexity of two commonly adopted contrastive loss functions (i.e., InfoNCE and JSD estimator) for a node is $O(ND)$ and $O(D)$, respectively, where $N$ is the number of nodes, and $D$ is the embedding dimension. Additionally, GCL normally requires a large number of training epochs to be well-trained on large-scale datasets. Inspired by an observation of a technical defect (i.e., inappropriate usage of Sigmoid function) commonly used in two representative GCL works, DGI and MVGRL, we revisit GCL and introduce a new learning paradigm for self-supervised GRL, namely, Group Discrimination (GD), and propose a novel GD-based method called Graph Group Discrimination (GGD). Instead of similarity computation, GGD directly discriminates two groups of summarised node instances with a simple binary cross-entropy loss. As such, GGD only requires $O(1)$ for loss computation of a node. In addition, GGD requires much fewer training epochs to obtain competitive performance compared with GCL methods on large-scale datasets. These two advantages endow GGD with the very efficient property. Extensive experiments show that GGD outperforms state-of-the-art self-supervised methods on 8 datasets. In particular, GGD can be trained in 0.18 seconds (6.44 seconds including data preprocessing) on ogbn-arxiv, which is orders of magnitude (10,000+ faster than GCL baselines} while consuming much less memory. Trained with 9 hours on ogbn-papers100M with billion edges, GGD outperforms its GCL counterparts in both accuracy and efficiency.

</p>
</details>

<details><summary><b>Can Requirements Engineering Support Explainable Artificial Intelligence? Towards a User-Centric Approach for Explainability Requirements</b>
<a href="https://arxiv.org/abs/2206.01507">arxiv:2206.01507</a>
&#x1F4C8; 2 <br>
<p> Umm-e-Habiba, Justus Bogner, Stefan Wagner</p></summary>
<p>

**Abstract:** With the recent proliferation of artificial intelligence systems, there has been a surge in the demand for explainability of these systems. Explanations help to reduce system opacity, support transparency, and increase stakeholder trust. In this position paper, we discuss synergies between requirements engineering (RE) and Explainable AI (XAI). We highlight challenges in the field of XAI, and propose a framework and research directions on how RE practices can help to mitigate these challenges.

</p>
</details>

<details><summary><b>GINK: Graph-based Interaction-aware Kinodynamic Planning via Reinforcement Learning for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2206.01488">arxiv:2206.01488</a>
&#x1F4C8; 2 <br>
<p>Se-Wook Yoo, Seung-Woo Seo</p></summary>
<p>

**Abstract:** There are many challenges in applying deep reinforcement learning (DRL) to autonomous driving in a structured environment such as an urban area. This is because the massive traffic flows moving along the road network change dynamically. It is a key factor to detect changes in the intentions of surrounding vehicles and quickly find a response strategy. In this paper, we suggest a new framework that effectively combines graph-based intention representation learning and reinforcement learning for kinodynamic planning. Specifically, the movement of dynamic agents is expressed as a graph. The spatio-temporal locality of node features is conserved and the features are aggregated by considering the interaction between adjacent nodes. We simultaneously learn motion planner and controller that share the aggregated information via a safe RL framework. We intuitively interpret a given situation with predicted trajectories to generate additional cost signals. The dense cost signals encourage the policy to be safe for dynamic risk. Moreover, by utilizing the data obtained through the direct rollout of learned policy, robust intention inference is achieved for various situations encountered in training. We set up a navigation scenario in which various situations exist by using CARLA, an urban driving simulator. The experiments show the state-of-the-art performance of our approach compared to the existing baselines.

</p>
</details>

<details><summary><b>Offline Reinforcement Learning with Causal Structured World Models</b>
<a href="https://arxiv.org/abs/2206.01474">arxiv:2206.01474</a>
&#x1F4C8; 2 <br>
<p>Zheng-Mao Zhu, Xiong-Hui Chen, Hong-Long Tian, Kun Zhang, Yang Yu</p></summary>
<p>

**Abstract:** Model-based methods have recently shown promising for offline reinforcement learning (RL), aiming to learn good policies from historical data without interacting with the environment. Previous model-based offline RL methods learn fully connected nets as world-models that map the states and actions to the next-step states. However, it is sensible that a world-model should adhere to the underlying causal effect such that it will support learning an effective policy generalizing well in unseen states. In this paper, We first provide theoretical results that causal world-models can outperform plain world-models for offline RL by incorporating the causal structure into the generalization error bound. We then propose a practical algorithm, oFfline mOdel-based reinforcement learning with CaUsal Structure (FOCUS), to illustrate the feasibility of learning and leveraging causal structure in offline RL. Experimental results on two benchmarks show that FOCUS reconstructs the underlying causal structure accurately and robustly. Consequently, it performs better than the plain model-based offline RL algorithms and other causal model-based RL algorithms.

</p>
</details>

<details><summary><b>Evaluating Transfer-based Targeted Adversarial Perturbations against Real-World Computer Vision Systems based on Human Judgments</b>
<a href="https://arxiv.org/abs/2206.01467">arxiv:2206.01467</a>
&#x1F4C8; 2 <br>
<p>Zhengyu Zhao, Nga Dang, Martha Larson</p></summary>
<p>

**Abstract:** Computer vision systems are remarkably vulnerable to adversarial perturbations. Transfer-based adversarial images are generated on one (source) system and used to attack another (target) system. In this paper, we take the first step to investigate transfer-based targeted adversarial images in a realistic scenario where the target system is trained on some private data with its inventory of semantic labels not publicly available. Our main contributions include an extensive human-judgment-based evaluation of attack success on the Google Cloud Vision API and additional analysis of the different behaviors of Google Cloud Vision in face of original images vs. adversarial images. Resources are publicly available at \url{https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/google_results.zip}.

</p>
</details>

<details><summary><b>Zero-Shot Bird Species Recognition by Learning from Field Guides</b>
<a href="https://arxiv.org/abs/2206.01466">arxiv:2206.01466</a>
&#x1F4C8; 2 <br>
<p>Andrés C. Rodríguez, Stefano D'Aronco, Rodrigo Caye Daudt, Jan D. Wegner, Konrad Schindler</p></summary>
<p>

**Abstract:** We exploit field guides to learn bird species recognition, in particular zero-shot recognition of unseen species. The illustrations contained in field guides deliberately focus on discriminative properties of a species, and can serve as side information to transfer knowledge from seen to unseen classes. We study two approaches: (1) a contrastive encoding of illustrations that can be fed into zero-shot learning schemes; and (2) a novel method that leverages the fact that illustrations are also images and as such structurally more similar to photographs than other kinds of side information. Our results show that illustrations from field guides, which are readily available for a wide range of species, are indeed a competitive source of side information. On the iNaturalist2021 subset, we obtain a harmonic mean from 749 seen and 739 unseen classes greater than $45\%$ (@top-10) and $15\%$ (@top-1). Which shows that field guides are a valuable option for challenging real-world scenarios with many species.

</p>
</details>

<details><summary><b>One-shot Learning for Autonomous Aerial Manipulation</b>
<a href="https://arxiv.org/abs/2206.01411">arxiv:2206.01411</a>
&#x1F4C8; 2 <br>
<p>Claudio Zito, Eliseo Ferrante</p></summary>
<p>

**Abstract:** This paper is concerned with learning transferable contact models for aerial manipulation tasks. We investigate a contact-based approach for enabling unmanned aerial vehicles with cable-suspended passive grippers to compute the attach points on novel payloads for aerial transportation. This is the first time that the problem of autonomously generating contact points for such tasks has been investigated. Our approach builds on the underpinning idea that we can learn a probability density of contacts over objects' surfaces from a single demonstration. We enhance this formulation for encoding aerial transportation tasks while maintaining the one-shot learning paradigm without handcrafting task-dependent features or employing ad-hoc heuristics; the only prior is extrapolated directly from a single demonstration. Our models only rely on the geometrical properties of the payloads computed from a point cloud, and they are robust to partial views. The effectiveness of our approach is evaluated in simulation, in which one or three quadropters are requested to transport previously unseen payloads along a desired trajectory. The contact points and the quadroptors configurations are computed on-the-fly for each test by our apporach and compared with a baseline method, a modified grasp learning algorithm from the literature. Empirical experiments show that the contacts generated by our approach yield a better controllability of the payload for a transportation task. We conclude this paper with a discussion on the strengths and limitations of the presented idea, and our suggested future research directions.

</p>
</details>

<details><summary><b>Hybrid Models for Mixed Variables in Bayesian Optimization</b>
<a href="https://arxiv.org/abs/2206.01409">arxiv:2206.01409</a>
&#x1F4C8; 2 <br>
<p>Hengrui Luo, Younghyun Cho, James W. Demmel, Xiaoye S. Li, Yang Liu</p></summary>
<p>

**Abstract:** We systematically describe the problem of simultaneous surrogate modeling of mixed variables (i.e., continuous, integer and categorical variables) in the Bayesian optimization (BO) context. We provide a unified hybrid model using both Monte-Carlo tree search (MCTS) and Gaussian processes (GP) that encompasses and generalizes multiple state-of-the-art mixed BO surrogates. Based on the architecture, we propose applying a new dynamic model selection criterion among novel candidate families of covariance kernels, including non-stationary kernels and associated families. Different benchmark problems are studied and presented to support the superiority of our model, along with results highlighting the effectiveness of our method compared to most state-of-the-art mixed-variable methods in BO.

</p>
</details>

<details><summary><b>MetaLR: Layer-wise Learning Rate based on Meta-Learning for Adaptively Fine-tuning Medical Pre-trained Models</b>
<a href="https://arxiv.org/abs/2206.01408">arxiv:2206.01408</a>
&#x1F4C8; 2 <br>
<p>Yixiong Chen, Jingxian Li, Hua Jiang, Li Liu, Chris Ding</p></summary>
<p>

**Abstract:** When applying transfer learning for medical image analysis, downstream tasks often have significant gaps with the pre-training tasks. Previous methods mainly focus on improving the transferabilities of the pre-trained models to bridge the gaps. In fact, model fine-tuning can also play a very important role in tackling this problem. A conventional fine-tuning method is updating all deep neural networks (DNNs) layers by a single learning rate (LR), which ignores the unique transferabilities of different layers. In this work, we explore the behaviors of different layers in the fine-tuning stage. More precisely, we first hypothesize that lower-level layers are more domain-specific while higher-level layers are more task-specific, which is verified by a simple bi-directional fine-tuning scheme. It is harder for the pre-trained specific layers to transfer to new tasks than general layers. On this basis, to make different layers better co-adapt to the downstream tasks according to their transferabilities, a meta-learning-based LR learner, namely MetaLR, is proposed to assign LRs for each layer automatically. Extensive experiments on various medical applications (i.e., POCUS, BUSI, Chest X-ray, and LiTS) well confirm our hypothesis and show the superior performance of the proposed methods to previous state-of-the-art fine-tuning methods.

</p>
</details>

<details><summary><b>The Algorithmic Imprint</b>
<a href="https://arxiv.org/abs/2206.03275">arxiv:2206.03275</a>
&#x1F4C8; 1 <br>
<p>Upol Ehsan, Ranjit Singh, Jacob Metcalf, Mark O. Riedl</p></summary>
<p>

**Abstract:** When algorithmic harms emerge, a reasonable response is to stop using the algorithm to resolve concerns related to fairness, accountability, transparency, and ethics (FATE). However, just because an algorithm is removed does not imply its FATE-related issues cease to exist. In this paper, we introduce the notion of the "algorithmic imprint" to illustrate how merely removing an algorithm does not necessarily undo or mitigate its consequences. We operationalize this concept and its implications through the 2020 events surrounding the algorithmic grading of the General Certificate of Education (GCE) Advanced (A) Level exams, an internationally recognized UK-based high school diploma exam administered in over 160 countries. While the algorithmic standardization was ultimately removed due to global protests, we show how the removal failed to undo the algorithmic imprint on the sociotechnical infrastructures that shape students', teachers', and parents' lives. These events provide a rare chance to analyze the state of the world both with and without algorithmic mediation. We situate our case study in Bangladesh to illustrate how algorithms made in the Global North disproportionately impact stakeholders in the Global South. Chronicling more than a year-long community engagement consisting of 47 inter-views, we present the first coherent timeline of "what" happened in Bangladesh, contextualizing "why" and "how" they happened through the lenses of the algorithmic imprint and situated algorithmic fairness. Analyzing these events, we highlight how the contours of the algorithmic imprints can be inferred at the infrastructural, social, and individual levels. We share conceptual and practical implications around how imprint-awareness can (a) broaden the boundaries of how we think about algorithmic impact, (b) inform how we design algorithms, and (c) guide us in AI governance.

</p>
</details>

<details><summary><b>Constraints on parameter choices for successful reservoir computing</b>
<a href="https://arxiv.org/abs/2206.02575">arxiv:2206.02575</a>
&#x1F4C8; 1 <br>
<p>L. Storm, K. Gustavsson, B. Mehlig</p></summary>
<p>

**Abstract:** Echo-state networks are simple models of discrete dynamical systems driven by a time series. By selecting network parameters such that the dynamics of the network is contractive, characterized by a negative maximal Lyapunov exponent, the network may synchronize with the driving signal. Exploiting this synchronization, the echo-state network may be trained to autonomously reproduce the input dynamics, enabling time-series prediction. However, while synchronization is a necessary condition for prediction, it is not sufficient. Here, we study what other conditions are necessary for successful time-series prediction. We identify two key parameters for prediction performance, and conduct a parameter sweep to find regions where prediction is successful. These regions differ significantly depending on whether full or partial phase space information about the input is provided to the network during training. We explain how these regions emerge.

</p>
</details>

<details><summary><b>Automated visual inspection of silicon detectors in CMS experiment</b>
<a href="https://arxiv.org/abs/2206.02572">arxiv:2206.02572</a>
&#x1F4C8; 1 <br>
<p>Dr. Nupur Giri, Dr. Shashi Dugad, Amit Chhabria, Rashmi Manwani, Priyanka Asrani</p></summary>
<p>

**Abstract:** In the CMS experiment at CERN, Geneva, a large number of HGCAL sensor modules are fabricated in advanced laboratories around the world. Each sensor module contains about 700 checkpoints for visual inspection thus making it almost impossible to carry out such inspection manually. As artificial intelligence is more and more widely used in manufacturing, traditional detection technologies are gradually being intelligent. In order to more accurately evaluate the checkpoints, we propose to use deep learning-based object detection techniques to detect manufacturing defects in testing large numbers of modules automatically.

</p>
</details>

<details><summary><b>Image Data collection and implementation of deep learning-based model in detecting Monkeypox disease using modified VGG16</b>
<a href="https://arxiv.org/abs/2206.01862">arxiv:2206.01862</a>
&#x1F4C8; 1 <br>
<p>Md Manjurul Ahsan, Muhammad Ramiz Uddin, Mithila Farjana, Ahmed Nazmus Sakib, Khondhaker Al Momin, Shahana Akter Luna</p></summary>
<p>

**Abstract:** While the world is still attempting to recover from the damage caused by the broad spread of COVID-19, the Monkeypox virus poses a new threat of becoming a global pandemic. Although the Monkeypox virus itself is not deadly and contagious as COVID-19, still every day, new patients case has been reported from many nations. Therefore, it will be no surprise if the world ever faces another global pandemic due to the lack of proper precautious steps. Recently, Machine learning (ML) has demonstrated huge potential in image-based diagnoses such as cancer detection, tumor cell identification, and COVID-19 patient detection. Therefore, a similar application can be adopted to diagnose the Monkeypox-related disease as it infected the human skin, which image can be acquired and further used in diagnosing the disease. Considering this opportunity, in this work, we introduce a newly developed "Monkeypox2022" dataset that is publicly available to use and can be obtained from our shared GitHub repository. The dataset is created by collecting images from multiple open-source and online portals that do not impose any restrictions on use, even for commercial purposes, hence giving a safer path to use and disseminate such data when constructing and deploying any type of ML model. Further, we propose and evaluate a modified VGG16 model, which includes two distinct studies: Study One and Two. Our exploratory computational results indicate that our suggested model can identify Monkeypox patients with an accuracy of $97\pm1.8\%$ (AUC=97.2) and $88\pm0.8\%$ (AUC=0.867) for Study One and Two, respectively. Additionally, we explain our model's prediction and feature extraction utilizing Local Interpretable Model-Agnostic Explanations (LIME) help to a deeper insight into specific features that characterize the onset of the Monkeypox virus.

</p>
</details>

<details><summary><b>A Robust Backpropagation-Free Framework for Images</b>
<a href="https://arxiv.org/abs/2206.01820">arxiv:2206.01820</a>
&#x1F4C8; 1 <br>
<p>Timothy Zee, Alexander G. Ororbia, Ankur Mali, Ifeoma Nwogu</p></summary>
<p>

**Abstract:** While current deep learning algorithms have been successful for a wide variety of artificial intelligence (AI) tasks, including those involving structured image data, they present deep neurophysiological conceptual issues due to their reliance on the gradients computed by backpropagation of errors (backprop) to obtain synaptic weight adjustments; hence are biologically implausible. We present a more biologically plausible approach, the error-kernel driven activation alignment (EKDAA) algorithm, to train convolution neural networks (CNNs) using locally derived error transmission kernels and error maps. We demonstrate the efficacy of EKDAA by performing the task of visual-recognition on the Fashion MNIST, CIFAR-10 and SVHN benchmarks as well as conducting blackbox robustness tests on adversarial examples derived from these datasets. Furthermore, we also present results for a CNN trained using a non-differentiable activation function. All recognition results nearly matches that of backprop and exhibit greater adversarial robustness compared to backprop.

</p>
</details>

<details><summary><b>Algorithm for Constrained Markov Decision Process with Linear Convergence</b>
<a href="https://arxiv.org/abs/2206.01666">arxiv:2206.01666</a>
&#x1F4C8; 1 <br>
<p>Egor Gladin, Maksim Lavrik-Karmazin, Karina Zainullina, Varvara Rudenko, Alexander Gasnikov, Martin Takáč</p></summary>
<p>

**Abstract:** The problem of constrained Markov decision process is considered. An agent aims to maximize the expected accumulated discounted reward subject to multiple constraints on its costs (the number of constraints is relatively small). A new dual approach is proposed with the integration of two ingredients: entropy regularized policy optimizer and Vaidya's dual optimizer, both of which are critical to achieve faster convergence. The finite-time error bound of the proposed approach is provided. Despite the challenge of the nonconcave objective subject to nonconcave constraints, the proposed approach is shown to converge (with linear rate) to the global optimum. The complexity expressed in terms of the optimality gap and the constraint violation significantly improves upon the existing primal-dual approaches.

</p>
</details>

<details><summary><b>Rapid rhythmic entrainment in bio-inspired central pattern generators</b>
<a href="https://arxiv.org/abs/2206.01638">arxiv:2206.01638</a>
&#x1F4C8; 1 <br>
<p>Alex Szorkovszky, Frank Veenstra, Kyrre Glette</p></summary>
<p>

**Abstract:** Entrainment of movement to a periodic stimulus is a characteristic intelligent behaviour in humans and an important goal for adaptive robotics. We demonstrate a quadruped central pattern generator (CPG), consisting of modified Matsuoka neurons, that spontaneously adjusts its period of oscillation to that of a periodic input signal. This is done by simple forcing, with the aid of a filtering network as well as a neural model with tonic input-dependent oscillation period. We first use the NSGA3 algorithm to evolve the CPG parameters, using separate fitness functions for period tunability, limb homogeneity and gait stability. Four CPGs, maximizing different weighted averages of the fitness functions, are then selected from the Pareto front and each is used as a basis for optimizing a filter network. Different numbers of neurons are tested for each filter network. We find that period tunability in particular facilitates robust entrainment, that bounding gaits entrain more easily than walking gaits, and that more neurons in the filter network are beneficial for pre-processing input signals. The system that we present can be used in conjunction with sensory feedback to allow low-level adaptive and robust behaviour in walking robots.

</p>
</details>

<details><summary><b>A Survey on Surrogate-assisted Efficient Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2206.01520">arxiv:2206.01520</a>
&#x1F4C8; 1 <br>
<p>Shiqing Liu, Haoyu Zhang, Yaochu Jin</p></summary>
<p>

**Abstract:** Neural architecture search (NAS) has become increasingly popular in the deep learning community recently, mainly because it can provide an opportunity to allow interested users without rich expertise to benefit from the success of deep neural networks (DNNs). However, NAS is still laborious and time-consuming because a large number of performance estimations are required during the search process of NAS, and training DNNs is computationally intensive. To solve the major limitation of NAS, improving the efficiency of NAS is essential in the design of NAS. This paper begins with a brief introduction to the general framework of NAS. Then, the methods for evaluating network candidates under the proxy metrics are systematically discussed. This is followed by a description of surrogate-assisted NAS, which is divided into three different categories, namely Bayesian optimization for NAS, surrogate-assisted evolutionary algorithms for NAS, and MOP for NAS. Finally, remaining challenges and open research questions are discussed, and promising research topics are suggested in this emerging field.

</p>
</details>

<details><summary><b>Functional Connectivity Methods for EEG-based Biometrics on a Large, Heterogeneous Dataset</b>
<a href="https://arxiv.org/abs/2206.01475">arxiv:2206.01475</a>
&#x1F4C8; 1 <br>
<p>Pradeep Kumar G, Utsav Dutta, Kanishka Sharma, Ramakrishnan Angarai Ganesan</p></summary>
<p>

**Abstract:** This study examines the utility of functional connectivity (FC) and graph-based (GB) measures with a support vector machine classifier for use in electroencephalogram (EEG) based biometrics. Although FC-based features have been used in biometric applications, studies assessing the identification algorithms on heterogeneous and large datasets are scarce. This work investigates the performance of FC and GB metrics on a dataset of 184 subjects formed by pooling three datasets recorded under different protocols and acquisition systems. The results demonstrate the higher discriminatory power of FC than GB metrics. The identification accuracy increases with higher frequency EEG bands, indicating the enhanced uniqueness of the neural signatures in beta and gamma bands. Using all the 56 EEG channels common to the three databases, the best identification accuracy of 97.4% is obtained using phase-locking value (PLV) based measures extracted from the gamma frequency band. Further, we investigate the effect of the length of the analysis epoch to determine the data acquisition time required to obtain satisfactory identification accuracy. When the number of channels is reduced to 21 from 56, there is a marginal reduction of 2.4% only in the identification accuracy using PLV features in the gamma band. Additional experiments have been conducted to study the effect of the cognitive state of the subject and mismatched train/test conditions on the performance of the system.

</p>
</details>

<details><summary><b>PAC Statistical Model Checking of Mean Payoff in Discrete- and Continuous-Time MDP</b>
<a href="https://arxiv.org/abs/2206.01465">arxiv:2206.01465</a>
&#x1F4C8; 1 <br>
<p>Chaitanya Agarwal, Shibashis Guha, Jan Křetínský, M. Pazhamalai</p></summary>
<p>

**Abstract:** Markov decision processes (MDP) and continuous-time MDP (CTMDP) are the fundamental models for non-deterministic systems with probabilistic uncertainty. Mean payoff (a.k.a. long-run average reward) is one of the most classic objectives considered in their context. We provide the first algorithm to compute mean payoff probably approximately correctly in unknown MDP; further, we extend it to unknown CTMDP. We do not require any knowledge of the state space, only a lower bound on the minimum transition probability, which has been advocated in literature. In addition to providing probably approximately correct (PAC) bounds for our algorithm, we also demonstrate its practical nature by running experiments on standard benchmarks.

</p>
</details>

<details><summary><b>Safety Certification for Stochastic Systems via Neural Barrier Functions</b>
<a href="https://arxiv.org/abs/2206.01463">arxiv:2206.01463</a>
&#x1F4C8; 1 <br>
<p>Frederik Baymler Mathiesen, Simeon Calvert, Luca Laurenti</p></summary>
<p>

**Abstract:** Providing non-trivial certificates of safety for non-linear stochastic systems is an important open problem that limits the wider adoption of autonomous systems in safety-critical applications. One promising solution to address this problem is barrier functions. The composition of a barrier function with a stochastic system forms a supermartingale, thus enabling the computation of the probability that the system stays in a safe set over a finite time horizon via martingale inequalities. However, existing approaches to find barrier functions for stochastic systems generally rely on convex optimization programs that restrict the search of a barrier to a small class of functions such as low degree SoS polynomials and can be computationally expensive. In this paper, we parameterize a barrier function as a neural network and show that techniques for robust training of neural networks can be successfully employed to find neural barrier functions. Specifically, we leverage bound propagation techniques to certify that a neural network satisfies the conditions to be a barrier function via linear programming and then employ the resulting bounds at training time to enforce the satisfaction of these conditions. We also present a branch-and-bound scheme that makes the certification framework scalable. We show that our approach outperforms existing methods in several case studies and often returns certificates of safety that are orders of magnitude larger.

</p>
</details>

<details><summary><b>LenslessPiCam: A Hardware and Software Platform for Lensless Computational Imaging with a Raspberry Pi</b>
<a href="https://arxiv.org/abs/2206.01430">arxiv:2206.01430</a>
&#x1F4C8; 1 <br>
<p>Eric Bezzam, Sepand Kashani, Martin Vetterli, Matthieu Simeoni</p></summary>
<p>

**Abstract:** Lensless imaging seeks to replace/remove the lens in a conventional imaging system. The earliest cameras were in fact lensless, relying on long exposure times to form images on the other end of a small aperture in a darkened room/container (camera obscura). The introduction of a lens allowed for more light throughput and therefore shorter exposure times, while retaining sharp focus. The incorporation of digital sensors readily enabled the use of computational imaging techniques to post-process and enhance raw images (e.g. via deblurring, inpainting, denoising, sharpening). Recently, imaging scientists have started leveraging computational imaging as an integral part of lensless imaging systems, allowing them to form viewable images from the highly multiplexed raw measurements of lensless cameras (see [5] and references therein for a comprehensive treatment of lensless imaging). This represents a real paradigm shift in camera system design as there is more flexibility to cater the hardware to the application at hand (e.g. lightweight or flat designs). This increased flexibility comes however at the price of a more demanding post-processing of the raw digital recordings and a tighter integration of sensing and computation, often difficult to achieve in practice due to inefficient interactions between the various communities of scientists involved. With LenslessPiCam, we provide an easily accessible hardware and software framework to enable researchers, hobbyists, and students to implement and explore practical and computational aspects of lensless imaging. We also provide detailed guides and exercises so that LenslessPiCam can be used as an educational resource, and point to results from our graduate-level signal processing course.

</p>
</details>


{% endraw %}
Prev: [2022.06.02]({{ '/2022/06/02/2022.06.02.html' | relative_url }})  Next: [2022.06.04]({{ '/2022/06/04/2022.06.04.html' | relative_url }})