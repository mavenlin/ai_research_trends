Prev: [2022.07.28]({{ '/2022/07/28/2022.07.28.html' | relative_url }})  Next: [2022.07.30]({{ '/2022/07/30/2022.07.30.html' | relative_url }})
{% raw %}
## Summary for 2022-07-29, created on 2022-08-05


<details><summary><b>Language Models Can Teach Themselves to Program Better</b>
<a href="https://arxiv.org/abs/2207.14502">arxiv:2207.14502</a>
&#x1F4C8; 2560 <br>
<p>Patrick Haluptzok, Matthew Bowers, Adam Tauman Kalai</p></summary>
<p>

**Abstract:** This work shows how one can use large-scale language models (LMs) to synthesize programming problems with verified solutions, in the form of programming puzzles, which can then in turn be used to fine-tune those same models, improving their performance. This work builds on two recent developments. First, LMs have achieved breakthroughs in non-trivial reasoning and algorithm implementation, generating code that can solve some intermediate-level competitive programming problems. However, training code LMs involves curated sets of natural-language problem descriptions and source-code tests and solutions, which are limited in size. Second, a new format of programming challenge called a programming puzzle was introduced, which does not require a natural language description and is directly specified by a source-code test. In this work we show how generating synthetic programming puzzles and solutions, verified for correctness by a Python interpreter, can be used to improve performance in solving test puzzles from P3, a public benchmark set of Python Programming Puzzles. Additionally, we release a dataset of 1 million puzzles and solutions generated by the Codex model, which we show can improve smaller models through fine-tuning.

</p>
</details>

<details><summary><b>20 years of network community detection</b>
<a href="https://arxiv.org/abs/2208.00111">arxiv:2208.00111</a>
&#x1F4C8; 186 <br>
<p>Santo Fortunato, M. E. J. Newman</p></summary>
<p>

**Abstract:** A fundamental technical challenge in the analysis of network data is the automated discovery of communities - groups of nodes that are strongly connected or that share similar features or roles. In this commentary we review progress in the field over the last 20 years.

</p>
</details>

<details><summary><b>Neural Correspondence Field for Object Pose Estimation</b>
<a href="https://arxiv.org/abs/2208.00113">arxiv:2208.00113</a>
&#x1F4C8; 20 <br>
<p>Lin Huang, Tomas Hodan, Lingni Ma, Linguang Zhang, Luan Tran, Christopher Twigg, Po-Chen Wu, Junsong Yuan, Cem Keskin, Robert Wang</p></summary>
<p>

**Abstract:** We propose a method for estimating the 6DoF pose of a rigid object with an available 3D model from a single RGB image. Unlike classical correspondence-based methods which predict 3D object coordinates at pixels of the input image, the proposed method predicts 3D object coordinates at 3D query points sampled in the camera frustum. The move from pixels to 3D points, which is inspired by recent PIFu-style methods for 3D reconstruction, enables reasoning about the whole object, including its (self-)occluded parts. For a 3D query point associated with a pixel-aligned image feature, we train a fully-connected neural network to predict: (i) the corresponding 3D object coordinates, and (ii) the signed distance to the object surface, with the first defined only for query points in the surface vicinity. We call the mapping realized by this network as Neural Correspondence Field. The object pose is then robustly estimated from the predicted 3D-3D correspondences by the Kabsch-RANSAC algorithm. The proposed method achieves state-of-the-art results on three BOP datasets and is shown superior especially in challenging cases with occlusion. The project website is at: linhuang17.github.io/NCF.

</p>
</details>

<details><summary><b>StyleLight: HDR Panorama Generation for Lighting Estimation and Editing</b>
<a href="https://arxiv.org/abs/2207.14811">arxiv:2207.14811</a>
&#x1F4C8; 20 <br>
<p>Guangcong Wang, Yinuo Yang, Chen Change Loy, Ziwei Liu</p></summary>
<p>

**Abstract:** We present a new lighting estimation and editing framework to generate high-dynamic-range (HDR) indoor panorama lighting from a single limited field-of-view (LFOV) image captured by low-dynamic-range (LDR) cameras. Existing lighting estimation methods either directly regress lighting representation parameters or decompose this problem into LFOV-to-panorama and LDR-to-HDR lighting generation sub-tasks. However, due to the partial observation, the high-dynamic-range lighting, and the intrinsic ambiguity of a scene, lighting estimation remains a challenging task. To tackle this problem, we propose a coupled dual-StyleGAN panorama synthesis network (StyleLight) that integrates LDR and HDR panorama synthesis into a unified framework. The LDR and HDR panorama synthesis share a similar generator but have separate discriminators. During inference, given an LDR LFOV image, we propose a focal-masked GAN inversion method to find its latent code by the LDR panorama synthesis branch and then synthesize the HDR panorama by the HDR panorama synthesis branch. StyleLight takes LFOV-to-panorama and LDR-to-HDR lighting generation into a unified framework and thus greatly improves lighting estimation. Extensive experiments demonstrate that our framework achieves superior performance over state-of-the-art methods on indoor lighting estimation. Notably, StyleLight also enables intuitive lighting editing on indoor HDR panoramas, which is suitable for real-world applications. Code is available at https://style-light.github.io.

</p>
</details>

<details><summary><b>Curriculum Learning for Data-Efficient Vision-Language Alignment</b>
<a href="https://arxiv.org/abs/2207.14525">arxiv:2207.14525</a>
&#x1F4C8; 20 <br>
<p>Tejas Srinivasan, Xiang Ren, Jesse Thomason</p></summary>
<p>

**Abstract:** Aligning image and text encoders from scratch using contrastive learning requires large amounts of paired image-text data. We alleviate this need by aligning individually pre-trained language and vision representation models using a much smaller amount of paired data, augmented with a curriculum learning algorithm to learn fine-grained vision-language alignments. TOnICS (Training with Ontology-Informed Contrastive Sampling) initially samples minibatches whose image-text pairs contain a wide variety of objects to learn object-level alignment, and progressively samples minibatches where all image-text pairs contain the same object to learn finer-grained contextual alignment. Aligning pre-trained BERT and VinVL models to each other using TOnICS outperforms CLIP on downstream zero-shot image retrieval while using less than 1% as much training data.

</p>
</details>

<details><summary><b>End-to-end View Synthesis via NeRF Attention</b>
<a href="https://arxiv.org/abs/2207.14741">arxiv:2207.14741</a>
&#x1F4C8; 19 <br>
<p>Zelin Zhao, Jiaya Jia</p></summary>
<p>

**Abstract:** In this paper, we present a simple seq2seq formulation for view synthesis where we take a set of ray points as input and output colors corresponding to the rays. Directly applying a standard transformer on this seq2seq formulation has two limitations. First, the standard attention cannot successfully fit the volumetric rendering procedure, and therefore high-frequency components are missing in the synthesized views. Second, applying global attention to all rays and pixels is extremely inefficient. Inspired by the neural radiance field (NeRF), we propose the NeRF attention (NeRFA) to address the above problems. On the one hand, NeRFA considers the volumetric rendering equation as a soft feature modulation procedure. In this way, the feature modulation enhances the transformers with the NeRF-like inductive bias. On the other hand, NeRFA performs multi-stage attention to reduce the computational overhead. Furthermore, the NeRFA model adopts the ray and pixel transformers to learn the interactions between rays and pixels. NeRFA demonstrates superior performance over NeRF and NerFormer on four datasets: DeepVoxels, Blender, LLFF, and CO3D. Besides, NeRFA establishes a new state-of-the-art under two settings: the single-scene view synthesis and the category-centric novel view synthesis. The code will be made publicly available.

</p>
</details>

<details><summary><b>ALADIN: Distilling Fine-grained Alignment Scores for Efficient Image-Text Matching and Retrieval</b>
<a href="https://arxiv.org/abs/2207.14757">arxiv:2207.14757</a>
&#x1F4C8; 14 <br>
<p>Nicola Messina, Matteo Stefanini, Marcella Cornia, Lorenzo Baraldi, Fabrizio Falchi, Giuseppe Amato, Rita Cucchiara</p></summary>
<p>

**Abstract:** Image-text matching is gaining a leading role among tasks involving the joint understanding of vision and language. In literature, this task is often used as a pre-training objective to forge architectures able to jointly deal with images and texts. Nonetheless, it has a direct downstream application: cross-modal retrieval, which consists in finding images related to a given query text or vice-versa. Solving this task is of critical importance in cross-modal search engines. Many recent methods proposed effective solutions to the image-text matching problem, mostly using recent large vision-language (VL) Transformer networks. However, these models are often computationally expensive, especially at inference time. This prevents their adoption in large-scale cross-modal retrieval scenarios, where results should be provided to the user almost instantaneously. In this paper, we propose to fill in the gap between effectiveness and efficiency by proposing an ALign And DIstill Network (ALADIN). ALADIN first produces high-effective scores by aligning at fine-grained level images and texts. Then, it learns a shared embedding space - where an efficient kNN search can be performed - by distilling the relevance scores obtained from the fine-grained alignments. We obtained remarkable results on MS-COCO, showing that our method can compete with state-of-the-art VL Transformers while being almost 90 times faster. The code for reproducing our results is available at https://github.com/mesnico/ALADIN.

</p>
</details>

<details><summary><b>Minimal Neural Atlas: Parameterizing Complex Surfaces with Minimal Charts and Distortion</b>
<a href="https://arxiv.org/abs/2207.14782">arxiv:2207.14782</a>
&#x1F4C8; 11 <br>
<p>Weng Fei Low, Gim Hee Lee</p></summary>
<p>

**Abstract:** Explicit neural surface representations allow for exact and efficient extraction of the encoded surface at arbitrary precision, as well as analytic derivation of differential geometric properties such as surface normal and curvature. Such desirable properties, which are absent in its implicit counterpart, makes it ideal for various applications in computer vision, graphics and robotics. However, SOTA works are limited in terms of the topology it can effectively describe, distortion it introduces to reconstruct complex surfaces and model efficiency. In this work, we present Minimal Neural Atlas, a novel atlas-based explicit neural surface representation. At its core is a fully learnable parametric domain, given by an implicit probabilistic occupancy field defined on an open square of the parametric space. In contrast, prior works generally predefine the parametric domain. The added flexibility enables charts to admit arbitrary topology and boundary. Thus, our representation can learn a minimal atlas of 3 charts with distortion-minimal parameterization for surfaces of arbitrary topology, including closed and open surfaces with arbitrary connected components. Our experiments support the hypotheses and show that our reconstructions are more accurate in terms of the overall geometry, due to the separation of concerns on topology and geometry.

</p>
</details>

<details><summary><b>Robust Trajectory Prediction against Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2208.00094">arxiv:2208.00094</a>
&#x1F4C8; 10 <br>
<p>Yulong Cao, Danfei Xu, Xinshuo Weng, Zhuoqing Mao, Anima Anandkumar, Chaowei Xiao, Marco Pavone</p></summary>
<p>

**Abstract:** Trajectory prediction using deep neural networks (DNNs) is an essential component of autonomous driving (AD) systems. However, these methods are vulnerable to adversarial attacks, leading to serious consequences such as collisions. In this work, we identify two key ingredients to defend trajectory prediction models against adversarial attacks including (1) designing effective adversarial training methods and (2) adding domain-specific data augmentation to mitigate the performance degradation on clean data. We demonstrate that our method is able to improve the performance by 46% on adversarial data and at the cost of only 3% performance degradation on clean data, compared to the model trained with clean data. Additionally, compared to existing robust methods, our method can improve performance by 21% on adversarial examples and 9% on clean data. Our robust model is evaluated with a planner to study its downstream impacts. We demonstrate that our model can significantly reduce the severe accident rates (e.g., collisions and off-road driving).

</p>
</details>

<details><summary><b>Graph Neural Networks for Channel Decoding</b>
<a href="https://arxiv.org/abs/2207.14742">arxiv:2207.14742</a>
&#x1F4C8; 9 <br>
<p>Sebastian Cammerer, Jakob Hoydis, Fayçal Aït Aoudia, Alexander Keller</p></summary>
<p>

**Abstract:** In this work, we propose a fully differentiable graph neural network (GNN)-based architecture for channel decoding and showcase competitive decoding performance for various coding schemes, such as low-density parity-check (LDPC) and BCH codes. The idea is to let a neural network (NN) learn a generalized message passing algorithm over a given graph that represents the forward error correction (FEC) code structure by replacing node and edge message updates with trainable functions. Contrary to many other deep learning-based decoding approaches, the proposed solution enjoys scalability to arbitrary block lengths and the training is not limited by the curse of dimensionality. We benchmark our proposed decoder against state-of-the-art in conventional channel decoding as well as against recent deep learning-based results. For the (63,45) BCH code, our solution outperforms weighted belief propagation (BP) decoding by approximately 0.4 dB with significantly less decoding iterations and even for 5G NR LDPC codes, we observe a competitive performance when compared to conventional BP decoding. For the BCH codes, the resulting GNN decoder can be fully parametrized with only 9640 weights.

</p>
</details>

<details><summary><b>Open-radiomics: A Research Protocol to Make Radiomics-based Machine Learning Pipelines Reproducible</b>
<a href="https://arxiv.org/abs/2207.14776">arxiv:2207.14776</a>
&#x1F4C8; 8 <br>
<p> Ernest,  Namdar, Matthias W. Wagner, Birgit B. Ertl-Wagner, Farzad Khalvati</p></summary>
<p>

**Abstract:** The application of artificial intelligence (AI) techniques to medical imaging data has yielded promising results. As an important branch of AI pipelines in medical imaging, radiomics faces two major challenges namely reproducibility and accessibility. In this work, we introduce open-radiomics, a set of radiomics datasets, and a comprehensive radiomics pipeline that investigates the effects of radiomics feature extraction settings such as binWidth and image normalization on the reproducibility of the radiomics results performance. To make radiomics research more accessible and reproducible, we provide guidelines for building machine learning (ML) models on radiomics data, introduce Open-radiomics, an evolving collection of open-source radiomics datasets, and publish baseline models for the datasets.

</p>
</details>

<details><summary><b>Thutmose Tagger: Single-pass neural model for Inverse Text Normalization</b>
<a href="https://arxiv.org/abs/2208.00064">arxiv:2208.00064</a>
&#x1F4C8; 7 <br>
<p>Alexandra Antonova, Evelina Bakhturina, Boris Ginsburg</p></summary>
<p>

**Abstract:** Inverse text normalization (ITN) is an essential post-processing step in automatic speech recognition (ASR). It converts numbers, dates, abbreviations, and other semiotic classes from the spoken form generated by ASR to their written forms. One can consider ITN as a Machine Translation task and use neural sequence-to-sequence models to solve it. Unfortunately, such neural models are prone to hallucinations that could lead to unacceptable errors. To mitigate this issue, we propose a single-pass token classifier model that regards ITN as a tagging task. The model assigns a replacement fragment to every input token or marks it for deletion or copying without changes. We present a dataset preparation method based on the granular alignment of ITN examples. The proposed model is less prone to hallucination errors. The model is trained on the Google Text Normalization dataset and achieves state-of-the-art sentence accuracy on both English and Russian test sets. One-to-one correspondence between tags and input words improves the interpretability of the model's predictions, simplifies debugging, and allows for post-processing corrections. The model is simpler than sequence-to-sequence models and easier to optimize in production settings. The model and the code to prepare the dataset is published as part of NeMo project.

</p>
</details>

<details><summary><b>Artifact Identification in X-ray Diffraction Data using Machine Learning Methods</b>
<a href="https://arxiv.org/abs/2207.14804">arxiv:2207.14804</a>
&#x1F4C8; 7 <br>
<p>Howard Yanxon, James Weng, Hannah Parraga, Wenqian Xu, Uta Ruett, Nicholas Schwarz</p></summary>
<p>

**Abstract:** The in situ synchrotron high-energy X-ray powder diffraction (XRD) technique is highly utilized by researchers to analyze the crystallographic structures of materials in functional devices (e.g., battery materials) or in complex sample environments (e.g., diamond anvil cells or syntheses reactors). An atomic structure of a material can be identified by its diffraction pattern, along with detailed analysis such as Rietveld refinement which indicates how the measured structure deviates from the ideal structure (e.g., internal stresses or defects). For in situ experiments, a series of XRD images is usually collected on the same sample at different conditions (e.g., adiabatic conditions), yielding different states of matter, or simply collected continuously as a function of time to track the change of a sample over a chemical or physical process. In situ experiments are usually performed with area detectors, collecting 2D images composed of diffraction rings for ideal powders. Depending on the material's form, one may observe different characteristics other than the typical Debye Scherrer rings for a realistic sample and its environments, such as textures or preferred orientations and single crystal diffraction spots in the 2D XRD image. In this work, we present an investigation of machine learning methods for fast and reliable identification and separation of the single crystal diffraction spots in XRD images. The exclusion of artifacts during an XRD image integration process allows a precise analysis of the powder diffraction rings of interest. We observe that the gradient boosting method can consistently produce high accuracy results when it is trained with small subsets of highly diverse datasets. The method dramatically decreases the amount of time spent on identifying and separating single crystal spots in comparison to the conventional method.

</p>
</details>

<details><summary><b>Towards Unconstrained Audio Splicing Detection and Localization with Neural Networks</b>
<a href="https://arxiv.org/abs/2207.14682">arxiv:2207.14682</a>
&#x1F4C8; 7 <br>
<p>Denise Moussa, Germans Hirsch, Christian Riess</p></summary>
<p>

**Abstract:** Freely available and easy-to-use audio editing tools make it straightforward to perform audio splicing. Convincing forgeries can be created by combining various speech samples from the same person. Detection of such splices is important both in the public sector when considering misinformation, and in a legal context to verify the integrity of evidence. Unfortunately, most existing detection algorithms for audio splicing use handcrafted features and make specific assumptions. However, criminal investigators are often faced with audio samples from unconstrained sources with unknown characteristics, which raises the need for more generally applicable methods.
  With this work, we aim to take a first step towards unconstrained audio splicing detection to address this need. We simulate various attack scenarios in the form of post-processing operations that may disguise splicing. We propose a Transformer sequence-to-sequence (seq2seq) network for splicing detection and localization. Our extensive evaluation shows that the proposed method outperforms existing dedicated approaches for splicing detection [3, 10] as well as the general-purpose networks EfficientNet [28] and RegNet [25].

</p>
</details>

<details><summary><b>Going Off-Grid: Continuous Implicit Neural Representations for 3D Vascular Modeling</b>
<a href="https://arxiv.org/abs/2207.14663">arxiv:2207.14663</a>
&#x1F4C8; 7 <br>
<p>Dieuwertje Alblas, Christoph Brune, Kak Khee Yeung, Jelmer M. Wolterink</p></summary>
<p>

**Abstract:** Personalised 3D vascular models are valuable for diagnosis, prognosis and treatment planning in patients with cardiovascular disease. Traditionally, such models have been constructed with explicit representations such as meshes and voxel masks, or implicit representations such as radial basis functions or atomic (tubular) shapes. Here, we propose to represent surfaces by the zero level set of their signed distance function (SDF) in a differentiable implicit neural representation (INR). This allows us to model complex vascular structures with a representation that is implicit, continuous, light-weight, and easy to integrate with deep learning algorithms. We here demonstrate the potential of this approach with three practical examples. First, we obtain an accurate and watertight surface for an abdominal aortic aneurysm (AAA) from CT images and show robust fitting from as little as 200 points on the surface. Second, we simultaneously fit nested vessel walls in a single INR without intersections. Third, we show how 3D models of individual arteries can be smoothly blended into a single watertight surface. Our results show that INRs are a flexible representation with potential for minimally interactive annotation and manipulation of complex vascular structures.

</p>
</details>

<details><summary><b>Decentralized Machine Learning for Intelligent Health Care Systems on the Computing Continuum</b>
<a href="https://arxiv.org/abs/2207.14584">arxiv:2207.14584</a>
&#x1F4C8; 7 <br>
<p>Dragi Kimovski, Sasko Ristov, Radu Prodan</p></summary>
<p>

**Abstract:** The introduction of electronic personal health records (EHR) enables nationwide information exchange and curation among different health care systems. However, the current EHR systems do not provide transparent means for diagnosis support, medical research or can utilize the omnipresent data produced by the personal medical devices. Besides, the EHR systems are centrally orchestrated, which could potentially lead to a single point of failure. Therefore, in this article, we explore novel approaches for decentralizing machine learning over distributed ledgers to create intelligent EHR systems that can utilize information from personal medical devices for improved knowledge extraction. Consequently, we proposed and evaluated a conceptual EHR to enable anonymous predictive analysis across multiple medical institutions. The evaluation results indicate that the decentralized EHR can be deployed over the computing continuum with reduced machine learning time of up to 60% and consensus latency of below 8 seconds.

</p>
</details>

<details><summary><b>Robust Rayleigh Regression Method for SAR Image Processing in Presence of Outliers</b>
<a href="https://arxiv.org/abs/2208.00097">arxiv:2208.00097</a>
&#x1F4C8; 6 <br>
<p>B. G. Palm, F. M. Bayer, R. Machado, M. I. Pettersson, V. T. Vu, R. J. Cintra</p></summary>
<p>

**Abstract:** The presence of outliers (anomalous values) in synthetic aperture radar (SAR) data and the misspecification in statistical image models may result in inaccurate inferences. To avoid such issues, the Rayleigh regression model based on a robust estimation process is proposed as a more realistic approach to model this type of data. This paper aims at obtaining Rayleigh regression model parameter estimators robust to the presence of outliers. The proposed approach considered the weighted maximum likelihood method and was submitted to numerical experiments using simulated and measured SAR images. Monte Carlo simulations were employed for the numerical assessment of the proposed robust estimator performance in finite signal lengths, their sensitivity to outliers, and the breakdown point. For instance, the non-robust estimators show a relative bias value $65$-fold larger than the results provided by the robust approach in corrupted signals. In terms of sensitivity analysis and break down point, the robust scheme resulted in a reduction of about $96\%$ and $10\%$, respectively, in the mean absolute value of both measures, in compassion to the non-robust estimators. Moreover, two SAR data sets were used to compare the ground type and anomaly detection results of the proposed robust scheme with competing methods in the literature.

</p>
</details>

<details><summary><b>Low-complexity Approximate Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2208.00087">arxiv:2208.00087</a>
&#x1F4C8; 6 <br>
<p>R. J. Cintra, S. Duffner, C. Garcia, A. Leite</p></summary>
<p>

**Abstract:** In this paper, we present an approach for minimizing the computational complexity of trained Convolutional Neural Networks (ConvNet). The idea is to approximate all elements of a given ConvNet and replace the original convolutional filters and parameters (pooling and bias coefficients; and activation function) with efficient approximations capable of extreme reductions in computational complexity. Low-complexity convolution filters are obtained through a binary (zero-one) linear programming scheme based on the Frobenius norm over sets of dyadic rationals. The resulting matrices allow for multiplication-free computations requiring only addition and bit-shifting operations. Such low-complexity structures pave the way for low-power, efficient hardware designs. We applied our approach on three use cases of different complexity: (i) a "light" but efficient ConvNet for face detection (with around 1000 parameters); (ii) another one for hand-written digit classification (with more than 180000 parameters); and (iii) a significantly larger ConvNet: AlexNet with $\approx$1.2 million matrices. We evaluated the overall performance on the respective tasks for different levels of approximations. In all considered applications, very low-complexity approximations have been derived maintaining an almost equal classification performance.

</p>
</details>

<details><summary><b>Contrastive UCB: Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2207.14800">arxiv:2207.14800</a>
&#x1F4C8; 6 <br>
<p>Shuang Qiu, Lingxiao Wang, Chenjia Bai, Zhuoran Yang, Zhaoran Wang</p></summary>
<p>

**Abstract:** In view of its power in extracting feature representation, contrastive self-supervised learning has been successfully integrated into the practice of (deep) reinforcement learning (RL), leading to efficient policy learning in various applications. Despite its tremendous empirical successes, the understanding of contrastive learning for RL remains elusive. To narrow such a gap, we study how RL can be empowered by contrastive learning in a class of Markov decision processes (MDPs) and Markov games (MGs) with low-rank transitions. For both models, we propose to extract the correct feature representations of the low-rank model by minimizing a contrastive loss. Moreover, under the online setting, we propose novel upper confidence bound (UCB)-type algorithms that incorporate such a contrastive loss with online RL algorithms for MDPs or MGs. We further theoretically prove that our algorithm recovers the true representations and simultaneously achieves sample efficiency in learning the optimal policy and Nash equilibrium in MDPs and MGs. We also provide empirical studies to demonstrate the efficacy of the UCB-based contrastive learning method for RL. To the best of our knowledge, we provide the first provably efficient online RL algorithm that incorporates contrastive learning for representation learning. Our codes are available at https://github.com/Baichenjia/Contrastive-UCB.

</p>
</details>

<details><summary><b>Rating the Crisis of Online Public Opinion Using a Multi-Level Index System</b>
<a href="https://arxiv.org/abs/2207.14740">arxiv:2207.14740</a>
&#x1F4C8; 6 <br>
<p>Fanqi Meng, Xixi Xiao, Jingdong Wang</p></summary>
<p>

**Abstract:** Online public opinion usually spreads rapidly and widely, thus a small incident probably evolves into a large social crisis in a very short time, and results in a heavy loss in credit or economic aspects. We propose a method to rate the crisis of online public opinion based on a multi-level index system to evaluate the impact of events objectively. Firstly, the dissemination mechanism of online public opinion is explained from the perspective of information ecology. According to the mechanism, some evaluation indexes are selected through correlation analysis and principal component analysis. Then, a classification model of text emotion is created via the training by deep learning to achieve the accurate quantification of the emotional indexes in the index system. Finally, based on the multi-level evaluation index system and grey correlation analysis, we propose a method to rate the crisis of online public opinion. The experiment with the real-time incident show that this method can objectively evaluate the emotional tendency of Internet users and rate the crisis in different dissemination stages of online public opinion. It is helpful to realizing the crisis warning of online public opinion and timely blocking the further spread of the crisis.

</p>
</details>

<details><summary><b>Forensic License Plate Recognition with Compression-Informed Transformers</b>
<a href="https://arxiv.org/abs/2207.14686">arxiv:2207.14686</a>
&#x1F4C8; 6 <br>
<p>Denise Moussa, Anatol Maier, Andreas Spruck, Jürgen Seiler, Christian Riess</p></summary>
<p>

**Abstract:** Forensic license plate recognition (FLPR) remains an open challenge in legal contexts such as criminal investigations, where unreadable license plates (LPs) need to be deciphered from highly compressed and/or low resolution footage, e.g., from surveillance cameras. In this work, we propose a side-informed Transformer architecture that embeds knowledge on the input compression level to improve recognition under strong compression. We show the effectiveness of Transformers for license plate recognition (LPR) on a low-quality real-world dataset. We also provide a synthetic dataset that includes strongly degraded, illegible LP images and analyze the impact of knowledge embedding on it. The network outperforms existing FLPR methods and standard state-of-the art image recognition models while requiring less parameters. For the severest degraded images, we can improve recognition by up to 8.9 percent points.

</p>
</details>

<details><summary><b>SYNTA: A novel approach for deep learning-based image analysis in muscle histopathology using photo-realistic synthetic data</b>
<a href="https://arxiv.org/abs/2207.14650">arxiv:2207.14650</a>
&#x1F4C8; 6 <br>
<p>Leonid Mill, Oliver Aust, Jochen A. Ackermann, Philipp Burger, Monica Pascual, Katrin Palumbo-Zerr, Gerhard Krönke, Stefan Uderhardt, Georg Schett, Christoph S. Clemen, Rolf Schröder, Christian Holtzhausen, Samir Jabari, Andreas Maier, Anika Grüneboom</p></summary>
<p>

**Abstract:** Artificial intelligence (AI), machine learning, and deep learning (DL) methods are becoming increasingly important in the field of biomedical image analysis. However, to exploit the full potential of such methods, a representative number of experimentally acquired images containing a significant number of manually annotated objects is needed as training data. Here we introduce SYNTA (synthetic data) as a novel approach for the generation of synthetic, photo-realistic, and highly complex biomedical images as training data for DL systems. We show the versatility of our approach in the context of muscle fiber and connective tissue analysis in histological sections. We demonstrate that it is possible to perform robust and expert-level segmentation tasks on previously unseen real-world data, without the need for manual annotations using synthetic training data alone. Being a fully parametric technique, our approach poses an interpretable and controllable alternative to Generative Adversarial Networks (GANs) and has the potential to significantly accelerate quantitative image analysis in a variety of biomedical applications in microscopy and beyond.

</p>
</details>

<details><summary><b>KG-NSF: Knowledge Graph Completion with a Negative-Sample-Free Approach</b>
<a href="https://arxiv.org/abs/2207.14617">arxiv:2207.14617</a>
&#x1F4C8; 6 <br>
<p>Adil Bahaj, Safae Lhazmir, Mounir Ghogho</p></summary>
<p>

**Abstract:** Knowledge Graph (KG) completion is an important task that greatly benefits knowledge discovery in many fields (e.g. biomedical research). In recent years, learning KG embeddings to perform this task has received considerable attention. Despite the success of KG embedding methods, they predominantly use negative sampling, resulting in increased computational complexity as well as biased predictions due to the closed world assumption. To overcome these limitations, we propose \textbf{KG-NSF}, a negative sampling-free framework for learning KG embeddings based on the cross-correlation matrices of embedding vectors. It is shown that the proposed method achieves comparable link prediction performance to negative sampling-based methods while converging much faster.

</p>
</details>

<details><summary><b>Transfer Learning for Segmentation Problems: Choose the Right Encoder and Skip the Decoder</b>
<a href="https://arxiv.org/abs/2207.14508">arxiv:2207.14508</a>
&#x1F4C8; 6 <br>
<p>Jonas Dippel, Matthias Lenga, Thomas Goerttler, Klaus Obermayer, Johannes Höhne</p></summary>
<p>

**Abstract:** It is common practice to reuse models initially trained on different data to increase downstream task performance. Especially in the computer vision domain, ImageNet-pretrained weights have been successfully used for various tasks. In this work, we investigate the impact of transfer learning for segmentation problems, being pixel-wise classification problems that can be tackled with encoder-decoder architectures. We find that transfer learning the decoder does not help downstream segmentation tasks, while transfer learning the encoder is truly beneficial. We demonstrate that pretrained weights for a decoder may yield faster convergence, but they do not improve the overall model performance as one can obtain equivalent results with randomly initialized decoders. However, we show that it is more effective to reuse encoder weights trained on a segmentation or reconstruction task than reusing encoder weights trained on classification tasks. This finding implicates that using ImageNet-pretrained encoders for downstream segmentation problems is suboptimal. We also propose a contrastive self-supervised approach with multiple self-reconstruction tasks, which provides encoders that are suitable for transfer learning in segmentation problems in the absence of segmentation labels.

</p>
</details>

<details><summary><b>SHAP for additively modeled features in a boosted trees model</b>
<a href="https://arxiv.org/abs/2207.14490">arxiv:2207.14490</a>
&#x1F4C8; 6 <br>
<p>Michael Mayer</p></summary>
<p>

**Abstract:** An important technique to explore a black-box machine learning (ML) model is called SHAP (SHapley Additive exPlanation). SHAP values decompose predictions into contributions of the features in a fair way. We will show that for a boosted trees model with some or all features being additively modeled, the SHAP dependence plot of such a feature corresponds to its partial dependence plot up to a vertical shift. We illustrate the result with XGBoost.

</p>
</details>

<details><summary><b>Enhanced gradient-based MCMC in discrete spaces</b>
<a href="https://arxiv.org/abs/2208.00040">arxiv:2208.00040</a>
&#x1F4C8; 5 <br>
<p>Benjamin Rhodes, Michael Gutmann</p></summary>
<p>

**Abstract:** The recent introduction of gradient-based MCMC for discrete spaces holds great promise, and comes with the tantalising possibility of new discrete counterparts to celebrated continuous methods such as MALA and HMC. Towards this goal, we introduce several discrete Metropolis-Hastings samplers that are conceptually-inspired by MALA, and demonstrate their strong empirical performance across a range of challenging sampling problems in Bayesian inference and energy-based modelling. Methodologically, we identify why discrete analogues to preconditioned MALA are generally intractable, motivating us to introduce a new kind of preconditioning based on auxiliary variables and the `Gaussian integral trick'.

</p>
</details>

<details><summary><b>MulViMotion: Shape-aware 3D Myocardial Motion Tracking from Multi-View Cardiac MRI</b>
<a href="https://arxiv.org/abs/2208.00034">arxiv:2208.00034</a>
&#x1F4C8; 5 <br>
<p>Qingjie Meng, Chen Qin, Wenjia Bai, Tianrui Liu, Antonio de Marvao, Declan P O'Regan, Daniel Rueckert</p></summary>
<p>

**Abstract:** Recovering the 3D motion of the heart from cine cardiac magnetic resonance (CMR) imaging enables the assessment of regional myocardial function and is important for understanding and analyzing cardiovascular disease. However, 3D cardiac motion estimation is challenging because the acquired cine CMR images are usually 2D slices which limit the accurate estimation of through-plane motion. To address this problem, we propose a novel multi-view motion estimation network (MulViMotion), which integrates 2D cine CMR images acquired in short-axis and long-axis planes to learn a consistent 3D motion field of the heart. In the proposed method, a hybrid 2D/3D network is built to generate dense 3D motion fields by learning fused representations from multi-view images. To ensure that the motion estimation is consistent in 3D, a shape regularization module is introduced during training, where shape information from multi-view images is exploited to provide weak supervision to 3D motion estimation. We extensively evaluate the proposed method on 2D cine CMR images from 580 subjects of the UK Biobank study for 3D motion tracking of the left ventricular myocardium. Experimental results show that the proposed method quantitatively and qualitatively outperforms competing methods.

</p>
</details>

<details><summary><b>Personalised recommendations of sleep behaviour with neural networks using sleep diaries captured in Sleepio</b>
<a href="https://arxiv.org/abs/2208.00033">arxiv:2208.00033</a>
&#x1F4C8; 5 <br>
<p>Alejo Nevado-Holgado, Colin Espie, Maria Liakata, Alasdair Henry, Jenny Gu, Niall Taylor, Kate Saunders, Tom Walker, Chris Miller</p></summary>
<p>

**Abstract:** SleepioTM is a digital mobile phone and web platform that uses techniques from cognitive behavioural therapy (CBT) to improve sleep in people with sleep difficulty. As part of this process, Sleepio captures data about the sleep behaviour of the users that have consented to such data being processed. For neural networks, the scale of the data is an opportunity to train meaningful models translatable to actual clinical practice. In collaboration with Big Health, the therapeutics company that created and utilizes Sleepio, we have analysed data from a random sample of 401,174 sleep diaries and built a neural network to model sleep behaviour and sleep quality of each individual in a personalised manner. We demonstrate that this neural network is more accurate than standard statistical methods in predicting the sleep quality of an individual based on his/her behaviour from the last 10 days. We compare model performance in a wide range of hyperparameter settings representing various scenarios. We further show that the neural network can be used to produce personalised recommendations of what sleep habits users should follow to maximise sleep quality, and show that these recommendations are substantially better than the ones generated by standard methods. We finally show that the neural network can explain the recommendation given to each participant and calculate confidence intervals for each prediction, all of which are essential for clinicians to be able to adopt such a tool in clinical practice.

</p>
</details>

<details><summary><b>Using Multi-modal Data for Improving Generalizability and Explainability of Disease Classification in Radiology</b>
<a href="https://arxiv.org/abs/2207.14781">arxiv:2207.14781</a>
&#x1F4C8; 5 <br>
<p>Pranav Agnihotri, Sara Ketabi,  Khashayar,  Namdar, Farzad Khalvati</p></summary>
<p>

**Abstract:** Traditional datasets for the radiological diagnosis tend to only provide the radiology image alongside the radiology report. However, radiology reading as performed by radiologists is a complex process, and information such as the radiologist's eye-fixations over the course of the reading has the potential to be an invaluable data source to learn from. Nonetheless, the collection of such data is expensive and time-consuming. This leads to the question of whether such data is worth the investment to collect. This paper utilizes the recently published Eye-Gaze dataset to perform an exhaustive study on the impact on performance and explainability of deep learning (DL) classification in the face of varying levels of input features, namely: radiology images, radiology report text, and radiologist eye-gaze data. We find that the best classification performance of X-ray images is achieved with a combination of radiology report free-text and radiology image, with the eye-gaze data providing no performance boost. Nonetheless, eye-gaze data serving as secondary ground truth alongside the class label results in highly explainable models that generate better attention maps compared to models trained to do classification and attention map generation without eye-gaze data.

</p>
</details>

<details><summary><b>Tangential Wasserstein Projections</b>
<a href="https://arxiv.org/abs/2207.14727">arxiv:2207.14727</a>
&#x1F4C8; 5 <br>
<p>Florian Gunsilius, Meng Hsuan Hsieh, Myung Jin Lee</p></summary>
<p>

**Abstract:** We develop a notion of projections between sets of probability measures using the geometric properties of the 2-Wasserstein space. It is designed for general multivariate probability measures, is computationally efficient to implement, and provides a unique solution in regular settings. The idea is to work on regular tangent cones of the Wasserstein space using generalized geodesics. Its structure and computational properties make the method applicable in a variety of settings, from causal inference to the analysis of object data. An application to estimating causal effects yields a generalization of the notion of synthetic controls to multivariate data with individual-level heterogeneity, as well as a way to estimate optimal weights jointly over all time periods.

</p>
</details>

<details><summary><b>Robust Quantitative Susceptibility Mapping via Approximate Message Passing</b>
<a href="https://arxiv.org/abs/2207.14709">arxiv:2207.14709</a>
&#x1F4C8; 5 <br>
<p>Shuai Huang, James J. Lah, Jason W. Allen, Deqiang Qiu</p></summary>
<p>

**Abstract:** Purpose: It has been challenging to recover QSM in the presence of phase errors, which could be caused by the noise or strong local susceptibility shifts in cases of brain hemorrhage and calcification. We propose a Bayesian formulation for QSM where a two-component Gaussian-mixture distribution is used to model the long-tailed noise (error) distribution, and design an approximate message passing (AMP) algorithm with automatic and adaptive parameter estimation.
  Theory: Wavelet coefficients of the susceptibility map follow the Laplace distribution. The measurement noise follows a two-component Gaussian-mixture distribution where the second Gaussian component models the noise outliers. The distribution parameters are treated as unknown variables and jointly recovered with the susceptibility using AMP.
  Methods: The proposed AMP with parameter estimation (AMP-PE) is compared with the state-of-the-art nonlinear L1-QSM and MEDI approaches that adopt the L1-norm and L2-norm data-fidelity terms respectively. The three approaches are tested on the Sim2Snr1 data from QSM challenge 2.0, the in vivo data from both healthy and hemorrhage scans.
  Results: On the simulated Sim2Snr1 dataset, AMP-PE achieved the lowest NRMSE and SSIM, MEDI achieved the lowest HFEN, and each approach also has its own strong suit when it comes to various local evaluation metrics. On the in vivo dataset, AMP-PE is better at preserving structural details and removing streaking artifacts than L1-QSM and MEDI.
  Conclusion: By leveraging a customized Gaussian-mixture noise prior, AMP-PE achieves better performance on the challenging QSM cases involving hemorrhage and calcification. It is equipped with built-in parameter estimation, which avoids subjective bias from the usual visual fine-tuning step of in vivo reconstruction.

</p>
</details>

<details><summary><b>Enhanced Laser-Scan Matching with Online Error Estimation for Highway and Tunnel Driving</b>
<a href="https://arxiv.org/abs/2207.14674">arxiv:2207.14674</a>
&#x1F4C8; 5 <br>
<p>Matthew McDermott, Jason Rife</p></summary>
<p>

**Abstract:** Lidar data can be used to generate point clouds for the navigation of autonomous vehicles or mobile robotics platforms. Scan matching, the process of estimating the rigid transformation that best aligns two point clouds, is the basis for lidar odometry, a form of dead reckoning. Lidar odometry is particularly useful when absolute sensors, like GPS, are not available. Here we propose the Iterative Closest Ellipsoidal Transform (ICET), a scan matching algorithm which provides two novel improvements over the current state-of-the-art Normal Distributions Transform (NDT). Like NDT, ICET decomposes lidar data into voxels and fits a Gaussian distribution to the points within each voxel. The first innovation of ICET reduces geometric ambiguity along large flat surfaces by suppressing the solution along those directions. The second innovation of ICET is to infer the output error covariance associated with the position and orientation transformation between successive point clouds; the error covariance is particularly useful when ICET is incorporated into a state-estimation routine such as an extended Kalman filter. We constructed a simulation to compare the performance of ICET and NDT in 2D space both with and without geometric ambiguity and found that ICET produces superior estimates while accurately predicting solution accuracy.

</p>
</details>

<details><summary><b>Restoring Vision in Adverse Weather Conditions with Patch-Based Denoising Diffusion Models</b>
<a href="https://arxiv.org/abs/2207.14626">arxiv:2207.14626</a>
&#x1F4C8; 5 <br>
<p>Ozan Özdenizci, Robert Legenstein</p></summary>
<p>

**Abstract:** Image restoration under adverse weather conditions has been of significant interest for various computer vision applications. Recent successful methods rely on the current progress in deep neural network architectural designs (e.g., with vision transformers). Motivated by the recent progress achieved with state-of-the-art conditional generative models, we present a novel patch-based image restoration algorithm based on denoising diffusion probabilistic models. Our patch-based diffusion modeling approach enables size-agnostic image restoration by using a guided denoising process with smoothed noise estimates across overlapping patches during inference. We empirically evaluate our model on benchmark datasets for image desnowing, combined deraining and dehazing, and raindrop removal. We demonstrate our approach to achieve state-of-the-art performances on both weather-specific and multi-weather image restoration, and qualitatively show strong generalization to real-world test images.

</p>
</details>

<details><summary><b>Content-Aware Differential Privacy with Conditional Invertible Neural Networks</b>
<a href="https://arxiv.org/abs/2207.14625">arxiv:2207.14625</a>
&#x1F4C8; 5 <br>
<p>Malte Tölle, Ullrich Köthe, Florian André, Benjamin Meder, Sandy Engelhardt</p></summary>
<p>

**Abstract:** Differential privacy (DP) has arisen as the gold standard in protecting an individual's privacy in datasets by adding calibrated noise to each data sample. While the application to categorical data is straightforward, its usability in the context of images has been limited. Contrary to categorical data the meaning of an image is inherent in the spatial correlation of neighboring pixels making the simple application of noise infeasible. Invertible Neural Networks (INN) have shown excellent generative performance while still providing the ability to quantify the exact likelihood. Their principle is based on transforming a complicated distribution into a simple one e.g. an image into a spherical Gaussian. We hypothesize that adding noise to the latent space of an INN can enable differentially private image modification. Manipulation of the latent space leads to a modified image while preserving important details. Further, by conditioning the INN on meta-data provided with the dataset we aim at leaving dimensions important for downstream tasks like classification untouched while altering other parts that potentially contain identifying information. We term our method content-aware differential privacy (CADP). We conduct experiments on publicly available benchmarking datasets as well as dedicated medical ones. In addition, we show the generalizability of our method to categorical data. The source code is publicly available at https://github.com/Cardio-AI/CADP.

</p>
</details>

<details><summary><b>Image Augmentation for Satellite Images</b>
<a href="https://arxiv.org/abs/2207.14580">arxiv:2207.14580</a>
&#x1F4C8; 5 <br>
<p>Oluwadara Adedeji, Peter Owoade, Opeyemi Ajayi, Olayiwola Arowolo</p></summary>
<p>

**Abstract:** This study proposes the use of generative models (GANs) for augmenting the EuroSAT dataset for the Land Use and Land Cover (LULC) Classification task. We used DCGAN and WGAN-GP to generate images for each class in the dataset. We then explored the effect of augmenting the original dataset by about 10% in each case on model performance. The choice of GAN architecture seems to have no apparent effect on the model performance. However, a combination of geometric augmentation and GAN-generated images improved baseline results. Our study shows that GANs augmentation can improve the generalizability of deep classification models on satellite images.

</p>
</details>

<details><summary><b>A One-Shot Reparameterization Method for Reducing the Loss of Tile Pruning on DNNs</b>
<a href="https://arxiv.org/abs/2207.14545">arxiv:2207.14545</a>
&#x1F4C8; 5 <br>
<p>Yanchen Li, Qingzhong Ai, Fumihiko Ino</p></summary>
<p>

**Abstract:** Recently, tile pruning has been widely studied to accelerate the inference of deep neural networks (DNNs). However, we found that the loss due to tile pruning, which can eliminate important elements together with unimportant elements, is large on trained DNNs. In this study, we propose a one-shot reparameterization method, called TileTrans, to reduce the loss of tile pruning. Specifically, we repermute the rows or columns of the weight matrix such that the model architecture can be kept unchanged after reparameterization. This repermutation realizes the reparameterization of the DNN model without any retraining. The proposed reparameterization method combines important elements into the same tile; thus, preserving the important elements after the tile pruning. Furthermore, TileTrans can be seamlessly integrated into existing tile pruning methods because it is a pre-processing method executed before pruning, which is orthogonal to most existing methods. The experimental results demonstrate that our method is essential in reducing the loss of tile pruning on DNNs. Specifically, the accuracy is improved by up to 17% for AlexNet while 5% for ResNet-34, where both models are pre-trained on ImageNet.

</p>
</details>

<details><summary><b>Face-to-Face Contrastive Learning for Social Intelligence Question-Answering</b>
<a href="https://arxiv.org/abs/2208.01036">arxiv:2208.01036</a>
&#x1F4C8; 4 <br>
<p>Alex Wilf, Qianli M. Ma, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency</p></summary>
<p>

**Abstract:** Creating artificial social intelligence - algorithms that can understand the nuances of multi-person interactions - is an exciting and emerging challenge in processing facial expressions and gestures from multimodal videos. Recent multimodal methods have set the state of the art on many tasks, but have difficulty modeling the complex face-to-face conversational dynamics across speaking turns in social interaction, particularly in a self-supervised setup. In this paper, we propose Face-to-Face Contrastive Learning (F2F-CL), a graph neural network designed to model social interactions using factorization nodes to contextualize the multimodal face-to-face interaction along the boundaries of the speaking turn. With the F2F-CL model, we propose to perform contrastive learning between the factorization nodes of different speaking turns within the same video. We experimentally evaluated the challenging Social-IQ dataset and show state-of-the-art results.

</p>
</details>

<details><summary><b>Weakly Supervised Deep Instance Nuclei Detection using Points Annotation in 3D Cardiovascular Immunofluorescent Images</b>
<a href="https://arxiv.org/abs/2208.00098">arxiv:2208.00098</a>
&#x1F4C8; 4 <br>
<p>Nazanin Moradinasab, Yash Sharma, Laura S. Shankman, Gary K. Owens, Donald E. Brown</p></summary>
<p>

**Abstract:** Two major causes of death in the United States and worldwide are stroke and myocardial infarction. The underlying cause of both is thrombi released from ruptured or eroded unstable atherosclerotic plaques that occlude vessels in the heart (myocardial infarction) or the brain (stroke). Clinical studies show that plaque composition plays a more important role than lesion size in plaque rupture or erosion events. To determine the plaque composition, various cell types in 3D cardiovascular immunofluorescent images of plaque lesions are counted. However, counting these cells manually is expensive, time-consuming, and prone to human error. These challenges of manual counting motivate the need for an automated approach to localize and count the cells in images. The purpose of this study is to develop an automatic approach to accurately detect and count cells in 3D immunofluorescent images with minimal annotation effort. In this study, we used a weakly supervised learning approach to train the HoVer-Net segmentation model using point annotations to detect nuclei in fluorescent images. The advantage of using point annotations is that they require less effort as opposed to pixel-wise annotation. To train the HoVer-Net model using point annotations, we adopted a popularly used cluster labeling approach to transform point annotations into accurate binary masks of cell nuclei. Traditionally, these approaches have generated binary masks from point annotations, leaving a region around the object unlabeled (which is typically ignored during model training). However, these areas may contain important information that helps determine the boundary between cells. Therefore, we used the entropy minimization loss function in these areas to encourage the model to output more confident predictions on the unlabeled areas. Our comparison studies indicate that the HoVer-Net model trained using our weakly ...

</p>
</details>

<details><summary><b>Machine Learning and Computer Vision Techniques in Bee Monitoring Applications</b>
<a href="https://arxiv.org/abs/2208.00085">arxiv:2208.00085</a>
&#x1F4C8; 4 <br>
<p>Simon Bilik, Ondrej Bostik, Lukas Kratochvila, Adam Ligocki, Matej Poncak, Tomas Zemcik, Milos Richter, Ilona Janakova, Petr Honec, Karel Horak</p></summary>
<p>

**Abstract:** Machine learning and computer vision are dynamically growing fields, which have proven to be able to solve very complex tasks. They could also be used for the monitoring of the honeybee colonies and for the inspection of their health state, which could identify potentially dangerous states before the situation is critical, or to better plan periodic bee colony inspections and therefore save significant costs. In this paper, we present an overview of the state-of-the-art computer vision and machine learning applications used for bee monitoring. We also demonstrate the potential of those methods as an example of an automated bee counter algorithm. The paper is aimed at veterinary and apidology professionals and experts, who might not be familiar with machine learning to introduce to them its possibilities, therefore each family of applications is opened by a brief theoretical introduction and motivation related to its base method. We hope that this paper will inspire other scientists to use the machine learning techniques for other applications in bee monitoring.

</p>
</details>

<details><summary><b>A review of Deep learning Techniques for COVID-19 identification on Chest CT images</b>
<a href="https://arxiv.org/abs/2208.00032">arxiv:2208.00032</a>
&#x1F4C8; 4 <br>
<p>Briskline Kiruba S, Petchiammal A, D. Murugan</p></summary>
<p>

**Abstract:** The current COVID-19 pandemic is a serious threat to humanity that directly affects the lungs. Automatic identification of COVID-19 is a challenge for health care officials. The standard gold method for diagnosing COVID-19 is Reverse Transcription Polymerase Chain Reaction (RT-PCR) to collect swabs from affected people. Some limitations encountered while collecting swabs are related to accuracy and longtime duration. Chest CT (Computed Tomography) is another test method that helps healthcare providers quickly identify the infected lung areas. It was used as a supporting tool for identifying COVID-19 in an earlier stage. With the help of deep learning, the CT imaging characteristics of COVID-19. Researchers have proven it to be highly effective for COVID-19 CT image classification. In this study, we review the recent deep learning techniques that can use to detect the COVID-19 disease. Relevant studies were collected by various databases such as Web of Science, Google Scholar, and PubMed. Finally, we compare the results of different deep learning models, and CT image analysis is discussed.

</p>
</details>

<details><summary><b>Multimodal SuperCon: Classifier for Drivers of Deforestation in Indonesia</b>
<a href="https://arxiv.org/abs/2207.14656">arxiv:2207.14656</a>
&#x1F4C8; 4 <br>
<p>Bella Septina Ika Hartanti, Valentino Vito, Aniati Murni Arymurthy, Andie Setiyoko</p></summary>
<p>

**Abstract:** Deforestation is one of the contributing factors to climate change. Climate change has a serious impact on human life, and it occurs due to emission of greenhouse gases, such as carbon dioxide, to the atmosphere. It is important to know the causes of deforestation for mitigation efforts, but there is a lack of data-driven research studies to predict these deforestation drivers. In this work, we propose a contrastive learning architecture, called Multimodal SuperCon, for classifying drivers of deforestation in Indonesia using satellite images obtained from Landsat 8. Multimodal SuperCon is an architecture which combines contrastive learning and multimodal fusion to handle the available deforestation dataset. Our proposed model outperforms previous work on driver classification, giving a 7% improvement in accuracy in comparison to a state-of-the-art rotation equivariant model for the same task.

</p>
</details>

<details><summary><b>Computational complexity reduction of deep neural networks</b>
<a href="https://arxiv.org/abs/2207.14620">arxiv:2207.14620</a>
&#x1F4C8; 4 <br>
<p>Mee Seong Im, Venkat R. Dasari</p></summary>
<p>

**Abstract:** Deep neural networks (DNN) have been widely used and play a major role in the field of computer vision and autonomous navigation. However, these DNNs are computationally complex and their deployment over resource-constrained platforms is difficult without additional optimizations and customization.
  In this manuscript, we describe an overview of DNN architecture and propose methods to reduce computational complexity in order to accelerate training and inference speeds to fit them on edge computing platforms with low computational resources.

</p>
</details>

<details><summary><b>Archaeology of random recursive dags and Cooper-Frieze random networks</b>
<a href="https://arxiv.org/abs/2207.14601">arxiv:2207.14601</a>
&#x1F4C8; 4 <br>
<p>Simon Briend, Francisco Calvillo, Gábor Lugosi</p></summary>
<p>

**Abstract:** We study the problem of finding the root vertex in large growing networks. We prove that it is possible to construct confidence sets of size independent of the number of vertices in the network that contain the root vertex with high probability in various models of random networks. The models include uniform random recursive dags and uniform Cooper-Frieze random graphs.

</p>
</details>

<details><summary><b>Stochastic Parallelizable Eigengap Dilation for Large Graph Clustering</b>
<a href="https://arxiv.org/abs/2207.14589">arxiv:2207.14589</a>
&#x1F4C8; 4 <br>
<p>Elise van der Pol, Ian Gemp, Yoram Bachrach, Richard Everett</p></summary>
<p>

**Abstract:** Large graphs commonly appear in social networks, knowledge graphs, recommender systems, life sciences, and decision making problems. Summarizing large graphs by their high level properties is helpful in solving problems in these settings. In spectral clustering, we aim to identify clusters of nodes where most edges fall within clusters and only few edges fall between clusters. This task is important for many downstream applications and exploratory analysis. A core step of spectral clustering is performing an eigendecomposition of the corresponding graph Laplacian matrix (or equivalently, a singular value decomposition, SVD, of the incidence matrix). The convergence of iterative singular value decomposition approaches depends on the eigengaps of the spectrum of the given matrix, i.e., the difference between consecutive eigenvalues. For a graph Laplacian corresponding to a well-clustered graph, the eigenvalues will be non-negative but very small (much less than $1$) slowing convergence. This paper introduces a parallelizable approach to dilating the spectrum in order to accelerate SVD solvers and in turn, spectral clustering. This is accomplished via polynomial approximations to matrix operations that favorably transform the spectrum of a matrix without changing its eigenvectors. Experiments demonstrate that this approach significantly accelerates convergence, and we explain how this transformation can be parallelized and stochastically approximated to scale with available compute.

</p>
</details>

<details><summary><b>Reweighted Manifold Learning of Collective Variables from Enhanced Sampling Simulations</b>
<a href="https://arxiv.org/abs/2207.14554">arxiv:2207.14554</a>
&#x1F4C8; 4 <br>
<p>Jakub Rydzewski, Ming Chen, Tushar K. Ghosh, Omar Valsson</p></summary>
<p>

**Abstract:** Enhanced sampling methods are indispensable in computational physics and chemistry, where atomistic simulations cannot exhaustively sample the high-dimensional configuration space of dynamical systems due to the sampling problem. A class of such enhanced sampling methods works by identifying a few slow degrees of freedom, termed collective variables (CVs), and enhancing the sampling along these CVs. Selecting CVs to analyze and drive the sampling is not trivial and often relies on physical and chemical intuition. Despite routinely circumventing this issue using manifold learning to estimate CVs directly from standard simulations, such methods cannot provide mappings to a low-dimensional manifold from enhanced sampling simulations as the geometry and density of the learned manifold are biased. Here, we address this crucial issue and provide a general reweighting framework based on anisotropic diffusion maps for manifold learning that takes into account that the learning data set is sampled from a biased probability distribution. We consider manifold learning methods based on constructing a Markov chain describing transition probabilities between high-dimensional samples. We show that our framework reverts the biasing effect yielding CVs that correctly describe the equilibrium density. This advancement enables the construction of low-dimensional CVs using manifold learning directly from data generated by enhanced sampling simulations. We call our framework reweighted manifold learning. We show that it can be used in many manifold learning techniques on data from both standard and enhanced sampling simulations.

</p>
</details>

<details><summary><b>Best-of-Both-Worlds Algorithms for Partial Monitoring</b>
<a href="https://arxiv.org/abs/2207.14550">arxiv:2207.14550</a>
&#x1F4C8; 4 <br>
<p>Taira Tsuchiya, Shinji Ito, Junya Honda</p></summary>
<p>

**Abstract:** This paper considers the partial monitoring problem with $k$-actions and $d$-outcomes and provides the first best-of-both-worlds algorithms, whose regrets are bounded poly-logarithmically in the stochastic regime and near-optimally in the adversarial regime. To be more specific, we show that for non-degenerate locally observable games, the regret in the stochastic regime is bounded by $O(k^3 m^2 \log(T) \log(k_Π T) / Δ_{\mathrm{\min}})$ and in the adversarial regime by $O(k^{2/3} m \sqrt{T \log(T) \log k_Π})$, where $T$ is the number of rounds, $m$ is the maximum number of distinct observations per action, $Δ_{\min}$ is the minimum optimality gap, and $k_Π$ is the number of Pareto optimal actions. Moreover, we show that for non-degenerate globally observable games, the regret in the stochastic regime is bounded by $O(\max\{c_{\mathcal{G}}^2 / k,\, c_{\mathcal{G}}\} \log(T) \log(k_Π T) / Δ_{\min}^2)$ and in the adversarial regime by $O((\max\{c_{\mathcal{G}}^2 / k,\, c_{\mathcal{G}}\} \log(T) \log(k_Π T)))^{1/3} T^{2/3})$, where $c_{\mathcal{G}}$ is a game-dependent constant. Our algorithms are based on the follow-the-regularized-leader framework that takes into account the nature of the partial monitoring problem, inspired by algorithms in the field of online learning with feedback graphs.

</p>
</details>

<details><summary><b>Contrastive Pre-training of Spatial-Temporal Trajectory Embeddings</b>
<a href="https://arxiv.org/abs/2207.14539">arxiv:2207.14539</a>
&#x1F4C8; 4 <br>
<p>Yan Lin, Huaiyu Wan, Shengnan Guo, Youfang Lin</p></summary>
<p>

**Abstract:** Pre-training trajectory embeddings is a fundamental and critical procedure in spatial-temporal trajectory mining, and is beneficial for a wide range of downstream tasks. The key for generating effective trajectory embeddings is to extract high-level travel semantics from trajectories, including movement patterns and travel purposes, with consideration of the trajectories' long-term spatial-temporal correlations. Despite the existing efforts, there are still major challenges in pre-training trajectory embeddings. First, commonly used generative pretext tasks are not suitable for extracting high-level semantics from trajectories. Second, existing data augmentation methods fit badly on trajectory datasets. Third, current encoder designs fail to fully incorporate long-term spatial-temporal correlations hidden in trajectories. To tackle these challenges, we propose a novel Contrastive Spatial-Temporal Trajectory Embedding (CSTTE) model for learning comprehensive trajectory embeddings. CSTTE adopts the contrastive learning framework so that its pretext task is robust to noise. A specially designed data augmentation method for trajectories is coupled with the contrastive pretext task to preserve the high-level travel semantics. We also build an efficient spatial-temporal trajectory encoder to efficiently and comprehensively model the long-term spatial-temporal correlations in trajectories. Extensive experiments on two downstream tasks and three real-world datasets prove the superiority of our model compared with the existing trajectory embedding methods.

</p>
</details>

<details><summary><b>Factorizable Joint Shift in Multinomial Classification</b>
<a href="https://arxiv.org/abs/2207.14514">arxiv:2207.14514</a>
&#x1F4C8; 4 <br>
<p>Dirk Tasche</p></summary>
<p>

**Abstract:** Factorizable joint shift was recently proposed as a type of dataset shift for which the characteristics can be estimated from observed data. For the multinomial (multi-class) classification setting, we derive a representation of factorizable joint shift in terms of the source (training) distribution, the target (test) prior class probabilities and the target marginal distribution of the features. On the basis of this result, we propose alternatives to joint importance aligning, at the same time pointing out the limitations encountered when making an assumption of factorizable joint shift. Other results of the paper include correction formulae for the posterior class probabilities both under general dataset shift and factorizable joint shift. In addition, we investigate the consequences of assuming factorizable joint shift for the bias caused by sample selection.

</p>
</details>

<details><summary><b>Meta Reinforcement Learning with Successor Feature Based Context</b>
<a href="https://arxiv.org/abs/2207.14723">arxiv:2207.14723</a>
&#x1F4C8; 3 <br>
<p>Xu Han, Feng Wu</p></summary>
<p>

**Abstract:** Most reinforcement learning (RL) methods only focus on learning a single task from scratch and are not able to use prior knowledge to learn other tasks more effectively. Context-based meta RL techniques are recently proposed as a possible solution to tackle this. However, they are usually less efficient than conventional RL and may require many trial-and-errors during training. To address this, we propose a novel meta-RL approach that achieves competitive performance comparing to existing meta-RL algorithms, while requires significantly fewer environmental interactions. By combining context variables with the idea of decomposing reward in successor feature framework, our method does not only learn high-quality policies for multiple tasks simultaneously but also can quickly adapt to new tasks with a small amount of training. Compared with state-of-the-art meta-RL baselines, we empirically show the effectiveness and data efficiency of our method on several continuous control tasks.

</p>
</details>

<details><summary><b>Automatic Reward Design via Learning Motivation-Consistent Intrinsic Rewards</b>
<a href="https://arxiv.org/abs/2207.14722">arxiv:2207.14722</a>
&#x1F4C8; 3 <br>
<p>Yixiang Wang, Yujing Hu, Feng Wu, Yingfeng Chen</p></summary>
<p>

**Abstract:** Reward design is a critical part of the application of reinforcement learning, the performance of which strongly depends on how well the reward signal frames the goal of the designer and how well the signal assesses progress in reaching that goal. In many cases, the extrinsic rewards provided by the environment (e.g., win or loss of a game) are very sparse and make it difficult to train agents directly. Researchers usually assist the learning of agents by adding some auxiliary rewards in practice. However, designing auxiliary rewards is often turned to a trial-and-error search for reward settings that produces acceptable results. In this paper, we propose to automatically generate goal-consistent intrinsic rewards for the agent to learn, by maximizing which the expected accumulative extrinsic rewards can be maximized. To this end, we introduce the concept of motivation which captures the underlying goal of maximizing certain rewards and propose the motivation based reward design method. The basic idea is to shape the intrinsic rewards by minimizing the distance between the intrinsic and extrinsic motivations. We conduct extensive experiments and show that our method performs better than the state-of-the-art methods in handling problems of delayed reward, exploration, and credit assignment.

</p>
</details>

<details><summary><b>Improving Small Lesion Segmentation in CT Scans using Intensity Distribution Supervision: Application to Small Bowel Carcinoid Tumor</b>
<a href="https://arxiv.org/abs/2207.14700">arxiv:2207.14700</a>
&#x1F4C8; 3 <br>
<p>Seung Yeon Shin, Thomas C. Shen, Stephen A. Wank, Ronald M. Summers</p></summary>
<p>

**Abstract:** Finding small lesions is very challenging due to lack of noticeable features, severe class imbalance, as well as the size itself. One approach to improve small lesion segmentation is to reduce the region of interest and inspect it at a higher sensitivity rather than performing it for the entire region. It is usually implemented as sequential or joint segmentation of organ and lesion, which requires additional supervision on organ segmentation. Instead, we propose to utilize an intensity distribution of a target lesion at no additional labeling cost to effectively separate regions where the lesions are possibly located from the background. It is incorporated into network training as an auxiliary task. We applied the proposed method to segmentation of small bowel carcinoid tumors in CT scans. We observed improvements for all metrics (33.5% $\rightarrow$ 38.2%, 41.3% $\rightarrow$ 47.8%, 30.0% $\rightarrow$ 35.9% for the global, per case, and per tumor Dice scores, respectively.) compared to the baseline method, which proves the validity of our idea. Our method can be one option for explicitly incorporating intensity distribution information of a target in network training.

</p>
</details>

<details><summary><b>A Graph Theoretic Exploration of Coronary Vascular Trees</b>
<a href="https://arxiv.org/abs/2207.14624">arxiv:2207.14624</a>
&#x1F4C8; 3 <br>
<p>Jay Aodh Mackenzie</p></summary>
<p>

**Abstract:** The aim of this study was to automate the generation of small coronary vascular networks from large point clouds that represent the coronary arterial network. Smaller networks that can be generated in a predictable manner can be used to assess the impact of network morphometry on, for example, blood flow in hemodynamic simulations. We develop a set of algorithms for generating coronary vascular networks from large point clouds. These algorithms sort the point cloud, simplify its network structure without information loss, and produce subgraphs based on given, physiologically meaningful parameters. The data were originally collected from optical fluorescence cryomicrotome images and processed before their use here.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for System-on-Chip: Myths and Realities</b>
<a href="https://arxiv.org/abs/2207.14595">arxiv:2207.14595</a>
&#x1F4C8; 3 <br>
<p>Tegg Taekyong Sung, Bo Ryu</p></summary>
<p>

**Abstract:** Neural schedulers based on deep reinforcement learning (DRL) have shown considerable potential for solving real-world resource allocation problems, as they have demonstrated significant performance gain in the domain of cluster computing. In this paper, we investigate the feasibility of neural schedulers for the domain of System-on-Chip (SoC) resource allocation through extensive experiments and comparison with non-neural, heuristic schedulers. The key finding is three-fold. First, neural schedulers designed for cluster computing domain do not work well for SoC due to i) heterogeneity of SoC computing resources and ii) variable action set caused by randomness in incoming jobs. Second, our novel neural scheduler technique, Eclectic Interaction Matching (EIM), overcomes the above challenges, thus significantly improving the existing neural schedulers. Specifically, we rationalize the underlying reasons behind the performance gain by the EIM-based neural scheduler. Third, we discover that the ratio of the average processing elements (PE) switching delay and the average PE computation time significantly impacts the performance of neural SoC schedulers even with EIM. Consequently, future neural SoC scheduler design must consider this metric as well as its implementation overhead for practical utility.

</p>
</details>

<details><summary><b>Conditioning Normalizing Flows for Rare Event Sampling</b>
<a href="https://arxiv.org/abs/2207.14530">arxiv:2207.14530</a>
&#x1F4C8; 3 <br>
<p>Sebastian Falkner, Alessandro Coretti, Salvatore Romano, Phillip Geissler, Christoph Dellago</p></summary>
<p>

**Abstract:** Understanding the dynamics of complex molecular processes is often linked to the study of infrequent transitions between long-lived stable states. The standard approach to the sampling of such rare events is to generate an ensemble of transition paths using a random walk in trajectory space. This, however, comes with the drawback of strong correlation between subsequently visited paths and with an intrinsic difficulty in parallelizing the sampling process. We propose a transition path sampling scheme based on neural-network generated configurations. These are obtained employing normalizing flows, a neural network class able to generate decorrelated samples from a given distribution. With this approach, not only are correlations between visited paths removed, but the sampling process becomes easily parallelizable. Moreover, by conditioning the normalizing flow, the sampling of configurations can be steered towards the regions of interest. We show that this allows for resolving both the thermodynamics and kinetics of the transition region.

</p>
</details>

<details><summary><b>Evaluating the Practicality of Learned Image Compression</b>
<a href="https://arxiv.org/abs/2207.14524">arxiv:2207.14524</a>
&#x1F4C8; 3 <br>
<p>Hongjiu Yu, Qiancheng Sun, Jin Hu, Xingyuan Xue, Jixiang Luo, Dailan He, Yilong Li, Pengbo Wang, Yuanyuan Wang, Yaxu Dai, Yan Wang, Hongwei Qin</p></summary>
<p>

**Abstract:** Learned image compression has achieved extraordinary rate-distortion performance in PSNR and MS-SSIM compared to traditional methods. However, it suffers from intensive computation, which is intolerable for real-world applications and leads to its limited industrial application for now. In this paper, we introduce neural architecture search (NAS) to designing more efficient networks with lower latency, and leverage quantization to accelerate the inference process. Meanwhile, efforts in engineering like multi-threading and SIMD have been made to improve efficiency. Optimized using a hybrid loss of PSNR and MS-SSIM for better visual quality, we obtain much higher MS-SSIM than JPEG, JPEG XL and AVIF over all bit rates, and PSNR between that of JPEG XL and AVIF. Our software implementation of LIC achieves comparable or even faster inference speed compared to jpeg-turbo while being multiple times faster than JPEG XL and AVIF. Besides, our implementation of LIC reaches stunning throughput of 145 fps for encoding and 208 fps for decoding on a Tesla T4 GPU for 1080p images. On CPU, the latency of our implementation is comparable with JPEG XL.

</p>
</details>

<details><summary><b>Class-Difficulty Based Methods for Long-Tailed Visual Recognition</b>
<a href="https://arxiv.org/abs/2207.14499">arxiv:2207.14499</a>
&#x1F4C8; 3 <br>
<p>Saptarshi Sinha, Hiroki Ohashi, Katsuyuki Nakamura</p></summary>
<p>

**Abstract:** Long-tailed datasets are very frequently encountered in real-world use cases where few classes or categories (known as majority or head classes) have higher number of data samples compared to the other classes (known as minority or tail classes). Training deep neural networks on such datasets gives results biased towards the head classes. So far, researchers have come up with multiple weighted loss and data re-sampling techniques in efforts to reduce the bias. However, most of such techniques assume that the tail classes are always the most difficult classes to learn and therefore need more weightage or attention. Here, we argue that the assumption might not always hold true. Therefore, we propose a novel approach to dynamically measure the instantaneous difficulty of each class during the training phase of the model. Further, we use the difficulty measures of each class to design a novel weighted loss technique called `class-wise difficulty based weighted (CDB-W) loss' and a novel data sampling technique called `class-wise difficulty based sampling (CDB-S)'. To verify the wide-scale usability of our CDB methods, we conducted extensive experiments on multiple tasks such as image classification, object detection, instance segmentation and video-action classification. Results verified that CDB-W loss and CDB-S could achieve state-of-the-art results on many class-imbalanced datasets such as ImageNet-LT, LVIS and EGTEA, that resemble real-world use cases.

</p>
</details>

<details><summary><b>FCSN: Global Context Aware Segmentation by Learning the Fourier Coefficients of Objects in Medical Images</b>
<a href="https://arxiv.org/abs/2207.14477">arxiv:2207.14477</a>
&#x1F4C8; 3 <br>
<p>Young Seok Jeon, Hongfei Yang, Mengling Feng</p></summary>
<p>

**Abstract:** The encoder-decoder model is a commonly used Deep Neural Network (DNN) model for medical image segmentation. Conventional encoder-decoder models make pixel-wise predictions focusing heavily on local patterns around the pixel. This makes it challenging to give segmentation that preserves the object's shape and topology, which often requires an understanding of the global context of the object. In this work, we propose a Fourier Coefficient Segmentation Network~(FCSN) -- a novel DNN-based model that segments an object by learning the complex Fourier coefficients of the object's masks. The Fourier coefficients are calculated by integrating over the whole contour. Therefore, for our model to make a precise estimation of the coefficients, the model is motivated to incorporate the global context of the object, leading to a more accurate segmentation of the object's shape. This global context awareness also makes our model robust to unseen local perturbations during inference, such as additive noise or motion blur that are prevalent in medical images. When FCSN is compared with other state-of-the-art models (UNet+, DeepLabV3+, UNETR) on 3 medical image segmentation tasks (ISIC\_2018, RIM\_CUP, RIM\_DISC), FCSN attains significantly lower Hausdorff scores of 19.14 (6\%), 17.42 (6\%), and 9.16 (14\%) on the 3 tasks, respectively. Moreover, FCSN is lightweight by discarding the decoder module, which incurs significant computational overhead. FCSN only requires 22.2M parameters, 82M and 10M fewer parameters than UNETR and DeepLabV3+. FCSN attains inference and training speeds of 1.6ms/img and 6.3ms/img, that is 8$\times$ and 3$\times$ faster than UNet and UNETR.

</p>
</details>

<details><summary><b>Reconstructing Sparse Illicit Supply Networks: A Case Study of Multiplex Drug Trafficking Networks</b>
<a href="https://arxiv.org/abs/2208.01739">arxiv:2208.01739</a>
&#x1F4C8; 2 <br>
<p>Jin-Zhu Yu, Mincheng Wu, Gisela Bichler, Felipe Aros-Vera, Jianxi Gao</p></summary>
<p>

**Abstract:** The network structure provides critical information for law enforcement agencies to develop effective strategies to interdict illicit supply networks. However, the complete structure of covert networks is often unavailable, thus it is crucially important to develop approaches to infer a more complete structure of covert networks. In this paper, we work on real-world multiplex drug trafficking networks extracted from an investigation report. A statistical approach built on the EM algorithm (DegEM) as well as other methods based on structural similarity are applied to reconstruct the multiplex drug trafficking network given different fractions of observed nodes and links. It is found that DegEM approach achieves the best predictive performance in terms of several accuracy metrics. Meanwhile, structural similarity-based methods perform poorly in reconstructing the drug trafficking networks due to the sparsity of links between nodes in the network. The inferred multiplex networks can be leveraged to (i) inform the decision-making on monitoring covert networks as well as allocating limited resources for collecting additional information to improve the reconstruction accuracy and (ii) develop more effective interdiction strategies.

</p>
</details>

<details><summary><b>Paddy Leaf diseases identification on Infrared Images based on Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2208.00031">arxiv:2208.00031</a>
&#x1F4C8; 2 <br>
<p>Petchiammal A, Briskline Kiruba S, D. Murugan</p></summary>
<p>

**Abstract:** Agriculture is the mainstay of human society because it is an essential need for every organism. Paddy cultivation is very significant so far as humans are concerned, largely in the Asian continent, and it is one of the staple foods. However, plant diseases in agriculture lead to depletion in productivity. Plant diseases are generally caused by pests, insects, and pathogens that decrease productivity to a large scale if not controlled within a particular time. Eventually, one cannot see an increase in paddy yield. Accurate and timely identification of plant diseases can help farmers mitigate losses due to pests and diseases. Recently, deep learning techniques have been used to identify paddy diseases and overcome these problems. This paper implements a convolutional neural network (CNN) based on a model and tests a public dataset consisting of 636 infrared image samples with five paddy disease classes and one healthy class. The proposed model proficiently identified and classified paddy diseases of five different types and achieved an accuracy of 88.28%

</p>
</details>

<details><summary><b>Encoder-Decoder Architecture for 3D Seismic Inversion</b>
<a href="https://arxiv.org/abs/2207.14789">arxiv:2207.14789</a>
&#x1F4C8; 2 <br>
<p>Maayan Gelboim, Amir Adler, Yen Sun, Mauricio Araya-Polo</p></summary>
<p>

**Abstract:** Inverting seismic data to build 3D geological structures is a challenging task due to the overwhelming amount of acquired seismic data, and the very-high computational load due to iterative numerical solutions of the wave equation, as required by industry-standard tools such as Full Waveform Inversion (FWI). For example, in an area with surface dimensions of 4.5km $\times$ 4.5km, hundreds of seismic shot-gather cubes are required for 3D model reconstruction, leading to Terabytes of recorded data. This paper presents a deep learning solution for the reconstruction of realistic 3D models in the presence of field noise recorded in seismic surveys. We implement and analyze a convolutional encoder-decoder architecture that efficiently processes the entire collection of hundreds of seismic shot-gather cubes. The proposed solution demonstrates that realistic 3D models can be reconstructed with a structural similarity index measure (SSIM) of 0.8554 (out of 1.0) in the presence of field noise at 10dB signal-to-noise ratio.

</p>
</details>

<details><summary><b>Big Data and Analytics Implementation in Tertiary Institutions to Predict Students Performance in Nigeria</b>
<a href="https://arxiv.org/abs/2207.14677">arxiv:2207.14677</a>
&#x1F4C8; 2 <br>
<p>Ozioma Collins Oguine, Kanyifeechukwu Jane Oguine, Hashim Ibrahim Bisallah</p></summary>
<p>

**Abstract:** The term Big Data has been coined to refer to the gargantuan bulk of data that cannot be dealt with by traditional data-handling techniques. Big Data is still a novel concept, and in the following literature, we intend to elaborate on it in a palpable fashion. It commences with the concept of the subject in itself, along with its properties and the two general approaches to dealing with it. Big Data provides an opportunity for educational Institutions to use their Information Technology resources strategically to improve educational quality, guide students to higher completion rates and improve student persistence and outcomes. This paper explores the attributes of big data that are relevant to educational institutions, investigates the factors influencing the adoption of big data and analytics in learning institutions, and seeks to establish the limiting factors hindering the use of big data in Institutions of higher learning. A survey research design was adopted in conducting this research, and Questionnaires were the instrument employed for data collection.

</p>
</details>

<details><summary><b>Ensemble forecasts in reproducing kernel Hilbert space family: dynamical systems in Wonderland</b>
<a href="https://arxiv.org/abs/2207.14653">arxiv:2207.14653</a>
&#x1F4C8; 2 <br>
<p>Bérenger Hug, Etienne Memin, Gilles Tissot</p></summary>
<p>

**Abstract:** A methodological framework for ensemble-based estimation and simulation of high dimensional dynamical systems such as the oceanic or atmospheric flows is proposed. To that end, the dynamical system is embedded in a family of reproducing kernel Hilbert spaces with kernel functions driven by the dynamics. This family is nicknamed Wonderland for its appealing properties. In Wonderland the Koopman and Perron-Frobenius operators are unitary and uniformly continuous. This property warrants they can be expressed in exponential series of diagonalizable bounded infinitesimal generators. Access to Lyapunov exponents and to exact ensemble based expressions of the tangent linear dynamics are directly available as well. Wonderland enables us the devise of strikingly simple ensemble data assimilation methods for trajectory reconstructions in terms of constant-in-time linear combinations of trajectory samples. Such an embarrassingly simple strategy is made possible through a fully justified superposition principle ensuing from several fundamental theorems.

</p>
</details>

<details><summary><b>Cyclic Policy Distillation: Sample-Efficient Sim-to-Real Reinforcement Learning with Domain Randomization</b>
<a href="https://arxiv.org/abs/2207.14561">arxiv:2207.14561</a>
&#x1F4C8; 2 <br>
<p>Yuki Kadokawa, Lingwei Zhu, Yoshihisa Tsurumine, Takamitsu Matsubara</p></summary>
<p>

**Abstract:** Deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. However, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. To alleviate this problem, we propose a sample-efficient method named Cyclic Policy Distillation (CPD). CPD divides the range of randomized parameters into several small sub-domains and assigns a local policy to each sub-domain. Then, the learning of local policies is performed while {\it cyclically} transitioning the target sub-domain to neighboring sub-domains and exploiting the learned values/policies of the neighbor sub-domains with a monotonic policy-improvement scheme. Finally, all of the learned local policies are distilled into a global policy for sim-to-real transfer. The effectiveness and sample efficiency of CPD are demonstrated through simulations with four tasks (Pendulum from OpenAIGym and Pusher, Swimmer, and HalfCheetah from Mujoco), and a real-robot ball-dispersal task.

</p>
</details>

<details><summary><b>Effectiveness of Transformer Models on IoT Security Detection in StackOverflow Discussions</b>
<a href="https://arxiv.org/abs/2207.14542">arxiv:2207.14542</a>
&#x1F4C8; 2 <br>
<p>Nibir Chandra Mandal, G. M. Shahariar, Md. Tanvir Rouf Shawon</p></summary>
<p>

**Abstract:** The Internet of Things (IoT) is an emerging concept that directly links to the billions of physical items, or "things", that are connected to the Internet and are all gathering and exchanging information between devices and systems. However, IoT devices were not built with security in mind, which might lead to security vulnerabilities in a multi-device system. Traditionally, we investigated IoT issues by polling IoT developers and specialists. This technique, however, is not scalable since surveying all IoT developers is not feasible. Another way to look into IoT issues is to look at IoT developer discussions on major online development forums like Stack Overflow (SO). However, finding discussions that are relevant to IoT issues is challenging since they are frequently not categorized with IoT-related terms. In this paper, we present the "IoT Security Dataset", a domain-specific dataset of 7147 samples focused solely on IoT security discussions. As there are no automated tools to label these samples, we manually labeled them. We further employed multiple transformer models to automatically detect security discussions. Through rigorous investigations, we found that IoT security discussions are different and more complex than traditional security discussions. We demonstrated a considerable performance loss (up to 44%) of transformer models on cross-domain datasets when we transferred knowledge from a general-purpose dataset "Opiner", supporting our claim. Thus, we built a domain-specific IoT security detector with an F1-Score of 0.69. We have made the dataset public in the hope that developers would learn more about the security discussion and vendors would enhance their concerns about product security.

</p>
</details>

<details><summary><b>Some Practice for Improving the Search Results of E-commerce</b>
<a href="https://arxiv.org/abs/2208.00108">arxiv:2208.00108</a>
&#x1F4C8; 1 <br>
<p>Fanyou Wu, Yang Liu, Rado Gazo, Benes Bedrich, Xiaobo Qu</p></summary>
<p>

**Abstract:** In the Amazon KDD Cup 2022, we aim to apply natural language processing methods to improve the quality of search results that can significantly enhance user experience and engagement with search engines for e-commerce. We discuss our practical solution for this competition, ranking 6th in task one, 2nd in task two, and 2nd in task 3. The code is available at https://github.com/wufanyou/KDD-Cup-2022-Amazon.

</p>
</details>


{% endraw %}
Prev: [2022.07.28]({{ '/2022/07/28/2022.07.28.html' | relative_url }})  Next: [2022.07.30]({{ '/2022/07/30/2022.07.30.html' | relative_url }})